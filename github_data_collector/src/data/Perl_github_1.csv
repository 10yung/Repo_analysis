,full_name,forks_count,open_issues_count,watchers_count,comment_count,star_count,issue_content
0,so-fancy/diff-so-fancy,287,11,13231,,13231,"I recently started using `diff-so-fancy`. I really like the way new files are being shown. I used to miss them when scrolling quickly even with `diff-highlight`, that doesn't happen anymore.

What happens to me now is that I miss the beginning of a new commit when running a command like `git log -p`.

Suggestion: similarly to how files are shown like:
```
______________________________________...
file.txt:123
______________________________________...
``` 
could commits look like:
```
******************************************************...
******************************************************...
commit 123abc...
author: Donald Knuth
Commit Title
* commit
* description
******************************************************...
******************************************************...
______________________________________...
file.txt:123
______________________________________...
file.txt diffs




______________________________________...
file2.txt:123
______________________________________...
file2.txt diffs



******************************************************...
******************************************************...
commit 123abd...
author: Genghis Khan
Commit Title
* commit
* description
******************************************************...
******************************************************...
______________________________________...
file.txt:123
______________________________________...
file.txt diffs




______________________________________...
file2.txt:123
______________________________________...
file2.txt diffs




```
The rationale behind it is: file diffs and part of a commit. Hence the graphical representation of a commit should be ""larger"" than the one for each file. Similarly to how ""Title1"" is often displayed in a larger font than ""Title2"", in docs for example.

Cheers.[[[[[Next]]]]]Dear,

First, thanks a lot for this wonderful package… which should be standard!

Second, I'm reporting weird output in my environment (MinTTY on Cygwin):
- The ruler is 1-char too long (coming back onto the next physical line)
- The ruler is not nice as yours: always the same, in both values of the parameter

![image](https://user-images.githubusercontent.com/1748469/74652237-e1dbcc80-5185-11ea-8616-f8fe2307983d.png)

Any idea and/or help?

Best regards!

"
1,brendangregg/FlameGraph,1121,107,9505,,9505,"We use Debian and vanilla kernel packaging capabilities, and those produce versiond `vmlinux` files with frames like these:

```
        ffffffffb8f6abf0 nf_hook_slow+0x40 (/usr/lib/debug/boot/vmlinux-5.4.14-cloudflare-2020.1.11)
        ffffffffb8f74051 ip_local_deliver+0xd1 (/usr/lib/debug/boot/vmlinux-5.4.14-cloudflare-2020.1.11)
        ffffffffb8f7412c ip_rcv+0xbc (/usr/lib/debug/boot/vmlinux-5.4.14-cloudflare-2020.1.11)
```

This change allows matching for those as kernel functions.[[[[[Next]]]]]This also re-generates all the perf collapse files to account for the missing stack in each one.

r? @brendangregg 

Fixes #230."
2,AlDanial/cloc,572,13,9293,,9293,"I have tried to use `cloc --diff` using version 1.84 on Windows 10.
The paths `./` or absolute paths `C://` does not yield same results. 
Although moving to the same directory provides good results.
please see below.

Notice that i provided `./` relative paths for subdirectories
**It provides 0 Same and 0 Modified results. All results are either added or removed**

```
PS C:\CAFlowRepos\esw-ai> $BaseDir=""./CAFlow_9443428a301d7e59bd690aefd23f07654b78e076""                                                                                                                                
PS C:\CAFlowRepos\esw-ai> $TargetDir=""./CAFlow_d80df9d30d8b146323639a79e87667c33366f49c""                                                                                                                              
PS C:\CAFlowRepos\esw-ai> $Alignment=""alignment1.txt""                                                                                                                                                                 
PS C:\CAFlowRepos\esw-ai> cloc --diff --ignore-case --skip-uniqueness --ignore-whitespace --diff-alignment=$Alignment --diff-timeout 300 $BaseDir $TargetDir                                                               
760 text files.
    1071 text files.
Wrote alignment1.txtfiles.
     327 files ignored.

github.com/AlDanial/cloc v 1.84  T=7.00 s (248.7 files/s, 119447.7 lines/s)
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
C#
 same                            0              0              0              0
 modified                        0              0              0              0
 added                         709          25142           2835         611215
 removed                       470           8106           1538          90716
JSON
 same                            0              0              0              0
 modified                        0              0              0              0
 added                          72              3              0          38715
 removed                        38              3              0          17055
Sass
 same                            0              0              0              0
 modified                        0              0              0              0
 added                          90           1292           1017           7413
 removed                        92           1279           1018           7388
CSS
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           2             16             16           3516
 removed                         2             11             16           3509
TypeScript
 same                            0              0              0              0
 modified                        0              0              0              0
 added                          46            414            166           2073
 removed                        55            393            174           1928
HTML
 same                            0              0              0              0
 modified                        0              0              0              0
 added                          17             65             91           1205
 removed                        19            128             95            987
Java
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           2            131            195            781
 removed                         2            131            195            781
MSBuild script
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           9             56              5            696
 removed                         9             55              5            421
YAML
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           2              8              6            235
 removed                         3             10              8            263
Markdown
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           7             95              0            267
 removed                         5             80              0            183
Groovy
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           6             19              2            178
 removed                         5             15              0            141
PowerShell
 same                            0              0              0              0
 modified                        0              0              0              0
 added                          26             62             31            130
 removed                        13             70             50            155
XML
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           3              2              0            125
 removed                         3              0              0            117
JavaScript
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           4             12             66             92
 removed                         4             12             66             92
R
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           1              9              2             61
 removed                         1              9              2             61
Bourne Shell
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           8             27             14             54
 removed                         7             24             14             48
Dockerfile
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           3             17             18             49
 removed                         2             10              9             28
C/C++ Header
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           1             12              0             18
 removed                         1             12              0             18
DOS Batch
 same                            0              0              0              0
 modified                        0              0              0              0
 added                           1              5              0             13
 removed                         1              5              0             13
-------------------------------------------------------------------------------
SUM:
 same                            0              0              0              0
 modified                        0              0              0              0
 added                        1009          27387           4464         666836
 removed                       732          10353           3190         123904
-------------------------------------------------------------------------------
PS C:\CAFlowRepos\esw-ai>                                                                                                                                                                                             
```

Notice the change that i provided names of subdirectories in this case directly

**This way it produces correct results**


```
PS C:\CAFlowRepos\esw-ai> $BaseDir=""CAFlow_9443428a301d7e59bd690aefd23f07654b78e076""                                                                                                                                  
PS C:\CAFlowRepos\esw-ai> $TargetDir=""CAFlow_d80df9d30d8b146323639a79e87667c33366f49c""                                                                                                                                
PS C:\CAFlowRepos\esw-ai> $Alignment=""alignment2.txt""                                                                                                                                                                 
PS C:\CAFlowRepos\esw-ai> cloc --diff --ignore-case --skip-uniqueness --ignore-whitespace --diff-alignment=$Alignment --diff-timeout 300 $BaseDir $TargetDir

     760 text files.
    1071 text files.
Wrote alignment2.txtfiles.
     329 files ignored.

github.com/AlDanial/cloc v 1.84  T=25.00 s (49.1 files/s, 28480.7 lines/s)
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
C#
 same                          150           4797            905          80016
 modified                      158              0             44           2134
 added                         401          18524           1886         529065
 removed                       162           1488            589           8566
JSON
 same                           13              3              0          11812
 modified                       16              0              0           2760
 added                          43              0              0          24143
 removed                         9              0              0           2483
Sass
 same                           79           1107           1017           7290
 modified                        6              0              0              7
 added                           5             26              0            116
 removed                         7             13              1             91
CSS
 same                            1              1             16           3464
 modified                        1              0              0             34
 added                           0              5              0             18
 removed                         0              0              0             11
TypeScript
 same                           15             55            158            725
 modified                       17              0              1            148
 added                          14            239              7           1200
 removed                        23            218             15           1055
HTML
 same                            2              3             88            131
 modified                        6              0              0            113
 added                           9             25              3            961
 removed                        11             88              7            743
Java
 same                            2            131            195            781
 modified                        0              0              0              0
 added                           0              0              0              0
 removed                         0              0              0              0
MSBuild script
 same                            0              0              5            362
 modified                        9              0              0             41
 added                           0              2              0            293
 removed                         0              1              0             18
Markdown
 same                            2             14              0            123
 modified                        3              0              0             38
 added                           2             15              0            106
 removed                         0              0              0             22
YAML
 same                            0              0              6            219
 modified                        2              0              0             14
 added                           0              0              0              2
 removed                         1              2              2             30
PowerShell
 same                            2              2              5             22
 modified                        7              0              9             34
 added                          17             33             17             74
 removed                         4             41             36             99
Groovy
 same                            1              2              0            135
 modified                        4              0              0              6
 added                           1              4              2             37
 removed                         0              0              0              0
XML
 same                            1              0              0            115
 modified                        2              0              0              2
 added                           0              2              0              8
 removed                         0              0              0              0
JavaScript
 same                            4             12             66             92
 modified                        0              0              0              0
 added                           0              0              0              0
 removed                         0              0              0              0
Dockerfile
 same                            0              0              2              3
 modified                        1              0              0              1
 added                           2             15             16             45
 removed                         1              8              7             24
R
 same                            1              9              2             61
 modified                        0              0              0              0
 added                           0              0              0              0
 removed                         0              0              0              0
Bourne Shell
 same                            5             18             14             46
 modified                        2              0              0              2
 added                           1              3              0              6
 removed                         0              0              0              0
C/C++ Header
 same                            1             12              0             18
 modified                        0              0              0              0
 added                           0              0              0              0
 removed                         0              0              0              0
DOS Batch
 same                            0              0              0             11
 modified                        1              0              0              2
 added                           0              0              0              0
 removed                         0              0              0              0
-------------------------------------------------------------------------------
SUM:
 same                          279           6166           2479         105426
 modified                      235              0             54           5336
 added                         495          18893           1931         556074
 removed                       218           1859            657          13142
-------------------------------------------------------------------------------
PS C:\CAFlowRepos\esw-ai>
```[[[[[Next]]]]]Command example:cloc  --git --diff e6add3c3e2dd8ff32d62f953821213042f580e92~1 e6add3c3e2dd8ff32d62f953821213042f580e92
current: Calculate all files, unmodified files will also be counted
Expectation: I hope that I can control only the modified files through parameter control.
"
3,sitaramc/gitolite,980,4,7686,,7686,"Hey, I've send you email 2 weeks ago - no response. Let the pull request hang around now."
4,major/MySQLTuner-perl,966,35,5982,,5982,"Current version shows to be - Version 1.7.15

I'm currently running - MySQLTuner 1.7.19 - Major Hayden <major@mhtx.net>

Please comment about correct version + correct download link, as...

[http://mysqltuner.com/mysqltuner.pl](http://mysqltuner.com/mysqltuner.pl) redirects to the old version.

Thanks.[[[[[Next]]]]]Dear maintainer,

The recent merge (https://github.com/major/MySQLTuner-perl/commit/1e8b32a25396907917c4c64d2fdd3ecb1e1a1337#diff-2cc6ed630854d08fdcfd8c17c70d25ef) broke mysqltuner.pl syntax. There seem to be a non-resolved merge conflict in this file (l.1 is `<<<<<<< HEAD`)"
5,Jack000/Expose,242,21,4128,,4128,"`rsync` is missing from the dependency list and its required in line [expose.sh:972](https://github.com/Jack000/Expose/blob/a1a7c27ddecb2858e10a369247535a1b4c721fbf/expose.sh#L972) to copy the resources to `_site`.[[[[[Next]]]]]Hello,
I'm new to expose but I already love it.
I have a small issue.
Reading the docs is possible to have some yaml vars in the text including custom variables to be used in a custom template.
Now, I have my text file that looks like this:

`A train to somewhere?
---
title: new adventures
textcolor: #ffffff
---`

I would expect to see the first line in the image and the part between '---' parsed as yaml.
The results is that no text is displayed in the image.
If I remove the yaml part

`A train to somewhere?`

I see text as expected in the image.
I also tried removing the custom var ""title"" but the result is the same, if there's yaml section in the file the text is not displayed in the image.

Am I doing something wrong?
Thanks!"
6,sullo/nikto,630,79,3778,,3778,"Hi @sullo,

see that below~
root@kali:~# nikto -h xxx.xxx.xxx.xxx -port 443 -C all
- Nikto v2.1.6
---------------------------------------------------------------------------
+ Target IP:          
+ Target Hostname:   
+ Target Port:        
..
..

...
+ Allowed HTTP Methods: GET, HEAD, POST, PUT, DELETE, OPTIONS 
**+ OSVDB-397: HTTP method ('Allow' Header): 'PUT' method could allow clients to save files on the web server.
+ OSVDB-5646: HTTP method ('Allow' Header): 'DELETE' may allow clients to remove files on the web server.**



Is this really vulnerable?
To be able understand why is OSVDB(OSVDB-397,OSVDB-5646)?

reference:
- https://tomcat.apache.org/tomcat-8.0-doc/changelog.html
 : Tomcat 8.0.16 [ 57187: Regression handling the special * URL. (remm)]
- https://bz.apache.org/bugzilla/show_bug.cgi?id=57187
- https://svn.apache.org/viewvc/tomcat/trunk/java/org/apache/catalina/connector/CoyoteAdapter.java?r1=1636547&r2=1637839&pathrev=1637839

Thank you.
[[[[[Next]]]]]Hi guys,

It seems like the XML output file structure changed since earlier version which now includes a ""second set"" of <niktoscan> tags:


```
<niktoscan> 
<!DOCTYPE niktoscan SYSTEM ""/var/lib/nikto/docs/nikto.dtd"">
<niktoscan hoststest=""0"" options=""-h http://scanme.webscantest.com/ -o scanme_nikto -Format xml"" version=""2.1.6"" scanstart=""Thu Apr 16 16:14:47 2020"" scanend=""Wed Dec 31 19:00:00 1969"" scanelapsed="" seconds"" nxmlversion=""1.2"">
...  
</niktoscan> 
</niktoscan>
```

In the past, the file structure was like this: https://github.com/dradis/dradis-nikto/blob/master/spec/fixtures/files/localhost.xml

So as this requires to manually modify the xml output before it can be ingested by Dradis, I would like to know if this ""double tags format"" will be the one used from now on. If that's the case, I'll put in a request to the Dradis folks so they can modify the parser.

Thanks!
"
7,x0rz/EQGRP,2117,14,3631,,3631,"

 <a href=""http://www.freebiebitcoin.com"">Earn free bitcoin</a>[[[[[Next]]]]]"
8,sarabander/sicp-pdf,443,12,3616,,3616,"For example you cannot search for the word ""dotted"" as in a dotted pair.

For example, on page 645, the words ""dotted tails"" are overlayed with doed tails.
Note the unicode ligature.

On page 611:
""All of the company’s em-
ployees aend this meeting.""
Note the ligature again.
The ft ligature is also commonly wrongly overlayed, as in page 633 ""After Louis types this""[[[[[Next]]]]]Is it possible to create a Japanese version, or better yet a line-by-line Japnese-English bilingual version of SICP?
Here is the translation https://sicp.iijlab.net/fulltext/xcont.html"
9,openresty/nginx-tutorials,417,2,2436,,2436,"string的index是从1开始的，因此index为-1，实际的正index应为string.len(s),而不是string.len(s)+init (string.len(s)+(-1))
应该写成string.len(s)+init+1[[[[[Next]]]]]求中文教程继续更新。
你的文档很好啊，看完能学到很多东西，为什么没有继续更新了呢？
"
10,thoughtbot/rcm,108,28,2329,,2329,"  * Fix #206 : messages for -C being a copy so can't update
  * Fix #254 : expect at least one existing dotfiles directory[[[[[Next]]]]]See https://github.com/Homebrew/homebrew-core/commit/acac1ed26447b9f9acad937dc74451c503ac8ad6"
11,mojolicious/mojo,513,45,2193,,2193,"### Summary
This is a short PR to add a link to the `all_text` method, from `text`, explaining that `all_text` should be used to extract text content from all descendant nodes. 

### Motivation
Simply to make it a little clearer to the reader, perhaps as yet unfamiliar with the framework who may have missed the already explicit documentation, and providing a helpful link to the `all_text` method. 

### References

https://perlmonks.org/?node_id=11115910
[[[[[Next]]]]]* Mojolicious version: 8.40
* Perl version: 5.18
* Operating system: Centos6

### Steps to reproduce the behavior
Logging a `Mojo::Exception` results in premature stringification of the exception when the app log has a context. This occurs by default on exceptions as a combination of
https://metacpan.org/release/Mojolicious/source/lib/Mojo/Log.pm#L72
and https://metacpan.org/release/Mojolicious/source/lib/Mojolicious/Plugin/DefaultHelpers.pm#L176

To see this in action:
```
$ cat log.t
use strict;
use warnings;

use Log::Any::Adapter;
use Test::Mojo;
use Test::More;

{
    package Log::Any::Adapter::Mojo::Test; # this package wants an error object
    use base qw(Log::Any::Adapter::Base);

    use Test::More;

    sub structured {
        my ($self, $level, $category, @log_args) = @_;

        # This fails!
        isa_ok($log_args[0], 'Mojo::Exception')
            or diag explain $log_args[0];
        # Do something with Mojo::Exception
    }

    sub is_error { 1 }
    sub is_debug { 0 }
}

{
    package Mojolicious::Test::Log; # an app that dies
    use Mojolicious::Lite;
    use Mojolicious::Plugin::Log::Any;

    plugin 'Log::Any';

    get '/error' => sub { die ""Log Me"" };
}

subtest test_exceptions => sub {
    my $t = Test::Mojo->new('Mojolicious::Test::Log');
    Log::Any::Adapter->set('Mojo::Test');

    # this succeeds, but the logging itself fails
    $t->get_ok('/error')
      ->status_is(500 => 'threw exception');
};

done_testing();
$ prove log.t
```

### Expected behavior

The test should pass.
That would mean that we're not stringifying a `Mojo::Exception`, and whatever log mechanism is in use can eg. extract a stack trace from the exception.

A real-life example of needing the exception _object_ is https://metacpan.org/release/Log-Any-Adapter-Sentry-Raven/source/lib/Log/Any/Adapter/Sentry/Raven.pm#L135

### Actual behavior
Instead, the exception is stringified by `Mojo::Log`.
```
$ prove log.t
log.t ..
    #   Failed test 'The class (or class-like) '[error] [ab129e02] Log Me at log.t line 36.
    # ' isa 'Mojo::Exception''
    #   at /$path/Mojo/Log/Role/AttachLogger.pm line 71.
    #     The class (or class-like) '[error] [ab129e02] Log Me at log.t line 36.
    # ' isn't a 'Mojo::Exception'
    # [error] [b34e468f] Log Me at log.t line 36.
    # Looks like you failed 1 test of 3.
log.t .. 1/?
#   Failed test 'test_exceptions'
#   at log.t line 46.
# Looks like you failed 1 test of 1.
log.t .. Dubious, test returned 1 (wstat 256, 0x100)
Failed 1/1 subtests

Test Summary Report
-------------------
log.t (Wstat: 256 Tests: 1 Failed: 1)
  Failed test:  1
  Non-zero exit status: 1
Files=1, Tests=1,  0 wallclock secs ( 0.01 usr  0.01 sys +  0.33 cusr  0.06 csys =  0.41 CPU)
Result: FAIL
```

### Suggested Fix
Prepend to the exception _message_ rather than the exception itself.
```
sub _log {
  my ($self, $level) = (shift, pop);
  my @msgs = ref $_[0] eq 'CODE' ? $_[0]() : @_;
+  if ($self->context) {
+    if (@msgs == 1 && blessed($msgs[0]) && $msgs[0]->isa('Mojo::Exception')) {
+      $msgs[0]->message(""$self->{context} "".$msgs[0]->message);
+    }
+    else {
+      $msgs[0] = ""$self->{context} $msgs[0]"";
+    }
+  }
-  $msgs[0] = ""$self->{context} $msgs[0]"" if $self->{context};
  ($self->{parent} || $self)->emit('message', $level, @msgs);
}
```"
12,SpiderLabs/owasp-modsecurity-crs,641,62,2131,,2131,"This PR fixes #650.

A small footnote for this modification: I generated a [spreadsheet](https://docs.google.com/spreadsheets/d/1x6tg8RyAELw0h4y1uoMEi3rPiLfrNFpK598kyXLtogs/edit#gid=1586050007) for the better visibility of changes.

The column E/F contains the status of actions before, J/K after the modification. The `PL control` is a formula, if the `id` of the rule is ended up with `...011`, `...012`. If it's ""yes"", then `Need 'ver' act.` is ""no"". This means the `PL control` rules didn't got the `ver` action now.

`Need to add` column is ""yes"" if the action should be at rule (it's not PL control rule) but there isn't yet. If this is ""yes"" the script added it.

If the rule needs the `ver` and contains it after the modification, then the `Check` field is `OK` - but doesn't matter that the action was present or not. All fields must be `OK` in this column.

The `Changed` fields indicates that a change has been made (was not present before - it present after).

Definition of `PL control`: 
```
id < 1000000 and (id % 1000 >= 100 or id % 1000 <= 10)
  or
id > 1000000
```
I think this form describes the rules with `skipAfter` actions and doesn't affect exclusion rules. The modification affects all other `SecRule` and `SecAction` entries.

Let me know if there are still missing any `ver` action, or if it's unnecessary.

Note, of course, the modification follows the [expected sequence of actions](https://github.com/SpiderLabs/owasp-modsecurity-crs/wiki/Order-of-ModSecurity-Actions-in-CRS-rules).[[[[[Next]]]]]This is the Agenda for the Monthly CRS Chat.

The chat is going to happen on https://owasp.slack.com in the channel #coreruleset on Monday, May 4, at 20:30 CET.

## Items on the Agenda:

Previous Meetings decisions: [here](https://github.com/SpiderLabs/owasp-modsecurity-crs/issues/1733#issuecomment-610394063)

### PRs

* #1707 New ldap injection rule 921200 (fixes issue #276)
* #1708 Perf issue with regexes that start with repeating digits
* #1710 Add word boundaries around values in SQL tautologies (942130) - reviewed, approved by @franbuehler. Ready to be merged.
* #1734 Fix content type whitelist (feedback @franbuehler: rule only on test system, @lifeforms?)
* #1735 Fix link for 941310
* #1738 WordPress: exclude additional URL fields in profile editor 
* #1739 XenForo: update exclusions
* #1740 Make Content-Type case insensitive (on hold until #1748 is merged)
* #1742 Suppress rule 200002 when editing contacts in Nextcloud
* #1743 Allow REPORT requests without Content-Type header in Nextcloud
* #1744 Update README.md
* #1745 Changed variable to lowercase (fixed #1741)
* #1746 Fix 921120 FP (resolves issue #1615)
* #1748 Content-Type var fix ModSec v2 v3 900220 soap xml
* #1750 Added 'ver' action with current version to all necessary rules (fix for #650)


<!-- Add PRs in ascending order -->

#### PRs on hold

* #1602 932200: PL1 RCE bypass uninitialized variable (DRAFT) (Has been in need of action for a long time)
* #1616 Revert #578 (Needs action)
* #1663 RE2 compatibility for 920120 (no feedback from CDN unfortunately) 
* #1667 Remove /util/docker folder from v3.3/dev branch (now in dedicated repo) (In progress)
* #1674 Extend sql having in rule 942230 (no feedback from CDN unfortunately) 
* #1690 Update REQUEST-920-PROTOCOL-ENFORCEMENT.conf (Needs action)

### Other items

* GitHub migration scheduled for March 18 had to be cancelled / postponed. TW and CRS do not agree on the procedure. Migration team: @dune73, @lifeforms and @fzipi.
* 

Feel free to add items as you see fit either above, or below as comments.


### Open Issues

In January 2020, we decided to look into 10 issues at the chat every month. But only after the Other items. Pick the issues before the meeting and list them below.

    Issue slot 1:
    Issue slot 2:
    Issue slot 3:
    Issue slot 4:
    Issue slot 5:
    Issue slot 6:
    Issue slot 7:
    Issue slot 8:
    Issue slot 9:
    Issue slot 10:

If you are not yet on the OWASP Slack, here is your invite: https://join.slack.com/t/owasp/shared_invite/enQtNjExMTc3MTg0MzU4LWQ2Nzg3NGJiZGQ2MjRmNzkzN2Q4YzU1MWYyZTdjYjA2ZTA5M2RkNzE2ZjdkNzI5ZThhOWY5MjljYWZmYmY4ZjM .
Everybody is welcome to join our community chat."
13,YabataDesign/afterglow-theme,140,50,2130,,2130,"Are you willing to add a free license to this project?[[[[[Next]]]]]windows10, sublime3 build3200

![image](https://user-images.githubusercontent.com/39895740/54988237-fa347d00-4ff0-11e9-99f7-662acb81086c.png)
"
14,CNSRE/ABTestingGateway,706,74,2110,,2110,"[[[[[Next]]]]]bug：多级分流造成的 shdict key 名冲突

url如： http://api.xxx.com/prod/test/xxx-service/passService/payCallback

uri /prod/test/xxx-service/passService/payCallback

一级策略为： 第二段URL的值对应返回 后端upstream
转发规则： test == 》 up：test  dev ==> up:dev

二级策略为： 第一段URL的值对应返回 后端upstream
转发规则： prod == 》 up: pord   release ==>release

问题：
当 uri 为： /prod/prod/paytem-service/swiftpassService/payCallback
转发up为： prod   正常

在shat key 过期前访问
uri 为： /release/prod/paytem-service/swiftpassService/payCallback
转发up为： prod   不正常 正确应是 release

原因：

文件： diversion\diversion.lua +356

setUpstream 的时候 key用的是 策略匹配后得出来的值，这里得出来的是： 第一次key是 prod ，第二次key是  release(当前没有set的直接读到缓存))。对应的第一级分流的值为 -1，第二级分流的值为 prod和release（第二次）

文件：diversion\diversion.lua +248
文件：abtesting\utils\cache.lua +118

_M.getUpstream   get key 的时候用的是策略匹配出来的值作为key， 第一次是 prod ，第二次应该是  release

因为匹配缓存中的Upstream使用的是for循环进行多级分流匹配，第一级分流(first)get 到了upstream（返回了prod）  第二级分流（second）没有匹配到upstream（release应该是nil）。
但匹配到 first级别的upstream 后就直接返回了，此时的upstream是错误的，正确的应该是 second级别的内容。


解决：  将 分级的 shdict key名进行区分

文件： diversion\diversion.lua 
upstreamCache:setUpstream 处，将key名修改成不能使用 ”策略匹配后得出来的值“我这里使用的是：
334行local info下面添加：local shat_key = {idx,""-"",info}
注释 upstreamCache:setUpstream(info, -1) 替换添加：upstreamCache:setUpstream(table.concat(shat_key), -1)
注释 upstreamCache:setUpstream(info, upstream) 替换添加：upstreamCache:setUpstream(table.concat(shat_key), upstream)

文件：abtesting\utils\cache.lua +118

113行 local info  = usertable[idx] 下面添加： local shat_key = {idx,""-"",info}
注释： local ups   = cache:get(info) 替换添加： local ups   = cache:get(table.concat(shat_key))

不知这样解决是否有问题，目前我还在自行测试 @BG2BKK "
15,sqitchers/sqitch,168,58,1985,,1985,"I've tried running as administrator. I've also tried installing sqlite3 seperately. 
```
perl -v

This is perl 5, version 30, subversion 2 (v5.30.2) built for MSWin32-x64-multi-thread
...
```

```
PS C:\Windows\system32> cpan install App::Sqitch
Loading internal logger. Log::Log4perl recommended for better logging
CPAN: CPAN::SQLite loaded ok (v0.217)
Database was generated on Wed, 29 Apr 2020 22:31:01 GMT
Running install for module 'App::Sqitch'
CPAN: Digest::SHA loaded ok (v6.02)
CPAN: Compress::Zlib loaded ok (v2.093)
Checksum for C:\STRAWB~1\cpan\sources\authors\id\D\DW\DWHEELER\App-Sqitch-v1.0.0.tar.gz ok
CPAN: Archive::Tar loaded ok (v2.36)
CPAN: YAML::XS loaded ok (v0.81)
CPAN: CPAN::Meta::Requirements loaded ok (v2.140)
CPAN: Parse::CPAN::Meta loaded ok (v2.150010)
CPAN: CPAN::Meta loaded ok (v2.150010)
CPAN: Module::CoreList loaded ok (v5.20200314)
Configuring D/DW/DWHEELER/App-Sqitch-v1.0.0.tar.gz with Build.PL
Created MYMETA.yml and MYMETA.json
Creating new 'Build' script for 'App-Sqitch' version 'v1.0.0'
  DWHEELER/App-Sqitch-v1.0.0.tar.gz
  C:\Strawberry\perl\bin\perl.exe Build.PL -- OK
Running Build for D/DW/DWHEELER/App-Sqitch-v1.0.0.tar.gz
Building App-Sqitch
  DWHEELER/App-Sqitch-v1.0.0.tar.gz
  C:\Strawberry\perl\bin\perl.exe ./Build -- OK
Running Build test for DWHEELER/App-Sqitch-v1.0.0.tar.gz
t/add.t ............. ok
t/base.t ............ 85/189 '--nosuchscript.ply--' is not recognized as an internal or external command,
operable program or batch file.
t/base.t ............ ok
t/blank.t ........... ok
t/bundle.t .......... ok
t/change.t .......... ok
t/changelist.t ...... ok
t/checkout.t ........ ok
t/command.t ......... ok
t/config.t .......... ok
t/configuration.t ... ok
t/conn_cmd_role.t ... ok
t/cx_cmd_role.t ..... ok
t/datetime.t ........ ok
t/depend.t .......... ok
t/deploy.t .......... ok
t/engine.t .......... ok
t/engine_cmd.t ...... ok
t/exasol.t .......... ok
t/firebird.t ........ ok
t/help.t ............ ok
t/init.t ............ ok
t/item_formatter.t .. ok
t/linelist.t ........ ok
t/log.t ............. ok
t/mooseless.t ....... ok
t/mysql.t ........... ok
t/options.t ......... ok
t/oracle.t .......... ok
t/pg.t .............. ok
t/plan.t ............ ok
t/plan_cmd.t ........ ok
t/pragma.t .......... ok
t/rebase.t .......... ok
t/revert.t .......... ok
t/rework.t .......... ok
t/show.t ............ ok
t/snowflake.t ....... ok
t/sqlite.t .......... 60/? Usage: .read FILE
""sqlite3.exe"" unexpectedly returned exit value 1
# Tests were run but no plan was declared and done_testing() was not seen.
# Looks like your test exited with 255 just after 121.
t/sqlite.t .......... Dubious, test returned 255 (wstat 65280, 0xff00)
All 121 subtests passed
t/status.t .......... ok
t/tag.t ............. ok
t/tag_cmd.t ......... ok
t/target.t .......... ok
t/target_cmd.t ...... ok
t/upgrade.t ......... ok
t/verify.t .......... ok
t/vertica.t ......... ok
t/x.t ............... ok

Test Summary Report
-------------------
t/sqlite.t        (Wstat: 65280 Tests: 121 Failed: 0)
  Non-zero exit status: 255
  Parse errors: No plan found in TAP output
Files=47, Tests=6998, 81 wallclock secs ( 1.53 usr +  0.27 sys =  1.80 CPU)
Result: FAIL
Failed 1/47 test programs. 0/6998 subtests failed.
  DWHEELER/App-Sqitch-v1.0.0.tar.gz
  C:\Strawberry\perl\bin\perl.exe ./Build test -- NOT OK
//hint// to see the cpan-testers results for installing this module, try:
  reports DWHEELER/App-Sqitch-v1.0.0.tar.gz
Stopping: 'install' failed for 'App::Sqitch'.
```[[[[[Next]]]]]I am running a windows server with MySQL I installed together with XAMPP - MySQL Ver 15.1 Distrib 10.4.11-MariaDB, for Win64 (AMD64), source revision 7c2c420b70b19cc02b5281127205e876f3919dad

When I run sqitch deploy I keep getting error - ""mysql.exe"" unexpectedly returned exit value 1 and a lot of other version information about MySQL as below:

`C:\Users\Me\Desktop\vivo-db>sqitch deploy
Adding registry tables to db:mysql://root@/sqitch
mysql.exe  Ver 15.1 Distrib 10.4.11-MariaDB, for Win64 (AMD64), source revision 7c2c420b70b19cc02b5281127205e876f3919dad
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Usage: mysql.exe [OPTIONS] [database]

Default options are read from the following files in the given order:
C:\Windows\my.ini C:\Windows\my.cnf C:\my.ini C:\my.cnf C:\xampp\mysql\my.ini C:\xampp\mysql\my.cnf C:\xampp\mysql\data\my.ini C:\xampp\mysql\data\my.cnf
The following groups are read: mysql mariadb-client client client-server client-mariadb
The following options may be given as the first argument:
--print-defaults          Print the program argument list and exit.
--no-defaults             Don't read default options from any option file.
The following specify which files/extra groups are read (specified before remaining options):
--defaults-file=#         Only read default options from the given file #.
--defaults-extra-file=#   Read this file after the global files are read.
--defaults-group-suffix=# Additionally read default groups with # appended as a suffix.

  -?, --help          Display this help and exit.
  -I, --help          Synonym for -?
  --abort-source-on-error
                      Abort 'source filename' operations in case of errors
  --auto-rehash       Enable automatic rehashing. One doesn't need to use
                      'rehash' to get table and field completion, but startup
                      and reconnecting may take a longer time. Disable with
                      --disable-auto-rehash.
                      (Defaults to on; use --skip-auto-rehash to disable.)
  -A, --no-auto-rehash
                      No automatic rehashing. One has to use 'rehash' to get
                      table and field completion. This gives a quicker start of
                      mysql and disables rehashing on reconnect.
  --auto-vertical-output
                      Automatically switch to vertical output mode if the
                      result is wider than the terminal width.
  -B, --batch         Don't use history file. Disable interactive behavior.
                      (Enables --silent.)
  --binary-as-hex     Print binary data as hex
  --character-sets-dir=name
                      Directory for character set files.
  --column-type-info  Display column type information.
  -c, --comments      Preserve comments. Send comments to the server. The
                      default is --skip-comments (discard comments), enable
                      with --comments.
  -C, --compress      Use compression in server/client protocol.
  -#, --debug[=#]     This is a non-debug version. Catch this and exit.
  --debug-check       Check memory and open file usage at exit.
  -T, --debug-info    Print some debug info at exit.
  -D, --database=name Database to use.
  --default-character-set=name
                      Set the default character set.
  --delimiter=name    Delimiter to be used.
  -e, --execute=name  Execute command and quit. (Disables --force and history
                      file.)
  -E, --vertical      Print the output of a query (rows) vertically.
  -f, --force         Continue even if we get an SQL error. Sets
                      abort-source-on-error to 0
  -G, --named-commands
                      Enable named commands. Named commands mean this program's
                      internal commands; see mysql> help . When enabled, the
                      named commands can be used from any line of the query,
                      otherwise only from the first line, before an enter.
                      Disable with --disable-named-commands. This option is
                      disabled by default.
  -i, --ignore-spaces Ignore space after function names.
  --init-command=name SQL Command to execute when connecting to MariaDB server.
                      Will automatically be re-executed when reconnecting.
  --local-infile      Enable/disable LOAD DATA LOCAL INFILE.
  -b, --no-beep       Turn off beep on error.
  -h, --host=name     Connect to host.
  -H, --html          Produce HTML output.
  -X, --xml           Produce XML output.
  --line-numbers      Write line numbers for errors.
                      (Defaults to on; use --skip-line-numbers to disable.)
  -L, --skip-line-numbers
                      Don't write line number for errors.
  -n, --unbuffered    Flush buffer after each query.
  --column-names      Write column names in results.
                      (Defaults to on; use --skip-column-names to disable.)
  -N, --skip-column-names
                      Don't write column names in results.
  --sigint-ignore     Ignore SIGINT (CTRL-C).
  -o, --one-database  Ignore statements except those that occur while the
                      default database is the one named at the command line.
  -p, --password[=name]
                      Password to use when connecting to server. If password is
                      not given it's asked from the tty.
  -W, --pipe          Use named pipes to connect to server.
  -P, --port=#        Port number to use for connection or 0 for default to, in
                      order of preference, my.cnf, $MYSQL_TCP_PORT,
                      /etc/services, built-in default (3306).
  --progress-reports  Get progress reports for long running commands (like
                      ALTER TABLE)
                      (Defaults to on; use --skip-progress-reports to disable.)
  --prompt=name       Set the command line prompt to this value.
  --protocol=name     The protocol to use for connection (tcp, socket, pipe).
  -q, --quick         Don't cache result, print it row by row. This may slow
                      down the server if the output is suspended. Doesn't use
                      history file.
  -r, --raw           Write fields without conversion. Used with --batch.
  --reconnect         Reconnect if the connection is lost. Disable with
                      --disable-reconnect. This option is enabled by default.
                      (Defaults to on; use --skip-reconnect to disable.)
  -s, --silent        Be more silent. Print results with a tab as separator,
                      each row on new line.
  -S, --socket=name   The socket file to use for connection.
  --ssl               Enable SSL for connection (automatically enabled with
                      other flags).
  --ssl-ca=name       CA file in PEM format (check OpenSSL docs, implies
                      --ssl).
  --ssl-capath=name   CA directory (check OpenSSL docs, implies --ssl).
  --ssl-cert=name     X509 cert in PEM format (implies --ssl).
  --ssl-cipher=name   SSL cipher to use (implies --ssl).
  --ssl-key=name      X509 key in PEM format (implies --ssl).
  --ssl-crl=name      Certificate revocation list (implies --ssl).
  --ssl-crlpath=name  Certificate revocation list path (implies --ssl).
  --tls-version=name  TLS protocol version for secure connection.
  --ssl-verify-server-cert
                      Verify server's ""Common Name"" in its cert against
                      hostname used when connecting. This option is disabled by
                      default.
  -t, --table         Output in table format.
  --tee=name          Append everything into outfile. See interactive help (\h)
                      also. Does not work in batch mode. Disable with
                      --disable-tee. This option is disabled by default.
  -u, --user=name     User for login if not current user.
  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.
  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.
  -v, --verbose       Write more. (-v -v -v gives the table output format).
  -V, --version       Output version information and exit.
  -w, --wait          Wait and retry if connection is down.
  --connect-timeout=# Number of seconds before connection timeout.
  --max-allowed-packet=#
                      The maximum packet length to send to or receive from
                      server.
  --net-buffer-length=#
                      The buffer size for TCP/IP and socket communication.
  --select-limit=#    Automatic limit for SELECT when using --safe-updates.
  --max-join-size=#   Automatic limit for rows in a join when using
                      --safe-updates.
  --secure-auth       Refuse client connecting to server if it uses old
                      (pre-4.1.1) protocol.
  --server-arg=name   Send embedded server this as a parameter.
  --show-warnings     Show warnings after every statement.
  --plugin-dir=name   Directory for client-side plugins.
  --default-auth=name Default authentication client-side plugin to use.
  --binary-mode       By default, ASCII '\0' is disallowed and '\r\n' is
                      translated to '\n'. This switch turns off both features,
                      and also turns off parsing of all clientcommands except
                      \C and DELIMITER, in non-interactive mode (for input
                      piped to mysql or loaded using the 'source' command).
                      This is necessary when processing output from mysqlbinlog
                      that may contain blobs.
  --connect-expired-password
                      Notify the server that this client is prepared to handle
                      expired password sandbox mode even if --batch was
                      specified.

Variables (--variable-name=value)
and boolean options {FALSE|TRUE}  Value (after reading options)
--------------------------------- ----------------------------------------
abort-source-on-error             TRUE
auto-rehash                       TRUE
auto-vertical-output              FALSE
binary-as-hex                     FALSE
character-sets-dir                (No default value)
column-type-info                  FALSE
comments                          FALSE
compress                          FALSE
debug-check                       FALSE
debug-info                        FALSE
database                          test
default-character-set             auto
delimiter                         ;
vertical                          FALSE
force                             FALSE
named-commands                    FALSE
ignore-spaces                     FALSE
init-command                      (No default value)
local-infile                      FALSE
no-beep                           FALSE
host                              (No default value)
html                              FALSE
xml                               FALSE
line-numbers                      TRUE
unbuffered                        FALSE
column-names                      FALSE
sigint-ignore                     FALSE
port                              0
progress-reports                  FALSE
prompt                            \N [\d]>
protocol
quick                             FALSE
raw                               FALSE
reconnect                         FALSE
socket                            (No default value)
ssl                               FALSE
ssl-ca                            (No default value)
ssl-capath                        (No default value)
ssl-cert                          (No default value)
ssl-cipher                        (No default value)
ssl-key                           (No default value)
ssl-crl                           (No default value)
ssl-crlpath                       (No default value)
tls-version                       (No default value)
ssl-verify-server-cert            FALSE
table                             FALSE
user                              root
safe-updates                      FALSE
i-am-a-dummy                      FALSE
connect-timeout                   0
max-allowed-packet                16777216
net-buffer-length                 16384
select-limit                      1000
max-join-size                     1000000
secure-auth                       FALSE
show-warnings                     FALSE
plugin-dir                        (No default value)
default-auth                      (No default value)
binary-mode                       FALSE
connect-expired-password          FALSE
""mysql.exe"" unexpectedly returned exit value 1


C:\Users\Me\Desktop\vivo-db>mysql --version
mysql  Ver 15.1 Distrib 10.4.11-MariaDB, for Win64 (AMD64), source revision 7c2c420b70b19cc02b5281127205e876f3919dad`

"
16,tobie/ua-parser,522,0,1978,,1978,
17,jfcoz/postgresqltuner,112,8,1951,,1951,"i'm using the script on a windows machine. Everything is ok, but it cannot run OS command. 

This is the output: 

```
perl C:\Users\Dario\postgresqltuner.pl --host=[host] --database=[db] --user=[user] --password=[pswd]
Use of uninitialized value $ENV{""HOME""} in concatenation (.) or string at C:\Users\Dario\postgresqltuner.pl line 73.
postgresqltuner.pl version 1.0.1
[31m[BAD]     [0mI CANNOT invoke executables, my report will be incomplete
Connecting to localhost:5432 database postgres as user 'postgres'...
Impossibile trovare il percorso specificato.
[OK]      The user acount used by me for reporting has superuser rights on this PostgreSQL instance
=====  OS information  =====
[UNKNOWN] Unable to run OS commands on localhost.  You will obtain no OS-related information
=====  General instance informations  =====
-----  PostgreSQL version  -----
[OK]      You are using the latest PostreSQL major version (12.1)
-----  Uptime  -----
[INFO]    Service uptime:  13m 50s
[WARN]    Uptime less than 1 day.  This report may be inaccurate
-----  Databases  -----
[INFO]    Database count (except templates): 1
[INFO]    Database list (except templates): postgres
-----  Extensions  -----
[INFO]    Number of activated extensions: 2
[INFO]    Activated extensions: plpgsql adminpack
[WARN]    Extension pg_stat_statements is disabled in database postgres
-----  Users  -----
[OK]      No user account will expire in less than 7 days
[OK]      No user with password=username
[OK]      Password encryption enabled
-----  Connection information  -----
[INFO]    max_connections: 100
[INFO]    Current used connections: 7 (7.00%)
[INFO]    3 connections are reserved for super user (3.00%)
[INFO]    Average connection age:  11m 38s
-----  Memory usage  -----
[INFO]    Configured work_mem: 4.00 MB
[INFO]    Using an average ratio of work_mem buffers by connection of 150% (use --wmp to change it)
[INFO]    Total work_mem (per connection): 6.00 MB
[INFO]    shared_buffers: 128.00 MB
[INFO]    Track activity reserved size: 0.00 B
[WARN]    maintenance_work_mem is less or equal to its default value.  Increase it to reduce maintenance tasks duration
[INFO]    Max memory usage:
                  shared_buffers (128.00 MB)
                + max_connections * work_mem * average_work_mem_buffers_per_connection (100 * 4.00 MB * 150 / 100 = 600.00 MB)
                + autovacuum_max_workers * maintenance_work_mem (3 * 64.00 MB = 192.00 MB)
                + track activity size (0.00 B)
                = 920.00 MB
[INFO]    effective_cache_size: 4.00 GB
[INFO]    Cumulated size of all databases: 22.91 MB
[WARN]    shared_buffer is too big for the total databases size, uselessly using memory
[UNKNOWN] OS total mem unknown: unable to analyse PostgreSQL memory usage
-----  Huge Pages  -----
[UNKNOWN] No Huge Pages on this OS
-----  Logs  -----
[OK]      log_hostname is off: no reverse DNS lookup latency
[WARN]    Log of long queries deactivated.  It will be more difficult to optimize query performance
[OK]      log_statement=none
-----  Two-phase commit  -----
[OK]      Currently there is no two-phase commit transaction
-----  Autovacuum  -----
[OK]      autovacuum is activated
[INFO]    autovacuum_max_workers: 3
-----  Checkpoint  -----
[WARN]    checkpoint_completion_target (0.5) is low
[INFO]    Given those settings PostgreSQL may (depending on its workload) ask the kernel to write (to the storage) up to 1024.00 MB in a timeframe lasting 150 seconds <=> 6.83 MB bytes/second during this timeframe.  You may want to check that your storage is able to cope with this, along with all other I/O (non-writing queries, other software...) operations potentially active during this timeframe.  If this seems inadequate check max_wal_size, checkpoint_timeout and checkpoint_completion_target
-----  Storage  -----
[OK]      fsync is on
[OK]      synchronize_seqscans is on
-----  WAL  -----
-----  Planner  -----
[OK]      I/O cost settings are set at their default values
[UNKNOWN] I have no information about the rotational/SSD storage: I'm unable to check random_page_cost and seq_page_cost settings
[BAD]     Some plan features are disabled: enable_partitionwise_aggregate,enable_partitionwise_join
=====  Database information for database postgres  =====
-----  Database size  -----
[INFO]    Database postgres total size: 8.17 MB
[INFO]    Database postgres tables size: 5.16 MB (63.19%)
[INFO]    Database postgres indexes size: 3.01 MB (36.81%)
-----  Tablespace location  -----
[OK]      No tablespace in PGDATA
-----  Shared buffer hit rate  -----
[INFO]    shared_buffer_heap_hit_rate: 98.69%
[INFO]    shared_buffer_toast_hit_rate: 57.14%
[INFO]    shared_buffer_tidx_hit_rate: 83.72%
[INFO]    shared_buffer_idx_hit_rate: 99.43%
[OK]      This is very good (if this PostgreSQL instance was recently used as it usually is, and was not stopped since)
-----  Indexes  -----
[OK]      No invalid index
[OK]      No unused indexes
-----  Procedures  -----
[OK]      No procedures with default costs

=====  Configuration advice  =====
-----  checkpoint  -----
[MEDIUM] checkpoint_completion_target is low.  Some checkpoints may abruptly overload the storage with write commands for a long time, slowing running queries down.  To avoid such temporary overload you may balance checkpoint writes using a higher value
-----  extension  -----
[LOW] Enable pg_stat_statements in database postgres to collect statistics on all queries (not only those longer than log_min_duration_statement)
-----  reporting  -----
[HIGH] Please configure your .ssh/config to allow postgresqltuner.pl to connect via ssh to localhost without password authentication.  This will allow it to collect more system informations
```[[[[[Next]]]]]<!--- Provide a general summary of the issue in the Title above -->

When specifying the hostname of the database, `postgresqltuner.pl` currently assumes that it should be able to ssh to this instance and then run commands locally.  However, with an AWS RDS database, this is not possible.  Sure, you can wait for the ssh command to time out, and then the code continues, after issuing the error ""I CANNOT invoke executables, my report will be incomplete"".  It would be nice to have an option where we can skip the attempt to use ssh, and go straight to the DBI interface.

## Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->

`postgresqltuner.pl --host=dbhost --database=testdb --user=username --password=qwerty --skip-ssh`

Causes the program to skip the attempt to connect to the database via ssh, and go straight to the DBI.

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior. Paste the relevant part from output -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->

`postgresqltuner.pl --host=dbhost --database=testdb --user=username --password=qwerty`

Causes the program to first attempt to connect to the database host via ssh, so that it can run local commands.  If this ssh attempt fails, then it falls back to using DBI.

## Possible Solution
<!--- Not obligatory, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement the addition or change -->

Add a `--skip-ssh` option that allows you to skip the attempt to connect via ssh to the database host.

## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code to reproduce, if relevant -->

This isn't really a bug (per se), so there are no steps to replicate.

## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

I'm using AWS RDS, where it is not possible to ssh into the database host, and therefore it doesn't make sense to have the program always try to connect via ssh first, before it falls back to DBI.

## Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Version used: postgresqltuner.pl version 1.0.1
* PostgreSQL version: 9.6.11
* Operating System and version: Various clients, but server is AWS RDS

"
18,darold/pgbadger,229,8,1941,,1941,"Got this error overnight:

LOG: Ok, generating HTML daily report into /var/groupsio/misc/pgbadger/2020/04/30/...
Modification of non-creatable array value attempted, subscript -1 at /usr/local/bin/pgbadger line 19572.

We ship logs off the database server hourly, and here is command line that generated this error:

/usr/local/bin/pgbadger -j 5 -I postgresql-2020-04-30_01.log -O /var/xxx/misc/pgbadger

This is on Centos 7, latest pgbadger, postgresql 9.6.

We just started using pgbadger yesterday, so we have less than 24 hours of using it.[[[[[Next]]]]]Hi there! 
After running pgBadger I've marked that there is no user names in **Queries** reports. Although, I able to see statistic by users in the ""Connections per user"" report. 

**pbBadger version**: 11.2
**Command:** `pgbadger rds_postgres.log -f stderr -p ""%t:%r:%u@%d:[%p]:""`
**Postgres version:** `10.10`
**postgres.conf:** 
- log_line_prefix = %t:%r:%u@%d:[%p]:
- other configuration values are taken from [pgBadger documentation](https://github.com/darold/pgbadger#postgresql-configuration)
<details>
  <summary>Here is a part of my log</summary>
2020-04-27 23:00:00 UTC:10.100.101.185(15749):user-name@user-name-db:[18264]:LOG: duration: 6.281 ms statement: FETCH 100 FROM c6
2020-04-27 23:00:00 UTC:10.100.98.159(8572):user-name@user-name-db:[21814]:LOG: duration: 0.217 ms statement: DISCARD ALL
2020-04-27 23:00:00 UTC:10.100.98.159(8572):user-name@user-name-db:[21814]:LOG: duration: 0.032 ms parse <unnamed>: set session ""company.correlationid"" = 'e3909a79-a471-4ff1-ba3c-0ed136c55cc7'
2020-04-27 23:00:00 UTC:10.100.98.159(8572):user-name@user-name-db:[21814]:LOG: duration: 0.011 ms bind <unnamed>: set session ""company.correlationid"" = 'e3909a79-a471-4ff1-ba3c-0ed136c55cc7'
2020-04-27 23:00:00 UTC:10.100.98.159(8572):user-name@user-name-db:[21814]:LOG: duration: 3.511 ms execute <unnamed>: set session ""company.correlationid"" = 'e3909a79-a471-4ff1-ba3c-0ed136c55cc7'
2020-04-27 23:00:00 UTC:10.100.98.159(8572):user-name@user-name-db:[21814]:LOG: duration: 0.142 ms parse <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Jim', 'John', 'Liz')

2020-04-27 23:00:00 UTC:10.100.98.159(39823):user-name@user-name-db:[21815]:LOG: duration: 0.208 ms statement: DISCARD ALL
2020-04-27 23:00:00 UTC:10.100.98.159(39823):user-name@user-name-db:[21815]:LOG: duration: 0.018 ms parse <unnamed>: set session ""company.correlationid"" = '4ac6301b-0124-4369-948e-c758d4ffc2c2'
2020-04-27 23:00:00 UTC:10.100.98.159(39823):user-name@user-name-db:[21815]:LOG: duration: 0.006 ms bind <unnamed>: set session ""company.correlationid"" = '4ac6301b-0124-4369-948e-c758d4ffc2c2'
2020-04-27 23:00:00 UTC:10.100.98.159(39823):user-name@user-name-db:[21815]:LOG: duration: 0.009 ms execute <unnamed>: set session ""company.correlationid"" = '4ac6301b-0124-4369-948e-c758d4ffc2c2'
2020-04-27 23:00:00 UTC:10.100.98.159(39823):user-name@user-name-db:[21815]:LOG: duration: 0.111 ms parse <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')

2020-04-27 23:00:00 UTC:10.100.98.159(39823):user-name@user-name-db:[21815]:LOG: duration: 0.155 ms bind <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')

2020-04-27 23:00:00 UTC:10.100.98.159(39823):user-name@user-name-db:[21815]:LOG: duration: 0.052 ms execute <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')

2020-04-27 23:00:00 UTC:10.100.98.159(8572):user-name@user-name-db:[21814]:LOG: duration: 3.154 ms bind <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')

2020-04-27 23:00:00 UTC:10.100.98.159(30724):user-name@user-name-db:[21816]:LOG: duration: 0.847 ms statement: DISCARD ALL
2020-04-27 23:00:00 UTC:10.100.98.159(30724):user-name@user-name-db:[21816]:LOG: duration: 0.019 ms parse <unnamed>: set session ""company.correlationid"" = '8d7f3321-15b4-4423-a20b-4b2d310bd94a'
2020-04-27 23:00:00 UTC:10.100.98.159(30724):user-name@user-name-db:[21816]:LOG: duration: 0.005 ms bind <unnamed>: set session ""company.correlationid"" = '8d7f3321-15b4-4423-a20b-4b2d310bd94a'
2020-04-27 23:00:00 UTC:10.100.98.159(30724):user-name@user-name-db:[21816]:LOG: duration: 0.008 ms execute <unnamed>: set session ""company.correlationid"" = '8d7f3321-15b4-4423-a20b-4b2d310bd94a'
2020-04-27 23:00:00 UTC:10.100.98.159(30724):user-name@user-name-db:[21816]:LOG: duration: 0.252 ms parse <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')

2020-04-27 23:00:00 UTC:10.100.98.159(30724):user-name@user-name-db:[21816]:LOG: duration: 0.573 ms bind <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')

2020-04-27 23:00:00 UTC:10.100.98.159(30724):user-name@user-name-db:[21816]:LOG: duration: 0.054 ms execute <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')

2020-04-27 23:00:00 UTC:10.100.98.159(19609):user-name@user-name-db:[21817]:LOG: duration: 0.195 ms statement: DISCARD ALL
2020-04-27 23:00:00 UTC:10.100.98.159(19609):user-name@user-name-db:[21817]:LOG: duration: 0.024 ms parse <unnamed>: set session ""company.correlationid"" = 'e3909a79-a471-4ff1-ba3c-0ed136c55cc7'
2020-04-27 23:00:00 UTC:10.100.98.159(19609):user-name@user-name-db:[21817]:LOG: duration: 0.006 ms bind <unnamed>: set session ""company.correlationid"" = 'e3909a79-a471-4ff1-ba3c-0ed136c55cc7'
2020-04-27 23:00:00 UTC:10.100.98.159(19609):user-name@user-name-db:[21817]:LOG: duration: 0.008 ms execute <unnamed>: set session ""company.correlationid"" = 'e3909a79-a471-4ff1-ba3c-0ed136c55cc7'
2020-04-27 23:00:00 UTC:10.100.98.159(19609):user-name@user-name-db:[21817]:LOG: duration: 0.284 ms parse <unnamed>: SELECT
t1.""firstName"",
t1.""lastName""
FROM
""Employees"" t1
WHERE
t1.firstName IN ('Kate', 'Ann', 'Tom')
</details>
"
19,sjdy521/Mojo-Webqq,348,15,1780,,1780,"- RT
- Linux QQ全新回归
- 支持x64、ARM64、MIPS64四种架构
- https://im.qq.com/linuxqq/index.html
[[[[[Next]]]]]由于业务调整，webQQ即将在2019年1月1日停止服务。请到im.qq.com下载QQ客户端使用，感谢你对QQ的支持。
https://web2.qq.com"
20,rsnapshot/rsnapshot,182,54,1702,,1702,"Hi,

I don't understand how I should set up my configuration to make my backup to a remote host (via ssh?)
I currently have
```
snapshot_root   /mnt/backup/rsnapshot
backup  /home/          localhost/
backup  /etc/           localhost/
backup  /usr/local/     localhost/
```

should I just change localhost by the name/IP of the server?[[[[[Next]]]]]Hi @sgpinkus ,

first of all - thanks for maintaining rsnapshot! :+1: 

Maybe you can suggest to merge [rsnapshot-ng](https://github.com/AenonDynamics/rsnapshot-ng) in the future as major release (v2). I've created the fork when rsnapshot was unmaintained.

it includes a new project structure, [Node.js based testcases](https://github.com/AenonDynamics/rsnapshot-ng/tree/ng/test), full [systemd support](https://github.com/AenonDynamics/rsnapshot-ng/tree/ng/systemd) and i've removed all the old/deprecated stuff as well as some minor enhancements (new config parser regex with space delimiters).

due to some breaking changes it cannot by merged into the current v1 branch.

best regards, Andi"
21,imapsync/imapsync,274,20,1599,,1599,"- there should be tests for the new search()
- there should be tests for the newly repaird top()
- search() should get fancier, dunno how
- search() should be documented ... er... when it's ... desgined properly
[[[[[Next]]]]]I'm trying to sync a mailbox where the password of the source mailbox has an opening bracket. This leads to the following error:

```
Host1: connecting and login on host1 [example.com] port [993] with user [me@example.com]
Host1 banner: * OK [CAPABILITY IMAP4rev1 SASL-IR LOGIN-REFERRALS ID ENABLE IDLE NAMESPACE LITERAL+ AUTH=PLAIN AUTH=LOGIN] Dovecot ready.
Host1: example.com says it has CAPABILITY for AUTHENTICATE LOGIN
Host1 failure: Error login on [example.com] with user [me@example.com] auth [LOGIN]: 2 BAD Missing ')'
```

It looks like the error comes directly from the remote mailserver. So how do I need to provide such a password, so imapsync can provide it in the right way to the remote mailserver?

Thanks in advance
Andi"
22,duckduckgo/duckduckgo,216,30,1538,,1538,"When I search for `es6 capitalize`, many of the resulting pages do not include the word 'capitalize' (or 'capitalise'). This is true even if I search for `es6 +capitalize`, `es6 ""capitalize""` or `es6 +""capitalize""`.

I don't know what else to do frankly. When I enter a keyword, I want the search engine to search for that keyword. Isn't that why I'm entering a keyword in the first place?! Just don't ignore what users are typing in.[[[[[Next]]]]]Not sure if I've assigned this to the right person to review.  

I'm upgrading our Perl modules and I'm upgrading Perl.  One of the things I'm doing is making sure the changes don't cause syntax errors in modules or scripts.  These 2 modules fail to compile (perl -c).  I believe this code is unused so I'd like to remove it so I don't continuously run into this issue when doing upgrades.

Thanks!"
23,beyondgrep/ack2,149,9,1524,,1524,"For #670.

Ignore uppercase characters in regex meta-characters, character escapes, and other constructs.  For example, --smart-case should see all lowercase here:

    ack --smart-case '--s\x6Dart\Wcas\N{LATIN SMALL LETTER E}'

On the other hand, it will now see uppercase ""M"" and ""E"" here:

    ack --smart-case '--s\115art-cas\x{0045}'[[[[[Next]]]]]File::Temp::tempdir() internally calls File::Path::rmtree() to implement the
'CLEANUP => 1' option.  A security vulnernability was discovered in rmtree()
in early 2017.  This vulnerability has been addressed in File::Path versions
2.14 and later; a thus patched version of File::Path will appear in Perl-5.28
to be released in spring 2018.

The security correction changes the functionality of rmtree() when not called
with a true value as its third positional argument:

    rmtree($my_tempdir, 0, 0);

As of File::Path 2.14, this syntax will no longer remove directories for which
the user lacks both 'read' and 'execute' permissions.  For example, any
directory whose numerical permissions are octal 0000 or 0200 will no longer be
deleted.

The file for which this patch is being submitted contains a chmod() call with
0000 permissions.  While, even if this patch is not applied, all tests in the
file will continue to PASS, the 0000 directories will not be deleted and the
person running the test will be shown warnings that some directories have not
been deleted.  The patch attached addresses this situation by restoring owner
'read' and 'execute' permissions to the directory before the call to tempdir()
goes out of scope.  This will once again remove the tempdirs, eliminate the
warnings and avert user confusion."
24,InteliSecureLabs/Linux_Exploit_Suggester,403,4,1397,,1397,"Linux exploit suggestor doesnt suggest exploits for kernel version 4.x  . Update of the script with the exploits for Kernel 4.x is needed.
[[[[[Next]]]]]Hi,
I tested this on a local box, here is the output I got

$ perl ./Linux_Exploit_Suggester.pl -k 4.2.0

Kernel local: 4.2.0

Searching among 65 exploits...

Possible Exploits:

and then it immediately exited.

Unsure whether its unable to search from any exploits or just could not find any."
25,munin-monitoring/munin,405,133,1389,,1389,"**Describe the bug**

The graphs for memory using the varnish_ plugin are empty.

**To Reproduce**
Steps to reproduce the behavior:
1. Install varnish via apt on Ubuntu 18.04
2. Download the varnish_ plugin from the munin master repo (the one packed with Ubuntu throws compilation errors)
3. Enable the plugin using suggest
4. Observe the graphs

**Expected behavior**

The graph data is created.


**Software**
OS Ubuntu 18.04
Munin 2.037
Varnish 5.2.1

**Additional context**
This appears to be something to do with the print_dynamic subroutine in the plugin. I've created a Work In Progress PR here https://github.com/munin-monitoring/munin/pull/1320 this semi-fixes it, it allows the values to show in the graph but they're not showing the correct numbers. This is stretching my Perl skills a bit so if someone else could have a look and see if we can get this sorted I'd appreciate it. For now as a work around I've made a simple bash script to grab the stats I need.[[[[[Next]]]]]"
26,jimsalterjrs/sanoid,140,66,1344,,1344,Fixes #533 [[[[[Next]]]]]Fixes #532
27,openresty/openresty-systemtap-toolkit,279,27,1283,,1283,"when run ngx-active-reqs by stap 4.0 without the ""-k"" option, it reports the following errors:
```
semantic error: symbol without referent: identifier 'nreqs' at <input>:133:13
    source:         if (nreqs || !0) {
                            ^
```
so we can assign the $keep_waiting const to a var to fix it[[[[[Next]]]]]error is:
semantic error: while resolving probe point: identifier 'process' at <input>:5:7
        source: probe process(""/usr/sbin/nginx"").function(""ngx_process_events_and_timers""),
                      ^

semantic error: no match

Pass 2: analysis failed.  [man error::pass2]
Number of similar error messages suppressed: 1.
Rerun with -v to see them.

and but this command work correctly
stap -e 'probe begin { printf(""Hello, World!\n""); exit() }'
stap -e 'probe kernel.function(""sys_open"") {log(""hello world"") exit()}'"
28,get-iplayer/get_iplayer,150,1,1242,,1242,"Lock files are sometimes zero length (eg. from a disk-full
condition).  Check for this (zero lines read) and skip
trying to test for existence of a previous process if this is the
case.

It might be better to take a real lock out on the file rather than relying on process identification.  Then the OS will automatically remove the lock when the process exists.  If you can't get a lock, there is
an old process still running."
29,sjdy521/Mojo-Weixin,257,17,1140,,1140,"不知道什么时候开始，每天凌晨大概2点到4点，就会自退出登录，每天早上都要重新扫码登陆。不知道怎么回事，是腾讯那边限制了吗？
<img width=""484"" alt=""微信截图_20200426211954"" src=""https://user-images.githubusercontent.com/52463333/80308829-bf100900-8803-11ea-8ed7-340a51855967.png"">
[[[[[Next]]]]]用的也是web版的登录吗？听说“17年后的微信web登录被腾讯关了”"
30,k4rthik/git-cal,59,17,1072,,1072,"Currently, what's plotted is `weekday vs. months` within a year. 
Feature request: provide an option to plot `weekday vs. hours` within a week (averaging all weeks), in the commit's Time Zone (so 12:00 is noon and 23:59 is almost midnight for the *developer* submitting the commit).[[[[[Next]]]]]Please provide running instructions in the README"
31,kost/dvcs-ripper,242,6,1060,,1060,"```
$ rip-git -v -u http://censored/.git/ -o repo2 -t 10 -g
[i] Downloading git files from http://censored/.git/
[i] Auto-detecting 404 as 200 with 3 requests
[i] Getting correct 404 responses
[i] Using session name: fFqxEqjj
[d] found COMMIT_EDITMSG
[d] found config
[d] found description
[d] found HEAD
[d] found index
[!] Not found for packed-refs: 404 Not Found
[!] Not found for objects/info/alternates: 404 Not Found
[!] Not found for info/grafts: 404 Not Found
[d] found logs/HEAD
[d] found objects/7e/126c5c6151f8dd36abda39f0d7cd13fdb4646f
[d] found objects/a5/7903d406eeb9e7b7d0095bf4534be15322929f
[d] found objects/e9/110f8730ae517674dcc09651eb570aae7de549
[d] found objects/f9/c6bf17ec7eb376fb50ebac935328623aedb0cc
[d] found objects/d9/0016c0a550394b2051d65a817f1e658aa65892
[d] found objects/6c/5d9264a4f05e2b7d753beda8d40f2f69a714c3
[d] found objects/c7/54ac17f47495e396913993ff48fd10eb70723e
[d] found objects/4f/863231bf62ae8e337df2cdb73832b8c9842011
[d] found objects/ff/fc3436fdc898c0bbff7e134c64ddcac4d4d7b8
[d] found objects/43/2edd2aca6787c882fa2ea3edf3f1c5e224c81e
[d] found objects/2c/66d164f4008c9b6d2dce7f3ee998042f7a7c7d
[d] found refs/heads/master
[!] Please install Parallel::Prefork CPAN module for parallel requests
[i] Running git fsck to check for missing items
Checking object directories: 100% (256/256), done.
[i] Got items with git fsck: 0, Items fetched: 0
[!] No more items to fetch. That's it!
[!] Performing intelligent guessing of packed refs
Undefined subroutine &main::permutations called at /usr/bin/rip-git line 404.
```

https://github.com/kost/dvcs-ripper/blob/0672a34f35de62143859e49f178928148b97c973/rip-git.pl#L404[[[[[Next]]]]]for rip-git

`-o <s> specify output dir` works only if the output dir already exists. If it doesn't exist instead of creating it it will clone to the default `./.git/`"
32,creaktive/rainbarf,67,2,1058,,1058,"Hello,

I'm using https://github.com/powerline/powerline and try to add rainbarf. By default it looks like this in `tmux`:

![bildschirmfoto 2015-02-01 um 17 39 37](https://cloud.githubusercontent.com/assets/944459/5992814/50c68508-aa39-11e4-8744-fd40d38f0826.png)

When I now add the rainbarf through my `.tmux.conf, it'll look like this:

![bildschirmfoto 2015-02-01 um 17 41 58](https://cloud.githubusercontent.com/assets/944459/5992819/aebb5bc0-aa39-11e4-80be-c8c9d69f6580.png)

As you can see, it'll replace the complete right segement group of Powerline, but i actually want to add it as additional segment in there. 

Any ideas how to do so?

(Please note, I usually have wider shell windows, so the width in the screenshots above is not the issue of this problem)

Thanks in advance.
[[[[[Next]]]]]UTF-8 support in status bar is known to be broken (double-encoding) in GNU Screen 4.0.3 (see http://superuser.com/questions/344707/write-special-chars-in-hardstatus-of-gnu-screen).
"
33,fletcher/MultiMarkdown,549,5,1033,,1033,"Hi fletcher,

This is edge case, yes, but here's what's prompted me to patch MMdown. I use Notational Velocity (nvAlt) to write blog posts. I use MMdown w/ footnotes. I view the source and copy/paste it into posterous's html editor, and it takes the liberty of stripping out ""id"" attributes from the ""li"" footnote elements, and on top of that, chokes on the colons in the footnote ids.

This patch replaces colons with underscores. It also adds ""a name=fn_footnoteid""-style anchors — which posterous accepts — in order to give the footnotes a proper link.

I absolutely love MMdown, thanks for all the hard work.

All best,
Nano
[[[[[Next]]]]]MultiMarkdown fails to properly parse nested lists. Given this MultiMarkdown:

```
homepage

:   The official home of this project on the web.

bugtracker
:   This entry describes the bug tracking system for this distribution. It is
    a [Map](#Map) with the following valid keys:

    web
    :   a <a href=""#URI"">URI</a> pointing to a web front-end for the bug
        tracker

    mailto
    :   an email address to which bug reports can be sent

repository
:   This entry describes the source control repository for this distribution.
    It is a [Map](#Map) with the following valid keys:

    url
    :   a [URI](#URI) pointing to the repository itself

    we
    :   a [URI](#URI) pointing to a web front-end for the repository

    type
    :   a lowercase string indicating the VCS used

:   Because a URI like `http://myrepo.example.com/` is ambiguous as to type,
    producers should provide a `type` whenever a `url` key is given. The
    `type` field should be the name of the most common program used to work
    with the repository, e.g. git, svn, cvs, darcs, bzr or hg.
```

The output is:

```
<dl>
<dt>homepage</dt>
<dd>
<p>The official home of this project on the web.</p>
</dd>

<dt>bugtracker</dt>
<dd>
<p>This entry describes the bug tracking system for this distribution. It is
a <a href=""#Map"">Map</a> with the following valid keys:</p>
</dd>

</dl>

<pre><code>web
:   a &lt;a href=""#URI""&gt;URI&lt;/a&gt; pointing to a web front-end for the bug
    tracker

mailto
:   an email address to which bug reports can be sent</code></pre>

<dl>
<dt>repository</dt>
<dd>
<p>This entry describes the source control repository for this distribution.
It is a <a href=""#Map"">Map</a> with the following valid keys:</p>
</dd>

</dl>

<pre><code>url
:   a [URI](#URI) pointing to the repository itself

we
:   a [URI](#URI) pointing to a web front-end for the repository

type
:&lt;dl&gt;</code></pre>

<p><dt>a lowercase string indicating the VCS used</dt>
<dd></p>

<p>Because a URI like <code>http://myrepo.example.com/</code> is ambiguous as to type,
producers should provide a <code>type</code> whenever a <code>url</code> key is given. The
<code>type</code> field should be the name of the most common program used to work
with the repository, e.g. git, svn, cvs, darcs, bzr or hg.</p>

<p></dd></p>

<p></dl></p>
```

Wow. Here's what it should be (output generated by peg-multimarkdown):

```
<dl>
<dt>homepage
</dt>
<dd>
<p>The official home of this project on the web.</p></dd>

<dt>bugtracker
</dt>
<dd>
<p>This entry describes the bug tracking system for this distribution. It is
 a <a href=""#Map"">Map</a> with the following valid keys:</p>
<dl>
<dt>web
</dt>
<dd>a <a href=""#URI"">URI</a> pointing to a web front-end for the bug
 tracker</dd>

<dt>mailto
</dt>
<dd>an email address to which bug reports can be sent</dd>
</dl>
</dd>

<dt>repository
</dt>
<dd>
<p>This entry describes the source control repository for this distribution.
 It is a <a href=""#Map"">Map</a> with the following valid keys:</p>
<dl>
<dt>url
</dt>
<dd>a <a href=""#URI"">URI</a> pointing to the repository itself</dd>

<dt>we
</dt>
<dd>a <a href=""#URI"">URI</a> pointing to a web front-end for the repository</dd>

<dt>type
</dt>
<dd>a lowercase string indicating the VCS used</dd>
</dl>
</dd>

<dd>
<p>Because a URI like <code>http://myrepo.example.com/</code> is ambiguous as to type,
 producers should provide a <code>type</code> whenever a <code>url</code> key is given. The
 <code>type</code> field should be the name of the most common program used to work
 with the repository, e.g. git, svn, cvs, darcs, bzr or hg.</p></dd>
</dl>
```

Since I rely on Text::MultiMarkdown from CPAN in my Perl apps (which is directly ported from here), I can't use peg-multimarkdown ([yet!](https://github.com/fletcher/peg-multimarkdown/issues/46)). So a fix for this issue in the Perl version would be appreciated.

Thanks!

David
"
34,munin-monitoring/contrib,660,41,1027,,1027,"This is a fork of the redis_ plugin

Changes in the fork:

* Supports multiple redis instances
* Supports AWS elasticache and other environments where the CONFIG
command is disabled
* Uses multigraph to separate graphs by instance
* Category is 'redis'[[[[[Next]]]]]This is a fork of the php5-fpm_status plugin.

Changes from in the fork:

* Supports multiple pools using environment variables to specify urls
* Graph category is php
* Supports wget and curl
* Uses MUNIN_STATEFILE
* Added GPLv3 License"
35,webfrogs/xcode_shell,403,1,1016,,1016,
36,StefanSchroeder/Golang-Regex-Tutorial,127,5,1004,,1004,"If I have a massive regex, how do I split it over multiple lines without affecting the matching logic?[[[[[Next]]]]]Use `regexp.MustCompile` instead of `Compile` which returns an error that isn't used which leads to ""err declared and not used"" when run as is."
37,idevz/vanilla,224,3,999,,999,Is there an English version of the docs available?[[[[[Next]]]]]gitbook 中文文档404
38,lulzlabs/AirChat,148,16,991,,991,[[[[[Next]]]]]I ran into this reference needing updating while walking through the readme on debian. 
39,yoshinorim/mha4mysql-manager,393,55,991,,991,"#131 [[[[[Next]]]]]Sometimes it makes sense to isolate ssh_port as a parameter.
We can use different ssh_port in our progra."
40,infobyte/evilgrade,250,8,976,,976,"whenever i try to start evilgrade i always get this problem 
you can see that below i have pasted that and please help me resolving this problem
evilgrade>show options

Display options:
===============

.------------------------------------------------------------------------------------------------.
| Name        | Default                | Description                                             |
+-------------+------------------------+---------------------------------------------------------+
| port        |                     80 | Webserver listening port                                |
| debug       |                      1 | Debug mode                                              |
| DNSPort     |                     53 | Listen Name Server port                                 |
| DNSEnable   |                      1 | Enable DNS Server ( handle virtual request on modules ) |
| faraday     |                      0 | Enable RPC Faraday connection                           |
| DNSAnswerIp |              127.0.0.1 | Resolve VHost to ip  )                                  |
| RPCfaraday  | http://127.0.0.1:9876/ | Faraday RPC Server                                      |
| sslport     |                    443 | Webserver SSL listening port                            |
'-------------+------------------------+---------------------------------------------------------'

evilgrade>config dap
evilgrade(dap)>set agent /var/www/html/evilleaks/rev_http_main.exe
set agent, /var/www/html/evilleaks/rev_http_main.exe
evilgrade(dap)>show options

Display options:
===============

Name = Download Accelerator
Version = 1.0
Author = [""Francisco Amato < famato +[AT]+ infobytesec.com>""]
Description = """"
VirtualHost = ""(update.speedbit.com)""

.----------------------------------------------------------------------------------------------------------.
| Name        | Default                                         | Description                              |
+-------------+-------------------------------------------------+------------------------------------------+
| endsite     | update.speedbit.com/updateok.html               | Website display when finish update       |
| enable      |                                               1 | Status                                   |
| description | This critical update fix internal vulnerability | Description display in the update        |
| title       | Critical update                                 | Title name display in the update         |
| failsite    | www.speedbit.com/finishupdate.asp?noupdate=&R=0 | Website display when did't finish update |
| agent       | /var/www/html/evilleaks/rev_http_main.exe       | Agent to inject                          |
'-------------+-------------------------------------------------+------------------------------------------'

evilgrade(dap)>start
evilgrade(dap)>
[5/3/2020:13:36:13] - [WEBSERVER] - Webserver ready. Waiting for connections ...

evilgrade(dap)>
[5/3/2020:13:36:13] - [DNSSERVER] - DNS Server Ready. Waiting for Connections ...

evilgrade(dap)>

Error: [DNSSERVER] - Error Initiating DNS Server
[[[[[Next]]]]]whene i write ./evilgrade 
it shows to me this message

Can't locate RPC/XML.pm in @INC (you may need to install the RPC::XML module) (@INC contains: /root/eeee/evilgrade-master /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.30.0 /usr/local/share/perl/5.30.0 /usr/lib/x86_64-linux-gnu/perl5/5.30 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.30 /usr/share/perl/5.30 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base) at /etc/perl/isrcore/shellz.pm line 36.
Compilation failed in require at ./evilgrade line 26.
BEGIN failed--compilation aborted at ./evilgrade line 26.
"
41,p0pr0ck5/lua-resty-waf,244,34,943,,943,"https://github.com/openresty/lua-resty-upload/issues/53[[[[[Next]]]]]hi
can i change default error page for blocked request?
because after change error page waf doesn't write in log file
can you guide me?"
42,duckduckgo/zeroclickinfo-goodies,1897,63,926,,926,"### Description
The time for sunset in Toronto is off by one hour. I suspect this is due to a timezone issue.

<img width=""722"" alt=""Screen Shot 2020-04-24 at 7 23 27 PM"" src=""https://user-images.githubusercontent.com/53376/80264361-ee871000-8661-11ea-93a3-13016f9c6cde.png"">


## Steps to recreate
Search for ""Sunset in Toronto""

## People to notify
<!-- Please @mention any relevant people/organizations here:-->
[Maintainer](http://docs.duckduckhack.com/maintaining/guidelines.html): @Mailkov

## People to notify
<!-- Please @mention any relevant people/organizations here:-->

<!-- LANGUAGE LEADERS ONLY: REMOVE THIS LINE
## Get Started
- [ ] 1) Claim this issue by commenting below
- [ ] 2) Review our [Contributing Guide](https://github.com/duckduckgo/zeroclickinfo-goodies/blob/master/CONTRIBUTING.md)
- [ ] 3) [Set up your development environment](https://docs.duckduckhack.com/welcome/setup-dev-environment.html), and fork this repository
- [ ] 4) Create a Pull Request
<!-- DO NOT REMOVE -->
---

<!-- The Instant Answer ID can be found by clicking the `?` icon beside the Instant Answer result on DuckDuckGo.com -->
Instant Answer Page: https://duck.co/ia/view/sun_info
<!-- FILL THIS IN:                           ^^^^ -->
[[[[[Next]]]]]Currently, the quotation mark in the ASCII table appears as `\""`, this PR fixes it by removing the trailing `\`

<!-- 

***
DuckDuckHack is currently in Maintenance mode
Please read before submitting: https://duckduckhack.com
***

Use the following format for your Pull Request title above ^^^^^:

{IA Name}: {Description of change}

-->

## Description of new Instant Answer, or changes
Removes trailing backlash for the quotation mark in the ascii table.


## Related Issues and Discussions
/

## People to notify
/

<!-- DO NOT REMOVE -->
---

<!-- The Instant Answer ID can be found by clicking the `?` icon beside the Instant Answer result on DuckDuckGo.com -->
Instant Answer Page: https://duck.co/ia/view/ascii_table

"
43,hokaccha/nodebrew,58,14,912,,912,"Hi, I treat some Node versions but I always install yarn, npm-check, and etc. Can we omit this process?

Like this https://github.com/nvm-sh/nvm#default-global-packages-from-file-while-installing[[[[[Next]]]]]Currently, $arch for aarch64 is set as ""armv7l"".

https://github.com/hokaccha/nodebrew/blob/master/nodebrew
````perl
    } elsif ($machine =~ m/aarch64/) {
        $arch = 'armv7l';
````

Since ""armv7l"" is 32-bit, can we change it to be able to select ""arm64"" (64-bit) as well?

---

The armv7l binaries provided by Node.js are 32-bit binary while aarch64 is a 64-bit archtecture.

````sh
$ file node-v11.2.0-linux-armv7l/bin/node 
node-v11.2.0-linux-armv7l/bin/node: ELF 32-bit LSB executable, ARM, EABI5 version 1 (GNU/Linux), dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux 3.16.42, not stripped
````

This is because the original pull-request is made for Chrome OS where the OS is 64-bit but the userland is 32-bit for some efficiency.

Below is the original pull-request to add an aarch64 configuration to the Nodebrew.

PR : https://github.com/hokaccha/nodebrew/pull/69  
Merge : https://github.com/hokaccha/nodebrew/commit/5117ab1d8d84e6c8595cc4437084f20614d0dcb6

And it seems that the request came from the following issue of Chromebrew for your reference.

https://github.com/skycocker/chromebrew/issues/2405

Since aarch64 is a 64-bit architecture, it would be nice if we can choose ""arm64"" along with ""armv7l"" as well.  
Node.js offers arm64 64-bit binaries which are native to aarch64.

````sh
$ file node-v11.2.0-linux-arm64/bin/node 
node-v11.2.0-linux-arm64/bin/node: ELF 64-bit LSB executable, ARM aarch64, version 1 (GNU/Linux), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 3.7.0, BuildID[sha1]=327b8840de15505d13a9dc1ca8cfa3662ca6eb5b, not stripped
````

I need this to use Nodebrew on aarch64 systems where the userland is also 64-bit such as Debian 9 on Gemini PDA.
It may be the case for Raspberry Pi 64-bit OS as well.

Here's a patch to resolve it.  

It uses `ptrsize` to check the bitness of the userland binary by picking up the perl itself as a sample.

I have tested it on a Debian 9 aarch64 system.  
It downloads and installs the 64-bit binary with no problem.

I have not tested it for Chrome OS since I do not have one.  
I hope it works well on the Chrome OS.

````diff
diff --git a/nodebrew b/nodebrew
index 9f6da59..0273107 100755
--- a/nodebrew
+++ b/nodebrew
@@ -733,7 +733,12 @@ sub system_info {
     } elsif ($machine =~ m/armv7l/) {
         $arch = 'armv7l';
     } elsif ($machine =~ m/aarch64/) {
-        $arch = 'armv7l';
+        use Config;
+        if($Config{ptrsize} == 8) {
+          $arch = 'arm64';
+        } else {
+          $arch = 'armv7l';
+        }
     } elsif ($sysname =~ m/sunos/i) {
         # SunOS $machine => 'i86pc'. but use 64bit kernel.
         # Solaris 11 not support 32bit kernel.
````"
44,agentzh/code2ebook,128,1,861,,861,"![qq 20150115154517](https://cloud.githubusercontent.com/assets/5835688/5754016/9f7e31ce-9ccd-11e4-96e3-bf857ddf8025.png)

Should we need a  `--language` option to deal with different languages' syntax?
"
45,OpenKore/openkore,849,89,859,,859,"Openkore version git: 2020_04_29
Server: Miro (private server)
site: http://www.miragnarokonline.ml/

Bug Report / Feature Request: ""Timeout on Map Server""

Summary: bot able to login to account server and character server but then gets disconnected in map server. I'm also experiencing the same issues with non-protected private servers. Is there a general guide on fixing this error?

server:
ip 51.79.159.200
port 6900
master_version 55
version 1
serverType kRO_RagexeRE_2017_06_14b
serverEncoding Western
addTableFolders kRO/RagexeRE_2017_06_14b;translated/kRO_english;kRO
charBlockSize 155
private 1
secureLogin 0
secureLogin_type 0
secureLogin_requestCode
secureLogin_account 0
gameGuard 0

recvpackets:
https://pastebin.com/zcVMfJDr

![screenshot](https://i.imgur.com/KKEIyRL.png)

I am able to connect but it keeps freezing on Map Server and then it disconnects, how to fix this issue?

[[[[[Next]]]]]## ------------------ Openkore Issues Template ------------------
<!-- all message is hidden -->

<!-- Before submitting an issue, ensure you are on the latest release -->
<!-- Check if an issue already exists for your request -->
<!-- Please post in English if possible -->
<!-- -DON'T DELETE THIS. FILL THIS FORM. -->
<!-- -Use this template or your issue will be closed. -->

* **Openkore version git**: 
<!-- find Version git :[GitHub hash](https://github.com/OpenKore/openkore/wiki/How-to-check-version-git-you-bot.)-->
* **Server**: 
<!-- ex. iRO/kRO/bRO/cRO -->
* **Bug Report / Feature Request**:
<!-- Your problem is Bug Report / Feature Request . ex = **Bug Report / Feature Request**: Feature Request -->
* **Summary**:
<!-- Summarize your problem ex. New map is coming EP. 99 -->

I know it is something to ask for all hardworking coders and developer here because you've done so many things on this application, kudos to our developer and contributors. I want to raise an issue regarding openkore since its only running now on cRO, and the rest is has a lot to do, for example like me i want to create an account on cRO, creating an account needs mobile no. So its hard to get an account for us who lives in US or some part of the world, we really want to play and bot when we are away. But unfortunately we cant, i tried the tutorial for getting connected to a private servers but a lot of them had anti cheat programs and as for me who dont know how to code or configure im only relying and hoping that someone provides here a working server even if its private. I hope all contributors and developers try to consider making alternative to bot like on private servers or some other Ragnarok Online. I know somebody will reply to me that make your own or some thing like that, well i must say not all of us born techy please try to be nice to me. :) if you have working server pls provide the details and client to download. :) thank you very much guys. And thank you all contributors and developers who are ceaselessly working on openkore. Thanks!
"
46,miragejs/ember-cli-mirage,424,21,848,,848,"# Bug

`""ember-cli-mirage"": ""^1.1.6"",`

I have this code:
```js
  this.get('/users/me', () => {
    throw ""My fancy error""
  });
```

![chrome_rwulS3tD1M](https://user-images.githubusercontent.com/1536262/80712271-f50eff00-8b1b-11ea-8bb1-b4b487d4ad95.png)

Any mistake in route handler definition will be shown as ""[object Object]"". So we have to do this to find out what's wrong:

```js
  this.get('/users/me', () => {
   try {
     throw ""My fancy error""
    } catch(e) {
      console.error(e)
    }
  });
```[[[[[Next]]]]]Bumps [jquery](https://github.com/jquery/jquery) from 3.4.1 to 3.5.0. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-gxr4-xjj5-5px2"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Potential XSS vulnerability in jQuery</strong></p>
<h3>Impact</h3>
<p>Passing HTML from untrusted sources - even after sanitizing it - to one of jQuery's DOM manipulation methods (i.e. <code>.html()</code>, <code>.append()</code>, and others) may execute untrusted code.</p>
<h3>Patches</h3>
<p>This problem is patched in jQuery 3.5.0.</p>
<h3>Workarounds</h3>
<p>To workaround the issue without upgrading, adding the following to your code:</p>
<pre lang=""js""><code>jQuery.htmlPrefilter = function( html ) {
	return html;
};
</code></pre>
<p>You need to use at least jQuery 1.12/2.2 or newer to be able to apply this workaround.</p>
<h3>References</h3>
<p><a href=""https://blog.jquery.com/2020/04/10/jquery-3-5-0-released/"">https://blog.jquery.com/2020/04/10/jquery-3-5-0-released/</a>
<a href=""https://jquery.com/upgrade-guide/3.5/"">https://jquery.com/upgrade-guide/3.5/</a></p>
</tr></table> ... (truncated)
<p>Affected versions: &gt;= 1.2 &lt; 3.5.0</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-jpcq-cgw6-v4j6"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Potential XSS vulnerability in jQuery</strong>
In jQuery versions greater than or equal to 1.0.3 and before 3.5.0, passing HTML containing <option> elements from untrusted sources - even after sanitizing it - to one of jQuery's DOM manipulation methods (i.e. .html(), .append(), and others) may execute untrusted code.</p>
<p>This problem is patched in jQuery 3.5.0.</p>
<p>Affected versions: &gt;= 1.0.3 &lt; 3.5.0</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/jquery/jquery/commit/7a0a850f3d41c0412609c1d32b1e602d4afe2f4e""><code>7a0a850</code></a> 3.5.0</li>
<li><a href=""https://github.com/jquery/jquery/commit/8570a08f6689223aa06ca8cc51d488c6d81d44f9""><code>8570a08</code></a> Release: Update AUTHORS.txt</li>
<li><a href=""https://github.com/jquery/jquery/commit/da3dd85b63c4e3a6a768132c2a83a1a6eec24840""><code>da3dd85</code></a> Ajax: Do not execute scripts for unsuccessful HTTP responses</li>
<li><a href=""https://github.com/jquery/jquery/commit/065143c2e93512eb0c82d1b344b71d06eb7cf01c""><code>065143c</code></a> Ajax: Overwrite s.contentType with content-type header value, if any</li>
<li><a href=""https://github.com/jquery/jquery/commit/1a4f10ddc37c34c6dc3a451ee451b5c6cf367399""><code>1a4f10d</code></a> Tests: Blacklist one focusin test in IE</li>
<li><a href=""https://github.com/jquery/jquery/commit/9e15d6b469556eccfa607c5ecf53b20c84529125""><code>9e15d6b</code></a> Event: Use only one focusin/out handler per matching window &amp; document</li>
<li><a href=""https://github.com/jquery/jquery/commit/966a70909019aa09632c87c0002c522fa4a1e30e""><code>966a709</code></a> Manipulation: Skip the select wrapper for &lt;option&gt; outside of IE 9</li>
<li><a href=""https://github.com/jquery/jquery/commit/1d61fd9407e6fbe82fe55cb0b938307aa0791f77""><code>1d61fd9</code></a> Manipulation: Make jQuery.htmlPrefilter an identity function</li>
<li><a href=""https://github.com/jquery/jquery/commit/04bf577e2f961c9dde85ddadc77f71bc7bc671cc""><code>04bf577</code></a> Selector: Update Sizzle from 2.3.4 to 2.3.5</li>
<li><a href=""https://github.com/jquery/jquery/commit/7506c9ca62a2f3ef773e19385918c31e9d62d412""><code>7506c9c</code></a> Build: Resolve Travis config warnings</li>
<li>Additional commits viewable in <a href=""https://github.com/jquery/jquery/compare/3.4.1...3.5.0"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~mgol"">mgol</a>, a new releaser for jquery since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=jquery&package-manager=npm_and_yarn&previous-version=3.4.1&new-version=3.5.0)](https://dependabot.com/compatibility-score/?dependency-name=jquery&package-manager=npm_and_yarn&previous-version=3.4.1&new-version=3.5.0)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
If all status checks pass Dependabot will automatically merge this pull request.

[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in the `.dependabot/config.yml` file in this repo:
- Update frequency
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>"
47,yuki-kimoto/gitprep,112,37,831,,831,"On Windows clients I have seen encoding errors when trying to interact with GitPrep (installed as CGI, behind Apache 2.4).
The workaround was to force the git client to use http/1.1 instead of http/2:

`git config --global http.version HTTP/1.1 `[[[[[Next]]]]]How do I do that? I have 5 perl processes running when running the web server on Windows 7 and would like to reduce that to 2 or 3 perl processes."
48,hadley/ggplot2-book,419,16,826,,826,"Seems to be GitHub Actions related, we also have the same in https://github.com/Robinlovelace/geocompr/issues/500 and https://github.com/ThinkR-open/engineering-shiny-book/issues/151[[[[[Next]]]]]When rendered with Github action / MacOs, the tibble are not correctly printed.

![Screenshot 2020-04-27 at 22 03 42](https://user-images.githubusercontent.com/17936236/80416070-cf8fb480-88d3-11ea-8e43-2627fb1b4bf7.png)

I'm working on this bug here: https://github.com/ThinkR-open/building-shiny-apps-workflow/issues/147, just wanted to share "
49,Moham3dRiahi/Th3inspector,304,3,822,,822,"Plz help
![Screenshot_20200409_152838](https://user-images.githubusercontent.com/63394300/78883226-d5356f80-7a76-11ea-8fef-1d7f133319f6.jpg)
[[[[[Next]]]]]Your tool/software has been inventoried on [*Rawsec's CyberSecurity Inventory*](https://inventory.rawsec.ml/).

### What is Rawsec's CyberSecurity Inventory?

An inventory of tools and resources about CyberSecurity. This inventory aims to help people to find everything related to CyberSecurity.

+ **Open source**: Every information is available and up to date. If an information is missing or deprecated, you are invited to (help us).
+ **Practical**: Content is categorized and table formatted, allowing to search, browse, sort and filter.
+ **Fast**: Using static and client side technologies resulting in fast browsing.
+ Rich tables: search, sort, browse, filter, clear
+ Fancy informational popups
+ Badges / Shields
+ Static API
+ Twitter bot

More details about features [here](https://inventory.rawsec.ml/features.html).

Note: the inventory is a FLOSS (Free, Libre and Open-Source Software) project.

### Why?

+ **Specialized websites**: Some websites are referencing tools but additional information is not available or browsable. Make additional searches take time.
+ **Curated lists**: Curated lists are not very exhaustive, up to date or browsable and are very topic related.
+ **Search engines**: Search engines sometimes does find nothing, some tools or resources are too unknown or non-referenced. These is where crowdsourcing is better than robots.

### Why should you care about being inventoried?

Mainly because this is giving visibility to your tool, more and more people are using the *Rawsec's CyberSecurity Inventory*, this helps them find what they need.

### Why the badge?

The badge shows to your community that your are inventoried. This also shows you care about your project and want it growing, that your tool is not an abandonware.

Also we took time to inventory your tool and you are gaining visibility from that: **we added your tool to our inventory to make it known now it is your turn to add the badge to your project README to help our project being known**.

### Ok but...

You should think I asked nothing to you, I don't need visibility or/and I don't like your badge: your are free not to use it.
"
50,beyondgrep/ack1,95,0,820,,820,
51,git-deploy/git-deploy,65,20,809,,809,"Hi!

Could you put a fresh version on CPAN? Because current version is old and has bugs.

Thank you![[[[[Next]]]]]This merely runs `iconv -f iso-8859-1 -t utf-8` on dist.ini to make dzil
commands work on UTF-8 locales."
52,GouveaHeitor/nipe,186,15,799,,799,"Buenas, acabo de crear un sistema operativo debian 10 en una maquina virtual para hacer pruebas con el y poder torificarlo con el script perl nipe, pero al ejecutar el comando sudo cpan install Switch JSON Config :: Simple no me acaba diciendo siempre que No such file or directory. Por si puede ser un problema al ejecutar el comando estoy en /Escritorio/nipe Alguien sabe como arreglar esto porfavor?
Muchas Gracias[[[[[Next]]]]]error: only one operation may be used at a time
"
53,jonreid/XcodeCoverage,314,1,788,,788,"Hi, 
I'm able to export a nice report for test running on simulator. 
But when trying with the actual device, I always get the following errors: 
""Reading tracefile Coverage.info
lcov: ERROR: no valid records found in tracefile Coverage.info""

Any suggestion? Thank you

"
54,cullum/dank-selfhosted,40,5,778,,778,Is it possible to remove the restriction for needing a secondary DNS provider and instead just work with one provider?[[[[[Next]]]]]Is it possible to make some of the roles optional so that people can pick and choose what they want?
55,inverse-inc/packetfence,204,429,762,,762,"Description
===========
Not Ready
Provide an advanced LDAP condition to allow custom LDAP queries

NEWS file entries
=======================
* Provide an advanced LDAP condition to allow custom LDAP queries

Issue
=====
fixes #5397

Delete branch after merge
=========================
NO

Checklist
=========
- [ ] Document the feature
- [x] Add unit tests
- [ ] Add acceptance tests (TestLink)[[[[[Next]]]]]I am facing a problem where i need to do some ldap search based on partial information in some radius attributes.

Let's say we have the radius attribute User-Name = zaym@reboot.acme.com and we need to do a ldap search like (&(cn=rebootVLAN)(memberOf=dn=cn=zaym,dc=reboot,dc=acme,dc=com)) and if there is a result then we set a role and if not found we reject.

The advanced ldap filter and set role on not found are part of another issue numbers: #5397 and #5398.

What i need is to be able to do the following:

> User-Name ~= (\w+)\@([^.]+)\.acme.com/
> 
> PacketFence-Internal-Attribute-1 = $1
> PacketFence-Internal-Attribute-2 = $2.VLAN
> PacketFence-Internal-Attribute-3 = $2
> 

Then is the ldap authentication source:

(&(cn=${PacketFence-Internal-Attribute-2})(memberOf=dn=cn=${PacketFence-Internal-Attribute-1},dc=${PacketFence-Internal-Attribute-3} = $1,dc=acme,dc=com))
"
56,Perl/perl5,230,1897,761,,761,"Overview of test reports: http://fast-matrix.cpantesters.org/?dist=Regexp-CharClasses-Helper%200.005
A sample fail report: http://www.cpantesters.org/cpan/report/8dd2da96-8b66-11ea-8059-64d73489f42c[[[[[Next]]]]]This issue can be seen on perl 5.31.11 and I've also reproduced it with 5.26.3 so it's not a new blocker issue.

The original offending line and error are:

    my @test_files = sort path(File::ShareDir::dist_dir('Foo-Bar'), 'tests')->children;
    > Can't locate object method ""children"" via package ""tests"" (perhaps you forgot to load ""tests""?)

(where `path` comes from Path::Tiny), but I boiled this down to not need extra modules thusly:

```
use strict;
use warnings;

package Foo {
  sub children { 'a', 'b', 'c' }
}

sub path { bless {}, 'Foo' }
sub dir { $_[0].'/hello' }

my @files = sort path(dir('foo'), 'bar')->children;
```

and produces the error:

    Can't locate object method ""children"" via package ""bar"" (perhaps you forgot to load ""bar""?) at repro.pl line 11.

Grinnz helpfully suggested adding `+` to the expression passed to `sort`, which makes the error go away. Nevertheless, this is an interesting parsing bug that might warrant a look.
"
57,Lochnair/vyatta-wireguard,44,45,760,,760,"To my understanding wg-quick is part of the userpace tools, right?
If so, they're not included in the package?[[[[[Next]]]]]My VPN provider has wireguard protocol support. Is there a way I can load their credentials and apply my device as a client? Please help."
58,mikaku/Monitorix,148,33,747,,747,"Hello,

autocheck_responsiveness always check http://localhost:port, even if ""host"" value is set to listen on a specific ipv4 address.
```
<httpd_builtin>
        enabled = y
        host = 10.255.0.51
        port = 8080
        user = nobody
        group = nobody
        log_file = /var/log/monitorix-httpd
        hosts_deny =
        hosts_allow = 10.255.0.0/24
        autocheck_responsiveness = n
        <auth>
                enabled = n
                msg = Monitorix: Restricted access
                htpasswd = /var/lib/monitorix/htpasswd
        </auth>
</httpd_builtin>
```

logs

```
Sat May  2 15:18:00 2020 - WARNING: HTTP built-in server not responding at 'http://localhost:8080/monitorix'.
Sat May  2 15:19:01 2020 - WARNING: HTTP built-in server not responding at 'http://localhost:8080/monitorix'.
Sat May  2 15:20:00 2020 - WARNING: HTTP built-in server not responding at 'http://localhost:8080/monitorix'.
```


[[[[[Next]]]]]I'm using Monitorix 3.10.1 from Debian repositories.

Currently HTTP password authentication is set ( /etc/monitorix/monitorix.conf ) with:
httpd_builtin -> auth -> enabled = y

But I need to not save clear passwords here:
emailreports -> url_prefix

To reach both securities (web authentication + not clear passwords on files), I need that authentication is not required for requests from localhost.
My proposal is to allow more values to ""enabled"" property and add ""disabled"" property:
enabled=y
enabled=n
enabled=CIDR address
disabled=y
disabled=n
disabled=CIDR address

With this, I could configure this setup:
enabled=y
disabled=192.168.0.0/16"
59,jondonas/linux-exploit-suggester-2,131,0,738,,738,
60,nferraz/st,49,11,736,,736,"It would be useful to support mode, not just mean and median.[[[[[Next]]]]]This change makes `st` a bit quicker for large inputs. The main boost comes from de-duplicating the `validate` check for every number. The validation check is also replaced with Scalar::Util's `looks_like_number`, which passes the existing test suite, is part of core, and is implemented in C.

This change, as it is now, would require a version bump on the library since previously, `process` would die on invalid input. This change assumes the caller has validated the input. It should be straightforward to avoid that if necessary.

I've included some simple runs on a 40mb file showing the before and after below. The run time for this file was reduced to 14s, originally taking 21s. Both times were taken after multiple runs of tests to account for page caches being warm etc. 

Current `st`:

```
-bash-4.2$ time st --complete /tmp/input.txt
N	min	q1	median	q3	max	sum	mean	stddev	stderrvariance
4.45998e+06	0.002401	0.00371	0.004048	0.004653	0.069798	28189.6	0.00632058	0.00852295	4.03574e-06	7.26406e-05

real	0m21.341s
user	0m20.551s
sys	0m0.790s
```

Proposed:

```
-bash-4.2$ time st --complete /tmp/input.txt
N	min	q1	median	q3	max	sum	mean	stddev	stderrvariance
4.45998e+06	0.002401	0.00371	0.004048	0.004653	0.069798	28189.6	0.00632058	0.00852295	4.03574e-06	7.26406e-05

real	0m14.079s
user	0m13.255s
sys	0m0.823s
```"
61,Moham3dRiahi/XAttacker,351,3,729,,729,"The install script is rather techy, but have included almost everything required to get this running after a fresh install of termux[[[[[Next]]]]]Your tool/software have been inventoried on [*Rawsec's CyberSecurity Inventory*](https://inventory.rawsec.ml/).

### What is Rawsec's CyberSecurity Inventory?

An inventory of tools and resources about CyberSecurity. This inventory aims to help people to find everything related to CyberSecurity.

+ **Open source**: Every information is available and up to date. If an information is missing or deprecated, you are invited to (help us).
+ **Practical**: Content is categorized and table formatted, allowing to search, browse, sort and filter.
+ **Fast**: Using static and client side technologies resulting in fast browsing.
+ Rich tables: search, sort, browse, filter, clear
+ Fancy informational popups
+ Badges / Shields
+ Static API
+ Twitter bot

More details about features [here](https://inventory.rawsec.ml/features.html).

Note: the inventory is a FLOSS (Free, Libre and Open-Source Software) project.

### Why?

+ **Specialized websites**: Some websites are referencing tools but additional information is not available or browsable. Make additional searches take time.
+ **Curated lists**: Curated lists are not very exhaustive, up to date or browsable and are very topic related.
+ **Search engines**: Search engines sometimes does find nothing, some tools or resources are too unknown or non-referenced. These is where crowdsourcing is better than robots.

### Why should you care about being inventoried?

Mainly because this is giving visibility to your tool, more and more people are using the *Rawsec's CyberSecurity Inventory*, this helps them find what they need.

### Why the badge?

The badge shows to your community that your are inventoried. This also shows you care about your project and want it growing, that your tool is not an abandonware.

Also we took time to inventory your tool and you are gaining visibility from that: **we added your tool to our inventory to make it known now it is your turn to add the badge to your project README to help our project being known**.

### Ok but...

You should think I asked nothing to you, I don't need visibility or/and I don't like your badge: your are free not to use it.
"
62,pasky/speedread,74,7,709,,709,"[[[[[Next]]]]]```sh
echo ""Möööööööööö"" > t
speedread t
```

will yield:

```sh
MÃ¶Ã¶Ã¶Ã¶Ã¶Ã¶Ã¶Ã¶Ã¶Ã¶
```

<img width=""570"" alt=""screen shot 2018-05-01 at 16 56 24"" src=""https://user-images.githubusercontent.com/5759366/39477774-983a221e-4d60-11e8-8fee-fec8ff4bd337.png"">

```sh
echo ""Möööööööööö"" | speedread
```

does work though.

<img width=""570"" alt=""screen shot 2018-05-01 at 16 57 02"" src=""https://user-images.githubusercontent.com/5759366/39477805-af5a44a6-4d60-11e8-87e5-b2cf7179f33f.png"">
"
63,PerlDancer/Dancer,227,77,708,,708,"For #1212 [[[[[Next]]]]]If you use code like
````
response_content_like( [GET => '/web/page.html'], qr/You are logged in/, 'logged in' );
````
and the page does not match the regex, the whole of the retrieved web content is output to console.

It should show a more summarized view of the failure, perhaps like Test::LongString does
"
64,addy-dclxvi/i3-starterpack,103,9,707,,707,"Sorry to write as an issue, 
i'm using XFCE with debian and cant figure out how to got rid of those ugly menu bars.
thank you in advance.. [[[[[Next]]]]]I couldn't make your fonts to work even after checking out #12 so I decided to go for [Font Awesome](https://fontawesome.com/) which is a widely used font. This is a bit of a work in progress but just wanted you and the other users to check it out.

Here are the results on my machine:

![image](https://user-images.githubusercontent.com/8255422/67144908-302e9c80-f274-11e9-8436-b4115a25b9f3.png)

PS. Thanks for sharing your config, it helped me get started with i3!"
65,backuppc/backuppc,104,62,703,,703,"Hello,

I am just building new packages for Ubuntu 18, as both rsync-bpdc and BackupPC are outdated. Once done I would be willing to help to either update the build description and / or post my packages somewhere.

Thanks for your software,
Torsten.[[[[[Next]]]]]BackupPC V4.3.2

**Starting point**
hdd with 2.7TB backuppc data folder, created with BackupPC V3 (Debian 7)
installed BackupPC V4.3.2 on new machine running Debian 10 LXDE
mounted backuppc data folder
ran ""BackupPC_migrateV3toV4""
ran ""BackupPC_nightly 0 255""

**Result**
backuppc cpool not empty
Checking on hard linked files I found they all resided in folder pc/apollo/new, total size 483GB, with 650 entries in file pc/apollo/NewFileList (apollo is my client's name)
removed contents of folder pc/apollo/new and re-ran ""BackupPC_nightly 0 255"", which emptied the V3 pool

I assume ""new"" was created during a backup, but apparently the backup task did not complete, and folder new was not renamed into a valid backup folder

"
66,bollwarm/SecToolSet,182,0,694,,694,
67,muennich/urxvt-perls,98,3,690,,690,"Hi,

Any chance of a 2.3 tag?

It's an awesome extension, thanks for making it![[[[[Next]]]]]Every now and then keyboard-select won't update primary selection (while selecting with mouse still does the job). Have to open another urxvt to keep going.

Version: 2.2
OS: FreeBSD 11.1, affected since at least version 9."
68,skx/sysadmin-util,92,0,684,,684,
69,bagder/everything-curl,148,0,684,,684,
70,OTRS/otrs,416,8,678,,678,"[[[[[Next]]]]]`<p class=""MsoNormal""><span lang=""EN""><o:p>&nbsp;</o:p></span></div>`

We have article with 1500+ such lines and DocumentCleanup() 100% loads
entry core for hours

There can be multiple such articles in one ticket, so one opened
AgentTicketZoom page can hang multiple cores"
71,miyagawa/cpanminus,194,113,678,,678,"This is still in early development phase and pretty dumb, but I would like to let you know of the release of `install-with-cpanm` GitHub action

https://github.com/marketplace/actions/install-with-cpanm

This action allows to install cpanm on a container (linux, windows, ...) and optionally install several modules from a list or a cpanfile.

This case was created to inform you and maybe consider adding some note to the documentation referencing it, so people can start taking advantages of it.

Here are several examples using it:
https://github.com/perl-actions/install-with-cpanm/actions/runs/81136053

Some basic syntax:
```yaml
- name: install cpanm and multiple modules
  uses: perl-actions/install-with-cpanm@v1.1
  with:
    install: |
      Simple::Accessor
      Test::Parallel

# or you can use a cpanfile
#     cpanfile: 'your-cpanfile'
# default values you can customize
#     sudo: true
# where to install cpanm
#     path: ""$Config{installsitescript}/cpanm""
# which perl binary to use
#     perl: 'perl'
```

## Using install-with-cpanm in a GitHub workflow

Here is a sample integration using install-with-cpanm action
to test your Perl Modules using multiple Perl versions via the
perl-tester images.

```yaml
# .github/workflows/linux.yml
jobs:
  perl_tester:
    runs-on: ubuntu-latest
    name: ""perl v${{ matrix.perl-version }}""

    strategy:
      fail-fast: false
      matrix:
        perl-version:
          - ""5.30""
          - ""5.28""
          - ""5.26""
        # ...
        # - '5.8'

    container:
      image: perldocker/perl-tester:${{ matrix.perl-version }}

    steps:
      - uses: actions/checkout@v2
      - name: uses install-with-cpm
        uses: perl-actions/install-with-cpanm@v1.1
        with:
          cpanfile: ""cpanfile""
          sudo: false
      - run: perl Makefile.PL
      - run: make test
```

you can read more from https://github.com/perl-actions/install-with-cpanm[[[[[Next]]]]]Currently if a `Menlo::Dependency` has a `mirror`, but no `dist` the mirror is ignored. It should be possible to query the specific mirror for the module as happens for the default CPAN.

This PR enables that and works with miyagawa/cpanfile#54"
72,huichen/mlf,244,2,671,,671,"最后没成型吗？[[[[[Next]]]]]我用Spark写过两个机器学习算法，[Naive Bayes classifier](https://github.com/apache/incubator-spark/pull/292), [Random forest](https://github.com/apache/incubator-spark/pull/370), [Apache Spark 的 RDD](http://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf) 是一个比Map-reduce和MPI更好用的分布式框架，表达力也很强。

看样子你目前是想直接使用golang 的 channel 实现分布式机器学习算法？这样的话，跟直接用MPI差不多，太底层，写的代码会很罗嗦。

方便程度：Spark  > Hadoop > MPI，  代码简洁度：Spark > Hadoop > MPI，限制程度：MapReduce > Spark > MPI，MPI是最自由的，写起来也是最麻烦的，所以任何分布式计算框架，都似乎是在抽象和性能之间进行折中。

只有用更高层的抽象工具，写机器学习算法才会更简洁。

对了，[Apache Tez](http://hortonworks.com/hadoop/tez/)，也是一个DAG计算框架（跟Spark很类似，本质上都是DAG），你也可以看看。还有MSRA的 [Dryad](http://research.microsoft.com/en-us/projects/dryad/)，等等。我个人觉得Spark的RDD平衡的更好，也有非常成熟的实现，就是Spark本身。

关于用 golang 实现 Spark的RDD，有一个项目在此 [Gopark](https://github.com/mijia/gopark)，不过不太活跃，但是可以联系作者，一起做形成合力，照目前这种活跃度，项目完工遥遥无期。。。。
"
73,mrnugget/opencv-haar-classifier-training,466,8,668,,668,"Updating instructions for usage in windows.[[[[[Next]]]]]when I run: perl bin/createsamples.pl positives.txt negatives.txt samples 1500   ""opencv_createsamples -bgcolor 0 -bgthresh 0 -maxxangle 1.1\
   -maxyangle 1.1 maxzangle 0.5 -maxidev 40 -w 20 -h 20"""
74,duncs/clusterssh,60,26,660,,660,"I have two monitors, 1920 wide each.  The OS is Fedora 28 (same results on Centos 8) both with Mate destop which is a fork of Gnome 2.  This is a physical, not virtual setup. 

I usually open four windows (web{1..4} and when I do, I get one tucked under the others. 
![image](https://user-images.githubusercontent.com/151407/76170264-b3368d80-6156-11ea-8fe8-6e1534c76f4a.png)

I'd rather that cssh realize it can't fit the fourth window, and either put it on the next monitor, or below the first windows.  I can't find anything in .clustessh/config that looks like it will help. 

Any suggestions? 

Thanks, 
Ed Greenberg
[[[[[Next]]]]]Each time menu click , I see following in console window. It does not causes any issues but annoying 

SetupSysMenu: GetSystemMenu() failed for HWND 0xf0644
SetupSysMenu: GetSystemMenu() failed for HWND 0x100644
"
75,trizen/trizen,33,35,657,,657,"Hi,
I'm using snapper hook to create pre/post snapshots for package installation.
However when using trizen snapper creates a snapshots for every single package.

Would it be possible to create a single pre/post snapshot for installation of multiple packages with trizen? This would be similar function compared to pacman that installs all packages of a multi-selection.

THX[[[[[Next]]]]]I have a set of local aur replacements via git insteadOf. However trizen always compares to the aur version when doing update checks,  which keeps rebuilding my forks again and again on each full system upgrade. Is there a way to customize the update checking logic?"
76,gugod/App-perlbrew,212,173,651,,651,"Hello,

I am trying to install perl via perlbrew. I am on a shared cluster so I do not have admin privileges,
but I am part of a group and I want to install perl for everyone in the group.

I used the PERLBREW_ROOT environment variable to install perlbrew in a shared group location with:

```bash
export PERLBREW_ROOT=/home/groups/hbfraser/modules/packages/perlbrew/0.8/
curl -L https://install.perlbrew.pl | bash
```
I then placed the bin directory on my PATH and did `perlbrew init`

Then I tried to install a perl version and I simply can't. It doesn't matter which version or whether I use the --force option. I also cannot do a manual make install because perlbrew is failing *before* setting up the configure.

Whatever option I try I always get the same logfile. Some error with patch not recognizing  some argument for patch when getting attribute `system.nfs4_acl of system.nfs4_acl`. An example logfile is below

```
Auto-guessed '5.26.3'
patching Configure
/usr/bin/patch: getting attribute system.nfs4_acl of system.nfs4_acl: Invalid argume
nt
Died at /home/groups/hbfraser/modules/packages/perlbrew/0.8//bin/patchperl line 1778
.
##### Brew Failed #####
```

Is there any way around this?
Or am I doing something wrong?
Sur[[[[[Next]]]]]Also cannot be switched to with `perlbrew use` or `perlbrew switch`.

This is because the standard `make install` for cperl doesn't create a binary called `perl` but a binary called `cperl` instead.

If you do this, everything works okay:

```
perlbrew install --notest cperl-5.30.0
ln -s $PERLBREW_ROOT/perls/cperl-5.30.0/bin/{cperl,perl}
```

But it would be nice if the linking didn't need to be done manually."
77,AlisamTechnology/ATSCAN,264,0,644,,644,
78,SpiderLabs/ModSecurity-nginx,149,15,643,,643,"This is a PR that uses SpiderLabs/ModSecurity#2304 to support audit log rotation when nginx reloads config or reopens log files.

I tested this by:
1. Using `lsof` to observe nginx has the audit log open
1. Moving the audit log file
1. Using `lsof` to confirm the nginx now references the moved file
1. Signaling the nginx master process with SIGHUP or SIGUSR1.
1. Testing the same things with `nginx -s reload` and `nginx -s reopen`

When I wasn't convinced of the thread-safety of audit log writes and log reopen within nginx, I also attempted to test it with the following script using GNU parallel:
`parallel -j+0 ./test-reopen.sh ::: {1..10000}`

```bash
#!/bin/bash

set -euo pipefail

read s < /dev/urandom
TEST=$(( ${#s} % 11 ))

if [[ TEST -eq 0 ]]; then
	echo ""$1 reopen with SIGUSR1""
	kill -USR1 ""$(pgrep -P1 nginx)""
elif [[ TEST -eq 1 ]]; then
	echo ""$1 reload with SIGHUP""
	kill -HUP ""$(pgrep -P1 nginx)""
else
	echo ""$1 triggering modsec logging""
	# Matches a silly rule created for testing
	curl --silent http://localhost/index.html?asdf 2>&1 >/dev/null &
fi

pgrep -d"", "" nginx
```

This test didn't hurt, but due to nginx's primarily single-threaded architecture, I believe log reopen is thread-safe here by default.

resolves #121 [[[[[Next]]]]]Hello,
Sorry for my bad English because i'm french.
So, I am experiencing a malfunction in my NGINX server.
When I try to update my certificates with CERTBOT I get the following error:

```
root@XXX:/# certbot 
Saving debug log to /var/log/letsencrypt/letsencrypt.log
Error while running nginx -c /etc/nginx/nginx.conf -t.

nginx: [emerg] module ""/etc/nginx/modules/ngx_http_modsecurity_module.so"" version 1017010 instead of 1018000 in /etc/nginx/nginx.conf:1
nginx: configuration file /etc/nginx/nginx.conf test failed


Certbot doesn't know how to automatically configure the web server on this system. However, it can still get a certificate for you. Please run ""certbot certonly"" to do so. You'll need to manually configure your web server to use the resulting certificate.
```

Thx

`root@XXX:/# nginx -v
nginx version: nginx/1.18.0
`"
79,trizen/youtube-viewer,55,25,642,,642,@trizen thanks for building a wonderful tool! I've been [maintaining a Homebrew tap](https://github.com/TheKevJames/homebrew-youtube-viewer) for building ``youtube-viewer`` -- figured I'd include the link here in case it helps anyone out.[[[[[Next]]]]]Is there a way to make the comments pane independent so it can be left open in a certain spot on the screen.  This would allow you to navigate to different videos and while leaving the comments pain in a its own window and not have to close it each time. A shortcut key would be nice as well for comments. 
80,andrewning/sortphotos,223,38,635,,635,[[[[[Next]]]]]Exif-Tool updated to 11.92 version. Including .pm files required for master branch to work. Btw Phil changed his email!
81,RexOps/Rex,205,185,620,,620,"For #1311[[[[[Next]]]]]For #1310 

The test can probably be improved. It just tests the proper error message thrown because no real connection is set. "
82,chromatic/modern_perl_book,184,18,620,,620,"to the Community Sites section ( sections/perl_community.pod )[[[[[Next]]]]]You write ""though in this case, the Regexp::English module has a much better phone number regex already written for you.""

But looking at the docs for Regexp::English, I see no such thing. I thought maybe you meant Regexp::Common, but that doesn't have one either."
83,hamishcoleman/thinkpad-ec,72,33,615,,615,"Tried to build the patch on two separate platforms recently, but got this same error. I had the latest available clone of the repo at the time. Live Internet connection on both machines during the build:
`make patched.x230.img`
`Downloading x230 BIOS 2.75 (G2ETB5WW)   EC 1.14 (G2HT35WW)`
This part succeeds, I have the ISO files now.
`git submodule update --init --remote`
`fatal: not a git repository (or any of the parent directories): .git`
`make: *** [Makefile:296: mec-tools/Makefile] Error 128`
On the other platform the error was `129` instead of `128`, but the rest was the same.[[[[[Next]]]]]As per https://www.reddit.com/r/thinkpad/comments/9ivh0u/thinkpad_keyboards_measurement_of_polling_lag_and/ -- is it possible to patch the keyboard firmware to eliminate the polling issue that has been plaguing Thinkpads for the better part of a decade? Or am I totally misreading what this program can do?"
84,Nordaaker/convos,52,20,609,,609,"I installed Convos 5 months ago and I've collected so many messages and channels since that period. From time to time, my server suffered some ""downs"" and I thought it was a temporary problem caused by some local conflicts with other programs that bind the same network interface. However as the number of the messages logged was increasing, my suffered more downs than ever. At the moment, each time I want to access to IRC via Convos, I have to restart Convos via terminal. It's a little bit annoying.

When I write ""down"", I mean the situation of not-accessing the convos interface. Instead the ""Convos is offline"" warning is showed.
I might assume all of this since in particular the API call `/api/user.json?connections=true&dialogs=true` fails returning a time-out code. I'm suspecting that the search component request too many files (~~90 days of ""full activity"" in channels are like looking for a string in 500k lines~~ maybe does it look for future logs?) to servers.

### Technical information
* OS: Debian 10 64bit;
* Convos version: 4.03;
* Browser: Chromium-based;[[[[[Next]]]]]Would be awesome to be able so search for gifs to paste directly in the convos ui.
I quite like the Telegram ui where you use the gif bot like `@gif whatever` and get a bunch of gifs to choose from:
![image](https://user-images.githubusercontent.com/5526/76083340-adea0f00-5fad-11ea-840d-81a28bf24a26.png)
"
85,dotphiles/dotphiles,328,4,584,,584,"I'm planning to add some new stuff into dotphiles (like bashrc and some things round about Ubuntu).
What are the steps for adding new stuff? How can i define, what are the target place, and the target name? Can i use dotphiles binary to do that?
Are you interested for a Pull Request?[[[[[Next]]]]]Reproduce:
1. start tmux
2. ssh into embedded device with busybox.
3. start top
4. see error message: `'screen-256color': unknown terminal type.

Change that might have caused: 
./tmux/tmux.conf
```diff
-set -g default-terminal $TERM
+set -g default-terminal screen-256color
```

I believe tmux should inherit TERM from its environment.

This can be fixed temporarily by adding the following alias for ssh:
```
# Prevents local TERM from affecting ssh.
alias ssh='TERM=xterm ssh'
```

"
86,oetiker/SmokePing,120,70,569,,569,"Hello,

I use to run a couple of smokeping instances with slaves.
Today I've tried to run a smokeping slave v2.7.3 current git that connect to the same version as master, using https (with apache).
When I try to run the slave, I get:
```
WARNING Master said 501 Protocol scheme 'https' is not supported (LWP::Protocol::https not installed)
```

Having installed missing `perl-LWP-Protocol-https` package and restarted the master (also installed later on the slave), I get the same message.

Is slave contacting master via https supported by Smokeping ?
If yes, anything I did wrong ?
Of course, I can reach the master via https.

Best regards.[[[[[Next]]]]]Hello,

I just fetched current git master from this repo (commit commit b681331b1b3780c6ddc778376e7b536ced99d317).
After installation, the GUI reports as Smokeping 2.6.0.

Having installed smokeping 2.7.3 (downloaded as tar.gz from the release page), it reports as 2.7.3.

I traced down the issue to `lib/Smokeping.pm` where `$VERSION=""2.006000"";` is stated.

I'm just puzzled that even in the release tag of v2.7.3, that file states the same.

Best regards."
87,mrash/fwknop,114,82,568,,568,"Hi,
I would like to sniff for ex. eth0 and wg0 (wireguard) at the same time but I didn't found nothing about that maybe because it's not possible ?!
I've tried adding a second interface in fwknopd.conf -> PCAP_INTF no it didn't worked.
Maybe the solution is in this post https://github.com/mrash/fwknop/issues/310
but I didn't understand everything so if someone can enlight me ?
Thank you in advance[[[[[Next]]]]]Hi,

Above the siplify address a patchset that allow to use gnulib.

I plan to push more change simplifying fwknop by using well know and tested function from gnulib

It will allow to simplify the code

bastien"
88,innotop/innotop,101,23,567,,567,"Super is very wide privilege for Innotop 

when run without super privilege:
localhost: Access denied; you need (at least one of) the SUPER, REPLICATION CLIENT privilege(s) for this operation[[[[[Next]]]]]quick fix"
89,smxi/inxi,53,14,555,,555,"Hi.

I want suggest new feature - detailed information about RAM modules.
Information like this
```
---=== Memory Characteristics ===---
Maximum module speed                             1333 MHz (PC3-10600)
Size                                             8192 MB
Banks x Rows x Columns x Bits                    8 x 16 x 10 x 64
Ranks                                            2
SDRAM Device Width                               8 bits
Bus Width Extension                              0 bits
tCL-tRCD-tRP-tRAS                                9-9-9-24
Supported CAS Latencies (tCL)                    9T, 8T, 7T, 6T

---=== Timings at Standard Speeds ===---
tCL-tRCD-tRP-tRAS as DDR3-1333                   9-9-9-24
tCL-tRCD-tRP-tRAS as DDR3-1066                   7-7-7-20
tCL-tRCD-tRP-tRAS as DDR3-800                    6-6-6-15

---=== Timing Parameters ===---
Minimum Cycle Time (tCK)                         1.500 ns
Minimum CAS Latency Time (tAA)                   13.125 ns
Minimum Write Recovery time (tWR)                15.000 ns
Minimum RAS# to CAS# Delay (tRCD)                13.125 ns
Minimum Row Active to Row Active Delay (tRRD)    6.000 ns
Minimum Row Precharge Delay (tRP)                13.125 ns
Minimum Active to Precharge Delay (tRAS)         36.000 ns
Minimum Active to Auto-Refresh Delay (tRC)       49.125 ns
Minimum Recovery Delay (tRFC)                    260.000 ns
Minimum Write to Read CMD Delay (tWTR)           7.500 ns
Minimum Read to Pre-charge CMD Delay (tRTP)      7.500 ns
Minimum Four Activate Window Delay (tFAW)        30.000 ns

---=== Optional Features ===---
Operable voltages                                1.5V
RZQ/6 supported?                                 Yes
RZQ/7 supported?                                 Yes
DLL-Off Mode supported?                          Yes
Operating temperature range                      0-95 degrees C
Refresh Rate in extended temp range              2X
Auto Self-Refresh?                               No
On-Die Thermal Sensor readout?                   No
Partial Array Self-Refresh?                      Yes
Module Thermal Sensor                            No
SDRAM Device Type                                Standard Monolithic

---=== Physical Characteristics ===---
Module Height                                    30 mm
Module Thickness                                 2 mm front, 2 mm back
Module Width                                     133.35 mm
Module Reference Card                            B revision 1
Rank 1 Mapping                                   Mirrored

---=== Manufacturer Data ===---
Module Manufacturer                              Kingston
Manufacturing Location Code                      0x07
Manufacturing Date                               2017-W38
Assembly Serial Number                           0x332DBC11
Part Number                                      99U5403-466.A00LF
```
Can be received via `decode-dimms` command from `i2c-tools-perl` package. Also need to load modules:
```
modprobe eeprom
modprobe i2c-i801
```

Add this functional please.[[[[[Next]]]]]The Russian Elbrus cpu x86/64 cpu series recently came to my attention through some pull requests.

https://en.wikipedia.org/wiki/List_of_Russian_microprocessors

https://weekly-geekly.github.io/articles/391259/index.html

> An important clarification. It is wrong to mention the designation “Elbrus-2000”, as well as the abbreviation “E2K” in the context of modern products: the official name of this microprocessor architecture is “Elbrus”, without any suffixes. The name ""Elbrus-2000"" was chosen for the architecture, which they were going to implement together with Western companies in 2000. At the very beginning of 1999, an article describing the architecture of the microprocessor ""Elbrus-2000"" was printed in the Microprocessor Report as ""Elbrus-2000"", and in abbreviated form - ""E2k"". The current architecture of “Elbrus” has been significantly improved in relation to the E2k architecture, this is the third version, so the use of the old designation is not quite correct. In addition, the abbreviation E2K (with the capital letter ""K"") can be interpreted by orthodox computer scientists as 2048, which is completely worthless. 

I'd like to get full support added, which will require /proc/cpuinfo and     	
`($sysname, $nodename, $release, $version, $machine) = POSIX::uname();`
In terms of inxi, the values that are used are equivalent to: 
```
uname -o
uname -m
uname -a [for good measure]
```
Data per cpu:

**Elbrus 2EK:**
https://en.wikipedia.org/wiki/Elbrus_2000
Relevant specs:
300 MHz
cores: 1 ?
Cache:
64 KB L1 instruction cache 
64 KB L1 data cache 
256 KB L2 cache

**S**
No info. This might be just the original 2EK single core.

**2S+**
https://en.wikipedia.org/wiki/Elbrus-2S%2B
500 MHz 
cores: 2
cache: 
L1 instruction: 64 KB
L1 Data: 64 KB
L2 (per core): 1M
/proc/cpuinfo [incomplete]
```
processor       : 0
vendor_id       : E2K MACHINE
cpu family      : 4
model           : 20255552
model name      : Elbrus-e2k-e2c+
revision        : 1
cpu MHz         : 496.580
L1 cache size   : 64 KB
L1 cache line length    : 32 bytes
L2 cache size   : 1024 KB
L2 cache line length    : 64 bytes
```

**2SM**
https://en.wikipedia.org/wiki/Elbrus-2S%2B
300 MHz
cores: 2
cache: 
L1 instruction: 64 KB
L1 Data: 64 KB
L2 (per core): 1M

**4S**
https://en.wikipedia.org/wiki/Elbrus-2S%2B
800 MHz
cores: 4
cache: 
L1 instruction: 128 KB
L1 Data: 64 KB
L2 (per core): 8M

**8S**
https://en.wikipedia.org/wiki/Elbrus-8S
1.3 GHz
cores: 8
cache: 
L1 instruction: 128 KB
L1 Data: 64 KB
L2 (per core): 512KB
L3 (shared across cores): 16 MB 4 banks, 1 port each
architecture:   | VLIW, Elbrus (proprietary, closed) version 5, 64-bit

**8SB**
Maybe 2019

**16S**
coming 2019 or 2020

**E1C+/1S+**
This is a SOC, includes GPU
http://mcst.ru/mbe1c-pc
1000 MHz
cores: 1
/proc/cpuinfo:
```
processor       : 0
vendor_id       : MBE1C-PC
cpu family      : 4
model           : 8
model name      : E1C+
revision        : 1
cpu MHz         : 984.617955
L1 cache size   : 64 KB
L1 cache line length    : 32 bytes
L2 cache size   : 2048 KB
L2 cache line length    : 64 bytes
bogomips        : 1970.36
```





"
90,circulosmeos/gdown.pl,115,5,537,,537,"I am trying to download a very large 5 gig file. After all day downloading, I went to bed. In the middle of the night, the internet shut down. This morning I started back up to continue the download. But it is starting a new download. I see that the numbers in the wget-log are not the same as what is in the terminal window. Is there a way to just type in the numbers to continue the download from yesterday?[[[[[Next]]]]]I tried to download a folder, but it says ""404 not found"" error."
91,lamw/vghetto-scripts,365,36,537,,537,"Hello,

Would it be possible to add a possibility to have it work with an on-prem S3 solution ? So being able to add the url of our S3 solution ?

Thanks[[[[[Next]]]]]The code adds the possibility to query also for datacenter name instead of cluster name.
Please verify if the script still works for clusters as I don't have any to test it with."
92,Logitech/slimserver,159,37,526,,526,"Often, files are not played from the start if selected to play while playing another file.
I cannot reproduce this consistently, but it happens every 4th or 5th time a new file is selected to play.[[[[[Next]]]]]If album folders are renamed/moved without changed content, the files deleted count differs from the files added count by one - this seems to be consistent behavior in v8.0.x.
See [here](https://ibb.co/MR53Wkn).
Folder contains 263 mp3 files organized in subfolders.
As far as I can see, this is only a GUI, not a functional bug"
93,vsespb/mt-aws-glacier,57,35,514,,514,"Good day! I have a huge file collection(about 3 million files) and have uploaded around half of it but I stop midway because of some issue(s) in the EC2 server. 
Now, I tried to restart the process and I understand that it will again compare and skip out all the unmodified file(s) but it seems like it is taking a lot of time on just listing and comparing the files and I am curious if this is normal? I am currently at 400000 files as listed in the logs and this has been running close to **two days** already.

I have the following command executed just for context:
""nohup bash -c './mtglacier sync --config config.d/sync-media-backup.cfg --max-number-of-files 3000000 --concurrency 4 --partsize 64 --new >> /var/log/aws-glacier/sync.log' > /dev/null 2>&1 & echo $!""

Additionally, the EC2 server I have is also newly created and is dedicated just for this glacier upload operation. Is their a configuration option that I am missing to somehow throttle the **sync** process? Appreciate any feedback!
[[[[[Next]]]]]MT-AWS-Glacier, Copyright 2012-2014 Victor Efimov http://mt-aws.com/ Version 1.120

PID 1634 Started worker
PID 1635 Started worker
PID 1636 Started worker
PID 1637 Started worker
ERROR (parent): With current partsize=16777216MiB we will exceed 10000 parts limit for the file ""********"" (file size 186955223040)"
94,metabrainz/musicbrainz-server,215,43,512,,512,"### Implements MBS-10801, MBS-10802

This should be the last use of the display_relationship TT macro so this removes that too.

On top of https://github.com/metabrainz/musicbrainz-server/pull/1474[[[[[Next]]]]]`user_exists` exists on the Perl side to check if a user is logged in without possibly fetching that user from the database. It serves no purpose in our JavaScript; if the user is logged in, `$c.user` will be defined."
95,bestpractical/rt,179,88,507,,507,"During the development of a project, we had to create almost a dozen stacked RT extensions. We would have found the ability to subscribe to RT events quite powerful in order to implement certain features that, in the end, we had to implement with workarounds.

This changeset implements the invocation of two almost-identical events during the extensions initialization, in case the extensions want to use them. They are completely optional, meaning no existing extension is required to implement such methods.[[[[[Next]]]]]Allow sending email between RT queues on the same RT server."
96,openresty/stapxx,134,16,506,,506,"Beacause my company need to Signed kernel module,

so when i use this :  ./samples/lj-lua-stacks.sxx --arg time=5             --skip-badvars -x 5878  

and then server will give me :

Found exact match for libluajit: /usr/local/openresty/luajit/lib/libluajit-5.1.so.2.1.0
ERROR: Couldn't insert module '/tmp/stap2aamnM/stap_adf2660fb37e7e80e31dbfe8dc46d514_21214.ko': Required key not available
WARNING: /usr/bin/staprun exited with status: 1
Pass 5: run failed.  [man error::pass5]

so how can i just get a ko file ?
[[[[[Next]]]]]$ sudo ./stapxx/samples/lj-lua-stacks.sxx --arg time=30 DMAXSKIPPED=409600 DMAXMAPENTRIES=4096000 DSTP_NO_OVERLOAD  --skip-badvars -x 24248  > tmp1.bt
Found exact match for libluajit: /opt/luajit/lib/libluajit-5.1.so.2.1.0
WARNING: Start tracing 24248 (/opt/yz7/nginx/sbin/nginx)
WARNING: Please wait for 30 seconds...
WARNING: user string copy fault -14 at 0000000069726f13 [man error::fault]
ERROR: Skipped too many probes, check MAXSKIPPED or try again with stap -t for more details.
WARNING: Number of errors: 0, skipped probes: 101
WARNING: /usr/bin/staprun exited with status: 1
Pass 5: run failed.  [man error::pass5]

"
97,mikepound/pwned-search,92,2,499,,499,Isn't it a bit worrying that the password is stored in plaintext in the terminal history?[[[[[Next]]]]]
98,hachiojipm/awesome-perl,78,8,491,,491,[[[[[Next]]]]]Add pagerduty client
99,wireghoul/dotdotpwn,125,2,488,,488,"Ie, if / has to be encoded as %2f the traversal should use `..%2f..%2f..%2fetc%2fpasswd` not `..%2f..%2f../etc/passwd`[[[[[Next]]]]]Currently the http-url and http modules are requiring a pattern passed via the -k parameter like `-k ""root:""`

It would make sense to use sane defaults for each tested file like:

/etc/passwd -> root:
/etc/hosts -> localhost
boot.ini -> [boot loader]

and just make -k optional where people can overwrite the tested pattern.
"
