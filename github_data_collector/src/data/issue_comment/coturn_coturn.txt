I've been looking at [the wiki for loadbalancing](https://github.com/coturn/coturn/wiki/TURN-Performance-and-Load-Balance) and for multiple systems it states:

> Set a less complex scheme with round-robin DNS. The client must send all its requests to the same DNS-discovered TURN server. That scheme supports all use cases.

But how would this work if client A gets the ip of TURN server B, and client C gets the ip of TURN server D - their ICE candidates will be different, right? So how do they connect? How would authentication work even if they can agree on a TURN server.
Hi everybody,

Does anybody already has a working coturn configuration with Microsoft Direct Access ? I'm currently running a coTurn server with permission to relay audio and video flux through authentication and this relay is working perfectly but not when client are connected over Direct Access.

Negotiation on port 3478 seems good, but client is forced to use relay mode. Negotiation seems to return usable port on the turn server itself, but because this negotiation return IP addresses of the turn server, Direct Access is unable to transmit IPv4 while everything must use domain name.

Is there any tweak to let coturn returning domain name in reply instead of IP addresses, especially for itself?

added dbd_rest interface with remote_auth_api  usage option possibility
allows to connect to 3-d party server via RESTfull API of that server and fetch secret based on username

-- not sure if needed for now. but better remove after review
oauth functionality via RESTfull API of 3-d party server but not supported officially.
docker file updated with debian-stretch as well

I'm not sure about usage of 'W' and 'w' keys and about couple of of other things. So suggestions are required. 
I faced with a problem that a client (one of the participants in the call) may suddenly lose the connection. The client uses a mobile network.

Server Configuration:
- Coturn server v4.5.0.3
- Janus webrtc server v0.7.6

All calls use a TURN server that listens on port 443 and accepts only TLS connections. Using the TLS protocol is a necessary measure, otherwise the outgoing UDP traffic from the client does not reach the server (I suspect that it is blocked by the Internet provider). To diagnose the problem, I took a tcpdump of the traffic, both on the client side and on the server side. At the time of the loss of connection - Wireshark detects TCP Dup Ack on the outgoing traffic from the client, the same thing is observed on the incoming traffic on the server side. However, no RTP packet from TURN to Janus was lost.

Based on the dump of the TLS traffic on the server side measured the jitter of the client’s network. I measured it myself according to the algorithm:
1. Calculate the time difference between consecutive packets: packet No. 2 frame.time_epoch - packet No. 1 frame.time_epoch
2. Summarize the difference
3. Amount divided by the number of packages

I suspect that the problem is not on the side of the client’s mobile network, since the jitter only grew to 35ms at the time of losing the connection, while it was 17 when things were okay. So it occures to me that, yes the network suffers a bit, but not to the point of disconnecting the call (but still the call gets broken). So the techonolgy in some way just reacts unappropriitally to a mild network delay fluctuations.

At the time of a connection loss, the server turn logs have a records:
`TLS/TCP socket disconnected: client-ip-address:61116 closed (2nd stage), user <1577189233:uid> realm <domain> origin <>, local server-ip-address:443, remote client-ip-address:61116, reason: TLS/TCP socket buffer operation error (callback)`

Client TCP snapshot of outgoing traffic:
![image](https://user-images.githubusercontent.com/22684316/71408644-69aacc00-2658-11ea-88be-3d0e3bec68e2.png)

TCP snapshot of incoming traffic from the server side:
![image](https://user-images.githubusercontent.com/22684316/71408654-70d1da00-2658-11ea-8ebf-17c8241cfaad.png)

Summary of RTP traffic from TURN to Janus server:
![image](https://user-images.githubusercontent.com/22684316/71408669-78917e80-2658-11ea-9527-d6d6e193eb27.png)
![image](https://user-images.githubusercontent.com/22684316/71408682-81825000-2658-11ea-901e-2eebe231311e.png)

Please tell me, what could be wrong?
Hello,

We found it very beneficial to run the turns server on port 443 for bypassing restrictive firewalls. Usually this is easy, simply set the listener port to 443. In some cases this port is also used for a webserver, which complicates the matter.

I have implemented a feature that allows coturn to work behind haproxy as a reverse proxy. This allows multiplexing https and turns on the same port. An example haproxy.conf is included. In addition, you need to add 'tcp-proxy-port=5555' to your coturn config to start the proxy listener.

One cannot simply use a normal TCP load balancer as the source ip/port seen by coturn will be wrong. This affects the core protocol functionality (eg mapped address will show the reverse proxy ip).

Sincerely,
Bertold

Example haproxy.conf:

    frontend ssl-in
        mode tcp
        bind *:443 ssl crt /keys/cert.pem
        bind :::443 ssl crt /keys/cert.pem

        tcp-request inspect-delay 5s

        acl turn0 payload(0,1),hex -m sub 0
        acl turn1 payload(0,1),hex -m sub 1
        acl turn2 payload(0,1),hex -m sub 2
        acl turn3 payload(0,1),hex -m sub 3

        tcp-request content accept if HTTP
        tcp-request content accept if turn0 || turn1 || turn2 || turn3

        use_backend https if HTTP
        use_backend coturn if turn0 || turn1 || turn2 || turn3

    backend https
        mode http
        option forwardfor
        server https 192.168.1.1:80 cookie A

    backend coturn
        mode tcp
        server coturn 192.168.1.2:5555 send-proxy-v2

As reported by [RFC:](https://tools.ietf.org/html/rfc5389#section-16.1.2)
```
Revealing the specific software version of the agent through the
SOFTWARE attribute might allow them to become more vulnerable to
attacks against software that is known to contain security holes.
Implementers SHOULD make usage of the SOFTWARE attribute a
configurable option.
```
Just add `prod` to the configuration file to hide software version in Binding Success Response

![image](https://user-images.githubusercontent.com/1625334/71191778-5fb75080-2287-11ea-8f6a-0232de5ec8bb.png)

Hey There,

I've been using this turn server to relay connections using ICE and TCP, but have recently found that mobile users on Safari using Cloudflare's 1.1.1.1 mobile VPN are blocked from viewing the webRTC video streams.

In my coturn server I can see the appropriate logs, but I don't see the stream itself:
```
ession 001000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
187: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet ALLOCATE processed, success
193: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
195: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet ALLOCATE processed, success
203: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
213: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
223: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
233: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
243: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
246: session 001000000000000006: usage: realm=<exampledomain.com>, username=<>, rp=1, rb=20, sp=1, sb=100
246: session 001000000000000006: peer usage: realm=<exampledomain.com>, username=<>, rp=0, rb=0, sp=0, sb=0
246: session 001000000000000006: closed (2nd stage), user <> realm <exampledomain.com> origin <>, local 198.199.112.107:3478, remote 209.161.251.159:64969, reason: allocation watchdog determined stale session state
253: session 000000000000000006: realm <exampledomain.com> user <>: incoming packet BINDING processed, success
```

Currently my turn config is the default configuration, with only the realm being my actual domain (above for placeholder purposes exampledomain.com). I am running the coturn server via: `sudo turnserver -c /etc/turnserver.conf -v`.

I am running on Ubuntu 18.04 as well as using `4.5.1.1` as my current coturn version.

Startup looks like this:
```
0: log file opened: /var/log/turn_18214_2019-12-13.log
0:
RFC 3489/5389/5766/5780/6062/6156 STUN/TURN Server
Version Coturn-4.5.1.1 'dan Eider'
0:
Max number of open files/sockets allowed for this process: 1048576
0:
Due to the open files/sockets limitation,
max supported number of TURN Sessions possible is: 524000 (approximately)
0:

==== Show him the instruments, Practical Frost: ====

0: TLS supported
0: DTLS supported
0: DTLS 1.2 supported
0: TURN/STUN ALPN supported
0: Third-party authorization (oAuth) supported
0: GCM (AEAD) supported
0: OpenSSL compile-time version: OpenSSL 1.1.1  11 Sep 2018 (0x1010100f)
0:
0: SQLite supported, default database location is /usr/local/var/db/turndb
0: Redis is not supported
0: PostgreSQL is not supported
0: MySQL is not supported
0: MongoDB is not supported
0:
0: Default Net Engine version: 3 (UDP thread per CPU core)

=====================================================

0: Domain name:
0: Default realm: exampledomain.com
0: ERROR:
CONFIG ERROR: Empty cli-password, and so telnet cli interface is disabled! Please set a non empty cli-password!
0: WARNING: cannot find certificate file: turn_server_cert.pem (1)
0: WARNING: cannot start TLS and DTLS listeners because certificate file is not set properly
0: WARNING: cannot find private key file: turn_server_pkey.pem (1)
0: WARNING: cannot start TLS and DTLS listeners because private key file is not set properly
0: NO EXPLICIT LISTENER ADDRESS(ES) ARE CONFIGURED
0: ===========Discovering listener addresses: =========
0: Listener address to use: 127.0.0.1
0: Listener address to use: 198.199.112.107
0: Listener address to use: 10.12.0.10
0: Listener address to use: 172.17.0.1
0: Listener address to use: 172.18.0.1
0: Listener address to use: 172.16.238.1
0: Listener address to use: ::1
0: =====================================================
0: Total: 5 'real' addresses discovered
0: =====================================================
0: NO EXPLICIT RELAY ADDRESS(ES) ARE CONFIGURED
0: ===========Discovering relay addresses: =============
0: Relay address to use: 198.199.112.107
0: Relay address to use: 10.12.0.10
0: Relay address to use: 172.17.0.1
0: Relay address to use: 172.18.0.1
0: Relay address to use: 172.16.238.1
0: Relay address to use: ::1
0: =====================================================
0: Total: 6 relay addresses discovered
0: =====================================================
0: pid file created: /var/run/turnserver.pid
0: IO method (main listener thread): epoll (with changelist)
0: Wait for relay ports initialization...
0:   relay 198.199.112.107 initialization...
0:   relay 198.199.112.107 initialization done
0:   relay 10.12.0.10 initialization...
0:   relay 10.12.0.10 initialization done
0:   relay 172.17.0.1 initialization...
0:   relay 172.17.0.1 initialization done
0:   relay 172.18.0.1 initialization...
0:   relay 172.18.0.1 initialization done
0:   relay 172.16.238.1 initialization...
0:   relay 172.16.238.1 initialization done
0:   relay ::1 initialization...
0:   relay ::1 initialization done
0: Relay ports initialization done
0: IO method (general relay thread): epoll (with changelist)
0: turn server id=0 created
0: IPv4. SCTP listener opened on : 127.0.0.1:3478
0: IPv4. TCP listener opened on : 127.0.0.1:3478
0: IPv4. SCTP listener opened on : 127.0.0.1:3479
0: IPv4. TCP listener opened on : 127.0.0.1:3479
0: IPv4. SCTP listener opened on : 198.199.112.107:3478
0: IPv4. TCP listener opened on : 198.199.112.107:3478
0: IPv4. SCTP listener opened on : 198.199.112.107:3479
0: IPv4. TCP listener opened on : 198.199.112.107:3479
0: IPv4. SCTP listener opened on : 10.12.0.10:3478
0: IPv4. TCP listener opened on : 10.12.0.10:3478
0: IPv4. SCTP listener opened on : 10.12.0.10:3479
0: IPv4. TCP listener opened on : 10.12.0.10:3479
0: IPv4. SCTP listener opened on : 172.17.0.1:3478
0: IPv4. TCP listener opened on : 172.17.0.1:3478
0: IPv4. SCTP listener opened on : 172.17.0.1:3479
0: IPv4. TCP listener opened on : 172.17.0.1:3479
0: IPv4. SCTP listener opened on : 172.18.0.1:3478
0: IPv4. TCP listener opened on : 172.18.0.1:3478
0: IPv4. SCTP listener opened on : 172.18.0.1:3479
0: IPv4. TCP listener opened on : 172.18.0.1:3479
0: IPv4. SCTP listener opened on : 172.16.238.1:3478
0: IPv4. TCP listener opened on : 172.16.238.1:3478
0: IPv4. SCTP listener opened on : 172.16.238.1:3479
0: IPv4. TCP listener opened on : 172.16.238.1:3479
0: IPv6. SCTP listener opened on : ::1:3478
0: IPv6. TCP listener opened on : ::1:3478
0: IPv6. SCTP listener opened on : ::1:3479
0: IO method (general relay thread): epoll (with changelist)
0: turn server id=1 created
0: IPv4. TCP listener opened on : 127.0.0.1:3478
0: IPv4. TCP listener opened on : 127.0.0.1:3479
0: IPv4. TCP listener opened on : 198.199.112.107:3478
0: IPv4. TCP listener opened on : 198.199.112.107:3479
0: IPv4. TCP listener opened on : 10.12.0.10:3478
0: IPv4. TCP listener opened on : 10.12.0.10:3479
0: IPv4. TCP listener opened on : 172.17.0.1:3478
0: IPv4. TCP listener opened on : 172.17.0.1:3479
0: IPv4. TCP listener opened on : 172.18.0.1:3478
0: IPv4. TCP listener opened on : 172.18.0.1:3479
0: IPv4. TCP listener opened on : 172.16.238.1:3478
0: IPv4. TCP listener opened on : 172.16.238.1:3479
0: IPv6. TCP listener opened on : ::1:3478
0: IPv6. TCP listener opened on : ::1:3479
0: IPv4. UDP listener opened on: 127.0.0.1:3478
0: IPv4. UDP listener opened on: 127.0.0.1:3479
0: IPv4. UDP listener opened on: 198.199.112.107:3478
0: IPv4. UDP listener opened on: 198.199.112.107:3479
0: IPv4. UDP listener opened on: 10.12.0.10:3478
0: IPv4. UDP listener opened on: 10.12.0.10:3479
0: IPv4. UDP listener opened on: 172.17.0.1:3478
0: IPv4. UDP listener opened on: 172.17.0.1:3479
0: IPv4. UDP listener opened on: 172.18.0.1:3478
0: IPv4. UDP listener opened on: 172.18.0.1:3479
0: IPv4. UDP listener opened on: 172.16.238.1:3478
0: IPv4. UDP listener opened on: 172.16.238.1:3479
0: IPv6. UDP listener opened on: ::1:3478
0: IPv6. UDP listener opened on: ::1:3479
0: Total General servers: 2
0: IPv6. TCP listener opened on : ::1:3479
0: IO method (admin thread): epoll (with changelist)
0: IO method (auth thread): epoll (with changelist)
0: IO method (auth thread): epoll (with changelist)
0: SQLite DB connection success: /usr/local/var/db/turndb
```

This all looks fairly standard. Has anyone navigated around NAT traversal mobilly with cloudflare's VPN before?

Hi, will you consider supporting export metrics to Prometheus? 