Hi

I'm trying to replicate code in lme4-photon-sleep.zip in https://github.com/linkedin/photon-ml/issues/374 using Apache Toree notebook (directly accessing PhotonML API) Spark version 2.3.4 with scala 2.11.8 and latest Photon version jar.


I get error when trying to save random effects from model in the following step


```
val dx_re = mixedModel.toMap.get("rand").get match {
      case m: RandomEffectModel =>
        val reModelRDD = m.modelsRDD
        val re_tup = reModelRDD.map(x => (x._1, x._2.coefficients.means.toArray.zipWithIndex))
        val re_flat = re_tup.flatMap{
          case (store, arr) => {
            arr.map(cell => (store, cell))
          }
        }
        val coeffNames = rand_effects.columns.slice(1,rf_cols+2)
        val re_flat_col = re_flat.map(store_tup => (store_tup._1, coeffNames.apply(store_tup._2._2), store_tup._2._1))
  
        val dx_re = spark.createDataFrame(re_flat_col).selectExpr("_1 as store", "_2 as column", "_3 as coeff")
        dx_re
    }
dx_re.show()

```

> Message: <console>:82: error: value modelsRDD in class RandomEffectModel cannot be accessed in com.linkedin.photon.ml.model.RandomEffectModel
>  Access to protected value modelsRDD not permitted because
>  enclosing class $iw is not a subclass of
>  class RandomEffectModel in package model where target is defined
>                val reModelRDD = m.modelsRDD

Is this something related to my environment or changes in  Photon ML API?

If related to Photon ML how can I see/save random effects without using ModelProcessingUtils.saveGameModelToHDFS?

Problem with  ModelProcessingUtils.saveGameModelToHDFS is that it requires inputIndexMaps that is generated by AvroReader that I'd like to avoid as my data is in csv.


thanks

Hello

I wonder if there are any plans to implement GLMix in tensorflow.

thanks!
Changes are:
(1) Added unit tests in `PriorDistributionTest.scala`;
(2) Fixed bugs in L2 regularization gradient and Hessian computation.
The 'model-metadata.json' file is not saved in GCS after a full GAME run.

[Here](https://github.com/linkedin/photon-ml/blob/049dfa8736ec7db58bc815f95d1de547ecdbf8fb/photon-client/src/main/scala/com/linkedin/photon/ml/data/avro/ModelProcessingUtils.scala#L498) is the code that runs it.

This prevents from doing warm-start training as the prior run's file is needed.

Please fix. Thanks!
- Fix bug: previously AvroDataReader would only repartition when IndexMapLoaders provided
- Removed integration test assertions that depended on strict ordering of data in DataFrame
- Added integration test to check that explicit repartition is called
this is currently the implementation of ratio modeling for feature selection of random effect in photon.
I follow the algorithm described in the original publication but some twists are made according to discussion with yiming and alex.

- [x] Unit tests all pass.

- [x] Integration tests all pass.

The algorithm in reality(highly related with codebase instead of only mathematical expression) is as follows:

1.pass in the featureStatisticSummary 
2.identify the binomial columns
3.compute the lowerbound for binomial columns based on the t value
4.select the feature based on only the following lowerbound criterion(non-binomial and intercept columns are kept automatically)
```
if (t < 1) {
  T_l = 1 / T_u
}

if (T_l > 1D) {
  //  select feature
}
```

As a WIP commit, there are things to polish in near future since we currently focus on the feasibility of this experimental method and try to minimize user-side changes :

- [x] unit tests not fully covering all scenarios of feature selection. Currently the binomial cases are not selected, we need to craft some data that covering all cases.

- [x] binomial feature column identification predicate needs to be stronger. Current solution is inherently flawed, we need more computation at feature summary stage to ensure this one.

- [ ] hyperparameter interface design. for convenience purposes, the user side interface for pass in normal distribution quartile and lowerbound threshold hyperparameter redesign.

- [x] the relationship with pearson correlation feature selection. We need another parameter to decide on the algorithm of feature selection or mix them in later stage.

- [x] crafted test data need some change, currently some unneeded feature summary entries are not carefully addressed.

- [ ] further experiment report and benchmark report after regression tests

- [x] the way we currently keep non-binary and intercept columns is not good for further feature ranking report planned. need redesign

@joshvfleming @ashelkovnykov 
When optimization tracking is enabled, random effects currently track and summarize the convergence reason (or lack thereof) for each ID. The IDs that failed to converge should be logged and output at the end of training to aid tracking bugs.

It's also important to question: what causes models to fail to converge - can we detect it before training through data validation alone?
While comparing spark.ml and scikit, we realized that Game is using a sum in the loss function computation, but that is not desirable for scaling and numerical stability. We should change our loss function calculations to use a mean instead. 
Today, intercept terms in `GameEstimator` are handled differently than they are in spark.ml `Predictor.fit`, so that the same `DataFrame` cannot be passed as is to both to produce the same result. In Game, we need to add an "intercept" feature column if we want to get the same model out of `fit` as spark.ml. T
It would be more idiomatic with Spark for us to remove all ownership of RDDs and Dataframes from the core Photon-ML code, transforming it into a pipeline of transforms on a RDD/Dataframe loaded by the client and provided to the API.