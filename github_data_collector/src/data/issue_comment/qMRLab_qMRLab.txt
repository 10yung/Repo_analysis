Hey @ileppe and @agahkarakuzu !

Someone flagged a bug in Barral's original code in my fork (https://github.com/mathieuboudreau/Gold-Standard-Inversion-Recovery-T1-Mapping/issues/1). I was wondering if either of you encountered this while working on the qMRLab implementation, and what workaround did you have. It does appear that that variable contains all the important sequence information, per the similar simulation script that works for me: https://github.com/mathieuboudreau/Gold-Standard-Inversion-Recovery-T1-Mapping/blob/master/mfiles/mainSim.m
I have opened the qMRLab using Jupyter nb , but I am not sure how to actually run the code and study my images. Any help is appreciated. 
#255

On `mp2rage` branch I was trying to use `mt_sat` and get the following error:

```
Error while evaluating UIControl Callback
```

It is not verbose enough for me to understand what exactly it is atm. Yet, I know that I did some changes to the GUI functionality on the `mp2rage` branch, will have to go through those changes and fix this problem. 
hey team! what should be the strategy for handling division by zero (or epsilon) when computing MTR (this applies to other methods too, e.g. MTsat)?

- detect small divisor, mask out those elements during division and replace those elements in the output array by X
- divide everything and handle the output (look for aberrant values and replace by X)
  - one problem with that is that when saving niftis with a very large range (i.e. including e.g. -/+ 10^15), the precision gets hurt in an uncontrolled manner (requires to take care of the output dtype, pushing physical space (e.g. with float64) unnecessarily).
  - another problem (minor), is that division by zero might be handled differently across platforms, potentially yielding differences in precision (see my comment below) and/or warning messages.

What should be X:  zeros? nan? inf?
- i see two problems with replacing by zero:
  - users might blindly use the output image to aggregate metrics, and include zeros in their calculations.
    - a mask could be provided alongside the output image, but some uninformed users will not consider the mask and go on with their processing. I've seen that happening.
  - some users will want to resample their output image to another space, yielding critical bias when interpolating zeroed-values (at least, nan/inf would output an error, depending on the software).

I've been trying to handle this at both levels (during the division process, and at the output level), to provide maximum flexibility. See an example [here](https://github.com/neuropoly/spinalcordtoolbox/pull/2503) (feedback welcome :-)).
This is a TO-DO item to be worked on immediately after the ISMRM deadline.

Per our email discussion, we need to implement a way so that the Protocol panel can be designed in the exact same way as the Option panel is in "Option 2" of the figure below.

![MP2RAGE](https://user-images.githubusercontent.com/1421029/66416192-a9580500-e9d3-11e9-8149-d4543d99daf9.png)

Both MP2RAGE (to merge soon) and MTSat need to then be refactored to used this new format for a cleaner GUI and better user experience.
Hello qMRILab developers 
I am using your package for QSM analysis . 
when I run the code I got some errors which is not resolvable for me 
I will attach it below . 
I appreciate any help . 
thanks a lot 


Error using logical
NaN's cannot be converted to logicals.

Error in qsm_sb/fit (line 194)
  data.Mask = logical(data.Mask);

Error in FitData (line 209)
    Fit = Model.fit(data);

Error in qMRLab>FitGo_FitData (line 362)
FitResults = FitData(data,Model,1);

Error in qMRLab>FitGO_Callback (line 344)
FitGo_FitData(hObject, eventdata, handles);

Error in gui_mainfcn (line 95)
        feval(varargin{:});

Error in qMRLab (line 37)
    gui_mainfcn(gui_State, varargin{:});

Error in
matlab.graphics.internal.figfile.FigFile/read>@(hObject,eventdata)qMRLab('FitGO_Callback',hObject,eventdata,guidata(hObject)) 
Error while evaluating UIControl Callback.

I am very pleased to add this joint work by @yasuhik and @TomMingasson and myself.
 
## Purpose
This Monte Carlo simulator for 2D diffusion is able to generate synthetic diffusion signal from any 2D axon packing.

## Approach
First, the [axonpacking](https://github.com/neuropoly/axonpacking) software is used to generate dense packing of circles. Then, the Monte Carlo simulator moves water molecules around in the packing and apply the phase shift induced by the diffusion gradients. 

## Interface
First step is to generate an axon packing. Pre-packed examples are proposed:
<img width="969" alt="Capture d’écran 2019-08-28 à 19 25 23" src="https://user-images.githubusercontent.com/7785316/63878317-a841ba00-c9c9-11e9-96af-093dcd2148b6.png">

Then, when clicking on `Update` button, the Monte Carlo simulation runs in this packing.
![image](https://user-images.githubusercontent.com/7785316/63879406-f657bd00-c9cb-11e9-8946-edf673e13e09.png)
_Note: blues dots correspond to extra-axonal water molecules and red dots to intra-axonal water_
_Note: The `MPG strength` and `Signal Strength` plots correspond to the last bvalue in the protocol. But Signal Strength is computed for all bvalues from the protocol._

Once the simulation is finished, synthetic data are plotted and fitted by the charmed model.
![image](https://user-images.githubusercontent.com/7785316/63879931-fa380f00-c9cc-11e9-939c-2bb80f2f99c4.png)
The user is able to save this synthetic signal in a `.mat` file.

## Results
1. Free water diffusion
![image](https://user-images.githubusercontent.com/7785316/63878464-f5259080-c9c9-11e9-862e-6e2cb3062807.png)
![image](https://user-images.githubusercontent.com/7785316/63878661-59e0eb00-c9ca-11e9-93e3-b2ef8ba3b8e1.png)
With no axons, the diffusion coefficient is correctly measured:
  **Test 1 (600 particles):
  D_monte_carlo = 1.5x10-3 mm2/s 
  ADC_fitted = 1.58x10-3 mm2/s 
  Test 2 (600 particles):
  D_monte_carlo = 2.5x10-3 mm2/s 
  ADC_fitted = 2.69x10-3 mm2/s** 

2. Small pulse approximation model in single diameter samples 
<img width="969" alt="Capture d’écran 2019-08-28 à 18 35 08" src="https://user-images.githubusercontent.com/7785316/63879135-58fc8900-c9cb-11e9-8d32-c84e27010ce2.png">
We observe the diffusion-diffraction patterns and we can correctly measure axon diameter.
<img width="622" alt="Capture d’écran 2019-08-28 à 18 29 40" src="https://user-images.githubusercontent.com/7785316/63879277-9e20bb00-c9cb-11e9-9b11-cde6a7ef299e.png">

  **AxonDiameterPacking = 8µm
  AxonDiameterFitted = 7.98µm** 
<img width="619" alt="Capture d’écran 2019-08-28 à 18 34 58" src="https://user-images.githubusercontent.com/7785316/63879291-a5e05f80-c9cb-11e9-935d-5d4e88481d7d.png">

  **AxonDiameterPacking = 5µm
  AxonDiameterFitted = 4.70µm** 

#### Open Questions and Pre-Merge TODOs
- [ ] Use github checklists. When solved, check the box and explain the answer.

- [ ] Review that changed source files/lines are related to the pull request/issue
_If any files/commits were accidentally included, cherry-pick them into another branch._

- [ ] Review that changed source files/lines were not accidentally deleted
_Fix appropriately if so._

- [ ] Test new features or bug fix
_If not implemented/resolved adequately, solve it or inform the developer by requesting changes in your review._
_Preferably, set breakpoints in the locations that the code was changed and follow allong line by line to see if the code behaves as intended._

##### Manual GUI tests (general)

- [ ] Does the qMRLab GUI open?
- [ ] Can you change models?
- [ ] Can you load a data folder for a model?
- [ ] Can you view data?
- [ ] Can you zoom in the image?
- [ ] Can you pan out of the image?
- [ ] Can you view the histogram of the data?
- [ ] Can you change the color map?
- [ ] Can you fit dataset (Fit data)?
- [ ] Can you save/load the results?
- [ ] Can you open the options panel?
- [ ] Can you change option parameters?
- [ ] Can you save/load option paramters?
- [ ] Can you select a voxel?
- [ ] Can you fit the data of that voxel ("View data fit")?
- [ ] Can you simulate and fit a voxel ("Single Voxel Curve")?
- [ ] Can you run a Sensitivity Analysis?
- [ ] Can you simulate a Multi Voxel Distribution?

##### Specifications

  - Version:
  - Platform:
  - Subsystem:

Hi all, I am trying to process T2 relaxation data in a naive rat brain with a mask covering just to corpus callosum as that is what we are mainly interested in. The data was collected at 21T, so it is expected that the T2MW will be very short, so I have been trying to process with the cutoff T2 range of MW to be 0 to ~20, with some tries lower and higher. I was able to make lower ranges by changing the T2.range in the "getT2.m" file from 1.5*TE to 1 or 0.5*TE since my TEs begin at 8.5. However, I am getting data that seems to be zeroed out T2MW, and consequently MWF as well, with a few sporadic voxels showing _some_ trends of what I think would be normal and others showing nonzero results but only 1 peak. When looking at independent voxels in the GUI, the T2 relaxation curve looks totally normal, so I don't believe the issue lies with the data itself. 


I am curious as to what I may be recommended to change in the code itself, whether it be mu, the chi ^2 range (and within what ranges would be acceptable?), of if there is a tolerance variable that may be throwing it off. I have attached my data, mask, protocol parameters for the GUI, and an example set of processed data so show what I am talking about if that may help. I am not sure if my assumptions or setups to the processing are valid or incorrect. 
[MWF data and results.zip](https://github.com/qMRLab/qMRLab/files/3546860/MWF.data.and.results.zip)
Any suggestions? 


Just noticed this here when creating a branch: https://travis-ci.org/qMRLab/qMRLab/jobs/575809658

Getting the following error:

```
$ travis_retry sudo apt-get -y -qq install octave liboctave-dev octave-pkg-dev
Unable to correct problems, you have held broken packages.
The command "sudo apt-get -y -qq install octave liboctave-dev octave-pkg-dev" failed. Retrying, 2 of 3.
```

For "Gaussian" and "spline" filters, it appears that there's a lot of bleed-through from the noise outside the brain, unlike for "median" and "polynomial" filters. For certain scale bar ranges, this can make it appear like there's different masking or erosion after filtering. See Figure 2 in this blog post: https://qmrlab.org/2019/08/08/b1filter.html