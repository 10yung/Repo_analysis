anyone can you give  me a steps to test the pretrained model
Hello Kim.

Using the MATLAB MRCG proved to take a lot of RAM.
I can not use a bigger than 5Min file as an input with 16GB RAM system.
In the paper it was written that a very long sound file was used for train, so how could you compute the MRCG for it?

Thanks, Ravid.
Hi dear


I ran your reposity , but it shown some error .
I find there is no data under data/train/feat/  directory
can you help with me?

Thanks
weizhe
Thanks for the code repo!

Q1. Could you please explain the meaning of the following functions in VAD/utils.py?
-Truelabel2Trueframe
-frame2rawlabel
-vad_post

What exactly are these functions doing? 

Really appreciate if you could reply ASAP. The greater the detail you can provide, the better. Thanks a lot!
 Can anyone share the noisy data,  General Series 6000 Combo and NOISEX-92.
Hi,

I am a DSP engineer and acoustician. I'm new in the field of machine learning and neural networks and I am learning a lot working on your code :). 
I am trying to understand the feasibility to squeeze your VAD graph architecture to be used in real-time. Right now I am able to retrain the neural net modifying a few parameters (mainly the frame window and overlap) using the D2 dataset in your paper. Although, it looks like the best ways to improve the graph computation are:

1) To use a less complex feature extractor other than the MRCG (I pretend to investigate this hypothesis later).
2) To retrain the neural net for smaller batch sizes with D2. In your paper your use 4096 which corresponds to several seconds of audio. 

I 've tried to perform this training multiple times for different batch sizes (2048,1024,512,...) and I failed so far in this quest. Sometimes the accuracy of the training achieves a high value but it never generalizes for the test data.

I believe something is wrong on the training parameters and that's because I am contacting you for guidelines. Did you ever try to train the neural net for smaller batch sizes? Something should be changed on the net architecture or on the training parameters?

What is the recommended relative size of the audio to be tested over batch size? More clearly: may I test a graph trained with a large batch size with a very small audio sample? My intuition is that it is not possible. That's because I would like to retrain the net with a smaller batch size so that I could perform sequential tests with an audio buffer of reasonable size (let's say 500 ms).

Finally, do you have any recommendation for simplifying the network computational complexity without sacrificing too much in performance? 

I appreciate your time in sharing your knowledge and experience,
Cheers,
Lucas

 
Firstly, thanks for your contribution in VAD field! I have two question:
1. wether the train data of net input is the MRCG featureï¼Ÿ
2. what is the deference of VAD_LSTM and VAD_LSTM2 ?
tks!
Hi,
See you again.
How is everything going ?

Could you please supply the trained model,I just want to have a test ,
emm,Could the model strip the silence ? Or How could I realize ?

Thx 
According to my understanding, when an audio file is passed to the VAD model to be analyzed, the DNN (as well as other models) gets loaded to do the job, but when a second audio file is passed to the VAD, the module gets reloaded, which takes up a lot of time. Is there any way to load the module only once and have the module predict on many audio files?

Thanks!
Hi Kim,

Apologize for disturbing you for many times, but I have problem understanding your normalization code. I found some code in the `acoustic_feat_ex.m`:
```matlab
%% Save global normalization factor

global_mean = train_mean / length(audio_list);
global_std = train_std / length(audio_list);
save([save_dir, '/global_normalize_factor'], 'global_mean', 'global_std');
```

and in every `data_reader_XXX.py`:
```python
norm_param = sio.loadmat(self._norm_dir+'/global_normalize_factor.mat')
self.train_mean = norm_param['global_mean']
self.train_std = norm_param['global_std']
```

My questions are:  
1. Is a global normalize factor for the whole dataset saved in `acoustic_feat_ex.m`? Why don't calculate factor for every single train file and apply normalization on it?
2. If so, why this factor is used also during the prediction phase (because `data_reader_XXX.py`s are also used during the prediction)? Is this a mistake?

Thanks in advance!  
Charlie Jiang