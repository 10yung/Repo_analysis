when i run my code so for some instant run and then give me this error 
ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at C:\w\1\s\windows\pytorch\aten\src\THNN/generic/ClassNLLCriterion.c:97

`loading vocabulary file bert-base-uncased-vocab.txt
loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\redro\.pytorch_pretrained_bert\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
extracting archive file C:\Users\redro\.pytorch_pretrained_bert\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\redro\AppData\Local\Temp\tmpbysl_867
Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

n_trainable_params: 109484547, n_nontrainable_params: 0
> training arguments:
>>> model_name: bert_spc
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x0000013E80479E18>
>>> learning_rate: 2e-05
>>> dropout: 0.1
>>> l2reg: 0.01
>>> num_epoch: 10
>>> batch_size: 64
>>> log_step: 10
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> device: cpu
>>> seed: None
>>> cross_val_fold: 10
>>> model_class: <class 'models.bert_spc.BERT_SPC'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_bert_indices', 'bert_segments_ids']
fold : 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0`
Greetings, 

I have two tensors each of 4 dimensions when i try to multiply them I got this error "multiplication between 4D and 4D tensors not yet supported"

Is there any alternative to multiply two tensor of 4 dimensions in lua ?

Thank you in advance 
I am getting an error while installing `torch`

```
readline.c:8:10: fatal error: readline/readline.h: No such file or directory
 #include <readline/readline.h>
          ^~~~~~~~~~~~~~~~~~~~~
compilation terminated.
```

I have executed the following commands:
```

git clone https://github.com/torch/distro.git ~/torch --recursive
cd ~/torch; bash install-deps;
./install.sh
```
Can we change this size/1073741824 into size * 1.0/1073741824 to make the err msg more precise?


How do i convert the txt file to .t7 format?
Hi,
I would like to cross-compile Torch on my computer (Ubuntu x64) in order to use it on an embedding system (Linux ARMv8). I would like to know if it is possible for Torch, and if I could have some clues about how it works?  
Thanks
Torch version 1.10. Cuda version 9.0. Cudnn version 7.0.   RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILEDã€‚What is the reason? Does the cudnn version not match? But my tensorflow works.
Is there a way to run Torch on [repl.it](https://repl.it/) ?

https://repl.it/languages/polygott
Problem with CUDA, Mac OSX 10.14

I have CUDA version 10.1.105 installed

However, the installer finds an older CUDA version 5.5:

..........

Found CUDA on your machine. Installing CUDA packages
Warning: unmatched variable LUALIB

jopts=$(getconf _NPROCESSORS_CONF)

echo "Building on $jopts cores"
cmake -E make_directory build && cd build && cmake .. -DLUALIB= -DLUA_INCDIR=/Users/gustafullman/torch/install/include -DCMAKE_CXX_FLAGS=${CMAKE_CXX_FLAGS} -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH="/Users/gustafullman/torch/install/bin/.." -DCMAKE_INSTALL_PREFIX="/Users/gustafullman/torch/install/lib/luarocks/rocks/cutorch/scm-1" && make -j$jopts install

Building on 8 cores
-- Found Torch7 in /Users/gustafullman/torch/install
CMake Error at /usr/local/Cellar/cmake/3.9.6/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:137 (message):
  Could NOT find CUDA: Found unsuitable version "5.5", but required is at
  least "6.5" (found /usr/local/cuda)
Call Stack (most recent call first):
  /usr/local/Cellar/cmake/3.9.6/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:375 (_FPHSA_FAILURE_MESSAGE)
  /Users/gustafullman/torch/install/share/cmake/torch/FindCUDA.cmake:1009 (find_package_handle_standard_args)
  CMakeLists.txt:7 (FIND_PACKAGE)


-- Configuring incomplete, errors occurred!
See also "/Users/gustafullman/torch/extra/cutorch/build/CMakeFiles/CMakeOutput.log".

Error: Build error: Failed building.
I'm running `preprocess_stage2.lua` code [https://github.com/anibali/lidc-idri-preprocessing/tree/master/stage2](url). But getting below error

```
lua: Trying to resize storage that is not resizable at /home/msaha6/torch/pkg/torch/lib/TH/generic/THStorage.c:183
stack traceback:
	[C]: ?
	[C]: in function 'IntTensor'
	preprocess_stage2.lua:73: in main chunk
	[C]: ?
```

## To Reproduce

Steps to reproduce the behavior: I'm running below code using command `lua preprocess_stage2.lua `

```
`require('torch')
local cjson = require('cjson')
local pl = require('pl.import_into')()
local DenseVolume = require('DenseVolume')

torch.setdefaulttensortype('torch.FloatTensor')

-- Set manual seeds for reproducible RNG
torch.manualSeed(1234)
math.randomseed(1234)

-- Input directory
local stage1_dir = '/data/lidc/LIDC-IDRI_stage1'
-- Output directory
local stage2_dir = '/data/lidc/LIDC-IDRI_stage2'

-- Check that stage1_dir is an existing directory.
if not pl.path.isdir(stage1_dir) then
  error(string.format('Input directory not found: "%s"', stage1_dir))
end

-- The number of augmented variations we want to generate for each example.
-- It is possible to increase this number and run the script again.
local n_augmentations = 32

local examples = pl.dir.getallfiles(stage1_dir, '*/nodule_*_metadata.json')
local planes = torch.Tensor(3, 113, 113)

local function normalize_voxels(voxels)
  local min = -2048
  local max = 4096
  local deviation = (max - min) / 2
  local offset = -(deviation + min)
  voxels:add(offset):div(deviation)
  return voxels
end

-- Reads and parses entire JSON file
local function read_json_file(path)
  local file = io.open(path, 'r')
  if not file then return nil end
  local text = file:read('*all')
  file:close()
  return cjson.decode(text)
end

for i,example_file in ipairs(examples) do
  print(string.format('%4d/%4d', i, #examples))

  local out_dir = pl.path.join(
    stage1_dir,
    ({string.find(pl.path.relpath(example_file, stage1_dir), '(.*/nodule_.*)_metadata%.json')})[3]
  )

  local example_dir = pl.path.dirname(example_file)
  local scan_metadata = read_json_file(pl.path.join(example_dir, 'scan_metadata.json'))
  local metadata = read_json_file(example_file)

  if pl.path.isdir(out_dir) then
    -- Find the current number of augmentations we have stored
    local planes_files = pl.dir.getallfiles(out_dir, 'planes_*.t7')
    table.sort(planes_files)
    local cur_n_augs = 0
    if #planes_files > 0 then
      cur_n_augs = tonumber(({string.find(pl.path.basename(planes_files[#planes_files]), 'planes_(%d+).t7')})[3])
    end
    -- Increase the number of augmentations if necessary
    if n_augmentations > cur_n_augs then
      -- Load voxels from disk
      local int_storage = torch.IntStorage(pl.path.join(example_dir, 'scan.dat'), false)
      local voxels = torch.IntTensor(int_storage, 1, torch.LongStorage{scan_metadata.rows, scan_metadata.cols, scan_metadata.slices}):float()
      normalize_voxels(voxels)

      local pixel_size = 80 / planes:size(2)
      local centre = {metadata.y_pos, metadata.x_pos, metadata.slice_number}

      local dv = DenseVolume.new(voxels,
        {scan_metadata.row_spacing, scan_metadata.column_spacing, scan_metadata.slice_thickness})

      for j = (cur_n_augs + 1), n_augmentations do
        dv:to_planes(planes, pixel_size, centre, DenseVolume.jitter(math.pi / 90, 1.0, 0.02))
        torch.save(pl.path.join(out_dir, string.format('planes_%03d.t7', j)), planes)
      end
    end
  else
    -- Make output directory and copy metadata files across
    pl.dir.makepath(out_dir)
    pl.file.copy(pl.path.join(example_dir, 'scan_metadata.json'), pl.path.join(out_dir, 'scan_metadata.json'))
    pl.file.copy(example_file, pl.path.join(out_dir, 'nodule_metadata.json'))

    -- Load voxels from disk
    local int_storage = torch.IntStorage(pl.path.join(example_dir, 'scan.dat'), false)
    local tensor_size = torch.LongStorage{scan_metadata.rows, scan_metadata.cols, scan_metadata.slices}
    local voxels = torch.IntTensor(int_storage):view(tensor_size):float()
    normalize_voxels(voxels)

    local pixel_size = 80 / planes:size(2)
    local centre = {metadata.y_pos, metadata.x_pos, metadata.slice_number}

    local dv = DenseVolume.new(voxels,
      {scan_metadata.row_spacing, scan_metadata.column_spacing, scan_metadata.slice_thickness})

    -- Generate and save unaugmented planes
    dv:to_planes(planes, pixel_size, centre)
    torch.save(pl.path.join(out_dir, string.format('planes.t7', j)), planes)

    -- Generate and save augmented planes
    for j=1,n_augmentations do
      dv:to_planes(planes, pixel_size, centre, DenseVolume.jitter(math.pi / 90, 1.0, 0.02))
      torch.save(pl.path.join(out_dir, string.format('planes_%03d.t7', j)), planes)
    end
  end

  collectgarbage()
end `
```

<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->

## Expected behavior

<!-- A clear and concise description of what you expected to happen. -->

## Environment
PyTorch version: 0.3.1
Is debug build: No
CUDA used to build PyTorch: 8.0.61

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
CMake version: version 2.8.12.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: 
GPU 0: Quadro K1200
GPU 1: Quadro K1200

Nvidia driver version: 410.79
cuDNN version: /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn.so.7.2.1

Versions of relevant libraries:
[pip3] msgpack-numpy==0.4.3.2
[pip3] numpy==1.16.2
[pip3] torch==0.3.1
[pip3] torchfile==0.1.0
[pip3] torchvision==0.2.0
[conda] Could not collect

## Additional context

I found some post related to this issue but I was not able to solve in my code. [https://github.com/torch/torch7/pull/389](url) and [https://github.com/torch/torch7/issues/363](url)
