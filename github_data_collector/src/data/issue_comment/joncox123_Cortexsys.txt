
What is the content of the function **gather.m**?  I have been trying to run the example **MNIST_Deep_Classifier** but it produces the following message error:
**Undefined function or variable 'endfunction'.

Error in gather (line 3)
endfunction**

When I checked the function, this is empty, the only text, after the definition of the function,
is **endfunction**. 

What is the purpouse of the function **gather.m**?

Thanks in advance.



Hi all,
I had a problem compiling the mmx files with build_mmx.m Script. 

Error Code:
...Cortexsys\nn_core\mmx\mmx.cpp:79:16: error: expected initializer before 'teval'
 DWORD _stdcall teval(void* pn)

Fix: 
In File mmx.cpp Line 79 add a double underscore to stdcall:
L79: DWORD __stdcall teval(void* pn)

Hope this helps :)
Hello,
I have been trying to create a convolutional autoencoder for use with 1D data.  I can define the network, and I can run data through the untrained network, but attempting to train the network produces the following error:

Output argument "gp" (and maybe others) not assigned during call to "LinU/ograd".

Error in nnCostFunctionCNN (line 53)
                d{k} = (nn.A{nn.N_l}.v - Y.v).*nn.l.af{nn.N_l}.ograd(nn.A{nn.N_l}.v);

Error in @(nn,r,newRandGen)nnCostFunctionCNN(nn,r,newRandGen)

Error in gradientDescentAdaDelta (line 69)
    [J, dJdW, dJdB] = feval(f, nn, r, true);

Any suggestions for a workaround would be appreciated.
The network defined as follows:
input size = 100, output size = 4

```
layers.af{1} = [];
layers.sz{1} = [input_size 1 1];
layers.typ{1} = defs.TYPES.INPUT;

layers.af{end+1} = ReLU(defs, []);
layers.sz{end+1} = [input_size 1 1];
layers.typ{end+1} = defs.TYPES.FULLY_CONNECTED;

layers.af{end+1} = ReLU(defs, []);
layers.sz{end+1} = [output_size 1 1];
layers.typ{end+1} = defs.TYPES.FULLY_CONNECTED;

if defs.plotOn
    nnShow(23, layers, defs);
end
```
Error in
```
Error using  - 
Matrix dimensions must agree.

Error in squaredErrorCostFun (line 2)
    J = (Y.v(:,:,t)-A.v(:,:,t)).^2;

Error in ReLU/cost (line 65)
            J = squaredErrorCostFun(Y, A, m, t);

Error in nnCostFunctionCNN (line 29)
J = nn.l.af{nn.N_l}.cost(Y, nn.A{nn.N_l}, m, 1) + J_s;

Error in
Train_proposal>@(nn,r,newRandGen)nnCostFunctionCNN(nn,r,newRandGen)

Error in gradientDescentAdaDelta (line 69)
    [J, dJdW, dJdB] = feval(f, nn, r, true);

Error in Train_proposal (line 158)
nn = gradientDescentAdaDelta(costFunc, nn, defs, [], [], [], [], 'Training
Entire Network');
```
Thanks for the great toolbox!

I would like to build a encoder-LSTM-decoder network using your toolbox.

What would be best practice to train such a network, as to my understanding the input format for the encoder and decoder would differ from the LSTM, which would make it impossible to train the network in one go, correct?

Is it therefore possible to train the encoder and decoder networks separately and use the encoder output as input to the LSTM network for training. And after training stack the layers?
Hi Jon,
When I use the normal gradientdescent function and I set alpha to zero (as your comment in that line implies that this will lead to a variable learning rate) the learning rate will actually stay at 0 the entire time and my error for the MNIST stays at ~90%. If I set alpha to a value it will use this as the first value and then decay it according to the equation in alphatau. So it works, but the comment is misleading. There seems to be only the option of using a variable learning rate. A constant seems not implemented. 

Anyways, great code :)

I want to use LSTM for mnsit classification , i have created two cell arrays for input data and labelled data both 0f 5000x1 , X nad y respectively , X have each cell of 400 x 1, which is the 20x20 image ,Is it the right approach??? but the problem is that i have to set T = 5000 and its taking too long to train the network..
Any suggestions 
I want to use LSTM neural network for classification of images, the input of Lstm must be cell array ?