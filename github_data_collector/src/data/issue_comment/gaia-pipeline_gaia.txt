We should probably release a new version? Last release was ~Feb; It's not just good practise; it helps keep interested parties following the project/progress via "Watch Releases" :)
Going through the documentation, examples and the Go SDK (_I assume the other language SDKs are the same_); It doesn't seem possible to have a job compute and return some output which you may use as input into the next job(s) in your pipeline.

The only thing a Job can do is take some input `Arguments` and return an error. I assume the design calls for inputs to be known up front.

What if I need some inputs to a Job in my pipeline whose values are dependent on a previous job? This doesn't seem possible right now; Is this by design? Does this add considerable complexity to something like Gaia?

In a "normal" gRPC/Protobuf service oriented architecture (_which Gaia is loosely based around; but behaves more like server-less, faas..._) you would expect to be able to return some "output" from your service's endpoints/functions/etc.

Thoughts?
Closes #219 
Use base64 encoded pipeline name for virtual env creation as it fails with non ascii chars.

Refer to issue for more information.
Steps to reproduce

1. Create new pipeline
2. For Repo, use the example repo `https://github.com/gaia-pipeline/python-example` 
3. For Pipeline name give `testæ–‡`

**Output**:
Pipeline creation fails

**Expected Output**:
Pipeline should be created successfully


The source of the issue can be traced to creation of the virtual environment. This is a known issue with virtualenv
https://github.com/pypa/virtualenv/issues/457

The pipeline also fails with the name that contains `$` followed by one or more characters
example :  `test$python`.

We currently check if a pipeline binary needs to be rebuilt again on the worker when an exception is thrown which contains `exec format error` (https://github.com/gaia-pipeline/gaia/blob/master/workers/agent/agent.go#L464). We need to make sure that this error message is thrown for every supported programming language.
The python SDK is currently optimized for python 2.7 which will be not longer supported by 01.01.2020. We need to upgrade the SDK to support python 3.

In all the source code there are a lot of places where pointers are not needed or are declared all over the place.

When we first create a struct, we don't know it's memory address so using pointer semantic is pointless ( pun intended :D ).

Something like this:

```go
mW := &mockWhatever{}
```

These things are confusing and are hard to read. This means you will have a cognitive load whenever you see this variable passed around because you have to remember that it will be an address. Instead the `&` adds readability. Which means it should be used at places where it denotes *sharing*. Like on a return:

```go
mW := Whatever{}
...
...
return &mW
```

This is now easy to read, you can see that it will return an address. Where as this: 

```go
mW := &Whatever{}
...
// Long method
return mW
```

Here you have to remember that you returned an address after reading a 100-200 line long method which was doing stuff all over the place.

Use `&` when it's needed. And make sure a pointer exists because it need to be a pointer and not for the convenient way of checking for `nil` upon a db lookup. We should use the `ok` pattern for that.

Hi,

I read through the documentation for this feature but couldnt see any support for it, but i think it would be useful to have some kind of support for repositories configurations on start-up without using the UI.

When using the docker image it is a somewhat common use case to deploy and then tear down configurations resulting in having to redefine all the repositories containing pipelines manually, such as the url, language of pipeline etc. Having this in a config file and mounting it would be really helpful in this respect.


 