cqlsh> source 'load-timeseries.cql';
Using 7 child processes

Starting copy of isd_weather_data.weather_station with columns ['id', 'name', 'country_code', 'state_code', 'call_sign', 'lat', 'long', 'elevation'].
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
    prepare(preparation_data)
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
    file, path_name, etc = imp.find_module(main_name, dirs)
ImportError: No module named cqlsh
    prepare(preparation_data)
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
    file, path_name, etc = imp.find_module(main_name, dirs)
ImportError: No module named cqlsh
Traceback (most recent call last):
  File "<string>", line 1, in <module>
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
    prepare(preparation_data)
Traceback (most recent call last):
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
  File "<string>", line 1, in <module>
    prepare(preparation_data)
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
    file, path_name, etc = imp.find_module(main_name, dirs)
ImportError: No module named cqlsh
        prepare(preparation_data)
file, path_name, etc = imp.find_module(main_name, dirs)
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
ImportError: No module named cqlsh
Traceback (most recent call last):
  File "<string>", line 1, in <module>
    file, path_name, etc = imp.find_module(main_name, dirs)
ImportError: No module named cqlsh
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
    prepare(preparation_data)
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
    file, path_name, etc = imp.find_module(main_name, dirs)
ImportError: No module named cqlsh
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
    prepare(preparation_data)
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
    file, path_name, etc = imp.find_module(main_name, dirs)
ImportError: No module named cqlsh
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Python27\lib\multiprocessing\forking.py", line 380, in main
    prepare(preparation_data)
  File "C:\Python27\lib\multiprocessing\forking.py", line 503, in prepare
    file, path_name, etc = imp.find_module(main_name, dirs)
ImportError: No module named cqlsh
load-timeseries.cql:7:8 child process(es) died unexpectedly, aborting
Processed: 0 rows; Rate:       0 rows/s; Avg. rate:       0 rows/s
0 rows imported from 0 files in 0.173 seconds (0 skipped).
Fixes #46 by by uncommenting the method `preStart` in `ApiNodeGuardian`. With this change, the client application actually works.
The client application `com.datastax.killrweather.KillrWeatherClientApp` doesn't do anything at the moment. When started, it displays the following logs and then hangs:

```
sbt clients/run
[info] Loading project definition from /Users/i027947/Projects/lmlambda/killrweather/project
[warn] There may be incompatibilities among your library dependencies.
[warn] Here are some of the libraries that were evicted:
[warn] 	* com.typesafe.sbt:sbt-git:0.6.2 -> 0.6.4
[warn] Run 'evicted' to see detailed eviction warnings
[info] Set current project to KillrWeather (in build file:/Users/i027947/Projects/lmlambda/killrweather/)
[warn] Multiple main classes detected.  Run 'show discoveredMainClasses' to see the list

Multiple main classes detected, select one to run:

 [1] com.datastax.killrweather.KafkaDataIngestionApp
 [2] com.datastax.killrweather.KillrWeatherClientApp

Enter number: 2

[info] Running com.datastax.killrweather.KillrWeatherClientApp 
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/i027947/.ivy2/cache/ch.qos.logback/logback-classic/jars/logback-classic-1.0.13.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/i027947/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder]
[INFO] [2017-01-05 11:37:27,374] [akka.event.slf4j.Slf4jLogger]: Slf4jLogger started
[INFO] [2017-01-05 11:37:27,447] [Remoting]: Starting remoting
[INFO] [2017-01-05 11:37:27,654] [Remoting]: Remoting started; listening on addresses :[akka.tcp://KillrWeather@127.0.0.1:2552]
[INFO] [2017-01-05 11:37:27,668] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2552] - Starting up...
[INFO] [2017-01-05 11:37:27,754] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2552] - Registered cluster JMX MBean [akka:type=Cluster]
[INFO] [2017-01-05 11:37:27,754] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2552] - Started up successfully
[INFO] [2017-01-05 11:37:27,774] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2552] - No seed-nodes configured, manual cluster join required
[INFO] [2017-01-05 11:37:27,815] [com.datastax.killrweather.ApiNodeGuardian]: Starting at akka.tcp://KillrWeather@127.0.0.1:2552
[INFO] [2017-01-05 11:37:27,817] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2552] - Metrics collection has started successfully
[INFO] [2017-01-05 11:37:27,823] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2552] - Node [akka.tcp://KillrWeather@127.0.0.1:2552] is JOINING, roles [client]
[INFO] [2017-01-05 11:37:27,825] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2552] - Trying to join seed nodes [akka.tcp://KillrWeather@127.0.0.1:2552] when already part of a cluster, ignoring
[INFO] [2017-01-05 11:37:27,838] [com.datastax.killrweather.AutomatedApiActor]: Starting.
```

This can be fixed by uncommenting the method `preStart` in `ApiNodeGuardian`. I intend to do a PR for the fix.
Fixes #37 by changing some lines of code in `KafkaDataIngestionApp.scala` according to the documentation available in http://doc.akka.io/docs/akka-http/current/scala/http/low-level-server-side-api.html. In addition, reduces the number of `HttpDataFeedActor` actors from 10 to 1 to avoid errors due to port conflicts.

With this change, the following command actually works:

```
curl -v -X POST --header "X-DATA-FEED: ./data/load/sf-2008.csv.gz" http://localhost:8080/weather/data
```
Fixes #24 by updating Spark and Cassandra versions to the latest ones. On my laptop this works with the latest Cassandra version (3.9), but I still need to use `-Dcassandra.connection.host=127.0.0.1`. Perhaps the README should be updated as well.
I am ussing DSE Cassandra "[cqlsh 5.0.1 | Cassandra 3.0.8.1293 | DSE 5.0.2" but getting "com.datastax.driver.core.exceptions.NoHostAvailableException: " error when akka is trying to connect to cassandra database.  I have updated  the rpc_address and the broadcast_rpc_address parameters in the yaml file as below. Any thoughts on what could be wrong or how to determine the cause?

$ sbt app/run -Dcassandra.connection.host=127.0.0.1
[info] Loading project definition from /root/killrweather/project
[warn] There may be incompatibilities among your library dependencies.
[warn] Here are some of the libraries that were evicted:
[warn]  \* com.typesafe.sbt:sbt-git:0.6.2 -> 0.6.4
[warn] Run 'evicted' to see detailed eviction warnings
[info] Set current project to KillrWeather (in build file:/root/killrweather/)
[info] Running com.datastax.killrweather.KillrWeatherApp 
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/root/.ivy2/cache/ch.qos.logback/logback-classic/jars/logback-classic-1.0.13.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/root/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder]
[INFO] [2016-09-23 14:27:48,486] [akka.event.slf4j.Slf4jLogger]: Slf4jLogger started
[INFO] [2016-09-23 14:27:48,531] [Remoting]: Starting remoting
[INFO] [2016-09-23 14:27:48,801] [Remoting]: Remoting started; listening on addresses :[akka.tcp://KillrWeather@127.0.0.1:2550]
[INFO] [2016-09-23 14:27:48,810] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - Starting up...
[INFO] [2016-09-23 14:27:48,856] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - Registered cluster JMX MBean [akka:type=Cluster]
[INFO] [2016-09-23 14:27:48,856] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - Started up successfully
[INFO] [2016-09-23 14:27:48,864] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - No seed-nodes configured, manual cluster join required
[INFO] [2016-09-23 14:27:48,898] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - Metrics collection has started successfully
ZooKeeperServer isRunning: true
log4j:WARN No appenders could be found for logger (kafka.utils.VerifiableProperties).
log4j:WARN Please initialize the log4j system properly.
Starting the Kafka server at 198.159.220.11:2181
[INFO] [2016-09-23 14:27:54,293] [akka.event.slf4j.Slf4jLogger]: Slf4jLogger started
[INFO] [2016-09-23 14:27:54,296] [Remoting]: Starting remoting
[INFO] [2016-09-23 14:27:54,302] [Remoting]: Remoting started; listening on addresses :[akka.tcp://sparkDriver@thingspacelabsd11.networkfleet.com:43119]
[INFO] [2016-09-23 14:27:54,392] [org.spark-project.jetty.server.Server]: jetty-8.y.z-SNAPSHOT
[INFO] [2016-09-23 14:27:54,401] [org.spark-project.jetty.server.AbstractConnector]: Started SocketConnector@0.0.0.0:59834
[INFO] [2016-09-23 14:27:54,498] [org.spark-project.jetty.server.Server]: jetty-8.y.z-SNAPSHOT
[INFO] [2016-09-23 14:27:54,506] [org.spark-project.jetty.server.AbstractConnector]: Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2016-09-23 14:27:54,758] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - Node [akka.tcp://KillrWeather@127.0.0.1:2550] is JOINING, roles [analytics]
[INFO] [2016-09-23 14:27:54,764] [com.datastax.killrweather.NodeGuardian]: Starting at akka.tcp://KillrWeather@127.0.0.1:2550
[INFO] [2016-09-23 14:27:54,764] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - Trying to join seed nodes [akka.tcp://KillrWeather@127.0.0.1:2550] when already part of a cluster, ignoring
[INFO] [2016-09-23 14:27:54,873] [Cluster(akka://KillrWeather)]: Cluster Node [akka.tcp://KillrWeather@127.0.0.1:2550] - Leader is moving node [akka.tcp://KillrWeather@127.0.0.1:2550] to [Up]
[DEBUG] [2016-09-23 14:27:54,874] [com.datastax.killrweather.NodeGuardian]: Member [akka.tcp://KillrWeather@127.0.0.1:2550] joined cluster.
[ERROR] [2016-09-23 14:27:55,246] [akka.actor.OneForOneStrategy]: Failed to open native connection to Cassandra at {127.0.0.1}:9042
akka.actor.ActorInitializationException: exception during creation
        at akka.actor.ActorInitializationException$.apply(Actor.scala:166) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.actor.ActorCell.create(ActorCell.scala:596) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:456) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.actor.ActorCell.systemInvoke(ActorCell.scala:478) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:263) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.dispatch.Mailbox.run(Mailbox.scala:219) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [akka-actor_2.10-2.3.11.jar:na]
        at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library-2.10.5.jar:na]
        at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library-2.10.5.jar:na]
        at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library-2.10.5.jar:na]
        at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library-2.10.5.jar:na]
Caused by: java.io.IOException: Failed to open native connection to Cassandra at {127.0.0.1}:9042
        at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:181) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$2.apply(CassandraConnector.scala:167) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$2.apply(CassandraConnector.scala:167) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:31) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:56) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:76) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:104) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.CassandraConnector.withClusterDo(CassandraConnector.scala:115) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.cql.Schema$.fromCassandra(Schema.scala:243) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.writer.TableWriter$.apply(TableWriter.scala:182) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.spark.connector.streaming.DStreamFunctions.saveToCassandra(DStreamFunctions.scala:32) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        at com.datastax.killrweather.KafkaStreamingActor.<init>(KafkaStreamingActor.scala:45) ~[classes/:na]
        at com.datastax.killrweather.NodeGuardian$$anonfun$1.apply(NodeGuardian.scala:42) ~[classes/:na]
        at com.datastax.killrweather.NodeGuardian$$anonfun$1.apply(NodeGuardian.scala:42) ~[classes/:na]
        at akka.actor.TypedCreatorFunctionConsumer.produce(Props.scala:343) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.actor.Props.newActor(Props.scala:252) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.actor.ActorCell.newActor(ActorCell.scala:552) ~[akka-actor_2.10-2.3.11.jar:na]
        at akka.actor.ActorCell.create(ActorCell.scala:578) ~[akka-actor_2.10-2.3.11.jar:na]
        ... 9 common frames omitted
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.InvalidQueryException: unconfigured table schema_keyspaces))
        at com.datastax.driver.core.ControlConnection.reconnectInternal(ControlConnection.java:223) ~[cassandra-driver-core-2.1.5.jar:na]
        at com.datastax.driver.core.ControlConnection.connect(ControlConnection.java:78) ~[cassandra-driver-core-2.1.5.jar:na]
        at com.datastax.driver.core.Cluster$Manager.init(Cluster.java:1230) ~[cassandra-driver-core-2.1.5.jar:na]
        at com.datastax.driver.core.Cluster.getMetadata(Cluster.java:333) ~[cassandra-driver-core-2.1.5.jar:na]
        at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:174) ~[spark-cassandra-connector_2.10-1.3.0-M1.jar:1.3.0-M1]
        ... 26 common frames omitted
[DEBUG] [2016-09-23 14:27:59,420] [com.datastax.killrweather.NodeGuardian]: NodeMetrics[heap-memory-committed:1008205824,heap-memory-max:1008205824,system-load-average:0.55,heap-memory-used:226654768,cpu-combined:0.0]
[DEBUG] [2016-09-23 14:28:08,914] [com.datastax.killrweather.NodeGuardian]: NodeMetrics[heap-memory-committed:1008205824,cpu-combined:0.009101701622477245,heap-memory-max:1008205824,system-load-average:0.62,heap-memory-used:230459632]
[DEBUG] [2016-09-23 14:28:18,913] [com.datastax.killrweather.NodeGuardian]: NodeMetrics[heap-memory-committed:1008205824,heap-memory-max:1008205824,heap-memory-used:232953840,cpu-combined:0.0070140280561122245,system-load-average:0.53]
[DEBUG] [2016-09-23 14:28:28,913] [com.datastax.killrweather.NodeGuardian]: NodeMetrics[system-load-average:0.45,heap-memory-committed:1008205824,heap-memory-used:234236752,heap-memory-max:1008205824,cpu-combined:0.0055151667084482325]

$ vi  $CASS_HOME/resources/cassandra/conf/cassandra.yaml
rpc_address: 0.0.0.0
broadcast_rpc_address: 1.2.3.4

$ cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
....

I have followed all the instruction to run the app and the clients. I wanted to use the REST interface to ingest data. In the KafkaDataIngestionApp, I have commented out the following lines to stop the initial data ingestion.
/*
    /\* Handles initial data ingestion in Kafka for running as a demo. */
    for (fs <- initialData; data <- fs.data) {
      log.info("Sending {} to Kafka", data)
      router ! KafkaMessageEnvelope[String, String](KafkaTopic, KafkaKey, data)
    }
*/
When I used the following command to post the data, I am not able to connect. I have changed the host name to loop back address, changed the port number etc Still it is giving the same problem of connection refused. 

curl -v -X POST --header "X-DATA-FEED: ./data/load/sf-2008.csv.gz" http://localhost:8080/weather/data
- Adding handle: conn: 0x7f9f00803a00
- Adding handle: send: 0
- Adding handle: recv: 0
- Curl_addHandleToPipeline: length: 1
- \- Conn 0 (0x7f9f00803a00) send_pipe: 1, recv_pipe: 0
- About to connect() to localhost port 8080 (#0)
-   Trying ::1...
-   Trying 127.0.0.1...
-   Trying fe80::1...
- Failed connect to localhost:8080; Connection refused
- Closing connection 0
  curl: (7) Failed connect to localhost:8080; Connection refused

Can you please help? 

``` code
./dse spark
Spark assembly has been built with Hive, including Datanucleus jars on classpath
Exception in thread "main" java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
    at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
    at org.apache.hadoop.security.Groups.<init>(Groups.java:64)
    at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
    at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:255)
    at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:232)
    at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:718)
    at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:703)
    at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:605)
    at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:1996)
    at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:1996)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:1996)
    at org.apache.spark.SecurityManager.<init>(SecurityManager.scala:207)
    at org.apache.spark.repl.SparkIMain.<init>(SparkIMain.scala:118)
    at org.apache.spark.repl.SparkILoop$SparkILoopInterpreter.<init>(SparkILoop.scala:187)
    at org.apache.spark.repl.SparkILoop.createInterpreter(SparkILoop.scala:216)
    at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:948)
    at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:944)
    at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:944)
    at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
    at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:944)
    at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1058)
    at org.apache.spark.repl.Main$.main(Main.scala:31)
    at org.apache.spark.repl.Main.main(Main.scala)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
    at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
    at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.reflect.InvocationTargetException
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
    at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:129)
    ... 32 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.security.JniBasedUnixGroupsMapping.anchorNative()V
    at org.apache.hadoop.security.JniBasedUnixGroupsMapping.anchorNative(Native Method)
    at org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:49)
    at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:38)
    ... 37 more
```

**well ,it is weird to connect a spark cluster and cassandra.
I install cassandra in my computer.**

*_First,I run this code in IntelliJ IDEA : *_

`  val conf = new SparkConf(true)
    .set("spark.cassandra.connection.host", "127.0.0.1")

  val sc = new SparkContext("local[*]", "test", conf)
  val table: CassandraRDD[CassandraRow] = sc.cassandraTable("system_traces", "events")

  val rowCount = table.count()
  table.toLocalIterator foreach println

  println(s"Total Rows in Table: $rowCount")
  sc.stop()`

**Everything is OK.**

**then I connect the spark cluster and cassandra:**
`  val conf = new SparkConf(true)
    .set("spark.cassandra.connection.host", "192.168.211.128")

  val sc = new SparkContext("spark://192.168.210.47:7077", "test", conf)
  val table: CassandraRDD[CassandraRow] = sc.cassandraTable("system_traces", "events")

  val rowCount = table.count()
  table.toLocalIterator foreach println

  println(s"Total Rows in Table: $rowCount")
  sc.stop()`

**IDE returns:**
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/03/04 02:07:07 INFO SparkContext: Running Spark version 1.3.1
16/03/04 02:07:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/03/04 02:07:07 INFO SecurityManager: Changing view acls to: root
16/03/04 02:07:07 INFO SecurityManager: Changing modify acls to: root
16/03/04 02:07:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/04 02:07:08 INFO Slf4jLogger: Slf4jLogger started
16/03/04 02:07:08 INFO Remoting: Starting remoting
16/03/04 02:07:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@Master:37901]
16/03/04 02:07:08 INFO Utils: Successfully started service 'sparkDriver' on port 37901.
16/03/04 02:07:08 INFO SparkEnv: Registering MapOutputTracker
16/03/04 02:07:08 INFO SparkEnv: Registering BlockManagerMaster
16/03/04 02:07:08 INFO DiskBlockManager: Created local directory at /tmp/spark-1f1e100b-21a7-4485-99cf-19f89303419b/blockmgr-1556269c-ecae-486c-8366-ed10d1c61a8a
16/03/04 02:07:08 INFO MemoryStore: MemoryStore started with capacity 958.2 MB
16/03/04 02:07:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-837f5fcb-0047-4b87-b307-a58f379177cc/httpd-d44d74b1-2d37-4b5b-bd10-5ebe138ec972
16/03/04 02:07:08 INFO HttpServer: Starting HTTP Server
16/03/04 02:07:08 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/04 02:07:08 INFO AbstractConnector: Started SocketConnector@0.0.0.0:35873
16/03/04 02:07:08 INFO Utils: Successfully started service 'HTTP file server' on port 35873.
16/03/04 02:07:08 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/04 02:07:13 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/04 02:07:13 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/03/04 02:07:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/04 02:07:13 INFO SparkUI: Started SparkUI at http://Master:4040
16/03/04 02:07:13 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/04 02:07:33 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/04 02:07:53 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/04 02:08:13 ERROR SparkDeploySchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.
16/03/04 02:08:13 WARN SparkDeploySchedulerBackend: Application ID is not initialized yet.
16/03/04 02:08:13 ERROR TaskSchedulerImpl: Exiting due to error from cluster scheduler: All masters are unresponsive! Giving up.

**then I change cassandra address:**
`val conf = new SparkConf(true)
    .set("spark.cassandra.connection.host", "192.168.211.128")
  val sc = new SparkContext("local[*]", "test", conf)`

**IDE returns:**
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/03/04 02:11:53 INFO SparkContext: Running Spark version 1.3.1
16/03/04 02:11:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/03/04 02:11:53 INFO SecurityManager: Changing view acls to: root
16/03/04 02:11:53 INFO SecurityManager: Changing modify acls to: root
16/03/04 02:11:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/04 02:11:54 INFO Slf4jLogger: Slf4jLogger started
16/03/04 02:11:54 INFO Remoting: Starting remoting
16/03/04 02:11:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@Master:60079]
16/03/04 02:11:54 INFO Utils: Successfully started service 'sparkDriver' on port 60079.
16/03/04 02:11:54 INFO SparkEnv: Registering MapOutputTracker
16/03/04 02:11:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/04 02:11:54 INFO DiskBlockManager: Created local directory at /tmp/spark-2a5256d6-03a1-4f6f-92b4-a35eae7937a9/blockmgr-e116d3d6-7499-4e0e-b22f-e33c4d9b29dd
16/03/04 02:11:54 INFO MemoryStore: MemoryStore started with capacity 958.2 MB
16/03/04 02:11:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-411693ab-5fc3-4a6a-a186-24354b381129/httpd-32279b97-4e69-4491-b6f7-2926cb2edc4d
16/03/04 02:11:54 INFO HttpServer: Starting HTTP Server
16/03/04 02:11:54 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/04 02:11:54 INFO AbstractConnector: Started SocketConnector@0.0.0.0:55059
16/03/04 02:11:54 INFO Utils: Successfully started service 'HTTP file server' on port 55059.
16/03/04 02:11:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/04 02:11:59 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/04 02:11:59 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/03/04 02:11:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/04 02:11:59 INFO SparkUI: Started SparkUI at http://Master:4040
16/03/04 02:11:59 INFO Executor: Starting executor ID <driver> on host localhost
16/03/04 02:11:59 INFO AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@Master:60079/user/HeartbeatReceiver
16/03/04 02:11:59 INFO NettyBlockTransferService: Server created on 55233
16/03/04 02:11:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/04 02:11:59 INFO BlockManagerMasterActor: Registering block manager localhost:55233 with 958.2 MB RAM, BlockManagerId(<driver>, localhost, 55233)
16/03/04 02:11:59 INFO BlockManagerMaster: Registered BlockManager
Exception in thread "main" java.io.IOException: Failed to open native connection to Cassandra at {192.168.211.128}:9042
    at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:181)
    at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$2.apply(CassandraConnector.scala:167)
    at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$2.apply(CassandraConnector.scala:167)
    at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:31)
    at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:56)
    at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:76)
    at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:104)
    at com.datastax.spark.connector.cql.CassandraConnector.withClusterDo(CassandraConnector.scala:115)
    at com.datastax.spark.connector.cql.Schema$.fromCassandra(Schema.scala:243)
    at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:49)
    at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:59)
    at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:59)
    at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:148)
    at com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:59)
    at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:118)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:217)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1535)
    at org.apache.spark.rdd.RDD.reduce(RDD.scala:900)
    at com.datastax.spark.connector.rdd.CassandraTableScanRDD.count(CassandraTableScanRDD.scala:246)
    at cassandraTest$delayedInit$body.apply(cassandraTest.scala:16)
    at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
    at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
    at scala.App$$anonfun$main$1.apply(App.scala:71)
    at scala.App$$anonfun$main$1.apply(App.scala:71)
    at scala.collection.immutable.List.foreach(List.scala:318)
    at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
    at scala.App$class.main(App.scala:71)
    at cassandraTest$.main(cassandraTest.scala:9)
    at cassandraTest.main(cassandraTest.scala)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /192.168.211.128:9042 (com.datastax.driver.core.TransportException: [/192.168.211.128:9042] Cannot connect))
    at com.datastax.driver.core.ControlConnection.reconnectInternal(ControlConnection.java:223)
    at com.datastax.driver.core.ControlConnection.connect(ControlConnection.java:78)
    at com.datastax.driver.core.Cluster$Manager.init(Cluster.java:1230)
    at com.datastax.driver.core.Cluster.getMetadata(Cluster.java:333)
    at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:174)
    ... 36 more

**with local cassandra address and spark cluster:**
`  val conf = new SparkConf(true)
    .set("spark.cassandra.connection.host", "127.0.0.1")

  val sc = new SparkContext("spark://192.168.210.47:7077", "test", conf)`

**IDE returns:**
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/03/04 02:19:06 INFO SparkContext: Running Spark version 1.3.1
16/03/04 02:19:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/03/04 02:19:06 INFO SecurityManager: Changing view acls to: root
16/03/04 02:19:06 INFO SecurityManager: Changing modify acls to: root
16/03/04 02:19:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/04 02:19:07 INFO Slf4jLogger: Slf4jLogger started
16/03/04 02:19:07 INFO Remoting: Starting remoting
16/03/04 02:19:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@Master:42883]
16/03/04 02:19:07 INFO Utils: Successfully started service 'sparkDriver' on port 42883.
16/03/04 02:19:07 INFO SparkEnv: Registering MapOutputTracker
16/03/04 02:19:07 INFO SparkEnv: Registering BlockManagerMaster
16/03/04 02:19:07 INFO DiskBlockManager: Created local directory at /tmp/spark-4a2d101b-f7aa-4d7e-b295-8da39377fcd4/blockmgr-c8d8ae90-10a4-4015-87fa-b627bb46427c
16/03/04 02:19:07 INFO MemoryStore: MemoryStore started with capacity 958.2 MB
16/03/04 02:19:07 INFO HttpFileServer: HTTP File server directory is /tmp/spark-e01aabb3-1cdd-4b1a-8ef6-db376dc55143/httpd-d535d35f-96ac-48a4-ad31-de4180f57085
16/03/04 02:19:07 INFO HttpServer: Starting HTTP Server
16/03/04 02:19:07 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/04 02:19:07 INFO AbstractConnector: Started SocketConnector@0.0.0.0:56722
16/03/04 02:19:07 INFO Utils: Successfully started service 'HTTP file server' on port 56722.
16/03/04 02:19:07 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/04 02:19:12 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/04 02:19:12 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/03/04 02:19:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/04 02:19:12 INFO SparkUI: Started SparkUI at http://Master:4040
16/03/04 02:19:12 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/04 02:19:32 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/04 02:19:52 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/04 02:20:12 ERROR SparkDeploySchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.
16/03/04 02:20:12 WARN SparkDeploySchedulerBackend: Application ID is not initialized yet.
16/03/04 02:20:12 ERROR TaskSchedulerImpl: Exiting due to error from cluster scheduler: All masters are unresponsive! Giving up.

**Generally speaking,if I connect spark or cassandra which is not in my computer, IDE returns Error!!

Somebody please helps me!!**

I try to run [SimpleSparkJob].
It works well if I do not change anything.
I want to run the Demo to a Cluster,and change the code like this:
`val conf = new SparkConf(true).set("spark.cassandra.connection.host", "127.0.0.1")
      .setMaster("spark://192.168.210.47:7077").setAppName("spark.cassandra.connection")`
The IDE return this error:
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/03/03 15:29:46 INFO SparkContext: Running Spark version 1.3.1
16/03/03 15:29:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/03/03 15:29:47 INFO SecurityManager: Changing view acls to: root
16/03/03 15:29:47 INFO SecurityManager: Changing modify acls to: root
16/03/03 15:29:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/03 15:29:47 INFO Slf4jLogger: Slf4jLogger started
16/03/03 15:29:47 INFO Remoting: Starting remoting
16/03/03 15:29:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@Master:44565]
16/03/03 15:29:47 INFO Utils: Successfully started service 'sparkDriver' on port 44565.
16/03/03 15:29:47 INFO SparkEnv: Registering MapOutputTracker
16/03/03 15:29:47 INFO SparkEnv: Registering BlockManagerMaster
16/03/03 15:29:47 INFO DiskBlockManager: Created local directory at /tmp/spark-d7c6da22-eed7-469f-a120-f3aa0fb6d650/blockmgr-6bed18a9-6b12-4963-baae-ab99c60efadc
16/03/03 15:29:47 INFO MemoryStore: MemoryStore started with capacity 958.2 MB
16/03/03 15:29:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-81b29c62-e8a7-48a3-99f1-15789561cc16/httpd-b4767476-467f-41be-90d4-051a7a5d8171
16/03/03 15:29:47 INFO HttpServer: Starting HTTP Server
16/03/03 15:29:47 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/03 15:29:47 INFO AbstractConnector: Started SocketConnector@0.0.0.0:58063
16/03/03 15:29:47 INFO Utils: Successfully started service 'HTTP file server' on port 58063.
16/03/03 15:29:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/03 15:29:53 INFO Server: jetty-8.y.z-SNAPSHOT
16/03/03 15:29:53 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/03/03 15:29:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/03 15:29:53 INFO SparkUI: Started SparkUI at http://Master:4040
16/03/03 15:29:53 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/03 15:30:13 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/03 15:30:33 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.210.47:7077/user/Master...
16/03/03 15:30:53 ERROR SparkDeploySchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.
16/03/03 15:30:53 WARN SparkDeploySchedulerBackend: Application ID is not initialized yet.
## 16/03/03 15:30:53 ERROR TaskSchedulerImpl: Exiting due to error from cluster scheduler: All masters are unresponsive! Giving up.

It seems that something wrong with akka.tcp://sparkMaster@192.168.210.47:7077/user/Master,
so I run this code:
`object RemoteActorApp extends App {
  val system = ActorSystem("spike-spark-issue")
  val actor = system.actorSelection("akka.tcp://sparkMaster@192.168.210.47:7077/user/Master")
  if (actor == null) println("null actor") else println("correct")
}`
that returns **correct**.
I got the log in the folder of spark:
## INFO Master: 192.168.23.101:36188 got disassociated, removing it.

well ,192.168.23.101 is my computer's IP and thiere is a cluster too.
Any good advice? 
Many thx.
