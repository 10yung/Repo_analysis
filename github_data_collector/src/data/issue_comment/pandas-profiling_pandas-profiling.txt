Introducing static type checking to this repository (#302). It finds some errors, it makes some errors.
 'The internally computed table of expected frequencies has a zero element at (0, 5).')
  correlation_name=correlation_name, error=error
**Describe the bug**

The user encounters several issues when running `pandas-profiling` in JupyterLab:

- The jupyter widgets are not enabled by default, nor does the package provide a warning. The user has to manually run `jupyter labextension install @jupyter-widgets/jupyterlab-manager`
- Non-widget components (e.g. the overview table) are not formatted properly.

![interface](https://user-images.githubusercontent.com/9756388/72286729-005e1d80-3646-11ea-9085-039f3dcc0158.PNG)
 
<!--
A clear and concise description of what the bug is.
If the description consists of multiple non-related bugs, you are encouraged to create separate issues.
-->

**To Reproduce**

The problems above can be reproduced by running the code below in JupterLab:

```
# As featured on the Google Cloud Platform website:
# https://cloud.google.com/solutions/building-a-propensity-model-for-financial-services-on-gcp

import pandas as pd

from pandas_profiling import ProfileReport

df = pd.read_csv('https://storage.googleapis.com/erwinh-public-data/bankingdata/bank-full.csv', sep=';')

profile = ProfileReport(df, title="GCP Banking Data")
profile
```

**Missing functionality**

More details on which rows are potentially duplicate. As I failed to find them in the report or using pandas or manual query, especially when the dataset is 70K lines or large datasets.

![Screen Shot 2020-01-13 at 11 59 55](https://user-images.githubusercontent.com/1570917/72254731-d2a0b680-35fc-11ea-95ac-f37e8988f7f5.png)


**Proposed feature**

Just like Missing values and correlations tabs at the bottom of the report - we could have one for Duplicated rows or information as well.

Also, a bit of an outline, what is deemed as duplicate - in my case 395 out of 70K were duplicate it's a marginal figure but it's also good to know which ones are they and what are they - they might make a (small) dent on the end-results.

**Alternatives considered**

Maybe manually query or use pandas to filter duplicate rows.

**Additional context**

Unfortunately, I can't share the dataset but if I can reproduce this via another instance that is shareable I will do so. Although I think it's not a bug as such.
**Missing functionality**

On the back of the issue raised - https://github.com/pandas-profiling/pandas-profiling/issues/315 - I would like to request for improved documentation about removed features and alternative ways to overcome them when using the new version of `pandas-profiling`, starting `v2.4.0`.

**Proposed feature**

- docs on why `style={'full_width': True}, minify_html=True` cannot be used anymore and what to do instead
- changes made to how rejected variables info can be retrieved once the profiling task is finished
- some more details on what  kind of correlation(s) are used and this can be selected via a parameter (I did see some work go in wrt to this, see https://github.com/pandas-profiling/pandas-profiling/issues/298)

Also described in https://github.com/pandas-profiling/pandas-profiling/issues/315

**Alternatives considered**

A solution or two provided in https://github.com/pandas-profiling/pandas-profiling/issues/315

**Question**

If I ran pandas-profiling on a raw dataset and then on a pre-processed version of the same dataset would I notice a change or improvement in the results? 

The pre-processed version would have columns scaled (normalised and scaled). Does scaling or encoding the columns help with accuracy or performance?

Note: I don't mean removing outliers or bad data or those kinds of pre-processing.

**Version information:**

Current or previous versions of pandas-profiling

PS: can we also have a Question type for raising issues (as this is not a bug report)
**Missing functionality**
Testing does not verify the types, but type hints are often provided. Static type checking can help us catch errors. 

**Proposed feature**
Static type checking should be integrated into the testing suite. Problems detected by the type checker should be resolved.

Add to `.travis-ci.yml`:
```
if [ $TEST == 'types' ]; then pytest --mypy -m mypy pandas_profiling/; fi
```

Add to `requirements-test.txt`:
```
pytest-mypy
mypy
```

**Alternatives considered**
There are more static type checkers available for Python. For example Microsoft's Pyright. Arguments for a specific alternative type checker are welcome.


Abnormal values analysis: "Division by zero" is fixed
The error "Division by zero" is fixed.
For the variant of matches of values P90% and P95% the check for increase (in percentage) of a maximum from P95%.
For the variant of matches of values P5% and P10% the check for increase (in percentage) of P5% from a minimum.
Added flag "check_abnormal_values" to initiate abnormal values analysis (can be "False" by default).

**Is your feature request related to a problem? Please describe.**
When you're profiling data and have a report later down the line you might have to re-profile that same data to see how the data has progressed. This includes going through both reports and manually comparing the difference in them.

**Describe the solution you'd like**
A nice solution to this would be a system to compare two reports to highlight and outline the differences between the report in terms of how this data is being transformed.


