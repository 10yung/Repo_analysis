Could you create a new release of your library with java 8 compatibility?
Thx a lot! 

Baptiste


Do you plan to release a version for Scala `2.12.x` ?
for dice/sorensen metric, your example of "night", "natch" you are showing a value of .60, however according to the algorith the expected answer for the same two strings is .25

could you please elaborate on how you got .60?

links for reference:
https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient

http://www.gutenberg.us/articles/eng/S%C3%B8rensen_similarity_index

http://wooorm.com/dice-coefficient/
The current implementation is too slow: it is a recursive algorithm without memoization, which means a lot of states are repeatedly computed.
Try this dynamic programming version that guarantees O(mn) performance:
```scala
  def dist(x: String, y: String): Int = {
    val d = Array.ofDim[Int](x.length + 1, y.length + 1)
    for (i <- 0 to x.length) d(i)(0) = i
    for (j <- 0 to y.length) d(0)(j) = j
    for (j <- 1 to y.length; i <- 1 to x.length) {
      if (x(i - 1) == y(j - 1)) d(i)(j) = d(i - 1)(j - 1)
      else d(i)(j) = min(d(i - 1)(j), d(i)(j - 1), d(i - 1)(j - 1)) + 1
    }
    d(x.length)(y.length)
  }
```
No real changes - just sbt update and change spec2 dependency - no longer supports org.specs2.mutable.SpecificationWithJUnit  - changed to org.specs2.mutable.Specification
Changed version to 0.27.5 - not sure what the versioning policy is?
The [Scaladoc link](https://rockymadden.com/stringmetric/scaladoc/) in the README is returning a 404.

Fixes #24. Apart from including the missing characters (`z`, `Z`, and `9`) in their respective classes and filters, this change should yield equal results as the upstream version.

I didn't want to change the functionality drastically not to break existing code, but this trait is actually reinventing the character classes already available on Scala's `Char` class. These include `isLower`, `isUpper`, `toLower`, `isLetter,`isDigit`, etc.

I would suggest deprecating this trait and use the following existing alternatives (compatible with the `StringTransform` type):
- `_.filter(_.isLetter)` instead of `filterAlpha`
- `_.filterNot(_.isLetter)` instead of `filterNotAlpha`
- `_.filter(_.isDigit)` instead of `filterNumeric`
- `_.filterNot(_.isDigit)` instead of `filterNotNumeric`
- `_.filter(_.isLetterOrDigit)` instead of `filterAlphaNumeric`
- `_.filterNot(_.isLetterOrDigit)` instead of `filterNotAlphaNumeric`
- `_.filter(_.isLower)` instead of `filterLowerCase`
- `_.filterNot(_.isLower)` instead of `filterNotLowerCase`
- `_.filter(_.isUpper)` instead of `filterUpperCase`
- `_.filterNot(_.isUpper)` instead of `filterNotUpperCase`
- `_.map(_.toLower)` instead of `ignoreAlphaCase`

They are not equivalent, but they are part of the standard library, and I would argue that they are much more accurate than the existing filters.

The character ranges in `com.rockymadden.stringmetric.transform`

``` scala
    private val Ascii = NumericRange(0x00, 0x7F, 1)
    private val ExtendedAscii = NumericRange(0x00, 0x7F, 1)
    private val Latin = NumericRange(0x00, 0x24F, 1)
    private val LowerCase = NumericRange(0x61, 0x7A, 1)
    private val Numbers = NumericRange(0x30, 0x39, 1)
    private val UpperCase = NumericRange(0x41, 0x5A, 1)
```

do not include all the intended characters, because the `apply` method of Scala's `NumericRange` is _exclusive_, i.e. it _does not_ include the upper bound of the defined range. Consequently, `LowerCase` does not include `z`, `UpperCase` does not include `Z`, `Numbers` does not include `9`, etc.
Thus, when using `withTransform` with any of the predefined filters in this object, these characters will be discarded from comparison.
