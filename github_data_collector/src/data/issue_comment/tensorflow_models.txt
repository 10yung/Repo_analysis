This pr fixs bug of class DenseEinsum.
Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: /research/global_objectives
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: TF2.x
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: tf_upgrade_v2 fails

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"`

### Describe the problem
I would like to request that the excellent loss functions in loss_layers get upgraded to use TF2.x, perhaps even with appropriate Keras wrappers and promotion to mainline TF. I recently discovered the research work here and tried using it in my TF2.x project but was not sure how to upgrade the usage of the model_variables (although I did get roc_auc_loss up and running). In general, if these loss functions are stable I believe they would represent important advances to the machine learning community if they were added into the main repository - it still seems to be a relatively common belief that one cannot optimize towards precision/recall-related objectives, and this would help dispel that notion.

Thank you to @mackeya-google and the original authors for putting this out there!

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Relevant section of upgrade log:
281:17: ERROR: Using member tf.contrib.framework.model_variable in deprecated module tf.contrib. tf.contrib.framework.model_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: Struct2Depth
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes in pytorch
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Not needed
- **TensorFlow version (use command below)**: Not needed
- **Bazel version (if compiling from source)**: Not needed
- **CUDA/cuDNN version**: 10
- **GPU model and memory**: GeForce 11GB
- **Exact command to reproduce**: None

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"`

### Describe the problem
Hi @aneliaangelova !

Could you please let me know what should be the ideal value of global scale var, when its trained?

I am trying to implement "object constraint loss" in pytorch but facing difficulties. The scale var I defined slowly decreases to zero. I posted a similar question on stackoverflow : https://stackoverflow.com/questions/59800247/pytorch-equivalent-of-tf-variable

Thankyou!


```python
s10 = tf.train.Saver(slim.get_model_variables(scope = 'nasnet'))
```
what's the scope? because 'nasnet' is not right.
Thanks!
------------------------

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 18.04 LTS)**
- **TensorFlow version (use command below)**: 1.15
- **CUDA/cuDNN version**: 10.0
- **GPU model and memory**: Nvidia tegra x2

sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v43 tensorflow-gpu==1.15

### Describe the problem

I have installed the Tensorflow API Object Detection from the r1.13.0 branch in my Jetson TX2 and I executed the object_detection_tutorial.pynb from r1.13.0 branch with the pretrained SSD mobinet v2/v1. In both cases the model take 8s-12s in make an inference with the example images provided, is taking too much time.

also, I cant see my GPU device with:

`tf.test.is_gpu_available()
tf.test.gpu_device_name()`

Any idea of what am i doing wrong? maybe


Has anybody script or knew command to generate Deeplab documentation from code comments?
[deeplab] [Deeplab]
### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubunto 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: CUDA 9
- **GPU model and memory**: Titan RTX 23 GB
- **Exact command to reproduce**: not relevant

### Describe the problem
I see one can configure a masks predictions head in an SSD model as can be seen [here](https://github.com/tensorflow/models/blame/master/research/object_detection/protos/ssd.proto#L103). But I don't find in the code how it is being used, and whether and how it contributes to the loss function.
I know the API supports Mask RCNN, but I need to use the single-stage variant instead.
Please share any insights regarding how the API produces the mask predictions and where is the code which wires it to the total loss.
If it is not - is it expected?

Thanks in advance.



Changed tf.gfile.GFile in line 138 to tf.io.gfile.GFile
Machine : Win10 64-bit
python : Anaconda3 , python 3.6
tensorflow : 1.14
model configuration : ssd_mobilenet_v1_coco.config
pre-trained model used : ssd_mobilenet_v1

in model/research
`python object_detection/legacy/train.py --logtostderr --train_dir=object_detection/training/ --pipeline_config_path=object_detection/ssd_mobilenet_v1_coco.config`

error : `google.protobuf.text_format.ParseError: 87:6 : Message type "object_detection.protos.Hyperparams" has no field named "s".` 


Any help please!!