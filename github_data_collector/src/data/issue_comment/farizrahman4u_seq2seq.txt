afte i use sudo pip install git+https://github.com/farizrahman4u/seq2seq.git,I write import seq2seq in python command line , but i meet this bug:

Using TensorFlow backend.
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 668, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 638, in _load_backward_compatible
  File "/Users/shawn/anaconda3/lib/python3.7/site-packages/seq2seq-1.0.0-py3.7.egg/seq2seq/__init__.py", line 1, in <module>
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 668, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 638, in _load_backward_compatible
  File "/Users/shawn/anaconda3/lib/python3.7/site-packages/seq2seq-1.0.0-py3.7.egg/seq2seq/cells.py", line 1, in <module>
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 668, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 638, in _load_backward_compatible
  File "/Users/shawn/anaconda3/lib/python3.7/site-packages/recurrentshop-1.0.0-py3.7.egg/recurrentshop/__init__.py", line 1, in <module>
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 668, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 638, in _load_backward_compatible
  File "/Users/shawn/anaconda3/lib/python3.7/site-packages/recurrentshop-1.0.0-py3.7.egg/recurrentshop/engine.py", line 10, in <module>
NameError: name 'K' is not defined

How can i solve this? thank u 

Actually, I plan to do a machine translation project with this seq2seq module. Before that, I just did a simple test and got a very bad result. I don't know where goes wrong. Pls help me...
Here's the process:

**#1. traning set**
```
def generate_sequence(length, n_unique):
    return [randint(1, n_unique-1) for _ in range(length)]
x = np.array(generate_sequence(100000,100)).reshape(10000,10)
y = np.array(generate_sequence(50000,100)).reshape(10000,5)
x_encoder_input_data = to_categorical(x)
y_decoder_target_data = to_categorical(y)

#x_encoder_input_data.shape = (10000, 10, 100)
#10000 training data, x_input_length=10,x_input_dim=100
#y_decoder_target_data.shape = (10000, 5, 100)

```
**#2. building&training model**
```
model = SimpleSeq2Seq(input_dim=100,
             input_length=10, 
            output_dim=100, 
            hidden_dim=128,
            output_length=5)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])
model.fit(x_encoder_input_data,  y_decoder_target_data, batch_size=128, epochs=500)
```
**#3. the partial losses** 

```
Epoch 1/500
10000/10000  - 44s 4ms/step - loss: 7.2350 - acc: 0.0108
Epoch 2/500
10000/10000  - 20s 2ms/step - loss: 6.9500 - acc: 0.0104
Epoch 3/500
10000/10000  - 22s 2ms/step - loss: 10.7297 - acc: 0.0103
Epoch 4/500
10000/10000  - 20s 2ms/step - loss: 8.6834 - acc: 0.0096
Epoch 5/500
10000/10000  - 21s 2ms/step - loss: 8.4943 - acc: 0.0099
Epoch 6/500
10000/10000  - 19s 2ms/step - loss: 8.4487 - acc: 0.0100
Epoch 7/500
10000/10000  - 19s 2ms/step - loss: 8.6318 - acc: 0.0099
Epoch 8/500
10000/10000  - 18s 2ms/step - loss: 8.5765 - acc: 0.0099
Epoch 9/500
10000/10000  - 20s 2ms/step - loss: 8.4753 - acc: 0.0099
Epoch 10/500
10000/10000  - 20s 2ms/step - loss: 8.3738 - acc: 0.0099
Epoch 11/500
10000/10000  - 20s 2ms/step - loss: 8.3999 - acc: 0.0098
Epoch 12/500
10000/10000  - 19s 2ms/step - loss: 8.3108 - acc: 0.0099
Epoch 13/500
10000/10000  - 19s 2ms/step - loss: 8.3457 - acc: 0.0099
Epoch 14/500
10000/10000  - 19s 2ms/step - loss: 8.4852 - acc: 0.0098
Epoch 15/500
10000/10000  - 18s 2ms/step - loss: 8.4749 - acc: 0.0099
Epoch 16/500
10000/10000  - 18s 2ms/step - loss: 8.5881 - acc: 0.0098
Epoch 17/500
10000/10000  - 19s 2ms/step - loss: 8.3868 - acc: 0.0099
Epoch 18/500
10000/10000   - 21s 2ms/step - loss: 8.2499 - acc: 0.0098
Epoch 19/500
10000/10000   - 20s 2ms/step - loss: 8.4659 - acc: 0.0099
Epoch 20/500
10000/10000  - 20s 2ms/step - loss: 7.8421 - acc: 0.0099
Epoch 21/500
10000/10000   - 21s 2ms/step - loss: 7.6197 - acc: 0.0099
Epoch 22/500
10000/10000  - 20s 2ms/step - loss: 7.6193 - acc: 0.0099
Epoch 23/500
10000/10000   - 19s 2ms/step - loss: 7.6193 - acc: 0.0099
Epoch 24/500
10000/10000   - 21s 2ms/step - loss: 7.6193 - acc: 0.0099
Epoch 25/500
10000/10000   - 19s 2ms/step - loss: 7.6193 - acc: 0.0099
Epoch 26/500
10000/10000  - 22s 2ms/step - loss: 7.6193 - acc: 0.0099
Epoch 27/500
10000/10000  - 22s 2ms/step - loss: 7.6193 - acc: 0.0099
··· ···
```
**#4. predicting**
```
for seq_index in range(6):
    predictions = model.predict(x_encoder_input_data[seq_index:seq_index+1])
    predicted_list=[]

    for prediction_vector in predictions:
        for pred in prediction_vector:
            next_token = np.argmax(pred)
            predicted_list.append(next_token)
            
    print('-')
    print('Input sentence:', X[seq_index])
    print('Decoded sentence:', predicted_list)
    print('Target sentence:', y[seq_index])
```
**#5. the predicting results:**
```
-
Input sentence: [28, 2, 46, 12, 21, 6]      #  x
Decoded sentence: [78, 78, 78, 78, 66] # y_predict
Target sentence: [82 22 82 41 27]          # y
-
Input sentence: [12, 20, 45, 28, 18, 42]
Decoded sentence: [78, 78, 66, 66, 66]
Target sentence: [43 36 30 13 64]
-
Input sentence: [3, 43, 45, 4, 33, 27]
Decoded sentence: [78, 78, 66, 66, 66]
Target sentence: [90 20 56 23 32]
-
Input sentence: [34, 50, 21, 20, 11, 6]
Decoded sentence: [78, 78, 78, 78, 66]
Target sentence: [27 57 50 57 81]
-
Input sentence: [47, 42, 14, 2, 31, 6]
Decoded sentence: [78, 78, 78, 78, 66]
Target sentence: [77 94 47 26 67]
-
Input sentence: [20, 24, 34, 31, 37, 25]
Decoded sentence: [78, 78, 66, 66, 66]
Target sentence: [11 48 99 67 66]
```


Hi 

I have a simple categorical sequence data set like 
Target has 3 classes

X1 | X2 | X3 | X4 | X5 | X6 | X7 | X8 | X9 | X10 | X11 | X12 | Target
-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --
0 | 1 | 1 | 2 | 2 | 2 | 3 | 3 | 3 | 3 | 3 | 3 | 1

Will be able to use seq2seq for these king of problems?
can you sample syntax

Thank you. 
Hey

Is there any way to get the attention weights? That would be super nice :)
Typo "imporve" -> "improve"
> `    model = Sequential()
    model.add(Embedding(39, 39, input_length=24, mask_zero=True))
    model.add(Seq2Seq(input_length=24, input_dim=39, hidden_dim=10, output_length=22, output_dim=39))`
raise the Exception
how to predict AttentionSeq2Seq model for my input value such as x = np.random.random((samples, input_length, input_dim))?
ths your seq2seq framework ， help me get a lot prize and work
I've got "error: no commands supplied" when I try to run setup file, any idea?
Hi, as you may have seen that keras has CuDNNLSTM and CuDNNGRU layers optimized for GPUs. 

Is there any possibility that we can add that to this?

I tried but There's no CuDNNLSTMCell available, so I wasn't able to get it running. But any help would be appreciated.