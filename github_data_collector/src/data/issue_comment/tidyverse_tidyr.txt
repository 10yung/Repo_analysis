It is unclear how to use `pivot_longer_spec()` or `build_longer_spec()`.  The documentation does not have examples, and the vignette (https://cran.r-project.org/web/packages/tidyr/vignettes/pivot.html) doesn't actually use the result to generate a longer table.  It looks like older versions could be used as input to `pivot_longer()` with a `spec` argument, but that appears to have been removed.

Can an example please be added to the documentation for `pivot_longer_spec()` and also for `pivot_wider_spec()`?

Generally related to #829 as a documentation issue for this function.
Hi,

I have some code which uses a fair bit of meta programming (so a table of audit measures basically - where we have lists of the audit measure function being applied). I spotted a neat-looking optimisation to use tidyr to unnest the list.

Unfortunately, when using unnest where the list elements are functions, we get errors within the function (and presumably unpredictable behaviour). Ironically it's presumably because internally tidyr is doing exactly what my code is trying to do with the results of the function!

To demonstrate this, I used the tidyr example and converted the 'films' list-column to have functions rather than film titles (imagine we're going to pluck those functions and insert them into a later dplyr query on a table).

<details>

---

Brief description of the problem

```r
df <- tibble(
   character = c("Toothless", "Dory"),
   metadata = list(
     list(
       species = "dragon",
       color = "black",
       films = c(
         rlang::expr(.data[["title"]] == "How to Train Your Dragon"),
         rlang::expr(.data[["title"]] == "How to Train Your Dragon 2"),
         rlang::expr(.data[["title"]] == "How to Train Your Dragon: The Hidden World")
        )
     ),
     list(
       species = "clownfish",
       color = "blue",
       films = c(rlang::expr(.data[["title"]] == "Finding Nemo"),
         rlang::expr(.data[["title"]] == "Finding Dory"))
     )
   )
 )

tidyr::unnest_wider(df, metadata)

tidyr::unnest_longer(df, films)
```

The last command to unnest films results in:

Error in eval_tidy(enquo(var), var_env) : object 'films' not found

</details>
Broken since https://github.com/r-lib/vctrs/issues/660. Also added fixes so that tidyr now tests correctly with dev tibble.

CC @DavisVaughan (I can't request a review).
The DBI interface generates data frames that have integer64 columns, for example when counting the number of records.

pivot_wider generates incorrect & repeated output when the values_from is a integer64 column. The resulting data frame has the following value repeated many times:  `9218868437227407266`.

A less than satisfying fix is:

  `mutate(n = as.numeric(n))`

or 

  `bigint = "integer"` in 

```
con <- dbConnect(
  # prefer `connection_open` when running interactively...
  RPostgres::Postgres(),
  # without the following (and preceding) lines, 
  # bigint become int64 which is a problem for ggplot
  bigint = "integer",  
  host = "localhost",
  port = 5432 ...
```
I imagine the (great!) new functions `pivot_wider()` and `pivot_longer()` have had a lot of thought, which is awesome. However, for the arguments order of `pivot_wider()`, I think some extra user-friendliness would improve convenience a lot.

For `pivot_wider()`, I would suggest to move the argument `id_cols` to a 5th place, after `data`, `names_from`, `values_from` and `values_fill`:
```r
# current
pivot_wider(data, id_cols = NULL, names_from = name,
  names_prefix = "", names_sep = "_", names_repair = "check_unique",
  values_from = value, values_fill = NULL, values_fn = NULL)

# suggested
pivot_wider(data, names_from = name, values_from = value, 
  values_fill = NULL, id_cols = NULL, names_prefix = "",
  names_sep = "_", names_repair = "check_unique", values_fn = NULL)
```

I have two arguments for this:

1. Since you softly force users to migrate from `spread()` as this function [is now retired](https://tidyr.tidyverse.org/reference/spread.html) which [will lead to future removal](https://www.tidyverse.org/lifecycle/), I guess most users expect the use of `pivot_wider()` to be somewhat as fast and easy as `spread()`. But `pivot_wider()` often requires manual and cumbersome definition of arguments, which in my experience is needed in almost all use cases. This means it is quite far from a drop-in replacement of `spread()`. With the suggested order, this would be solved immediately:
    ```r
    # old
    storms %>%
      count(year, status) %>%
      spread(status, n, 0)

    # current
    storms %>%
      count(year, status) %>%
      pivot_wider(names_from = status, values_from = n, values_fill = list(n = 0))

    # suggested
    storms %>%
      count(year, status) %>%
      pivot_wider(status, n, list(n = 0))
    ```

    For `values_fill`, I would additionally suggest to make it work more intelligently by picking `values_from` as a new list name at default so e.g. `pivot_wider(status, n, 0)` works, but that's another discussion.

2. You [added 4 use cases](https://tidyr.tidyverse.org/reference/pivot_wider.html#examples) to the documentation, that (as users can reasonably expect) shows best practises. Not a single one of them works with `id_cols`, which is now the second argument. Instead, all examples at least contain the manually set (and consequently typed!) `names_from` and `values_from`:
    ```r
    # (pasted from: https://tidyr.tidyverse.org/reference/pivot_wider.html#examples)

    fish_encounters %>%
      pivot_wider(names_from = station, values_from = seen)
    # Fill in missing values
    fish_encounters %>%
      pivot_wider(
        names_from = station,
        values_from = seen,
        values_fill = list(seen = 0)
      )

    # Generate column names from multiple variables
    us_rent_income %>%
      pivot_wider(names_from = variable, values_from = c(estimate, moe))

    # Can perform aggregation with values_fn
    warpbreaks <- as_tibble(warpbreaks[c("wool", "tension", "breaks")])
    warpbreaks
    warpbreaks %>%
      pivot_wider(
        names_from = wool,
        values_from = breaks,
        values_fn = list(breaks = mean)
      )
    ```

    At best, this makes users even wonder how `id_cols` works. But in my honest opinion, it strongly suggests that a reordering of arguments would improve convenience, decrease typing, fasten analysis and, most importantly, help users adapt to `pivot_wider()` in a most user-friendly way.

`replace`	    If `data` is a data frame, a named list giving the value to replace NA with for each column. If data is a vector, a single value used for replacement.

I believe that if the users puts a single value to replace NAs and inputs a data frame, the same replacement value should be applied across all columns. If however the user wants a more elaborate replacement pattern, a named list can be provided. I think the case where you replace NAs across the board is quite common. 

When asking pivot_longer to parse doubles out of column names, round-number values fail with a "lossy cast" error:

```r
ok <- tribble(~X1.1cm, ~X1.2cm, 1, 2)
fail <- tribble(~X1.0cm, ~X1.5cm, 1, 2)

pivot_longer(
    data = ok,
    cols = starts_with("X"),
    names_pattern = "X([\\d.]+)cm",
    names_ptypes = list(name = double()))
# # A tibble: 2 x 2
#    name value
#   <dbl> <dbl>
# 1   1.1     1
# 2   1.2     2

pivot_longer(
    data = fail,
    cols = starts_with("X"),
    names_pattern = "X([\\d.]+)cm",
    names_ptypes = list(name = double()))
# Error: Lossy cast from `x` <character> to `to` <double>.
# Locations: 1
# Run `rlang::last_error()` to see where the error occurred.

# workaround: pivot as character, then coerce
pivot_longer(
    data = fail,
    cols = starts_with("X"),
    names_pattern = "X([\\d.]+)cm") %>%
mutate(name = parse_number(name))
# # A tibble: 2 x 2
#    name value
#   <dbl> <dbl>
# 1   1       1
# 2   1.5     2
```

Looks like the complaint originates from a `!=` comparison inside `vctrs:::vec_cast.double.character`. I realize the cast technically *is* lossy (in the sense that `c("1.0", "1.1") != c(1.0, 1.1)` evaluates to `c(TRUE, FALSE)`), which is why I'm opening the issue here instead of in vctrs -- whether or not this is the intended behavior from `vec_cast.double.character`, I'd hope that `pivot_longer` would account for float precision when I give it an explicit float prototype.
fixes #840 
To get the names of the list column elements one needs an extra step with `mutate()`. To avoid this one could add the argument `indices_to` like in `unnest_longer()`.

``` r
df <- tibble(
  x = 1:2,
  y = list(first = c(1, b = 2), second = c(a = 10, b = 11, c = 12))
)

hoist(
  df, y,
  b = "b",
  indices_to = "names"
)

#> # A tibble: 2 x 4
#>       x names      b y           
#>   <int> <chr>  <dbl> <named list>
#> 1     1 first      2 <dbl [1]>   
#> 2     2 second    11 <dbl [2]>  
```
In case I'm not just missing an obvious pre-existing solution, it would be nice to be able to specify how resulting columns from `pivot_wider` will be ordered. Using the `us_rent_income` example,
```
us_rent_income %>%
  pivot_wider(names_from = variable, values_from = c(estimate, moe))
```
produces the columns, `estimate_income`, `estimate_rent`, `moe_income`, and `moe_rent`. In my use-case (getting to a double-header table), I want them to be in the order, `estimate_income`, `moe_income`, `estimate_rent`, and `moe_rent`.