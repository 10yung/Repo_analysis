### json4s version
3.6.7
### scala version
2.12
### jdk version
1.8

Hi I have a question about default values in case classes. I'm having trouble setting a default value for a `Map` value when the input contains an explicit `null`-value. Here's a test to demonstrate:
```
import org.json4s.Formats
import org.json4s.NoTypeHints
import org.json4s.native.Serialization
import org.scalatest.FlatSpec

case class IntClass(v: Int = 0)
case class MapClass(v: Map[String, String] = Map.empty)

class Json4sTest extends FlatSpec{
  implicit val formats: Formats = Serialization.formats(NoTypeHints)

  // This passes
  "IntClass" should "deserialize with default when value is missing" in {
    assert(Serialization.read[IntClass]("""{}""").v === 0)
  }

  // This passes
  it should "deserialize with default when value is null" in {
    assert(Serialization.read[IntClass]("""{"v": null}""").v === 0)
  }

  // This passes
  "MapClass" should "deserialize with default when value is missing" in {
    assert(Serialization.read[MapClass]("""{}""").v === Map.empty)
  }

  // This Fails!
  it should "deserialize with default when value is null" in {
    assert(Serialization.read[MapClass]("""{"v": null}""").v === Map.empty)
  }
}
```

Is there any way I can use a default value for the `Map` in this case?

### json4s 3.6.7

### scala version 2.12.10

### jdk version 1.8.0_92

In 3.5.x I could do:

`val extractedOptionalField = (myJsonObject \ "myOptionalField").extractOpt[String]`

Which worked, and produced `None` when "myOptionalField" is not present in the object.
For some reason this does not work in 3.6.x when the field is missing  (throws `org.json4s.package$MappingException`: Did not find value which can be converted into java.lang.String). As a workaround I found that i can use `extract[Option[String]]` and it works as expected. But I do not understand what is the point of `extractOpt` if it throws an exception in case the field is missing? What is the reason the behavior changed? For me it seems broken.



### json4s version
```
    "org.json4s" %% "json4s-native" % "3.7.0-M1",
//    "org.json4s" %% "json4s-native" % "3.6.3",
//    "org.json4s" %% "json4s-ext" % "3.6.3",
    "org.json4s" %% "json4s-ext" % "3.7.0-M1",
```

### scala version
`scalaVersion := "2.12.8"
`
### jdk version
```
java version "1.8.0_191"
Java(TM) SE Runtime Environment (build 1.8.0_191-b12)

```
Hi. I have a case class generated from an Avro schema.  When I pass a JSON string to be parsed that is missing a field in the case class, the parser returns an object with default values for ALL fields. The expected result is an object with values for fields where they exist in the JSON and defaults where they do not. 

Below is a trivial example to demonstrate:

**Given an Avro generated case class with fields "first" and "last"...**
```
import scala.annotation.switch

case class FullName(var first: String = "F", var last: String = "L") extends org.apache.avro.specific.SpecificRecordBase {
  def this() = this("F", "L")
  def get(field$: Int): AnyRef = {
    (field$: @switch) match {
      case 0 => {
        first
      }.asInstanceOf[AnyRef]
      case 1 => {
        last
      }.asInstanceOf[AnyRef]
      case _ => new org.apache.avro.AvroRuntimeException("Bad index")
    }
  }
  def put(field$: Int, value: Any): Unit = {
    (field$: @switch) match {
      case 0 => this.first = {
        value.toString
      }.asInstanceOf[String]
      case 1 => this.last = {
        value.toString
      }.asInstanceOf[String]
      case _ => new org.apache.avro.AvroRuntimeException("Bad index")
    }
    ()
  }
  def getSchema: org.apache.avro.Schema = FullName.SCHEMA$
}

object FullName {
  val SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"FullName\",\"namespace\":\"test.vendor.basic\",\"fields\":[{\"name\":\"first\",\"type\":\"string\",\"default\":\"F\"},{\"name\":\"last\",\"type\":\"string\",\"default\":\"L\"}]}")
}
```
when processing a response with only **ONE FIELD**
```
val httpBody = "[{\"first\":\"bob\"}]"
val messageObject = responseParser.parseList[FullName](httpBody)
```
and

```  def parseList[T](string: String)(implicit m: Manifest[List[T]]): List[T] = {
    val jsonAst = JsonMethods.parse(string)
  implicit val formats: Formats = DefaultFormats
    jsonAst.extract[List[T]]

}
```

the output is `List({“first”: “F”, “last”: “L”})`

I would expect to get `List({"first":"bob","last":"L"}) 
where the **default** is used only for the missing field.


I have tried a number of the various configs around `format` and have not found success.
It is written in the comment of `org.json4s.Executable` as follows.

```
This class is intended as a workaround until we are able to use Java 8's java.lang.reflect.Executable class.
```
json4s depends on paranamer, but it seems that the equivalent function has been introduced in Java8, so it can be removed.

https://github.com/paul-hammant/paranamer

https://stackoverflow.com/questions/21455403/how-to-get-method-parameter-names-in-java-8-using-reflection
### json4s version
3.5.3

### scala version
2.12.10

### jdk version
1.8
### json4s version
3.6.7

### scala version
2.12.8

### jdk version
OpenJDK 1.8.201

I have a json that contains a field like this:
```
{
  "some_timestamp": 123123123,
  // other fields
}
```

And case class like
```
case class SomeData(some_timestamp: Date, ...)
```

I tried to create a FieldSerializr:
```
  implicit val formats = DefaultFormats + FieldSerializer[SomeData](
    {
      case ("some_timestamp", JInt(timestamp)) =>
        Some(("some_timestamp", new Date(timestamp.toLong)))
    }
  )
```

But it doesn't work as expected. It says
```
No usable value for some_timestamp
Do not know how to convert JInt(1558451394) into class java.util.Date
```
### json4s version
3.6.0
### scala version
2.11.12
### jdk version
1.8

I have problem when try i to parse json string into scala case class object,
when i run the code with json4s version 3.5.5 or previous it work fine but with version 3.6.0 and upper i get **exception**:

```
"Exception in thread "main" org.json4s.package$MappingException: No usable value for header
No usable value for s_enum_value
No usable value for $outer
Can't find field scala$Enumeration$$vmap from class scala.Enumeration
	at org.json4s.reflect.package$.fail(package.scala:95)"

```

 **the code example:**

```scala
package io.check
import org.json4s.jackson.Serialization.{read => readJson}
import org.json4s.{DefaultFormats, Formats}

object App {

  protected implicit val formats: Formats = DefaultFormats

  case class header_type(s_enum_value: s_enum_value_type.Value = s_enum_value_type.e_enum_val_3)

  case class SomeMsg(header: header_type, x: Int, y: Float)

  def main(args: Array[String]): Unit = {

    val jsonVal: String = "{\"header\" : {\"s_enum_value\" : \"e_enum_val_1\"},\"x\" : 3, \"y\" : 2.5}"


    val res = readJson[SomeMsg](jsonVal)

    println(res)

  }
}

object s_enum_value_type extends Enumeration {
  type s_enum_value_type = Value
  val e_enum_val_1, e_enum_val_2, e_enum_val_3 = Value
}
object s_enum_value_type extends Enumeration {
  type s_enum_value_type = Value
  val e_enum_val_1, e_enum_val_2, e_enum_val_3 = Value
}

```
### json4s version
3.5.3
### scala version
2.11.8
### jdk version
1.8
### spark version
2.4.3

hey,guys,i run json4s on spark 2.0 is ok,but spark 2.4.3 has this error :

```
java.lang.NoSuchMethodError: org.json4s.JsonAST$JBool$.False()Lorg/json4s/JsonAST$JBool;
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:26)
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:46)
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:39)
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:32)
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:46)
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:39)
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:46)
 at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:39)
 at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1626)
 at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1220)
 at org.json4s.jackson.JsonMethods$class.parse(JsonMethods.scala:25)
 at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:55)
```
Getting `NoSuchMethodError` in json4s `3.6.7` with Spark SQL (`2.4.0`, compiled against json4s `3.5.x`) because this method signature was changed in #519 .

Adding it back as package private (`private[json4s]`) would allow you to keep binary compatibility with 3.5.x but at the same time not allowing users of 3.6.x to use it.

Related to this is would be useful if the contract for binary compatibility between releases was a bit more explicit in the readme.

Thanks.