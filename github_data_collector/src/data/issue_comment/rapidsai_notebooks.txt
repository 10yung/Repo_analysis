Add SVR example to the svm_demo notebook. 

@JohnZed: Currently SVC and SVR are in a single notebook, let me know if you prefer to have the SVR example in a separate notebook. 



**Describe the bug**
Hi,

While looking for Multi-Node Multi-GPU examples, I have noticed that KMeans Multi-Node Multi-GPU notebook is, in reality, a Single-Node Multi-GPU example.

It makes use of LocalCudaCluster, which, if I am not wrong, only works on a single machine (with multiple GPUs).

I think it would be well-worth to:
- Rename notebook file name, from `kmeans_mnmg_demo.ipynb` to `kmeans_snmg_demo.ipynb`.
- Change the description in the notebook, stating it is a Single-Node Multi GPU example.
- In the future, add a Multi-Node Multi-GPU example.

The notebook I am referring to:
https://github.com/rapidsai/notebooks/blob/branch-0.12/cuml/kmeans_mnmg_demo.ipynb

Finally, please let me mention that the link to this notebook at README.md file is wrong.

Hope it helps.

Miguel
Hotfix for SSSP - copy of working version in branch-0.12

<!--

Thank you for contributing to RAPIDS Notebooks :)

Here are some guidelines to help the review process go smoothly.

1. Please write a description in this text box of the changes that are being
   made.

2. Please ensure that you have written units tests for the changes made/features
   added.

3. If you are closing an issue please use one of the automatic closing words as
   noted here: https://help.github.com/articles/closing-issues-using-keywords/

4. If your pull request is not ready for review but you want to make use of the
   continuous integration testing facilities please label it with `[WIP]`.

5. If your pull request is ready to be reviewed without requiring additional
   work on top of it, then remove the `[WIP]` label (if present) and replace
   it with `[REVIEW]`. If assistance is required to complete the functionality,
   for example when the C/C++ code of a feature is complete but Python bindings
   are still required, then add the label `[HELP-REQ]` so that others can triage
   and assist. The additional changes then can be implemented on top of the
   same PR. If the assistance is done by members of the rapidsAI team, then no
   additional actions are required by the creator of the original PR for this,
   otherwise the original author of the PR needs to give permission to the
   person(s) assisting to commit to their personal fork of the project. If that
   doesn't happen then a new PR based on the code of the original PR can be
   opened by the person assisting, which then will be the PR that will be
   merged.

6. Once all work has been done and review has taken place please do not add
   features or make changes out of the scope of those requested by the reviewer
   (doing this just add delays as already reviewed code ends up having to be
   re-reviewed/it is hard to tell what is new etc!). Further, please do not
   rebase your branch on master/force push/rewrite history, doing any of these
   causes the context of any comments made by reviewers to be lost. If
   conflicts occur against master they should be resolved by merging master
   into the branch used for making the pull request.

Many thanks in advance for your cooperation!

-->

Auto-merge triggered by push to `branch-0.11` that creates a PR to keep `branch-0.12` up-to-date. If this PR is unable to be immediately merged due to conflicts, it will remain open for the team to manually merge.

adding new notebook that uses cugraph and cuspatial to analyze.  This notebook quickly goes over using cuGraph's Pagerank, BFS, and Louvain, as well as cuspatial's haversine distance.

`!wgets` is for review will be removed if the data used is approved for reuse, otherwise it will go to notebooks-contrib and cuXfilter will be added

readme is coming soon if approved
<!--

Thank you for contributing to RAPIDS Notebooks :)

Here are some guidelines to help the review process go smoothly.

1. Please write a description in this text box of the changes that are being
   made.

2. Please ensure that you have written units tests for the changes made/features
   added.

3. If you are closing an issue please use one of the automatic closing words as
   noted here: https://help.github.com/articles/closing-issues-using-keywords/

4. If your pull request is not ready for review but you want to make use of the
   continuous integration testing facilities please label it with `[WIP]`.

5. If your pull request is ready to be reviewed without requiring additional
   work on top of it, then remove the `[WIP]` label (if present) and replace
   it with `[REVIEW]`. If assistance is required to complete the functionality,
   for example when the C/C++ code of a feature is complete but Python bindings
   are still required, then add the label `[HELP-REQ]` so that others can triage
   and assist. The additional changes then can be implemented on top of the
   same PR. If the assistance is done by members of the rapidsAI team, then no
   additional actions are required by the creator of the original PR for this,
   otherwise the original author of the PR needs to give permission to the
   person(s) assisting to commit to their personal fork of the project. If that
   doesn't happen then a new PR based on the code of the original PR can be
   opened by the person assisting, which then will be the PR that will be
   merged.

6. Once all work has been done and review has taken place please do not add
   features or make changes out of the scope of those requested by the reviewer
   (doing this just add delays as already reviewed code ends up having to be
   re-reviewed/it is hard to tell what is new etc!). Further, please do not
   rebase your branch on master/force push/rewrite history, doing any of these
   causes the context of any comments made by reviewers to be lost. If
   conflicts occur against master they should be resolved by merging master
   into the branch used for making the pull request.

Many thanks in advance for your cooperation!

-->

This seems to be missing from the cuml demo notebooks. 
cuML has been building out the sklearn.metrics API on GPUs. It would be nice to see a single demo notebook that could show off these metrics side by side with sklearn. 

So far we have accuracy_score, adjusted_rand_score, & r2_score. We are adding more each release. 
We need a demo notebook for random projection. This should be a simple demo. 
Description says it all. This would make it easier for users to understand the notebooks. 