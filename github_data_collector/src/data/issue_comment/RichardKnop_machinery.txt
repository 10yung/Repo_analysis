Hi @RichardKnop,
 
When is features (pause task and progress value) improved? 

> https://github.com/OptimalBits/bull

Pause: 
```
queue.pause().then(function(){
  // queue is paused now
});

queue.resume().then(function(){
  // queue is resumed now
})
```

Progress:
```
audioQueue.process(function(job, done){
  // transcode audio asynchronously and report progress
  job.progress(42);

  // call done when finished
  done();
```

Hi there,

Is that possible to use Redis sentinel as the result backend with v1.7.3?
I couldn't find how to set the URL. From the code it seems we need to create redis client with 

`redis.NewUniversalClient(ropt)`

But there is no parameter to specify the sentinel MasterName so this will turn to a Redis Cluster client.
`
```
	if strings.HasPrefix(cnf.ResultBackend, "redis://") {
		parts := strings.Split(cnf.ResultBackend, "redis://")
		addrs := strings.Split(parts[1], ",")
		if len(addrs) > 1 {
			return redisbackend.NewGR(cnf, addrs, 0), nil
		} else {
			redisHost, redisPassword, redisDB, err := ParseRedisURL(cnf.ResultBackend)

			if err != nil {
				return nil, err
			}

			return redisbackend.New(cnf, redisHost, redisPassword, "", redisDB), nil
		}
	}
```

Any suggestion? Thanks.
I like this project very much, but I am always wondering why does this project mix the version  v1 and v2 in same branch?Normally we distinguish different version by branches.
Right now we have limitations of passing type, value to arguments, that is also specific type. Is there any way we could pass named argument, like 

1. `Name:"role_id", Type: string, Value: "xyz" '? 
something like this.
2. How would I send byte as args?
I start two coroutines for the chain task.
chain01:     task03  task01 task02
chain02:     task01  task05 task04

When task01 of chain01 is finished executing, it gets stuck and doesn't execute task05.

	go func() {
		log.INFO.Println("Chain(01) of tasks:")
		chain, err := tasks.NewChain(&processTask3, &processTask1, &processTask2)
		if err != nil {
			log.ERROR.Fatalf("Error creating chain: %s", err)
		}

		chainAsyncResult, err := server.SendChainWithContext(ctx, chain)
		if err != nil {
			log.ERROR.Fatalf("Could not send chain: %s", err.Error())
		}

		results, err := chainAsyncResult.Get(time.Duration(time.Millisecond * 5))
		if err != nil {
			log.ERROR.Fatalf("Getting task result failed with error: %s", err.Error())
		}
		log.INFO.Printf("%v\n", tasks.HumanReadableResults(results))
		wg.Done()
	}()

	go func() {
		log.INFO.Println("Chain(02) of tasks:")
		chain, err := tasks.NewChain(&processTask1, &processTask5, &processTask4)
		if err != nil {
			log.ERROR.Fatalf("Error creating chain: %s", err)
		}

		chainAsyncResult, err := server.SendChainWithContext(ctx, chain)
		if err != nil {
			log.ERROR.Fatalf("Could not send chain: %s", err.Error())
		}

		results, err := chainAsyncResult.Get(time.Duration(time.Millisecond * 5))
		if err != nil {
			log.ERROR.Fatalf("Getting task result failed with error: %s", err.Error())
		}
		log.INFO.Printf("%v\n", tasks.HumanReadableResults(results))
		wg.Done()
	}()


DEBUG: 2019/12/03 17:08:16 amqp.go:333 Received new message: {"UUID":"task_86149caa-5141-4c4f-b997-141ee5e7baf0","Name":"process01","RoutingKey":"machinery_task","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":[{"UUID":"task_0f49f9ee-6b94-4d6e-ac0c-d45c6b8cb2a5","Name":"process02","RoutingKey":"","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":null,"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}],"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}
DEBUG: 2019/12/03 17:08:16 amqp.go:333 Received new message: {"UUID":"task_40f6f08b-fb7c-47b8-9740-fc3bc102f482","Name":"process03","RoutingKey":"machinery_task","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":[{"UUID":"task_86149caa-5141-4c4f-b997-141ee5e7baf0","Name":"process01","RoutingKey":"machinery_task","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":[{"UUID":"task_0f49f9ee-6b94-4d6e-ac0c-d45c6b8cb2a5","Name":"process02","RoutingKey":"","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":null,"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}],"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}],"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}
INFO: 2019/12/03 17:08:16 machinery.go:140  I am a start of task handler for: process01 
INFO: 2019/12/03 17:08:16 machinery.go:140  I am a start of task handler for: process03 
DEBUG: 2019/12/03 17:08:17 worker.go:249 Processed task task_86149caa-5141-4c4f-b997-141ee5e7baf0. Results = I`m Process01
DEBUG: 2019/12/03 17:08:17 amqp.go:333 Received new message: {"UUID":"task_0f49f9ee-6b94-4d6e-ac0c-d45c6b8cb2a5","Name":"process02","RoutingKey":"machinery_task","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":null,"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}
INFO: 2019/12/03 17:08:17 machinery.go:145  I am an end of task handler for: process01 
INFO: 2019/12/03 17:08:17 machinery.go:140  I am a start of task handler for: process02 
DEBUG: 2019/12/03 17:08:19 worker.go:249 Processed task task_40f6f08b-fb7c-47b8-9740-fc3bc102f482. Results = I`m Process03
DEBUG: 2019/12/03 17:08:19 amqp.go:333 Received new message: {"UUID":"task_86149caa-5141-4c4f-b997-141ee5e7baf0","Name":"process01","RoutingKey":"machinery_task","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":[{"UUID":"task_0f49f9ee-6b94-4d6e-ac0c-d45c6b8cb2a5","Name":"process02","RoutingKey":"","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":null,"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}],"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}
INFO: 2019/12/03 17:08:19 machinery.go:145  I am an end of task handler for: process03 
INFO: 2019/12/03 17:08:19 machinery.go:140  I am a start of task handler for: process01 
DEBUG: 2019/12/03 17:08:19 worker.go:249 Processed task task_0f49f9ee-6b94-4d6e-ac0c-d45c6b8cb2a5. Results = I`m Process02
INFO: 2019/12/03 17:08:19 machinery.go:145  I am an end of task handler for: process02 
DEBUG: 2019/12/03 17:08:20 worker.go:249 Processed task task_86149caa-5141-4c4f-b997-141ee5e7baf0. Results = I`m Process01
DEBUG: 2019/12/03 17:08:20 amqp.go:333 Received new message: {"UUID":"task_0f49f9ee-6b94-4d6e-ac0c-d45c6b8cb2a5","Name":"process02","RoutingKey":"machinery_task","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":null,"Headers":{},"Priority":0,"Immutable":true,"RetryCount":2,"RetryTimeout":0,"OnSuccess":null,"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}
INFO: 2019/12/03 17:08:20 machinery.go:145  I am an end of task handler for: process01 
INFO: 2019/12/03 17:08:20 machinery.go:140  I am a start of task handler for: process02 
DEBUG: 2019/12/03 17:08:22 worker.go:249 Processed task task_0f49f9ee-6b94-4d6e-ac0c-d45c6b8cb2a5. Results = I`m Process02
INFO: 2019/12/03 17:08:22 machinery.go:145  I am an end of task handler for: process02 
time="2019-11-30T07:09:59+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:09:59+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:09:59+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:09:59+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:09:59+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:00+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:00+08:00" level=error msg="worker error handler:Set state pending error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:00+08:00" level=error msg="worker error handler:Set state to 'retry' for task bngqai39ras9mflnv980 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:00+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqai39ras9mflnv9fg returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:00+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:00+08:00" level=error msg="worker error handler:Publish message error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:00+08:00" level=error msg="worker error handler:dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:01+08:00" level=error msg="worker error handler:dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:02+08:00" level=error msg="worker error handler:dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:04+08:00" level=error msg="worker error handler:dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:07+08:00" level=error msg="worker error handler:dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'started' for task bngqair9ras9mflnvdhg returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqair9ras9mflnvdt0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqair9ras9mflnvec0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqair9ras9mflnveig returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqaj39ras9mflnvesg returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqaj39ras9mflnvf8g returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqaj39ras9mflnvfgg returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqaj39ras9mflnvfog returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajb9ras9mflnvg10 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajb9ras9mflnvgb0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajb9ras9mflnvgi0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajb9ras9mflnvgr0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajj9ras9mflnvh3g returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:12+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajj9ras9mflnvhgg returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:Set state to 'started' for task bngqajr9ras9mflnvi8g returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajr9ras9mflnvij0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajr9ras9mflnvio0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajr9ras9mflnviu0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqajr9ras9mflnvj80 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqak39ras9mflnvjh0 returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:10:20+08:00" level=error msg="worker error handler:Set state to 'received' for task bngqak39ras9mflnvjsg returned error: dial tcp 127.0.0.1:6379: socket: too many open files"
time="2019-11-30T07:14:22+08:00" level=error msg="worker error handler:Set state pending error: dial tcp 127.0.0.1:6379: socket: too many open files"

INFO: 2019/11/28 15:17:00 worker.go:54 - ResultBackend: redis://192.168.1.253:6379/2
INFO: 2019/11/28 15:17:00 redis.go:94 [*] Waiting for messages. To exit press CTRL+C
DEBUG: 2019/11/28 15:17:07 redis.go:297 Received new message: {"UUID":"task_3f4c817a-8cf6-4eca-afe7-f6f4fb34f541","Name":"task_done","RoutingKey":"machinery_tasks","ETA":null,"GroupUUID":"","GroupTaskCount":0,"Args":[{"Name":"ss","Type":"int64","Value":1},{"Name":"dd","Type":"int64","Value":1}],"Headers":{},"Priority":0,"Immutable":false,"RetryCount":0,"RetryTimeout":0,"OnSuccess":null,"OnError":null,"ChordCallback":null,"BrokerMessageGroupId":"","SQSReceiptHandle":"","StopTaskDeletionOnError":false,"IgnoreWhenTaskNotRegistered":false}
INFO: 2019/11/28 15:17:07 main.go:70  I am a start of task handler for: task_done 
ERROR: 2019/11/28 15:17:07 task.go:130 goroutine 51 [running]:
runtime/debug.Stack(0x1d54ec8, 0xc0004f6180, 0x2)
	F:/go/src/runtime/debug/stack.go:24 +0xa4
github.com/RichardKnop/machinery/v1/tasks.(*Task).Call.func1(0xc0004d7cc8, 0xc0004ea280)
	E:/go/mod/test/pkg/mod/github.com/!richard!knop/machinery@v1.7.1/v1/tasks/task.go:130 +0xc3
panic(0xfb3520, 0x14bb4d0)
	F:/go/src/runtime/panic.go:679 +0x1c0
reflect.Value.call(0xfab2e0, 0x122e628, 0x13, 0x11bc320, 0x4, 0xc000422810, 0x2, 0x2, 0x10f7ca0, 0x1155e80, ...)
	F:/go/src/reflect/value.go:380 +0x151b
reflect.Value.Call(0xfab2e0, 0x122e628, 0x13, 0xc000422810, 0x2, 0x2, 0xc0000b0d20, 0xc0004a6400, 0x5e)
	F:/go/src/reflect/value.go:321 +0xbb
github.com/RichardKnop/machinery/v1/tasks.(*Task).Call(0xc0004ea280, 0x0, 0x0, 0x0, 0x14d66e0, 0xc0003b8b30)
	E:/go/mod/test/pkg/mod/github.com/!richard!knop/machinery@v1.7.1/v1/tasks/task.go:142 +0x264
github.com/RichardKnop/machinery/v1.(*Worker).Process(0xc00049a500, 0xc00030a1e0, 0x0, 0x0)
	E:/go/mod/test/pkg/mod/github.com/!richard!knop/machinery@v1.7.1/v1/worker.go:170 +0x390
github.com/RichardKnop/machinery/v1/brokers/redis.(*Broker).consumeOne(0xc0001f2000, 0xc000008000, 0x1df, 0x1df, 0x14e0fa0, 0xc00049a500, 0x0, 0x0)
	E:/go/mod/test/pkg/mod/github.com/!richard!knop/machinery@v1.7.1/v1/brokers/redis/redis.go:299 +0x55f
github.com/RichardKnop/machinery/v1/brokers/redis.(*Broker).consume.func2(0xc0001f2000, 0xc000008000, 0x1df, 0x1df, 0x14e0fa0, 0xc00049a500, 0xc00053e480, 0xa, 0xc0004ae1e0)
	E:/go/mod/test/pkg/mod/github.com/!richard!knop/machinery@v1.7.1/v1/brokers/redis/redis.go:258 +0x71
created by github.com/RichardKnop/machinery/v1/brokers/redis.(*Broker).consume
	E:/go/mod/test/pkg/mod/github.com/!richard!knop/machinery@v1.7.1/v1/brokers/redis/redis.go:257 +0x15a

INFO: 2019/11/28 15:17:07 main.go:74  I am an end of task handler for: task_done 
ERROR: 2019/11/28 15:17:07 main.go:66  I am an error handler: reflect: Call with too many input arguments 
Just like the source code in exaple：
```
	errorhandler := func(err error) {
		log.ERROR.Println("I am an error handler:", err)
	}
	pretaskhandler := func(signature *tasks.Signature) {
		log.INFO.Println("I am a start of task handler for:", signature.Name)
	}
	posttaskhandler := func(signature *tasks.Signature) {
		log.INFO.Println("I am an end of task handler for:", signature.Name)
	}
	worker.SetPostTaskHandler(posttaskhandler)
	worker.SetErrorHandler(errorhandler)
	worker.SetPreTaskHandler(pretaskhandler)
```
I think the "errorhandler" also need param "signature *tasks.Signature", like the follow：
```
	errorhandler := func(signature *tasks.Signature，err error) {
		log.ERROR.Printf("I am an error handler(task:%s):", signature. Name, err)
	}
```
I am currently writing an API that will use the result backend to create a dashboard informing of task results. For this, I would need to be able to access the task's signature (ex: to list parameters of the job). Would it be possible to add it?

Not that I am willing to create a PR that implements this for mongodb backend, provided you are willing to merge it / update other backend to reflect the functionality

Regards,