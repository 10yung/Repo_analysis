Currently all implementations of a component type (inputs, processors, outputs, etc) have documentation residing in a single long document. These documents consist of a config example (containing all fields) and some text, the text _may_ describe the purpose of particular fields, but most are undocumented.

It would be nice to expand the documentation of a component such that we see a config snippet, a general description of the behaviour and purpose of the component, followed by a break down of each field with further details (where applicable).

In order to do that we certainly need to break out the docs for each component into their own page, otherwise we'll end up bloating the docs. We should therefore solve the following:

1. Doc pages per component implementation, and a `README.md` that lists them (in sections?) and provides component-wide advice.
1a. Should we also redirect `docs/inputs/README.md#foo` to `docs/inputs/foo.md`?
2. Per field documentation
3. Distinction between optional vs mandatory and common vs advanced fields
3a. Should we limit the config example to only common fields?


Apache Pulsar is a distributed pub-sub messaging system, similar to Apache Kafka, but significantly more flexible, and arguably performs better.

It would be very useful to have input/output support for Pulsar in Benthos.

There is an [officially supported golang client](http://pulsar.apache.org/docs/en/client-libraries-go/), which wraps their official C++ client.
The `kafka` and `kinesis` inputs do not support batching at the output level. This is currently covered in documentation but there's nothing stopping a user from missing it and falling into this hole.

Before the next major release (where output batching is more prominent and obvious) I need a solution. Two currently off the top of my head:

- Allow output level batching by tracking offsets
- Inputs that don't support output batching can add context to each message, the output batcher then detects this and refuses to batch it (with intermittent warning logs).

Tracking offsets would mean recording all offsets consumed and acked and allowing them to be processed out of sync. It's not impossible but it's a headache to ensure messages aren't duplicated during restarts (if a single message fails to propagate during shutdown then we reprocess any number of backlogged offsets).

This adds support for [Sarama's SASL access token providers](https://godoc.org/github.com/Shopify/sarama#AccessTokenProvider) to the Kafka inputs and outputs. Since access token providers are callbacks a custom build of Benthos that registers the access token provider under a given name must be used; that name is then used in the config to specify which access token provider to use.

For example, we have a library that generates auth tokens based on our cloud provider's IAM infrastructure, the `main.go` against this branch looks something like this:

```go
package main

import (
	"os"

	"github.com/Jeffail/benthos/v3/lib/input/reader"
	"github.com/Jeffail/benthos/v3/lib/service"
	"example.com/iam_auth"
)

func main() {
	provider := iam_auth.NewJWTTokenProvider()
	reader.KafkaRegisterAccessTokenProvider("iam", provider)
	service.Run()
}
```

This has a corresponding input configuration along the lines of:

```yaml
input:
  type: kafka
  kafka:
    addresses:
      - "localhost:9094"
    sasl:
      enabled: true
      token_provider: "iam"
    start_from_oldest: false
    topic: "example"
    tls:
      enabled: true
```

A static access token can also be specified via `access_token`, this is useful for testing, or for general purpose use if your tokens are long-lived and you can get away without worrying about refreshes and don't want to build your own Benthos binary.

----

Benthos is useful, thank you!
It would be cool if Benthos was able to reload configurations without a restart. Initially this would simply involve stopping and starting the entire pipeline, but eventually we might be able to optimise it to avoid downtime entirely.

We should investigate the feasibility of using `SIGHUP` as a signal to reload config. We can also potentially add a REST endpoint. There's also the possibility of watching the config file for changes and reloading automatically (or based on a configured interval).
@Jeffail,

We have created our own custom processor which can use a redis cluster for rate limiting purposes and would like to contribute the code as new functionality in benthos. Before getting started though I am wondering where and how it should be added in terms of structure. I see a number of different approaches:

- Create a new `cache` or `redis` rate limits resource effectively duplicating the existing `cache` resource and define new args for this functionality under the existing `rate_limit` processor
- Allow the `rate_limit` processor to use cache resources and define new args for this functionality
- Create a new `rate_limit_cache` or `rate_limit_redis`  processor and disregard the `rate_limits` and `cache` resource types

Any preferences between these or other ways of structuring this new functionality??
I'm pushing my Benthos instances quite hard and I've noticed that the application stals and becomes very slow when the memory buffer becomes large (order of gigabytes).

I'm under the impression that Benthos needs to do a lot of computation before being able to pop work of the memory buffer. The outputs are working very slow at this point. If I'm restarting Benthos the outputs have higher throughput.

`$ curl localhost:4196/metrics`
```json
{
    "benthos": {
        "buffer": {
            "ack": {
                "error": 0
            },
            "backlog": 1073519480,
            "latency": 3459190663233,
            "latency_readable": "57m39.190663233s",
            "read": {
                "count": 572787,
                "error": 0
            },
            "send": {
                "error": 0,
                "success": 572777
            },
            "write": {
                "count": 574061,
                "error": 0
            }
        },
        "goroutines": 98,
        "input": {
            "batch": {
                "received": 574062
            },
            "connection": {
                "failed": 0,
                "lost": 0,
                "up": 1
            },
            "count": 574062,
            "latency": 221092826308,
            "latency_readable": "3m41.092826308s",
            "processor": {
                "0": {
                    "batch": {
                        "sent": 574062
                    },
                    "count": 574062,
                    "error": 0,
                    "sent": 1722186
                },
                "1": {
                    "batch": {
                        "sent": 574062
                    },
                    "count": 574062,
                    "error": 0,
                    "sent": 1722186
                },
                "2": {
                    "batch": {
                        "sent": 574062
                    },
                    "count": 574062,
                    "error": 0,
                    "sent": 1722186
                },
                "3": {
                    "batch": {
                        "sent": 574062
                    },
                    "count": 574062,
                    "error": 0,
                    "sent": 1722186
                }
            },
            "received": 1722186,
            "running": 1
        },
        "output": {
            "batch": {
                "bytes": 41354712513,
                "latency": 4382352187,
                "latency_readable": "4.382352187s",
                "sent": 16929
            },
            "broker": {
                "outputs": {
                    "0": {
                        "batch": {
                            "bytes": 41354712513,
                            "latency": 4382352187,
                            "latency_readable": "4.382352187s",
                            "sent": 16929
                        },
                        "connection": {
                            "failed": 0,
                            "lost": 0,
                            "up": 8
                        },
                        "count": 20723,
                        "retry": {
                            "count": 16937,
                            "end_of_retries": 0,
                            "parts": {
                                "send": {
                                    "success": 16929
                                }
                            },
                            "running": 8,
                            "send": {
                                "error": 3787,
                                "success": 16929
                            }
                        },
                        "sent": 16929
                    }
                }
            },
            "connection": {
                "failed": 0,
                "lost": 0,
                "up": 8
            },
            "count": 20723,
            "retry": {
                "count": 16937,
                "end_of_retries": 0,
                "parts": {
                    "send": {
                        "success": 16929
                    }
                },
                "running": 8,
                "send": {
                    "error": 3787,
                    "success": 16929
                }
            },
            "sent": 16929
        },
        "pipeline": {
            "processor": {
                "0": {
                    "batch": {
                        "sent": 16938
                    },
                    "condition": {
                        "count": 1668162,
                        "false": 1668162,
                        "true": 0
                    },
                    "count": 572786,
                    "dropped": 555848,
                    "on_condition": 0,
                    "on_count": 16732,
                    "on_period": 206,
                    "on_size": 0,
                    "sent": 1718358
                },
                "1": {
                    "batch": {
                        "sent": 16938
                    },
                    "count": 16938,
                    "error": 0,
                    "sent": 16938,
                    "success": 16938
                },
                "2": {
                    "batch": {
                        "sent": 16938
                    },
                    "count": 16938,
                    "error": 0,
                    "sent": 16938
                }
            }
        },
        "uptime": "6h8m13.953894625s"
    }
}
```

```shell
# pmap 432
432:   /usr/local/bin/benthos -c /etc/benthos/conf.yaml
0000000000400000  40196K r-x-- benthos
0000000002d40000      4K r---- benthos
0000000002d41000    440K rw--- benthos
0000000002daf000    180K rw---   [ anon ]
0000000003dcf000    200K rw---   [ anon ]
000000c000000000 4063232K rw---   [ anon ]
00007f9da4000000  64712K rw---   [ anon ]
00007f9da7f32000    824K -----   [ anon ]
00007f9da8000000  25204K rw---   [ anon ]
00007f9da989d000  40332K -----   [ anon ]
00007f9dac000000  65348K rw---   [ anon ]
00007f9daffd1000    188K -----   [ anon ]
00007f9db0000000  65080K rw---   [ anon ]
00007f9db3f8e000    456K -----   [ anon ]
00007f9db4000000  65496K rw---   [ anon ]
00007f9db7ff6000     40K -----   [ anon ]
00007f9db8000000  65004K rw---   [ anon ]
00007f9dbbf7b000    532K -----   [ anon ]
00007f9dbc000000  65404K rw---   [ anon ]
00007f9dbffdf000    132K -----   [ anon ]
00007f9dc0000000  64796K rw---   [ anon ]
00007f9dc3f47000    740K -----   [ anon ]
00007f9dc4000000  65208K rw---   [ anon ]
00007f9dc7fae000    328K -----   [ anon ]
00007f9dc8000000  65492K rw---   [ anon ]
00007f9dcbff5000     44K -----   [ anon ]
00007f9dcc000000  65440K rw---   [ anon ]
00007f9dcffe8000     96K -----   [ anon ]
00007f9dd0000000  65364K rw---   [ anon ]
00007f9dd3fd5000    172K -----   [ anon ]
00007f9dd4000000  65224K rw---   [ anon ]
00007f9dd7fb2000    312K -----   [ anon ]
00007f9dd8000000  64968K rw---   [ anon ]
00007f9ddbf72000    568K -----   [ anon ]
00007f9ddc000000  65516K rw---   [ anon ]
00007f9ddfffb000     20K -----   [ anon ]
00007f9de0000000  64896K rw---   [ anon ]
00007f9de3f60000    640K -----   [ anon ]
00007f9de4000000  65088K rw---   [ anon ]
00007f9de7f90000    448K -----   [ anon ]
00007f9de8000000  64844K rw---   [ anon ]
00007f9debf53000    692K -----   [ anon ]
00007f9dec000000  65020K rw---   [ anon ]
00007f9deff7f000    516K -----   [ anon ]
00007f9df0d70000  35416K rw---   [ anon ]
00007f9df302a000  81752K rw---   [ anon ]
00007f9df8000000    132K rw---   [ anon ]
00007f9df8021000  65404K -----   [ anon ]
00007f9dfc000000    132K rw---   [ anon ]
00007f9dfc021000  65404K -----   [ anon ]
00007f9e00000000    132K rw---   [ anon ]
00007f9e00021000  65404K -----   [ anon ]
00007f9e0400b000    128K rw---   [ anon ]
00007f9e04033000  16156K rw---   [ anon ]
00007f9e04ffa000      4K -----   [ anon ]
00007f9e04ffb000   8192K rw---   [ anon ]
00007f9e057fb000      4K -----   [ anon ]
00007f9e057fc000   8192K rw---   [ anon ]
00007f9e05ffc000      4K -----   [ anon ]
00007f9e05ffd000   8192K rw---   [ anon ]
00007f9e067fd000      4K -----   [ anon ]
00007f9e067fe000   8192K rw---   [ anon ]
00007f9e06ffe000      4K -----   [ anon ]
00007f9e06fff000   8192K rw---   [ anon ]
00007f9e077ff000      4K -----   [ anon ]
00007f9e07800000   8192K rw---   [ anon ]
00007f9e08000000  65460K rw---   [ anon ]
00007f9e0bfed000     76K -----   [ anon ]
00007f9e0c000000    132K rw---   [ anon ]
00007f9e0c021000  65404K -----   [ anon ]
00007f9e10000000    132K rw---   [ anon ]
00007f9e10021000  65404K -----   [ anon ]
00007f9e14000000    132K rw---   [ anon ]
00007f9e14021000  65404K -----   [ anon ]
00007f9e18000000    132K rw---   [ anon ]
00007f9e18021000  65404K -----   [ anon ]
00007f9e1c007000    960K rw---   [ anon ]
00007f9e1c0f7000      4K -----   [ anon ]
00007f9e1c0f8000   8192K rw---   [ anon ]
00007f9e1c8f8000      4K -----   [ anon ]
00007f9e1c8f9000   8192K rw---   [ anon ]
00007f9e1d0f9000      4K -----   [ anon ]
00007f9e1d0fa000   8192K rw---   [ anon ]
00007f9e1d8fa000      4K -----   [ anon ]
00007f9e1d8fb000   8192K rw---   [ anon ]
00007f9e1e0fb000     40K r-x-- libnss_files-2.24.so
00007f9e1e105000   2048K ----- libnss_files-2.24.so
00007f9e1e305000      4K r---- libnss_files-2.24.so
00007f9e1e306000      4K rw--- libnss_files-2.24.so
00007f9e1e307000     24K rw---   [ anon ]
00007f9e1e30d000   1408K rw---   [ anon ]
00007f9e1e46d000      4K -----   [ anon ]
00007f9e1e46e000   8192K rw---   [ anon ]
00007f9e1ec6e000      4K -----   [ anon ]
00007f9e1ec6f000   8192K rw---   [ anon ]
00007f9e1f46f000      4K -----   [ anon ]
00007f9e1f470000   8192K rw---   [ anon ]
00007f9e1fc70000      4K -----   [ anon ]
00007f9e1fc71000   8192K rw---   [ anon ]
00007f9e20471000      4K -----   [ anon ]
00007f9e20472000   8192K rw---   [ anon ]
00007f9e20c72000      4K -----   [ anon ]
00007f9e20c73000   8192K rw---   [ anon ]
00007f9e21473000      4K -----   [ anon ]
00007f9e21474000  43076K rw---   [ anon ]
00007f9e23e85000     80K r-x-- libresolv-2.24.so
00007f9e23e99000   2044K ----- libresolv-2.24.so
00007f9e24098000      4K r---- libresolv-2.24.so
00007f9e24099000      4K rw--- libresolv-2.24.so
00007f9e2409a000      8K rw---   [ anon ]
00007f9e2409c000     12K r-x-- libkeyutils.so.1.5
00007f9e2409f000   2044K ----- libkeyutils.so.1.5
00007f9e2429e000      4K r---- libkeyutils.so.1.5
00007f9e2429f000      4K rw--- libkeyutils.so.1.5
00007f9e242a0000     44K r-x-- libkrb5support.so.0.1
00007f9e242ab000   2044K ----- libkrb5support.so.0.1
00007f9e244aa000      4K r---- libkrb5support.so.0.1
00007f9e244ab000      4K rw--- libkrb5support.so.0.1
00007f9e244ac000     12K r-x-- libcom_err.so.2.1
00007f9e244af000   2044K ----- libcom_err.so.2.1
00007f9e246ae000      4K r---- libcom_err.so.2.1
00007f9e246af000      4K rw--- libcom_err.so.2.1
00007f9e246b0000    188K r-x-- libk5crypto.so.3.1
00007f9e246df000   2048K ----- libk5crypto.so.3.1
00007f9e248df000      8K r---- libk5crypto.so.3.1
00007f9e248e1000      4K rw--- libk5crypto.so.3.1
00007f9e248e2000      4K rw---   [ anon ]
00007f9e248e3000    804K r-x-- libkrb5.so.3.3
00007f9e249ac000   2048K ----- libkrb5.so.3.3
00007f9e24bac000     56K r---- libkrb5.so.3.3
00007f9e24bba000     12K rw--- libkrb5.so.3.3
00007f9e24bbd000    148K r-x-- liblzma.so.5.2.2
00007f9e24be2000   2044K ----- liblzma.so.5.2.2
00007f9e24de1000      4K r---- liblzma.so.5.2.2
00007f9e24de2000      4K rw--- liblzma.so.5.2.2
00007f9e24de3000     88K r-x-- libgcc_s.so.1
00007f9e24df9000   2044K ----- libgcc_s.so.1
00007f9e24ff8000      4K r---- libgcc_s.so.1
00007f9e24ff9000      4K rw--- libgcc_s.so.1
00007f9e24ffa000   1036K r-x-- libm-2.24.so
00007f9e250fd000   2044K ----- libm-2.24.so
00007f9e252fc000      4K r---- libm-2.24.so
00007f9e252fd000      4K rw--- libm-2.24.so
00007f9e252fe000   1480K r-x-- libstdc++.so.6.0.22
00007f9e25470000   2048K ----- libstdc++.so.6.0.22
00007f9e25670000     40K r---- libstdc++.so.6.0.22
00007f9e2567a000      8K rw--- libstdc++.so.6.0.22
00007f9e2567c000     16K rw---   [ anon ]
00007f9e25680000     28K r-x-- librt-2.24.so
00007f9e25687000   2044K ----- librt-2.24.so
00007f9e25886000      4K r---- librt-2.24.so
00007f9e25887000      4K rw--- librt-2.24.so
00007f9e25888000     12K r-x-- libdl-2.24.so
00007f9e2588b000   2044K ----- libdl-2.24.so
00007f9e25a8a000      4K r---- libdl-2.24.so
00007f9e25a8b000      4K rw--- libdl-2.24.so
00007f9e25a8c000    288K r-x-- libgssapi_krb5.so.2.2
00007f9e25ad4000   2044K ----- libgssapi_krb5.so.2.2
00007f9e25cd3000      8K r---- libgssapi_krb5.so.2.2
00007f9e25cd5000      8K rw--- libgssapi_krb5.so.2.2
00007f9e25cd7000    520K r-x-- libnorm.so.1.0.0
00007f9e25d59000   2048K ----- libnorm.so.1.0.0
00007f9e25f59000     12K r---- libnorm.so.1.0.0
00007f9e25f5c000      4K rw--- libnorm.so.1.0.0
00007f9e25f5d000    704K rw---   [ anon ]
00007f9e2600d000    284K r-x-- libpgm-5.2.so.0.0.122
00007f9e26054000   2048K ----- libpgm-5.2.so.0.0.122
00007f9e26254000      4K r---- libpgm-5.2.so.0.0.122
00007f9e26255000      4K rw--- libpgm-5.2.so.0.0.122
00007f9e26256000     16K rw---   [ anon ]
00007f9e2625a000    400K r-x-- libsodium.so.18.1.1
00007f9e262be000   2048K ----- libsodium.so.18.1.1
00007f9e264be000      4K r---- libsodium.so.18.1.1
00007f9e264bf000      4K rw--- libsodium.so.18.1.1
00007f9e264c0000     48K r-x-- libunwind.so.8.0.1
00007f9e264cc000   2044K ----- libunwind.so.8.0.1
00007f9e266cb000      4K rw--- libunwind.so.8.0.1
00007f9e266cc000     60K rw---   [ anon ]
00007f9e266db000   1620K r-x-- libc-2.24.so
00007f9e26870000   2048K ----- libc-2.24.so
00007f9e26a70000     16K r---- libc-2.24.so
00007f9e26a74000      8K rw--- libc-2.24.so
00007f9e26a76000     16K rw---   [ anon ]
00007f9e26a7a000    636K r-x-- libzmq.so.5.2.2
00007f9e26b19000   2044K ----- libzmq.so.5.2.2
00007f9e26d18000     32K r---- libzmq.so.5.2.2
00007f9e26d20000      4K rw--- libzmq.so.5.2.2
00007f9e26d21000     96K r-x-- libpthread-2.24.so
00007f9e26d39000   2044K ----- libpthread-2.24.so
00007f9e26f38000      4K r---- libpthread-2.24.so
00007f9e26f39000      4K rw--- libpthread-2.24.so
00007f9e26f3a000     16K rw---   [ anon ]
00007f9e26f3e000    140K r-x-- ld-2.24.so
00007f9e26f63000   1972K rw---   [ anon ]
00007f9e27151000     64K rw---   [ anon ]
00007f9e27161000      4K r---- ld-2.24.so
00007f9e27162000      4K rw--- ld-2.24.so
00007f9e27163000      4K rw---   [ anon ]
00007fff60705000    132K rw---   [ stack ]
00007fff6072f000      8K r----   [ anon ]
00007fff60731000      8K r-x--   [ anon ]
ffffffffff600000      4K r-x--   [ anon ]
 total          6238112K
```
Currently our process has been running smoothly using Benthos but a new requirement has been added and we need support for TLS NSQ as input. 

The current [configuration for NSQ](https://docs.benthos.dev/inputs/#nsq) as an input does not give us the flexibility to pass in TLS options. 

Having support for this will increase security measurements and allow us to pass vulnerability tests. 

The current [NSQ config](https://github.com/Jeffail/benthos/blob/master/lib/input/reader/nsq.go#L56) could be updated and there could be a flag that if enabled could add on `tls_v1` and the `tls_config` [properties](https://godoc.org/github.com/nsqio/go-nsq#Config) that way we can pass the require parameters and TLS can be enabled. 

For example our current need would look like this: 
```
if c.EnableTLS {
    nsqConfig.Set("tls_v1", true)
    nsqConfig.Set("tls_config", &tls.Config{
        InsecureSkipVerify: true,
    })
}
```

Thank you. 
Benthos has a huge amount of flexibility with processors such as `process_field` and `process_map`. However, most of the time users just want to perform a relatively simple and common operation on a field, e.g. increment a value:

```yaml
- process_field:
     codec: metadata
     path: foo
     result_type: int
     processors:
      - number:
          operator: add
          value: 1
```

For that purpose we _could_ use `awk`:

```yaml
pipeline:
  processors:
    - awk:
        program: |
          { metadata_set("foo", metadata_get("foo") + 1) }
```

But there's a performance hit and it seems a little heavy handed for something so simple.

Perhaps we could add a more general solution for these common operators that doesn't require a full scripting engine.