Currently the following network stanza will generate an error:
```
network {
  mode = "bridge"
  port "http" { }
}
```

This is because there is no `to` field in the port stanza. We should change this to map the `to` field to what ever the host port is assigned. This means for a dynamic port, if `to` is not specified Nomad will map the port to the same value that is allocated for the dynamic port. For static ports, this means the port will get mapped to the same port specified in `static`.
The panic described in #6954 was caused by a missing length check in `gopsutil` which we've contributed upstream as https://github.com/shirou/gopsutil/pull/822. Once that's been merged and released, we should update `gopsutil`
For reporting security vulnerabilities [please refer to the website.](https://www.nomadproject.io/security.html)

If you have a question, prepend your issue with `[question]` or preferably use the [nomad mailing list](https://www.nomadproject.io/community.html).

If filing a bug please include the following:

### Nomad version
Output from `nomad version`
```
root@dc1-consul-server:~# nomad version
Nomad v0.10.1 (0d4e5d949fe073c47a947ea36bfef31a3c49224f)

root@dc1-consul-server:~# consul version
Consul v1.6.1
Protocol 2 spoken by default, understands 2 to 3 (agent will automatically use protocol >2 when speaking to compatible agents)
```


### Operating system and Environment details
Linux

### Issue

I am unable to create more than 1 container with dynamic ports when using the consul connect stanza, this only allows me to create 1 container only, and obviously in prod I wil be running more than 1 container, so this is an issue or I may mis configuring the hcl file.

### Reproduction steps

```
nomad plan job.hcl

nomad run job.hcl
```
### Job file (if appropriate)

```
job "cinemas" {

  datacenters = ["dc1-ncv"]
  region      = "dc1-region"
  type        = "service"

  group "payment-api" {
    count = 2

    task "payment-api" {
      driver = "docker"
      config {
        image = "crizstian/payment-service-go:v0.4"
        port_map = {
          http = 3000
        }
      }

      env {
        DB_SERVERS   = "mongodb1.service.consul:27017,mongodb2.service.consul:27018,mongodb3.service.consul:27019"
        SERVICE_PORT = "3000"
        CONSUL_IP    = "172.20.20.11"
      }

      resources {
        cpu    = 50
        memory = 50
      }
    }

    network {
      mode = "bridge"
      port "http" {}
    }

    service {
      name = "payment-api"
      port = "http"

      connect {
        sidecar_service {}
      }
    }
  }
```

### Nomad Client logs (if appropriate)
If possible please post relevant logs in the issue.

```
root@dc1-consul-server:~# nomad status cinemas
ID            = cinemas
Name          = cinemas
Submit Date   = 2020-01-17T17:55:42Z
Type          = service
Priority      = 50
Datacenters   = dc1-ncv
Status        = running
Periodic      = false
Parameterized = false

Summary
Task Group        Queued  Starting  Running  Failed  Complete  Lost
booking-api       0       0         1        0       0         0
notification-api  0       0         1        0       0         0
payment-api       0       0         0        2       0         0

Future Rescheduling Attempts
Task Group   Eval ID   Eval Time
payment-api  7cb95a40  3m54s from now

Latest Deployment
ID          = 67ee6134
Status      = running
Description = Deployment is running

Deployed
Task Group        Desired  Placed  Healthy  Unhealthy  Progress Deadline
booking-api       1        1       1        0          2020-01-17T18:05:54Z
notification-api  1        1       1        0          2020-01-17T18:05:56Z
payment-api       2        2       0        2          2020-01-17T18:05:42Z

Allocations
ID        Node ID   Task Group        Version  Desired  Status   Created  Modified
465ce441  8a2c2a09  payment-api       0        run      failed   17s ago  1s ago
4a6b3f97  8a2c2a09  payment-api       0        run      failed   17s ago  1s ago
5b81c2d7  8a2c2a09  booking-api       0        run      running  17s ago  4s ago
77371af4  8a2c2a09  notification-api  0        run      running  17s ago  3s ago
root@dc1-consul-server:~# nomad alloc status 465ce441
ID                     = 465ce441
Eval ID                = 0fa75599
Name                   = cinemas.payment-api[0]
Node ID                = 8a2c2a09
Node Name              = dc1-consul-server
Job ID                 = cinemas
Job Version            = 0
Client Status          = failed
Client Description     = Failed tasks
Desired Status         = run
Desired Description    = <none>
Created                = 27s ago
Modified               = 11s ago
Deployment ID          = 67ee6134
Deployment Health      = unhealthy
Reschedule Eligibility = 3m44s from now

Allocation Addresses (mode = "bridge")
Label                      Dynamic  Address
http                       yes      10.0.2.15:24820
connect-proxy-payment-api  yes      10.0.2.15:27636 -> 27636

Task "connect-proxy-payment-api" is "dead"
Task Resources
CPU        Memory           Disk     Addresses
3/250 MHz  9.0 MiB/128 MiB  300 MiB

Task Events:
Started At     = 2020-01-17T17:55:46Z
Finished At    = 2020-01-17T17:55:53Z
Total Restarts = 0
Last Restart   = N/A

Recent Events:
Time                  Type                 Description
2020-01-17T17:55:57Z  Killing              Sent interrupt. Waiting 5s before force killing
2020-01-17T17:55:53Z  Killed               Task successfully killed
2020-01-17T17:55:53Z  Terminated           Exit Code: 0
2020-01-17T17:55:53Z  Killing              Sent interrupt. Waiting 5s before force killing
2020-01-17T17:55:53Z  Sibling Task Failed  Task's sibling "payment-api" failed
2020-01-17T17:55:46Z  Started              Task started by client
2020-01-17T17:55:45Z  Task Setup           Building Task Directory
2020-01-17T17:55:42Z  Received             Task received by client

Task "payment-api" is "dead"
Task Resources
CPU     Memory  Disk     Addresses
50 MHz  50 MiB  300 MiB

Task Events:
Started At     = N/A
Finished At    = 2020-01-17T17:55:53Z
Total Restarts = 0
Last Restart   = N/A

Recent Events:
Time                  Type            Description
2020-01-17T17:55:57Z  Killing         Sent interrupt. Waiting 5s before force killing
2020-01-17T17:55:53Z  Killing         Sent interrupt. Waiting 5s before force killing
2020-01-17T17:55:53Z  Not Restarting  Error was unrecoverable
2020-01-17T17:55:53Z  Driver Failure  Failed to create container configuration for image "crizstian/payment-service-go:v0.4" ("sha256:c29d40e80fdbec8aeea0dda2420abb0f421dafa10ff30d417ab616f94cb0faaa"): Trying to map ports but no network interface is available
2020-01-17T17:55:45Z  Driver          Downloading image
2020-01-17T17:55:45Z  Task Setup      Building Task Directory
2020-01-17T17:55:42Z  Received        Task received by client
```

Logs and other artifacts may also be sent to: nomad-oss-debug@hashicorp.com

Please link to your Github issue in the email and reference it in the subject
line:

> To: nomad-oss-debug@hashicorp.com
>
> Subject: GH-1234: Errors garbage collecting allocs

Emails sent to that address are readable by all HashiCorp employees but are *not* publicly visible.

### Nomad Server logs (if appropriate)
```
    2020-01-17T17:55:53.008Z [ERROR] client.driver_mgr.docker: failed to create container configuration: driver=docker image_name=crizstian/payment-service-go:v0.4 image_id=sha256:c29d40e80fdbec8aeea0dda2420abb0f421dafa10ff30d417ab616f94cb0faaa error="Trying to map ports but no network interface is available"
    2020-01-17T17:55:53.008Z [ERROR] client.alloc_runner.task_runner: running driver failed: alloc_id=465ce441-bb62-7b1f-fb26-072a8b7abfa8 task=payment-api error="Failed to create container configuration for image "crizstian/payment-service-go:v0.4" ("sha256:c29d40e80fdbec8aeea0dda2420abb0f421dafa10ff30d417ab616f94cb0faaa"): Trying to map ports but no network interface is available"
    2020-01-17T17:55:53.008Z [INFO ] client.alloc_runner.task_runner: not restarting task: alloc_id=465ce441-bb62-7b1f-fb26-072a8b7abfa8 task=payment-api reason="Error was unrecoverable"
    2020-01-17T17:55:53.009Z [ERROR] client.driver_mgr.docker: failed to create container configuration: driver=docker image_name=crizstian/payment-service-go:v0.4 image_id=sha256:c29d40e80fdbec8aeea0dda2420abb0f421dafa10ff30d417ab616f94cb0faaa error="Trying to map ports but no network interface is available"
    2020-01-17T17:55:53.010Z [ERROR] client.alloc_runner.task_runner: running driver failed: alloc_id=4a6b3f97-b1f1-530b-f86f-f97fe34c625d task=payment-api error="Failed to create container configuration for image "crizstian/payment-service-go:v0.4" ("sha256:c29d40e80fdbec8aeea0dda2420abb0f421dafa10ff30d417ab616f94cb0faaa"): Trying to map ports but no network interface is available"
```

ECS = Elastic Container Service, as per Amazons documentation

https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html
"Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service ..."

This PR attempts to pick up some issues found in https://github.com/hashicorp/nomad/issues/4749 .  Issue 4749 has some other issues, but this addresses one of the problems associated with leadership flapping.

In particular, this PR addresses two issues:

First, if a non-leader is promoted but then immediately loses leadership, don't bother establishing it and attempting Barrier raft transactions.  By using a buffered channel, before establishing leadership, we peek into rest of channel to see lost it before attempting to establish leadership.  This should only occur when leadership is flapping while `leaderLoop` is running/shutting down.

Second, this fixes a condition where we may reattempt to reconcile and establish leadership even after we lost raft leadership.

Consider the case where a step down occurs during the leaderLoop Barrier call and/or it times out.  The Barrier call times out after 2m by default, but reconcile interval defaults to 1m.  Thus, both `<-stopCh` and `<-interval` clauses are ready in the `WAIT` select statement.  Golang may arbitrary chose one, resulting into potentially unnecessary Barrier call.

Here, we prioritize honoring `stopCh` and ensure we return early if Barrier or reconciliation fails.


Also, add a script to ease updating the golang version we use.  It's a bit hacky but better than manually chasing down version references.

The changes are mostly bug fixes and seem safe:

> go1.12.14 (released 2019/12/04) includes a fix to the runtime. See the [Go 1.12.14 milestone](https://github.com/golang/go/issues?q=milestone%3AGo1.12.14+label%3ACherryPickApproved) on our issue tracker for details.
>
> go1.12.15 (released 2020/01/09) includes fixes to the runtime and the net/http package. See the [Go 1.12.15 milestone](https://github.com/golang/go/issues?q=milestone%3AGo1.12.15+label%3ACherryPickApproved) on our issue tracker for details.
From https://golang.org/doc/devel/release.html#go1.12.minor

The e2e framework instantiates clients for Nomad/Consul but the provisioning of the actual Nomad cluster is left to Terraform. The Terraform provisioning process uses `remote-exec` to deploy specific versions of Nomad so that we don't have to bake an AMI every time we want to test a new version. But Terraform treats the resulting instances as immutable, so we can't use the same tooling to update the version of Nomad in-place. This is a prerequisite for upgrade testing.

This changeset extends the e2e framework to provide the option of deploying Nomad (and, in the future, Consul/Vault) with specific versions to running infrastructure. This initial implementation is focused on deploying to a single cluster via `ssh` (because that's our current need), but provides interfaces to hook the test run at the start of the run, the start of each suite, or the start of a given test case.

The input JSON for configuring provisioning targets can be generated by Terraform (or written by hand). That work is #6948


The e2e framework instantiates clients for Nomad/Consul but the provisioning of the actual Nomad cluster is left to Terraform. The Terraform provisioning process uses `remote-exec` to deploy specific versions of Nomad so that we don't have to bake an AMI every time we want to test a new version. But Terraform treats the resulting instances as immutable, so we can't use the same tooling to update the version of Nomad in-place. This is a prerequisite for upgrade testing.

This changeset:
* provides Terraform output that written to JSON used by the framework to configure provisioning via `terraform output provisioning` (consumed by #6949)
* provides Terraform output that can be used by test operators to configure their shell via `$(terraform output environment)`
* drops `remote-exec` provisioning steps from Terraform
* makes changes to the deployment scripts to ensure they can be run multiple times w/ different versions against the same host.
For reporting security vulnerabilities [please refer to the website.](https://www.nomadproject.io/security.html)

If you have a question, prepend your issue with `[question]` or preferably use the [nomad mailing list](https://www.nomadproject.io/community.html).

If filing a bug please include the following:

### Nomad version 0.10.3-dev
Output from `nomad version`

### Operating system and Environment details

Archlinux docker image (`FROM archlinux:latest`)

### Issue

`make dev-ui` fails with no clear resolution:

```bash
$ make dev-ui
warning sha.js@2.4.11: Invalid bin entry for "sha.js" (in "sha.js").
warning " > @babel/plugin-proposal-object-rest-spread@7.5.4" has unmet peer dependency "@babel/core@^7.0.0-0".
warning "@babel/plugin-proposal-object-rest-spread > @babel/plugin-syntax-object-rest-spread@7.2.0" has unmet peer dependency "@babel/core@^7.0.0-0".
warning "ember-data > @ember-data/-build-infra > @babel/plugin-transform-block-scoping@7.6.2" has unmet peer dependency "@babel/core@^7.0.0-0".
warning "ember-data > @ember-data/-build-infra > babel-plugin-debug-macros@0.3.3" has unmet peer dependency "@babel/core@^7.0.0".
warning "ember-data > ember-cli-typescript > @babel/plugin-transform-typescript@7.4.5" has unmet peer dependency "@babel/core@^7.0.0-0".
warning "ember-data > ember-cli-typescript > @babel/plugin-transform-typescript > @babel/plugin-syntax-typescript@7.3.3" has unmet peer dependency "@babel/core@^7.0.0-0".
```

### Reproduction steps

```bash
git clone https://github.com/hashicorp/nomad.git
cd nomad
make bootstrap 
make dev 
make dev-ui
```

Full docker image:

```
FROM archlinux:latest

RUN pacman -Syu --noconfirm

RUN pacman -S --noconfirm \
    go \
    python2 \
    python2-pip \
    python \
    python-pip \
    git \
    make \
    gcc \
    docker \
    neovim \
    yarn

ENV PATH="/root/go/bin:${PATH}"

###################
# Setup Hashicorp.
###################
ENV HC="/root/go/src/github.com/hashicorp"
RUN mkdir -p ${HC}

## Nomad. https://www.hashicorp.com/products/nomad
RUN cd ${HC} && git clone https://github.com/hashicorp/nomad.git && cd nomad && make bootstrap && make dev && make dev-ui && nomad -v 
```

### Job file (if appropriate)

### Nomad Client logs (if appropriate)
If possible please post relevant logs in the issue.

Logs and other artifacts may also be sent to: nomad-oss-debug@hashicorp.com

Please link to your Github issue in the email and reference it in the subject
line:

> To: nomad-oss-debug@hashicorp.com
>
> Subject: GH-1234: Errors garbage collecting allocs

Emails sent to that address are readable by all HashiCorp employees but are *not* publicly visible.

### Nomad Server logs (if appropriate)
