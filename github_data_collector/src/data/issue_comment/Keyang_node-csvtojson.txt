
These lines:
https://github.com/Keyang/node-csvtojson/blob/e5ce6cf5141e26790b3499d5465a5ce775306e63/src/Converter.ts#L49-L53

Would be much more useful if the error included the `filePath` variable.

```
this.emit('error', new Error(`File does not exist at "${filePath}". Check to make sure the file path to your csv is correct.`));
```
I want to be able to validate the headers of an uploaded file by uppercasing and replacing spaces in order to provide a forgiving user experience. and then proceed to replace the headers used as keys in the JSON so that I can reference the properties by the correct name. I do not want to simply supply my own headers upfront because that then eliminates the inherent ease of use this library provides which is being able to accept the columns in any order.

file:
```
header1, HeaDER 2, header        3
value1, value2, value3
```

```
const myKnownHeaders = ['HEADER1','HEADER2','HEADER3'];
csv().on('header', (headers) => {
  // validate headers 
  let newHeaders = headers.map(a => a.replace(/\s+/g, '_').toUpperCase());
  if ( myKnownHeaders.every(elem => newHeaders.indexOf(elem) > -1)) ) {
    // idk, set the headers that are to be used as key somehow
  }
})
```

I thought doing

```
csv({
        headers: fileHeaders
    }). . .
```
 would have worked but the header event just emits my own headers back to me which doesn't work.
I want to convert my csv file line by line to JSON and after that write it line by line to result.txt

Here is what I am doing

```
import fs from 'fs';
import path from 'path';
import readline from 'readline';
import csvToJson from 'csvtojson';

const csvFilePath = path.join(__dirname, '/example.csv');
const fileOutputPath = path.join(__dirname, '/result.txt');

const input = fs.createReadStream(csvFilePath);

const output = fs.createWriteStream(fileOutputPath, {
  flags: 'w',
});

const inputFileLine = readline.createInterface({
  input,
  terminal: false,
  output,
})

inputFileLine.on('line', (line) => {

  const result = csvToJson()
    .fromString(line)
    .then((csvRow) => {
      console.log(csvRow);
      return csvRow;
    })

  console.log(result);

  // output.write(result);
})
```
Unfortunately every time I am getting an empty array inside then(). But line exists! If I add noheader: true  then the output is like this:

```
[
  {
    field1: 'firstName',
    field2: 'lastName',
    field3: 'email',
    field4: 'phoneNumber'
  }
]
[
  {
    field1: 'John',
    field2: 'Doe',
    field3: 'john@doe.com',
    field4: '0123456789'
  }
]
[
  {
    field1: 'Jane',
    field2: 'Doe',
    field3: 'jane@doe.com',
    field4: '9876543210'
  }
]
```

But I am 100% sure that header exists and I don't need noheader config.
Is there any way to use fromString inside readline event?


Seems like if there is a delimiter character in the last column of a csv (except for in the last row), then since the field gets wrapped with quotes, when it is parsed the second quote is left in. For example given this input:
```
first,second,third,fourth
one,aa aa,bb bb,cc cc
two,dd dd,"ee, ee","ff, ff"
three,gg gg,hh hh,"ii, ii"
```
The parsed data is:
`
[ { first: 'one', second: 'aa aa', third: 'bb bb', fourth: 'cc cc' },
  { first: 'two',
    second: 'dd dd',
    third: 'ee, ee',
    fourth: 'ff, ff"' },
  { first: 'three',
    second: 'gg gg',
    third: 'hh hh',
    fourth: 'ii, ii' } ]
`

As you can see "ff, ff" is parsed as 'ff, ff"'. The other values with delimiters in them are parsed fine since they are not in the last row or the last column.
Because the latest version of this library is incompatible with the angular version 8.3.19 I have replaced bluebird with native promises as proposed in #339. @Keyang please review the changes I've made and merge if everything is working.
Hello,

`.preFileLine((fileLineString, lineIdx)=>{`
`    if (lineIdx === 0){`
`        return fileLineString.replace(/ /g,'')`
`    }`
`    return fileLineString`
`})`

I'm using preFileLine() to remove spaces in CSV column headers. 

For example:

`column 1, column 2`
`ab cd, test test`

should result in

`column1, column2`
`ab cd, test test`

When there are several rows in the CSV file – everything works fine. Still, when there is only one line in the CSV – the spaces are also being replaced in it. As far as I can see, this happens because of lineIdx for the second line stays 0.

What I have noticed is that **it happens for any number of rows in CSV because for the last row in a file the lineIdx counter is not being incremented.**
Bumps [mixin-deep](https://github.com/jonschlinkert/mixin-deep) from 1.3.1 to 1.3.2.
<details>
<summary>Commits</summary>

- [`754f0c2`](https://github.com/jonschlinkert/mixin-deep/commit/754f0c20e1bc13ea5a21a64fbc7d6ba5f7b359b9) 1.3.2
- [`90ee1fa`](https://github.com/jonschlinkert/mixin-deep/commit/90ee1fab375fccfd9b926df718243339b4976d50) ensure keys are valid when mixing in values
- See full diff in [compare view](https://github.com/jonschlinkert/mixin-deep/compare/1.3.1...1.3.2)
</details>
<details>
<summary>Maintainer changes</summary>

This version was pushed to npm by [doowb](https://www.npmjs.com/~doowb), a new releaser for mixin-deep since your current version.
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mixin-deep&package-manager=npm_and_yarn&previous-version=1.3.1&new-version=1.3.2)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/Keyang/node-csvtojson/network/alerts).

</details>
Does anybody know how I can convert the gallery field in the CSV into a JSON array?
The field is a list of image URLs separated by pipes.

I have the following CSV.
![Capture3](https://user-images.githubusercontent.com/12853207/67605303-9c614280-f743-11e9-8566-a6d15f7b2b56.PNG)

At the moment the result I get from csvtojson is:
![result](https://user-images.githubusercontent.com/12853207/67605728-cc5d1580-f744-11e9-9bb1-e920c96ca435.PNG)


I am trying to create the following. If somebody can point me to the right direction.
![Capture2](https://user-images.githubusercontent.com/12853207/67605295-966b6180-f743-11e9-995b-4e031b02c8d3.PNG)

Simple question: is it possible to have rows converted into seperate JSON files instead of all the rows in a single JSON file as an array.