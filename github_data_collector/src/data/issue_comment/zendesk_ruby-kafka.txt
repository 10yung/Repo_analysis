Hi, ruby-kafka 0.6.8 use which message format versionÔºåtks ~
If this is a bug report, please fill out the following:

* Version of Ruby: 2.3.4
* Version of ruby-kafka: v0.7.10

Please verify that the problem you're seeing hasn't been fixed by the current `master` of ruby-kafka.

###### Steps to reproduce

Ruby Kafka client defined as followed: 

```ruby
 Kafka.new(
  %w[kafka1:9093],
  logger: Rails.logger,
  ssl_ca_cert: File.read('config/ccpa/root_ca.pem'),
  ssl_client_cert: File.read('config/ccpa/privacy-sor.pem'),
  ssl_client_cert_key: File.read('config/ccpa/privacy-sor.pem')
)
```

# Please write an example that reproduces the problem you're describing.
I'm encoding a message via Avro am trying to do deliver this message, in doing so when I try to deliver this message I get an error that the certificate couldn't be verified. In addition to this I've confirmed that the issue isn't with the certs because when I run: 

```
openssl s_client \
-host kf0002.cf.prd349.preprod3.bar.foo \
-port 9093 \
-CAfile root_ca.pem \
-state -debug \
-cert privacy-sor.pem \
-key privacy-sor.pem
```

I get: `Verify return code: 0 (ok)`

###### Expected outcome

My expected outcome is certificate verification doesn't fail. 

###### Actual outcome

When I try to deliver a encoded avro message to my topic I got the following: 

```ruby
New topics added to target list: privacy.prd2293.datadictionary.v0.qa
Fetching cluster metadata from kafka://kf0002.cf.prd349.dev3.bar.foo:9093
[topic_metadata] Opening connection to kf0002.cf.prd349.dev3.bar.foo:9093 with client id ruby-kafka...
Closing socket to kf0002.cf.prd349.dev3.bar.foo:9093
OpenSSL::SSL::SSLError: SSL_connect returned=1 errno=0 state=error: certificate verify failed
from /Users/home/Code/web/.bundle/ruby/2.3.0/gems/ruby-kafka-0.7.10/lib/kafka/ssl_socket_with_timeout.rb:69:in `connect_nonblock'
```

If this is a bug report, please fill out the following:

* Version of Ruby: 2.3.7
* Version of Kafka: 2.2
* Version of ruby-kafka: 0.7.6

Please verify that the problem you're seeing hasn't been fixed by the current `master` of ruby-kafka.

###### Steps to reproduce

I'm trying to connec to three different topics, I can easily connect to two of them and listen with no issue, but on the third one I get the following stack error:

```
TypeError: no implicit conversion of nil into Integer
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/encoder.rb:57:in `pack'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/encoder.rb:57:in `write_int32'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/fetch_request.rb:64:in `block (2 levels) in encode'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/encoder.rb:82:in `each'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/encoder.rb:82:in `write_array'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/fetch_request.rb:58:in `block in encode'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/encoder.rb:82:in `each'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/encoder.rb:82:in `write_array'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/fetch_request.rb:55:in `encode'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/request_message.rb:22:in `encode'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/protocol/encoder.rb:178:in `encode_with'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/connection.rb:165:in `write_request'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/connection.rb:104:in `block in send_request'
  from /usr/local/bundle/gems/activesupport-5.0.7.2/lib/active_support/notifications.rb:166:in `instrument'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/instrumenter.rb:21:in `instrument'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/connection.rb:97:in `send_request'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/broker.rb:188:in `send_request'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/broker.rb:54:in `fetch_messages'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetch_operation.rb:81:in `block in execute'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetch_operation.rb:71:in `each'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetch_operation.rb:71:in `flat_map'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetch_operation.rb:71:in `execute'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetcher.rb:201:in `fetch_batches'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetcher.rb:157:in `step'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetcher.rb:111:in `loop'
  from /usr/local/bundle/gems/ruby-kafka-0.7.6/lib/kafka/fetcher.rb:56:in `block in start'
```

And I can't quite figure out why is it happening, has anyone had an similar issue?

###### Expected outcome

I would start receiving the messages like with the other topics I use.

###### Actual outcome

I got the error mentioned above

We currently run kafka consumers in a jobs framework, where the expectation is that jobs complete in a certain period of time (e.g. 60s).  As it is right now, the `each_batch` or `each_message` block will block indefinitely until there are messages on the topic.  We understand that is generally desirable in the common case, and that our use-case is slightly outside the norm, but that is what it is ü§∑‚Äç‚ôÇ 

@dasch what's your preference here:
- encumber the `each_message` and `each_batch` methods with a `timeout` function described in https://github.com/zendesk/ruby-kafka/issues/578 (which, BTW we've been running as a fork for quite a long time successfully)
- re-open https://github.com/zendesk/ruby-kafka/pull/369 and work to get that merged

Thanks and we appreciate your time and effort into supporting ruby-kafka ‚ù§Ô∏è 
Kafka Java Client handle certain types of errors with retries
For example:
https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L1185
https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L1189
https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L1141

This PR sync behavior for these scenarios.
I see the pause functionality has been implemented to pause processing messages for a partition. But the use case I have is to pause the consumer loop for indefinite time and resume later. This will pause processing of any message until notified to resume. Is there a way to do this using ruby-kafka.

https://github.com/zendesk/ruby-kafka/blob/master/lib/kafka/consumer.rb#L204


