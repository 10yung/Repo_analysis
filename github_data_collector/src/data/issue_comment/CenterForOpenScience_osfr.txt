I believe (based on my use of the osf_upload function) that there is a typo in the docs. Line 76 of gives the example code: 
`osf_upload("iris.csv", overwrite = TRUE) %>%`

but I believe it should be:
`osf_upload("iris.csv", conflicts = "overwrite") %>%`

Thank you for this package it has been extremely helpful for automating processes in my lab!
provide a function to duplicate files/directories in same location
The API provides endpoints for generating and listing external IDs (currently limited to DOIs). We could implement something like

```r
osf_generate_id(proj, type = "doi")
```

which would return a modified version of `proj` with a new `doi` column.

* The generic name provides for the possibility of being able to generate other IDs
* *generate* is annoyingly long... might need a different verb
* Should it verify a node is public? Is that a requirement?

Would also need `osf_ls_ids()` to list previously generated IDs since they aren't returned by default.

Comments/suggestions, @cboettig?
- [ ] Add multi-file transfer functionality to README and vignettes
- [ ] Add logging instructions to CONTRIBUTING
- [ ] Is `osf_rm()`'s recursive argument still necessary? (on hold https://github.com/CenterForOpenScience/osf.io/issues/9252)
When using the osf_upload function in combination with purrr::walk I received an inconsistent error.  I could upload ~50 files with no problems. 

Later when trying the same basic code with a much larger directory (~1000) files only 700 files uploaded before I received this message:

> Error:
> Encountered an unexpected error with the OSF API
> Please report this at https://github.com/aaronwolen/osfr/issues
> * Status code: 502
> * Request: https://api.osf.io/v2/files/5c7d5f92773b2d00180427b9/


Code that failed with error above:

      osf_retrieve_node("3r7nw") %>%
      osf_mkdir(., path = "2019-3-4 tetramer with amylose in KCl") %>%
      walk(files, osf_upload, x = .)

I adjusted the code figuring it was a timeout issue and tried to complete the upload with:

     osf_retrieve_node("3r7nw") %>%
     osf_ls_files() %>%
     filter(name == "2019-3-4 tetramer with amylose in KCl") %>%
     walk(files, osf_upload, x = ., overwrite = TRUE)

and got this error:
>Error: Internal Server Error
>       HTTP status code 500.

Note: `overwrite = FALSE` failed to work, which is why overwrite is set to TRUE

As I stated originally, the same basic code worked for 50 files, but larger uploads failed to fully complete. 

Have enjoyed using the package and this won't stop me from using it, just 1000 files is a standard size project for me so batch uploads without having to use the web interface is really useful.
This would be useful for my [codebook](https://github.com/rubenarslan/codebook) package.
[A tweet](https://twitter.com/__jsta/status/928738955423571968) suggested to add preprint search in the `fulltext` package, which might also perfectly fit here.

@sckott, would you consider it preferable to add it here or in `fulltext`? I am planning (and have been for too long...) to submit this package to rOpenSci for review anyway when it's somewhat more fleshed out, so would value your input to prevent redundancy.