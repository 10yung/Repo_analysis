This is the stack trace we got in our tests
```
fatal error: concurrent map read and map write

goroutine 7 [running]:
runtime.throw(0x17b1b17, 0x21)
	/usr/local/go/src/runtime/panic.go:774 +0x72 fp=0xc00c97f8b8 sp=0xc00c97f888 pc=0x431422
runtime.mapaccess2_faststr(0x15f4040, 0xc011202f90, 0x257c531, 0x1, 0xc00c97fa70, 0xcb5919)
	/usr/local/go/src/runtime/map_faststr.go:116 +0x48f fp=0xc00c97f928 sp=0xc00c97f8b8 pc=0x4150ff
github.com/blevesearch/bleve/analysis.TokenFrequencies.MergeAll(0xc011202f90, 0x14488dd, 0x2, 0xc01121cc00)
	/home/circleci/.go_workspace/pkg/mod/github.com/blevesearch/bleve@v0.0.0-20190812174355-c997533a776f/    +0x100 fp=0xc00c97fa38 sp=0xc00c97f928 pc=0x9d6770
github.com/blevesearch/bleve/document.(*CompositeField).Compose(0xc00e499d80, 0x14488dd, 0x2, 0x1, 0xc01121cc00)
	/home/circleci/.go_workspace/pkg/mod/github.com/blevesearch/bleve@v0.0.0-20190812174355-c997533a776f/document/field_composite.go:122 +0xf2 fp=0xc00c97fa80 sp=0xc00c97fa38 pc=0x9dd902
github.com/blevesearch/bleve/index/upsidedown.(*UpsideDownCouch).Analyze(0xc001dbda80, 0xc00e499d00, 0x2)
	/home/circleci/.go_workspace/pkg/mod/github.com/blevesearch/bleve@v0.0.0-20190812174355-c997533a776f/index/upsidedown/analysis.go:77 +0xc10 fp=0xc00c97ff28 sp=0xc00c97fa80 pc=0xc9b630
github.com/blevesearch/bleve/index.AnalysisWorker(0xc0004f1e00, 0xc0004f1e60)
	/home/circleci/.go_workspace/pkg/mod/github.com/blevesearch/bleve@v0.0.0-20190812174355-c997533a776f/index/analysis.go:106 +0x55 fp=0xc00c97ffd0 sp=0xc00c97ff28 pc=0x9e12b5
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc00c97ffd8 sp=0xc00c97ffd0 pc=0x460741
created by github.com/blevesearch/bleve/index.NewAnalysisQueue
	/home/circleci/.go_workspace/pkg/mod/github.com/blevesearch/bleve@v0.0.0-20190812174355-c997533a776f/index/analysis.go:94 +0xc8
```

I think that the root cause is that iterating on the map, pointers change under the hood, which will lead to analysing the same document twice
mappings
`// a generic reusable mapping for english text
	englishTextFieldMapping := bleve.NewTextFieldMapping()
	englishTextFieldMapping.Analyzer = en.AnalyzerName
	englishTextFieldMapping.Store = true
	englishTextFieldMapping.IncludeInAll = true

	// a generic reusable mapping for keyword text
	//	keywordFieldMapping := bleve.NewTextFieldMapping()
	//	keywordFieldMapping.Analyzer = keyword.Name

	docMapping := bleve.NewDocumentMapping()

	docMapping.AddFieldMappingsAt("id", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("cnname", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("citycode", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("citycn", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("enname", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("country", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("country_code", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("province", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("cityen", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("city_pinyin", englishTextFieldMapping)
	docMapping.AddFieldMappingsAt("city_jianpin", englishTextFieldMapping)

	indexMapping := bleve.NewIndexMapping()
	indexMapping.DefaultAnalyzer = "en"
	indexMapping.DefaultMapping = docMapping
	//indexMapping.IndexDynamic = true
`
query
`func  Search(q string, from, size int) (items []interface{}, err error) {

	var searchQuery query.Query
	if q != "" {
		queryId := query.NewMatchPhraseQuery(q)
		queryId.SetField("id")
		queryCnname := query.NewMatchPhraseQuery(q)
		queryCnname.SetField("cnname")
		queryCitycode := query.NewMatchPhraseQuery(q)
		queryCitycode.SetField("citycode")
		queryCitycn := query.NewMatchPhraseQuery(q)
		queryCitycn.SetField("citycn")
		queryEnname := query.NewMatchPhraseQuery(q)
		queryEnname.SetField("enname")
		queryCountrycode := query.NewMatchPhraseQuery(q)
		queryCountrycode.SetField("country_code")
		queryCountry := query.NewMatchPhraseQuery(q)
		queryCountry.SetField("country")

		disQuery := bleve.NewDisjunctionQuery()
		disQuery.AddQuery(queryId, queryCnname, queryCitycode, queryCitycn, queryEnname, queryCountrycode, queryCountry)
		searchQuery = disQuery
	} else {
		searchQuery = bleve.NewMatchAllQuery()
	}

	searchRequest := bleve.NewSearchRequestOptions(searchQuery, size, from, true)
	searchRequest.Fields = []string{"id", "cnname", "citycode", "citycn", "enname", "country_code", "country"}
	searchRequest.SortBy([]string{"-id"})

	searchResult, err := b.index.Search(searchRequest)
	if err != nil {
		return
	}
	//fmt.Println(searchResult)
	for _, v := range searchResult.Hits {
		items = append(items, v.Fields)
		//	fmt.Printf("no%d %s %s %v\n", i, v.Index, v.ID, v.Fields)
	}
	return
}`

when i run  search("bjs", 0., 10), i want query match the whole bjs phrase documents,but i found that it return a document not match the whole phrase bjs.
the doc1 is 
{
    "_id" : "COO",
    "cnname" : "科托努机场",
    "citycode" : "COO",
    "citycn" : "科托努",
    "enname" : "Cadjehoun",
    "country" : "贝宁",
    "province" : "",
    "cityen" : "Cotonou",
    "country_code" : "BJ",
    "region_code" : "AF"
}

how to make search("bjs", 0., 10) not match the doc1 only match documents which has whole bjs string



I'm not sure what I'm doing wrong, I think I should get a result, but I don't not sure why?

```
package main

import (
	"fmt"
	"os"

	"github.com/blevesearch/bleve"
)

func main() {
	// open a new index
	mapping := bleve.NewIndexMapping()
	os.RemoveAll("example.bleve")
	index, err := bleve.New("example.bleve", mapping)
	if err != nil {
		fmt.Println(err)
		return
	}

	type DataStruct struct {
		Name string
	}
	testData1 := DataStruct{"Text Here"}
	testData2 := DataStruct{"Here we Are"}

	index.Index("testData1", testData1)
	index.Index("testData2", testData2)

	query := bleve.NewMatchQuery("Text")
	search := bleve.NewSearchRequest(query)
	searchResults, err := index.Search(search)
	if err != nil {
		fmt.Println(err)
		return
	}
	fmt.Println(searchResults)
	fmt.Println("-------------------------")
	fmt.Printf("%v\n", testData2)
	testQueryString := "Here we Are"
	fmt.Println("Query String = ", testQueryString)
	phraseQuery := bleve.NewMatchPhraseQuery(testQueryString)
	searchQuery := bleve.NewSearchRequest(phraseQuery)
	searchResultsQuery, err := index.Search(searchQuery)
	if err != nil {
		fmt.Println(err)
		return
	}

	fmt.Println(searchResultsQuery)
}
```

The output is: 

> 1 matches, showing 1 through 1, took 0s
>     1. testData1 (1.000000)
> 
> -------------------------
> {Here we Are}
> Query String =  Here we Are
> No matches


If I change the phrase to "Here we Go", it works fine: 

> 1 matches, showing 1 through 1, took 993.3µs
>     1. testData1 (1.000000)
> 
> -------------------------
> {Here we Go}
> Query String =  Here we Go
> 1 matches, showing 1 through 1, took 0s
>     1. testData2 (1.000000)
Implemented Lithuanian language analyzer using latest Snowball stemmer https://github.com/blevesearch/snowballstem/pull/1.

Analyzer made by using Russian and Romanian analyzers as examples.

Tests seem correct, I am a Lithuanian speaker. I may add more example sentences if necessary.
The snippet below for prefix based search does not return any matches. Ideally it should match both the records:
```
//Indexing

	contact1 := struct {
		ID   string
		Name string
	}{
		ID:   "1",
		Name: "Syamkrishna",
	}

	contact2 := struct {
		ID   string
		Name string
	}{
		ID:   "2",
		Name: "Syama",
	}

	mapping := bleve.NewIndexMapping()

	var index bleve.Index
	index, err := bleve.New("bleve/example.test", mapping)
	if err != nil {
		index, err = bleve.Open("bleve/example.test")

		if err != nil {
			panic(err)
		}
	}
	index.Index(contact1.ID, contact1)
	index.Index(contact2.ID, contact2)
	//Querying
	query := bleve.NewMatchQuery("syam")
	query.SetPrefix(4)
	searchRequest := bleve.NewSearchRequest(query)
	searchResult, _ := index.Search(searchRequest)

	fmt.Printf("%s\n", searchResult)
```
When searching for fuzzy I can't see the matched terms in the Locations.

I.E:
I have in the db: `Almog Baku`
I'm doing a fuzzy search for `Alog` (with `IncludeLocations=true`)
I will receive a hit with no locations.
This is a fix for memory leak from in-mem index (blevesearch/bleve#374). 

I made a fix in the underlying store - https://github.com/blevesearch/bleve/pull/1314. but seems like Compact() function is recommended by the owner - https://github.com/blevesearch/blevex/pull/30.
How would I dump an async snapshot of the index with scorch? And write it to an io.writer?
Our single  scorch index has 80,000,000 documents and a query that hits 300,000 docs and returns the first 10 docs takes 10 seconds or so to return. 

My question is if I don't care the exact number of total hits of a certain query, is there any way to make the search faster, ie: just return some hits quickly.
Hi - we have a project that uses bleve in-memory index based on gtreap implementation. We noticed a similar behavior that dictionary rows keep grow even after all the documents referring to them are deleted. I found https://github.com/blevesearch/bleve/issues/374, and seems that someone made a temporary only to leveldb, which does not apply to bleve in-memory index use-case.

So I've made this PR to systematically fix #374 for all different index store implementations. Looking forward to your feedback!