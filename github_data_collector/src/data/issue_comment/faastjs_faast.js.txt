This PR contains the following updates:

| Package | Type | Update | Change |
|---|---|---|---|
| [@types/aws-lambda](https://togithub.com/DefinitelyTyped/DefinitelyTyped) | devDependencies | patch | [`8.10.37` -> `8.10.39`](https://renovatebot.com/diffs/npm/@types%2faws-lambda/8.10.37/8.10.39) |

---

### Renovate configuration

:date: **Schedule**: At any time (no schedule defined).

:vertical_traffic_light: **Automerge**: Enabled.

:recycle: **Rebasing**: Whenever PR becomes conflicted, or if you modify the PR title to begin with "`rebase!`".

:no_bell: **Ignore**: Close this PR and you won't be reminded about this update again.

---

 - [ ] <!-- rebase-check -->If you want to rebase/retry this PR, check this box

---

This PR has been generated by [WhiteSource Renovate](https://renovate.whitesourcesoftware.com). View repository job log [here](https://app.renovatebot.com/dashboard#faastjs/faast.js).
I've just started researching options for a large scale batch computing job and although pricing isn't a huge worry (since it's a one-off job), it is something that interests me in case I end up building a deployment script/framework that can be used on future projects:

* [Google Cloud Function](https://cloud.google.com/functions/pricing-summary/) (1GB, 1GHz): (0.0000025 + 0.00001)*60*60 = $0.045 / hr / core
* [Google Preemptible n1-highcpu-64](https://cloud.google.com/compute/pricing) (~1GB per core, ~2GHz): 0.48/64 = $0.0075 / hr / core

So the cloud function approach appears to be ~6x the price of the preemptible machine approach? And if you take into account clock speed then it's somewhere near 12x the price? I also haven't taken into account the invocation pricing of the cloud functions, but I'm assuming that would be small. The preemptible machine approach also has the advantage of being able to run code for longer than 10 or 15 mins, which is very handy for me - it saves me splitting up files that need to be processed into smaller, digestible-in-10-minutes chunks and coding all the logic to handle merging and stuff.

@BrandiATMuhkuh, who you were talking to on [the hacker news thread](https://news.ycombinator.com/reply?id=19813577) seems to have switched to many-core machine(s) after trying the cloud function approach, and I wonder if pricing was a consideration there?

If I've not made any mistakes or incorrect assumptions, then is it within the scope of faast.js to consider preemptible machines? Since you've implemented a `local` provider, I'm assuming that you've done most of the leg-work required to be able to deploy it to an actual machine, rather than a cloud function.
https://www.loom.com/share/58bfe85472ca4f56927b47d0c0bba9e1
Currently `CommonOptions.addZipFile` and `CommonOptions.addDirectory` add files into the code package that is uploaded directly. There is a 50MB limit on AWS for the code package. Lambda Layers allows us to increase this limit to 250MB.

We should use Lambda Layers to implement these options. A separate layer can be created for each value (there is a limit of 5 layers for each function), then all can be added to the function. Layers are already used for implementing `packageJson` so this should be relatively straightforward, as the garbage collector should work as-is if we follow the `faast-*` naming convention.
Currently with AWS, using the `packageJson` option with faast.js causes a new Lambda Layer to be created that can be reused if the same `package.json` is used by future functions (only if `useDependencyCaching` is `true`, which is the default). The layers created for caching are deleted by garbage collection using the same `retentionInDays` value as other resources. In practice this means that every 24h the packages will be reinstalled from scratch once, which makes function creation slower than needed in most cases.

We could do one of several things to improve this:

1. Add a separate retention period to the options, which is longer. Say, 30 days.
2. Use a smarter caching algorithm to keep a small number of layers around. For example, deleting the layer with the oldest creation date after reaching a limit of, say, 20 layers. The limit could be configured.

Note that the longer the packages are cached, the more likely there will be minor version updates that are missed. On the other hand, more frequent updates means longer lambda creation time, and the possibility that code breaks because dependencies are quietly updated that doesn't fully respect semver.

Suggest going with 2. Not sure what to do about the quiet update problem, maybe faast.js should issue a note to the console.
