> I did not look deep into karafka source code but looks like karafka leverages process isolation for consumer isolation.
> 
> Is the consumer_group tightly coupled to the process or the consumer class itself?
> 
> The costs associated with spawning a separate JVM per consumer group may not be scalable for JRuby and might be better to run multiple threads in the JVM. It might add the possibility of running multiple consumers in different consumer groups within the same process where using a single consumer to subscribe to multiple topics is not feasible.
> 
> I'm confident that this approach may not fit in libraries like karafka itself where majority of users run MRI Ruby. I just want to hear your thoughts on the approach.

ref from @Adithya-copart: https://github.com/appsignal/rdkafka-ruby/pull/106
I have been trying to connect `karafka` app to `heroku kafka` addon but I get the following error:

>I, [2019-12-20T17:12:03.425476 #29399]  INFO -- : Fetching cluster metadata from kafka+ssl://ec2-x-x-x-x.compute-1.amazonaws.com:9096
Traceback (most recent call last):
       16: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/cluster.rb:52:in 'add_target_topics'
       15: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/cluster.rb:98:in 'refresh_metadata!'
       14: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/cluster.rb:350:in 'cluster_info'
       13: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/cluster.rb:370:in 'fetch_cluster_info'
       12: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/cluster.rb:370:in 'each'
       11: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/cluster.rb:375:in 'block in fetch_cluster_info'
       10: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/broker.rb:44:in 'fetch_metadata'
        9: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/broker.rb:200:in 'send_request'
        8: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/connection.rb:97:in 'send_request'
        7: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/instrumenter.rb:21:in 'instrument'
        6: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/activesupport-6.0.2/lib/active_support/notifications.rb:182:in 'instrument'
        5: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/connection.rb:98:in 'block in send_request'
        4: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/connection.rb:127:in 'open'
        3: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/connection.rb:127:in 'new'
        2: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/ssl_socket_with_timeout.rb:69:in 'initialize'
        1: from /home/farhan/.rvm/gems/ruby-2.6.5/gems/ruby-kafka-0.7.10/lib/kafka/ssl_socket_with_timeout.rb:69:in 'connect_nonblock'
OpenSSL::SSL::SSLError (SSL_connect returned=1 errno=0 state=error: certificate verify failed (unspecified certificate verification error))

Following is the configuration in `karafka.rb`

    setup do |config|
      config.kafka.seed_brokers = ENV['KAFKA_URL'].to_s.split(',').map(&:strip)
      if ENV['KAFKA_TRUSTED_CERT']
        tmp_ca_file = ::Tempfile.new('kafka_ca_certs')
        tmp_ca_file.write(ENV.fetch('KAFKA_TRUSTED_CERT'))
        tmp_ca_file.close
        config.kafka.ssl_ca_cert_file_path = tmp_ca_file.path
      end
      if ENV['KAFKA_CLIENT_CERT'] && ENV['KAFKA_CLIENT_CERT_KEY']
        config.kafka.ssl_client_cert = ENV['KAFKA_CLIENT_CERT']
        config.kafka.ssl_client_cert_key = ENV['KAFKA_CLIENT_CERT_KEY']
      end
      config.client_id = 'async_processor'
    end

**What I tried**

 - `OpenSSL::SSL::VERIFY_PEER = OpenSSL::SSL::VERIFY_NONE`

But then I get different error:

> ERROR -- : Failed to assign partitions to 1 messages in TutorialTopic

**Maybe helpful point**
Since it is a shared cluster, I have a config in heroku name `KAFKA_PREFIX` not sure what to do with it, tried appending it to the topic but in vain.

What am I missing?

Info:
```
ruby '2.6.5'
karafka '1.3.1'
```
Hello!
I have problem with responder in ruby-rails setup. From rails console I see that responder starts to connect with:
```
I, [2019-08-13T17:19:41.080285 #13215]  INFO -- : Fetching cluster metadata from kafka://localhost:9092
D, [2019-08-13T17:19:41.080362 #13215] DEBUG -- : [topic_metadata] Opening connection to localhost:9092 with client id delivery_boy...

```
But as you can see from my configuration file and server output I have a broker with different port and client_id. Is there something missing from configuration for responder to work or can someone give me any hints why is it acting like this? 


Karafka server output:
Karafka framework version: 1.2.13
Application client id: example_app
Backend: inline
Batch fetching: false
Batch consuming: false
Boot file: /home/kylli/REPOS/lendify/karafka.rb
Environment: development
Kafka seed brokers: ["kafka://127.0.0.1:9093"]

Configuration: 

```
NV['RAILS_ENV'] ||= 'development'
ENV['KARAFKA_ENV'] = ENV['RAILS_ENV']
require ::File.expand_path('../config/environment', __FILE__)
Rails.application.eager_load!

class KarafkaApp < Karafka::App
  setup do |config|
    config.kafka.seed_brokers = %w[kafka://127.0.0.1:9093]
    config.client_id = 'example_app'
    config.backend = :inline
    config.batch_fetching = false
  end


  consumer_groups.draw do
    consumer_group :example do

      topic :orders do
        consumer OrderConsumer
      end
    end
  end
end

KarafkaApp.boot!
```

Responder file:

```
class OrderResponder < ApplicationResponder
  topic :order

  def respond(credit_application)
    respond_to :order, credit_application
  end

end
```
 And in my code I use responder as -> OrderResponder.call(self)






We need to benchmark if `params['payload']` is faster then `params.payload`, plus if we will gain anything more if we will remove those methods.

Refs https://github.com/karafka/karafka/pull/534#pullrequestreview-267618040
In order to query the app's status, instead of subscribing to the app's events and storing or sending them, an endpoint like `/health.json` could provide a simple JSON with the app's status, reason (in case of error) and some other useful information.
Now we have a responder that by default runs an instance, buffers, and dispatches in a single run via the class `#call` method. We can also initialize the instance and run it manually but that does not allow us to have a long running buffering responder. I would like to have a possibility to long buffer data and dispatch it when needed.
I'm currently working on a multithreaded framework for batching and enqueueing data into a background ruby thread. This could be used to leverage the Karafka framework and provide multi threaded flow with having a single consumer group.
The development of rdkafka-ruby is in progress. Once some neded features are available, we could migrate to it.

Things required:
- [x] Check the config validators quality and the way they operate (https://github.com/karafka/karafka/issues/434)
- [x] Migrate producer (WaterDrop) (https://github.com/karafka/waterdrop/issues/75)
- [x] Normalize the settings (https://github.com/karafka/karafka/issues/425)
- [x] drop jruby support for Karafka ecosystem (https://github.com/karafka/karafka/issues/433)
- [ ] instrumentation
- [ ] batch processing
- [ ] batch metadata (or a way to calculate those)
- [ ] settings normalization (https://github.com/karafka/karafka/issues/425)
- [ ] Docs
- [ ] Long running loop (https://github.com/appsignal/rdkafka-ruby/issues/12)
- [ ] hooks for before/after poll and other lifecycle moments
- [ ] Regexp support for topic subscription
Several settings related to Kafka are not 1:1 between Karafka and kafka. It would be good to normalize that to match Kafka conventions.
@mbj https://github.com/mbj/mutant