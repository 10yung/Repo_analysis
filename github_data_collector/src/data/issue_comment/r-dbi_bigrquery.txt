A minor suggested change to `README.md` to make getting started a little easier for newcomers. 

Recommend changing 

```R
library(bigrquery)
billing <- bq_test_project() # replace this with your project ID 
sql <- "SELECT year, month, day, weight_pounds FROM `publicdata.samples.natality`"

tb <- bq_project_query(billing, sql)
bq_table_download(tb, max_results = 10)
```

To 

```R
library(bigrquery)
# Sys.setenv(BIGQUERY_TEST_PROJECT = "your-project-id") # Replace with your GCP project ID
billing <- bq_test_project()
sql <- "SELECT year, month, day, weight_pounds FROM `publicdata.samples.natality`"

tb <- bq_project_query(billing, sql)
bq_table_download(tb, max_results = 10)
```

(basically a line to ensure `bq_test_project()` succeeds)
First of all, thank you for the great package "bigrquery" !
I can run the code below in RStudio and from the console. But it gives me an error "Can't get Google credentials" when I try to run it via "crontab".

Here is the code

```r
# 1. Library
library(bigrquery)

# 2. Credentials
BQ_AUTH_PATH <- "file_name.json"
BQ_PROJECT_ID <- "project_id"

# 3. Auth to BQ via 'json' credentials
bq_auth(path = BQ_AUTH_PATH)

# 4. Define 'project_id'
project_id <- BQ_PROJECT_ID

# 5. Define SQL queries
sql <- "SELECT * FROM `Ads.cpm_data`"

# 5. Load data
query_exec(sql, project_id, use_legacy_sql = FALSE)
```
Please, advice me how to fix this issue.

Thanks

Andrii
Hello!

I have an error when try loading data to BigQuery into new table. 

`Error: Invalid JSON payload received. Unknown name "autodetect" at 'job.configuration.load': Proto field is not repeating, cannot start list. [invalid]`

If i load data into exist table i have't error.

## reprex

``` r
library(bigrquery)
library(magrittr)

bq_auth(path = "C:/my_develop_workshop/ppc_digest/token_bigquery/bq_service_key.json")

bq_table(project = "netpeak-1079",
         dataset = "concert_ua",
         table   = "mytable") %>%
  bq_table_upload(values = mtcars,
                  create_disposition = "CREATE_IF_NEEDED",
                  write_disposition = "WRITE_APPEND")
#> Error: Invalid JSON payload received. Unknown name "autodetect" at 'job.configuration.load': Proto field is not repeating, cannot start list. [invalid]
```

<sup>Created on 2019-11-14 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>

<details>

<summary>Session info</summary>

``` r
devtools::session_info()
#> - Session info ----------------------------------------------------------
#>  setting  value                       
#>  version  R version 3.5.3 (2019-03-11)
#>  os       Windows Server x64          
#>  system   x86_64, mingw32             
#>  ui       RTerm                       
#>  language (EN)                        
#>  collate  English_United States.1252  
#>  ctype    English_United States.1252  
#>  tz       Europe/Helsinki             
#>  date     2019-11-14                  
#> 
#> - Packages --------------------------------------------------------------
#>  package     * version    date       lib source                          
#>  askpass       1.1        2019-01-13 [1] CRAN (R 3.5.3)                  
#>  assertthat    0.2.1      2019-03-21 [1] CRAN (R 3.5.3)                  
#>  backports     1.1.5      2019-10-02 [1] CRAN (R 3.5.3)                  
#>  bigrquery   * 1.2.0.9000 2019-08-07 [1] Github (r-dbi/bigrquery@5f43228)
#>  bit           1.1-14     2018-05-29 [1] CRAN (R 3.5.2)                  
#>  bit64         0.9-7      2017-05-08 [1] CRAN (R 3.5.2)                  
#>  callr         3.2.0      2019-03-15 [1] CRAN (R 3.5.3)                  
#>  cli           1.1.0      2019-03-19 [1] CRAN (R 3.5.3)                  
#>  crayon        1.3.4      2017-09-16 [1] CRAN (R 3.5.3)                  
#>  curl          4.2        2019-09-24 [1] CRAN (R 3.5.3)                  
#>  DBI           1.0.0      2018-05-02 [1] CRAN (R 3.5.3)                  
#>  desc          1.2.0      2018-05-01 [1] CRAN (R 3.5.3)                  
#>  devtools      2.0.2      2019-04-08 [1] CRAN (R 3.5.3)                  
#>  digest        0.6.22     2019-10-21 [1] CRAN (R 3.5.3)                  
#>  evaluate      0.13       2019-02-12 [1] CRAN (R 3.5.3)                  
#>  fs            1.3.1      2019-05-06 [1] CRAN (R 3.5.3)                  
#>  gargle        0.4.0      2019-10-04 [1] CRAN (R 3.5.3)                  
#>  glue          1.3.1      2019-03-12 [1] CRAN (R 3.5.3)                  
#>  highr         0.8        2019-03-20 [1] CRAN (R 3.5.3)                  
#>  htmltools     0.3.6      2017-04-28 [1] CRAN (R 3.5.3)                  
#>  httr          1.4.1      2019-08-05 [1] CRAN (R 3.5.3)                  
#>  jsonlite      1.6        2018-12-07 [1] CRAN (R 3.5.3)                  
#>  knitr         1.23       2019-05-18 [1] CRAN (R 3.5.3)                  
#>  magrittr    * 1.5        2014-11-22 [1] CRAN (R 3.5.3)                  
#>  memoise       1.1.0      2017-04-21 [1] CRAN (R 3.5.3)                  
#>  openssl       1.4.1      2019-07-18 [1] CRAN (R 3.5.3)                  
#>  pillar        1.4.2      2019-06-29 [1] CRAN (R 3.5.3)                  
#>  pkgbuild      1.0.3      2019-03-20 [1] CRAN (R 3.5.3)                  
#>  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 3.5.3)                  
#>  pkgload       1.0.2      2018-10-29 [1] CRAN (R 3.5.3)                  
#>  prettyunits   1.0.2      2015-07-13 [1] CRAN (R 3.5.3)                  
#>  processx      3.3.1      2019-05-08 [1] CRAN (R 3.5.3)                  
#>  ps            1.3.0      2018-12-21 [1] CRAN (R 3.5.3)                  
#>  R6            2.4.0      2019-02-14 [1] CRAN (R 3.5.3)                  
#>  Rcpp          1.0.2      2019-07-25 [1] CRAN (R 3.5.3)                  
#>  remotes       2.0.4      2019-04-10 [1] CRAN (R 3.5.3)                  
#>  rlang         0.4.0      2019-06-25 [1] CRAN (R 3.5.3)                  
#>  rmarkdown     1.12       2019-03-14 [1] CRAN (R 3.5.3)                  
#>  rprojroot     1.3-2      2018-01-03 [1] CRAN (R 3.5.3)                  
#>  sessioninfo   1.1.1      2018-11-05 [1] CRAN (R 3.5.3)                  
#>  stringi       1.4.3      2019-03-12 [1] CRAN (R 3.5.3)                  
#>  stringr       1.4.0      2019-02-10 [1] CRAN (R 3.5.3)                  
#>  tibble        2.1.3      2019-06-06 [1] CRAN (R 3.5.3)                  
#>  usethis       1.5.0      2019-04-07 [1] CRAN (R 3.5.3)                  
#>  withr         2.1.2      2018-03-15 [1] CRAN (R 3.5.3)                  
#>  xfun          0.7        2019-05-14 [1] CRAN (R 3.5.3)                  
#>  yaml          2.2.0      2018-07-25 [1] CRAN (R 3.5.2)                  
#> 
#> [1] C:/Users/Alsey/Documents/R/win-library/3.5
#> [2] C:/Program Files/R/R-3.5.3/library
```

</details>

As default call GOOGLE_APPLICATION_CREDENTIALS var in bq_auth.
`bq_auth(path = Sys.getenv('GOOGLE_APPLICATION_CREDENTIALS'))`

As [google site](https://cloud.google.com/docs/authentication/getting-started#auth-cloud-implicit-python) recommends.
In case exists, I want to write_truncate data in a partition table.
And in case not, I want to create the table, with the partition column, and then write the data.
All using the same command.
Ideally, command should look like
```
out = bq_project_query(x = 'ds-billing',
                       query = "select cast('2019-10-10' as date) day,  7 n ",
                  destination_table = "ds-project.ds_project.test_5$20191010",
                 write_disposition = 'WRITE_TRUNCATE',
                 time_partitioning = list(field = 'day', type='DAY'))
bq_table_download(out)
```
But this **not work**.

If it  helps, in python
```
client.query(query = 
"select cast('2019-10-10' as date) day,  7 n "
,
job_config=bigquery.QueryJobConfig(destination="ds-project.ds_project.test_5$20191010",
write_disposition=bigquery.job.WriteDisposition.WRITE_TRUNCATE,
time_partitioning=bigquery.table.TimePartitioning(field="day"))
).to_dataframe()
```
**works**
I can successfully connect and download data from Google BigQuery using the bigrquery package.

`test <- dbTesting %>%
  tbl("px_testing7") %>% 
  collect()`

However, as soon as I add a verb (mutate, select, groupby+summarise...), I receive the following error message "Error: An internal error occurred and the request could not be completed. [internalError]". Examples:

`test <- dbTesting %>%
  tbl("px_testing7") %>% 
  mutate(newVar="newVal") %>%
  collect()`

Or

`test <- dbTesting %>%
  tbl("px_testing7") %>% 
  select(country_code) %>%
  collect()`

Using the most recent version of dbplyr and bigrquery installed through devtools in R.

The DDL statement "DROP TABLE IF EXISTS dataset.tablename" currently throws an error if the table does not exist.  The statement should drop the table if it doesn't exist and not error otherwise, as described in the [bigquery api documentation](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#examples_5):

> The DROP TABLE IF EXISTS DDL statement deletes a table in the specified dataset only if the table exists. If the table name does not exist in the dataset, no error is returned, and no action is taken.


---

Brief description of the problem:

```r
  query <- "
    DROP TABLE IF EXISTS dataset.table_that_does_not_exist
  "
  
  query_exec(
    project = project,
    query = query,
    use_legacy_sql = FALSE
  )
```

(I think)
I've been running a query that fails trying convert between the R data type and the BQ data type:
```
## Create test table
library(bigrquery)
library(stringr)
library(DBI)
library(dplyr)

project_id <- "my-project-id
dataset_id <- "my-test_dataset"

ds <- bq_dataset(project = project_id,
                 dataset = dataset_id)

if(!bq_dataset_exists(ds))
  bigrquery::bq_dataset_create(ds)

con <- dbConnect(bigrquery::bigquery(), 
                 project = project_id,
                 use_legacy_sql = FALSE, 
                 dataset = dataset_id)

dbExecute(
  con, 
  str_interp(
    "
  CREATE TABLE IF NOT EXISTS `${project_id}.${dataset_id}.iris`
        (
      	Sepal_Length NUMERIC,
	      Sepal_Width NUMERIC,
	      Petal_Length NUMERIC,
	      Petal_Width STRING,  # Intentionally incorrect
	      Species STRING
        )
      "
  )
)

## Attempt to write data with mismatched types

iris_dat <- iris
colnames(iris_dat) <- gsub("\\.", "_", colnames(iris_dat)) # rename columns to match db table

try(
  dbWriteTable(con, str_interp("${project_id}.${dataset_id}.iris"), iris_dat, append=TRUE)
)
#
# Running job 'XXXXXXXX.job_0bjYLFBQgvgF2EyvP7Suu6CN-3vu.US' [|]  1s
# Error: Error while reading data, error message: JSON table encountered too many errors, 
#   giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more 
#   details. [invalid]
#
```

The displayed error message is not very helpful, since it does not describe how to access the "errors[] collection".

Ideally, the error handler in `bigrquery` would extract and display the "errors[] collection" for the user, a-là:

```
job_meta <- bq_job(
  project = project_id,
  job = "job_0bjYLFBQgvgF2EyvP7Suu6CN-3vu", 
  location = "US") %>% 
  bq_job_meta()

bind_rows(job_meta$status$errors)
#
# # A tibble: 3 x 2
# reason  message                                                                                                                                         
# <chr>   <chr>                                                                                                                                           
#   1 invalid Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] c…
#   2 invalid Error while reading data, error message: JSON processing encountered too many errors, giving up. Rows: 1; errors: 1; max bad: 0; error percent:…
#   3 invalid Error while reading data, error message: JSON parsing error in row starting at position 0: Could not convert value to string. Field: Petal_Widt…
#
```

---------------
OS Version:
```
Ubuntu 18.04.2 LTS
```

R version:
```               _                           
platform       x86_64-pc-linux-gnu         
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
status                                     
major          3                           
minor          6.0                         
year           2019                        
month          04                          
day            26                          
svn rev        76424                       
language       R                           
version.string R version 3.6.0 (2019-04-26)
nickname       Planting of a Tree          
```

Package versions:
```
DBI                 DBI      1.0.0                                  /usr/local/lib/R/site-library/DBI          4
stringr         stringr      1.4.0                                    /usr/lib/R/site-library/stringr          5
dplyr             dplyr      0.8.1                                      /usr/lib/R/site-library/dplyr         15
bigrquery     bigrquery 1.2.0.9000                            /usr/local/lib/R/site-library/bigrquery         17
```




bigrquery is unable to download tables with column type: 'BYTE'.

**query** 
select sha1('abc') 
**error** 
Error in bq_parse_files(schema_path, page_paths, n = page_info$n_rows,  : 
  Unknown type BYTES