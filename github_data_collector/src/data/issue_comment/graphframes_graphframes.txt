I am trying to use the `bfs` function inside pyspark. However, passing a column to `fromExpr` and `toExpr` results in `TypeError: Column is not iterable`.

My python code looks like this:

```python
from pyspark.sql import SparkSession
from graphframes import GraphFrame

spark = SparkSession.builder.appName("graph").getOrCreate()

spark.read \
     .parquet('data.parquet') \
     .createOrReplaceTempView('data')
data = spark.table('data')

sc.setCheckpointDir("/tmp/chk")
vertices = data.select('id', 'type')
edges = data.select(
    data.id.alias('src'),
    data.parent_id.alias('dst'),
)
graph = GraphFrame(vertices, edges)
start = some_vertex ...
paths = graph.bfs(vertices.id == start, vertices.type == 0)
```

which results in

```
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/tmp/spark-317abced-7449-4908-ac59-0f946fc223a7/userFiles-166b16e4-b3eb-444f-b882-7604b700ae14/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar/graphframes/graphframe.py", line 248, in bfs
  File "/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1151, in __call__
  File "/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1115, in _build_args
  File "/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1102, in _get_args
  File "/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip/py4j/java_collections.py", line 500, in convert
  File "/usr/hdp/current/spark2-client/python/pyspark/sql/column.py", line 345, in __iter__
    raise TypeError("Column is not iterable")
TypeError: Column is not iterable
```

However, the following code in scala works fine:

```scala
import org.graphframes._
import org.graphframes.GraphFrame

spark.read.parquet("data.parquet").createOrReplaceTempView("data")
data = spark.table("data")

sc.setCheckpointDir("/tmp/chk")
val vertices = data.select("id", "type")
val edges = data.select(data("id").alias("src"), data("parent_id").alias("dst"))
val graph = GraphFrame(vertices, edges)
val start = some_vertex ...
val paths = graph.bfs.fromExpr(vertices("id") === start).toExpr(vertices("type") === 0).run()
```

It looks to me like the python types are not correctly translated to java types.

## System Information

spark: version 2.3.0.2.6.5.0-292
scala: version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_77)
python: version 3.4.9
graphframes: 0.6.0-spark2.3-s_2.11
os: CentOS Linux release 7.5.1804 (Core)


Fix download_travis_dependencies.
We should enter cache dir first and then remove old tarball/spark_home_dir.

Build against spark 3.0 Preview release
Removes a count and log statement that have negative performance impacts and result only in some logging.
These lines in Connected Components are only used for logging and the computation of the count can be rather expensive:

```
    val numEdges = ee.count()
    logInfo(s"$logPrefix Found $numEdges edges after preparation.")
```

I'd like to use GraphFrames with java in my maven project.

in the official documentation they said that APIs are provided for scala, python and JAVA: https://graphframes.github.io/graphframes/docs/_site/index.html

but in real I find only APIs for scala and python!

so my question is: can I realy use GraphFrames with java ?
We have to update Spark patch version since **there are no 2.3.2 and 2.4.0 at mirror site**. In the meantime, I update sbt and sbt-plugins' patch version. 
I'd like to install graphframes 0.7.0 via pip but looks like that version isn't up on pypi. Is that going to happen?
So I followed the instructions of downloading the jar file, extracting, then zipping and adding the zip file to the `PYTHONPATH` as I can `import graphframes` without issue both from PySpark REPL and within iPython. But the minute I try to call ` GraphFrame(vertices, edges)` I get the following error from iPython when going through this script

```python
from functools import reduce
from pyspark.sql.functions import col, lit, when
from graphframes import *
from pyspark import SparkConf, SparkContext
from pyspark.sql import SQLContext

conf = SparkConf().setAppName("Log Analyzer")
sc = SparkContext(conf=conf)
sqlContext = SQLContext(sc)

vertices = sqlContext.createDataFrame([
    ("a", "Alice", 34),
    ("b", "Bob", 36),
    ("c", "Charlie", 30),
    ("d", "David", 29),
    ("e", "Esther", 32),
    ("f", "Fanny", 36),
    ("g", "Gabby", 60)], ["id", "name", "age"])

edges = sqlContext.createDataFrame([
    ("a", "b", "friend"),
    ("b", "c", "follow"),
    ("c", "b", "follow"),
    ("f", "c", "follow"),
    ("e", "f", "follow"),
    ("e", "d", "friend"),
    ("d", "a", "friend"),
    ("a", "e", "friend")
    ], ["src", "dst", "relationship"])

g = GraphFrame(vertices, edges)
print(g)
```
```python
Py4JJavaError                             Traceback (most recent call last)
<ipython-input-10-2baffb542980> in <module>
----> 1 g = GraphFrame(v,e)

~/Downloads/graphframes.zip/graphframes/graphframe.py in __init__(self, v, e)
     66         self._sqlContext = v.sql_ctx
     67         self._sc = self._sqlContext._sc
---> 68         self._jvm_gf_api = _java_api(self._sc)
     69 
     70         self.ID = self._jvm_gf_api.ID()

~/Downloads/graphframes.zip/graphframes/graphframe.py in _java_api(jsc)
     39 def _java_api(jsc):
     40     javaClassName = "org.graphframes.GraphFramePythonAPI"
---> 41     return jsc._jvm.Thread.currentThread().getContextClassLoader().loadClass(javaClassName) \
     42             .newInstance()
     43 

/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py in __call__(self, *args)
   1255         answer = self.gateway_client.send_command(command)
   1256         return_value = get_return_value(
-> 1257             answer, self.gateway_client, self.target_id, self.name)
   1258 
   1259         for temp_arg in temp_args:

/usr/local/lib/python3.7/site-packages/pyspark/sql/utils.py in deco(*a, **kw)
     61     def deco(*a, **kw):
     62         try:
---> 63             return f(*a, **kw)
     64         except py4j.protocol.Py4JJavaError as e:
     65             s = e.java_exception.toString()

/usr/local/lib/python3.7/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
    326                 raise Py4JJavaError(
    327                     "An error occurred while calling {0}{1}{2}.\n".
--> 328                     format(target_id, ".", name), value)
    329             else:
    330                 raise Py4JError(

Py4JJavaError: An error occurred while calling o53.loadClass.
: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:436)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:588)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:567)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:835)
```
So it looks like this is an issue loading a java class. Probably has to do with path. 

However, when I go through the steps of the quickstart after running `pyspark --packages graphframes:graphframes:0.7.0-spark2.4-s_2.11` (I've got the same zip file added to PYTHONPATH for both) I get the following error.

```java
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/private/var/folders/ff/1psxrlmd7w3ggbm81vngf5xw0000gn/T/spark-531b2515-5969-4010-b679-317fbd43c641/userFiles-95233dd4-0b75-4459-832e-4a9f383eb641/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar/graphframes/graphframe.py", line 89, in __init__
  File "/Users/twoo27/Downloads/spark-2.4.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/Users/twoo27/Downloads/spark-2.4.2-bin-hadoop2.7/python/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/Users/twoo27/Downloads/spark-2.4.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o65.createGraph.
: java.lang.NoSuchMethodError: scala.Predef$.refArrayOps([Ljava/lang/Object;)Lscala/collection/mutable/ArrayOps;
	at org.graphframes.GraphFrame$.apply(GraphFrame.scala:676)
	at org.graphframes.GraphFramePythonAPI.createGraph(GraphFramePythonAPI.scala:10)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:567)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:835)
```