I am implementing a custom recurrent class that inherits tf.layers.Layer, when using the Bidirectional wrapper I get the error:

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-3-7bd5b5269810> in <module>
----> 1 a = TimeDistributed(Bidirectional(char_recurrent_cell))

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/wrappers.py in __init__(self, layer, merge_mode, weights, backward_layer, **kwargs)
    434     if backward_layer is None:
    435       self.backward_layer = self._recreate_layer_from_config(
--> 436           layer, go_backwards=True)
    437     else:
    438       self.backward_layer = backward_layer

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/wrappers.py in _recreate_layer_from_config(self, layer, go_backwards)
    493     config = layer.get_config()
    494     if go_backwards:
--> 495       config['go_backwards'] = not config['go_backwards']
    496     if 'custom_objects' in tf_inspect.getfullargspec(
    497         layer.__class__.from_config).args:

KeyError: 'go_backwards'
```
This is the code for the layer itself:

```
class RecurrentConfig(BaseLayer):
    '''Basic configurable recurrent layer'''
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.layers: List[layers.Layer] = stack_layers(self.params,
                                                       self.num_layers,
                                                       self.layer_name)

    def call(self, inputs: np.ndarray) -> layers.Layer:
        '''This function is a sequential/functional call to this layers logic
        Args:
            inputs: Array to be processed within this layer
        Returns:
            inputs processed through this layer'''
        processed = inputs
        for layer in self.layers:
            processed = layer(processed)
        return processed

    @staticmethod
    def default_params() -> Dict[Any, Any]:
        return{
            'units': 32,
            'recurrent_initializer': 'glorot_uniform',
            'dropout': 0,
            'recurrent_dropout': 0,
            'activation': None,
            'return_sequences': True
        }
```

I have attempted to add the go_backwards to the config that is retrieved when get_config() is called but this results in another error:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-7bd5b5269810> in <module>
----> 1 a = TimeDistributed(Bidirectional(char_recurrent_cell))

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/wrappers.py in __init__(self, layer, merge_mode, weights, backward_layer, **kwargs)
    430     # Recreate the forward layer from the original layer config, so that it will
    431     # not carry over any state from the layer.
--> 432     self.forward_layer = self._recreate_layer_from_config(layer)
    433 
    434     if backward_layer is None:

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/wrappers.py in _recreate_layer_from_config(self, layer, go_backwards)
    506       return layer.__class__.from_config(config, custom_objects=custom_objects)
    507     else:
--> 508       return layer.__class__.from_config(config)
    509 
    510   @tf_utils.shape_type_conversion

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in from_config(cls, config)
    517         A layer instance.
    518     """
--> 519     return cls(**config)
    520 
    521   def compute_output_shape(self, input_shape):

~/nlpv3-general/nlp-lib/src/main/python/mosaix_py/mosaix_learn/layers/recurrent_layers.py in __init__(self, *args, **kwargs)
     12     '''Basic configurable recurrent layer'''
     13     def __init__(self, *args, **kwargs):
---> 14         super().__init__(*args, **kwargs)
     15         self.layers: List[layers.Layer] = stack_layers(self.params,
     16                                                        self.num_layers,

~/nlpv3-general/nlp-lib/src/main/python/mosaix_py/mosaix_learn/layers/base_layer.py in __init__(self, params, mode, layer_name, num_layers, cust_name, **kwargs)
     17                  cust_name: str = '',
     18                  **kwargs):
---> 19         super().__init__(params, mode, **kwargs)
     20         self.layer_name = layer_name
     21         self.cust_name = cust_name

~/nlpv3-general/nlp-lib/src/main/python/mosaix_py/mosaix_learn/configurable.py in __init__(self, params, mode, **kwargs)
     61 
     62     def __init__(self, params: Dict[AnyStr, Any], mode: ModeKeys, **kwargs):
---> 63         super().__init__(**kwargs) #type: ignore
     64         self._params = _parse_params(params, self.default_params())
     65         self._mode = mode

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __init__(self, trainable, name, dtype, dynamic, **kwargs)
    184     }
    185     # Validate optional keyword arguments.
--> 186     generic_utils.validate_kwargs(kwargs, allowed_kwargs)
    187 
    188     # Mutable properties

~/opt/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py in validate_kwargs(kwargs, allowed_kwargs, error_message)
    716   for kwarg in kwargs:
    717     if kwarg not in allowed_kwargs:
--> 718       raise TypeError(error_message, kwarg)

TypeError: ('Keyword argument not understood:', 'go_backwards')
```

Version info is:
tf_version: '2.1.0-dev20191125'
git_version: 'v1.12.1-19144-gf39f4ea3fa'
The [keras.applications](https://github.com/keras-team/keras-applications) module has been splitted from the main Keras repository.

Please submit your issue using this [link](https://github.com/keras-team/keras-applications/issues/new).

Thank you!

<em>Training a model that have a lot of outputs causes my keras to freeze, using 'use_multiprocessing=True' in fit it become freezes less(probably), but still freezes, i believe there is a problem in keras, i train it on data of size 2048 for 1 epoch for multiple times (reinforcement learning), it freezes randomly it freezes after few times of training but sometimes it takes thousands </em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.0/2.1
- Keras version:  2.3.0
- Python version:  3.7.2
- CUDA/cuDNN version:  CUDA 10.1/cuDNN 7.6.4 (tested also with CUDA 10)
- GPU model and memory:  GTX 1070 8 gb memory

**Describe the current behavior**  
My model freeze randomly during training. when i use a model with alot of multiple layers (9 in my case)

**Describe the expected behavior**  
it don't freeze ?

**Code to reproduce the issue**  
```
	dims = [8,64,150,80,30,9]
	input_layer = Input(shape=(dims[0],))

	hidden = Dense(dims[1],activation='relu')(input_layer)
	hidden = Dense(dims[2],activation='relu')(hidden)
	hidden = Dense(dims[3],activation='relu')(hidden)

	policy = []
	for i in range(dims[-1]):
		hiddenl = Dense(dims[-2],activation='relu')(hidden)
		policy.append( Dense(n_atoms,activation='softmax')(hiddenl) )

	rmodel = Model(inputs=input_layer, outputs=policy)
	rmodel.compile(loss=['categorical_crossentropy']*9, optimizer=Adam(lr=lr,decay=decay))
	return rmodel
```

**Other info / logs**  
`can't provide any other infos python don't display any errors` 

<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):   google colab
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.1.0-rc1
- Keras version:  2.2.5
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
The code `model.layers.pop(0)`
doesn't pop the input layer as expected, it still shows the input layer in summary

Model: "inception_v3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 450, 450, 3) 0                                            
__________________________________________________________________________________________________

**Describe the expected behavior**  
This issue is not present in Tensorflow 1.x with keras,  that works as expected

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

```
%tensorflow_version 2.x
from tensorflow.keras.applications.inception_v3 import InceptionV3
base_model = InceptionV3(weights= 'imagenet', include_top=False, input_shape= (450,450,3))
base_model.layers.pop(0)
base_model.summary()

```

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

Some lines in the **_code_** block of the keras docs is too long, the result of which is, there will be a horizonal scroll bar at the bottom of the **_code_** block. That is hard to read. The long lines should be rearranged to multiple short lines to improve readibility.

Example:
The docs for the SimpleRNN class (https://keras.io/layers/recurrent/#simplernn). The initializer of SimpleRNN has many arguments, but the docs put them in just a single long line. That makes it very hard to read. 
![docs line too long](https://user-images.githubusercontent.com/1805467/72451447-ea438f00-37f6-11ea-859b-d5427e444239.JPG)

The single long line should be rearranged to multiple short lines, just like what was did in the source code for the __init__ function of SimpleRNN.

![short lines](https://user-images.githubusercontent.com/1805467/72451555-119a5c00-37f7-11ea-8a41-811d29b52208.JPG)


I'm trying to pass the output of a CNN model as an input to LSTM. 
I'm currently working with videos. The array of each frame of the video is passed to a CNN model and the output is a vector array.  
I want to divide the output of CNN into a sequence of size 9 and pass it as an input to LSTM. I can't seem to figure it out how to divide the output of CNN into a sequence of size 9. I tried to use reshape but it didn't work.

Here's my current cnn model:

```
inp = Input(shape=(360,640,1))
norm_inp = BatchNormalization()(inp)
img_1 = Convolution2D(4, kernel_size=2, activation=activations.relu)(norm_inp)
img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)
img_1 = Dropout(rate=0.2)(img_1)
img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)
img_1 = MaxPooling2D(pool_size=(4, 4))(img_1)
img_1 = Dropout(rate=0.2)(img_1)
img_1 = Convolution2D(4, kernel_size=4, activation=activations.relu)(img_1)
img_1 = MaxPooling2D(pool_size=(4, 4))(img_1)
img_1 = Dropout(rate=0.2)(img_1)
img_1 = Flatten()(img_1)
dense_1 = BatchNormalization()(Dense(16, activation=activations.relu)(img_1))
# dense_1 = Dense(2, activation='softmax')(dense_1)
cnn2 = models.Model(inputs=inp, outputs=dense_1)
cnn2.summary()
```

I want the input to input to LSTM to be of shape (9,16)

Can someone help me with this please?
### Summary

Hi!


[Optuna]( (optuna.org) ) is a new hyperparameter optimization library, and we’ve written an integration module for Keras to make it easy to use Optuna to search for good hyperparameter settings and prune unpromising trials. We’re looking for ways to let Keras users know this is available and thought a badge to show Optuna integration is available would be helpful.

Here’s our example of using the pruning integration with Keras: https://github.com/optuna/optuna/blob/master/examples/pruning/keras_integration.py

If there are other ways you would recommend reaching out to Keras users to let them know about Optuna, please let us know.

Thanks!

### Related Issues

None

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [n] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)

<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory): Yes I have Written Custom code 
- OS Platform and Distribution (windows 10):  
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.0
- Keras version:  2.2.4
- Python version:  3.6
- CUDA/cuDNN version:  
- GPU model and memory:  geforce gtx 1070, 4gb

You can obtain the TensorFlow version with:  
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
I am trying to write a code to classify dicom Head CT images as "Hemorrhage" and "normal"

I have copied a code using theano backend and turned it into a tensorflow code, but when i try to run the code, it returns: 

"AttributeError: 'ProgbarLogger' object has no attribute 'log_values'"

I searched the internet and github, it seems the problem is because of "batch size" being bigger than the validation sample size.
So i changed batch size from 16 to 4, 8 and 2 and the same issue came out.
I increased my validation positive and negative sample size from 8 to 16 (32 in total) and nothing happened.

Also note that, the network trained on theano backend but i wanted to use GPU so i had to change it to tensorflow. 

So here are the codes;

The traceback code: 

```
Reading validation images
Reading image IMG-0043-00001.dcm from VldPoz
Reading image IMG-0068-00001.dcm from VldPoz
Reading image IMG-0069-00001.dcm from VldPoz
Reading image IMG-0070-00001.dcm from VldPoz
Reading image IMG-0071-00001.dcm from VldPoz
Reading image IMG-0072-00001.dcm from VldPoz
Reading image IMG-0073-00001.dcm from VldPoz
Reading image IMG-0074-00001.dcm from VldPoz
Reading image IMG-0087-00001.dcm from VldPoz
Reading image IMG-0093-00001.dcm from VldPoz
Reading image IMG-0111-00001.dcm from VldPoz
Reading image IMG-0112-00001.dcm from VldPoz
Reading image IMG-0116-00001.dcm from VldPoz
Reading image IMG-0184-00001.dcm from VldPoz
Reading image IMG-0204-00001.dcm from VldPoz
Reading image IMG-0220-00001.dcm from VldPoz
Reading image IMG-0002-00011.dcm from VldNeg
Reading image IMG-0002-00013.dcm from VldNeg
Reading image IMG-0003-00004.dcm from VldNeg
Reading image IMG-0003-00015.dcm from VldNeg
Reading image IMG-0003-00020.dcm from VldNeg
Reading image IMG-0003-00027.dcm from VldNeg
Reading image IMG-0061-00001.dcm from VldNeg
Reading image IMG-0062-00001.dcm from VldNeg
Reading image IMG-0162-00001.dcm from VldNeg
Reading image IMG-0163-00001.dcm from VldNeg
Reading image IMG-0164-00001.dcm from VldNeg
Reading image IMG-0165-00001.dcm from VldNeg
Reading image IMG-0166-00001.dcm from VldNeg
Reading image IMG-0167-00001.dcm from VldNeg
Reading image IMG-0168-00001.dcm from VldNeg
Reading image IMG-0169-00001.dcm from VldNeg
Reading image IMG-0113-00001.dcm from EgtPoz
Reading image IMG-0024-00001.dcm from EgtNeg
Reading image IMG-0114-00001.dcm from EgtPoz
Reading image IMG-0025-00001.dcm from EgtNeg
Train on 4 samples, validate on 32 samples

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in on_epoch(self, epoch, mode)
    680     try:
--> 681       yield epoch_logs
    682     finally:

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    120     with training_context.on_batch(
--> 121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:

~\Anaconda3\envs\tf_gpu\lib\contextlib.py in __enter__(self)
     80         try:
---> 81             return next(self.gen)
     82         except StopIteration:

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in on_batch(self, step, mode, size)
    692     self.callbacks._call_batch_hook(
--> 693         mode, 'begin', step, batch_logs)
    694     self.progbar.on_batch_begin(step, batch_logs)

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
    233     for callback in self.callbacks:
--> 234       batch_hook = getattr(callback, hook_name)
    235       batch_hook(batch, logs)

AttributeError: 'CSVLogger' object has no attribute 'on_train_batch_begin'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-30-dda50fbeae29> in <module>
     12     y = labels, epochs = 1,
     13     validation_data = (valImages.reshape(32,512,512,1), valLabels),
---> 14     callbacks = [ayirgac_log])

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    370                       total_epochs=1)
    371                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,
--> 372                                  prefix='val_')
    373 
    374     return model.history

~\Anaconda3\envs\tf_gpu\lib\contextlib.py in __exit__(self, type, value, traceback)
     97                 value = type()
     98             try:
---> 99                 self.gen.throw(type, value, traceback)
    100             except StopIteration as exc:
    101                 # Suppress StopIteration *unless* it's the same exception that

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in on_epoch(self, epoch, mode)
    684         # Epochs only apply to `fit`.
    685         self.callbacks.on_epoch_end(epoch, epoch_logs)
--> 686       self.progbar.on_epoch_end(epoch, epoch_logs)
    687 
    688   @tf_contextlib.contextmanager

~\Anaconda3\envs\tf_gpu\lib\site-packages\tensorflow_core\python\keras\callbacks.py in on_epoch_end(self, epoch, logs)
    766         self.log_values.append((k, logs[k]))
    767     if self.verbose:
--> 768       self.progbar.update(self.seen, self.log_values)
    769 
    770 

AttributeError: 'ProgbarLogger' object has no attribute 'log_values'
```


This one is where i store my functions to read and store train, validation and test images (the batchSize is  defined in this code)


```
from skimage import exposure
import os
import pydicom
import math
import random
import numpy
import matplotlib.pyplot as plt
import time

def imageCount(dirName):
   

    for root, dir, files in os.walk("F:\\Head_CT_Kanama_Series\\" + dirName):
        scans = [file  for file in files if file != "desktop.ini"]
        return len(scans)
    print(dirName + " is not a valid directory")
    exit(-1)
    

def readScan(scanNum, dirName):
  

    for root, dir, files in os.walk("F:\\Head_CT_Kanama_Series\\" + dirName):
        scans = [file  for file in files if file != "desktop.ini"]
        print("Reading image " + scans[scanNum] + " from " + dirName)
        data = pydicom.dcmread("F:\\Head_CT_Kanama_Series\\" + dirName + "/" + scans[scanNum],)
        data = data.pixel_array
        #plt.imshow(data, cmap=plt.cm.binary)
        #plt.show()
        data = exposure.equalize_adapthist(data)        
        #plt.imshow(data)
        #plt.show()
        return data
    print(dirName + " is not a valid directory")
    exit(-1)
    
def readValidationImages():

    labels = []
    patientData = []
    
    for i in range(0,imageCount("VldPoz")):
        data = readScan(i, "VldPoz")
        labels.append(1)
        patientData.append(data)
    for i in range(0,imageCount("VldNeg")):
        data = readScan(i, "VldNeg")
        labels.append(0)
        patientData.append(data)

    patientData = numpy.stack(patientData).astype(float)

    return patientData, numpy.stack(labels)

def readBatch(batchSize):

    labels = []
    patientData = []
    
    posLen = imageCount("EgtPoz") #deneme amacıyla kanamapoz, ilerde egitimPoz ile degistirilecek
    negLen = imageCount("EgtNeg") #deneme amacıyla kanamaneg, ilerde egitimNeg ile degistirilecek

    posStart = random.randint(0,(posLen- (batchSize//2)) - 1)
    negStart = random.randint(0,(negLen- (batchSize//2)) - 1)

    for i in range(batchSize //2):
        data = readScan(posStart + i, "EgtPoz")
        labels.append(1)
        patientData.append(data)
        data = readScan(negStart + i, "EgtNeg")
        labels.append(0)
        patientData.append(data)
    
    patientData = numpy.stack(patientData).astype(float)
    return patientData, numpy.stack(labels)

def normReadAll():
    
    labels = []
    patientData = []
    
    posLen = imageCount("EgtPoz") #egtpoz olarak değişecek
    negLen = imageCount("EgtNeg") #egtneg olarak değişecek

    for i in range(posLen):
        data = readScan(i, "EgtPoz")
        labels.append(1)
        data = exposure.equalize_adapthist(data)        
        patientData.append(data)
    for i in range(negLen):
        data = readScan(i, "EgtNeg")
        labels.append(0)
        data = exposure.equalize_adapthist(data)        
        patientData.append(data)
    
    patientData = numpy.stack(patientData).astype(float)
    return patientData, numpy.stack(labels)

def readTest():

    labels = []
    patientData = []
    
    posLen = imageCount("TestPoz")#testpoz olarak değişecek
    negLen = imageCount("TestNeg")#testpoz olarak değişecek

    for i in range(posLen):
        data = readScan(i, "TestPoz")
        labels.append(1)
        data = exposure.equalize_adapthist(data)        
        patientData.append(data)
    for i in range(negLen):
        data = readScan(i, "TestNeg")
        labels.append(0)
        data = exposure.equalize_adapthist(data)        
        patientData.append(data)
    
    patientData = numpy.stack(patientData).astype(float)
    return patientData, numpy.stack(labels)
```

And here, i define and train the model;

```
import tensorflow as tf
import matplotlib.pyplot as plt
import argparse
import math
import random
import keras
import sys
import numpy
from CT_dataloader import imageCount, readScan, readValidationImages, readBatch, readTest
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten, MaxPooling2D 
from tensorflow.keras import optimizers
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras import backend

model = Sequential()
model.add(Conv2D(16, 15, input_shape=(512,512,1)))
model.add(MaxPooling2D(pool_size=(4)))
model.add(Conv2D(16,7))
model.add(Activation('tanh'))
model.add(BatchNormalization())
model.add(Conv2D(16,7))
model.add(Activation('tanh'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(4)))
model.add(Conv2D(16,3))
model.add(Activation('tanh'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(4)))
model.add(Flatten())
model.add(Dense(16))
model.add(Activation('tanh'))
model.add(BatchNormalization())
model.add(Dense(1))
model.add(Activation('tanh'))

model.compile(loss="mean_squared_error",
            optimizer=optimizers.SGD(lr = .01),
            metrics=['accuracy'])

ayirgac_log = keras.callbacks.CSVLogger("KerasLog.csv", append = True)

print("Reading validation images")

batchSize = 4 
valImages, valLabels = readValidationImages()
        
bestLoss = float('inf')

for i in range(20):
    batch, labels = readBatch(batchSize)

    history = model.fit(x = batch.reshape(batchSize,512,512,1), 
    y = labels, epochs = 1,
    validation_data = (valImages.reshape(32,512,512,1), valLabels),
    callbacks = [ayirgac_log])
```



**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

**System information**  
- Have I written custom code (as opposed to using example directory):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Arch Linux
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  1.15.0 (also with tf2.0.0)
- Keras version:  2.2.4 (also with tf2.keras)
- Python version:  3.7.5
- CUDA/cuDNN version:  -
- GPU model and memory:  -

**Describe the current behavior**
Output for original model and its loaded from h5-file copy differ.

**Describe the expected behavior**
Output of both models expected to be the same.

**MWE:**
```
from keras.models import Model
from keras.layers import Input, Lambda
from keras.models import load_model
import numpy as np

def build_model(sz=2):
    input_x = Input(shape=(sz, 1))
    sliced_x = [Lambda(lambda x: x[:,j])(input_x) for j in range(sz)]
    model = Model(inputs=input_x, outputs=sliced_x)
    return model


m = build_model()
m.save('m.h5')
m_copy = load_model('m.h5')

data = np.array([[[1], [2]]])
print(m.predict(data))
print(m_copy.predict(data))
```
Outputs differ from each other:
```
[array([[1.]], dtype=float32), array([[2.]], dtype=float32)]
[array([[2.]], dtype=float32), array([[2.]], dtype=float32)]
```
The problem goes away if `sliced_x` is redefined in the following way:
```
sliced_x = [Lambda(lambda x,i: x[:,i], arguments={'i':j})(input_x) 
             for j in range(sz)]
```
However, original definition seems to be more natural.
I do believe this issue is somehow related to python lambda-function closures.



**System information**  
- Have I written custom code (as opposed to using example directory):  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  CentOS
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.14.0
- Keras version:  2.3.1
- Python version:  3.6
- CUDA/cuDNN version:   CUDA-10.0
- GPU model and memory: Not a problem.  
------------------------------------------------------------------------------------

modelA and modelB are two models with same structure.

modelA input shape: (None, dim1, dim2, None)
modelB input shape: (None, dim1, dim2, None)

the last dim is timestep so we can set it to None. 

To merge this two models into one, I'd like to run the following code:
```python
modelA = load_model(modelApath)
modelB = load_model(modelBpath)

new_input = Input((dim1,dim2,2000)) # I want a fixed timestep now, say 2000

## reset layer names to avoid name conflicts
for layer in modelA.layers:
    layer.name = "A_" + layer.name
for layer in modelB.layers:
    layer.name = "B_"+layer.name

modelA.name = "A"
mdoelB.name = "B"

out1 = modelA(new_input)
out2 = modelB(new_input)

new_model = Model([new_input], [out1,out2])

res = new_model.predict(feat) # will print correct result
new_model.save("new_model.h5") #save to local
```

Looks perfect.

But if I want to save the model to disk and reuse it, I'll get an error

```python
model = load_model("new_model.h5") # raise exception
model.summary()
```
Whole traceback

```traceback
Traceback (most recent call last):
  File "generate_new_model.py", line 75, in <module>
    model_new = load_model("new_model.h5")
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py", line 492, in load_wrapper
    return load_function(*args, **kwargs)
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py", line 584, in load_model
    model = _deserialize_model(h5dict, custom_objects, compile)
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py", line 274, in _deserialize_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py", line 627, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/layers/__init__.py", line 168, in deserialize
    printable_module_name='layer')
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 147, in deserialize_keras_object
    list(custom_objects.items())))
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/network.py", line 1075, in from_config
    process_node(layer, node_data)
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/network.py", line 1025, in process_node
    layer(unpack_singleton(input_tensors), **kwargs)
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py", line 506, in __call__
    output_shape = self.compute_output_shape(input_shape)
  File "/data1/moyanzitto/anaconda3/lib/python3.6/site-packages/keras/engine/network.py", line 612, in compute_output_shape
    str(len(self._input_layers)) + ' tensor inputs.')
ValueError: Invalid input_shape argument (None, 1, 39, 2000): model has 0 tensor inputs.
```
I think it's a bug.



