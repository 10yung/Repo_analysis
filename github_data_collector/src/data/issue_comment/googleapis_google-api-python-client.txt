So right now I'm using your library with multiple threads.
Due to the fact that httplib2 is not thread safe I tried to use your examples.
``` python
# Create a new Http() object for every request
def build_request(http, *args, **kwargs):
  new_http = httplib2.Http()
  return apiclient.http.HttpRequest(new_http, *args, **kwargs)
service = build('api_name', 'api_version', requestBuilder=build_request)

# Pass in a new Http() manually for every request
service = build('api_name', 'api_version')
http = httplib2.Http()
service.stamps().list().execute(http=http)
```

But either way I have the problem that the threads are not authenticated. In the documentation is nothing like this mentioned.
I tried just building an own `httplib2.Http()` object for every thread at the beginning of it and also tried the approach of overriding the default `requestBuilder` of the service which I used across all threads but nothing worked due to authentification issues.

In the end it worked for me that I just executed the following `authenticate_and_build_service()` function for every thread. This function basically return a new `service` object via the `build('drive', 'v3', credentials=creds)`.

``` python
def authenticate_and_build_service():
    # If modifying these scopes, delete the file server_token.pickle.
    scopes = ['https://www.googleapis.com/auth/drive']

    creds = None
    # The file server_token.pickle stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    if os.path.exists('server_token.pickle'):
        with open('server_token.pickle', 'rb') as token:
            creds = pickle.load(token)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'server_credentials.json', scopes)
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open('server_token.pickle', 'wb') as token:
            pickle.dump(creds, token)

    return build('drive', 'v3', credentials=creds)
```

Nevertheless I'm not sure if it has any downsides of building a `service` object for every thread and it would be nice if someone could comment on this and maybe even update the documentation.

I also didn't find a way in the `execute()` function to specify credentials.
I'm trying to upload files to Google Drive but the problem is even if I configured the offline access I can't get the access after the access_token is expired.

From here: https://google-auth.readthedocs.io/en/latest/user-guide.html#user-credentials

> If you obtain a refresh token, you can also specify the refresh token and token URI to allow the credentials to be automatically refreshed:
> 
> credentials = google.oauth2.credentials.Credentials(
>     'access_token',
>     refresh_token='refresh_token',
>     token_uri='token_uri',
>     client_id='client_id',
>     client_secret='client_secret')

#### Environment details

  - OS: Win 7
  - Python version: Python 3.6.8
  - pip version: pip 19.3.1
  - `google-api-python-client` version: 1.7.11

#### Steps to reproduce
When I configure the obtaining consent from the user I do this code:

`this.googleAuth.grantOfflineAccess() // Obtain the auth code`

This code I will change to the tokens:

```
from oauth2client import client
    json_path = os.path.join(static_folder_path, "client_secrets.json")
    credentials = None
    try:
        credentials = client.credentials_from_clientsecrets_and_code(
            json_path,
            scopes,
            auth_code)
    except Exception as ex:
        print(ex)
        return None
    return {
        'access_token': credentials.access_token,
        'refresh_token': credentials.refresh_token
    }
```
But when I try to make upload itself it works only for one hour:

```
credentials = google.oauth2.credentials.Credentials(user_access_token,
                                                        refresh_token = user_refresh_token,
                                                        token_uri = 'https://oauth2.googleapis.com/token',
                                                        client_id = get_config_var('GOOGLE_CLIENT_ID'),
                                                        client_secret = get_config_var('GOOGLE_CLIENT_SECRET')
    )

drive_service = build('drive', 'v3', credentials=credentials)
fd = io.BytesIO(file_bytes)
body = {'name': file_name, 'mimeType': 'application/pdf'}
media_body = MediaIoBaseUpload(fd = fd, mimetype='application/pdf')
file = drive_service.files().create(body=body,
                                            media_body=media_body,
                                            fields='id').execute()
```
After one hour, I have the following exception:

`('invalid_client: Unauthorized', '{\n  "error": "invalid_client",\n  "error_description": "Unauthorized"\n}')`

From here https://github.com/googleapis/google-api-python-client/issues/605#issuecomment-447958017 it says I don't need to do anything special and the client will refresh the token itself. But there is no any indication on what should be done and how it should work "itself". Please help!



While trying to get the api set up with python I kept getting a 400 error just using the provided sample code at Google Health Trends API Starting Guide.  

The code that I am using is 
```
#!/usr/bin/python
"""Sample code showing how to access the Google Flu Trends API."""

import csv
import datetime
import sys
import time

from googleapiclient.discovery import build

# ------ Insert your API key in the string below. -------
API_KEY = '[Key]'

SERVER = 'https://www.googleapis.com'
API_VERSION = 'v1beta'
DISCOVERY_URL_SUFFIX = '/discovery/v1/apis/trends/' + API_VERSION + '/rest'
DISCOVERY_URL = SERVER + DISCOVERY_URL_SUFFIX

MAX_QUERIES = 30


def DateToISOString(datestring):
  """Convert date from (eg) 'Jul 04 2004' to '2004-07-11'.
  Args:
    datestring: A date in the format 'Jul 11 2004', 'Jul 2004', or '2004'
  Returns:
    The same date in the format '2004-11-04'
  Raises:
     ValueError: when date doesn't match one of the three expected formats.
  """

  try:
    new_date = datetime.datetime.strptime(datestring, '%b %d %Y')
  except ValueError:
    try:
      new_date = datetime.datetime.strptime(datestring, '%b %Y')
    except ValueError:
      try:
        new_date = datetime.datetime.strptime(datestring, '%Y')
      except:
        raise ValueError("Date doesn't match any of '%b %d %Y', '%b %Y', '%Y'.")

  return new_date.strftime('%Y-%m-%d')


def GetQueryVolumes(queries, start_date, end_date,
                    geo='US', geo_level='country', frequency='week'):
  """Extract query volumes from Flu Trends API.
  Args:
    queries: A list of all queries to use.
    start_date: Start date for timelines, in form YYYY-MM-DD.
    end_date: End date for timelines, in form YYYY-MM-DD.
    geo: The code for the geography of interest which can be either country
         (eg "US"), region (eg "US-NY") or DMA (eg "501").
    geo_level: The granularity for the geo limitation. Can be "country",
               "region", or "dma"
    frequency: The time resolution at which to pull queries. One of "day",
               "week", "month", "year".

  Returns:
    A list of lists (one row per date) that can be output by csv.writer.

  Raises:
    ValueError: when geo_level is not one of "country", "region" or "dma".
  """

  if not API_KEY:
    raise ValueError('API_KEY not set.')

  service = build('trends', API_VERSION,
                  developerKey=API_KEY,
                  discoveryServiceUrl=DISCOVERY_URL)

  dat = {}

  # Note that the API only allows querying 30 queries in one request. In
  # the event that we want to use more queries than that, we need to break
  # our request up into batches of 30.
  batch_intervals = range(0, len(queries), MAX_QUERIES)

  for batch_start in batch_intervals:
    batch_end = min(batch_start + MAX_QUERIES, len(queries))
    query_batch = queries[batch_start:batch_end]
    # Make API query
    if geo_level == 'country':
      # Country format is ISO-3166-2 (2-letters), e.g. 'US'
      req = service.getTimelinesForHealth(terms=query_batch,
                                          time_startDate=start_date,
                                          time_endDate=end_date,
                                          timelineResolution=frequency,
                                          geoRestriction_country=geo)
    elif geo_level == 'dma':
      # See https://support.google.com/richmedia/answer/2745487
      req = service.getTimelinesForHealth(terms=query_batch,
                                          time_startDate=start_date,
                                          time_endDate=end_date,
                                          timelineResolution=frequency,
                                          geoRestriction_dma=geo)
    elif geo_level == 'region':
      # Region format is ISO-3166-2 (4-letters), e.g. 'US-NY' (see more examples
      # here: en.wikipedia.org/wiki/ISO_3166-2:US)
      req = service.getTimelinesForHealth(terms=query_batch,
                                          time_startDate=start_date,
                                          time_endDate=end_date,
                                          timelineResolution=frequency,
                                          geoRestriction_region=geo)
    else:
      raise ValueError("geo_type must be one of 'country', 'region' or 'dma'")

    res = req.execute()

    # Sleep for 1 second so as to avoid hittting rate limiting.
    time.sleep(1)

    # Convert the data from the API into a dictionary of the form
    # {(query, date): count, ...}
    res_dict = {(line[u'term'], DateToISOString(point[u'date'])):
                point[u'value']
                for line in res[u'lines']
                for point in line[u'points']}

    # Update the global results dictionary with this batch's results.
    dat.update(res_dict)

  # Make the list of lists that will be the output of the function
  res = [['date'] + queries]
  for date in sorted(list(set([x[1] for x in dat]))):
    vals = [dat.get((term, date), 0) for term in queries]
    res.append([date] + vals)

  return res


def main():
  # Examples of calling the GetQueryVolumes function for different geo
  # levels and time resolutions.
  us_weekly = GetQueryVolumes(['flu', 'cough'],
                              start_date='2011-01-01',
                              end_date='2015-01-01',
                              geo='US',
                              geo_level='country',
                              frequency='week')

  ma_region_daily = GetQueryVolumes(['flu', 'cough'],
                                    start_date='2011-01-01',
                                    end_date='2015-01-01',
                                    geo='US-MA',
                                    geo_level='region',
                                    frequency='day')

  boston_dma_monthly = GetQueryVolumes(['flu', 'cough'],
                                       start_date='2011-01-01',
                                       end_date='2015-01-01',
                                       geo='506',
                                       geo_level='dma',
                                       frequency='month')

  # Example of writing one of these files out as a CSV file to STDOUT.
  outwriter = csv.writer(sys.stdout)
  for row in us_weekly:
    outwriter.writerow(row)


if __name__ == '__main__':
  main()
```

and the errors that I am getting are : 

```
  Traceback (most recent call last): 
File "C:\Users\(me)\(directory name)\Lib\site-packages\test1.py", line 165, in <module>
main() 
File "C:\Users\(me)\(directory name)\Lib\site-packages\test1.py", line 137, in main us_weekly = GetQueryVolumes(['flu', 'cough'],
File "C:\Users\(me)\(directory name)\Lib\site-packages\test1.py", line 70, in GetQueryVolumes service = build('trends', 'v1beta', 
File "C:\Users\(me)\(directory name)\Lib\site-packages\googleapiclient\_helpers.py", line 130, in positional_wrapper return wrapped(*args, **kwargs) 
File "C:\Users\(me)\(directory name)\Lib\site-packages\googleapiclient\discovery.py", line 231, in build raise e 
File "C:\Users\(me)\(directory name)\Lib\site-packages\googleapiclient\discovery.py", line 222, in build content = _retrieve_discovery_doc( 
File "C:\Users\(me)\(directory name)\Lib\site-packages\googleapiclient\discovery.py", line 276, in _retrieve_discovery_doc raise HttpError(resp, content, uri=actual_url) googleapiclient.errors.HttpError: <HttpError 400 when requesting https://www.googleapis.com/discovery/v1/apis/trends/v1beta/rest?key=(key) returned "Bad Request">
```

From searching around on github and sites before this I've seen notes that googles documents are out of date and some use apiclient.discovery rather than the updated googleapiclient.discovery so I'm not sure how much of the getting started  guide needs to be updated  or is still relevant but I've followed it to  the best of my ability. Any help would be  greatly appreciated.
Some API's can return a content-length of 0 for Status 200 OK
responses that then results in a ValueError.

This change returns the expected response for no content if it detects
a response containing no content.

This commit fixes issue #804
It seems that the Admin Directory API now responds with `200 OK` and `content-length`'s of 0 as their "we have no content for you" responses instead of an empty JSON object as this client library assumes.

```
WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth
Traceback (most recent call last):
  File "/home/daniel/projects/test/vendor/googleapiclient/discovery_cache/__init__.py", line 41, in autodetect
    from . import file_cache
  File "/home/daniel/projects/test/vendor/googleapiclient/discovery_cache/file_cache.py", line 41, in <module>
    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')
ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth
INFO:googleapiclient.discovery:URL being requested: GET https://www.googleapis.com/discovery/v1/apis/admin/directory_v1/rest
INFO:googleapiclient.discovery:URL being requested: GET https://www.googleapis.com/admin/directory/v1/users?customer=my_customer&fields=users&alt=json&query=email%3Anoresults%2A
INFO:oauth2client.transport:Attempting refresh to obtain initial access_token
DEBUG:oauth2client.crypt:['REDACTED']
INFO:oauth2client.client:Refreshing access_token
Traceback (most recent call last):
  File "example.py", line 21, in <module>
    customer='my_customer', fields='users', query='email:noresults*').execute()
  File "/home/daniel/projects/test/vendor/googleapiclient/_helpers.py", line 130, in positional_wrapper
    return wrapped(*args, **kwargs)
  File "/home/daniel/projects/test/vendor/googleapiclient/http.py", line 857, in execute
    return self.postproc(resp, content)
  File "/home/daniel/projects/test/vendor/googleapiclient/model.py", line 216, in response
    return self.deserialize(content)
  File "/home/daniel/projects/test/vendor/googleapiclient/model.py", line 274, in deserialize
    body = json.loads(content)
  File "/usr/lib/python2.7/json/__init__.py", line 339, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
```

#### Environment details

  - OS: 18.04.1-Ubuntu
  - Python version: 2.7.17
  - pip version: 19.3.1
  - `google-api-python-client` version: 1.7.11

#### Steps to reproduce

  1. Do a `.list` operation with a query that returns zero results and only include the `fields` containing the results.
  2. You get a `ValueError: No JSON object could be decoded` since the API has started to return an 200 OK response with content-length of 0 when it previously always returned an `{}` in the body.

#### Snippet to reproduce

```python
import logging

from googleapiclient.discovery import build
from oauth2client.service_account import ServiceAccountCredentials

logging.basicConfig(level=logging.DEBUG)

credentials = ServiceAccountCredentials.from_json_keyfile_name(
    'key.json',
    scopes=[
        'https://www.googleapis.com/auth/admin.directory.user.readonly',
    ],
)
credentials = credentials.create_delegated('admin@example.com')

admin_directory = build('admin', 'directory_v1', credentials=credentials)

admin_directory.users().list(
    customer='my_customer', fields='users', query='email:noresults*').execute()
```
Recently updated httplib2 library (v0.16.0) have a breaking change causing this Exception:

`httplib2.RedirectMissingLocation: Redirected but response is missing a location: header`

**Steps to reproduce:**
1. `pip install --upgrade httplib2`
2. Now use the google drive library to upload a file (This is where I encountered the bug, it may break while using other stuffs a well)

It should either force to use 0.15.0 version of httplib2 or adapt the breaking changes introduced in the new version. 

A temporary fix for those using the client library would be to add httplib2==0.15.0 in requirements,txt of the project

If the description of the method contains any HTML tag, it will break the HTML rendering.
This PR escapes the HTML tag to prevent this problem depending on the different runtime python version
Only the python2 need to encode the Unicode object to str when writing HTML to file
If a nonexistent filename is passed, `self._fd` is never initialized. The destructor still attempts to close the file descriptor. This obscures the real error (file not existing).

Closes #798 

quickstart.py
```py
from __future__ import print_function
import pickle
import os.path
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

# If modifying these scopes, delete the file token.pickle.
SCOPES = ['https://www.googleapis.com/auth/drive']

def main():
    creds = None
    # The file token.pickle stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    if os.path.exists('token.pickle'):
        with open('token.pickle', 'rb') as token:
            creds = pickle.load(token)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open('token.pickle', 'wb') as token:
            pickle.dump(creds, token)

    service = build('drive', 'v3', credentials=creds)

    file_metadata = {'name': 'foo.jpg'}
    media = MediaFileUpload('files/foo.jpg',
                            mimetype='image/jpeg')
    file = service.files().create(body=file_metadata,
                                        media_body=media,
                                        fields='id').execute()
    print ('File ID: %s' % file.get('id'))

if __name__ == '__main__':
    main()
```

```
Traceback (most recent call last):
  File "quickstart.py", line 46, in <module>
    main()
  File "quickstart.py", line 39, in main
    mimetype='image/jpeg')
  File "/usr/local/google/home/busunkim/misc/fixit/drive-quickstart/env/lib/python3.7/site-packages/googleapiclient/_helpers.py", line 130, in positional_wrapper
    return wrapped(*args, **kwargs)
  File "/usr/local/google/home/busunkim/misc/fixit/drive-quickstart/env/lib/python3.7/site-packages/googleapiclient/http.py", line 555, in __init__
    fd = open(self._filename, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: 'files/foo.jpg'
Exception ignored in: <function MediaFileUpload.__del__ at 0x7f33b398c680>
Traceback (most recent call last):
  File "/usr/local/google/home/busunkim/misc/fixit/drive-quickstart/env/lib/python3.7/site-packages/googleapiclient/http.py", line 567, in __del__
    if hasattr(self, _fd):
NameError: name '_fd' is not defined
```

#### Environment details

  - OS: Ubuntu 18.04
  - Python version: 3.7.4
  - pip version: 19.2.3
  - `google-api-python-client` version: current

#### Steps to reproduce

  1. Add simple file upload from example to quickstart example from https://developers.google.com/drive/api/v3/quickstart/python
  2. After running console shows error: attributeerror 'mediafileupload' object has no attribute '_fd'