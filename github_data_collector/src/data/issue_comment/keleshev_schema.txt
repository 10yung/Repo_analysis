It would be really cool if you could use defined schemas as types. E.g.:

```
s = Schema({'x': int, 'y': str})
xy: s.type = {'x': 4, 'y':'a'}
```

I find myself defining Schemas to validate http responses in tests, but once they are defined, I would like to use them to provide type hints to my IDE. However, ATM I have to define a different type using either Typings or a dataclass in order to do so. This leads to code duplication where I have to define datatypes for type hints that are exact clones of the Schemas used in validation. This is bad. 

It would be much better to have a `schema.to_dataclass` or `schema.type` method to extract a dataclass or type. Even better if these methods would be called implicity when schemas are used as types. 
How to customize the error information for each field in JSON? For example, the "name" field is required. If I don't transmit this field, I want to prompt my own customized error response information instead of the default error prompt. I see that there is an "error" parameter function, but it can only prompt for the whole JSON, not provide custom error information for each field in the JSON
Wondering what's the recommended way to inherit from a parent schema...
So far I've been able to make it work as follows, but worried about this being brittle/broken in future revs:
```
>>> from copy import deepcopy
>>> from schema import Schema
>>> 
>>> schema_1 = Schema({'key': str})
>>> schema_2 = deepcopy(schema_1)
>>> schema_2._schema.update({'key': int})
>>> 
>>> schema_1.validate({'key': 1})
Traceback (most recent call last):
  File "<input>", line 1, in <module>
    schema_1.validate({'key': 1})
  File "/anaconda3/envs/buckaneer/lib/python3.5/site-packages/schema.py", line 254, in validate
    raise SchemaError([k] + x.autos, [e] + x.errors)
schema.SchemaError: Key 'key' error:
1 should be instance of 'str'
>>> 
>>> schema_2.validate({'key': 1})
{'key': 1}
```
Hello

I really like the way Schema validates data, but I felt limited by some features, like the pretty limited ``Hook``, JSON schema support, the fact that ``Schema`` systematically tries every key of a dict on every schema, and that most work is done at each validation instead of on initialization. 

So I eventually rewrote it: https://github.com/aure-olli/schema

I staid as compatible as possible the previous version, and match (almost) all the previous tests, while adding a big bunch of new one.

For the minor incompatibilities:
- I removed the support for https://github.com/keleshev/schema/issues/139: I don't see why it is a problem, ``Schema({Optiona('a'): 1, Optiona('a'): 2})`` can actually be useful, and silently removing one of them is clearly not any better.
-  The ``__repr__`` of ``Schema`` has unfortunately more useless stuffs due to the precompilation, but this shouldn't be a problem (just had to update some tests). And the representation of ``Regex`` is less clean.
- I changed the callback of ``Hook``: it now takes ``key, value, new, data`` in order to be able to edit ``new`` (useful for https://github.com/keleshev/schema/issues/204 for instance), which is still compatible with the tests and most examples written. 
- I authorize using ``json_schema`` without ``schema_id``, can be useful for generating a piece of JSON schema or an Open API schema.

For the new features, there are many:
- Everything is as precompiled as possible, and ``Dict`` is much more clever on which schemas to try with which key (depending on the value and the type of the key), as the test shows: https://github.com/aure-olli/schema/blob/35e114ab2be859b9a5de9d812fd8333c29f0cab6/test_schema.py#L1053
- Everything has the same base class: ``BaseSchema``
- As said, ``Hook`` is much more powerful, and can also define a ``catch(key, error, new, data)`` function for the case where the value is not matched.
- ``Optional`` is now a ``Hook`` (that shows its power), and ``Clean`` is similar but discards the key instead of saving it (they both can be used together)
- ``Regex`` can now have directly a compiled pattern, and has a ``regex_lib`` option to use other libraries as ``regex`` (https://pypi.org/project/regex/).
- And mostly, ``json_schema`` has totally been rewritten. It is now much more powerful and recursive, tries to do clever merging to compact the schema, can  represent regex and comparable, ... and can be specialized for JSON schema or Open API by passing ``target='json_schema'`` or ``target='openapi'``.

I tried to be as compatible as possible with the current version such that it can be merged. I think everybody would be glad to have this updated version. However, being a total refactoring, it clearly requires some discussions.

Thank you.
This is a feature request.

I would like it to be possible for an `Optional` whose value is a dictionary with `Optional` sub-entries to have as default a dictionary with the sub-entries and their defaults.

Maybe an example can help carry the meaning across:
```
from schema import Schema, Optional
schema = Schema({
        Optional('something', default={}): {
            Optional('method', default='A'): str,
            Optional('time', default=10): int,
        }
})
config1 = schema.validate({})
config2 = schema.validate({'something': {}})
config3 = schema.validate({'something': {'method': 'A', 'time': 10}})

print(config1)
>>> {'something': {}}
print(config2)
>>> {'something': {'method': 'A', 'time': 10}}
print(config3)
>>> {'something': {'method': 'A', 'time': 10}}

assert(config2 == config3) # Succeeds
assert(config1 == config2) # Fails
```
I would like both the asserts to succeed.

The behaviour is not currently supported (or maybe I could not find where it is documented - if this is the case, please advise). I would argue that it is a sensible behaviour to support: if I am using `schema` to parse a configuration file that is split in sections, I would like all the config entries to be set to their default values. The current behaviour, however, returns a structure with empty sub-sections, which means I need to specify my defaults somewhere else, and therefore have duplication (the worst kind of duplication, that of arbitrary constants).

It would be great if you could add an option for this behaviour!
Please advise if I can be of help.
Would be nice if there was an `async def async_validate` or something similar so you could have a coroutine as a validate method.
Recent commit https://github.com/keleshev/schema/commit/b73fb7187da46b627d84460bc981f45a28a438de treats callable `default` param to `Optional` specially (i.e. calling it instead of using it as it is)

This can cause confusion --- what if I want a callable itself as the default?
For example, I might have this schema:
```
Schema({Optional('key_type', default=str): type})
```
And the after this commit I am going to get `{'key_type': ''}` instead of `{'key_type': str}` if `key_type` is missing.

I would suggest reverting this asap before the new behavior is widely used and add `default_factory` for the same purpose, which is just what stdlib [dataclasses.field](https://docs.python.org/3/library/dataclasses.html?highlight=default_factory#dataclasses.field) and [collections.defaultdict](https://docs.python.org/3/library/collections.html?highlight=default_factory#collections.defaultdict) do
I encountered a situation where I'm trying to ensure that just one field in a schema is correct. Ideally, I would like to be able to say

``` python3
my_schema = schema.Schema({
    field_one : str,
    field_two : [str]
})

assert my_schema['field_one'].is_valid('string')
assert my_schema['field_two'].is_valid(['string'])
```

But at the moment, this doesn't seem to work.

Does this seem like a reasonable feature to add in a future release?
Use Case: I am creating a schema to validate a dictionary and for a key "key_1" I would like to use an enum to validate that the value is one of "value_1, value_2, value_3".
Hi. is it possible to load schema( that has And() function in it) from file? if yes could you give an example?
