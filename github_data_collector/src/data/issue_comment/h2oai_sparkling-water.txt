Related PR: https://github.com/h2oai/h2o-3/pull/4217
When will Sparkling water for Scala 2.12 and Spark 2.4 release?
I have **multiple applications** where each of them is creating its own H2O Sparkling Water **External Backend in Automatic mode**.
The problem is when two applications are trying to create its own backend in nearly same time.
Backend of first application is created successfully, however backend of the second application fails in its initialization phase. Is this some kind of know limitation or bug?
_Running PySparkling (3.26.8-2.4) on YARN._
I am trying to train H2O GBM algorithm on Databricks Cluster. H2O session is created, able to load data in to h2O, split the data , but when i am trying to train the model. I got the below error repeatedly

**Databricks specs: TestingCluster, 42.00 GB | 12 Cores | DBR 6.2 | Spark 2.4.4 | Scala 2.11**

> from pysparkling import *
> from pyspark.sql import SparkSession
> import h2o
> spark = SparkSession.builder.appName("SparklingWaterApp").getOrCreate()
> h2oConf = H2OConf(spark).set("spark.ui.enabled", "false")
> hc = H2OContext.getOrCreate(spark, conf=h2oConf)

> table_h2o = h2o.import_file(path = "dbfs:///tables/Somedata.csv", destination_frame = "table_h2o.hex",sep="\t")

> train_df,valid_df, test_df = table_h2o.split_frame(ratios=[0.8,0.1])
> 
> gbm = H2OGradientBoostingEstimator(ntrees = 1024, max_depth = 8,  stopping_metric = "misclassification", learn_rate = 0.02,                                                         
>                      learn_rate_annealing = 0.995,                                               
>                      sample_rate = 0.83,                                                       
>                      col_sample_rate = 0.86, 
>                      score_tree_interval = 8, nfolds =16,seed = 123)
> gbm.train(predictors, response, training_frame=train_df,validation_frame  = valid_df)
> h2o.save_model(gbm, path="dbfs:///tables/", force=True)

**_gbm Model Build progress: |█████████
H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='10.139.64.5', port=54321): Max retries exceeded with url: /3/Jobs/$0300ffffffff$_ad6e0e9e06cc863fde0358b6448a48d1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85d79e2a20>: Failed to establish a new connection: [Errno 111] Connection refused'))_**


Any help on this is appreciated. Thank You
Hi, thanks for a great repo!

I have `h2o-pysparkling-2.4==3.26.10` installed and want to enrich pyspark pipeline (including StringIndexer, VectorAssembler) with algorithms from h2o. But when I type `from pysparkling.ml import` ontly few of them are available (H2OXGBoost, H2OAutoML and so on). I wanted to end the pipeline with `H2OStackedEnsembleEstimator` from h2o.estimators. Is it possible? And if not, will it ever be?
Hello @jakubhava and Team... Hope you are doing good!!

I bring another issue of the same topic Spark DF to H2O Df in scala

I am following this notebook https://docs.databricks.com/_static/notebooks/h2o-sparkling-water-scala.html
And i get this error when I am converting spark dataframe to h2o

`[error] (run-main-0) java.lang.NoSuchMethodError: jsr166y.CountedCompleter.quietlyComplete()V
java.lang.NoSuchMethodError: jsr166y.CountedCompleter.quietlyComplete()V
	at jsr166y.CountedCompleter.__tryComplete(CountedCompleter.java:427)
	at jsr166y.CountedCompleter.tryComplete(CountedCompleter.java:383)
	at water.Atomic.compute2(Atomic.java:78)
	at water.Atomic.fork(Atomic.java:39)
	at water.Atomic.invoke(Atomic.java:31)
	at water.Lockable.write_lock(Lockable.java:61)
	at water.Lockable.delete_and_lock(Lockable.java:70)
	at water.Lockable.delete_and_lock(Lockable.java:67)
	at water.fvec.Frame.preparePartialFrame(Frame.java:1044)
	at water.fvec.FrameUtils$class.preparePartialFrame(FrameUtils.scala:30)
	at water.fvec.FrameUtils$.preparePartialFrame(FrameUtils.scala:72)
	at org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx.initFrame(InternalWriteConverterCtx.scala:43)
	at org.apache.spark.h2o.converters.WriteConverterCtxUtils$.convert(WriteConverterCtxUtils.scala:85)
	at org.apache.spark.h2o.converters.SparkDataFrameConverter$.toH2OFrame(SparkDataFrameConverter.scala:81)
	at org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:215)
	at org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:215)
	at org.apache.spark.h2o.utils.H2OContextUtils$class.withConversionDebugPrints(H2OContextUtils.scala:89)
	at org.apache.spark.h2o.H2OContext.withConversionDebugPrints(H2OContext.scala:64)
	at org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:215)
	at org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:212)
	at analyticsvidya.loanprediction3.H2OMain$.delayedEndpoint$com$vodafone$aquaduct$core$analyticsvidya$loanprediction3$H2OMain$1(H2OMain.scala:34)
	at analyticsvidya.loanprediction3.H2OMain$delayedInit$body.apply(H2OMain.scala:7)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:76)
	at scala.App$$anonfun$main$1.apply(App.scala:76)
	at scala.collection.immutable.List.foreach(List.scala:383)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35)
	at scala.App$class.main(App.scala:76)
	at analyticsvidya.loanprediction3.H2OMain$.main(H2OMain.scala:7)
	at analyticsvidya.loanprediction3.H2OMain.main(H2OMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
[trace] Stack trace suppress`
Hi, I am new to H2O.
In h2o-3 AutoML [docs](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html), I can set validation and leaderboard frame.
Can I do it in Sparkling water AutoML?
I can not find it in the [documentation](http://docs.h2o.ai/sparkling-water/2.4/latest-stable/doc/tutorials/sw_automl.html).

My env is:
1. Spark 2.4.4 Local mode
2. sparking water 3.26.0.10

Thank you.


Cluster: CDH 5.14
execute sparkling using:
```
spark2-shell \ 
  --packages ai.h2o:sparkling-water-package_2.11:3.26.10-2.4  \
  --conf spark.dynamicAllocation.enabled=false
```

Output:
```
scala> val h2oContext = H2OContext.getOrCreate(spark)
java.lang.ArrayIndexOutOfBoundsException: 10
	at water.UDPRebooted.checkForSuicide(UDPRebooted.java:58)
	at water.TCPReceiverThread.basic_packet_handling(TCPReceiverThread.java:292)
	at water.TCPReceiverThread$UDP_TCP_ReaderThread.run(TCPReceiverThread.java:249)
onExCompletion for water.FJPacket@7e1a57da
java.lang.ArrayIndexOutOfBoundsException: 10
	at water.AutoBuffer.getEnum(AutoBuffer.java:1269)
	at water.UDPClientEvent$ClientEvent$Icer.read9(UDPClientEvent$ClientEvent$Icer.java)
	at water.UDPClientEvent$ClientEvent$Icer.read(UDPClientEvent$ClientEvent$Icer.java)
	at water.Iced.read(Iced.java:69)
	at water.UDPClientEvent.call(UDPClientEvent.java:18)
	at water.FJPacket.compute2(FJPacket.java:29)
	at water.H2O$H2OCountedCompleter.compute(H2O.java:1417)
	at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)
	at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)
	at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)
	at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)
	at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)
java.util.NoSuchElementException: None.get
  at scala.None$.get(Option.scala:347)
  at scala.None$.get(Option.scala:345)
  at org.apache.spark.h2o.SparkSpecificUtils$.addSparklingWaterTab(SparkSpecificUtils.scala:43)
  at org.apache.spark.h2o.H2OContext.init(H2OContext.scala:139)
  at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:400)
  at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:428)
  ... 51 elided

scala> import h2oContext._
<console>:26: error: not found: value h2oContext
       import h2oContext._
              ^

scala> val h2oContext = H2OContext.getOrCreate(spark)
java.lang.IllegalArgumentException:
H2O context hasn't been started successfully in the previous attempt and H2O client with previous configuration is already running.
Because of the current H2O limitation that it can't be restarted within a running JVM,
please restart your job or spark session and create new H2O context with new configuration.")
```

Log attached.
[h2o_10.30.225.202_54321-3-info.log](https://github.com/h2oai/sparkling-water/files/3832512/h2o_10.30.225.202_54321-3-info.log)

I am trying to use H2O XGBoost model with my pyspark pipeline but i am getting below mentioned exception. I have pip installed following libs for using H2O model with pyspark.

Libs:
 h2o_pysparkling_2.4
h2o
sparkling

Exception:

water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: XGBoost_model_1572937136323_1.  Details: ERRR on field: XGBoost: XGBoost is not available on all nodes!

	at water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:19)
	at hex.tree.xgboost.XGBoost.init(XGBoost.java:119)
	at hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:234)
	at hex.ModelBuilder$Driver.compute2(ModelBuilder.java:222)
	at water.H2O$H2OCountedCompleter.compute(H2O.java:1417)
	at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)
	at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)
	at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)
	at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)
	at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

Any help will be highly appreciated
