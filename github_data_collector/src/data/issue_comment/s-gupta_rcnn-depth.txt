
>> demo

runname =

release


   Time taken for computing ng at scale 1: 5.574.

   Time taken for computing ng at scale 2: 1.747.
Time for full_cands_from_hiers: 1.221
Time for hole_filling: 9.599
Time for compute_base_features: 17.843
Time for mex_fast_reduction: 1.835
Time for compute_full_features: 0.011
Time for cand2labels: 0.054
Time for depth features: 4.538
Undefined function or variable 'caffe'.

Error in rcnn_load_model (line 28)
    caffe('init', rcnn_model.cnn.definition_file, rcnn_model.cnn.binary_file);

Error in run_all (line 41)
  rcnn_model = rcnn_load_model(rcnn_model);

Error in demo (line 6)
run_all(I, D, RD, C, out_file);

I can't find getPointCloudFromZ.m . where is it??
Hi, I'm trying to clone your repository(my OS is windows) and I ran into the following error.

> $ git clone https://github.com/s-gupta/rcnn-depth.git eccv14-code
> Cloning into 'eccv14-code'...
> remote: Counting objects: 1144, done.
> remote: Total 1144 (delta 0), reused 0 (delta 0), pack-reused 1144
> Receiving objects: 100% (1144/1144), 2.41 MiB | 2.92 MiB/s, done.
> Resolving deltas: 100% (428/428), done.
> fatal: cannot create directory at 'mcg/src/aux': Invalid argument
> warning: Clone succeeded, but checkout failed.
> You can inspect what was checked out with 'git status'
> and retry the checkout with 'git checkout -f HEAD'
> 
> 

After some searching, it turns out that aux is a reserved name for Windows which is why this error is popping out? Is there any way around this?

Hi,

I tried to compile caffe, but it will always give error about "cv".
My platform is CUDA 8.0+Ubuntu 16.04+opencv 3.2.0, i searched internet and found results that [nobody seems to compile successfully using opencv 3.2.0](https://stackoverflow.com/questions/44770879/caffe-build-fails-repeatedly/44771337), i wonder if it is true? If so, what should i do? 

Thanks!
Hey! I am very interested about your code about instance segmentation or semantic segmentation. How can Iget these parts?
Respected Sir,
I have read your research paper "Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images". 

I want to implement this code on my own data. I have kinect sensor.

I want to ask that how to get RGB-D image from kinect with color image and point clouds.?

I mean which tool is used to get it from kinect sensor.?

I am waiting for your response.

Regards
Hi! @s-gupta, I just want to ask you when I run the demo() and find a error like that

Invalid MEX-file '/home/zz/graduate_2/rcnn-depth/eccv14-code/structured-edges/private/edgesDetectMex.mexa64': dlopen: cannot load any
more object with static TLS

How can I do to fix it?
Hi:
　　Paper in the depth image to HHA image process is not detailed; can inform the detailed steps。

　　Looking forward to your reply．　