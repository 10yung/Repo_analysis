Instead of using Vec::extend with user-controlled piles of nodes, which could trigger arbitrarily large heap allocations, use space that was already allocated when constructing the tree: the parent pointers can serve the same purpose as a recursion stack.

Also I think the previous implementation would remove all the children of a node even if there were still other strong references to that node, so this implementation should be more generally correct.
I can't find release notes. I can't find a changelog. I can't find what has changed in the API, so I'm struggling to update my code.

> 122 | use html5ever::rcdom::{Handle, RcDom};
>    |                ^^^^^ could not find `rcdom` in `html5ever`

It seems like 0.25 has been a major change of the API, and `RcDom` [has been dropped entirely](https://docs.rs/html5ever/0.25.1/html5ever/?search=RcDom), all of my code is incompatible, and I don't even know where to start fixing it.



1. html5ever v0.22.5 is unaware of the `decoding` attribute: https://html.spec.whatwg.org/multipage/embedded-content.html#attr-img-decoding

2. `QualName::new(None, ns!(), local_name!("decoding"))` doesn't recognize the name. Is there another way to create the attribute? 


The implementation in https://github.com/servo/html5ever/blob/master/xml5ever/src/serialize/mod.rs is fairly simplistic, and does not reflect the complexity described by https://w3c.github.io/DOM-Parsing/#dfn-xml-serialization.
[The documentation](https://docs.rs/html5ever/0.22.5/html5ever/interface/struct.QualName.html) explains well what is the local name in general from HTML/XML perspective, but doesn't say anything about its usage in this particular Rust implementation. For example:

- How to get the name as `&str`?
- How to compare the name against several names in `match`?
- How to create a new one? `new()` says it's a "Simple constructor function.", but it's absolutely not simple, because it requires an instance of a peculiar `Atom<LocalNameStaticSet>` type.

`Atom`, `StaticAtomSet`, and `PhfStrSet` are not re-exported in the crate, so I can't see their documentation. 

There's `LocalNameStaticSet::get()` that appears to return something string-like, but when I call `qualname.local.get()` it seems to match a different method (on `Atom`?) that requires an undocumented argument.


I would be great to have an example or more explicit docs that shows how to search and modify the dom - or did I just not find that?
`src/main.rs`:

```rust
use std::fs;
use std::io::Cursor;

use std::default::Default;

extern crate html5ever;
use html5ever::parse_document;
use html5ever::driver::ParseOpts;
use html5ever::tendril::TendrilSink;
use html5ever::tree_builder::TreeBuilderOpts;
use html5ever::rcdom::RcDom;


fn main() {

    let buf = fs::read("failing").expect("Unable to read file");

    let mut buff = Cursor::new(buf);

    let opts = ParseOpts {
        tree_builder: TreeBuilderOpts {
            drop_doctype: true,
            scripting_enabled: false,
            ..Default::default()
        },
        ..Default::default()
    };

    match parse_document(RcDom::default(), opts)
        .from_utf8()
        .read_from(&mut buff) {
        _ => {}
    }

}
```

`Cargo.toml`
```
[package]
name = "rust-warc-streaming-parser"
version = "0.1.0"
authors = ["Jacek Wielemborek <d33tah@gmail.com>"]

[dependencies]
html5ever = "*"
```

```
thread 'main' panicked at 'assertion failed: c.is_some()', /home/d33tah/.cargo/registry/src/github.com-1ecc6299db9ec823/html5ever-0.22.3/src/tokenizer/mod.rs:554:9
stack backtrace:
   0: std::sys::unix::backtrace::tracing::imp::unwind_backtrace
             at libstd/sys/unix/backtrace/tracing/gcc_s.rs:49
   1: std::sys_common::backtrace::print
             at libstd/sys_common/backtrace.rs:71
             at libstd/sys_common/backtrace.rs:59
   2: std::panicking::default_hook::{{closure}}
             at libstd/panicking.rs:211
   3: std::panicking::default_hook
             at libstd/panicking.rs:227
   4: std::panicking::rust_panic_with_hook
             at libstd/panicking.rs:475
   5: std::panicking::begin_panic
             at /checkout/src/libstd/panicking.rs:409
   6: <html5ever::tokenizer::Tokenizer<Sink>>::discard_char
             at ./<panic macros>:3
   7: <html5ever::tokenizer::Tokenizer<Sink>>::step
             at /home/d33tah/.cargo/registry/src/github.com-1ecc6299db9ec823/html5ever-0.22.3/src/tokenizer/mod.rs:569
   8: <html5ever::tokenizer::Tokenizer<Sink>>::run
             at /home/d33tah/.cargo/registry/src/github.com-1ecc6299db9ec823/html5ever-0.22.3/src/tokenizer/mod.rs:361
   9: <html5ever::tokenizer::Tokenizer<Sink>>::feed
             at /home/d33tah/.cargo/registry/src/github.com-1ecc6299db9ec823/html5ever-0.22.3/src/tokenizer/mod.rs:219
  10: <html5ever::driver::Parser<Sink> as tendril::stream::TendrilSink<tendril::fmt::UTF8>>::process
             at /home/d33tah/.cargo/registry/src/github.com-1ecc6299db9ec823/html5ever-0.22.3/src/driver.rs:88
  11: <tendril::stream::Utf8LossyDecoder<Sink, A> as tendril::stream::TendrilSink<tendril::fmt::Bytes, A>>::process
             at /home/d33tah/.cargo/registry/src/github.com-1ecc6299db9ec823/tendril-0.4.0/src/stream.rs:179
  12: tendril::stream::TendrilSink::read_from
             at /home/d33tah/.cargo/registry/src/github.com-1ecc6299db9ec823/tendril-0.4.0/src/stream.rs:79
  13: rust_warc_streaming_parser::main
             at src/main.rs:29
  14: std::rt::lang_start::{{closure}}
             at /checkout/src/libstd/rt.rs:74
  15: std::panicking::try::do_call
             at libstd/rt.rs:59
             at libstd/panicking.rs:310
  16: __rust_maybe_catch_panic
             at libpanic_unwind/lib.rs:106
  17: std::rt::lang_start_internal
             at libstd/panicking.rs:289
             at libstd/panic.rs:392
             at libstd/rt.rs:58
  18: std::rt::lang_start
             at /checkout/src/libstd/rt.rs:74
  19: main
  20: __libc_start_main
  21: _start
```

And here's `failing` file, compressed with `zip`: [failing.zip](https://github.com/servo/html5ever/files/2454326/failing.zip)
This is needed for speculative parsing in Servo, where one needs to send the tokenizer state between threads. I created a `Sendable` trait, which is implemented by both the Tokenizer and the TreeBuilder.

Servo side PR: https://github.com/servo/servo/pull/19203
Hi, for issue #323 I was writing a small  `TokenSink` implementation. And to be honest, it took me good half-hour, to hour for that simplistic implementation.

I think what we might need is better docs, and possibly some convenience method. One pain point was adding following part:

```rust    
     let _ = tok.feed(&mut input);
     tok.end();
```

Do we need a different `tok.feed` and `tok.end()` methods? Can they be `let _ = tok.exec(&mut input)`?

One thing that also irked me, was that I couldn't have implemented was to have tokenizer abort when encountering anything that isn't `Text` token?


This is a feature request for the ability to “correct” bad input, by stripping away parts that are not conforming to the spec.  This is mostly useful for sanitizers, especially for pages that want to ensure that their contents are valid HTML.

This is a feature request for html5ever because of the intimate knowledge of the spec required.