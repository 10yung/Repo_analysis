Hi, as shown in the following full dependency graph of  **_bookstore_**, **_bookstore_** requires **_aiobotocore *_** ， while the installed version of **_aioboto3_**(6.4.1) requires _**aiobotocore  <0.11,>=0.10.2**_.

According to Pip's _“first found wins”_ installation strategy, _**aiobotocore  0.11.0**_ is the actually installed version.  

Although the first found package version _**aiobotocore  0.11.0**_ just satisfies the later dependency constraint （_**aiobotocore  <0.11,>=0.10.2**_), it will lead to a build failure once developers release a newer version of aiobotocore.

### Dependency tree--------
```
bookstore - 2.5.1
| +- aioboto3(install version:6.4.1 version range:*)
| | +- aiobotocore(install version:0.10.4 version range:<0.11,>=0.10.2)
| | | +- aiohttp(install version:3.6.2 version range:>=3.3.1)
| | | +- async-generator(install version:1.10 version range:>=1.10)
| | | +- botocore(install version:1.12.252 version range:<1.12.253,>=1.12.252)
| | | | +- docutils(install version:0.15.2 version range:>=0.10,<0.16)
| | | | +- jmespath(install version:0.9.4 version range:<1.0.0,>=0.7.1)
| | | +- wrapt(install version:1.11.2 version range:>=1.10.10)
| +- aiobotocore(install version:0.11.0 version range:*)
| | +- aiohttp(install version:3.6.2 version range:>=3.3.1)
| | +- async-generator(install version:1.10 version range:>=1.10)
| | +- botocore(install version:1.13.14 version range:>=1.13.14,<1.13.15)
| | | +- docutils(install version:0.15.2 version range:>=0.10,<0.16)
| | | +- jmespath(install version:0.9.4 version range:<1.0.0,>=0.7.1)
| | +- wrapt(install version:1.11.2 version range:>=1.10.10)
| +- future(install version:0.18.2 version range:*)
| +- futures(install version:3.3.0 version range:*)
| +- ipython(install version:7.9.0 version range:>=5.0)
| +- notebook(install version:6.0.2 version range:*)
| +- tornado(install version:6.0.3 version range:>=5.1.1) 
```

Thanks for your attention.
Best,
Neolith

We may be able to give people a straightforward way to revert to older versions of their notebooks by integrating directly with the Jupyter Checkpoints APIs.

This would allow us to surface a simple UI for users to revert to older versions of their notebooks from within the notebook itself.

Many thanks to @romain-intel for pointing out this possibility.
As brought up by @MSeal in https://github.com/nteract/bookstore/pull/176#discussion_r353329013 we should consider automating our version updates.

One of the easiest ways to set this up is to set up bumpversion and make that part of our releasing instructions.

In the meantime, we will just aggregate those spots that need updating inside the `RELEASING.md` instructions per 9e286ae9adcd92f83638a1661b960d31e5cc4d30.
In the classic notebook server, we have the `LargeFileManager` to handle large files as a streamed response. We could have something analogous for bookstore that would alleviate issues around archiving large files.

There are a few details that would need some explicit design work (e.g., do we also stream responses back to S3, do we queue a save in the case where saving to S3 is taking a long time instead of debouncing all requests, &c. ), but this seems well within scope of this project.
We've added to Papermill and it makes sense to add here too.
In #159 we realized that there is utility in logging more information at the point of validating the bookstore settings. To keep the PR more tightly scoped we only added it to the file system cloning validation.

We need to make a decision on if we want to add logs for:
- [ ] overall bookstore validation
- [ ] archive validation
- [ ] publishing validation
- [ ] s3 cloning validation
Related to #151 

This issue's scope is a documentation update that mentions the click process and that the extra click is needed for security and protection from malicious code execution.

Let's make #151 focused on a Security audit and evaluation of Bookstore.
In order to help folks understand why landing on the bookstore cloning page (served as `text/html`), we should outline the threat model, security risks, and mitigations.

## Summary

Some initial users have complained about having an extra click when cloning. It definitely slows the intended user experience of a smooth way to share notebooks.

We need to mitigate the risk of users loading notebooks that they didn't wish to onto their compute. Since the jupyter notebook server is one big remote code execution platform, the holy grail of security vulnerabilities, we have to be extra vigilant. While there are many other ways to attempt to exploit the overall system, we don't wish for _our_ portion to be a wide attack vector.

## Scenario

Malicious notebook is sitting on Bucket `MyBucket` at path `my/notebook/path.ipynb`

User is passed a link looking like:

```
http://localhost:8888/bookstore/clone?s3_bucket=MyBucket&s3_key=my/notebook/path.ipynb
```

With our current clone page, the user has to decide if they mean to import this notebook.
Today, when I was using bookstore to clone from S3, I found that responses were just hanging indefinitely.

It seems to be occurring when we attempt to read the s3 response object's body (with `await obj['Body'].read()`).

Importantly, it doesn't hang when using minio's mock s3 server.

Does anyone have any insight as to what could be causing this?

@kylek @willingc @mseal
Currently we are consuming the id passed through via the sessions response http://jupyter-api.surge.sh/#!/sessions/get_api_sessions_session in the `nb_client` library and not setting it to a variable. My guess is that this was removed earlier because of similar issues to those raised around keeping the kernel's "id" field.

I discovered this as I was writing unit tests for the client section; I am going to refrain from adding it in those tests, but will leave commented code in place to indicate the functionality's future return (mostly for the sake of future integration tests).