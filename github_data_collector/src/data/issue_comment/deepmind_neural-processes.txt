Comments on sampling from either prior (during testing) or the posterior (during training) are swapped.

"Note that targets contain contexts by design" -> is this is referring to how the latent encoder had previously been run on the contexts, rather than the targets themselves actually containing contexts?

Thanks!

When I run the 'attentive_neural_process.ipynb', I got the mistakes as follows:

ValueError: Variable layer_3/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File "<ipython-input-4-20f2577573c8>", line 28, in batch_mlp
    output, output_sizes[-1], name="layer_{}".format(i + 1))
  File "<ipython-input-6-a52e0030599a>", line 31, in __call__
    hidden = batch_mlp(encoder_input, self._output_sizes, "latent_encoder")
  File "<ipython-input-8-a2102227fa62>", line 58, in __call__
    prior = self._latent_encoder(context_x, context_y)

Hello,
I don't know if this is the right forum to ask.....

Is there a available demo on the one-shot classification using the Omniglot dataset presented in section 4.3 of the paper. I am unable to understand how you combined the different channels of convolutional output to compute the statistics and combine it with test image to perform classification?

None