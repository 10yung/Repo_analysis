Looks like need to add explicit dependencies on google-cloud-storage and google-cloud-core.

From https://pypi.org/project/google-cloud/
"""
WARNING: The google-cloud Python package is deprecated. On June 18, 2018, this package will no longer install any other packages.
"""
![image](https://user-images.githubusercontent.com/15324592/40666256-f4e18bac-6367-11e8-8c02-97d069035b69.png)

I was able to fix by adding 
![image](https://user-images.githubusercontent.com/15324592/40666351-23c969da-6368-11e8-8227-2a522a927345.png)

But it looks there are other issues related to working with folders

10x
Hi,

Looks like url decoding needs to be implemented to support decoded chars in folder names

![image](https://user-images.githubusercontent.com/15324592/40664494-b9e2a616-6363-11e8-833c-90dc38eabfb1.png)

10x
In the `_dir_model` method there is a segment of code that calls `self.get` on every contained blob if contents are set (see below). This organization creates a massive slowdown when navigating to GCS directories with more than a dozen files.

I suspect it should be straightforward to refactor this to directly use the returned `google.cloud.storage.Blob` objects returned by `bucket.list_blobs`. Similarly for directories with many sub-directories, you should be able to use the list of prefixes directly rather than running self.get many times.

offending code:
``` python
def _dir_model(self, path, members, content=True):
    ...
    for blob in blobs:
        ...
        contents.append(self.get(
```

I've filed this bug for tracking purposes - I don't have the bandwidth to resolve the bug at present.