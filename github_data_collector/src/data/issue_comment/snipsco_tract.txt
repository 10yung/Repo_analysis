
Hi @kali, will the SONOS aquirement of snips affect this repo? https://forum.snips.ai/t/important-message-regarding-the-snips-console/4145

It would be such a shame!!
Hello !
Was trying tract and so far it looks amazing.

While playing with a conv autoencoder model, I noticed that the Deconvolution layers are not supported in ONNX and Tensforflow.

Would it be hard to implement it ? I looked at the code but so far my skills are very limited as I really don't understand well deconvolution.

I could try to implement it, because i feel that this op is not very different from the Conv layer.
The thing is that dynamic outputs might be problematic.

Very good job so far ! it's a pleasure to see something so advanced in pure rust.

Cheers


I tried importing a simple model from the TF2 tutorial:

```Python
from __future__ import absolute_import, division, print_function, unicode_literals

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras



fashion_mnist = keras.datasets.fashion_mnist


(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']



train_images = train_images / 255.0

test_images = test_images / 255.0




model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=10)
#model.save('my_model.h5')

tf.saved_model.save(model, 'model_as_tf')
```

Then I copied the pb file and ran:

```Rust
use tract_core::prelude::*;
fn main() {

    let tf = tract_tensorflow::tensorflow();
    let model = tf.model_for_path("saved_model.pb").unwrap();

}
```

But it results in:

```
thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: TractError(Msg("WireError(UnexpectedWireType(WireTypeVarint))"), State { next_error: None, backtrace: InternalBacktrace { backtrace: Some(stack backtrace:

```

Does this lib work with TF2, if not, is there a way to convert a TF2 model to TF1? 

BTW thank you for this awesome lib!
I'm trying to load a model into rust and I'm getting an error when I run the model.

```
thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: 
TractError(Msg("Translating #30 \"global_average_pooling1d/Mean\" Unimplemented(Mean)"), 
State { next_error: Some(TractError(Msg("Operator can not be made a TypedOp."), 
State { next_error: None, backtrace: InternalBacktrace { backtrace: None } })), 
backtrace: InternalBacktrace { backtrace: None } })
```
It seems that the mean operation of global_average_pooling1d is not supported, does anyone know anymore about this?



Thanks for your greate work!
I would love to see an audio streaming inference Example here.

TIA
Andy

@kali Opening this draft PR so as to collect some potential early feedback.

The core generic tree ensemble engine seems to be working (what I've managed to test so far, I was actually super surprised that the tests vs lightgbm passed from the first try after I got it to compile, lol), now need to pin it to protobuf config, set up the rules, run a few basic benchmarks, wrap it in classifier/regressor types, etc. All features (including score post transforms except probit, different various comparison ops, inputnan handling etc) that can be provided in ONNX protobuf config are already supported here.

It's definitely not implemented in the most efficient way now, but I think it shouldn't be too bad (although before there's benchmarks, I have no idea how much worse it would be than the existing lightgbm/xgboost c++ engines).