
This is pull request was created automatically because we noticed your project was missing a Code of Conduct file.

Code of Conduct files facilitate respectful and constructive communities by establishing expected behaviors for project contributors.

This PR was crafted with love by Facebook's Open Source Team.
When I try to write a script for run_cmds, I find g and genmove can only run once, then the program will exit. Other commands don't have this problem. In cnnPlayerV2Framework.lua, line 664, g or genmove will return the "win_rate"(between 0 and 1), and in line 339, win_rate is read as quit, thus always return true and exit. When I delete the "win_rate" in line 664, it seems worked fine.
Hi,

Trying to run darkforest in mcts-only mode (no dcnn):

    $ th cnnPlayerMCTSV2.lua --cpu_only --time_limit 10
    Pattern file ../models/playout-model.bin loaded!
    CNNPlayerV2MCTS

    boardsize 19
    = 

    clear_board
    Params is NULL, set default parameters.
    Pattern file ../models/playout-model.bin loaded!
    ---- PatternV2 -----
    #hash_size: 1048576, NUM_PRIOR: 17, LEN_PRIOR: 49
    Verbose: 1, cnt_threshold: 1, alpha: 0.015000, batch_size: 8, temperature: 0.125000, ply_fraction: 0.001000
    neighbor: true, nakade: true, resp: true, save_atari: true, kill_other: true, global: false, ko: true, put_group_to_atari: true, eye: true
    #Pattern: 754901, collision: 198968663
    Sample from topn: -1
    -- End Patternv2 ---
    Segmentation fault (core dumped)

Am i doing something wrong, or is this a bug ?

Using latest git (ee97607), Ubuntu 14.04

How can I fix this error??
fs/alphago_leesedol_1.sgf 12"
Pattern file ../models/playout-model.bin loaded!
CNNPlayerV2MCTSCannot open pipe /home/ubuntu/darkforestGo/GO/./pipe-0-0 (client) !
/home/ubuntu/torch/install/bin/luajit: 

Hi,

First of all, thanks to your nice work.

I was trying to run your go engine on my server, which has about 120 GiB memory.

It went all right until I tried to train with provided dataset.

The output are as followed:

```
[root@localhost darkforestGo]# ./train.sh
{
  nstep = 3,
  optim = "supervised",
  loss = "policy",
  progress = false,
  nthread = 4,
  model_name = "model-12-parallel-384-n-output-bn",
  data_augmentation = true,
  actor = "policy",
  nGPU = 1,
  sampling = "replay",
  intermediate_step = 50,
  userank = true,
  alpha = 0.05,
  num_forward_models = 2048,
  batchsize = 256,
  epoch_size_test = 128000,
  feature_type = "extended",
  epoch_size = 128000,
  datasource = "kgs"
}	
fm_init: function: 0x4076e7c8	
fm_gen: function: 0x410f4a58	
fm_postprocess: nil	
rl.Dataset.__init(): forward_model_init is set, run it
rl.Dataset.__init(): forward_model_init is set, run it
rl.Dataset.__init(): forward_model_init is set, run it
| IndexedDataset: loaded ./dataset with 144748 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
| IndexedDataset: loaded ./dataset with 144748 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
rl.Dataset.__init(): forward_model_init is set, run it
| IndexedDataset: loaded ./dataset with 144748 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
| IndexedDataset: loaded ./dataset with 144748 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
rl.Dataset.__init(): forward_model_init is set, run it
| IndexedDataset: loaded ./dataset with 26814 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
rl.Dataset.__init(): forward_model_init is set, run it
| IndexedDataset: loaded ./dataset with 26814 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
rl.Dataset.__init(): forward_model_init is set, run it
| IndexedDataset: loaded ./dataset with 26814 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
rl.Dataset.__init(): forward_model_init is set, run it
| IndexedDataset: loaded ./dataset with 26814 examples
rl.Dataset.__init(): #forward model = 2048, batchsize = 256
THCudaCheck FAIL file=/tmp/luarocks_cutorch-scm-1-4547/cutorch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory
/root/torch/install/bin/luajit: /root/torch/install/share/lua/5.1/nn/Container.lua:67: 
In 1 module of nn.Sequential:
In 9 module of nn.Sequential:
/root/torch/install/share/lua/5.1/nn/THNN.lua:110: cuda runtime error (2) : out of memory at /tmp/luarocks_cutorch-scm-1-4547/cutorch/lib/THC/generic/THCStorage.cu:66
stack traceback:
	[C]: in function 'v'
	/root/torch/install/share/lua/5.1/nn/THNN.lua:110: in function 'BatchNormalization_updateOutput'
	/root/torch/install/share/lua/5.1/nn/BatchNormalization.lua:124: in function </root/torch/install/share/lua/5.1/nn/BatchNormalization.lua:113>
	[C]: in function 'xpcall'
	/root/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'
	/root/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function </root/torch/install/share/lua/5.1/nn/Sequential.lua:41>
	[C]: in function 'xpcall'
	/root/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'
	/root/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'
	./train/rl_framework/infra/bundle.lua:161: in function 'forward'
	./train/rl_framework/infra/agent.lua:46: in function 'optimize'
	./train/rl_framework/infra/engine.lua:114: in function 'train'
	./train/rl_framework/infra/framework.lua:304: in function 'run_rl'
	train.lua:155: in main chunk
	[C]: in function 'dofile'
	/root/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:150: in main chunk
	[C]: at 0x004064f0

WARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.
stack traceback:
	[C]: in function 'error'
	/root/torch/install/share/lua/5.1/nn/Container.lua:67: in function 'rethrowErrors'
	/root/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'
	./train/rl_framework/infra/bundle.lua:161: in function 'forward'
	./train/rl_framework/infra/agent.lua:46: in function 'optimize'
	./train/rl_framework/infra/engine.lua:114: in function 'train'
	./train/rl_framework/infra/framework.lua:304: in function 'run_rl'
	train.lua:155: in main chunk
	[C]: in function 'dofile'
	/root/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:150: in main chunk
	[C]: at 0x004064f0
```

I ran the "free" command before training. It turns out like this:

```
[root@localhost darkforestGo]# free
              total        used        free      shared  buff/cache   available
Mem:      115383448     1317128   112506528       10744     1559792   113786336
Swap:      67108860           0    67108860
```

It seems that I'm facing an "out of memory" issue.

May I ask how much memory do I need to train?

Or, is there anything wrong elsewere?

Thanks in advance
田教授，自己怎么制作dataset，我有很多棋谱，想加进去。
二月 07, 2017 12:16:42 上午 com.gokgs.client.gtp.GtpClient d
非常详细: Got successful response to command "genmove w": = G7
二月 07, 2017 12:16:42 上午 com.gokgs.client.gtp.a a
非常详细: Submitting move g7 to server
timeleft -- color: w, num_seconds: 49, num_moves: 0二月 07, 2017 12:16:42 上午 com.gokgs.client.gtp.GtpClient d
非常详细: Command sent to engine: time_left w 49 0
二月 07, 2017 12:16:42 上午 com.gokgs.client.gtp.GtpClient d
非常详细: Got successful response to command "time_left w 49 0": = 
二月 07, 2017 12:21:28 上午 com.gokgs.client.gtp.a b
警告: Opponent has not returned. Leaving game.
二月 07, 2017 12:21:28 上午 com.gokgs.client.gtp.GtpClient d
非常详细: Command sent to engine: kgs-game_over
二月 07, 2017 12:21:28 上午 com.gokgs.client.gtp.GtpClient d
严重: Got malformed response from engine: Warning: Ignoring unknown command - kgs-game_over 
? ???. nil
二月 07, 2017 12:21:28 上午 com.gokgs.client.gtp.GtpClient c
详细: Game ended. Starting another.
二月 07, 2017 12:21:28 上午 com.gokgs.client.gtp.GtpClient a
非常详细: Still an outstanding command, will wait until the system is idle before making a new game.


I'm in China, I can't download Dataset from "here"
Please download them here and save to the  ./dataset  directory.

Please give me new links just like what you do in Issue 17.
Thanks.
Usage step 1, cann't download models. The link is invalid.
Can anyone do that?