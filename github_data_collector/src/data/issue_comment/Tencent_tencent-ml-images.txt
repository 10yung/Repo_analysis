as i read loss function, notice:
 # b. get non-negative mask
  non_neg_mask = tf.fill(tf.shape(labels), -1.0, name='non_neg')
  non_neg_mask = tf.cast(tf.not_equal(labels, non_neg_mask), tf.float32)
  tf.summary.histogram('non_neg', non_neg_mask)

but based on above code , non_neg_mask is alwayes like : [1,1,1,1,1,1,1]
wonder non_neg_mask is useless?
I want to download open-images dataset by browser, but I can not select the version
Hi, thank you for sharing, I am interested to know that why the class_num is set to be 1000 in the flag.py. Is the given model in checkpoints just suitable for predicting the top 1000 classes of the dictionary?
腾讯开源代码质量堪忧啊。
还有一个问题就是，README写的够烂，踩了很多坑，train.py和finetune.py能运行tfrecord文件都不一样，一个多标签，一个多分类的代码，README里面完全没提。
另外tf1.6也不是所有的都能跑，根据cudnn的版本才行，这个也没提。
我发现train.py，损失函数是Cross_entropy, 如果多Multi-labels的图像分类，不应该是使用Binary entropy吗？望解答！
我训练自己的模型，但是我只用了train文件夹进行训练，没有创建val文件夹也没有对应的文件，可是查看tensorboard有一个train_accuracy曲线，从1开始往下掉，到30多万次的时候降到了0.6几，请问这是怎么回事啊

你好，我看到有一个single label的例子，要是多labels如何使用

