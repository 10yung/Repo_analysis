A proposition to resolve #61 

Motivation
-----------
`#[kernel]` function cannot use any variable, function, and so on because it will be compiled as a stand alone device code.

```rust
fn add_2(a: &mut f32) {
    *a = *a + 2.0;
}

#[kernel] 
pub fn add_2_all(a: *mut f32, n: usize) {
    let i = ::accel_core::index();
    unsafe { add_2(&mut *a.offset(i)) };  // add_2 cannot find
}
```

Resolution
-------------
Compile entire crate both as x86_64 and nvptx64 targets. 

- rust-ptx-linker will eliminate non-PTX kernel code which does not called from PTX kernel

Problems
------------
- [ ] std must be compiled with nvptx
- [ ] Compile flow (How to trigger nvptx build instead of proc-macro?)

This project is enough complicated for new developer to stop hacking. A guide book like [rustc-guide](https://github.com/rust-lang/rustc-guide) is needed.
Wrap [CUDA steraming API](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html) using async/await
CI on GPU
------------
GitHub Actions with self-hosted runner works?? #9 

Stable Rust
-------------
Stabilize Host-side code. Device-side code is out-of-scope because large amount of issues are remains for nvptx backend. See the link.

- [x] proc-macro has been stabilized as #63 
- [x] cargo check runs on stable Rust #66

Update dependencies
-----------------------
- [x] syn, quote, proc-macro2 1.0 #67 
- [x] rust-cuda/cuda-sys 0.3.0 #66 

rust-ptx-linker
-----------------
Linker flavor using rust-ptx-linker has been merged into rustc https://github.com/rust-lang/rust/pull/57937

- [x] Rewrite accel-derive with rust-ptx-linker #69 
- [x] archive nvptx crate

Document
------------
- [ ] Needs a guide book #68 

Links
-----
rust-lang/rust
-  NVPTX backend metabug https://github.com/rust-lang/rust/issues/38789

rust-cuda/wg
- Overview about existing solutions and approaches https://github.com/rust-cuda/wg/issues/2
-  Are we CUDA yet? https://github.com/rust-cuda/wg/issues/16
Hi there,

I am running a program which contains some error, and the Cuda runtime keeps returning 
`MissingConfiguration`

I can see in the cuda_sys code that this enum value maps to 2, nevertheless
MissingConfiguration in the Cuda runtime maps to 52, while 2 is 
  
```
    /**
     * The API call failed because it was unable to allocate enough memory to
     * perform the requested operation.
     */
    cudaErrorMemoryAllocation             =      2,
```

```
    /**
     * The device function being invoked (usually via ::cudaLaunchKernel()) was not
     * previously configured via the ::cudaConfigureCall() function.
     */
    cudaErrorMissingConfiguration         =      52
```

In the rust code there are no 52 nor 53 values:

```
    PeerAccessAlreadyEnabled = 50,
    PeerAccessNotEnabled = 51,
    DeviceAlreadyInUse = 54,
    ProfilerDisabled = 55,
```

I am using cuda 10.1. 
- is  this version supported? 
- is this a version missmatch? 
- Should I generate the bindings myself from the Cuda header? 

Cheers
I have a crate that has N rust accel functions.

When I rebuild this crate, even if I don't touch those N functions, it seems to trigger N nvptx-accel rebuilds.

Is this avoidable?
Is there a way to mix rust-accel with raw *.cu files?

I would like to write some __device__ helper functions in *.cu, then call them from #[kernel] functions defined in rust-accel.

Is there an example for how to do this?
See last slide of https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf

Is there a way to mark a field volatile in rust-accel ?
This pull request addresses the issue that CUDA headers change between versions. Thus, over time, cuda-sys becomes incompatible with newer CUDA versions. See also #56.

For example, Nvidia introduced a breaking API change going from version 9.2 to 10.0. They added a new field "uuid" to the beginning of cuda_sys::cudart::cudaDeviceProp, making all the fields after "uuid" invalid memory locations.

We solve such compatibility issues by generating new bindings every time that cuda-sys is built. This ensures that we are source-compatible with the installed CUDA version.
Unfortunately, I have a little time to manage this project. I'd like to seek anyone interested in managing/developing this project.