This is my initial pass at #89.  Happy to start iterating.

The main source of uncertainty for me is around `check_hostname` on the SSL context.  I tested without that set and then fretted about it for 3 weeks now, then added it as something you could configure.  I looked at both what JupyterHub and Dask Distributed do, and they both have actual opinions.  I went with making the default look like what Dask does because that's closest to our set of assumptions.  I'm not sure the "True" case has everything else needed to work.
i wanna run an instance of theia alongside notebook. Run notebook without jupyterhub can access theia service, but with jupyterhub, it throws error like below:
jupyter-theia-proxy 403 GET [W 2020-01-02 17:03:47.194 SingleUserNotebookApp log:158] 403 GET /hub/notebook/user/DE-a412aeee-2d38-11ea-a577-0255ac100083/theia/services

Anyone knows the reason? Am i missing something?

Thanks for your reply
I was wondering whether it would be possible to create some kind of a HelloWorld tutorial of using this extension? (Forgive me if one already exists).

I am trying to set this up on JupyterHub to proxy a streamlit app and I am struggling to find where to put all the config etc, knowing whether I need to start the server etc.

A simple tutorial for setting up an arbitrary port proxying would go along way in helping me set this up and I am sure I am not the only one this would benefit.

Let me know what you think?
Hi all,

As the title suggest, I am trying to allow each of our developers to access Theia from their Jupyter environment. Our Jupyterhub is hosted on GCP, and has been stable for many months. 

We are spinning up a Theia container using the zero-to-jupyterhub helm value file:

```
singleuser:
  extraContainers:
    - name: cloud-ide
      image: theiaide/theia-python
      args: ["--log-level=debug", "-v", "$(pwd)", "--hostname=127.0.0.1"]
```

Where the args above are my latest experiment in allowing a connection to Theia.

### SingleUser docker image
The singleuser docker image has the following commands run:
```
...

RUN sudo apt-get update -y -q && sudo apt-get install build-essential -y
RUN sudo apt-get install net-tools

...

# Enable proxy
RUN jupyter serverextension enable --sys-prefix jupyter_server_proxy && \
	jupyter labextension install jupyterlab-server-proxy

...
```

And the following Python libraries: 
```
configurable-http-proxy   1.3.0                         0    conda-forge
jupyter-codeserver-proxy  1.0b1                    pypi_0    pypi
jupyter-server-proxy      1.1.0                      py_0    conda-forge
jupyter-theia-proxy       1.0b1                    pypi_0    pypi
lazy-object-proxy         1.4.3            py36h516909a_0    conda-forge
jupyter_client            5.3.3                    py36_1    conda-forge
jupyter_core              4.5.0                      py_0    conda-forge
jupyterhub                1.0.0                    py36_0    conda-forge
jupyterlab                0.35.0                   py36_1    conda-forge
jupyterlab_server         0.2.0                      py_0    conda-forge
```

### Theia container logs output
You can see from this output that the hostname arg has not overwritten the default arg, and that the $(pwd) attempt didn't work as intended! However, I am not sure if this is even what needs to be changed, it is just the latest experimentation. 
```
yarn run v1.19.1
$ /home/theia/node_modules/.bin/theia start /home/project --hostname=0.0.0.0 --log-level=debug -v '$(pwd)' --hostname=127.0.0.1
root INFO Theia app listening on http://0.0.0.0,127.0.0.1:3000.

```

# Symptom
I am accessing the Theia container successfully, via the Jupyterhub URL+/proxy/3000/, but am greeted with an infinitely spinning Theia loading screen, getting very close it seems! The network traffic seems to indicate that Monaco is serving *something*, but I just repeatedly get 502 responses.

![image](https://user-images.githubusercontent.com/12683494/67823881-e1f18700-fb18-11e9-9bb3-5517bd5db703.png)

Any assistance would be appreciated. Is this even possible? Am I barking up the wrong tree entirely? 

I have been experimenting with passing args to the docker container (as seen above), but nothing seems to have any effect. I am under the impression that the containers should be able to freely communicate, so maybe there is something wrong with the working directory of Theia? 

Further, I'm not sure how exactly Theia is supposed to access the /home/joyan to view the user's files? Is there some configuration required for this? The Jupyter environment is accessing a persistent volume, and to my knowledge, the Theia container should be able to see it?
Is there a way to access the current directory shown in the jupyterlab file browser from python? In particular, I'd like to use that information in `jupyter_notebook_config.py` when starting up a shiny application.
Hi I'm trying to use Jupyter server proxy extension to run Tensorboard and access it directly!
I tested with /proxy/port and it works great, however I wanted to add the possibility to start it using https://jupyter-server-proxy.readthedocs.io/en/latest/server-process.html#specifying-config-via-traitlets (to be able to use simply the new tensorboard button and not have to start a terminal each time). 

I created a file '''jupyter_notebook_config.py''' copied to /root/.jupyter/jupyter_notebook_config.py
with the following content : 

```
c.ServerProxy.servers = {
  'tensorboard': {
    'command': ['tensorboard', '--logdir', '/tensorboard' , '--port', '{port}']
  }
}
```
- The first issue is that I dont see tensorboard option in the new toolbar but its not so important...
- If i access to /tensorboard/ Tensorboards starts to run (i can see it in htop) but I get a 504 bad gateway after a while. 
  - If I access /proxy/portNumberGeneratedRandomly it works !

Do you have an idea about whats going on ? 

Thank you for your help, 

Config:
Inside Kubeflow (kubernetes) last version of Jupyter server Proxy and version 1.15 of Tensorboard. 


Hello Guys,

I seem to have run into a bug with HTTP DELETE requests.

I'll try to describe a minimal case to reproduce the issue. 
I have a multi user jupyterhub installed over an anaconda distribution, and have a simple echo server running at port 8000.

Here is a GET request hitting the echo server without going through the proxy : 

```
$ curl -X GET localhost:8000
Method: GET
Path: 
```

Same request over the proxy with the jh token, and works as expected.

```
$ curl -L -H 'Authorization: token <token>' -X GET -k https://localhost/hub/user-redirect/proxy/8000/
Method: GET
Path: /?redirects=1
redirects: 1
```

Now I'm trying a DELETE method directly on the echo server : 

```
$ curl -X DELETE localhost:8000
Method: DELETE
Path: /
```

<details>
  <summary>Attempt the same request via the proxy. (Content folded due to verbose output - click to expand) </summary>

```
$ curl -vvv -L -H 'Authorization: token 179247401ccb4b2c83f7e53f205e8559' -X DELETE -k https://localhost/hub/user-redirect/proxy/8000/
*   Trying 127.0.0.1...
* TCP_NODELAY set
* Expire in 150000 ms for 3 (transfer 0x55b8d93ddf30)
* Expire in 200 ms for 4 (transfer 0x55b8d93ddf30)
* Connected to localhost (127.0.0.1) port 443 (#0)
* ALPN, offering http/1.1
> DELETE /hub/user-redirect/proxy/8000/ HTTP/1.1
> Host: localhost
> User-Agent: curl/7.64.0
> Accept: */*
> Authorization: token <token>
> 
< HTTP/1.1 405 Method Not Allowed
< server: TornadoServer/5.1.1
< content-type: text/html
< date: Mon, 23 Sep 2019 02:04:49 GMT
< x-jupyterhub-version: 1.0.0
< access-control-allow-headers: accept, content-type, authorization
< content-security-policy: frame-ancestors 'self'; report-uri /hub/security/csp-report
< content-length: 4740
< connection: close
< 



<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8">

    <title>JupyterHub</title>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    
    <link rel="stylesheet" href="/hub/static/css/style.min.css?v=883a1cf654bd9f5cdc5ca7c91efe7d71" type="text/css"/>
    
    <script src="/hub/static/components/requirejs/require.js?v=f0cc8bbb2fcef87fc194fecbb632fcfa" type="text/javascript" charset="utf-8"></script>
    <script src="/hub/static/components/jquery/dist/jquery.min.js?v=220afd743d9e9643852e31a135a9f3ae" type="text/javascript" charset="utf-8"></script>
    <script src="/hub/static/components/bootstrap/dist/js/bootstrap.min.js?v=2f34b630ffe30ba2ff2b91e3f3c322a1" type="text/javascript" charset="utf-8"></script>
    <script>
      require.config({
          
          urlArgs: "v=20190923115220",
          
          baseUrl: '/hub/static/js',
          paths: {
            components: '../components',
            jquery: '../components/jquery/dist/jquery.min',
            bootstrap: '../components/bootstrap/dist/js/bootstrap.min',
            moment: "../components/moment/moment",
          },
          shim: {
            bootstrap: {
              deps: ["jquery"],
              exports: "bootstrap"
            },
          }
      });
    </script>

    <script type="text/javascript">
      window.jhdata = {
        base_url: "/hub/",
        prefix: "/",
        
        user: "<user>",
        
        
        admin_access: false,
        
        
        options_form: false,
        
      }
    </script>

    
    

</head>

<body>

<noscript>
  <div id='noscript'>
    JupyterHub requires JavaScript.<br>
    Please enable it to proceed.
  </div>
</noscript>


  <nav class="navbar navbar-default">
    <div class="container-fluid">
      <div class="navbar-header">
        
        <span id="jupyterhub-logo" class="pull-left">
            <a href="/hub/"><img src='/hub/logo' alt='JupyterHub' class='jpy-logo' title='Home'/></a>
        </span>
        
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#thenavbar" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>

      <div class="collapse navbar-collapse" id="thenavbar">
        
        <ul class="nav navbar-nav">
          
            <li><a href="/hub/home">Home</a></li>
            <li><a href="/hub/token">Token</a></li>
            
          
        </ul>
        
        <ul class="nav navbar-nav navbar-right">
          
            <li>
              

            </li>
          
        </ul>
      </div>

      
      
    </div>
  </nav>










<div class="error">
  
  <h1>
    405 : Method Not Allowed
  </h1>
  
  
  
  
  
  
</div>






<div class="modal fade" id="error-dialog" tabindex="-1" role="dialog" aria-labelledby="error-label" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
        <h4 class="modal-title" id="error-label">Error</h4>
      </div>
      <div class="modal-body">
        
  <div class="ajax-error">
    The error
  </div>

      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
        <button type="button" class="btn btn-primary" data-dismiss="modal" data-dismiss="modal">OK</button>
      </div>
    </div>
  </div>
</div>



  


  <script type="text/javascript">
    function _remove_redirects_from_url() {
      if (window.location.search.length <= 1) {
        return;
      }
      var search_parameters = window.location.search.slice(1).split('&');
      for (var i = 0; i < search_parameters.length; i++) {
        if (search_parameters[i].split('=')[0] === 'redirects') {
          // remote redirects from search parameters
          search_parameters.splice(i, 1);
          var new_search = '';
          if (search_parameters.length) {
            new_search = '?' + search_parameters.join('&');
          }
          var new_url = window.location.origin +
                        window.location.pathname +
                        new_search +
                        window.location.hash;
          window.history.replaceState({}, "", new_url);
          return;
        }
      }
    }

    _remove_redirects_from_url();
  </script>


</body>

* Closing connection 0
</html>
``` 
</details>
However this time, it fails with a 405 Method not allowed.

jupyterhub log has: 
```
[W <timestamp> JupyterHub log:174] 405 DELETE /hub/user-redirect/proxy/8000/ (<username>@::ffff:127.0.0.1) 11.28ms
```


Also, In the url, I tried substituting `user-redirect` with my user name. But this time, I get a 404.
(`https://localhost/hub/user-redirect/proxy/8000/` -> `https://localhost/hub/<username>/proxy/8000/`) [1]


Note: I downgraded tornado to 5.1.1 (from 6.0.2), to see if it makes a difference. But it doesn't.

Installed packages:

```
$ conda list 'jupyter|tornado'
# packages in environment
#
# Name                    Version                   Build  Channel
jupyter                   1.0.0                    py37_7  
jupyter-contrib-core      0.3.3                    pypi_0    pypi
jupyter-contrib-nbextensions 0.5.1                    pypi_0    pypi
jupyter-highlight-selected-word 0.2.0                    pypi_0    pypi
jupyter-latex-envs        1.4.6                    pypi_0    pypi
jupyter-nbextensions-configurator 0.4.1                    pypi_0    pypi
jupyter-server-proxy      1.1.0                    pypi_0    pypi
jupyter_client            5.2.4                    py37_0  
jupyter_console           6.0.0                    py37_0  
jupyter_core              4.4.0                    py37_0  
jupyterhub                1.0.0                    pypi_0    pypi
jupyterlab                0.35.4           py37hf63ae98_0  
jupyterlab_server         0.2.0                    py37_0  
tornado                   5.1.1                    pypi_0    pypi
```

Could you advice.

EDIT
[1] : just realised it should be `https://localhost/user/<username>/proxy/8000/` , will test and update.
When trying to run [jupyterlab-nvdashboard](https://github.com/jacobtomlinson/jupyterlab-nvdashboard) on windows I'm getting the following error on startup.

![image](https://user-images.githubusercontent.com/1610850/65372592-409a2a00-dc6a-11e9-8551-662341565cc5.png)
_(Sorry about the screenshot, copying from powershell seems to lose all linebreaks)_

I imagine this is related to the way the server proxy is using asyncio/tornado to create subprocesses.

**Conda env**
```
name: pipeline
channels:
  - conda-forge
  - defaults
dependencies:
  - attrs=19.1.0=py_0
  - backcall=0.1.0=py_0
  - bleach=3.1.0=py_0
  - bokeh=1.3.4=py37_0
  - ca-certificates=2019.5.15=1
  - certifi=2019.6.16=py37_1
  - click=7.0=py_0
  - cloudpickle=1.2.2=py_0
  - colorama=0.4.1=py_0
  - cudatoolkit=10.0.130=0
  - cudnn=7.6.0=cuda10.0_0
  - cupy=6.0.0=py37h230ac6f_0
  - cytoolz=0.10.0=py37hfa6e2cd_0
  - dask=2.4.0=py_0
  - dask-core=2.4.0=py_0
  - decorator=4.4.0=py_0
  - defusedxml=0.5.0=py_1
  - distributed=2.4.0=py_0
  - entrypoints=0.3=py37_1000
  - fastrlock=0.4=py37h6538335_1000
  - freetype=2.10.0=h563cfd7_1
  - fsspec=0.5.1=py_0
  - heapdict=1.0.0=py37_1000
  - intel-openmp=2019.5=281
  - ipykernel=5.1.2=py37h5ca1d4c_0
  - ipython=7.8.0=py37h5ca1d4c_0
  - ipython_genutils=0.2.0=py_1
  - jedi=0.15.1=py37_0
  - jinja2=2.10.1=py_0
  - jpeg=9c=hfa6e2cd_1001
  - json5=0.8.5=py_0
  - jsonschema=3.0.2=py37_0
  - jupyter_client=5.3.1=py_0
  - jupyter_core=4.4.0=py_0
  - jupyterlab=1.1.4=py_0
  - jupyterlab_server=1.0.6=py_0
  - libblas=3.8.0=12_mkl
  - libcblas=3.8.0=12_mkl
  - liblapack=3.8.0=12_mkl
  - libpng=1.6.37=h7602738_0
  - libsodium=1.0.17=h2fa13f4_0
  - libtiff=4.0.10=h6512ee2_1003
  - llvmlite=0.29.0=py37hed17590_1
  - locket=0.2.0=py_2
  - lz4-c=1.8.3=he025d50_1001
  - m2w64-gcc-libgfortran=5.3.0=6
  - m2w64-gcc-libs=5.3.0=7
  - m2w64-gcc-libs-core=5.3.0=7
  - m2w64-gmp=6.1.0=2
  - m2w64-libwinpthread-git=5.0.0.4634.697f757=2
  - markupsafe=1.1.1=py37hfa6e2cd_0
  - mistune=0.8.4=py37hfa6e2cd_1000
  - mkl=2019.4=245
  - msgpack-python=0.6.2=py37he980bc4_0
  - msys2-conda-epoch=20160418=1
  - nbconvert=5.6.0=py37_1
  - nbformat=4.4.0=py_1
  - nodejs=10.13.0=0
  - notebook=6.0.1=py37_0
  - numba=0.45.1=py37hf9181ef_0
  - numpy=1.15.4=py37h8078771_1002
  - olefile=0.46=py_0
  - openssl=1.1.1d=he774522_0
  - packaging=19.2=py_0
  - pandas=0.25.1=py37he350917_0
  - pandoc=2.7.3=0
  - pandocfilters=1.4.2=py_1
  - parso=0.5.1=py_0
  - partd=1.0.0=py_0
  - pickleshare=0.7.5=py37_1000
  - pillow=6.1.0=py37h643dfcc_1
  - pip=19.2.3=py37_0
  - prometheus_client=0.7.1=py_0
  - prompt_toolkit=2.0.9=py_0
  - psutil=5.6.3=py37hfa6e2cd_0
  - pygments=2.4.2=py_0
  - pyparsing=2.4.2=py_0
  - pyrsistent=0.15.4=py37hfa6e2cd_0
  - python=3.7.3=h510b542_1
  - python-dateutil=2.8.0=py_0
  - pytz=2019.2=py_0
  - pywinpty=0.5.5=py37_1000
  - pyyaml=5.1.2=py37hfa6e2cd_0
  - pyzmq=18.1.0=py37h16f9016_0
  - send2trash=1.5.0=py_0
  - setuptools=41.2.0=py37_0
  - six=1.12.0=py37_1000
  - sortedcontainers=2.1.0=py_0
  - sqlite=3.29.0=hfa6e2cd_1
  - tbb=2019.8=he980bc4_0
  - tblib=1.4.0=py_0
  - terminado=0.8.2=py37_0
  - testpath=0.4.2=py_1001
  - tk=8.6.9=hfa6e2cd_1003
  - toolz=0.10.0=py_0
  - tornado=6.0.3=py37hfa6e2cd_0
  - traitlets=4.3.2=py37_1000
  - vc=14.1=h0510ff6_4
  - vs2015_runtime=14.16.27012=hf0eaf9b_0
  - wcwidth=0.1.7=py_1
  - webencodings=0.5.1=py_1
  - wheel=0.33.6=py37_0
  - wincertstore=0.2=py37_1002
  - winpty=0.4.3=4
  - xz=5.2.4=h2fa13f4_1001
  - yaml=0.1.7=hfa6e2cd_1001
  - zeromq=4.3.2=h6538335_2
  - zict=1.0.0=py_0
  - zlib=1.2.11=h2fa13f4_1006
  - zstd=1.4.0=hd8a0e53_0
  - pip:
    - aiohttp==3.6.1
    - async-timeout==3.0.1
    - chardet==3.0.4
    - idna==2.8
    - jupyter-server-proxy==1.1.0
    - jupyterlab-nvdashboard==0.1.9
    - multidict==4.5.2
    - pynvml==8.0.3
    - simpervisor==0.3
    - yarl==1.3.0
prefix: C:\Users\jacob\Miniconda3\envs\pipeline
```
I am trying to install rstudio alongside r-notebook, and install jupyter-server-proxy and jupyter-rsession-proxy with the following Dockerfile

```
FROM jupyter/r-notebook:latest

USER root

RUN git clone https://github.com/TheLocehiliosan/yadm.git /usr/local/share/yadm && \
    ln -s /usr/local/share/yadm/yadm /usr/local/bin/yadm

RUN apt-get update && \
    curl --silent -L --fail https://s3.amazonaws.com/rstudio-ide-build/server/bionic/amd64/rstudio-server-1.2.1578-amd64.deb > /tmp/rstudio.deb && \
    echo '81f72d5f986a776eee0f11e69a536fb7 /tmp/rstudio.deb' | md5sum -c - && \
    apt-get install -y --no-install-recommends /tmp/rstudio.deb && \
    rm /tmp/rstudio.deb && \
    apt-get clean && rm -rf /var/lib/apt/lists/* && apt-get remove -y r-*
ENV PATH=$PATH:/usr/lib/rstudio-server/bin

ENV R_HOME=/opt/conda/lib/R
ARG LITTLER=$R_HOME/library/littler

RUN echo "local({\n" \
         "   r <- getOption('repos')\n" \
         "   r['CRAN'] <- 'https://cloud.r-project.org'\n" \
         "   options(repos = r)\n" \
         "})\n" > $R_HOME/etc/Rprofile.site && \
         \
         R -e "install.packages(c('littler', 'docopt'))"
RUN sed -i 's/\/usr\/local\/lib\/R\/site-library/\/opt\/conda\/lib\/R\/library/g' $LITTLER/examples/*.r && \
	ln -s $LITTLER/bin/r $LITTLER/examples/*.r /usr/local/bin/ && \
	echo "$R_HOME/lib" | sudo tee -a /etc/ld.so.conf.d/littler.conf && \
	ldconfig

USER $NB_UID

RUN pip install nbgitpuller && \
    conda install -c conda-forge jupyter-server-proxy jupyter-rsession-proxy
```

I am getting the following error, which I can't seem to get rid of. However, the R studio seems to work fine except for this error. Is this just for keep-alive?

```
datascience-notebook_1  | Set username to: jovyan
datascience-notebook_1  | usermod: no changes
datascience-notebook_1  | Granting jovyan sudo access and appending /opt/conda/bin to sudo PATH
datascience-notebook_1  | Executing the command: jupyter lab --NotebookApp.password=sha1:8bc986167428:ec8719e895f4d408e658c23835844b3088bca5a9 --NotebookApp.certfile=/etc/ssl/notebook/mycert.pem --NotebookApp.keyfile=/etc/ssl/notebook/mykey.key
datascience-notebook_1  | [I 04:11:20.826 LabApp] JupyterLab extension loaded from /opt/conda/lib/python3.7/site-packages/jupyterlab
datascience-notebook_1  | [I 04:11:20.826 LabApp] JupyterLab application directory is /opt/conda/share/jupyter/lab
datascience-notebook_1  | [I 04:11:20.830 LabApp] Serving notebooks from local directory: /home/jovyan
datascience-notebook_1  | [I 04:11:20.830 LabApp] The Jupyter Notebook is running at:
datascience-notebook_1  | [I 04:11:20.830 LabApp] https://c55987e28ee9:8888/
datascience-notebook_1  | [I 04:11:20.830 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
datascience-notebook_1  | [W 04:11:57.370 LabApp] SSL Error on 9 ('111.111.111.111', 57084): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:57.370 LabApp] SSL Error on 10 ('111.111.111.111', 57086): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [I 04:11:57.423 LabApp] 302 GET / (111.111.111.111) 1.33ms
datascience-notebook_1  | [W 04:11:57.640 LabApp] SSL Error on 10 ('111.111.111.111', 57090): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:58.750 LabApp] SSL Error on 10 ('111.111.111.111', 57096): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:58.760 LabApp] SSL Error on 11 ('111.111.111.111', 57094): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:58.761 LabApp] SSL Error on 12 ('111.111.111.111', 57092): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:58.853 LabApp] SSL Error on 14 ('111.111.111.111', 57106): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:58.858 LabApp] SSL Error on 13 ('111.111.111.111', 57104): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:59.286 LabApp] SSL Error on 14 ('111.111.111.111', 57108): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [W 04:11:59.308 LabApp] SSL Error on 15 ('111.111.111.111', 57110): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:1056)
datascience-notebook_1  | [I 04:11:59.588 LabApp] Build is up to date
datascience-notebook_1  | [I 04:12:06.723 LabApp] 302 GET /rstudio (111.111.111.111) 1.44ms
datascience-notebook_1  | [I 04:12:07.016 LabApp] 302 GET /rstudio (111.111.111.111) 1.16ms
datascience-notebook_1  | /usr/lib/rstudio-server/bin/rsession: Relink `/opt/conda/lib/R/lib/../.././libgfortran.so.4' with `/lib/x86_64-linux-gnu/librt.so.1' for IFUNC symbol `clock_gettime'
datascience-notebook_1  | [E 04:12:35.730 LabApp] Uncaught exception POST /rstudio/events/get_events (111.111.111.111)
datascience-notebook_1  |     HTTPServerRequest(protocol='https', host='110.110.110.110:8887', method='POST', uri='/rstudio/events/get_events', version='HTTP/1.1', remote_ip='111.111.111.111')
datascience-notebook_1  |     Traceback (most recent call last):
datascience-notebook_1  |       File "/opt/conda/lib/python3.7/site-packages/tornado/web.py", line 1699, in _execute
datascience-notebook_1  |         result = await result
datascience-notebook_1  |       File "/opt/conda/lib/python3.7/site-packages/jupyter_server_proxy/handlers.py", line 434, in proxy
datascience-notebook_1  |         return await super().proxy(self.port, path)
datascience-notebook_1  |       File "/opt/conda/lib/python3.7/site-packages/jupyter_server_proxy/handlers.py", line 199, in proxy
datascience-notebook_1  |         response = await client.fetch(req, raise_error=False)
datascience-notebook_1  |     tornado.simple_httpclient.HTTPTimeoutError: Timeout during request
datascience-notebook_1  | [E 04:12:35.762 LabApp] Could not open static file ''
datascience-notebook_1  | [E 04:12:35.763 LabApp] {
datascience-notebook_1  |       "Host": "110.110.110.110:8887",
datascience-notebook_1  |       "Connection": "keep-alive",
datascience-notebook_1  |       "Content-Length": "149",
datascience-notebook_1  |       "Sec-Fetch-Mode": "cors",
datascience-notebook_1  |       "Origin": "https://110.110.110.110:8887",
datascience-notebook_1  |       "X-Csrf-Token": "d9881612-d8e6-4d21-85d1-5b131c645780",
datascience-notebook_1  |       "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36",
datascience-notebook_1  |       "Content-Type": "application/json",
datascience-notebook_1  |       "Accept": "application/json",
datascience-notebook_1  |       "X-Rs-Rid": "-1304597456",
datascience-notebook_1  |       "Dnt": "1",
datascience-notebook_1  |       "Sec-Fetch-Site": "same-origin",
datascience-notebook_1  |       "Referer": "https://110.110.110.110:8887/rstudio/",
datascience-notebook_1  |       "Accept-Encoding": "gzip, deflate, br",
datascience-notebook_1  |       "Accept-Language": "en-US,en;q=0.9,ko;q=0.8",
datascience-notebook_1  |       "Cookie": "port-token=d6722da5d331; username-110-110-110-110-8888=\"2|1:0|10:1567738412|28:username-110-110-110-110-8888|44:OWJiMDgwMDJkMDliNDBhM2I0ODgzYTdjYWYzMzIxMzE=|473c88faa331af0c7daebcb1e8a1001c563ada26657dab0bdc46dbc7bba35684\"; _xsrf=2|ad2e4a8f|8bfda290a46f6003266ac8e302109d43|1567810202; csrf-token=d9881612-d8e6-4d21-85d1-5b131c645780; username-110.110.110.110-8887=\"2|1:0|10:1567827401|28:username-110.110.110.110-8887|44:YzY0YzZhNzI0MTU1NGJhMmFiY2YyYjBmYjNmMDFmYTI=|bf5a7f5b564fddbccd7f33eb1cd09e948aebc170f93dc33dd7e48e13e98b306d\""
datascience-notebook_1  |     }
datascience-notebook_1  | [E 04:12:35.763 LabApp] 500 POST /rstudio/events/get_events (111.111.111.111) 20056.74ms referer=https://110.110.110.110:8887/rstudio/
datascience-notebook_1  | [E 04:12:56.882 LabApp] Uncaught exception POST /rstudio/events/get_events (111.111.111.111)
datascience-notebook_1  |     HTTPServerRequest(protocol='https', host='110.110.110.110:8887', method='POST', uri='/rstudio/events/get_events', version='HTTP/1.1', remote_ip='111.111.111.111')
datascience-notebook_1  |     Traceback (most recent call last):
datascience-notebook_1  |       File "/opt/conda/lib/python3.7/site-packages/tornado/web.py", line 1699, in _execute
datascience-notebook_1  |         result = await result
datascience-notebook_1  |       File "/opt/conda/lib/python3.7/site-packages/jupyter_server_proxy/handlers.py", line 434, in proxy
datascience-notebook_1  |         return await super().proxy(self.port, path)
datascience-notebook_1  |       File "/opt/conda/lib/python3.7/site-packages/jupyter_server_proxy/handlers.py", line 199, in proxy
datascience-notebook_1  |         response = await client.fetch(req, raise_error=False)
datascience-notebook_1  |     tornado.simple_httpclient.HTTPTimeoutError: Timeout during request
datascience-notebook_1  | [E 04:12:56.885 LabApp] {
datascience-notebook_1  |       "Host": "110.110.110.110:8887",
datascience-notebook_1  |       "Connection": "keep-alive",
datascience-notebook_1  |       "Content-Length": "149",
datascience-notebook_1  |       "Sec-Fetch-Mode": "cors",
datascience-notebook_1  |       "Origin": "https://110.110.110.110:8887",
datascience-notebook_1  |       "X-Csrf-Token": "d9881612-d8e6-4d21-85d1-5b131c645780",
datascience-notebook_1  |       "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36",
datascience-notebook_1  |       "Content-Type": "application/json",
datascience-notebook_1  |       "Accept": "application/json",
datascience-notebook_1  |       "X-Rs-Rid": "-2033399115",
datascience-notebook_1  |       "Dnt": "1",
datascience-notebook_1  |       "Sec-Fetch-Site": "same-origin",
datascience-notebook_1  |       "Referer": "https://110.110.110.110:8887/rstudio/",
datascience-notebook_1  |       "Accept-Encoding": "gzip, deflate, br",
datascience-notebook_1  |       "Accept-Language": "en-US,en;q=0.9,ko;q=0.8",
datascience-notebook_1  |       "Cookie": "port-token=d6722da5d331; username-110-110-110-110-8888=\"2|1:0|10:1567738412|28:username-110-110-110-110-8888|44:OWJiMDgwMDJkMDliNDBhM2I0ODgzYTdjYWYzMzIxMzE=|473c88faa331af0c7daebcb1e8a1001c563ada26657dab0bdc46dbc7bba35684\"; _xsrf=2|ad2e4a8f|8bfda290a46f6003266ac8e302109d43|1567810202; csrf-token=d9881612-d8e6-4d21-85d1-5b131c645780; username-110.110.110.110-8887=\"2|1:0|10:1567827401|28:username-110.110.110.110-8887|44:YzY0YzZhNzI0MTU1NGJhMmFiY2YyYjBmYjNmMDFmYTI=|bf5a7f5b564fddbccd7f33eb1cd09e948aebc170f93dc33dd7e48e13e98b306d\""
datascience-notebook_1  |     }
datascience-notebook_1  | [E 04:12:56.886 LabApp] 500 POST /rstudio/events/get_events (111.111.111.111) 20027.09ms referer=https://110.110.110.110:8887/rstudio/
```

What might be going wrong? What am I missing? Your help is appreciated!
I find the placement of the launcher entries in JupyterLab in the "Notebook" section to be kind of weird, since they are mostly not notebooks. Why not put them in the "other" category?