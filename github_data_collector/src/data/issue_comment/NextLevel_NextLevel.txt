I have been having problems with audio falling out of sync because of multiple audio buffers being skipped frequently. I am not sure what is the exact cause of the frames dropping, since it's hard to debug, but I rewritten fix from this fork: https://github.com/shaharyakir/NextLevel, which simply stores buffers that failed to attach and tries to re-append them together with the next frame.

It seems it solves most of the issues with audio sync for me. Is there something I am missing or can this be merged into master? Would this make sense to do also for video buffers? While video frame drops are more rare, it still does happen at times.
- Add ability to attach custom metadata to the writer output
- Useful if you want to attach e.g. CLLocation at the time of recording
**NextLevel release version: 0.16**

Users of my app are reporting crashes when capturing photos.
I analyzed crash reports and it looks the crashes occurs **only on `iPhone 6s` (iOS 13.3.0)**.

Crash occurs after calling `NextLevel.shared.capturePhoto()` and the message is:

> *** -[AVCapturePhotoOutput capturePhotoWithSettings:delegate:] settings.processedFileType must be present in self.availablePhotoFileTypes


My camera configuration code is pretty straightforward:
```swift
// Configure camera
let nextLevel = NextLevel.shared
nextLevel.captureMode = .photo
nextLevel.photoDelegate = self
nextLevel.photoConfiguration.preset = .high
```


I don't have iPhone 6s so it's hard for me to debug it but perhaps you folks will know where the issue is coming from.

___

Edit: my guess is that NextLevel sets codec to `hevc` on all iOS 11 devices but it's only supported on iPhone 7 and newer. iPhone 6s can process hevc photos but they can't capture in that format.
Is there any functionality or property to add watermark image over video?
```
        NextLevel.shared.captureMode = .photo
        NextLevel.shared.photoConfiguration.isHighResolutionEnabled = true

        NextLevel.shared.capturePhoto()

```

Returned `AVCapturePhoto` is:

`<AVCapturePhoto: 0x283834000 pts:823209.663467 1/1 settings:uid:3  photo:{4224x2376} time:0.168-0.485>`

As you can see, this is a 16x9 resolution. I've tried tinkering with other settings to try and get a 4:3 output, but to no luck. What am I missing? Thanks
I only saw how to use the api to record video in the example, but how to record photo, Can you provide 
 a exampleï¼Œplease help me. 
I have a requirement wherein I need to use these inputs to calculate the distance

I am able to fetch focal length along the X and Y axis but not sure how can I use this

```
public func focalLengthAndPrinciplePoint(focalLengthX: inout Float, focalLengthY: inout Float, principlePointX: inout Float, principlePointY: inout Float){
 
}

```
Any input will be really appreciated.
Experiencing something odd, when I record a set of clips and playback the saved video the video plays perfectly in the correct orientation, when exported, it is flipped upside down. Ideas?
I'm facing the issue "flipCaptureDevicePosition" to rotate the camera with font especially on iPhone 11.

I'm using below code to change the mode of the camera :

`NextLevel.shared.flipCaptureDevicePosition()`

By apply this its working fine with iPhone X, 8, 7 & all other devices but the same code is making an issue with iPhone 11 to show font camera view.

I have also make sure Im using the very updated pod version 0.16.0 but still having an issue to get the required output.

Kindly help me in this case. 

First, Thanks for this Libray

I set deviceOrientation = .portrait and output the image by photo.fileDataRepresentation()!

But when i take photos and show, the images orientantion is equal iphone orientation 

I want the images orientation is portrait but i cant fix, and all of image.imageOrientation are portrial

how to set the nextlevel?
