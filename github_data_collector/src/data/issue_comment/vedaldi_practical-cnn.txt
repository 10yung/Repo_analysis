i want to know where can get the standard answer about those taskï¼Ÿ
In the BP formulation(1), the x(L) should be x(L-1), and other formulations have the same problem.
The corresponding formulation in the matconvnet manual is right.
I want to train the vgg-vd-16 model from scratch, which parameter initialization method should I choose, gaussian or xavier or xavierimproved?
For example, in exercise 3, why you compute dzdx3 as follows:
dzdx3 = ...
    - single(res.x3 < 1 & pos) / sum(pos(:)) + ...
    + single(res.x3 > 0 & neg) / sum(neg(:)) ;
In other words, how to obtain the initial project tensor p in practice?
hi,
in part 2 there is a calculation of dzdx_empirical ,
can somone help and explain the calculation? why is there a sum? and why is there a division by eta and not a division by etx*ex (as i expected to be)?

thanks!

% Check the derivative numerically
ex = randn(size(x), 'single') ;
eta = 0.0001 ;
xp = x + eta * ex  ;
yp = vl_nnconv(xp, w, []) ;

dzdx_empirical = sum(dzdy(:) .* (yp(:) - y(:)) / eta) ;
dzdx_computed = sum(dzdx(:) .* ex(:)) ;

fprintf(...
  'der: empirical: %f, computed: %f, error: %.2f %%\n', ...
  dzdx_empirical, dzdx_computed, ...
  abs(1 - dzdx_empirical/dzdx_computed)*100) ;






Propose to add some titles to the images to be more clear what is what.
Propose to add some pauses, to that it would be possible to view the results step by step (less overwhelming).

Each time exercise5 is run, the results are different. Figure headings are 

1st time:  bell pepper (946), score 0.848
2nd time: bell pepper (946) score 0.303
3rd time: balloon( 418) score 0.647
: varying answers after that

There is no change by setting vl_simplenn options to 'disableDropout', 'true', --the results still vary.  This is on a Ubuntu 14.04, Matlab R2016a, with gcc 4.7.  There are no compiler warnings when setup is run (with default options).   

When exercise5 is run on a Mac Powerbook, with Matlab R2015a, it is stable. Results are the same every time.  

Hello,

I am trying to segment medical image using "softmaxloss" which refer to "vl_nnloss". I can segment my image using this example. But when I use "softmaxloss" layer, removing the last layer (forward and backward pass) as follows:

%remove this
net = addCustomLossLayer(net, @l2LossForward, @l2LossBackward) ;

%add this
net.layers{end+1} = struct(...
  'name', 'loss', ...
  'type', 'softmaxloss') ;

But my objective function generate error '0'. I couldn't figure out what else I should do to make this work with "softmaxloss/vl_nnloss" instead of regression. I will appreciate any kind of help. 

![output](https://cloud.githubusercontent.com/assets/18714137/17692909/504b128e-63d7-11e6-8228-7c3ed612d7ad.png)

Sincerely
Hosna

Specifically to the questions in the practicals. Thanks! :) 

I downloaded the files and everything but I've had trouble getting VLFeat to work. In particular its suggest to do:

```
0. Set the current directory to the practical base directory.
1. From Bash:
   1. Run `./extras/download.sh`. This will download the
      `imagenet-vgg-verydeep-16.mat` model as well as a binary
      copy of the VLFeat library and a copy of MatConvNet.
   2. Run `./extra/genfonts.sh`. This will download the Google Fonts
      and extract them as PNG files.
   3. Run `./extra/genstring.sh`. This will create
      `data/sentence-lato.png`.
2. From MATLAB run `addpath extra ; packFonts ;`. This will create
   `data/charsdb.mat`.
3. Test the practical: from MATLAB run all the exercises in order.
```

but it doesn't quite work because extra is not defined or anywhere to be found. Whats going on?

in particular I am trying to do:

% Visualize the output y
figure(2) ; clf ; vl_imarraysc(y) ; colormap gray ;

of the tutorial but matlab throws errors.

Thanks!
