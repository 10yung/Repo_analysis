I like `anyValue()` and I'd like to add `anyGreater()`, `anyLess()`, `anyGreaterOrEqual()` etc plus all of the row and column variants. I often find myself doing `any(x > 3)` or something like that and these calculations are inefficient in base R because the whole of `x > 3` gets calculated.
I can do this as a PR but I want to make sure you like the idea before going and doing it. If you like it, advice on how to name these functions would be appreciated.
Hi Henrik,

Great resource for matrix stats...is there any plans to implement these functions for sparse matrices? I understand that these functions are implemented for DelayedArrays, so that is an alternative...but may R packages do not support these arrays but do seem to support sparse matrices. 

Best,
--Tony
I was recently stumbling over the weighted* functions with logical input:

```
weightedMean(1:10 > 5) # Error
weightedMedian(1:10 > 5) # Error
weightedVar(1:10 > 5) # Works
```
Would it be possible to catch this case in an efficient way?

This is not meant as a full PR, but is meant to support the discussion in #160 . 
This simple change fixes the result and the numerical stability issue but does not check the center argument for sensible length.
Is `rowVars(mat-center)` supposed to be equal to `rowVars(mat, center)`?  Or only if `center==rowMeans(mat)`?

The former is not the case:
``` r
mat <- matrix(1:6, 2, 3)
matrixStats::rowVars(mat, center=1:2)
#> [1] 16 22
matrixStats::rowVars(mat-(1:2))
#> [1] 4 4
```

In any case, the current algorithm (with center) is numerically instable (@LTLA made me aware of that in a related case):
``` r
mat <- matrix(rnorm(100), 25, 4)+1E9
matrixStats::colVars(mat, center=colMeans(mat))
#> [1] 133.3333   0.0000   0.0000 133.3333
matrixStats::colVars(mat)
#> [1] 1.1828330 1.6575854 0.8001706 1.0915187
```

Furthermore, `center` accepts vectors of any length for which `max(length(center), nrow(mat))` is a multiple of `min(length(center), nrow(mat)`, leading to strange results:
``` r
mat <- matrix(1:6, 2, 3)
matrixStats::rowVars(mat, center=1:8)
#> [1]  16  22   4   4 -20 -26 -56 -68
````

`colVars` is equally affected.

I'll open a PR to highlight the issue in the code, but would only have time on the weekend to provide a full PR.
This seems like an easy win: I just add `if (is.logical(x)) x <- as.integer(x)` within the required functions. 
Love the package and have usually found it performant. Noticed one slightly lengthy computation of `rowSums2` and on benchmarking found it to be generally slower than `base::rowSums` for even moderately-sized matrices. Integer/double storage mode not at issue, though wider matrices tend to suffer more than tall ones.

Not critical at all for me -- just thought to share.

```r
library(bench)
library(matrixStats)

benches <- 
  bench::press(nrows = c(1e3, 1e4, 2e4),
               ncols = c(1e3, 1e4, 1e5),
               typeo = c("integer", "double"), 
               {
                 M <- matrix(rep_len(sample.int(1e6), 
                                     nrows * ncols),
                             nrow = nrows,
                             ncol = ncols)
                 if (typeo == "double") {
                   storage.mode(M) <- "double"
                 }
                 
                 bench::mark(rowSums(M),
                             rowSums2(M))
                 
               })
library(knitr)
benches %>%
  benches %>% 
  dplyr::select(expression, nrows, ncols, typeo, median, mem_alloc) %>%
  dplyr::mutate(median = as.character(median), 
                mem_alloc = as.character(mem_alloc)) %>% 
  kable(align = "lrrrrr")
```


|expression  | nrows|  ncols|   typeo|      median| mem_alloc|
|:-----------|-----:|------:|-------:|-----------:|---------:|
|rowSums(M)  |  1000|   1000| integer|     2.178ms|   7.859KB|
|rowSums2(M) |  1000|   1000| integer|     1.259ms|  15.727KB|
|rowSums(M)  | 10000|   1000| integer|    20.774ms|  78.172KB|
|rowSums2(M) | 10000|   1000| integer|    17.505ms|  86.039KB|
|rowSums(M)  | 20000|   1000| integer|    41.172ms| 156.297KB|
|rowSums2(M) | 20000|   1000| integer|    34.932ms| 164.164KB|
|rowSums(M)  |  1000|  10000| integer|    21.748ms|   7.859KB|
|rowSums2(M) |  1000|  10000| integer|    50.152ms|  86.039KB|
|rowSums(M)  | 10000|  10000| integer|   205.806ms|  78.172KB|
|rowSums2(M) | 10000|  10000| integer|   846.958ms| 156.352KB|
|rowSums(M)  | 20000|  10000| integer|   414.772ms| 156.297KB|
|rowSums2(M) | 20000|  10000| integer|  2823.719ms| 234.477KB|
|rowSums(M)  |  1000| 100000| integer|   217.868ms|   7.859KB|
|rowSums2(M) |  1000| 100000| integer|   861.286ms| 789.164KB|
|rowSums(M)  | 10000| 100000| integer|  2072.226ms|  78.172KB|
|rowSums2(M) | 10000| 100000| integer| 17011.231ms| 859.477KB|
|rowSums(M)  | 20000| 100000| integer|  4134.591ms| 156.297KB|
|rowSums2(M) | 20000| 100000| integer| 51381.608ms| 937.602KB|
|rowSums(M)  |  1000|   1000|  double|     2.073ms|   7.859KB|
|rowSums2(M) |  1000|   1000|  double|     1.150ms|  15.727KB|
|rowSums(M)  | 10000|   1000|  double|    20.872ms|  78.172KB|
|rowSums2(M) | 10000|   1000|  double|    21.605ms|  86.039KB|
|rowSums(M)  | 20000|   1000|  double|    41.800ms| 156.297KB|
|rowSums2(M) | 20000|   1000|  double|    56.464ms| 164.164KB|
|rowSums(M)  |  1000|  10000|  double|    20.949ms|   7.859KB|
|rowSums2(M) |  1000|  10000|  double|    61.742ms|  86.039KB|
|rowSums(M)  | 10000|  10000|  double|   209.302ms|  78.172KB|
|rowSums2(M) | 10000|  10000|  double|  1522.607ms| 156.352KB|
|rowSums(M)  | 20000|  10000|  double|   423.688ms| 156.297KB|
|rowSums2(M) | 20000|  10000|  double|  3047.046ms| 234.477KB|
|rowSums(M)  |  1000| 100000|  double|   202.939ms|   7.859KB|
|rowSums2(M) |  1000| 100000|  double|  1356.072ms| 789.164KB|
|rowSums(M)  | 10000| 100000|  double|  2102.539ms|  78.172KB|
|rowSums2(M) | 10000| 100000|  double| 25610.084ms| 859.477KB|
|rowSums(M)  | 20000| 100000|  double|  4261.124ms| 156.297KB|
|rowSums2(M) | 20000| 100000|  double| 41687.982ms| 937.602KB|
This issue is a question / feature request.

Do you think it would make sense to add functions like `duplicated()` and `anyDuplicated()` optimized to work on every row/column to this package?
It would be nice to have this feature when `rowDiffs()` / `colDiffs()` is used within intermediate calculations that require positional matching.

```r
x <- matrix(1:27, ncol = 3)
```

```r
library(matrixStats)
colDiffs(x)
     [,1] [,2] [,3]
[1,]    1    1    1
[2,]    1    1    1
[3,]    1    1    1
[4,]    1    1    1
[5,]    1    1    1
[6,]    1    1    1
[7,]    1    1    1
[8,]    1    1    1
```

### With `na.pad` set to TRUE
```r
library(xts)
xts::diff.xts(x, na.pad = TRUE)
      [,1] [,2] [,3]
 [1,]   NA   NA   NA
 [2,]    1    1    1
 [3,]    1    1    1
 [4,]    1    1    1
 [5,]    1    1    1
 [6,]    1    1    1
 [7,]    1    1    1
 [8,]    1    1    1
 [9,]    1    1    1
```

Also, on a different note I think `dim.` argument is not coerced to integer as intended when the `dim.` is given manually.  I believe the expression `dim <- as.integer(dim.)` was placed there to enforce it, but it's not passed into `C` call:

```r
 body(colDiffs)
{
    dim <- as.integer(dim.)
    .Call(C_rowDiffs, x, dim., rows, cols, as.integer(lag), as.integer(differences), 
        FALSE)
}
```
 Used an algorithm with partial sorting for speed.  See #75 