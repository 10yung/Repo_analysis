Hi,

In the code cnn_toxic.py shouldn't the the condition be "if i < num_words" instead of "if i <MAX_VOCAB_SIZE" ?

# prepare embedding matrix
print('Filling pre-trained embeddings...')
num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)
embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))
for word, i in word2idx.items():
  if i < MAX_VOCAB_SIZE:
    embedding_vector = word2vec.get(word)
    if embedding_vector is not None:
      # words not found in embedding index will be all zeros.
      embedding_matrix[i] = embedding_vector

Regards,
Hello,

It would be great if you could add the project requirements (requirements.txt, or in some other form). Installing the required libraries is not enough, since we end up not having the correct library versions for running the code.

Thanks
Closes #47.  Tests will run automatically on all code changes.

![Screenshot 2019-11-14 at 20 21 30](https://user-images.githubusercontent.com/3709715/68889277-e45cff00-071c-11ea-89c1-17ab80a12057.png)
Iran is one of the most seismic countries of the world. It is situated over the Himalayan-Alpide seismic belt and is one of those countries, which have lost many human lives and a lot of money due to the occurrence of earthquakes. Here a model is built using Machine Learning to predict PGA in this region.

The dataset was split into input part and the PGA value which was supposed to be predicted. The input part was standardised using ​StandardScalar. ● Now, the entire dataset was split into ​test set ​and​ training set. ● We trained the model using ​Logistic Regression, K-Nearest Neighbours(KNN) ​and Random Forest Regression ​using the training set. ● The trained models were tested with the test set to ​predict the efficiency​ of the model. ● Finally, two ​Ensemble models ​ were created combining the previous models, one is the Averaging​ technique and the other is ​Blending​ technique. The efficiency of the models were predicted by calculating the Mean Average Error​ MAE ​ , Mean Squared Error- ​ MSE ​ and Root Mean Squared Error- R ​ MSE. Lower the value, the higher is the efficiency. 
 
  

Artificial neural networks (ANNs) are powerful tools for machine learning with
applications in many areas including speech recognition, image classification,
medical diagnosis, and spam filtering. The Backpropagation algorithm which
learns the weights for a multilayer network, given a network with a fixed set of
units and interconnections. It employs gradient descent to attempt to minimize
the squared error between the network output values and target values for these
outputs.
To Find a specific hypothesis in a set of hypothesis, which is consistent with
positive training example. I have used Tennis Dataset with one of the most simplest Algorithm.
Added env.env.close() in order to remove the error:

Traceback (most recent call last):
  File "/home/ekele/anaconda3/envs/gpurl/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py", line 143, in __del__
  File "/home/ekele/anaconda3/envs/gpurl/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py", line 62, in close
  File "/home/ekele/anaconda3/envs/gpurl/lib/python3.6/site-packages/pyglet/window/xlib/__init__.py", line 480, in close
  File "/home/ekele/anaconda3/envs/gpurl/lib/python3.6/site-packages/pyglet/gl/xlib.py", line 345, in destroy
  File "/home/ekele/anaconda3/envs/gpurl/lib/python3.6/site-packages/pyglet/gl/base.py", line 334, in destroy
  File "/home/ekele/anaconda3/envs/gpurl/lib/python3.6/site-packages/pyglet/gl/xlib.py", line 335, in detach
  File "/home/ekele/anaconda3/envs/gpurl/lib/python3.6/site-packages/pyglet/gl/lib.py", line 97, in errcheck
ImportError: sys.meta_path is None, Python is likely shutting down
Hi, I use the code DQN, I can run the code successfully, but I find the GPU utilization is really low, about 8%. I use the 2080Ti and I use the GPU by adding the code at the begining of the DQN file.
```
import os

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
```
How can I improve the GPU utilization?  Thanks!!
Legacy __print__ statements are syntax errors in Python 3 but __print()__ function works as expected in both Python 2 and Python 3.

A superset of #40