https://github.com/ropensci/rtweet/blob/f9cada85b60101abce14c19afb8c4707202ad699/R/search_tweets.R#L403

Twitter premium now allows up to 500 per request. I think this should be modified. 


<!-- This is an issue template for bugs and requests for R pkg rtweet -->

<!-- If you've encountered a likely bug in rtweet, please take a few seconds to 
look through existing issues for a similar issue. If you don't see a related 
issue, please complete the prompts below to make it easier to replicate and 
[hopefully] resolve your issue.  -->

### Problem

I can't retrieve all of realDonaldTrump tweets. I sometimes get only a few, or a couple hundred. 

### Expected behavior

Using `get_timeline` I would expect to get all of realDonaldTrump's recent 3200 tweets.

### Reproduce the problem

<!-- Describe and provide relevant code to reproduce the problem -->
<!-- If code doesn't always produce error, provide approximate code anyway -->

``` r
djt <- get_timeline("realDonaldTrump", n = 3200)
nrow(djt)
```

### rtweet version

<!-- run the code below and copy/paste the output -->
0.7.0


### Session info

R version 3.6.1 (2019-07-05)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Catalina 10.15.2

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.6.1


### Token

run the code below and copy/paste the output. if you don't feel comfortable 
sharing that information, then share the first 3-4 characters for the 
oauth_app ($APP_NAME$) and key ($KEY$) as they appear in the printed output 
#> <Token>
#> <oauth_endpoint>
#>  request:   https://api.twitter.com/oauth/request_token
#>  authorize: https://api.twitter.com/oauth/authenticate
#>  access:    https://api.twitter.com/oauth/access_token
#> <oauth_app> pol*****
#>   key:    Snh****************
#>   secret: <hidden>
#> <credentials> oauth_token, oauth_token_secret, user_id, screen_name



<!-- If you think the problem may be related to features/limitations of 
Twitter's API, you can find more information about Twitter's APIs here: 
https://developer.twitter.com/en/docs.html -->

<!-- Thank you for using and improving rtweet!  -->

Closes #380.

My .Renviron didn't like having `\\` in the path. Updated to normalize to `/`.
### Problem

I created a token following the instructions in the vignette (using the access_token method). I then restarted my R session and tried to get_token, but it launched a browser window to allow the rtweet app to access my account.

### Expected behavior

It should have reloaded my token.

### Reproduce the problem

This appears to be a windows-specific issue (and COULD be idiosyncratic to something about my machine). This is what was added to my .Renviron: `TWITTER_PAT=C:\Users\jonth\Documents/.rtweet_token.rds`

Updating the `\`'s to `/`'s manually fixed the issue.

### rtweet version

<!-- run the code below and copy/paste the output -->

``` r
## copy/paste output
packageVersion("rtweet")

[1] ‘0.7.0’
```


### Session info

<!-- run the code below and copy/paste the output -->

``` r
## copy/paste output
sessionInfo()

R version 3.6.2 (2019-12-12)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] rtweet_0.7.0

loaded via a namespace (and not attached):
[1] httr_1.4.1     compiler_3.6.2 magrittr_1.5   R6_2.4.1       tools_3.6.2   
[6] jsonlite_1.6   packrat_0.5.0 
```
My concern was that when parsing large numbers of tweets, gigabytes of data would accumulate without having a good way to start their processing (other than closing and reopening the stream). If we implement a way to redirect the data stream to the standard output, then it can be piped to the `split` command, and subsequently, blocks of data can be parsed as soon as they are downloaded.

A working example with a new parameter `write_json_stdout` can be found here: https://github.com/albertojleon/rtweet/blob/master/R/stream.R

What do you think?
Fixes [issue 362](https://github.com/ropensci/rtweet/issues/362).
Update search_tweets such that the search_fullarchive function supports max 500 tweets per request, which is the limit for the Twitter premium API. Fixing this bug is important because it can double or more the cost of using the Twitter premium API.
Thanks for this great package! This is a suggestion:

It will be great if the user was able to choose the delimiter as a parameter for  'flatten()` and thus `write_as_csv()`

Let me know if it sounds useful. Happy to do a PR with this small change implemented
I've been working on building twitter networks elsewhere and had already laid a foundation before realizing that rtweet now has some built-in functionality, so I've got some lessons-learned that may be of interest.

I changed `unroll_connections()` so that it doesn't mangle UTF-8 data on Windows (`std::string` pains); building networks such as user-to-hashtag will now be safe for Windows folks if that's something desired in the future.

The algorithm is a bit simpler than the previous one and skips the `std::vectors`. My benchmarks are showing that it's >= 3x faster.
<!-- If you've encountered a likely bug in rtweet, please take a few seconds to 
look through existing issues for a similar issue. If you don't see a related 
issue, please complete the prompts below to make it easier to replicate and 
[hopefully] resolve your issue.  -->

### Problem

Twitter offers the [counts endpoint](https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search#CountsEndpoint) for the 30-day and full archive searches. If my understanding is correct, this may be a useful budgeting tool to determine how many results (and therefore how many requests) a given search will find. However, there does not seem to be a function in *rtweet* that wraps this endpoint. 

### Expected behavior

It should be possible to call the counts endpoint.


Apologies if I am missing something here.

