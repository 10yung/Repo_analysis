Similarly to how we can stack `using` blocks, I would like to see us be able to stack `try` and `unsafe`.

E.g.:
```cs
// Old
try
{
    unsafe
    {
        // Do stuff in unsafe context
    }
}

// New
// We can keep them on one line for legibility
try unsafe
{
    // Do stuff in unsafe context
}
```

**Use-case**
Sometimes, especially in the case of try-finally blocks, the entire try clause is unsafe context. For instance, here's some code I put together in learning how to use `Span`:
```cs
public Password(SecureString password)
{
    IntPtr valuePtr = IntPtr.Zero;
    try
    {
        valuePtr = Marshal.SecureStringToGlobalAllocUnicode(password);
        unsafe
        {
            _password = new Span<char>(valuePtr.ToPointer(), password.Length);
        }
    }
    finally
    {
        Marshal.ZeroFreeGlobalAllocUnicode(valuePtr);
    }
}
```
In this case, the marshal operation could be placed in the unsafe block without issue, and thus the entire try clause could be made unsafe. (Forgive me for using SecureString, the point was learning how to use low-level stuff like marshaling and span, so I went all-in. This is not production code).

I felt `try unsafe` should be the proper order since it reads somewhat like "try [this] unsafe [action]," though if `unsafe try` seems better due to keyword ranking or whatever other reasons, I'd love to hear thoughts.
I tend to run into this type of pattern quite often:

```c#
public static class Cache
{
    public T GetObject<T>(string key) => Cache<T>.GetObject(key);

    private static class Cache<T> // Error: name cannot match enclosing type
    {
        private Dictionary<string, T> _lookup = ...;

        public T GetObject(string key) => _lookup[key];
    }
}
```

Obviously I can find a different name for the inner class but sometimes that's annoying in terms of code readability and in the case of nested generic types there is only an ambiguity if the number of generic parameters is the same, so it would be nice to lift the matching name restriction for that particular case.
### Programming languages are opinionated

Programming languages are opinionated, whether we like it or not.
Any given programming language makes some things easy, and other things not as easy.
If someone is programming and has to choose between the two, the language effectively encourages them to do things the easy way.
Sometimes the opinions of a language are intentional, but sometimes the opinions are incidental and do not align with the language author's own opinions.
When that happens, that is a language design smell.
When we design and modify a language, we should aim to have its opinions align with our own.

### C# grew up opinionated

C# came preloaded with a set of opinions inherited from its predecessors.
- It is *object-oriented*: operations on a data type should be placed on the data type on which they operate. If an operation varies in behavior from one "kind" of instance to another, it should be `virtual` (*internal dispatch*). The exceptions to this, inherited from non-object-oriented C, are the integral and enum types, for which `switch` permits *external dispatch*.
- C# is *imperative*: algorithms are expressed as a sequence of steps described by *statements*.
- C# is *mutation-based*: objects are mutable and the purpose of computation is to mutate data.
- *Concurrency* is expressed by protecting mutable data with monitors (`lock`) to provide mutual exclusion during mutation.

### Opinions have changed over time

As we've learned more about good software engineering practices, we've reconsidered these opinions and modified the language and its libraries accordingly.
We added *extension methods* to permit a non-`virtual` operation to be declared outside the type on which it operates while being used by the client as if it were a member.
We added a number of enhancements to make more declarative (and less imperative) code possible, such as expression-bodied methods, Linq, the "elvis" `?.` operator, and local functions.
We added libraries that support fork-join concurrency and asynchronous computation pipelines.
We added auto-properties to make it easier to declare APIs with immutable members.
In all of these, we moved the language's opinion not by making the existing things harder, but by adding yet easier ways of doing things that align with our opinions of what is "right".

### The opinionated purpose of Programming With Data features

This cluster of features aims to move C#'s opinion:
- From *internal dispatch* to *external dispatch*
- From *mutation based* to patterns that work well with immutable data.
- From *imperative* (statement oriented) to *declarative* (e.g. expression oriented)

One shortcoming of C#'s opinion is that *internal dispatch* is frequently inappropriate for programming-in-the-large (i.e. for data types that span component boundaries).
This is particularly true when the data type cannot anticipate all of the operations that clients will want to perform on it, or when the data type is described by a set of related types.
Extension methods do not help much because they are not virtual; they give the appearance of internal dispatch without actually providing support for it.
Two programming patterns that can be used to address this are the use of *visitors*, and switching on *kind fields*.
These are widely used throughout Roslyn.
Both permit constant-time dispatch based on the logical "kind" of the data type.
But these programming patterns are clumsy and error-prone.
C# 6 adds *typeswitch* (pattern-matching in the switch statement) as a more direct way of expressing external dispatch without these issues.
Typeswitch moves the language's opinion toward external dispatch, but currently it has a performance penalty that is enough to discourage many uses (which we are trying to address with runtime support).

The purpose of records and pattern-matching are to reorient C#'s opinions toward what are now understood to be better programming practices:
- APIs for exchange types (types that are interfaces between program components) are better operated upon using *external dispatch* than *internal dispatch* for operations that are not core to the meaning of the data types.
- Expression-oriented code can be more declarative and more clear than statement-oriented code; we seek to make it easier to express algorithms using expression-oriented approaches.
- Many design issues are simpler when exchange types have an immutable API surface. We don't seek to change C#'s opinion that *variables* should by default be immutable (though we are open to that), as we do not propose using fields for these API elements.

### Example of a language design pitfall

It might seem that adding support for a hypothetical `readonly` modifier to parameters and locals would move the language's opinion in alignment with these directions.
That is not so, for two reasons.
First, `readonly int x` is not shorter than `int x`, so the opinion has hardly moved.
`val` instead of `var` is slightly better, but it moves an opinion from encouraging mutability of locals toward being neutral about the mutability of locals.
But it adds the opinion that types for locals should be inferred, which is not intended.
It also doesn't make immutable preferred because it isn't shorter.
Second, the benefits of immutability occur at API boundaries, not within a method body.
So the hypothetical change, even if it moved the language's opinion, would not do so in accordance with the reason for wanting to move the opinion.
(I'm not saying the `readonly` modifier would be a bad idea, just that it doesn't fit with this theme.)

For similar reasons, expression blocks are not particularly useful to move the language's opinion in a direction consistent with these preferences.
(Which is not to say it is a bad idea.)

### A design principle for Programming With Data

There is a useful design criterion for this cluster of features that can make them more intuitive for programmers:
there should be a syntactic alignment between the principal operations on an exchange type.
The principal operations are *declaration*, *creation*, *decomposiion*, and *dispatch*.
We can draw a matrix of categories of types to see how we're doing so far:

| Type | Declaration | Creation | Decomposition | Dispatch (pattern) |
|-|:-:|:-:|:-:|:-:|
|`int`|`int x`|`3`|`int x`|`int x` or `3`
|class with mutable fields|`class Point { public int X, Y; }`|`new Point { X = 3, Y = 4 }`|`p.X`|`Point { X: int x, Y: int y }` or `Point { X: 3, Y: 4 }`
|anonymous type|-|`new { X = 3, Y = 4 }`|`p.X`|`{ X: int x, Y: int y }` or `{ X: 3, Y: 4 }`
|record class|`class Point(int X, int Y);` (proposed)|`Point(3, 4)` (proposed)|`(int x, int y) = p`|`Point(int x, int y)` or `Point(3, 4)`
|tuple|`(int x, int y)`|`(3, 4)`|`(int x, int y) = p`|`(int x, int y)` or `(3, 4)`
|List|`List<int>`|`new List<int> { 3, 4 }`| ? | ?
|Dictionary|`Dictionary<K,V>`|`new Dictionary<K,V> { { K, V } }`| ? | ?

This illustrates our attempt to align the syntax between the different forms in which a type is used.
That alignment helps build the programmer's intuition and simplifies understanding of the features.
Hopefully we can keep the syntactic forms simple and aligned to continue that tradition.


Currently C# is very limited in code quotation abilities as it only supports lambda-expressions without statements in them which were originally introduced for LINQ.
Some other languages like LISP and Nemerle provide a much more powerful tool - quasi-quotation.
I.e. not only they allow to represent language expressions (syntax trees) statically as literals, but also allow to incorporate dynamically generated expressions into them in the same manner as string interpolation works.
That's how it could possibly look in C#:
```csharp
Expression F(Func<int, Expression> expr)
{
  var fourtyTwo = Expression.Contant(42);
  return ${ x => (x + $fourtyTwo) * $(expr(1)) };
}
```
In this case `F(i => Expression.Constant(i))` will return an expression equivalent to `x => (x + 42) * 1`

In the code above `${ expression }` represents a quote with a literal representation of an expression inside, `$name` and `$(expression)` represent incorporated values

Potentially a quotation block could contain any expression representable by the `System.Linq.Expressions` hierarchy.
That means quotes can be recursive - quotes within quotes, which questions the rules of interpolation: should `$name` always target the topmost (in quotation sense) name and be escaped with subsequent appending of more `$`s, or should it "unquote" one level up and each `$` added means "unqoute one more level up":
```csharp
var e = expr1;
var lam = ${ e => ${ $e } };
lam.Compile().Invoke(expr2);
```
In the first case the result would be `expr1`, in the second case `expr2`
In the same fashion of the __++__ or __--__ operators, there should be a __!!__ operator for the cases when we want to flip a boolean without having to self-reassign it. This is especially nice in practice when using long camel-cased variable names. Because instead of looking for a ! in the midst of a long code line, we can much more easily identify !! at the end and recognize its importance.

```csharp
bool longCamelCasedVariableName = false;

// ... later in code ...
longCamelCasedVariableName = !longCamelCasedVariableName;
```
This instead would be written as:
```csharp
bool longCamelCasedVariableName = false;

// .. later in code ...
longCamelCasedVariableName!!;
```
I've found myself running into this a few times as I port my libs to NRTs. It would be useful to be able to specify that a particular property or method return value means that a related property or field will not be null. It could be marked in either "direction" and the second example is probably easier to implement in the NRT flow analyzer, though the first example reads much nicer to me and can be implemented with overloaded constructors on the existing attributes:

```c#
public class Path
{
    public bool IsFilePath { get; }

    public bool IsDirectoryPath => !IsFilePath;

    // I think this is much nicer, overload NotNullWhen:
    [NotNullWhen(nameof(IsFilePath), true)]
    [NotNullWhen(nameof(IsDirectoryPath), false)]
    public Path? ParentDirectory { get; }
}

public class Path
{    
    // This direction feels a bit more awkward and probably requires new attributes
    // to feel somewhat sensible:
    [IndicatesNotNullWhen(true, nameof(ParentDirectory))]
    public bool IsFilePath { get; }

    [IndicatesNotNullWhen(false, nameof(ParentDirectory))]
    public bool IsDirectoryPath => !IsFilePath;

    public Path? ParentDirectory { get; }
}

Path path = GetPath();

if (path.IsFilePath)
{
    // Do not warn that ParentDirectory may be null:
    Console.WriteLine("Parent directory: " + path.ParentDirectory.ToString());
}
else
{
    // Warning that ParentDirectory may be null if ? or ! is not used:
    Console.WriteLine("Parent directory: " + (path.ParentDirectory?.ToString() ?? "[none]"));
}
```

This should/could also work for fields:

```c#
public class CollectionOfStuff
{
    [NotNullWhen(nameof(IsEmpty), false)]
    private Stuff[]? _stuff;

    public bool IsEmpty => _stuff == null || _stuff.Length == 0;

    public void DoSomething()
    {
        if (!IsEmpty)
            Array.Reverse(_stuff); // Don't warn that _stuff may be null
    }
}
```

I played around with various ways to name the `[IndicatesNotNullWhen]` annotation and arrange the parameters but I couldn't really come up with something that felt right. That said, both annotations could be useful since the `[IndicatesNotNullWhen]` variation could be used on return values of methods as well:

```c#
public class PersonEntity
{
    public string? Name { get; set; }

    [return: IndicatesNotNullWhen(true, nameof(Name))]
    public bool IsValid()
    {
        return !string.IsNullOrWhiteSpace(Name);
    }
}

var person = GetPerson();

if (person.IsValid())
{
    string[] nameParts = person.Name.Split(' '); // Don't warn that Name might be null
}
```
With the introduction of non-nullable reference types, I've hit a case a few times where I want to create a class like this one:

```
    public abstract class Foo<T> where T : notnull
    {
        public T? Value { get; set; }
    }
```

But I cannot because the compiler complains:

`A nullable type parameter must be known to be a value type or a non-nullable reference type.`

`Non-nullable property 'Value' is uninitialized. Consider declaring the property as nullable.`

Are there any plans to allow this? Am I missing something? I have my suspicions on why it was left out, but it feels like this could be allowed to some degree.
since `nameof` operator returns only the last member of the expression, to get the full path we must call `nameof` multiple times, as follow:

```c#
$"{nameof(httpContext)}.{nameof(httpContext.Response)}.{nameof(httpContext.Response.StatusCode)}"
```
to get the `httpContext.Response.StatusCode` string

if c# would have a new operator that get whole expression, only the last call would be sufficient. so I propose a new operator to do this job, that returns the same previous string.
```c#
fullnameof(httpContext.Response.StatusCode) == "httpContext.Response.StatusCode" // true
```


So, a little context... I'm working with a binding around the Vulkan Graphics and Compute API, and some of its methods have Span and pointer overloads. I need to pass a `null` literal for this, but it's somehow ambiguous between `Span<T>` and `T*`?

`Span<T>` has an implicit conversion from a `T[]` array (which can notably be a null reference), causing this, but shouldn't it use a direct match to null `T*` instead of causing this ambiguous resolution?

```cs
public static void MyMethod(Span<int> span)
{
}

public static unsafe void MyMethod(int* ptr)
{
}

. . . .

MyMethod(null); //This is somehow ambiguous
```