
In `parse_line` the JSON contents are parsed already inside the `try` statement and assigned to `json_data`. We can reuse the
contents of the variable and voiding parsing the JSON a second time.

The current implementation of logsters cause logster to not to run again
if the lock file exists even if a process does not hold a lock on that.

This approach is fine for filesystems that does not have working locking
(e.g. some NFS, S3FS, etc.).

For native local filesystems failing only if the lock cannot be obtained
results in easier recovery from dead logsters.
Added Link to New Relic Insights Outpuy
Can logster analyze iptables? Count of certain IP, port, build total tables?
I have recently tested most of the log parsers and none of them seem to work. The output just returns 0. If any one is actively working on this project do let me know.

Can we add this option ?
We do need raw data in graphite, not calculated based on time duration.

If there is  etc.:
METRIC_COUNT metric=some.metric.count value=2.2

we need this value (2.2) send to graphite.
The default format of the error log has changed from something like
`[Thu May 12 08:28:57.652118 2011] [error] ...`
to
`[Thu May 12 08:28:57.652118 2011] [core:error] ...`

Note the new module info. The ErrorLogLogster parser should be extended to understand this (i.e. probably ignore the module and successfully extract the severity).

Hi there,

Not a bug but a feature request. :)
Would be convenient to have logger object available in parser classes for debugging purposes.
