In the doc there are two approaches to deal with emojis: 
```
## Emojis
## Not run:
## Load R twitter data
x <- read.delim(system.file("docs/r_tweets.txt", package = "textclean"),
stringsAsFactors = FALSE)
x
library(dplyr); library(magrittr)
## There are 2 approaches

## Approach 1: Replace with words
x %>%
mutate(Tweet = replace_emoji(Tweet)) %$%
sentiment(Tweet)


## Approach 2: Replace with identifier token
combined_emoji <- update_polarity_table(
lexicon::hash_sentiment_jockers_rinker,
x = lexicon::hash_sentiment_emojis
)
x %>%
mutate(Tweet = replace_emoji_identifier(Tweet)) %$%
sentiment(Tweet, polarity_dt = combined_emoji)
## End(Not run)

```

The result is different.
![emoji approaches](https://user-images.githubusercontent.com/11485812/71606617-328c5d00-2b27-11ea-9e8a-ec9cfd59572f.png)

Is there any hint about why the results are different and in what circumstance which one is better? Thanks!  
Hello Tyler, all,

First of all, thank you on amazing work on this package!

I have a question regarding the Hu&Liu (2004) dictionary loaded into the package. Doing a simple frequency check returned the following distribution of words:

`Total Observations in Table:  6874 `

`  |            -2 |       -1.05 |           -1 |             0 |             1 | `

`|             7 |             6 |        4824 |           13 |       2024 | `

Thus it appears that 7 words have polarity of -2, 6 words polarity of -1.05 and 13 polarity of 0.
E.g. "i wish" or "unduly" both carry a -2 weight and "is like" and "i'm like" carry a 0.

Consulting the dictionary avaialable at: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html, none of these seem to appear there. In fact, I did not see any two-word items in the dictionary there.

While these do make sense, I wanted to ask about why they are included and if these weights are indeed accurate and as intended? How are these bigrams accounted for in the calculation?
Or am I doing something wrong?

Thanks!





Can you explain why the following sentences (which all seem positive) were given a negative score using this package? 


**Sentence | SentimentR (Current Package)**
Great boost of energy without a nasty crash afterwards | -0.25
My lips have never looked or felt better | -0.2828427
It is absolutely perfect no play in blade gorgeous to look at and hold extremely solid | -0.05
No gaps perfectly centered blade geometrical cemetrical grind on both sides | -0.2261335
It was a nice clean smell not floral or fruity | -0.1897367


Hi,

I love this package! I've been using it in regular sentiment analysis and had previously set up something like the example:

```
presidential_debates_2012 %>%
    get_sentences()
```

This used to produce a dataframe with all columns retained and the individual sentences that I could then run `sentiment()` on.  This no longer works, and I'm struggling to find a way to get sentiment on a _sentence_ level while preserving all of the remaining data in the original dataframe. 

Here is a reprex for what I'm working through:
```
library(sentimentr)
library(magrittr)
library(dplyr)

x <- tibble(text = c('I like data a lot.', 
                     'sentimentr is great for sentiment analysis.  I use it a lot.'),
            rating = c(5, 4))
x

# Does not preserve `rating` colulmn and is not at sentence level:
x %>%
 mutate(sentence = get_sentences(text)) %$%
    sentiment_by(sentence)

# Preserves `rating` column, but does not allow for sentence-level sentiment:
x %>%
 mutate(sentence = get_sentences(text)) %$%
    sentiment_by(sentence, list(rating))

# Allows for sentence-level sentiment, but does not preserve `rating` column
x %>%
  mutate(sentence = get_sentences(text)) %$%
    sentiment(sentence)
```

I've also tried a combination of `get_sentences()` + `tidyr::unnest()` and then using `bind_cols()` on a separate dataset built using `sentiment()`, which works most of the time, but fails when, for whatever reason, `sentiment()` produces more rows than its supporting dataframe (produced by `get_sentences()` + `tidyr::unnest()`)
mytext <- c(
  'do you like it?  It is red. But I hate really bad dogs',
  'I am the best friend.',
  "Do you really like it?  I'm not happy"
)

ss <- sentiment_by(mytext)

highlight(ss)

**gives this:** 

Error in `[.data.table`(y, , list(sentiment = attributes(x)[["averaging.function"]](sentiment),  : 
  attempt to apply non-function

**Doing this:** 

attr(ss, "averaging.function") <- sentimentr::average_downweighted_zero

**will make highlight work, but is clunky :/**
If I customize my own dictionary with `polarity_dt` / `valence_shifters_dt` in dataframe and specify that as arguments to `sentiment()` or `sentiment_by()`, does that replace the default dictionary? If so and I want to add to the existing lexicons, how do I go about doing that?
The "emotion" function is returning inconsistent results.

**Example 1:**
`emotion("I lie")`

The result should be a score 1 for "anger", "disgust" and "sadness".
The function, instead, returns score 3 for such emotions. 

Looking at the code, the problem seems to be the result of an incorrect "merge" operation on the temporary variable "out".


Notice that the problem disappears when analyzing multiple sentences in a vector, if at least one of the sentences contains a negated emotion.

**Example 2:**
`emotion(c("I don't love", "I lie"))`
The score for the second sentence is correct.

**Example 3:**
`emotion(c("I love", "I lie"))`
The score for the second sentence is different from the example above and incorrect.
I am getting this issue when I run my code: 

**simple code:** 
emotion(text, emotion_dt = lexicon::hash_nrc_emotions,
        valence_shifters_dt = lexicon::hash_valence_shifters,
        drop.unused.emotions = FALSE, un.as.negation = TRUE,
        un.as.negation.warn = isTRUE(all.equal(valence_shifters_dt,
        lexicon::hash_nrc_emotions)), n.before = 5, n.after = 2) 

**Error:**
Error in all.equal(valence_shifters_dt, lexicon::hash_nrc_emotions) : 
  object 'valence_shifters_dt' not found 

How do I import/access the valence shifters lexicon? 
Mailed Case and Changes description to tyler.rinker@gmail.com
Like questiins...quotes are often not indicative of the speakers sentiment.  Consider a way to weight these similar to questions.