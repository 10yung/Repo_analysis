

In computing the testing loss for the autoencoder, you reuse the training set

```
# test on holdout

loss = []
    for batch, test_x in tqdm(
        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES # Why is this using training again?
    ):
```
This isnâ€™t an issue but I was wondering if you could implement the InfoGAN model in tensorflow 2.0 as well.