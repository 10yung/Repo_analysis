**Is your feature request related to a problem? Please describe.**
If the data source is sending out multiple delimiter type files it should be possible to detect the delimiter automatically.

**Describe the solution you'd like**
Simple string comparison in the first few lines can give the column count equivalent character & finding the suitable delimiter

**Describe alternatives you've considered**
N/A
**Additional context**
N/A

This gets rid of unnecessary dependencies: `#padEnd` is supported from Node v8 (see https://node.green), `.travis.yml` lists Node v10 as the oldest supported version.

Indeed, this means csv-parse no longer depends on any third-party packages, which would be pretty neat. Currently:
```
$ npm install csv-parse
+ csv-parse@4.6.5
added 5 packages from 37 contributors
```
We're currently parsing an array using the `columns` option. However, we want our input to be able handle CSVs where the header is provided. Right now, it parses any provided header row as if it matched the `columns` array defined.

Ideally, if a header row is found that matches the `columns` option, the parser would drop it. Right now, we have to use a transformer to drop if present, when really, this scope seems more fitting for the parser logic. 

Has anyone else run into a similar issue with parsing CSVs with and without headers? Is there a better work-around than using a transformer? Unfortunately, due to the CSV sources, we cannot guarantee consistent CSV input with/without headers without extra burden to the users. 

```js
const csvHeader = 'id\nobj_1\nobj_2'; // header included
//const csvNoHeader = 'obj_1\nobj_2'; // no header

const passThrough = new Stream.PassThrough();
passThrough.write(csvHeader);
passThrough.end();

const idParser = CSV.parse({
  columns: ['id'],
  trim: true
});

passThrough.pipe(idParser); // outputs [{ id: 'id' }, { id: 'obj_1' }, { id: 'obj_2' }] 

// requires us to have to filter out `{ id: 'id' }` in future transformers
```
