Hi:
I tried some cases, and have a question, hope you can help solve some~~
I tried OpenAI-ES for Lnet5 on MNIST whose weights space is 44426 and it took 31 mins, 20 epochs to get 95% accuracy, and in the end the highest accuracy is 97%
I tried OpenAI-ES for Lnet5 on CIFAR-10 whose weights space is 62006 and it took 214 mins, 66 epochs to get 50% accuracy, and in the end the highest accuracy is 52%
I tried OpenAI-ES for Resnet18 on MNIST whose weights space is 11172810 and it took quite a long time but the accuracy kept around 11.35% that is no improvement....
I tried OpenAI-ES for Resnet18 on CIFAR-10 whose weights space is 11173962 and it took quite a long time but the accuracy kept around 10.00% that is no improvement....
 I guess there are some reasons that the OpenAI-ES did not work for Resnet18:
1) the weights space is huge!! and my popsize is too small, I tried set the popsize to 100,200,500, the result is still pool like above
2) the weights space is huge!! and the learning-rate and mute_rate(that is the sigma) should be carefully set based upon a lot of experiences and I tried my best to adjust them, still not work......
Can u help meï¼Œhope can  get some suggestions from u !!
:)    : )     :  )
Waiting on line
:(    : (     :  (
How long have CMA-ES cost on training?
I wanna use  tensorflow to test the CMA-ES on MNIST, as the same networks as yours, the training time become slower  as the iteration increase..... 
And the loss_val (cross-entropy) and accuracy have no obvious change after 50 iteration....(it have cost about 5 hours)
I use the same hyper-parameter as your setting...(population:101,sigma:0.01)
 
Hi! Thank you for sharing codes.

Do you have some explanations that MDN with tanh outperforms MDN with ReLU in this sinusoidal dataset?