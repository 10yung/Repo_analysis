*Issue #, if available:* #226 

*Description of changes:*
Add `NC_EXCEPTION` macro to replace old `NcException` API to let DSSTNE be compatible with newer netCDF library (v4.3)

By submitting this pull request, I confirm that my contribution is made under the terms of the Apache 2.0 license.

*Issue #, if available:* #227 

*Description of changes:*
* Replace `__shfl` with `SHFL` to keep CUDA shuffle API compatible
* Update README.md to guide user to download new version CUB library because old CUB library uses legacy CUDA shuffle API

By submitting this pull request, I confirm that my contribution is made under the terms of the Apache 2.0 license.

*Description of changes:*
* Fix old style python code which only can be run by Python2, now [autoencoder.py](https://github.com/amzn/amazon-dsstne/blob/master/benchmarks/tf/autoencoder.py) can be run by both Python2 and Python3.
* Replace `tf.sub` with `tf.subtract` to let [autoencoder.py](https://github.com/amzn/amazon-dsstne/blob/master/benchmarks/tf/autoencoder.py) be run by TensorFlow 1.x

By submitting this pull request, I confirm that my contribution is made under the terms of the Apache 2.0 license.

*Issue #, if available:* No issue

*Description of changes: Adds NVLINK support through DGX-1V, and enables more efficient sparse kernels for smaller embedding widths.


By submitting this pull request, I confirm that my contribution is made under the terms of the Apache 2.0 license.

it threw:
```
nvcc -O3 -std=c++11 --compiler-options=-fPIC -use_fast_math --ptxas-options="-v" -gencode arch=compute_70,code=sm_70 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_30,code=sm_30 -DOMPI_SKIP_MPICXX --keep-dir /test/workspace/ctr/amazon-dsstne/build/tmp/engine/cuda -I/usr/local/include -isystem /usr/local/cuda/include -isystem /usr/lib/openmpi/include -isystem /usr/include/jsoncpp -IB40C -IB40C/KernelCommon -I/test/workspace/ctr/amazon-dsstne/build/include -I../utils  -c kernels.cu -o /test/workspace/ctr/amazon-dsstne/build/tmp/engine/cuda/kernels.o
ptxas /tmp/tmpxft_00000a17_00000000-8_kernels.compute_70.ptx, line 61962; error   : Instruction 'shfl' without '.sync' is not supported on .target sm_70 and higher from PTX ISA version 6.4
```
the old CUDA shuffle API have been deprecated in CUDA 9.0, and not available after CUDA 10 ([link](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-vote-functions))

* CUDA: 10.1
* GPU: NVIDIA Tesla V100
It threw:
```
usr/include/ncException.h:27:7: note:   candidate expects 3 arguments, 4 provided
NNNetwork.cpp:4001:141: error: no matching function for call to 'netCDF::exceptions::NcException::NcException(const char [12], std::__cxx11::basic_string<char>, const char [14], int)'
                 throw NcException("NcException", "NNetwork::NNetwork: No weights supplied in NetCDF input file " + fname, __FILE__, __LINE__);
```
the available constructors of NcException in libnetcdf-c++4 are ([link](https://github.com/Unidata/netcdf-cxx4/blob/master/cxx4/ncException.h#L27)):
```
    class NcException : public std::exception {
    public:
      NcException(const char* complaint, const char* fileName, int lineNumber);
      NcException(int errorCode, const char* complaint, const char* fileName, int lineNumber);
```
there is no  constructor accepting arguments like `(const char*, const std::string&, const char*, int)`

* OS: Ubuntu 18.04
* libnetcdf-c++4: 4.3.0+ds-5 (installed by `apt install` command)
'fp' is defined here, but may be NULL
https://github.com/amzn/amazon-dsstne/blob/14bd7ee1c797e5325a6ae13122c54ab73cfe0236/src/amazon/dsstne/engine/NNWeight.cpp#L1131

Stream pointer might be NULL

https://github.com/amzn/amazon-dsstne/blob/14bd7ee1c797e5325a6ae13122c54ab73cfe0236/src/amazon/dsstne/engine/NNWeight.cpp#L1137
System version
Distributor ID: Ubuntu
Description:    Ubuntu 18.04.2 LTS
Release:        18.04
Codename:       bionic

Cuda version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130

When I run make command and have following errors:

============================================================
GpuTypes.h:252:23: warning: ‘cudaError_t cudaThreadExit()’ is deprecated [-Wdeprecated-declarations]
         cudaThreadExit(); \
         ~~~~~~~~~~~~~~^~
GpuTypes.h:557:5: note: in expansion of macro ‘RTERROR’
     RTERROR(status, "GpuBuffer::Deallocate failed (cudaFree)");
     ^~~~~~~
In file included from /usr/local/cuda/include/channel_descriptor.h:61:0,
                 from /usr/local/cuda/include/cuda_runtime.h:95,
                 from /usr/local/cuda/include/curand.h:59,
                 from GpuTypes.h:22,
                 from NNNetwork.cpp:13:
/usr/local/cuda/include/cuda_runtime_api.h:921:57: note: declared here
 extern __CUDA_DEPRECATED __host__ cudaError_t CUDARTAPI cudaThreadExit(void);
                                                         ^~~~~~~~~~~~~~
In file included from NNNetwork.cpp:13:0:
GpuTypes.h:252:23: warning: ‘cudaError_t cudaThreadExit()’ is deprecated [-Wdeprecated-declarations]
         cudaThreadExit(); \
         ~~~~~~~~~~~~~~^~
GpuTypes.h:557:5: note: in expansion of macro ‘RTERROR’
     RTERROR(status, "GpuBuffer::Deallocate failed (cudaFree)");
     ^~~~~~~
In file included from /usr/local/cuda/include/channel_descriptor.h:61:0,
                 from /usr/local/cuda/include/cuda_runtime.h:95,
                 from /usr/local/cuda/include/curand.h:59,
                 from GpuTypes.h:22,
                 from NNNetwork.cpp:13:
/usr/local/cuda/include/cuda_runtime_api.h:921:57: note: declared here
 extern __CUDA_DEPRECATED __host__ cudaError_t CUDARTAPI cudaThreadExit(void);
                                                         ^~~~~~~~~~~~~~
In file included from NNNetwork.cpp:13:0:
GpuTypes.h:252:23: warning: ‘cudaError_t cudaThreadExit()’ is deprecated [-Wdeprecated-declarations]
         cudaThreadExit(); \
         ~~~~~~~~~~~~~~^~
GpuTypes.h:557:5: note: in expansion of macro ‘RTERROR’
     RTERROR(status, "GpuBuffer::Deallocate failed (cudaFree)");
     ^~~~~~~
In file included from /usr/local/cuda/include/channel_descriptor.h:61:0,
                 from /usr/local/cuda/include/cuda_runtime.h:95,
                 from /usr/local/cuda/include/curand.h:59,
                 from GpuTypes.h:22,
                 from NNNetwork.cpp:13:
/usr/local/cuda/include/cuda_runtime_api.h:921:57: note: declared here
 extern __CUDA_DEPRECATED __host__ cudaError_t CUDARTAPI cudaThreadExit(void);
                                                         ^~~~~~~~~~~~~~
In file included from NNNetwork.cpp:13:0:
GpuTypes.h: In instantiation of ‘void GpuBuffer<T>::Deallocate() [with T = char]’:
GpuTypes.h:483:15:   required from ‘GpuBuffer<T>::~GpuBuffer() [with T = char]’
/usr/include/c++/7/bits/unique_ptr.h:78:2:   required from ‘void std::default_delete<_Tp>::operator()(_Tp*) const [with _Tp = GpuBuffer<char>]’
/usr/include/c++/7/bits/unique_ptr.h:268:17:   required from ‘std::unique_ptr<_Tp, _Dp>::~unique_ptr() [with _Tp = GpuBuffer<char>; _Dp = std::default_delete<GpuBuffer<char> >]’
GpuSort.h:47:44:   required from ‘GpuSort<KeyType, ValueType>::GpuSort(unsigned int) [with KeyType = unsigned int; ValueType = unsigned int]’
NNNetwork.cpp:850:93:   required from here
GpuTypes.h:252:23: warning: ‘cudaError_t cudaThreadExit()’ is deprecated [-Wdeprecated-declarations]
         cudaThreadExit(); \
         ~~~~~~~~~~~~~~^~
GpuTypes.h:557:5: note: in expansion of macro ‘RTERROR’
     RTERROR(status, "GpuBuffer::Deallocate failed (cudaFree)");
     ^~~~~~~
In file included from /usr/local/cuda/include/channel_descriptor.h:61:0,
                 from /usr/local/cuda/include/cuda_runtime.h:95,
                 from /usr/local/cuda/include/curand.h:59,
                 from GpuTypes.h:22,
                 from NNNetwork.cpp:13:
/usr/local/cuda/include/cuda_runtime_api.h:921:57: note: declared here
 extern __CUDA_DEPRECATED __host__ cudaError_t CUDARTAPI cudaThreadExit(void);
                                                         ^~~~~~~~~~~~~~
In file included from NNNetwork.cpp:13:0:
GpuTypes.h:252:23: warning: ‘cudaError_t cudaThreadExit()’ is deprecated [-Wdeprecated-declarations]
         cudaThreadExit(); \
         ~~~~~~~~~~~~~~^~
GpuTypes.h:557:5: note: in expansion of macro ‘RTERROR’
     RTERROR(status, "GpuBuffer::Deallocate failed (cudaFree)");
     ^~~~~~~
In file included from /usr/local/cuda/include/channel_descriptor.h:61:0,
                 from /usr/local/cuda/include/cuda_runtime.h:95,
                 from /usr/local/cuda/include/curand.h:59,
                 from GpuTypes.h:22,
                 from NNNetwork.cpp:13:
/usr/local/cuda/include/cuda_runtime_api.h:921:57: note: declared here
 extern __CUDA_DEPRECATED __host__ cudaError_t CUDARTAPI cudaThreadExit(void);
                                                         ^~~~~~~~~~~~~~
In file included from NNNetwork.cpp:13:0:
GpuTypes.h:252:23: warning: ‘cudaError_t cudaThreadExit()’ is deprecated [-Wdeprecated-declarations]
         cudaThreadExit(); \
         ~~~~~~~~~~~~~~^~
GpuTypes.h:557:5: note: in expansion of macro ‘RTERROR’
     RTERROR(status, "GpuBuffer::Deallocate failed (cudaFree)");
     ^~~~~~~
In file included from /usr/local/cuda/include/channel_descriptor.h:61:0,
                 from /usr/local/cuda/include/cuda_runtime.h:95,
                 from /usr/local/cuda/include/curand.h:59,
                 from GpuTypes.h:22,
                 from NNNetwork.cpp:13:
/usr/local/cuda/include/cuda_runtime_api.h:921:57: note: declared here
 extern __CUDA_DEPRECATED __host__ cudaError_t CUDARTAPI cudaThreadExit(void);
                                                         ^~~~~~~~~~~~~~
Makefile:58: recipe for target '/home/user02/source4/amazon-dsstne/build/tmp/engine/cpp/NNNetwork.o' failed
make[1]: *** [/home/user02/source4/amazon-dsstne/build/tmp/engine/cpp/NNNetwork.o] Error 1
make[1]: Leaving directory '/home/user02/source4/amazon-dsstne/src/amazon/dsstne/engine'
Makefile:13: recipe for target 'engine' failed
make: *** [engine] Error 2

According to the prediction requirements, the time series is granular in minutes. We first remove all the parts with missing rate exceeding 10% in the time series, but in the remaining time series, there are still some sparse time series.
For example, the time series of consumers paying per minute has a value of 0 at many points in time. If these sequences are directly modeled, the prediction effect of the model may be greatly reduced. So, how do you preprocess these sparse time series before building a predictive model? Have you ever encountered a similar situation and how is it handled? Thank you

The following image is a screenshot of some of the data in the sparse time series (the length of time is one month)
![豆芽图片20190827102109132](https://user-images.githubusercontent.com/52397681/63736082-7ee33a00-c8b4-11e9-908e-e954c4a77a5b.png)

I have encountered two separate issues when trying to build the Docker version of dsstne. I am using the DSSTNE CUDA 9.1 (ami-fe173884) ami on a g2.8xlarge instance in us-east-1.

**First**, I cannot run the driver information app. Whenever I try to run:

`nvidia-docker run --rm nvidia/cuda nvidia-smi`

The response is:

`docker: Error response from daemon: OCI runtime create failed: container_linux.go:296: starting container process caused "exec: \"nvidia-smi\": executable file not found in $PATH": unknown.`

I know the nvidia-smi app is there:

```
whereis nvidia-smi
nvidia-smi: /usr/bin/nvidia-smi /usr/share/man/man1/nvidia-smi.1.gz

```
And if I simply run the nvidia-smi app from bash I see that the driver is installed:

`+-----------------------------------------------------------------------------+
| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|==========================+======================+======================|
|   0  GRID K520           Off  | 00000000:00:03.0 Off |                  N/A |
| N/A   28C    P8    17W / 125W |     11MiB /  4036MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|========================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
`
But somehow the $PATH for nvidia-docker does not point to it. Do I need to build nvidia-docker to resolve this $PATH problem? Or use another ami? I see that there are other dsstne amis in us-east-1.


**Second**, if I go ahead and try to build dsstne from the repository using latest, I see a warning from the makefile:

`Step 13/15 : RUN cd /opt/amazon/dsstne/src/amazon/dsstne &&     make install
 ---> Running in 8545a8860f50
Makefile:6: **************************************************************************************
Makefile:7: ******************          USE OF DEPRECATED MAKEFILE              ******************
Makefile:8: ****************** PLEASE USE THE ONE AT THE ROOT OF THE REPOSITORY ******************
Makefile:9: **************************************************************************************
`

And the make fails with the error:
`mkdir -p /opt/amazon/dsstne/src/amazon/../../amazon-dsstne
cp -rfp /opt/amazon/dsstne/src/amazon/../../../build/lib /opt/amazon/dsstne/src/amazon/../../amazon-dsstne/lib
cp: cannot stat '/opt/amazon/dsstne/src/amazon/../../../build/lib': No such file or directory
make: *** [install] Error 1
Makefile:26: recipe for target 'install' failed
The command '/bin/sh -c cd /opt/amazon/dsstne/src/amazon/dsstne &&     make install' returned a non-zero code: 2
`

When I change the Dockerfile to use the Makefile at the root of the repo, the build fails with:

`In file included from src/main/native/com_amazon_dsstne_Dsstne.cpp:20:0:
src/main/native/jni_util.h:21:17: fatal error: jni.h: No such file or directory
compilation terminated.
make[1]: *** [target/native/build/com_amazon_dsstne_Dsstne.o] Error 1
`

At this point I am at an impasse. I did try following the setup instructions using the community ami Amazon DSSTNE (nvidia-docker) - ami-25c0eb32 but encountered the same error.

My next step is to try to rebuild nvidia-docker and then continue to grind through the dsstne docker build. But I hope that someone can let me know what I am doing wrong before I spend another day on this task instead of working with dsstne.

Mike Templeman
