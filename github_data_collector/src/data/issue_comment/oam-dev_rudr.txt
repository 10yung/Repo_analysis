<!-- Thanks for filing an issue! Before hitting the button, please answer these questions. It's helpful to search the existing GitHub issues first. It's likely that another user has already reported the issue you're facing, or it's a known issue that we're already aware of.

Describe *in detail* the feature/behavior/change you'd like to see.

Be ready for followup questions, and please respond in a timely manner. If we can't reproduce a bug or think a feature already exists, we might close your issue.  If we're wrong, PLEASE feel free to reopen it and explain why.

The fastest and best way to solve feature request issue is to give a Pull Request yourself.
-->

**OAM Spec Info**

Rudr will always follow OAM spec, if this feature is related with spec definition, please make sure they are consistent.

**Is your feature request related to a problem? Please describe.**
I'd like to scale workloads on other metrics than CPU/Memory with the Autoscaler trait.

**Describe the solution you'd like**
Autoscale based on Service Bus queue size

**Additional context**
I'm translating my KEDA sample (https://github.com/kedacore/sample-dotnet-worker-servicebus-queue) to OAM to give an example of what OAM leverages.

KEDA is already mentioned in the Autoscaler trait but doesn't seem to be supported, is that correct?

https://github.com/oam-dev/rudr/blob/master/docs/concepts/traits.md#autoscaler-trait

**Scenario**
```yaml
apiVersion: core.oam.dev/v1alpha1
kind: ComponentSchematic
metadata:
  name: order-worker-component
spec:
  workloadType: core.oam.dev/v1alpha1.Server
  containers:
    - name: order-worker-container
      image: tomkerkhove/keda-sample-dotnet-worker-servicebus-queue
      env:
        - name: KEDA_SERVICEBUS_QUEUE_CONNECTIONSTRING
          fromParam: ServiceBus_Queue_Connectionstring
        - name: PORT
          fromParam: port
      ports:
        - protocol: TCP
          containerPort: 9999
          name: http
  parameters:
    - name: ServiceBus_Queue_Connectionstring
      description: 'Connection string for the Azure Service Bus queue'
      type: string
      required: true
---
apiVersion: core.oam.dev/v1alpha1
kind: ApplicationConfiguration
metadata:
  name: order-worker-config
spec:
  components:
    - componentName: order-worker-component
      instanceName: order-worker-component
      parameterValues:
        - name: ServiceBus_Queue_Connectionstring
          value: "<redacted>"
      traits:
        - name: auto-scaler.core.oam.dev/v1alpha1
          properties:
            maximum: 5
            minimim: 0
```
It would be great to add DNS domain and SSL cert via Letsencrypt when a frontend app is deployed via Rudr.
Currently once we installed Rudr and OAM apps, we can only view them via kubectl.

It would be great if we can have a UI dashboard to list the apps and their traits, what capabilities (Workload/Trait/Scope) the platform provides.

Here's an example how CodeFresh displays helm releases:

![image](https://user-images.githubusercontent.com/920884/72004538-786cb380-3200-11ea-9cd5-5875000ef7ed.png)

Currently, the "resources" field in the container which describes minimal computing resource to the runtime is optional. But as per OAM spec, it is mandatory.

OAM have spec which defines how to run an Application, while we also need a standard way to know whether the Application is running well and cooperate with another Application. In k8s, we usually use `status` of an object to do this kind of work.

So I think we need some standard way to define the status of OAM object.




- The health scope should have APIs that I can query after a deployment fails (and assuming the YAML was valid), that will describe to me what went wrong with the deployment. 

- For example, if I deploy an ApplicationConfiguration and there is an error, the Health Scope should be queryable and return information on which components failed to come up and some deeper information as to why. 

- kubectl describe healthscope <name> and it returns a description of the scope and the problems within that scope 
Create error codes and message formats for those error codes so that errors can be consumed/reinterpreted by various clients/RPs. Rather than just having details of the error as the string, we can also add standardized error code so that any clients using them can re-interpret and inform it's client in a better way.

Add more diagnostics logs to figure out issues sooner.
The installation of [admission controller](https://github.com/oam-dev/admission-controller) should be part of rudr installation. So that could help rudr to mutate and validate spec applied to rudr.
Now we have resource minimum in Component definition, the operator may want to define resource limit. So we need resource limit as a Trait.