I am currently reading the paper and confused on what is actually considered as an attribute to transfer. It lists three things: color transfer, texture transfer, and style transfer.

In the example image of monalisa and avatar, looking at the image A', I made the following observation:
- it transferred the color, eyes and lips.

Then why didn't it transfer ears and nose?

What I understand is, it should only transfer color in this set of images. Eyes, lips, ears and nose are individual attributes of that person itself and it shouldn't change. Yes, it may be able to transfer style, i.e. if B' is a photo of girl with tiara headband, then it should transfer this style to A producing A'. But this isn't the case here..

In short, are we actually controlling the attributes to transfer? Or the model takes decisions on its own?

Thank you..
At first, I install protoc-2.6.1, but I get an error: 

> In file included from .build_release/src/caffe/proto/caffe.pb.cc:4:0:
.build_release/src/caffe/proto/caffe.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is
 #error This file was generated by a newer version of protoc which is
  ^
.build_release/src/caffe/proto/caffe.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update
 #error incompatible with your Protocol Buffer headers.  Please update
  ^
.build_release/src/caffe/proto/caffe.pb.h:14:2: error: #error your headers.
 #error your headers.
  ^
In file included from .build_release/src/caffe/proto/caffe.pb.cc:4:0:
.build_release/src/caffe/proto/caffe.pb.h:23:35: fatal error: google/protobuf/arena.h: No such file or directory
compilation terminated.
Makefile:582: recipe for target '.build_release/src/caffe/proto/caffe.pb.o' failed
make: *** [.build_release/src/caffe/proto/caffe.pb.o] Error 1

Then I install protoc-3.6.1 instead, but the error still exists.

I think this is because the protocol compiler (protoc) and the library header (/usr/include/google/protobuf) are inconsistent.

>% protoc --version
libprotoc 3.6.1
% grep GOOGLE_PROTOBUF_VERSION /usr/include/google/protobuf/stubs/common.h
#define GOOGLE_PROTOBUF_VERSION 2006001

I am not the user of  `root`, and the protoc is installed at my own dir.
So anyone could help me solve this problem?
Thanks!

Hello,

What are the minimal requirements for the GPU to run the demo:
deep_image_analogy.exe ../models/ ../demo/content.png ../demo/style.png ../demo/output/ 0 0.5 2 0
?

I have nVIdia GTX 970 and Windows 8.1, and it crashes unfortunately somewhere in CUDA with the log:

[libprotobuf WARNING ..\src\google\protobuf\io\coded_stream.cc:537] Reading dang
erously large protocol message.  If the message turns out to be larger than 2147
483647 bytes, parsing will be halted for security reasons.  To increase the limi
t (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in
google/protobuf/io/coded_stream.h.
[libprotobuf WARNING ..\src\google\protobuf\io\coded_stream.cc:78] The total num
ber of bytes read was 574671192
[libprotobuf WARNING ..\src\google\protobuf\io\coded_stream.cc:537] Reading dang
erously large protocol message.  If the message turns out to be larger than 2147
483647 bytes, parsing will be halted for security reasons.  To increase the limi
t (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in
google/protobuf/io/coded_stream.h.
[libprotobuf WARNING ..\src\google\protobuf\io\coded_stream.cc:78] The total num
ber of bytes read was 574671192
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv5_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv4_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv3_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv2_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv1_1.
Saving flow result.
Finished finding ann. Time : 37.588
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0827 15:12:08.460532  6884 syncedmem.hpp:31] Check failed: error == cudaSuccess
 (30 vs. 0)  unknown error

This is both for exe-from-git, and for build by myself.

In Debug build I see the error:
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv5_1.
F0827 15:41:30.334332  4332 pooling_layer.cu:212] Check failed: error == cudaSuc
cess (7 vs. 0)  too many resources requested for launch

Best regards,
Fedor


hello and thanks for the code
this is happening on KDE neon user (Ubuntu 16.04)
I tried to recompile caffe without cudnn but same problem happens 

```
./demo deep_image_analogy/models/ deep_image_analogy/demo/content.png deep_image_analogy/demo/style.png deep_image_analogy/demo/output/ 0 0.1 2 1
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 574671192
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 574671192
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv5_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv4_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv3_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv2_1.
Finding nearest neighbor field using PatchMatch Algorithm at layer:conv1_1.
Refining photo transfer.
Saving flow result.
Finished finding ann. Time : 121.885
*** Error in `./demo': free(): invalid pointer: 0x0000000002281d10 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f00373a67e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f00373af37a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f00373b353c]
/usr/lib/x86_64-linux-gnu/libprotobuf.so.9(_ZN6google8protobuf8internal28DestroyDefaultRepeatedFieldsEv+0x1f)[0x7f002eb5e8af]
/usr/lib/x86_64-linux-gnu/libprotobuf.so.9(_ZN6google8protobuf23ShutdownProtobufLibraryEv+0x8b)[0x7f002eb5db3b]
/usr/lib/x86_64-linux-gnu/libmirprotobuf.so.3(+0x233b9)[0x7f001d3ea3b9]
/lib64/ld-linux-x86-64.so.2(+0x10de7)[0x7f003cdc9de7]
/lib/x86_64-linux-gnu/libc.so.6(+0x39ff8)[0x7f0037368ff8]
/lib/x86_64-linux-gnu/libc.so.6(+0x3a045)[0x7f0037369045]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf7)[0x7f003734f837]
./demo[0x407729]
```
I got 2 1080Ti, is it possible to use both of it to speed it up ?
Thanks in advance
Hello,

I have been playing around with the pre-built demo provided and have had some success with it. However when I start to increase the weights on certain photos my system will hard crash. I have had success with ratio's up to around .6 and .7 but then it starts to be more likely that my system will crash. 

I had disabled the TDR which allowed me to run ratios up to around .6 since before I was only able to get it to run around .2 or .3.

The system I am using has an 2 x Nvidia M6000 Quadro GPUs so I would imagine that memory should not be an issue, but after much debugging I am out of ideas.

Would there be any additional reason that would cause the crash or any additional settings I could play with?

Many thanks
I have installed caffe before.
So what can I do to run your demo without install caffe again?
After I compiled caffe and tested it successfully, and then I followed the **Configure & Build**(Linux version).
While I executing "sh scripts/config_deep_image_analogy.sh", the error prompt is like this:

nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
./include/caffe/parallel.hpp(99): warning: type qualifier on return type is meaningless

./include/caffe/parallel.hpp(99): warning: type qualifier on return type is meaningless

deep_image_analogy/source/lbfgs.cu:17:9: warning: #pragma once in main file
 #pragma once
         ^
deep_image_analogy/source/lbfgs.cu:17:9: warning: #pragma once in main file
 #pragma once
         ^
/tmp/tmpxft_00002e95_00000000-29_Classifier.o：在函数‘Classifier::Classifier(std::string const&, std::string const&)’中：
Classifier.cpp:(.text+0xa8)：对‘caffe::Net<float>::Net(std::string const&, caffe::Phase, int, std::vector<std::string, std::allocator<std::string> > const*, caffe::Net<float> const*)’未定义的引用
Classifier.cpp:(.text+0xe7)：对‘caffe::Net<float>::CopyTrainedLayersFrom(std::string)’未定义的引用
/tmp/tmpxft_00002e95_00000000-29_Classifier.o：在函数‘Classifier::Predict(cv::Mat const&, std::vector<std::string, std::allocator<std::string> >&, std::vector<float*, std::allocator<float*> >&, std::vector<float*, std::allocator<float*> >&, std::vector<Dim, std::allocator<Dim> >&)’中：
Classifier.cpp:(.text+0x5bb)：对‘caffe::Net<float>::blob_by_name(std::string const&) const’未定义的引用
/tmp/tmpxft_00002e95_00000000-29_Classifier.o：在函数‘std::string* google::MakeCheckOpString<int, int>(int const&, int const&, char const*)’中：
Classifier.cpp:(.text._ZN6google17MakeCheckOpStringIiiEEPSsRKT_RKT0_PKc[_ZN6google17MakeCheckOpStringIiiEEPSsRKT_RKT0_PKc]+0x7b)：对‘google::base::CheckOpMessageBuilder::NewString()’未定义的引用
/tmp/tmpxft_00002e95_00000000-30_Deconv.o：在函数‘my_cost_function::f_gradf(float const*, float*, float*)’中：
Deconv.cpp:(.text+0x7e)：对‘caffe::Net<float>::blob_by_name(std::string const&) const’未定义的引用
Deconv.cpp:(.text+0xc4)：对‘caffe::Net<float>::blob_by_name(std::string const&) const’未定义的引用
Deconv.cpp:(.text+0x1b2)：对‘caffe::Net<float>::blob_by_name(std::string const&) const’未定义的引用
collect2: error: ld returned 1 exit status


I am a  green hand to caffe and this project, so how should I fix this error?
Thanks a lot!
Hi,
When I run demo file on system, single command uses 1.5GB.
My Nvidia card is gtx 1070 having 8 GB GPU memrory.
So I can only run  maximum 5 commands at a time (in multiple terminals) otherwise other wise the usage of GPU exceeds from 8GB so more command cannot executed.
I want to execute at least 70 to 80 commands at once(through web service).
So is it possible with this Card...?
Thanks and regards