Hi Team ,

Could you please share the helm chart for Kubernetes deployment.

Best regards,
Poshak

Well, actually I just wanted to report an issue and I'm not sure that I got how the demo notebooks load.

On the official tutorial [page](https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/) there is a [link](https://raw.githubusercontent.com/hortonworks-gallery/zeppelin-notebooks/hdp-2.6/2CJW53M52/note.json) to get all the Spark notebooks with hash *2CJW53M52*. I suppose that this page was created from [GitHub md file](https://github.com/hortonworks/data-tutorials/blob/master/tutorials/hdp/learning-spark-sql-with-zeppelin/tutorial.md).

However, on both of this pages screenshot suggest that after download of test data, data is moved from local system to '/tmp' folder in the Hadoop like this:

```# remove existing copies of dataset from HDFS
hdfs dfs -rm -r -f /tmp/flights.csv

# put data into HDFS
hdfs dfs -put /tmp/flights.csv /tmp/
```


and later:


```%spark2

// Create a flights DataFrame from CSV file
val flights = spark.read
              .option("header", "true")                              // Use first line as header
              .option("inferSchema", "true")                         // Infer schema
              .csv("/tmp/airflightsdelays/flights.csv")                               // Read data
```

Which is not correct. The error is present only at screenshots, the code in the notebook seems to be ok.

In the [original repo](https://github.com/hortonworks-gallery/zeppelin-notebooks) there is a [folder](https://github.com/hortonworks-gallery/zeppelin-notebooks/tree/master/2C174C9EK) with what seems to be a correct notebook (with hash *2C174C9EK*) for this tutorial, with the commands:

```hadoop fs -rm -r -f /tmp/airflightsdelays
hadoop fs -mkdir /tmp/airflightsdelays
# put data into HDFS
hadoop fs -put /tmp/flights.csv /tmp/airflightsdelays/
```

So it might be a good idea to fix either a screenshot or the code.

Hi guys,

Just wanted to let you know that we've migrated all links for https://www.zeppelinhub.com/viewer to https://www.zepl.com/explore

We'll be making the correct redirect but would be helpful if the links and directions could be updated with  the new URL (only the domain/explore needs to be updated. The proceeding random URL will be maintained).

Also, if you register to https://www.zepl.com/, you will be able to publish the notebooks directly to the desired public category.

Thanks.
ps. Btw, great stuff. Keep analyzing and sharing. Love the examples.
- updated path to zeppelin notebook
- path changed in hdp 2.5 sandbox

Sandbox-version

Sandbox information:
Created on: 24_06_2016_00_31_56 for
Hadoop stack version:  Hadoop 2.7.1.2.5.0.0-817
Ambari Version: 2.4.0.0-685
Ambari Hash: 9b70e50de85eeff18184d2158b6d03a5657751f6
Ambari build:  Release : 685
Java version:  1.7.0_101
OS Version:  CentOS release 6.8 (Final)

Commenting out redundant  `val sqlContext = new org.apache.spark.sql.SQLContext(sc)` as its already available.
