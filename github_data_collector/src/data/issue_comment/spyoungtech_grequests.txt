I am using grequests on my Django project, sending requests synchronously and concurrently, the number is 649. When I visit other pages, I get the following error：greenlet.error: cannot switch to a different thread。
This is the environment I use：
- Windows10 + 64
- Pycharm + Python3.6.8

This is my code：
```python
def async_http(peer_list):
    headers = {
        # 'Connection': 'close',
        'Content-Type': "application/x-www-form-urlencoded",
        'cache-control': "no-cache",
        'Postman-Token': "my-token"
    }
    timestamp = create_timestamp()
    url_list = []
    for peer in peer_list:
        befor = "xx?AccessId=vpncnadmin&peer=%s&timestamp=%s" % (peer, timestamp)
        sign = get_sign(befor)

        url = "http://xxxx.top:8088/api/xxx?AccessId=vpncnadmin&peer=" + peer + "&timestamp=" + timestamp + "&sign=" \
              + sign
        url_list.append(url)
    task = [grequests.get(url, headers=headers, timeout=30) for url in url_list]
    response = grequests.map(task, exception_handler=exception_handler, size=50)

    return response


def exception_handler(request, exception):
    failed_peer_list = []               
    send_url = request.url
    peer = send_url.split('&')[1].split('=')[1]
    failed_peer_list.append(peer)

    return failed_peer_list
```
I had a use-case where I needed to be able to identify which request/response was which, I felt this method was a nice and simple way of achieving this. 
Hi,

Encountered an error when using boto3 python client for S3.
The new API of S3 supports the method upload_file/upload_fileobj which I guess internally uses gevent. 
Importing both grequests and boto3 causes uploads to fail sporadically with the following exception:
 
> LoopExit: This operation would block forever 

This happens also when there's no use of grequests functionality only importing the library (maybe monkey_patching collision)

Your help is appreciated. 

I am trying to use `grequests` to connect to a server and parse data. `grequests` works fine with `Python 3.5`, but when I switch to `Python 3.6`, some weird problems start to show. They might get resolved by the order that I import the packages, i.e. importing `grequests` as the last one. Also, I have used the following piece of code to resolve some parallelizing issues as 
```
import gevent.monkey
gevent.monkey.patch_select(aggressive=True)
```

Apparently, there are some problems in using `gevent` in python 3.6. 
Hi guys! 
I've try to use grequests but the sessions wasn't close so my HA proxy was laggy...
I've solved the problem by closing the session in a finally. The tests pass in my env.
Maybe there is other solutions to this problem. 

Regards, 

Adrien
```python
#!/bin/env python3.5

import logging

import requests
import grequests

URL='https://www.startpage.com'

logging.basicConfig()
logging.getLogger().setLevel(logging.DEBUG)

def sessionGRequestsMap( nr_of_requests = 100 ):
    urls = []
    session = requests.Session()
    session.mount('https://', requests.adapters.HTTPAdapter( pool_maxsize=2 ) )
    for nr in range( 0, nr_of_requests ):
        urls.append( URL )
    rs = [grequests.get(u, session = session ) for u in urls]
    for r in grequests.map(rs):
        pass

def sessionGRequestsIMap( nr_of_requests = 100 ):
    urls = []
    session = requests.Session()
    session.mount('https://', requests.adapters.HTTPAdapter( pool_maxsize=2 ) )
    for nr in range( 0, nr_of_requests ):
        urls.append( URL )
    rs = [grequests.get(u, session = session ) for u in urls]
    for r in grequests.imap(rs):
        pass

sessionGRequestsMap( nr_of_requests = 20 )
print( "------------------------------------------------------------------" +
       "------------------------------------------------------------------" )
sessionGRequestsIMap( nr_of_requests = 20 )
```

first function creates 20 https connection in parallel
second function only two.

I would expect the first function also to only create two connections.
Please tell me, if I'm wrong
`request` may not have attr exception, I've tested for many times.

if `request` doesn't have exception attr, it will not call exception_handler, and at this time, response is none, so you don't know where to handle this situation.

So although `request` doesn't have exception attr, you can still call exception handler, so you can handle this situation by judgeing `request`'s attrs.

I am getting 403 response for all of my urls after I make a call to the Cisco ACI fabrics at the same time.
Sample code:-
```
for each in range(0,len(urls)):
            response.append(grequests.get(urls[each],cookies=cookiesArray[each]))
eachresp1 = grequests.map(response)
print(eachresp1,"eachresp1")
for r in eachresp1:
           respArray.append(r.json())
```

The eachresp returns 403 for each of the fabric url. Works fine with requests module when sending single url. But for faster results, I want to use grequests.
           
```
>>> import requests
>>> import grequests
>>> requests.get('https://google.com')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/lib/python3.6/site-packages/requests/api.py", line 70, in get
    return request('get', url, params=params, **kwargs)
  File "/usr/lib/python3.6/site-packages/requests/api.py", line 56, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3.6/site-packages/requests/sessions.py", line 488, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3.6/site-packages/requests/sessions.py", line 609, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3.6/site-packages/requests/adapters.py", line 423, in send
    timeout=timeout
  File "/usr/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/usr/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 345, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 844, in _validate_conn
    conn.connect()
  File "/usr/lib/python3.6/site-packages/requests/packages/urllib3/connection.py", line 314, in connect
    cert_reqs=resolve_cert_reqs(self.cert_reqs),
  File "/usr/lib/python3.6/site-packages/requests/packages/urllib3/util/ssl_.py", line 264, in create_urllib3_context
    context.options |= options
  File "/usr/lib/python3.6/ssl.py", line 459, in options
    super(SSLContext, SSLContext).options.__set__(self, value)
  File "/usr/lib/python3.6/ssl.py", line 459, in options
    super(SSLContext, SSLContext).options.__set__(self, value)
  File "/usr/lib/python3.6/ssl.py", line 459, in options
    super(SSLContext, SSLContext).options.__set__(self, value)
  [Previous line repeated 323 more times]
RecursionError: maximum recursion depth exceeded
```

If the order of imports is reversed, the problem no longer occurs.

With the following code snippet:

```
import grequests
from multiprocessing import Manager
Manager().list()
```
I get the following traceback:
```
Traceback (most recent call last):
  File "minimal.py", line 3, in <module>
    Manager().list()
  File "/usr/lib64/python2.7/multiprocessing/managers.py", line 667, in temp
    token, exp = self._create(typeid, *args, **kwds)
  File "/usr/lib64/python2.7/multiprocessing/managers.py", line 565, in _create
    conn = self._Client(self._address, authkey=self._authkey)
  File "/usr/lib64/python2.7/multiprocessing/connection.py", line 179, in Client
    answer_challenge(c, authkey)
  File "/usr/lib64/python2.7/multiprocessing/connection.py", line 440, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
IOError: [Errno 11] Resource temporarily unavailable
```
I'd guess some conflicting patching. I dumped grequests and it works. Also lol@curious_george, awesome :). Thanks for the lib! Using it here and there :)