I have a data set that has both NA values and -99 values which mean something slightly different (NA = not seen, -99 = seen but unanswered questions on a survey).

I cannot find a function in `naniar` to do a count of -99 by row.  I see that there is `miss_scan_count` which allows for specifying what counts as a missing value, but this function operates on columns and gives totals by column.  Is there a similar function to do this by rows?  All the row-wise missing functions like pct/count/prop etc don't have an argument for what values count as missing, they only look for `NA`.
Hello,

If you want to count the "?"s as missing data in your dataframe, you should use `"\\?"` as argument, otherwise the result will be 100% of the "?"s in your data.
Example:
`data.frame':	2671 obs. of  21 variables:
 $ x0 : chr  "b" "a" "a" "b" ...
 $ x1 : num  30.8 58.7 24.5 27.8 20.2 ...
 $ x2 : num  NA 4.46 0.5 1.54 5.62 ...
 $ x3 : chr  "u" "u" "u" "u" ...
 $ x4 : chr  "g" "g" "g" "g" ...
 $ x5 : chr  "w" "q" "q" "w" ...
 $ x6 : chr  "v" "h" "h" "v" ...
 $ x7 : num  1.25 3.04 1.5 3.75 1.71 ...
 $ x8 : chr  "t" "t" "t" "t" ...
 $ x9 : chr  "t" "t" "f" "t" ...
 $ x10: chr  "t" "6" "f" "5" ...
 $ x11: chr  "f" "f" "f" "t" ...
 $ x12: chr  "g" "g" "g" "g" ...
 $ x13: num  202 43 280 100 120 360 164 80 180 52 ...
 $ x14: num  NA 560 824 3 NA ...
 $ x20: chr  "t" "t" "t" "t" ...
 $ x17: num  116.9 225.6 92.1 104.2 77.9 ...
 $ x18: num  0.579 25.41 2.317 8.045 31.111 ...
 $ x19: num  202000 43000 280000 100000 120000 360000 164000 80000 180000 52000 ...
 $ x16: chr  "f" "f" "f" "f" ...
 $ y  : chr  "good" "good" "good" "good" ...
**miss_scan_count(data = training, search = list("?")), n=22)**` will output this:
` Variable     n
   <chr>    <int>
 1 x0        2671
 2 x1        2662
 3 x2        2546
 4 x3        2671
 5 x4        2671
 6 x5        2671
 7 x6        2671
 8 x7        2477
 9 x8        2671
10 x9        2671
11 x10       2671
12 x11       2671
13 x12       2671
14 x13       1961
15 x14       1590
16 x20       2671
17 x17       2662
18 x18       2671
19 x19       1961
20 x16       2671
21 y         2671`
the correct use of the function must  be:
`print(miss_scan_count(data = training, search = list("\\?")), n=22)
`.
(moved over here from https://stackoverflow.com/questions/58621567/naniarreplace-with-na-all-changes-factor-variables-to-integers)

I have a dataset where some missing values are coded as -99, and tried to use the naniar function replace_with_na_all to replace those values with NA. The function does this, but it also seems to convert my factor variables to integers, thereby losing the name of the factors.

This happens whether the factor itself already has some missing values or not, which you can see in the example below (in tibble1 the factor has a missing value from the start, in tibble2 it does not).

```r
library(tidyverse)
library(naniar)

# Example factor with missing values
tibble1 <- tribble(
  ~x, ~y,
  "a", 1,
  -99, 2,
  "c", -99
)

tibble1$x <- as.factor(tibble1$x) 


levels(tibble1$x) <- list("A" = "a",
                          "C" = "c")

# Showing original tibble and then after replace_with_na_all is used
tibble1
tibble1 %>% naniar::replace_with_na_all(condition = ~.x == -99) 




# Example factor without missing values
tibble2 <- tribble(
  ~x, ~y,
  "a", 1,
  "b", 2,
  "c", -99
)

tibble2$x <- as.factor(tibble2$x) 


levels(tibble2$x) <- list("A" = "a",
                          "B" = "b",
                          "C" = "c")

# Showing original tibble and then after replace_with_na_all is used
tibble2
tibble2 %>% naniar::replace_with_na_all(condition = ~.x == -99)  
```

Not sure if this is supposed to happen, but if it is, it was not clear to me from reading the documentation.
```r
any_not_na <- purrr::negate(anyNA)

any_not_na(airquality)

airquality %>%
  select_if(any_not_na)
```
This is a weird one that took me a long time to reproduce.  I'm making a plot with jittered points with errorbars (geom_errorbar, geom_linerange, and geom_errorbarh all have the following problem).  I do the jitter with the `position` argument so the errobars and points match up.  With `geom_point()`, the errorbars are correctly placed.  But with `geom_miss_point()` the errorbars are misplaced, but only when the axis labels aren't in the same order as in the dataframe (I think??).  Here's a reprex:

``` r
library(tidyverse)
library(naniar)

df1 <- tibble(y = rnorm(20, mean = 0, sd = 0.1),
              x = rep(c("a", "b", "c", "d", "e"), each = 4))

# different order for x
df2 <- tibble(y = rnorm(20, mean = 0, sd = 0.1),
              x = rep(c("e", "a", "b", "c", "d"), each = 4))

#set up jitter
j <- position_jitter(height = 0, width = 0.2)

# This works:
p <- ggplot(df2, aes(x, y)) +
  geom_point(position = j) +
  geom_linerange(aes(ymin = y - 0.5, ymax = y + 0.5), position = j)
p
```

![](https://i.imgur.com/aTKBcEn.png)

``` r

# misaligned errorbars:
p_miss <- ggplot(df2, aes(x, y)) +
  geom_miss_point(position = j, jitter = 0) +
  geom_linerange(aes(ymin = y - 0.5, ymax = y + 0.5), position = j)
p_miss
```

![](https://i.imgur.com/tGz0LZj.png)

``` r

# but this is fine for some reason:
p_miss2 <- ggplot(df1, aes(x, y)) + 
  geom_miss_point(position = j, jitter = 0) +
  geom_linerange(aes(ymin = y - 0.5, ymax = y + 0.5), position = j)
p_miss2
```

![](https://i.imgur.com/HIndl8Z.png)

``` r

# I think it has to do with factor levels or something because this fixes the second plot.
df2 %>% 
  mutate(x = fct_inorder(x)) %>%
  ggplot(aes(x,y)) + 
  geom_miss_point(position = j, jitter = 0) +
  geom_linerange(aes(ymin = y - 0.5, ymax = y + 0.5), position = j)
```

![](https://i.imgur.com/itH82np.png)

<sup>Created on 2019-07-19 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>

For large data sets `geom_bin2d` provides a useful alternative to geom_point. It would be nice to have something similar for large data with missings. Here's a crude mockup I made in paint:

![missing bin2d](https://user-images.githubusercontent.com/9996346/61265143-75a18080-a7d2-11e9-9fe1-b44a2ec5180b.png)

You'd probably move the missing bar down a bit and obviously the colour scale is a joke, but hopefully you get the idea. 

I first want to say that I really like geom_miss_point.  I'm using it on before/after species observation data and it shows the numbers of colonising and extinct species really well. But
I would like to be able to label the particularly commonly observed species which have gone extinct, and this doesn't at present appear possible; geom_text observes that it is ignoring the missing data. As the missing data portion of the plot  is quite condensed, it would be particularly useful to be able to use ggrepel::geom_text_repel for this.

![naniar1](https://user-images.githubusercontent.com/31484245/60352821-95f2d200-99c0-11e9-981d-175c93ac12e6.png)


See for example: https://github.com/earowang/mists#missing-data-polishing
When using `geom_miss_point()`, if there are missing values for both variables, then these are displayed along the a diagonal line. This isn't obvious in the vignette examples but when the number of missing values is high then it's obvious. See bottom left of the plot in the reprex below. 

Is it possible for these to instead be unequal / uncorrelated? 

I think this is something to do with how random uniform values are being selected for the jitter - they seem to be selected from a pre-set list of random numbers, rather than truely random each time. To see this, try running just the `ggplot(df) + naniar::geom_miss_point(aes(x, y))` over and over again in R, and you'll notice the jittered points don't change. (When you do something similar for `geom_jitter`, the plot will differ slightly each time.)  So, I think it's selecting from the same set of "random" uniform values. `set.seed()` just before the `ggplot` call makes no difference. It's not obvious to me from the source code why this might be happening.

Thanks very much for a brilliant package :+1: 

Reprex:

``` r
library('tidyverse')
library('naniar')

df <- tibble(
    x=rnorm(1000, 2, 1), 
    y=rnorm(1000, 5, 1)
    ) %>%
  mutate(
    x=ifelse(runif(1000)>0.2, x, NA),
    y=ifelse(runif(1000)>0.2, y, NA)
  )

ggplot(df) + naniar::geom_miss_point(aes(x, y))
```

![](https://i.imgur.com/xfFlv0i.png)




## Description

For some large datasets with few missing data, it is hard to distinguish if missing data are present or not using `gg_miss_var`.
This commit add a change in shape and color for variables with no missing data at all and variables with missing data.
Some more complex examples of `gg_miss_var` have been provided

## Example

``` r
library(dplyr)
#> 
#> Attachement du package : 'dplyr'
#> The following objects are masked from 'package:stats':
#> 
#>     filter, lag
#> The following objects are masked from 'package:base':
#> 
#>     intersect, setdiff, setequal, union
library(naniar)
dummy <- tibble(
    x = rep(1, 1000), 
    y = c(NA, rep(1, 999)), 
    z = sample(c(1, NA), 1000, replace = TRUE)
)
gg_miss_var(dummy)
```

![](https://i.imgur.com/LaKeR3j.png)

<sup>Created on 2019-02-18 by the [reprex package](https://reprex.tidyverse.org) (v0.2.1)</sup>

## Issue

Fix #167 