Finding this bug makes me even more impressed anyone has solved BipedalWalkerHardcore-v2 - it seems the observations from lidar have been inconsistent and incorrect, returning the furthest hit result instead of closest.

In screenshots below, I've tweaked the lidar drawing routine to draw last (in front of terrain and objects), and draw every trace each frame to more clearly see what's happening.

Before fix - lidar traces through ground, and hits the side of a pit, giving the agent the impression of a "phantom canyon" in front of the pit, that only appears as it approaches the pit: https://i.imgur.com/XKPnRTR.png

After fix - lidar is stopped by terrain, even when another object is behind it: https://i.imgur.com/Gg8B5BD.png

It feels very counter-intuitive for Box2Ds raycast to return furthest point first, but when I (double) checked the PyBox2D docs, I found that is indeed how it works: https://github.com/pybox2d/pybox2d/wiki/manual

> ... By returning
    0, you set the ray length to zero. By returning the current fraction, you proceed
    to find the **closest point**.

@olegklimov Tagging you since your name pops up the most in relation to BipedalWalker-v2

I've just restarted my models training with this fix applied, and been watching the traces like a hawk - worth noting it still seems to be imperfect sometimes - slightly penetrating a surface, but still looks much more accurate.
 

```
np.uint8(0).dtype.kind in np.typecodes['AllInteger'] == False
np.uint8(0).dtype.char in np.typecodes['AllInteger'] == True
```

```
dtype.kind	A character code (one of ‘biufcmMOSUV’) identifying the general kind of data.
dtype.char	A unique character code for each of the 21 different built-in types.
```
Hi,

I use Ubuntu 18.04. I can reproduce this error in a minimal example by creating a new conda environment and only `pip install gym`, so that the env only contains the following packages:

```
certifi==2019.11.28
cloudpickle==1.2.2
future==0.18.2
gym==0.15.4
numpy==1.18.1
opencv-python==4.1.2.30
pyglet==1.3.2
scipy==1.4.1
six==1.13.0
```

When I run the following code in that env:

```
import gym
env = gym.make('CartPole-v0')
env.reset()

for _ in range(1000):
    env.render()
    env.step(env.action_space.sample())
```

I get the following error:

```
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 1035, in _handle_fromlist
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jroy4/anaconda3/envs/irl/lib/python3.7/site-packages/gym/envs/classic_control/rendering.py", line 27, in <module>
    from pyglet.gl import *
  File "/home/jroy4/anaconda3/envs/irl/lib/python3.7/site-packages/pyglet/gl/__init__.py", line 221, in <module>
    from .xlib import XlibConfig as Config
  File "/home/jroy4/anaconda3/envs/irl/lib/python3.7/site-packages/pyglet/gl/xlib.py", line 12, in <module>
    from pyglet.canvas.xlib import XlibCanvas
  File "/home/jroy4/anaconda3/envs/irl/lib/python3.7/site-packages/pyglet/canvas/__init__.py", line 103, in <module>
    from pyglet.canvas.xlib import XlibDisplay as Display
  File "/home/jroy4/anaconda3/envs/irl/lib/python3.7/site-packages/pyglet/canvas/xlib.py", line 19, in <module>
    from . import xlib_vidmoderestore
  File "/home/jroy4/anaconda3/envs/irl/lib/python3.7/site-packages/pyglet/canvas/xlib_vidmoderestore.py", line 23, in <module>
    from pyglet.libs.x11 import xlib
  File "/home/jroy4/anaconda3/envs/irl/lib/python3.7/site-packages/pyglet/libs/x11/xlib.py", line 2928, in <module>
    XEHeadOfExtensionList.argtypes = [XEDataObject]
TypeError: item 1 in _argtypes_ passes a union by value, which is unsupported.
```

Any idea what is going on? Thanks!

**Edit: I use python=3.7.6**
this error occurs while importing tensorflow version 1.15 for openai gym.Please suggest any other tensorflow compatible versions.
The behaviors of Atari envs seem affected by the version of `atari-py` even though the env id the same.

```python
import gym

env = gym.make('MsPacmanNoFrameskip-v4')
env.seed(0)
env.reset()
done = False
t = 0
R = 0
while not done:
    _, r, done, _ = env.step(1)
    t += 1
    R += r
print(t, R)
```
Below is the output of this code for each pair of `gym` and `atari-py`. It seem like `atari-py` is the cause of the difference, but since `gym` requires `atari-py~=0.2.0` in `setup.py` from 1.3.0 (https://github.com/openai/gym/pull/1535) it should be responsible for the version of `atari-py`. That is why I opened this issue here, not in https://github.com/openai/atari-py.
- `gym==0.15.4` `atari-py==0.2.6`: 2009 90.0
- `gym==0.15.4` `atari-py==0.2.0`: 2009 90.0
- `gym==0.15.4` `atari-py==0.1.15`: 1329 90.0
- `gym==0.15.4` `atari-py==0.1.4`: 1329 90.0
- `gym==0.12.6` `atari-py==0.2.6`: 2009 90.0
- `gym==0.12.6` `atari-py==0.2.0`: 2009 90.0
- `gym==0.12.6` `atari-py==0.1.15`: 1329 90.0
- `gym==0.12.6` `atari-py==0.1.4`: 1329 90.0

I also confirmed such a difference for `ChopperCommandNoFrameskip-v4`.

I am concerned that these differences might significantly affect the evaluation of RL algorithms. Has anyone investigated the effect?
Hi, I am wondering for Mujoco tasks such as Hopper-v2, HalfCheetah-v2, and Swimmer, what are these the highest score of these tasks we can gain?  Or how to judge when a task is solved? Thanks.
I have only run a model on pong until now and when I used the gym.wrapper.Monitor to save the videos in the testing phase, it only saved videos of the first two episodes and did not do the same for the rest.
Since seed() is being called in default initialization of Space, it should be controllable for reproducibility.
Hi there,

I'd like to rotate target object(for example 'object0' in default xml file).

Where is defined setting random position of target position?