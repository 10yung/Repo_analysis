Please fill out the sections below to help us address your issue.

### Version of AWS SDK for Go?
v1.19.37 v1.28.5 

### Version of Go (`go version`)?
go1.13.5 darwin/amd64

### What issue did you see?
Production issue, running at k8s docker.
Batch download multi files, the memory of the progress is very high, up to 4G, cause OOM.
![image](https://user-images.githubusercontent.com/4799292/72657931-8df29200-39e5-11ea-8e31-b5182d76ea7c.png)

Test case, running at mac.
Write a unit test to download a 11M file, memory will increate to 300M
Run the test, pprof result:
![image](https://user-images.githubusercontent.com/4799292/72658386-31927100-39eb-11ea-956d-d8a77c4b0aa1.png)
Top info
![image](https://user-images.githubusercontent.com/4799292/72658407-80d8a180-39eb-11ea-8d22-31ab13443a49.png)

### Steps to reproduce

```
func Monitor() {
	ip := "0.0.0.0:6060"
	elog.Debugf("Start pprof %s", ip)
	if err := http.ListenAndServe(ip, nil); err != nil {
		elog.Errorf("start pprof failed on %s\n", ip)
		panic(err)
	}
}

func Test_S3Download(t *testing.T) {
	go Monitor()
	time.Sleep(10 * time.Second)
	ctx := context.Background()
	econfig.SetConfigFile("config.yaml")
	econfig.LoadConfig()
	accessKey := econfig.GetString("AccessKey")
	secretKey := econfig.GetString("SecretKey")
	bucket := econfig.GetString("Bucket")
	region := "us-east-1"
	creds := credentials.NewStaticCredentials(accessKey, secretKey, "")
	config := &aws.Config{
		Region:      aws.String(region),
		Credentials: creds,
	}
	sess := session.Must(session.NewSession(config))
	dl := s3manager.NewDownloader(sess)
	key := "test.snappy"
	w := &aws.WriteAtBuffer{}
	inputObject := &s3.GetObjectInput{
		Bucket: aws.String(bucket),
		Key:    aws.String(key),
	}
	elog.Debugxf(ctx, "Start get from s3")
	n, err := dl.DownloadWithContext(ctx, w, inputObject)
	if err != nil {
		elog.Warnxk(ctx, "Download from s3 failed.", "key", key, "error", err)
		return
	}
	elog.Debugxf(ctx, "Download done. key[%s] size[%d]", key, n)
	time.Sleep(60 * time.Second)
}
```

I saw there are some memory issue, cause OOM is big issue, what's the plan to fix this, or any suggestion to use s3manager.downloader and s3manager.uploader.
For changes to files under the `/model/` folder, and manual edits to autogenerated code (e.g. `/service/s3/api.go`) please create an Issue instead of a PR for those type of changes.

If there is an existing bug or feature this PR is answers please reference it here.

### Is this related to a problem?
It would be nice to be able to create a S3 EncryptionClients and DecryptionClients with an S3 client, in much the same way that `s3manager` does so that users who create S3 clients with special config values like assumer roles can use the client more easily.

### Feature description
Create a new constructor for the `EncryptionClient` called `NewEncryptorWithClient` or something similar that would conform to the following definition: `func NewEncryptorWithClient(svc *s3.S3, builder ContentCipherBuilder, options ...func(*EncryptionClient)) *EncryptionClient` that uses the `s3.S3` in place of calling `s3.New`.

Further, create a new constructor for the `DecryptionClient` called `NewDecryptorWithClient` or something similar that would conform to the following definition func NewDecryptorWithClient(svc *s3.S3, builder ContentCipherBuilder, options ...func(*DecryptionClient)) *DecryptionClient` that uses the `s3.S3` in place of calling `s3.New` and uses the `ContentCipherBuilder` in place of calling `kms.New`.

### Describe alternatives you've considered
I've considered creating the clients manually but that's more work than it should be, considering how prevalent these operations should be.
Please fill out the sections below to help us address your issue.

### Version of AWS SDK for Go?
1.27.4

### Version of Go (`go version`)?
1.13.5

### What issue did you see?
I tried to filter errors coming from Invoke for "RequestTooLargeException" but I actually got the error "RequestEntityTooLarge" exception:

```
2020/01/15 14:51:45 Error invoking lambda function
2020/01/15 14:51:45 RequestEntityTooLargeException: Request must be smaller than 6291456 bytes for the InvokeFunction operation
        status code: 413, request id: 4f90b35e-c583-4c6e-bccb-9956291dd896
```

My error handling code looked like:
```
log.Println("Error invoking lambda function")
log.Println(err)
awsErr, ok := err.(awserr.Error)
if ok && awsErr.Code() == lambda.ErrCodeRequestTooLargeException {
	log.Fatal("Request too large") // never gets called, because the error codes do not match
}
```

The SDK defines lambda.ErrCodeRequestTooLargeException, but not lambda.ErrCodeRequestEntityTooLargeException. So, am I looking in the wrong place for the error code constant? What's the difference between RequestTooLargeException and  RequestEntityTooLargeException? (The descriptions seem to describe the same thing.)

Workaround was just to use a string instead of referencing a constant from the package.


`CreatedDate` field in `GetSecretValueOutput` struct is actually Last Updated field. Please change the documentation to reflect that.


In service/secretsmanager/api.go:
```
// The date and time that this version of the secret was last updated.
CreatedDate *time.Time `type:"timestamp"`
```


### Version of AWS SDK for Go?
v1.28.0 

### Version of Go (`go version`)?
1.13.5, 1.13.6

### What issue did you see?
Excessive memory consumption when concurrently uploading to s3 using the s3 upload manager. The program runs out of memory and crashes when uploading from an AWS EC2 linux instance with 1 GB RAM. The program does not crash or leak memory when running with Go 1.12.14.

Profiling Go 1.12.14 on instance: The top nodes don't contain any memory usage related to aws-sdk-go

Profiling Go 1.13.6 on instance: Program crashes (as it runs out of memory) and unable to see profiling output, however running the program locally (16 GB RAM) I can see all the memory is consumed by the s3 upload processes unlike the above.

(pprof) top
Showing nodes accounting for 266243.44kB, 99.40% of 267842.77kB total
Dropped 501 nodes (cum <= 1339.21kB)
Showing top 10 nodes out of 11
      flat  flat%   sum%        cum   cum%
266240.12kB 99.40% 99.40% 266240.12kB 99.40%  github.com/aws/aws-sdk-go/service/s3/s3manager.newPartPool.func1
       1kB 0.00037% 99.40% 235524.98kB 87.93%  github.com/aws/aws-sdk-go/service/s3/s3manager.(*multiuploader).upload
    0.59kB 0.00022% 99.40% 266246.66kB 99.40%  github.com/aws/aws-sdk-go/service/s3/s3manager.Uploader.UploadWithContext
    0.38kB 0.00014% 99.40% 266245.95kB 99.40%  github.com/aws/aws-sdk-go/service/s3/s3manager.(*uploader).upload
    0.09kB 3.5e-05% 99.40% 266241.81kB 99.40%  github.com/aws/aws-sdk-go/service/s3/s3manager.(*uploader).nextReader
         0     0% 99.40% 266241.62kB 99.40%  github.com/aws/aws-sdk-go/service/s3/s3manager.(*partPool).Get
         0     0% 99.40% 266246.66kB 99.40%  github.com/aws/aws-sdk-go/service/s3/s3manager.Uploader.Upload
 
### Steps to reproduce
Run the code below using Go 1.13.6 from an AWS EC2 instance (I did this with 10 uploads each around 200 MB in size)

```go
package main

import (
	"io"
	"log"
	"math/rand"
	"net/http"
	"net/url"
	"os"
	"sync"
	"time"

	_ "net/http/pprof"

	"github.com/aws/aws-sdk-go/aws"
	"github.com/aws/aws-sdk-go/aws/session"
	"github.com/aws/aws-sdk-go/service/s3/s3manager"
	"github.com/pkg/profile"
)

func (s s3uploader) uploadToS3(path string, res io.Reader) error {
	_, err := s.u.Upload(&s3manager.UploadInput{
		Bucket: aws.String(os.Getenv("S3_STORAGE_BUCKET")),
		Key:    aws.String(path),
		Body:   res,
	})
	if err != nil {
		return err
	}
	return nil
}

func (s s3uploader) syncOne(source string) error {
	u, err := url.Parse(source)
	if err != nil {
		return err
	}
	var res *http.Response
	res, err = http.Get(source)
	if err != nil {
		return err
	}
	defer res.Body.Close()
	log.Printf("uploading: %s", source)
	if err := s.uploadToS3(u.Path, res.Body); err != nil {
		return err
	}
	return nil
}

func (s s3uploader) sync(urls []string, concurrency int) error {
	work := make(chan string)
	var wg sync.WaitGroup
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for url := range work {
				if err := s.syncOne(url); err != nil {
					time.Sleep(time.Millisecond*time.Duration(rand.Intn(5000)) + time.Second)
					log.Printf("Retrying url: %s", url)
				}
			}
		}()
	}

	for _, url := range urls {
		work <- url
	}
	close(work)
	wg.Wait()
	return nil
}

type s3uploader struct {
	u *s3manager.Uploader
}

func main() {
	go func() {
		log.Println(http.ListenAndServe("localhost:6060", nil))
	}()
	defer profile.Start(profile.MemProfile).Stop()
	conf := aws.Config{Region: aws.String(os.Getenv("AWS_REGION"))}
	s := session.New(&conf)
	uploader := s3manager.NewUploader(s, func(u *s3manager.Uploader) {
		u.PartSize = 10 * 1024 * 1024 // 10MB per part
	})
	var ul s3uploader
	ul.u = uploader

	const concurrency = 5
	if err := ul.sync(os.Args[1:], concurrency); err != nil {
		log.Printf("  ...syncing failed: %s", err)
		return
	}

}
```



   

### Version of AWS SDK for Go?
v1.26.8

### Version of Go (`go version`)?
go version go1.13 darwin/amd64

### What issue did you see?
Profiling the app shows that the app was spending much resources while handling TLS handshakes. 
Over a third of CPU/Memory was being used for TLS negotiation (which after setting the `MaxIdleConnsPerHost` seemed to be better)
However, even when `IdleConnTimeout` is set, the connections still seem to be discarded after around ~6-8 seconds of inactivity and a new TLS negotiation is initiated.

### Steps to reproduce
* Connect to Kinesis
```go
sess := session.Must(session.NewSession(&aws.Config{
		Region:                        aws.String(awsRegion),
		CredentialsChainVerboseErrors: aws.Bool(verboseErrors),
	}))
stsConfig := &aws.Config{
		Credentials:                   creds,
		Region:                        aws.String(awsRegion),
		CredentialsChainVerboseErrors: aws.Bool(verboseErrors),
		HTTPClient: &http.Client{
			Transport: &http.Transport{
				Proxy: http.ProxyFromEnvironment,
				DialContext: (&net.Dialer{
					Timeout:   30 * time.Second,
					KeepAlive: 30 * time.Second,
				}).DialContext,
				MaxIdleConns:          100,
				IdleConnTimeout:       90 * time.Second,
				MaxIdleConnsPerHost:   50,
				TLSHandshakeTimeout:   3 * time.Second,
				ExpectContinueTimeout: 1 * time.Second,
			},
		},
	}

client := kinesis.New(sess, stsConfig)
client.PutRecord(...)
```
* Execute the script to send some data

`net/http/transport.go` `addTLS()` is invoked, for every request that is 6-10 seconds apart to start a new TLS session.

### Expected
One would expect that the TLS session would only be initiated once, and be re-used from idle sessions
Please fill out the sections below to help us address your issue.

### Version of AWS SDK for Go?
V1.17.1

### Version of Go (`go version`)?
1.13

### What issue did you see?
Seeing JSON decoding error caused by closed network connection when reading from DynamoDB while the response status is 200. 

```
SerializationError: failed decoding JSON RPC response
status code: 200, request id: ****
caused by: read tcp ***:41784->**:443: use of closed network connection
```

Error message from:
https://github.com/aws/aws-sdk-go/blob/3c8d61f5257e0e0da3e8d901f56c6765878f09e5/private/protocol/jsonrpc/jsonrpc.go#L63

Two things confused us related to this issue:
- Why connection error is wrapped in an unmarshal error?
- Why 200 status code returned when there's a network issue?

Please advise, thanks.

### Steps to reproduce
Unfortunately, we don't have specific instructions to reproduce this. This issue happens sporadically when reading data from DyanmoDB. 
Now you have no way to specify a dynamodb.AttributeValue as a parameter to `expression.BuildOperand` method.
If you do so, it will be treated as any other struct, and instead of just passing a value, it will Marshal it's inner struct (all the {...BOOL: true, NULL: true, ...} fields that are needed for inner implementation).

That is a problem when you (for **example**) have a struct that was already been Marshalled:

```go
package main

import (
	"fmt"

	"github.com/aws/aws-sdk-go/service/dynamodb"
	"github.com/aws/aws-sdk-go/service/dynamodb/dynamodbattribute"
	"github.com/aws/aws-sdk-go/service/dynamodb/expression"
)

type T struct {
	ID    uint64  `dynamodbav:"id"`
	Code  string  `dynamodbav:"code"`
	Total float32 `dynamodbav:"amount"`
}

func main() {
	t := T{
		ID:    1,
		Code:  "code",
		Total: 10.5,
		// it can have dozens of fields
	}

	// it is now Marshalled into proper structs
	av, err := dynamodbattribute.MarshalMap(t)
	if err != nil {
		panic(err)
	}

	updateExpr := buildUpdateExpressionFrom(av)

	builder := expression.NewBuilder().
		WithUpdate(updateExpr)

	expr, err := builder.Build()
	if err != nil {
		panic(err)
	}

	fmt.Printf("%q", expr) // it will have a mess now. fixed in this PR
}

func buildUpdateExpressionFrom(av map[string]*dynamodb.AttributeValue) expression.UpdateBuilder {
	var expr expression.UpdateBuilder

	for attr, value := range av {
		expr = expr.Set(expression.Name(attr), expression.Value(value)) // <--- here is a problem now
	}

	return expr
}

```


Please fill out the sections below to help us address your issue.

### Version of AWS SDK for Go?

Release v1.26.7 (2019-12-20)
ab52e2140da6138c05220ee782cc2bcd85feecee

### Version of Go (`go version`)?

1.13

### What issue did you see?

According to https://docs.aws.amazon.com/cli/latest/userguide/cli-environment.html there is now a "standard" (unfortunately many API clients do indeed use AWS_REGION).

Suggest only using AWS_REGION if AWS_DEFAULT_REGION is not blank.
Essentially, I'd like to re-open #2103

In this decade `AWS_DEFAULT_REGION` is only valid approach to specify the region. All tools uses.

