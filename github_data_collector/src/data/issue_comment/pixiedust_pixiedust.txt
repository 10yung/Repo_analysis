As a developer using python 3.7, I want the "Continue execution until the current function returns" button to eventually end the debugging session so that I can debug

Premise: I am on python 3.7.3. Tested the code both with a normal kernel and with the pixiedust kernel (the debugger should work even outside of the pixiedust-spark kernel).

When running the debugger on the simple example

```python
%%pixie_debugger
import random
def find_max (values):
    max = 0
    for val in values:
        if val > max:
            max = val
    return max
find_max(random.sample(range(100), 10))
```

if I click "Continue execution until the current function returns" until the end of the snippet, the debugger gets to

```python
finally:
               # Reset our crash handler in place
                sys.excepthook = old_excepthook
```

in the coroutine

```python
@asyncio.coroutine
   def run_code(self, code_obj, result=None, *, async_=False)
```

then it goes through all the internals of asyncio and finally it hangs at 

```python
finally:
            self._restore_input()
```

in the coroutine

```python
@gen.coroutine
    def do_execute(self, code, silent, store_history=True,
                   user_expressions=None, allow_stdin=False)
```

(from this moment onwards the button "Continue execution until the current function returns" is idempotently leaving me on the same line).

None of the debugger buttons can get me unstack from here.
As a `<user type>`, I want to `<task>` so that `<goal>` (make this the title)

### Expected behavior
It should show the spark job monitor

### Actual behavior
it shows a error : Spark Job Progress Monitoring cannot be started on DSX

### Steps to reproduce the behavior

As a USER, I want to user pixiedust in jupyter of windows 10 so that I got the “exception in thread "main" java.io.IOException: No FileSystem for scheme: C”。

### Expected behavior
jupyter kernel pythonwithpixiedustspark24 should be able handle path: C:/spark-2.4.4-bin-hadoop2.7/python/pyspark/shell.py

### Actual behavior
Exception in thread "main" java.io.IOException: No FileSystem for scheme: C
        at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)
        at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)
                                .......
[IPKernelApp] WARNING | Unknown error in handling PYTHONSTARTUP file C:/spark-2.4.4-bin-hadoop2.7/python/pyspark/shell.py:

### Steps to reproduce the behavior
1. start from command line: jupyter lab
2. create a new ipynb page, input following:
**from pyspark import SparkContext
sc = SparkContext("local", "First App")**
3. run them. You may see the exception printed in the console of jupyter 
4.  _switch to original kernel "Python3", these two lines can be run without error_.

### environment
Windows 10 (only one hard disk C:\)
Anaconda python (3.7.3)
spark 2.44 with prebuilt hadoop 2.7 (winutil.exe included)
scala 2.11.8

### tried but not working:
set windows enviornment variable: 
**SPARK_HOME=C:/spark-2.4.4-bin-hadoop2.7**
change line 512 of createKernel.py as: 
**"PYTHONSTARTUP": "file:///{0}/python/pyspark/shell.py".format(self.spark_home)**,

As a `<user type>`, I want to `<task>` so that `<goal>` (make this the title)

### Expected behavior

### Actual behavior

### Steps to reproduce the behavior

As a `<user type>`, I want to `<task>` so that `<goal>` (make this the title)

### Expected behavior
Expected to get the interactive viewer
### Actual behavior
display nothing
### Steps to reproduce the behavior
read in csv with pd.read_csv
display(mydataframe)
### I have tired
convert my dataframe to pyspark.sql.dataframe.DataFrame
But still got nothing
As a data analyst, I want to create charts with secondary axis such that for primary & secondary axis I can have different chart types. 
I have referred to the issue raised in https://github.com/pixiedust/pixiedust/issues/11 and the only thing that I need is to have one as a bar chart and the other as a line chart rather than 2 bar chart. 

### Expected behavior
Currently we can only display chart types of the same nature
### Actual behavior
Ability to choose different chart types
### Steps to reproduce the behavior
https://github.com/pixiedust/pixiedust/issues/11 - Option to change chart type of axis is not available currently.


Regards
Ganesh Bhat
I can't  set break point in a file which the function is not shown in the jupyter note book. How can I do it?
Downloading 'Total population by country' from https://apsportal.ibm.com/exchange-api/v1/entries/889ca053a19986a4445839358a91963e/data?accessKey=657b130d504ab539947e51b50f0e338e
---------------------------------------------------------------------------
SSLCertVerificationError                  Traceback (most recent call last)
/miniconda3/lib/python3.7/urllib/request.py in do_open(self, http_class, req, **http_conn_args)
   1316                 h.request(req.get_method(), req.selector, req.data, headers,
-> 1317                           encode_chunked=req.has_header('Transfer-encoding'))
   1318             except OSError as err: # timeout error

/miniconda3/lib/python3.7/http/client.py in request(self, method, url, body, headers, encode_chunked)
   1228         """Send a complete request to the server."""
-> 1229         self._send_request(method, url, body, headers, encode_chunked)
   1230 

/miniconda3/lib/python3.7/http/client.py in _send_request(self, method, url, body, headers, encode_chunked)
   1274             body = _encode(body, 'body')
-> 1275         self.endheaders(body, encode_chunked=encode_chunked)
   1276 

/miniconda3/lib/python3.7/http/client.py in endheaders(self, message_body, encode_chunked)
   1223             raise CannotSendHeader()
-> 1224         self._send_output(message_body, encode_chunked=encode_chunked)
   1225 

/miniconda3/lib/python3.7/http/client.py in _send_output(self, message_body, encode_chunked)
   1015         del self._buffer[:]
-> 1016         self.send(msg)
   1017 

/miniconda3/lib/python3.7/http/client.py in send(self, data)
    955             if self.auto_open:
--> 956                 self.connect()
    957             else:

/miniconda3/lib/python3.7/http/client.py in connect(self)
   1391             self.sock = self._context.wrap_socket(self.sock,
-> 1392                                                   server_hostname=server_hostname)
   1393 

/miniconda3/lib/python3.7/ssl.py in wrap_socket(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)
    411             context=self,
--> 412             session=session
    413         )

/miniconda3/lib/python3.7/ssl.py in _create(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)
    852                         raise ValueError("do_handshake_on_connect should not be specified for non-blocking sockets")
--> 853                     self.do_handshake()
    854             except (OSError, ValueError):

/miniconda3/lib/python3.7/ssl.py in do_handshake(self, block)
   1116                 self.settimeout(None)
-> 1117             self._sslobj.do_handshake()
   1118         finally:

SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1056)

During handling of the above exception, another exception occurred:

URLError                                  Traceback (most recent call last)
<ipython-input-13-b8cd84001218> in <module>
----> 1 popdf = pixiedust.sampleData(3)

/miniconda3/lib/python3.7/site-packages/pixiedust/utils/environment.py in wrapper(*args, **kwargs)
    104                 elif version.startswith('2.'):
    105                     return 2
--> 106             except Exception as exc:
    107                 raise Exception("Unable to read spark Version, please check your install {}".format(exc))
    108             return None

/miniconda3/lib/python3.7/site-packages/pixiedust/utils/sampleData.py in sampleData(dataId, type, forcePandas)
     85 def sampleData(dataId=None, type='csv', forcePandas=False, delimiter=','):
     86     global dataDefs
---> 87     return SampleData(dataDefs, forcePandas, delimiter).sampleData(dataId, type)
     88 
     89 class SampleData(object):

/miniconda3/lib/python3.7/site-packages/pixiedust/utils/sampleData.py in sampleData(self, dataId, type)
     98         if dataId is None:
     99             self.printSampleDataList()
--> 100         elif str(dataId) in dataDefs:
    101             return self.loadSparkDataFrameFromSampleData(dataDefs[str(dataId)])
    102         elif "https://" in str(dataId) or "http://" in str(dataId) or "file://" in str(dataId):

/miniconda3/lib/python3.7/site-packages/pixiedust/utils/sampleData.py in loadSparkDataFrameFromSampleData(self, dataDef)
    189             df = json_normalize(data)
    190             return df
--> 191 
    192     def loadSparkDataFrameFromSampleData(self, dataDef):
    193         return Downloader(dataDef, self.forcePandas).download(self.dataLoader)

/miniconda3/lib/python3.7/site-packages/pixiedust/utils/sampleData.py in download(self, dataLoader)
    231             req = Request(url, None, self.headers)
    232             print("Downloading '{0}' from {1}".format(displayName, url))
--> 233             tdir = '/home/spark/shared' if Environment.hasSpark and not self.forcePandas and os.path.exists('/home/spark/shared') else tempfile.gettempdir()
    234             with tempfile.NamedTemporaryFile(delete=False, dir=tdir) as f:
    235                 bytesDownloaded = self.write(urlopen(req), f)

/miniconda3/lib/python3.7/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)
    220     else:
    221         opener = _opener
--> 222     return opener.open(url, data, timeout)
    223 
    224 def install_opener(opener):

/miniconda3/lib/python3.7/urllib/request.py in open(self, fullurl, data, timeout)
    523             req = meth(req)
    524 
--> 525         response = self._open(req, data)
    526 
    527         # post-process response

/miniconda3/lib/python3.7/urllib/request.py in _open(self, req, data)
    541         protocol = req.type
    542         result = self._call_chain(self.handle_open, protocol, protocol +
--> 543                                   '_open', req)
    544         if result:
    545             return result

/miniconda3/lib/python3.7/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args)
    501         for handler in handlers:
    502             func = getattr(handler, meth_name)
--> 503             result = func(*args)
    504             if result is not None:
    505                 return result

/miniconda3/lib/python3.7/urllib/request.py in https_open(self, req)
   1358         def https_open(self, req):
   1359             return self.do_open(http.client.HTTPSConnection, req,
-> 1360                 context=self._context, check_hostname=self._check_hostname)
   1361 
   1362         https_request = AbstractHTTPHandler.do_request_

/miniconda3/lib/python3.7/urllib/request.py in do_open(self, http_class, req, **http_conn_args)
   1317                           encode_chunked=req.has_header('Transfer-encoding'))
   1318             except OSError as err: # timeout error
-> 1319                 raise URLError(err)
   1320             r = h.getresponse()
   1321         except:

URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1056)>

So, Ive been trying to run this file for quite some time, I have gotten a ton of help, but none seem to work. When i drag the openme.py file into a command prompt file and enter, it says no module named colorama. After tryiny to install colorama with various commands, unistalling it, reinstalling it all multiple times, nothing has worked. Even weirder, when i try to use the command pip install colorama, it says i have it, but when i run the file after it says i dont have it. Any help would be appreciated.  ![image](https://user-images.githubusercontent.com/42871935/58387286-e8ac2900-7fd1-11e9-9dbd-e395715a80c2.png)


I'm a total newbie on this so its probably "user error", but...

I have a Jupyter Notebook that runs without errors. I've installed pixiedust, and am trying to use %%pixie_debugger as an IDE in a particular cell. 

Running the same cell without the debugger, no errors. 

With the debugger, and with no breakpoints set, if I click "continue to next breakpoint" (yellow "play" icon), I get a "name error" referring to a variable that is set in the global context. 

I would expect the code to execute the same way with or without the %%pixie_debugger line of code?

Any help would be appreciated... Thanks

