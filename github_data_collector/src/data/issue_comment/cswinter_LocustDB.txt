`count_by_passenger_count_pickup_year_trip_distance` is 50% slower after query refactor.
It should ensure that all output column names are unique.
Currently everything uses FNV, but there may be better choices in particular for string data. Should set up some benchmarks and find out.
Columns are reordered to have projections followed by aggregations.
There are a lot of cases where intermediary results could be streamed between operators, but aren't. One example is inability to stream from operators that produce a full output. There are probably some low hanging fruit, but proper solution is more involved and will need to revisit the overall design to solve this better, probably moving the graph partitioning from `QueryExecutor` to `QueryPlanner` to allow insertion of additional operators to aid streaming data.
There is one remaining place during query execution which is performed "manually" rather than by constructing and executing a query plan: https://github.com/cswinter/LocustDB/blob/38ba86d6f915e1173d9075f2a0fc206d674441c6/src/engine/execution/batch_merging.rs#L247
Mostly this just requires moving the `Data::append_all` function into a `VectorOperator` and corresponding `QueryPlan` variant and then constructing a query plan in the same fashion as all the other cases for merging batches.
Various parts of the code use `mem::transmute` to make lifetimes work out for data referencing strings. More details on the issue here: https://clemenswinter.com/2018/07/09/how-to-analyze-billions-of-records-per-second-on-a-single-desktop-pc/4/
Probably not worth revisiting this until generic associated types are available.
The tablename should be part of the RocksDB primary key so scans over a column that exists in multiple tables doesn't read unnecessary blocks.
Performance might benefit from ReadOptions.readahead and ReadOptions.iterate_upper_bound once those are exposed by rust-rocksdb
See https://github.com/andygrove/sqlparser-rs/issues/29