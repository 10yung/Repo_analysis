I think it shows some valid issues https://lgtm.com/projects/g/kornelski/pngquant/?mode=list


Hello, I used this code to compress PNG image in IOS project, but the data I got failed to pass a transparency judgment. I wonder if the compressed PNG is not a true color image. How can I modify the code,thank you!

my Code:

```
int progress_callback_function(float progress_percent, void* user_info) {
    return 1;
}
+ (NSData *)compressToPNGWithImage:(UIImage *)comImg {
    
    unsigned int width, height;

    CFDataRef pixelData = CGDataProviderCopyData(CGImageGetDataProvider(comImg.CGImage));
    const uint8_t* data = CFDataGetBytePtr(pixelData);

    width = (int)comImg.size.width;
    height = (int)comImg.size.height;

    liq_attr *handle = liq_attr_create();
    liq_attr_set_progress_callback(handle, progress_callback_function, NULL);
    liq_set_quality(handle, 75, 90);//图片质量范围 > 0 < 100;
    liq_set_speed(handle, 3);//压缩速度对压缩比有一定影响的
    liq_image *input_image = liq_image_create_rgba(handle, data, width, height, 0);
        // You could set more options here, like liq_set_quality
    liq_result *quantization_result;
    if (liq_image_quantize(input_image, handle, &quantization_result) != LIQ_OK) {
        fprintf(stderr, "Quantization failed\n");
        return nil;
    }

    // Use libimagequant to make new image pixels from the palette

    size_t pixels_size = width * height;
    unsigned char *raw_8bit_pixels = malloc(pixels_size);
    liq_set_dithering_level(quantization_result, 1.0);

    liq_write_remapped_image(quantization_result, input_image, raw_8bit_pixels, pixels_size);
    const liq_palette *palette = liq_get_palette(quantization_result);

        // Save converted pixels as a PNG file
        // This uses lodepng library for PNG writing (not part of libimagequant)

    LodePNGState state;
    lodepng_state_init(&state);
    state.info_raw.colortype = LCT_PALETTE;
    state.info_raw.bitdepth = 8;
    state.info_png.color.colortype = LCT_PALETTE;
    state.info_png.color.bitdepth = 8;

    for(int i=0; i < palette->count; i++) {
        lodepng_palette_add(&state.info_png.color, palette->entries[i].r, palette->entries[i].g, palette->entries[i].b, palette->entries[i].a);
        lodepng_palette_add(&state.info_raw, palette->entries[i].r, palette->entries[i].g, palette->entries[i].b, palette->entries[i].a);
    }

    unsigned char *output_file_data;
    size_t output_file_size;
    unsigned int out_status = lodepng_encode(&output_file_data, &output_file_size, raw_8bit_pixels, width, height, &state);
    if (out_status) {
        fprintf(stderr, "Can't encode image: %s\n", lodepng_error_text(out_status));
        return nil;
    }
    NSData *output_data = [NSData dataWithBytes:output_file_data length:output_file_size];

    liq_result_destroy(quantization_result); // Must be freed only after you're done using the palette
    liq_image_destroy(input_image);
    liq_attr_destroy(handle);

    free(raw_8bit_pixels);
    lodepng_state_cleanup(&state);
    return output_data;
}

```

judge:

```
       uint8_t c;
       [imageData getBytes:&c range:NSMakeRange(25, 1)];
       if (c == 0x03) {
           NSLog(@"It's not what I want!");
           return;
       }
```

I try call windows binary from c#. I use stdin and stdout and everything is works except small images (size is less than 4000 bytes). When I use call with image path everything works fine.

Code example and image example.

`            
var startInfo = new ProcessStartInfo()
            {
                CreateNoWindow = true,
                FileName = PngquantPath,
                Arguments = "256 --speed 3 --quality=45-85 --skip-if-larger -",
                RedirectStandardInput = true,
                RedirectStandardOutput = true,
                UseShellExecute = false,
            };


            using (Process process = Process.Start(startInfo))
            {
                using (var outputStream = new MemoryStream())
                {
                    process.StandardInput.BaseStream.Write(image.Bytes, 0, image.Bytes.Length);
                    process.WaitForExit(5000);
                    var err = process.StandardError.ReadToEnd();
                    await process.StandardOutput.BaseStream.CopyToAsync(outputStream);

                    image.Bytes = outputStream.ToArray();
                }
            }

![testx](https://user-images.githubusercontent.com/23473408/68895716-2a6c8f80-072a-11ea-96e5-fc7db5c53093.png)
` 
In the process of making changes to formulae in the Homebrew package manager, I noticed that pngquant was one of a handful of Rust-related applications without a `Cargo.lock` file in version control.  The Cargo book recommends the following ([source](https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html)):

> If you’re building an end product, which are executable like command-line tool or an application, or a system library with crate-type of staticlib or cdylib, check `Cargo.lock` into `git`.

More information about the reasoning can be found in the ["Why do binaries have Cargo.lock in version control, but not libraries?"](https://doc.rust-lang.org/cargo/faq.html#why-do-binaries-have-cargolock-in-version-control-but-not-libraries) section of the Cargo FAQ.

The `Cargo.lock` file helps package managers to keep builds reproducible, since `cargo install` simply uses the latest dependency versions unless the `--locked` flag is added to the command, in which case it will use the versions outlined in `Cargo.lock`.  Without a `Cargo.lock` file, there's a chance that a dependency update will break the build sometime in the future, which is something I've already encountered with other Rust binary projects.

Would you please consider checking `Cargo.lock` into version control, where appropriate?
This is more of a question. If I needed a palette output restricted to ARGB4888 and not ARGB8888 is it possible somehow to modify the code to reduce the bit depth available? I see the code that handles the IE 6.0 and alpha and it made me think that if I were to modify the alpha input values to only contains values that could be reduced to 4 bits (i.e. fixed intervals with no alpha values between those intervals) would that cause the output to strictly stick to those alphas in the output palette or would it generate blended alpha values beyond the restricted alphas I allowed in order to optimize the palette? I know I can go in and force the output palette to only have the alpha values I want but then the palette could end up with wasteful intra-alpha values that get reduced to the same alpha value in the end.
I was quite surprised that after running program for image optimization with defaults I ended up with 30% of smaller images and 70% of larger images, and with bigger total.

--skip-if-larger must be default setting
prepare_sort function in mediancut.c:
```      
       qsort(channels, 4, sizeof(channels[0]), comparevariance);
....
        // Only the first channel really matters. When trying median cut many times
        // with different histogram weights, I don't want sort randomness to influence outcome.
        tmp = ((unsigned int)(chans[channels[0].chan]*65535.0)<<16) |
                                        (unsigned int)((chans[channels[2].chan] + 
                                        chans[channels[1].chan]/2.0 + 
                                        chans[channels[3].chan]/4.0)*65535.0);
```

After qsort operation to channels,  the variance should be like this : channels array[0] >[1]>[2]>[3]. and from the comment it says " the first channel really matters."  I think the weight here is about the variance. so the weight should be like :array[0] >[1]>[2]>[3]. and the first <<16 could amply it's importance, and the least /4.0 makes it does not important.

So I think the code here should be like below, isn't it ?

```
        tmp = ((unsigned int)(chans[channels[0].chan]*65535.0)<<16) |
                                        (unsigned int)((chans[channels[1].chan] +  //[2]-->1 
                                        chans[channels[2].chan]/2.0 +   //[1]-->2
                                        chans[channels[3].chan]/4.0)*65535.0);
```

If not ,could you tell me why the code snippet is like original version?

thanks
Lu
ASAN reports this memory leak:
````
Direct leak of 41408 byte(s) in 1 object(s) allocated from:
    #0 0x7d6830 in malloc
    #1 0xccd03c in liq_aligned_malloc pngquant/libimagequant.c:472
    #2 0xccd913 in liq_image_use_low_memory pngquant/libimagequant.c:563
    #3 0xccd913 in liq_image_create_internal pngquant/libimagequant.c:606
    #4 0x1088ce3 in read_image pngquant.c:602
    #5 0x1088ce3 in pngquant_file pngquant.c:644
    #6 0x108a7d8 in pngquant pngquant.c:709
````
Instead of -fs8, I'd like to have the extension say which quality level it was saved at.
It would be pretty cool if there was some kind of `--dry-run` option which would print out the difference in filesize without altering the existing image.

This would allow you to see what the overall impact would be from different set of options/images before committing to writing anything to disk.