Ref: https://github.com/WebAssembly/spec/pull/814
Hello, thanks for the great project.

We are using it in a demo for a new rust based run-time for our product and needed to be able to do asynchronous host functions.

Use case being running multiple wasm modules on the same thread, when some/all have asynchronous io so we dont want to prevent other work from occurring.

I first tried to make it work with the unstable async/await rust api and wasn't happy with all the added workarounds that were required (mostly closures/traits) and we are currently using tokio 1.2 for our demo...so i just reworked some of the functions to return futures.

Currently missing good docs, tests, and a lot of finesse, to be clear I'm new to rust as a language so if this is just plain bad code i apologize ahead of time (but comments gladly accepted)

Some of the work in the interpreter loop seems like it could be done better and I would like a few things to be more compatible with the current api
- RuntimeArgs are passed as vecs instead of slices so they can be owned
- Rc around externals doesn't work with imports builder

Only other thought would be the use of the term x_async in the methods, with the upcoming 'async/await' these methods might be better called x_future so they dont get confused with the new rust async api.

Not sure if this would be of any use to the project, but would appreciate comments either way!

This is to allow building and running wasmi on constrained target such as microcontroller.
This requires the ability to build without std.

wasmi uses num_rational::BigRational for float conversion since 7fe6ef4e355faac97c66a691ea96e99eccb73e22 
BigRational needs the bigint or bigint-std but the no_std version does not work at the moment :
from num-rational release-notes:
> In the future, it may be possible to use the bigint feature with no_std

this way num-rational forces std since thes is no bigint for no_std
### WHAT THE PR DOES 
Replaces Vec-based LinearMemory management with a more efficient solution using VirtualAlloc and VirtualFree.

### EXPECTATIONS 
The new implementation using win32 APIs is expected to result in faster allocation and deallocation ops.

Here are some rough benchmarks on a Windows virtual machine.

|  Operations                                                                  | vec_memory (sec)  | VirtualAlloc (sec) |
|:--------------------------------------------------|:--------------------|:-----------------|
| Memory with 4GiB initial                                            | 359.029                   | 0.112                     | 
| Resizing memory to 4GiB and load at boundary     | 365.321                    | 0.119                     |
| Multiple incremental resizes and loads up to 3GiB | 23.746                      | 0.061                    |

<div align="center">
    <img width="500" alt="Screenshot 2019-10-05 at 9 28 28 PM" src="https://user-images.githubusercontent.com/20358651/66260517-936df880-e7b7-11e9-917d-d6a30459cd34.png">
</div>

### TODO
* [x] All tests pass on Windows
* [x] Manual tests pass 
    - [x] 65536 * 64KiB initial
    - [x] memory.grow 
    - [x] memory.size
    - [x] writing to uncommitted memory
    - [x] writing to unreserved memory
    - [x] writing to memory after release

### UNTESTED
* 32-bit Windows

### FIXES
[#200](https://github.com/paritytech/wasmi/issues/200)
The latest crates.io build no longer works with the core feature. num-traits is required by one of the dependent crates or by wasmi itself, and the std feature is not turned off, causing E0463 ("can't find crate for `std`"). This is how I'm including it:
```
wasmi = {version = "*", default-features=false, features=["core"]}
```

Long story short: It'd be really great if I could step through a WASM function's instructions one-by-one instead of having to execute the whole function start-to-finish.  This doesn't seem to be currently possible if I'm understanding the documentation and source code right.

Possible use-cases:

* Erlang-style preemptive concurrency (executing a module with a specified number of "reductions", after which execution forcibly pauses to allow other functions to run)
* Debuggers (e.g. to step through execution op-by-op and validate execution state)

I can think of a couple ways off the top of my head I'd go about implementing this:

* Pass in an optional maximum number of instructions to be executed (i.e. into `Interpreter.run_interpreter_loop` and `Interpreter.do_run_function` - and in turn into any functions calling it); if `Some(max)`, keep looping and decrementing until `max == 0`, then throw a resumable trap.
* Define entirely new functions that implement stepping (and possibly reimplement the existing functions in e.g. `impl Interpreter` to wrap these, if we want to avoid code duplication).

Would y'all be open to a PR implementing one or more of the above (or perhaps some entirely-different strategy)?  I realize the first option is most likely going to be a breaking change (unless perhaps combined with the second option).
At the moment, wasmi's linear memory is backed by `mmap` on "unix". However, on Windows it falls back to the vec implementation. 

We could use `VirtualAlloc`, an equivalent of `mmap` for our purposes, to implement the backend for linear memories on Windows.
Hello!

Is there a way to identify the module that is triggering a `wasmi::Externals::invoke_index` call?

I've run into an issue with a small PoC I'm working on, where I have multiple interacting modules, and some host functions. Some of the host functions require moving strings around, or other data that is located in the module's linear memory. Unfortunately, I haven't found a mechanism to determine which module's memory I should be accessing. (A small example would be 2 modules, A & B, where module A is calling `B.foo`, and `B.foo` is calling `env.print`.)

I figured if nothing exists currently, I can provide unique ImportResolvers for each module I load, that encodes the module's index and function index into the index returned by `resolve_func`, so I can extract it in `invoke_index`. But this feels kind of gross.

Any pointers would be greatly appreciated. :)


Really enjoying the wasmi btw, it has been a joy to work with so far. :)
It would be nice to have the ability to profile wasm execution.

I have a terrible hack in this branch (https://github.com/axic/wasmi/tree/profiling) â€“ didn't wanted to open a PR, but I would welcome any review and comments on deciding on a design or whether such a feature is wanted / would be accepted.

Can also open a PR if that is the best way forward.