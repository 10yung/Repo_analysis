Hi, I can't find the zip file for the vignette. Page does not exist? Would be useful for getting started. Thanks.

http://bio.math.berkeley.edu/sleuth/cuffdiff2/cuffdiff2_data_kallisto_results.zip
I am running kallisto quant in the latest insilicodb/kallisto docker container on Ubuntu 18.04. I downloaded a prebuilt index referenced in the kallisto manual. Every paired-end sample is killed. These same samples can be successfully pseudoaligned on linux server. My local machines have >>3.2G max RAM mentioned in Bray et al.

Error is a little cryptic. Any ideas?
```
root@073fc4250464:/DATA# kallisto quant -i mus_musculus/transcriptome.idx -n 6 -o FVB_liver_1 -b 100 FVB_liver_1.1.fastq.gz FVB_liver_1.2.fastq.gz

[quant] fragment length distribution will be estimated from the data
[index] k-mer length: 31
[index] number of targets: 118,489
[index] number of k-mers: 100,614,952
Killed
```
I am using sleuth to test for differential expression in viral transcripts (from RNA viruses, i.e. no isoforms) after assembling my RNAseq reads de novo. I'm curious whether it is best to map my raw reads to all of my de novo assembled contigs with Kallisto and use these estimated counts with sleuth, or if I can simply map my raw reads to the target viral transcript. My concern with the latter approach is that only mapping to a single transcript will throw off the shrinkage estimator. Am I correct in this assumption? Sorry if this is a super naive question! 
Hello,

The actual Sleuth package and plots within sleuth_live work/look great, but for some reason it appears that in the tables (when attempting to use sleuth_live), every single character from the Ensemble gene ID is being read into every single column, one character per column (screen shot below).
![Screen Shot 2019-11-12 at 12 23 21 PM](https://user-images.githubusercontent.com/57680365/68695528-35b49500-0549-11ea-9c08-0942906a11ce.png)

If I make gene tables or use plots in Sleuth itself (i.e., just use the various functions in R), everything works great, and moreover, if I download the table from sleuth_live, it looks correct (i.e., the ensemble ID is not split over the columns)...but for some reason it's reading into/appearing in sleuth_live in this weird way.

I have tried coercing the data/columns every which way in Sleuth, as well as saving sleuth object in different formats and reading back in to launch sleuth_live, but nothing seems to work...

I am using Mac OS, with latest versions of R and R studio. 

I may be barking up the wrong tree here, since this could be some kind of weird Shiny issue, but I just don't know enough/have enough experience with Shiny to figure it out...any help would be greatly appreciated,

Thank you.

Hello,

I get an error when using plot_ma() with a wald-test object.
The error message is (I've translated it from german if it is not completely correct):
`Error in FUN(X[[i]], ...) : Object 'mean_obs' not found` 

After assuring that I really gave a wald-test object as a parameter to the function I dug into the source code of the function and found that on line [664](https://github.com/pachterlab/sleuth/blob/24ca2859f13d1eac588d6dd2ac90bf860b4fe07e/R/plots.R#L664) of the plots.R sleuth_results() is called without `pval_aggregate=FALSE`. I assume the default value is TRUE. The function then returns a result set without the columns 'mean_obs' and 'b'. This seems to be the source of the error message. After manually doing the steps, but with `pval_aggregate=FALSE` it seems to work just fine.

best,
Nadine
Hi,

I am using Salmon (with -- numBootstraps 30), Wasabi and Sleuth for differential transcript level analysis. And I got this following error. I have checked issues #76 and #169 but I am not sure if this issue is related to those. Any ideas how to fix this? thanks.

so <- sleuth_prep(summarydata, extra_bootstrap_summary = TRUE)

reading in kallisto results
dropping unused factor levels
............
normalizing est_counts
55508 targets passed the filter
normalizing tpm
merging in metadata
summarizing bootstraps
.Error in bs_mat[, which_ids] : subscript out of bounds

> traceback()
5: transform_fun_counts(bs_mat[, which_ids])
4: process_bootstrap(i, samp_name, kal_path, num_transcripts, est_counts_sf[[i]], 
       read_bootstrap_tpm, ret$gene_mode, extra_bootstrap_summary, 
       target_id, mappings, which_ids, ret$gene_column, ret$transform_fun_counts, 
       ret$transform_fun_tpm, max_bootstrap)
3: FUN(X[[i]], ...)
2: apply_function(seq_along(kal_dirs), function(i) {
       samp_name <- sample_to_covariates$sample[i]
       kal_path <- get_kallisto_path(kal_dirs[i])
       process_bootstrap(i, samp_name, kal_path, num_transcripts, 
           est_counts_sf[[i]], read_bootstrap_tpm, ret$gene_mode, 
           extra_bootstrap_summary, target_id, mappings, which_ids, 
           ret$gene_column, ret$transform_fun_counts, ret$transform_fun_tpm, 
           max_bootstrap)
   })
1: sleuth_prep(summarydata, extra_bootstrap_summary = TRUE)

> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 16299)

[1] forcats_0.4.0     stringr_1.4.0     dplyr_0.8.3      
 [4] purrr_0.3.3       readr_1.3.1       tidyr_1.0.0      
 [7] tibble_2.1.3      ggplot2_3.2.1     tidyverse_1.2.1  
[10] annotables_0.1.91 sleuth_0.30.0    

Hi,

I'm trying to run sleuth_gene_table, but instead of "most_sig_transcript" and "list_of_transcripts", I got a column named "target_id" with one transcript name, and one column "all_target_ids" with only one transcript name too.

I looked at your code in sleuth.R and saw this:

```
sleuth_gene_table <- function(obj, test, test_type = 'lrt', which_model = 'full', which_group = 'ens_gene') {

  if (is.null(obj$target_mapping)) {
    stop("This sleuth object doesn't have added gene names.")
  }
  popped_gene_table <- sleuth_results(obj, test, test_type, which_model)

  popped_gene_table <- dplyr::arrange_(popped_gene_table, which_group, ~qval)
  popped_gene_table <- dplyr::group_by_(popped_gene_table, which_group)

  popped_gene_table <- dplyr::summarise_(popped_gene_table,
    target_id = ~target_id[1],
    pval = ~min(pval, na.rm  = TRUE),
    qval = ~min(qval, na.rm = TRUE),
    num_transcripts = ~n(),
    # all_target_ids = ~toString(target_id[1:length(target_id)])
    all_target_ids = ~paste0(target_id[1:length(target_id)], collapse = ',')
    )

  filter_empty <- nchar(popped_gene_table[[which_group]]) == 0 | # empty transcript name
    is.na(popped_gene_table[[which_group]]) | # empty gene name
    is.na(popped_gene_table$qval) # missing q-value
  filter_empty <- !filter_empty
  popped_gene_table <- popped_gene_table[filter_empty, ]

  adf(popped_gene_table)
}
```

Do you mean "target_id" now is "most_sig_transcript"? And do you have any idea it doesn't return me a full list of transcripts corresponding to a gene?
Thank you!

Hello.
I am now facing a problem when I library Sleuth in R.  The command is so <- sleuth_fit(so, ~condition, 'full'), and the problem is (4 NA values were found during variance shrinkage estimation due to mean observation values outside of the range used for the LOESS fit.
The LOESS fit will be repeated using exact computation of the fitted surface to extrapolate the missing values.These are the target ids with NA values: PPYR_00001-PA, PPYR_03317-PA, PPYR_05506-PA, PPYR_11147-PA).
And I don't konw what's the reason and how to deal with it, Could you please help me? 

 best wishes!

The dropbox link to the example Trapnell results , https://www.dropbox.com/s/eqx3jmylgns4wd3/Trapnell_results.zip?dl=1 , referenced in the walkthrough at https://pachterlab.github.io/sleuth_walkthroughs/trapnell/analysis.html  is a 404 not found.


It was discovered during testing that the `loess` function in the standard sleuth shrinkage estimation function (`sleuth:::shrink_df`) is set to use all available cores on the machine in the typical setup (OpenMP framework when installing R's internal Fortran and C++ code, no environment variables set). This is solved by setting the environment variable [`OMP_NUM_THREADS`](https://www.ibm.com/support/knowledgecenter/SSGH2K_13.1.0/com.ibm.xlc131.aix.doc/compiler_ref/ruomprun4.html), but most users will not know to do this.

I would advocate for having a mechanism to change this behavior from within sleuth, but it may not be kosher to change environment variables within R. An alternative would be to just provide a warning to the user (though this would come up every time in a standard run).

Issue is set up as an FYI to put in some solution before the next release