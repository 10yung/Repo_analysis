no matter stylize_image.sh or use python neural_style.py -....    it run in few seconds but  the output without no magic,   there are  some trigger arguements?
Is there an option to save every X number of variation? If there isnt, can you please implement it or provide a viable workaround? Thanks you so much
Would I have to segment the video first into the foreground and background and then run the script on each, and then mesh the two style videos together?

Ref: https://github.com/cysmith/neural-style-tf/issues/26

cc @cysmith @njordsir2
Hello,

when I run the code (ex: python neural_style.py --content_img  lion.jpg --content_img_dir image_input --style_imgs kandinsky.jpg --style_imgs_dir styles --device /gpu:0 --verbose --init_img_type style) and i display the value of **L_content** it always  0, I don't know why, any help please.
I am trying to stylizing video frames which are in video_input folder and used advanced bash command on your github for the same but i don't know how to generate flow files using make-opt-flow.sh
can you tell me the steps?
![Screenshot from 2019-10-17 14-47-11](https://user-images.githubusercontent.com/46345142/66997643-7ce96a80-f0f0-11e9-8bd8-2153b354136d.png)

i guess make-opt-flow.sh file is run using :
 ./make-opt-flow.sh "world_video_frames1/frame_{}.ppm" "video_output"
my frames are in format frame_0001.ppm
There is a script (tf_upgrade_v2 ) to convert "neural_style.py" from TensorFlow 1.X to TensorFlow 2.0 but the result script do not runs.





I've used [jcjohnson's implementation of Neural Style Transfer](https://github.com/jcjohnson/neural-style) before (and got great results), but wasn't satisfied with the memory usage and number of parameters.
With your implementation everything's running great and with lots of settings, but I'm wondering what settings I have to change to get the result as close to jcjohnson's one as possible.
Is there any way to get this working with ROCm?
I have both rocm and rocm-tensorflow installed, but when I try to do an image transfer I get this output. Is neural-style-tf not compatible with rocm? Or am I simply doing something wrong?
```
/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/samuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])

---- RENDERING SINGLE IMAGE ----

WARNING: Logging before flag parsing goes to stderr.
W0728 10:34:10.046397 140072776468288 deprecation_wrapper.py:119] From neural_style.py:550: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-28 10:34:10.046679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libhip_hcc.so
2019-07-28 10:34:10.088580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1651] Found device 0 with properties: 
name: Ellesmere [Radeon RX 470/480/570/570X/580/580X]
AMDGPU ISA: gfx803
memoryClockRate (GHz) 1.15
pciBusID 0000:10:00.0
2019-07-28 10:34:10.103296: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library librocblas.so
2019-07-28 10:34:10.103454: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libMIOpen.so'; dlerror: libMIOpen.so: cannot open shared object file: No such file or directory
2019-07-28 10:34:10.104424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library librocfft.so
2019-07-28 10:34:10.104641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library librocrand.so
2019-07-28 10:34:10.104649: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...
2019-07-28 10:34:10.104894: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-07-28 10:34:10.109805: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3693185000 Hz
2019-07-28 10:34:10.110222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a0b640 executing computations on platform Host. Devices:
2019-07-28 10:34:10.110237: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-28 10:34:10.111732: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4c005c0 executing computations on platform ROCM. Devices:
2019-07-28 10:34:10.111747: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Ellesmere [Radeon RX 470/480/570/570X/580/580X], AMDGPU ISA version: gfx803
2019-07-28 10:34:10.111997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 10:34:10.112005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      

BUILDING VGG-19 NETWORK
loading model weights...
constructing layers...
LAYER GROUP 1
--conv1_1 | shape=(1, 461, 400, 64) | weights_shape=(3, 3, 3, 64)
--relu1_1 | shape=(1, 461, 400, 64) | bias_shape=(64,)
--conv1_2 | shape=(1, 461, 400, 64) | weights_shape=(3, 3, 64, 64)
--relu1_2 | shape=(1, 461, 400, 64) | bias_shape=(64,)
W0728 10:34:12.987225 140072776468288 deprecation_wrapper.py:119] From neural_style.py:325: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

--pool1   | shape=(1, 231, 200, 64)
LAYER GROUP 2
--conv2_1 | shape=(1, 231, 200, 128) | weights_shape=(3, 3, 64, 128)
--relu2_1 | shape=(1, 231, 200, 128) | bias_shape=(128,)
--conv2_2 | shape=(1, 231, 200, 128) | weights_shape=(3, 3, 128, 128)
--relu2_2 | shape=(1, 231, 200, 128) | bias_shape=(128,)
--pool2   | shape=(1, 116, 100, 128)
LAYER GROUP 3
--conv3_1 | shape=(1, 116, 100, 256) | weights_shape=(3, 3, 128, 256)
--relu3_1 | shape=(1, 116, 100, 256) | bias_shape=(256,)
--conv3_2 | shape=(1, 116, 100, 256) | weights_shape=(3, 3, 256, 256)
--relu3_2 | shape=(1, 116, 100, 256) | bias_shape=(256,)
--conv3_3 | shape=(1, 116, 100, 256) | weights_shape=(3, 3, 256, 256)
--relu3_3 | shape=(1, 116, 100, 256) | bias_shape=(256,)
--conv3_4 | shape=(1, 116, 100, 256) | weights_shape=(3, 3, 256, 256)
--relu3_4 | shape=(1, 116, 100, 256) | bias_shape=(256,)
--pool3   | shape=(1, 58, 50, 256)
LAYER GROUP 4
--conv4_1 | shape=(1, 58, 50, 512) | weights_shape=(3, 3, 256, 512)
--relu4_1 | shape=(1, 58, 50, 512) | bias_shape=(512,)
--conv4_2 | shape=(1, 58, 50, 512) | weights_shape=(3, 3, 512, 512)
--relu4_2 | shape=(1, 58, 50, 512) | bias_shape=(512,)
--conv4_3 | shape=(1, 58, 50, 512) | weights_shape=(3, 3, 512, 512)
--relu4_3 | shape=(1, 58, 50, 512) | bias_shape=(512,)
--conv4_4 | shape=(1, 58, 50, 512) | weights_shape=(3, 3, 512, 512)
--relu4_4 | shape=(1, 58, 50, 512) | bias_shape=(512,)
--pool4   | shape=(1, 29, 25, 512)
LAYER GROUP 5
--conv5_1 | shape=(1, 29, 25, 512) | weights_shape=(3, 3, 512, 512)
--relu5_1 | shape=(1, 29, 25, 512) | bias_shape=(512,)
--conv5_2 | shape=(1, 29, 25, 512) | weights_shape=(3, 3, 512, 512)
--relu5_2 | shape=(1, 29, 25, 512) | bias_shape=(512,)
--conv5_3 | shape=(1, 29, 25, 512) | weights_shape=(3, 3, 512, 512)
--relu5_3 | shape=(1, 29, 25, 512) | bias_shape=(512,)
--conv5_4 | shape=(1, 29, 25, 512) | weights_shape=(3, 3, 512, 512)
--relu5_4 | shape=(1, 29, 25, 512) | bias_shape=(512,)
--pool5   | shape=(1, 15, 13, 512)
Traceback (most recent call last):
  File "/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1356, in _do_call
    return fn(*args)
  File "/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1339, in _run_fn
    self._extend_graph()
  File "/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1374, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Variable: {{node Variable}}was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.
         [[Variable]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "neural_style.py", line 858, in <module>
    main()
  File "neural_style.py", line 855, in main
    else: render_single_image()
  File "neural_style.py", line 824, in render_single_image
    stylize(content_img, style_imgs, init_img)
  File "neural_style.py", line 558, in stylize
    L_style = sum_style_losses(sess, net, style_imgs)
  File "neural_style.py", line 410, in sum_style_losses
    sess.run(net['input'].assign(img))
  File "/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 950, in run
    run_metadata_ptr)
  File "/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1350, in _do_run
    run_metadata)
  File "/home/samuel/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Variable: node Variable (defined at neural_style.py:243) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.
         [[Variable]]
```

build:
*windows 10
*anaconda
*python==3.6.8
*tensorflow-gpu==1.12.0
*scipy==1.3.0
*opencv-python==4.1.0.25
*nvidia 1050 Ti
*CUDA==9
*cudnn64_7



(nstyle2) D:\NEURAL_STYLE_TEST\neural-style-tf-master>python neural_style.py --content_img "face.jpg" --content_img_dir "image_input" --style_imgs "kandinsky.jpg" --style_imgs_dir "styles" --img_name "lion-kandinsky-output" --device "/gpu:0"

---- RENDERING SINGLE IMAGE ----

2019-07-25 21:51:01.105429: E tensorflow/core/common_runtime/session.cc:75] Not found: No session factory registered for the given session options: {target: "result" config: } Registered factories are {GRPC_SESSION, DIRECT_SESSION}.
Traceback (most recent call last):
  File "neural_style.py", line 865, in <module>
    main()
  File "neural_style.py", line 862, in main
    render_single_image()
  File "neural_style.py", line 829, in render_single_image
    stylize(content_img, style_imgs, init_img)
  File "neural_style.py", line 555, in stylize
    with tf.Session(args.tpu) as sess:
  File "D:\Conda\envs\nstyle2\lib\site-packages\tensorflow\python\client\session.py", line 1551, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File "D:\Conda\envs\nstyle2\lib\site-packages\tensorflow\python\client\session.py", line 676, in __init__
    self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)
tensorflow.python.framework.errors_impl.NotFoundError: No session factory registered for the given session options: {target: "result" config: } Registered factories are {GRPC_SESSION, DIRECT_SESSION}.