Bumps [lodash](https://github.com/lodash/lodash) from 4.17.11 to 4.17.15.
<details>
<summary>Commits</summary>

- [`ddfd9b1`](https://github.com/lodash/lodash/commit/ddfd9b11a0126db2302cb70ec9973b66baec0975) Bump to v4.17.15.
- [`b185fce`](https://github.com/lodash/lodash/commit/b185fcee26b2133bd071f4aaca14b455c2ed1008) Rebuild lodash and docs.
- [`be87d30`](https://github.com/lodash/lodash/commit/be87d303941222b97c482755afc0f4a77ce46c30) Bump to v4.17.14.
- [`a6fe6b1`](https://github.com/lodash/lodash/commit/a6fe6b1e174fd02b5e60eb2664405f4c1262c300) Rebuild lodash and docs.
- [`e371828`](https://github.com/lodash/lodash/commit/e37182845f16715a0d1c391c8662d83c55609cee) Bump to v4.17.13.
- [`357e899`](https://github.com/lodash/lodash/commit/357e899e685872b4af5403ecc4b2a928f961ae63) Rebuild lodash and docs.
- [`fd9a062`](https://github.com/lodash/lodash/commit/fd9a062d57646450b61f74029315abd4cc834b08) Bump to v4.17.12.
- [`e77d681`](https://github.com/lodash/lodash/commit/e77d68121ff00ba86b53eed5893d35adfe94c9dd) Rebuild lodash and docs.
- [`629d186`](https://github.com/lodash/lodash/commit/629d1865793182cd967196716f4beff223aa4a91) Update OpenJS references.
- [`2406eac`](https://github.com/lodash/lodash/commit/2406eac542b2a1282be8d812a6d8a45433ade80a) Fix minified build.
- Additional commits viewable in [compare view](https://github.com/lodash/lodash/compare/4.17.11...4.17.15)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.11&new-version=4.17.15)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/pikelet-lang/pikelet/network/alerts).

</details>
This switches to using `Fun` and `fun` in function types and values respectively, mirroring the syntax of record types and values. This avoides the following ambiguous syntax:

```
(x : A) -> B
```

This could either be parsed as:

- a dependent function type
- a non-dependent function with the input type annotated

I was attempting to get around this in [rust-nbe-for-mltt](https://github.com/brendanzab/rust-nbe-for-mltt) either by using parser combinators with ordered choice, or a hand-rolled recursive descent parser, but discovered that this would still require a significant amount of lookahead to resolve.

Im still open to discussing this further though! The new syntax has the downside of being less succinct, and I still find capitalised keywords a tad odd.

Closes #110
Removing patterns from the core language, in preparation for NbE.

Closes #128.
Our autobinding library, [Moniker](https://github.com/brendanzab/moniker) is currently not pulling its weight in terms of making it easy to understand the internals of Pikelet and will make supporting a high performance compiler heading into the future. In the words of @kleimkuhler:

> I know the times Ive explored enough into the codebase to get an idea of how you have implemented something, I usually end up at a point where a binding occurs and I lose track a little.

Also from conversations on Gitter, @boomshroom and others have struggled with grasping Moniker, so it's not an isolated issue! @jonsterling has also noted on Twitter that he is not really a fan of using ABTs (Abstract binding trees) in implementations:

> What I found is that unfortunately, it is difficult to see the right way to code a specific thing unless I have hand-coded the syntax. Some kind of ABT thing that abstracted over binding-sensitive traversals would be nice, but I concluded that the main point of ABTs, which was to abstract over binding itself (providing some interface with names, and automatically freshening etc., providing substitution) is actually harmful for implementations.

It's not only this - moniker is also standing in the way of using visitors in the compiler, and will cause us performance problems down the line as Pikelet codebases get larger. It also could make salsa/adapton style incrementalism harder.

## Requirements for name binding

The problems we will have to tackle when moving to a new variable binding scheme is:

- sound semantics
    - capture-avoiding substitution (`位x.e [e/x]` should not result in `位x.x`)
    - alpha equivalence (`位x.x` should be equivalent to `位y.y`)
    - reduce the chance of messing up variable binding when adding new features
- support existing and upcoming features
    - produce nice, stable, pretty names when pretty printing
    - recursive bindings (#46)
    - support reflection (like in Idris, Agda, F*, Lean)
- performance optimizations
    - allow for stable names across incremental compilations (see [adapton](http://adapton.org/) and [salsa](https://github.com/salsa-rs/salsa)) (#103)
    - reduce unnecessary tree traversals and variable shifts
    - allow for vistor-based fusion (#75) resulting in reduced allocations and as close-to single-pass compilation as we can get

## Possible solutions

We have a number of options open to us:

### Nominal binding

Use nominal binding, like in David Christiansen's [NBE tutorial](http://davidchristiansen.dk/tutorials/nbe/) - could be compatible with visitor-based futsion which might amortize some of the performance penalties. @pythonesque has expressed some concern over going down this route though, especially when it comes to recursive bindings.

### Graph libraries

Use [petgraph](https://github.com/bluss/petgraph), like in [Program Synthesis is Possible in Rust](http://fitzgeraldnick.com/2018/11/15/program-synthesis-is-possible-in-rust.html). Not sure how well this would support alpha equivalence though. This feels similar to the Scope Graph stuff from [A Theory of Name Resolution](https://eelcovisser.org/post/280/a-theory-of-name-resolution). I'm not sure if this has ever been applied to dependently typed languages though, and it is off-the beaten track in terms of the main-line of research.

### Locally Nameless

Continue to use a [locally nameless](https://www.chargueraud.org/research/2009/ln/main.pdf) approach as with moniker, but bring it into Pikelet. This might result in lots of traversals though, Lean has workarounds though. Also not compatible with visitors.

### Explicit substitutions with a fully representation

Apparently locally nameless has not been proven stable under substitution(?) for delayed substitutions, so we'd have to go with a fully nameless representation here, like in [autosubst](https://github.com/uds-psl/autosubst). This is well understood, but might be harder to get to work with visitors. The advantage would be that it would be quite close to what we would be doing in a theorem prover if we ever wanted to do a soundness proof of Pikelet.

### Use "semantic type checking"

This is what @jonsterling has advocated to me on Twitter:

> I base my stuff on an algorithm that I think comes from Thierry Coquand, called "semantic type checking". The main idea is as follows: 
>
> 1. Have a syntax based on De Bruijn indices. You don't even need to implement any operations on the syntax. This syntax will serve as the "unchecked" inputs to your judgments. (Like the `M` in `G !- M : A`.) 
> 2. Have a *semantic domain* based on De Bruijn _levels_. Interpret binders as closures; environments are sequences of values. 
> 3. In your bidirectional type checker, you have judgments like `G !- M <= A` and `G !- M => A`. in both cases, `G` and `A` are coming from the *semantic domain*, whereas `M` is syntax. In the mode-shift rule, you will check either definitional equivalence or subtyping (depending on the language), and this will be done structurally in the semantic domain -- this part has the structure of quotation from NbE, but let me observe that you actually don't ever need to quote anything. The algorithm has the same structure though.
>
> Now, let me point out the epic Power Move that we executed so far. 
>
> What was important was the yoga of having indices in the syntax and levels in the semantics. It means that the parts of your judgment that have wellformedness presuppositions, which we already agreed to draw from the semantic domain, can be *implicitly* weakened, so there is never any need anywhere in the algorithm to unleash a De Bruijn shift, or any kind of operation on syntax. The only thing you ever do to syntax is check the head constructor, and evaluate it into the domain afterward.

I will have to think about this more in order to get my head around it!

Here is an example type checker that uses the technique: https://github.com/jozefg/nbe-for-mltt/

### Improve Moniker's performance and documentation

I feel like it still would be handy to have a nice way of doing binding, but perhaps this would require more experimentation using other techniques first. I'm not sure though.
It'd be neat to have a top-level `tests` directory, with a bunch of Pikelet test files in there, and a custom test harness to check them.
Closes #109 

## TODO

- [x] Initialise docusaurus site
- [x] Move book documentation over to new site
- [x] Copy monthly Reddit updates to the blog
- [ ] Get KaTeX equations to render properly
- [ ] Styling cleanups
- [ ] Make homepage nice!
It would be neat to have a way to define Pikelet packages!

I'm also thinking it would also be neat to be able to define packages using Pikelet records!

```
record {
    name = "prelude";
    version = "0.1.0";
    copyright = "Apache-2.0";
    dependencies = [];
}
```

Having custom literals or something, perhaps like in [relit](https://github.com/cyrus-/relit) might make this nicer 

## TODO List

- [ ] add a `pikelet-package` crate
- [ ] ???
My brain is running round in circles trying to design this in a vacuum, so I thought I'd sketch out some high level thoughts on this stuff. There are a bunch of interlocking concerns, which makes it a little hard to figure out how to make any headway on it.

Currently our loader/driver API lives in the [`pikelet-driver`](https://github.com/pikelet-lang/pikelet/tree/master/crates/pikelet-driver), but it leaves a lot to be desired. Ultimately we want a Rust API that maintains some incrementally accumulated state, and has an API with functions that give a nice way to:

- parse source code
- type check ASTs
- evaluate expressions
- compile stuff
- load primitive functions
- query the current state
    - type at cursor position
    - jump to definition
    - complete at cursor
    - find all references
    - find all implementations
- editor actions
    - rename symbol
    - autoformat
    - case split
    - move hole into binding
    - search for hole substitutions
    - inline definition
    - extract definition

The Pikelet loader API would probably be consumed by the following clients:

- Pikelet CLI tools:
    - the compiler
    - the REPL
    - the language server
    - the package manager
- an application that embeds Pikelet as a scripting language
    - a rust application, eg. a game
    - via web assembly, eg. [sordina/pigraph](https://github.com/sordina/pigraph)
    - via a C ffi
- exotic editor/code visualisation tools
    - structured editing, for example:
        - http://hazel.org
        - http://www.cse.chalmers.se/~hallgren/Alfa/
    - bidirectional editors
        - http://ravichugh.github.io/sketch-n-sketch/

Import paths may be:

- relative to the current file
- global
    - from a built-in, eg. primitive functions
    - from a package dependency, or the standard library
    - from a dynamically loaded/compiled script

Paths need to be followed in topological order, forming a DAG. We will want to be able to listen to the file system for updates, and incrementally update as needed.

We probably want to avoid baking in a heavy compiler back-end (like LLVM) at this level, although I also wouldn't rule out including a JIT (like [CraneLift](https://github.com/CraneStation/cranelift)) for evaluating expressions at compile time.
Core languages like [PiSigma](https://www.andres-loeh.de/PiSigma/PiSigma.pdf) and [MiniTT](http://www.cse.chalmers.se/~bengt/papers/GKminiTT.pdf) have simple constructs for pattern matching, allowing for easier verification of type checking.

I'm not sure where this should be done, however. MLton seems to do it during its [defunctorise](http://mlton.org/Defunctorize) pass.

We can do it in a naive way for now, but there is an interesting paper showing how to do it well: [Compiling Pattern Matching to Good Decision Trees](http://moscova.inria.fr/~maranget/papers/ml05e-maranget.pdf). Do note that we have the added complication of perhaps wanting to add dependent patterns etc.

Compiling non-dependent pattern matching to case trees is described in chapter 5 of [The Implementation of Functional Programming Languages](https://www.microsoft.com/en-us/research/uploads/prod/1987/01/slpj-book-1987-r90.pdf). This is [what Sixten currently uses](https://gitter.im/pikelet-lang/Lobby?at=5c1b4b4b00ab9f271118b32f), "with some dependent pattern matching hacked in".

Compiling dependent pattern matching to case trees has been described by Jesper Cockx in:

- [Dependent pattern matching and proof-relevant unification](https://jesper.sikanda.be/files/thesis-final-digital.pdf)
- [Elaborating dependent (co)pattern matching](https://jesper.sikanda.be/files/elaborating-dependent-copattern-matching.pdf)
