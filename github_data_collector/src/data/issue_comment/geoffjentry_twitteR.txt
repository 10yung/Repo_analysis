Hello, I am a complete noob on anything that has to do with R Studio... I tried mirroring some YouTube videos to therefore allow me gather Twitter data for a project. 

I have created a Twitter app that has given me the respective API keys and have also downloaded the twitteR package on the software. Despite the efforts, when I try to run the line to set up the keys it gives me an error. 

Any ideas on how I can make it work? Thanks in advance!
(On the bottom right hand corner its a video that I am trying to follow) 

![help](https://user-images.githubusercontent.com/49489358/55891356-4e705d00-5bac-11e9-9a1f-c99eba7dbfb9.jpg)

i have collected some tweets around a few #hashtags through streaming API and would like to separate the file based on #hashtags. I am wondering if anyone has code for saving tweets file as a separate dataframe based on #hashtags and willing share? 
hey, I erased the size limit for dmSend() which is deprecated.

That function is still absent from rtweet I think, therefore my use of this repo :)
I have implemented a twitter application on my website based on OAuth.
But I got the error :  Whoa there!
There is no request token for this page. That’s the special key we need from applications asking to use your Twitter account. Please go back to the site or application that sent you here and try again; it was probably just a mistake.

–> i reseted the costumery key & secret key, but nothing. I also, reseted my token, but still nothing.
My code is as follows:
#connect all libraries
library(twitteR)
library(ROAuth)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)

#connect to API
download.file(url='https://curl.haxx.se/ca/cacert.pem', destfile='cacert.pem')
reqURL <- 'https://api.twitter.com/oauth/request_token'
accessURL <- 'https://api.twitter.com/oauth/access_token'
authURL <- 'https://api.twitter.com/oauth/authenticate'
consumerKey <- 'use29u2CLpp9Pb9aeALPBgKwf' #put the Consumer Key from Twitter Application
consumerSecret <- 'YRYvAExvschnj2fnPw4iIGC58xuk9xJyqDWG8zTTH3OBqDyuUY'  #put the Consumer Secret from Twitter Application
Cred <- OAuthFactory$new(consumerKey=consumerKey,
                         consumerSecret=consumerSecret,
                         requestURL=reqURL,
                         accessURL=accessURL,
                         authURL=authURL)
Cred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')) #There is URL in Console. You need to go to, get code and enter it in Console

save(Cred, file='twitter authentication.Rdata')
load('twitter authentication.Rdata') #Once you launched the code first time, you can start from this line in the future (libraries should be connected)
registerTwitterOAuth(Cred)

#the function for extracting and analyzing tweets
search <- function(searchterm)
{
  #extact tweets and create storage file
  
  list <- searchTwitter(searchterm, cainfo='cacert.pem', n=1500)
  df <- twListToDF(list)
  df <- df[, order(names(df))]
  df$created <- strftime(df$created, '%Y-%m-%d')
  if (file.exists(paste(searchterm, '_stack.csv'))==FALSE) write.csv(df, file=paste(searchterm, '_stack.csv'), row.names=F)
  
  #merge the last extraction with storage file and remove duplicates
  stack <- read.csv(file=paste(searchterm, '_stack.csv'))
  stack <- rbind(stack, df)
  stack <- subset(stack, !duplicated(stack$text))
  write.csv(stack, file=paste(searchterm, '_stack.csv'), row.names=F)
  
  #tweets evaluation function
  score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')
  {
    require(plyr)
    require(stringr)
    scores <- laply(sentences, function(sentence, pos.words, neg.words){
      sentence <- gsub('[[:punct:]]', "", sentence)
      sentence <- gsub('[[:cntrl:]]', "", sentence)
      sentence <- gsub('\\d+', "", sentence)
      sentence <- tolower(sentence)
      word.list <- str_split(sentence, '\\s+')
      words <- unlist(word.list)
      pos.matches <- match(words, pos.words)
      neg.matches <- match(words, neg.words)
      pos.matches <- !is.na(pos.matches)
      neg.matches <- !is.na(neg.matches)
      score <- sum(pos.matches) - sum(neg.matches)
      return(score)
    }, pos.words, neg.words, .progress=.progress)
    scores.df <- data.frame(score=scores, text=sentences)
    return(scores.df)
  }
  
  pos <- scan('C:/___________/positive-words.txt', what='character', comment.char=';') #folder with positive dictionary
  neg <- scan('C:/___________/negative-words.txt', what='character', comment.char=';') #folder with negative dictionary
  pos.words <- c(pos, 'upgrade')
  neg.words <- c(neg, 'wtf', 'wait', 'waiting', 'epicfail')
  
  Dataset <- stack
  Dataset$text <- as.factor(Dataset$text)
  scores <- score.sentiment(Dataset$text, pos.words, neg.words, .progress='text')
  write.csv(scores, file=paste(searchterm, '_scores.csv'), row.names=TRUE) #save evaluation results
  
  #total score calculation: positive / negative / neutral
  stat <- scores
  stat$created <- stack$created
  stat$created <- as.Date(stat$created)
  stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
  by.tweet <- group_by(stat, tweet, created)
  by.tweet <- summarise(by.tweet, number=n())
  write.csv(by.tweet, file=paste(searchterm, '_opin.csv'), row.names=TRUE)
  
  #chart
  ggplot(by.tweet, aes(created, number)) + geom_line(aes(group=tweet, color=tweet), size=2) +
    geom_point(aes(group=tweet, color=tweet), size=4) +
    theme(text = element_text(size=18), axis.text.x = element_text(angle=90, vjust=1)) +
    #stat_summary(fun.y = 'sum', fun.ymin='sum', fun.ymax='sum', colour = 'yellow', size=2, geom = 'line') +
    ggtitle(searchterm)
  
  ggsave(file=paste(searchterm, '_plot.jpeg'))
  
}

search("stockmarket") #enter keyword

Any one can help? ASAP please
I've written the following code:
`setup_twitter_oauth(consumer_key, consumer_secret)`

After this line, the following appears
`[1] "Using browser based authentication"`

Nothing happens after this so I don't know whether the authentication has taken place or not.
Hi,

I'm trying to get the friends for some users but encountered a weird problem:

<img width="749" alt="screen shot 2017-10-20 at 18 10 57" src="https://user-images.githubusercontent.com/25274600/31843679-6cd1ccde-b5c2-11e7-9a81-6d838ff8b6e0.png">

Basically it looks like the RetryOnRateLimit number is automatically reset after 15 or 16 trials, and I'm not sure why it cannot return the friend list after over 45 trials -- the Twitter api rate limit has a 15-min window but 45 trials equals about 45 minutes that definitely should move into the next window.

Using the same code I've successfully pulled friend list for some users, so I'm not sure if this problem is caused by some specific issues on this particular user. The user id is 171337448 for purpose to reproduce the issue.

Does anyone have any idea what's going on?

Hi!  I have this issue.  Whenever I download tweets statistics using lookupStatuses or making a loop for showStatus, favorite_count always seems to be 0, even though the tweet has been favorited many times, and it also seems that the number of favorites sums with retweets_count.  For example, a tweet had 3 RT's and 1 Fav, and when I download data it appears that this same tweet has had 4 RT's and 0 Fav.  I don't know if I'm doing something wrong, I've tried everything 
TweetData=as.data.frame(cbind(tweet = TweetText, date = TweetDate, lat = TweetLat, lon = TweetLon,
                         isretweet = isretweet, retweeted = retweeted, retweetcount = retweetcount, favoritecount = favoritecount, favorited = favorited))


When I try to download the tweets with the above-mentioned attributes it showing as "Rate limited .... blocking for a minute and retrying up to 113 times ..."

It's taking too long and I'm not sure how can I resolve this issue. 
install_github("geoffjentry/twitteR")

When I use the above command, I get following warning - 

Downloading GitHub repo geoffjentry/twitteR@master
from URL https://api.github.com/repos/geoffjentry/twitteR/zipball/master
Installing twitteR
trying URL 'https://cran.cnr.berkeley.edu/src/contrib/rjson_0.2.15.tar.gz'
Content type 'application/x-gzip' length 98905 bytes (96 KB)
==================================================
downloaded 96 KB

sh: 1: /bin/gtar: not found
sh: 1: /bin/gtar: not found
Error in system(cmd, intern = TRUE) : error in running command
In addition: Warning message:
In utils::untar(src, exdir = target, compressed = "gzip") :
  ‘/bin/gtar -xf '/tmp/Rtmp0cbchW/rjson_0.2.15.tar.gz' -C '/tmp/Rtmp0cbchW/devtools69303592ae94'’ returned error code 127


Can anyone help me on this?
Hello Guys, 

When I try to establish establish a connection to the Twitter API, I get an error:

> setup_twitter_oauth(API_key, API_secret, access_token, access_secret)
[1] "Using direct authentication"
Error in check_twitter_oauth() : OAuth authentication error:
This most likely means that you have incorrectly called setup_twitter_oauth()'

Please guide me on this. I have tried all the solutions offered in here, nothing worked for me.

The following is my R sessionInfo:

R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      
[5] LC_TIME=English_Australia.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.3.2

Thanks,

Farnaz