I am getting `scala.reflect.internal.Symbols$CyclicReference: illegal cyclic reference involving <refinement of scalikejdbc.QueryDSLFeature with scalikejdbc.SQLInterpolationFeature with scalikejdbc.SQLSyntaxSupportFeature>` when compiling with scala version 2.12.10. Compiling scala with 2.12.2 works fine. 
I have generated model classes with scalikejdbcGen. I tried regenerating the classes with the updated scala version, but it still produces the error. 

I am using Scalikejdbc version `3.4.0`.

Am I missing something here?
Scala team announced their great roadmap to Scala version 3. https://www.scala-lang.org/2019/12/18/road-to-scala-3.html

I believe it's about time to talk about the possibilities we can cater to the existing users in Scala 3 and beyond. I have the following topics here.

* Macros incompatibility issues in Scala 3
* My motivation towards Scala 3
* Decision time for Scala 3
* Continuing Scala 2 maintenance

## Macros incompatibility issues in Scala 3

According to https://www.scala-lang.org/2019/12/18/road-to-scala-3.html#what-about-macros

>What about macros?
>
>While Scala 3 can generally consume libraries built with Scala 2.13, this does not work for macros. Macro methods defined in 2.13 libraries cannot be used in Scala 3, because the Scala 3 compiler cannot execute the macro at compile-time.
>
>The macro system from Scala 2 is deeply tied to the internals of the Scala 2 compiler and cannot be migrated in a compatible fashion to Scala 3. Instead, Scala 3 ships with a new macro system. This means that macro definitions have to be re-written when migrating a codebase to Scala 3. Cross-building is possible by having separate source files for Scala 2 and 3 macro definitions.
>
>Libraries that define macros can be made available for both Scala 2.13 and Scala 3 by cross-compiling.

So, Scala 3's macro system is not compatible. I have to say it's challenging for this project. Particularly, [SQLInterpolationMacro](https://github.com/scalikejdbc/scalikejdbc/blob/3.4.0/scalikejdbc-interpolation-macro/src/main/scala/scalikejdbc/SQLInterpolationMacro.scala) is the most valuable piece of this library. I don't think people will still see the benefits of using ScalikeJDBC if without the feature.

In my understanding, offering the exact same functionalities in Scala 3 is almost impossible. If someone has ideas or alternatives that may be acceptable for many, I would love to hear those.

If we find some ways to continue supporting both Scala 2 and 3, I will continue this project for sure! Otherwise, I hate to say this but, if we cannot be with Scala 3 with good quality, we may have to announce that ScalikeJDBC won't support Scala 3 and will continue maintenance releases only for Scala 2.x.

## My motivation towards Scala 3

I'm a bit concerned about the number of reachable developers in the Scala 3 world. Generally speaking, the transition to something incompatible is always hard and it tends to take a long time.

To me, this project is a completely voluntary work. I have a full-time job, other open-source projects, and time with my family. My time is limited.

The possible outcomes will depend on my subjective observation. For now, I'm not so convinced to dedicate my time to Scala 3 related works yet. Depending on circumstances, I may consider looking for future maintainers even if this project continues.

## Decision time for Scala 3

I don't think many of Scala 2 users can move to Scala 3 so quickly. It may take a long time (or never happens to some). 

Even if this project cannot come up with something for Scala 3 at the moment, it doesn't mean we immediately have to make decisions like giving up supporting Scala 3.

## Continuing Scala 2 maintenance

The only certainty at this point is that ScalikeJDBC will continue Scala 2.x maintenance releases for a while. 

I don't guarantee concrete figures here but I will be committing to Scala 2 at least for a few years from now on.

## My ❤️ to the community

Thank you for reading this to the end. Although this project is facing difficulties, I hope the Scala community will have a bright future also with version 3.
I'm getting below exception when trying to get connection through google service account using google bigquery progress driver. 

`2019-12-11T10:43:33,327 ERROR SecureExceptionHandlerImpl,http-apr-8080-exec-7:116 - Cannot get a connection, pool error Could not create a validated object, cause: [TibcoSoftware][GoogleBigQuery JDBC Driver]The current database does not support transactions.`
I have the following stored procedure in psql mean to truncate the database (as I could not find support for that in scalikeJDBC):


```
CREATE OR REPLACE FUNCTION truncate_tables() RETURNS void AS $$
DECLARE
    statements CURSOR FOR
        SELECT tablename FROM pg_tables
        WHERE schemaname = 'public';
BEGIN
    FOR stmt IN statements LOOP
        EXECUTE 'TRUNCATE TABLE ' || quote_ident(stmt.tablename) || ' CASCADE;';
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

But I can't seem to find a way to use this with sql interpolation. I have tried different variations of:

```
  def truncateDatabase(implicit session: DBSession): Try[Unit] = {
    val sql = sqls"perform truncate_database()".update.apply()
  }
```

But I can't seem to find a way. Is this supported at all? Or Am I just blind? Thankful for all help!
Add double quotes for column name, otherwise may conflict with reserved keyword.

`org.postgresql.util.PSQLException: ERROR: syntax error at or near "limit"
org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2468) ~[postgresql-42.2.6.jar:42.2.6]
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2211) ~[postgresql-42.2.6.jar:42.2.6]
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:309) ~[postgresql-42.2.6.jar:42.2.6]
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:446) ~[postgresql-42.2.6.jar:42.2.6]
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:370) ~[postgresql-42.2.6.jar:42.2.6]
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:149) ~[postgresql-42.2.6.jar:42.2.6]
	at org.postgresql.jdbc.PgPreparedStatement.executeUpdate(PgPreparedStatement.java:124) ~[postgresql-42.2.6.jar:42.2.6]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-3.3.1.jar:?]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-3.3.1.jar:?]
	at scalikejdbc.DBConnectionAttributesWiredPreparedStatement.executeUpdate(DBConnectionAttributesWiredPreparedStatement.scala:80) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor.$anonfun$executeUpdate$1(StatementExecutor.scala:400) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23) ~[scala-library.jar:?]
	at scalikejdbc.StatementExecutor$NakedExecutor.apply(StatementExecutor.scala:22) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor$$anon$1.scalikejdbc$StatementExecutor$LoggingSQLAndTiming$$super$apply(StatementExecutor.scala:376) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor$LoggingSQLAndTiming.apply(StatementExecutor.scala:320) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor$LoggingSQLAndTiming.apply$(StatementExecutor.scala:306) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor$$anon$1.scalikejdbc$StatementExecutor$LoggingSQLIfFailed$$super$apply(StatementExecutor.scala:376) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor$LoggingSQLIfFailed.apply(StatementExecutor.scala:353) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor$LoggingSQLIfFailed.apply$(StatementExecutor.scala:352) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor$$anon$1.apply(StatementExecutor.scala:376) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.StatementExecutor.executeUpdate(StatementExecutor.scala:400) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession$.$anonfun$executeUpdate$1(DBSession.scala:798) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession$.$anonfun$executeUpdate$1$adapted(DBSession.scala:798) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession.$anonfun$updateWithFiltersInternal$1(DBSession.scala:537) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.LoanPattern.using(LoanPattern.scala:18) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.LoanPattern.using$(LoanPattern.scala:16) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.ActiveSession.using(DBSession.scala:837) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession.updateWithFiltersInternal(DBSession.scala:535) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession.updateWithFilters(DBSession.scala:477) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession.updateWithFilters$(DBSession.scala:466) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.ActiveSession.updateWithFilters(DBSession.scala:837) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession.updateAndReturnSpecifiedGeneratedKey(DBSession.scala:664) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSession.updateAndReturnSpecifiedGeneratedKey$(DBSession.scala:635) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.ActiveSession.updateAndReturnSpecifiedGeneratedKey(DBSession.scala:837) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSessionWrapper.$anonfun$updateAndReturnSpecifiedGeneratedKey$1(DBSessionWrapper.scala:92) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSessionWrapper.$anonfun$updateAndReturnSpecifiedGeneratedKey$1$adapted(DBSessionWrapper.scala:92) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSessionWrapper.$anonfun$withAttributesSwitchedDBSession$1(DBSessionWrapper.scala:34) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSessionAttributesSwitcher.withSwitchedDBSession(DBSessionAttributesSwitcher.scala:31) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSessionWrapper.withAttributesSwitchedDBSession(DBSessionWrapper.scala:33) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.DBSessionWrapper.updateAndReturnSpecifiedGeneratedKey(DBSessionWrapper.scala:92) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.SQLUpdateWithGeneratedKey.$anonfun$apply$20(SQL.scala:779) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.SQLUpdateWithGeneratedKey.$anonfun$apply$20$adapted(SQL.scala:779) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
	at scalikejdbc.SQLUpdateWithGeneratedKey.apply(SQL.scala:786) ~[scalikejdbc-core_2.12-3.3.5.jar:3.3.5]
`
```
spark-shell \
--jars /opt/jars/clickhouse4j-1.1.1.jar,\
/opt/jars/scalikejdbc_2.11-3.4.0.jar,\
/opt/jars/scalikejdbc-config_2.11-3.4.0.jar,\
/opt/jars/scalikejdbc-interpolation_2.11-3.4.0.jar
```


I got an unexpected error :
```
scala> import scalikejdbc._
<console>:23: error: Symbol 'type <none>.interpolation.Implicits' is missing from the classpath.
This symbol is required by 'trait scalikejdbc.SQLInterpolationFeature'.
Make sure that type Implicits is in your classpath and check for conflicting dependencies with `-Ylog-classpath`.
A full rebuild may help if 'SQLInterpolationFeature.class' was compiled against an incompatible version of <none>.interpolation.
       import scalikejdbc._
              ^
```
I am using IntelliJ's IDEA and see a message (screen shot below) that I should report a bug.

<img width="655" alt="Screen Shot 2019-09-27 at 10 25 22 AM" src="https://user-images.githubusercontent.com/7875594/65777012-30be9200-e111-11e9-9f98-1887dd192795.png">

This is from the file `SQL.scala` in scalikejdbc-core_2.13-3.3.5-sources.jar .  The stack trace is 

    map:382, SQL (scalikejdbc)
    findByFirstName:83, Person$ (com.bah.devops.common.entities)
    $anonfun$new$22:287, PersonTest (com.bah.devops.common.entities)
    apply:-1, 142103421 (com.bah.devops.common.entities.PersonTest$$Lambda$201)
    $anonfun$apply$1:132, TestSuite$TestFunAndConfigMap (org.scalatest.fixture)
    apply:-1, 1368128912 (org.scalatest.fixture.TestSuite$TestFunAndConfigMap$$Lambda$303)
    outcomeOf:85, OutcomeOf (org.scalatest)
    outcomeOf$:83, OutcomeOf (org.scalatest)
    outcomeOf:104, OutcomeOf$ (org.scalatest)
    apply:132, TestSuite$TestFunAndConfigMap (org.scalatest.fixture)
    apply:80, TestSuite$OneArgTest$$anon$1 (org.scalatest.fixture)
    withFixture:196, TestSuite (org.scalatest)
    withFixture$:195, TestSuite (org.scalatest)
    withFixture:226, FlatSpec (org.scalatest.fixture)
    $anonfun$withFixture$1:63, AutoRollback (scalikejdbc.scalatest)
    apply:-1, 903716563 (scalikejdbc.scalatest.AutoRollback$$Lambda$248)
    using:18, LoanPattern (scalikejdbc)
    using$:16, LoanPattern (scalikejdbc)
    using:21, PersonTest (com.bah.devops.common.entities)
    withFixture:57, AutoRollback (scalikejdbc.scalatest)
    withFixture$:56, AutoRollback (scalikejdbc.scalatest)
    withFixture:21, PersonTest (com.bah.devops.common.entities)
    invokeWithFixture$1:2127, FlatSpecLike (org.scalatest.fixture)
    $anonfun$runTest$1:2138, FlatSpecLike (org.scalatest.fixture)
    apply:-1, 1232703108 (org.scalatest.fixture.FlatSpecLike$$Lambda$236)
    runTestImpl:286, SuperEngine (org.scalatest)
    runTest:2138, FlatSpecLike (org.scalatest.fixture)
    runTest$:2119, FlatSpecLike (org.scalatest.fixture)
    runTest:226, FlatSpec (org.scalatest.fixture)
    $anonfun$runTests$1:2181, FlatSpecLike (org.scalatest.fixture)
    apply:-1, 62915435 (org.scalatest.fixture.FlatSpecLike$$Lambda$217)
    $anonfun$runTestsInBranch$1:393, SuperEngine (org.scalatest)
    apply:-1, 1425433685 (org.scalatest.SuperEngine$$Lambda$218)
    foreach:312, List (scala.collection.immutable)
    traverseSubNodes$1:381, SuperEngine (org.scalatest)
    runTestsInBranch:370, SuperEngine (org.scalatest)
    $anonfun$runTestsInBranch$1:407, SuperEngine (org.scalatest)
    apply:-1, 1425433685 (org.scalatest.SuperEngine$$Lambda$218)
    foreach:312, List (scala.collection.immutable)
    traverseSubNodes$1:381, SuperEngine (org.scalatest)
    runTestsInBranch:376, SuperEngine (org.scalatest)
    runTestsImpl:458, SuperEngine (org.scalatest)
    runTests:2181, FlatSpecLike (org.scalatest.fixture)
    runTests$:2180, FlatSpecLike (org.scalatest.fixture)
    runTests:226, FlatSpec (org.scalatest.fixture)
    run:1124, Suite (org.scalatest)
    run$:1106, Suite (org.scalatest)
    org$scalatest$fixture$FlatSpecLike$$super$run:226, FlatSpec (org.scalatest.fixture)
    $anonfun$run$1:2202, FlatSpecLike (org.scalatest.fixture)
    apply:-1, 1387671967 (org.scalatest.fixture.FlatSpecLike$$Lambda$210)
    runImpl:518, SuperEngine (org.scalatest)
    run:2202, FlatSpecLike (org.scalatest.fixture)
    run$:2201, FlatSpecLike (org.scalatest.fixture)
    run:226, FlatSpec (org.scalatest.fixture)
    run:99, JUnitRunner (org.scalatestplus.junit)
    run:137, JUnitCore (org.junit.runner)
    startRunnerWithArgs:68, JUnit4IdeaTestRunner (com.intellij.junit4)
    startRunnerWithArgs:47, IdeaTestRunner$Repeater (com.intellij.rt.execution.junit)
    prepareStreamsAndStart:242, JUnitStarter (com.intellij.rt.execution.junit)
    main:70, JUnitStarter (com.intellij.rt.execution.junit)

I am using these dependencies

       <dependency>
            <groupId>org.scalikejdbc</groupId>
            <artifactId>scalikejdbc-core_2.13</artifactId>
            <version>3.3.5</version>
        </dependency>
        <dependency>
            <groupId>org.scalikejdbc</groupId>
            <artifactId>scalikejdbc_2.13</artifactId>
            <version>3.3.5</version>
        </dependency>
        <dependency>
            <groupId>org.scalikejdbc</groupId>
            <artifactId>scalikejdbc-config_2.13</artifactId>
            <version>3.3.5</version>
        </dependency>
        <dependency>
            <groupId>org.scalikejdbc</groupId>
            <artifactId>scalikejdbc-streams_2.13</artifactId>
            <version>3.3.5</version>
        </dependency>
        <dependency>
            <groupId>org.scalikejdbc</groupId>
            <artifactId>scalikejdbc-test_2.13</artifactId>
            <version>3.3.5</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <version>42.2.8</version>
            <scope>test</scope>
        </dependency>

When I execute my test 

    it should "add person s and then find-by-firstname" in { implicit session: DBSession =>
      val person1: Person = Person.create(firstname1, lastname1, ssn1, email1, dob1).get
      val person3: Person = Person.create(firstname1, lastname3, ssn3, email3, dob3).get

      //    Person.findAll().foreach(println)

      val publisher1: DatabasePublisher[Person] = Person.findByFirstName(firstname1)

      Source.fromPublisher(publisher1).runForeach(println)


      val results1Future: Future[Seq[Person]] =
        Source.fromPublisher(publisher1).take(2).runWith(Sink.seq)

      val results1: Seq[Person] =
        Await.result(results1Future, Duration(5, TimeUnit.SECONDS))

      results1 should contain(person1)
      results1 should contain(person3)
    }

(when the commented out line is executed I see the correct values being printed).  I see these log messages

    2019-09-27 10:05:50,019 INFO  a.e.s.Slf4jLogger@[kka.actor.default-dispatcher-3] - Slf4jLogger started
    2019-09-27 10:05:50,798 INFO  s.s.DatabasePublisher@[kka.actor.default-dispatcher-3] - Database stream requested by subscriber: akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$$anon$1@27b94873 is ready
    2019-09-27 10:05:50,798 INFO  s.s.DatabasePublisher@[kka.actor.default-dispatcher-7] - Database stream requested by subscriber: akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$$anon$1@1935ae0e is ready
    2019-09-27 10:05:50,823 INFO  s.s.DatabaseSubscription@[kka.actor.default-dispatcher-4] - All data for subscriber: akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$$anon$1@1935ae0e has been sent
    2019-09-27 10:05:50,823 INFO  s.s.DatabaseSubscription@[kka.actor.default-dispatcher-6] - All data for subscriber: akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$$anon$1@27b94873 has been sent
    2019-09-27 10:05:50,826 INFO  s.s.DatabaseSubscription@[kka.actor.default-dispatcher-4] - Finished cleaning up database resources occupied for subscriber: akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$$anon$1@1935ae0e
    2019-09-27 10:05:50,826 INFO  s.s.DatabaseSubscription@[kka.actor.default-dispatcher-6] - Finished cleaning up database resources occupied for subscriber: akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$$anon$1@27b94873
    [ERROR] Tests run: 11, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.782 s <<< FAILURE! - in com.bah.devops.common.entities.PersonTest
    [ERROR] Person should add person s and then find-by-firstname(com.bah.devops.common.entities.PersonTest)  Time elapsed: 0.133 s  <<< ERROR!
    org.scalatest.exceptions.TestFailedException: Vector() did not contain element Person(14,FN1,LN1,000-00-0001,1@email.test.com,2019-01-02)
    	at com.bah.devops.common.entities.PersonTest.$anonfun$new$22(PersonTest.scala:298)
    	at com.bah.devops.common.entities.PersonTest.using(PersonTest.scala:21)
    	at com.bah.devops.common.entities.PersonTest.withFixture(PersonTest.scala:21)
Hello,

I have the following code:
```scala
  def store(jobInfoId: Long, struct: Array[Byte])(implicit session: DBSession = Checkpoint.autoSession): Unit = {
    DB localTx { implicit session =>
      withSQL {
        update(Checkpoint).set(
          column.endDt -> ZonedDateTime.now
        ).where.eq(column.jobInfoId, jobInfoId).and.gt(column.endDt,ZonedDateTime.now)
      }.update.apply()
      withSQL{
        insert.into(Checkpoint).namedValues(
          column.jobInfoId -> jobInfoId,
          column.struct -> struct
        )
      }.update().apply()
    }
  }
```

It does an update and than an insert, it works in PostgreSQL but in MariaDB just the latest statement works(the insert). If I remove the insert, the update start to work, also if I remove the ```    DB localTx { implicit session => ``` block works, but is not a single transaction as expected.   I'm doing something wrong ? 
https://github.com/scalikejdbc/scalikejdbc/pull/1033

https://github.com/scalikejdbc/scalikejdbc/blob/b312d3b4a35b043336cb31bb8a572111aa262f39/windows_test_filter.sbt#L2-L8
```
db.default.driver = "com.mysql.jdbc.Driver"
db.default.url = "jdbc:mysql://*****?characterEncoding=utf-8&useSSL=false"
db.default.user = *****
db.default.password = *****
db.default.poolInitialSize=1
db.default.poolMaxSize=3
db.default.connectionTimeoutMillis=1000
db.default.poolConnectionTimeoutMillis=1000
db.default.poolValidationQuery="select 1 as one"
```


The last packet successfully received from the server was 173,503,396 milliseconds ago. The last packet sent successfully to the server was 173,503,402 milliseconds ago. is longer than the server configured value of 'wait_timeout'. You should consider either expiring and/or testing connection validity before use in your application, increasing the server configured values for client timeouts, or using the Connector/J connection property 'autoReconnect=true' to avoid this problem. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:425) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:989) at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3743) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2506) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2677) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2545) at com.mysql.jdbc.ConnectionImpl.setReadOnlyInternal(ConnectionImpl.java:4984) at com.mysql.jdbc.ConnectionImpl.setReadOnly(ConnectionImpl.java:4977) at org.apache.commons.dbcp2.DelegatingConnection.setReadOnly(DelegatingConnection.java:550) at org.apache.commons.dbcp2.DelegatingConnection.setReadOnly(DelegatingConnection.java:550) at scalikejdbc.DBConnection$class.scalikejdbc$DBConnection$$setReadOnly(DBConnection.scala:93) at scalikejdbc.DBConnection$class.readOnlySession(DBConnection.scala:185) at scalikejdbc.NamedDB.readOnlySession(NamedDB.scala:17) at scalikejdbc.DBConnection$$anonfun$readOnly$1.apply(DBConnection.scala:201) at scalikejdbc.DBConnection$$anonfun$readOnly$1.apply(DBConnection.scala:201) at scalikejdbc.
