
Exception in thread "main" org.rocksdb.RocksDBException: Failed to create a directory: C:\code\weibocrawler\crawl\crawldb: ϵͳÕҲ»µ½ָ¶
	at org.rocksdb.RocksDB.open(Native Method)
	at org.rocksdb.RocksDB.open(RocksDB.java:231)
	at cn.edu.hfut.dmic.webcollector.plugin.rocks.RocksDBUtils.open(RocksDBUtils.java:94)
	at cn.edu.hfut.dmic.webcollector.plugin.rocks.RocksDBUtils.openCrawldbDatabase(RocksDBUtils.java:60)
	at cn.edu.hfut.dmic.webcollector.plugin.rocks.RocksDBManager.inject(RocksDBManager.java:87)
	at cn.edu.hfut.dmic.webcollector.crawldb.DBManager.inject(DBManager.java:66)
	at cn.edu.hfut.dmic.webcollector.crawler.Crawler.inject(Crawler.java:73)
	at cn.edu.hfut.dmic.webcollector.crawler.Crawler.start(Crawler.java:114)
	at cn.edu.hfut.dmic.webcollector.crawler.AutoParseCrawler.start(AutoParseCrawler.java:62)
	at cn.edu.hfut.dmic.webcollector.example.TutorialCrawler.main(TutorialCrawler.java:90)

依赖已加入：
```       <!-- https://mvnrepository.com/artifact/org.rocksdb/rocksdbjni -->
        <dependency>
            <groupId>org.rocksdb</groupId>
            <artifactId>rocksdbjni</artifactId>
            <version>5.17.2</version>
        </dependency>```
比如处理这个url http://www.suixian.gov.cn/news/News_View.asp?NewsID=20939 时会出现上述错误，我已经将其修改为非递归版本了，请问可以将代码提交上来吗？
代码没改 出错情况：
java.io.IOException: gzip finished without exhausting source
	at okio.GzipSource.read(GzipSource.java:100)
	at okio.Buffer.writeAll(Buffer.java:1053)
	at okio.RealBufferedSource.readByteArray(RealBufferedSource.java:108)
	at okhttp3.ResponseBody.bytes(ResponseBody.java:137)
	at cn.edu.hfut.dmic.webcollector.plugin.net.OkHttpRequester.getResponse(OkHttpRequester.java:114)
	at cn.edu.hfut.dmic.webcollector.crawler.AutoParseCrawler.execute(AutoParseCrawler.java:87)
	at cn.edu.hfut.dmic.webcollector.fetcher.Fetcher$FetcherThread.run(Fetcher.java:245)
亲问下分布式的版本在哪里下载？ 邮箱：737756485@qq.com   微信：xiaowenhuman
之前用2.52版本可以爬取，改成2.73-alpha版后，报错提示sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target。（是改用okhttps后导致的？？）
Bumps [c3p0](https://github.com/swaldman/c3p0) from 0.9.5.2 to 0.9.5.4.
<details>
<summary>Commits</summary>

- [`c61c00b`](https://github.com/swaldman/c3p0/commit/c61c00b1f7e3d6cf23501cd02b429474e4d22c73) Fix one missing word in docs...
- [`3aa4e5f`](https://github.com/swaldman/c3p0/commit/3aa4e5f2c57f231d609d9277770cb82d2e123bdd) Fix dangling \<tt> in docs.
- [`a93dc64`](https://github.com/swaldman/c3p0/commit/a93dc6497000efc821a2d40780231f98de11f3f9) Provide more accurate warning messages on XML parse failures.
- [`f38f276`](https://github.com/swaldman/c3p0/commit/f38f27635c384806c2a9d6500d80183d9f09d78b) Address more potential security concerns associated with the possibility of a...
- [`5a9b0eb`](https://github.com/swaldman/c3p0/commit/5a9b0ebc331e3a3e6f512cd551aed25c19f0beef) Address situation where a throwable during forceKillAcquires() leaves the for...
- [`042e90d`](https://github.com/swaldman/c3p0/commit/042e90d395d2c0504fce278ed27dea8772b9b7f8) Upgrade working version to 0.9.5.4
- [`c422ead`](https://github.com/swaldman/c3p0/commit/c422ead14de1ca530b72d5e0515880b7ed27df1e) Update source headers for v.0.9.5.3.
- [`9638cb5`](https://github.com/swaldman/c3p0/commit/9638cb5160aa58870cfbf8b4ee490344df052d9e) Update release notes and CHANGELOG.
- [`91430cf`](https://github.com/swaldman/c3p0/commit/91430cf3b5e0706b0d1883b3458d719a08c8e381) More doc fixes, modify testing resources to make it easy to check entity expa...
- [`5caea41`](https://github.com/swaldman/c3p0/commit/5caea41cb1e1463175644a071bca9216f3434206) Document availability of log4j2 logging, many thanks to user fireandfuel on G...
- Additional commits viewable in [compare view](https://github.com/swaldman/c3p0/compare/c3p0-0.9.5.2...c3p0-0.9.5.4)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.mchange:c3p0&package-manager=maven&previous-version=0.9.5.2&new-version=0.9.5.4)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/CrawlScript/WebCollector/network/alerts).

</details>
常常会遇到Too many connections的问题，使用的是spring的jdbctemplate。
请问不想修改mysql配置的情况下怎么减少爬虫的链接数量？
This pull request adds some unit test cases for class ContentExtractor, increasing 25% code coverage of the class.

![Screenshot from 2019-09-17 13-38-12](https://user-images.githubusercontent.com/25884341/65017327-ab88ef80-d950-11e9-8498-401032817a8e.png)


抛异常的日志级别能不能改warn或error.

超时也是info,线程被杀还是info,看无论什么都是info...没区分很无语啊。