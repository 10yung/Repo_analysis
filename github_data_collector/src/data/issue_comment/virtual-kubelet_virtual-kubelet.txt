Hi, [multicluster-scheduler](https://github.com/admiraltyio/multicluster-scheduler) was recently partially redesigned as a virtual-kubelet provider. I propose adding it to the list of available providers in the website and readme. @rbitia suggested I create this issue.

**Use Cases**

Given that multicluster-scheduler works at the pod level, it can be used as a general-purpose multi-cluster scheduler. Known adopters currently use it mostly for batch jobs, to utilize the resources of multiple clusters. Other use cases, like global services, require integrations with other tools, e.g., for ingress and cross-cluster networking.
This addresses the issue where certain (optional) APIs are unimplemented by the provider. 
### Environment summary

Provider (e.g. ACI, AWS Fargate): na

Version (e.g. 0.1, 0.2-beta): chart in master

K8s Master Info (e.g. AKS, ACS, Bare Metal, EKS): AKS Engine, v1.16

Install Method (e.g. Helm Chart): helm chart

### Issue Details

Kubernetes 1.16 deprecated `extensions/v1beta1` API for Deployment resource type. We are referencing that API in our chart and should test and bump to `apps/v1`

### Repo Steps

Install current helm chart on v1.16, receive error:
```
unable to build kubernetes objects from release manifest: unable to recognize "": no matches for kind "Deployment" in version "extensions/v1beta1"
```
I have tried to leverage work from @pires and @jieyu to have an up-to-date virtual kubelet provider for Apache Mesos. Work is available at https://github.com/criteo-forks/virtual-kubelet-mesos/ 
Is there a way to get a repository in the virtual-kubelet organization (like virtual-kubelet/mesos)?
I am new to virtual-kubelet and invesgating to use virtual-kubelet to implement a cluster federation. But in the project readme it's not recommend  to use virtual-kubelet to implement kubernetes federation "However, it should be noted that VK is explicitly not intended to be an alternative to Kubernetes federation". 

Like https://github.com/virtual-kubelet/virtual-kubelet/issues/32#issuecomment-352956441  kubernetes federation v1/v2 are too complicated for our use cases. In our use cases, we only use Deployment, Job and Pod, we want to implement a kubernetes provider, one virtual-kubelet per real kubernetes cluster, and join these virtual-kubelet to master kubernetes cluster, and user use master apiserver to submit deployment/job, the master cluster controller-manager will create pods for deployment, and scheduler will schedule pod onto node (virtual-kubelet + kubernetes provider), kubernetes provider will create pod in the real cluster and sync pod status between master cluster and virtual-kubelet cluster. 

I want to know if there some weakness or design decision makes virtual-kubelet not suitable for federate kubernetes clusters. Our use case is very simple, we only use Deployment, Job and Pod.

This adds the `DelayGC`, and `DisableGC` flags in order to change the behaviour of the VK to customize deletion behaviour in your own implementation of K8s controllers. 
---

### Environment summary

Provider: **ACI**

Version: **v1.13.1-vk-v0.9.0-1**

K8s Master Info: **AKS**

Install Method: **Azure Portal**

### Issue Details

I have setup a new AKS cluster with Virtual Kubelet enabled. Then I perform a load test with the help of JMeter on my pods. Together with a HPA I succesfully autoscale pods onto ACI instances. However, I have noted that the metrics server does not get any metrics from the ACI instance until after ~5 minutes. After this time the HPA is updated, and a new scale out is performed. If the load the increases during the ~5 minutes waiting time the HPA will not be updated until the next ~5 minutes threshold.

Is there any way I can affect this timing to be less than ~5 minutes, since I want to be even more resilient to burst of traffic for my pods?

### Repo Steps

1) Setup AKS cluster with Virtual Kubelet
2) Deploy example pod (See attached script for the ones I used)
3) Run JMeter and perform loadtest

Example output when no metrics is found on metrics-server is:
`1 reststorage.go:93] No metrics for pod default/php-apache-86ddb69d6f-9fjwj
`


**HPA.yaml**
```
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
  namespace: default
spec:
  maxReplicas: 100
  minReplicas: 1
  scaleTargetRef:
    apiVersion: extensions/v1beta1
    kind: Deployment
    name: php-apache
  targetCPUUtilizationPercentage: 5
```

**php-apache.yaml**
```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    run: php-apache
  name: php-apache
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      run: php-apache
  template:
    metadata:
      labels:
        run: php-apache
    spec:
      containers:
      - image: k8s.gcr.io/hpa-example
        imagePullPolicy: Always
        name: php-apache
        ports:
        - containerPort: 80
          protocol: TCP
        resources:
          limits:
            cpu: 200m
          requests:
            cpu: 200m
      nodeSelector:
         type: virtual-kubelet
      tolerations:
      - key: virtual-kubelet.io/provider
        operator: Equal
        value: azure
        effect: NoSchedule
```

**service.yaml**
```
apiVersion: v1
kind: Service
metadata:
  labels:
    run: php-apache
  name: php-apache
  namespace: default
spec:
  ports:
  - port: 80
    protocol: TCP \
    targetPort: 80
  selector:
    run: php-apache
  type: ClusterIP
```
Any ideas or feedback would be greatly appreciated. 
Thanks for an otherwise awesome product!

When we call CreatePod, if it fails too many times, we just silently drop it. Instead, we should mark the pod as failed, and give up.
---

### Environment summary

go version
go1.13 darwin/amd64

### Issue Details

Fail to build a new project depending on `github.com/virtual-kubelet/virtual-kubelet/log` with go1.13

After i set up the repo and try to build for the first to resolve all the dependencies with `go build`

![image](https://user-images.githubusercontent.com/42673593/65431568-45b6cf00-de4c-11e9-9b2c-4f1d41f0442a.png)

no error occurs if i run `go get github.com/virtual-kubelet/virtual-kubelet@v1.0.0` first to change the version of virtual kubelet to 1.0.0.

I think the following lines in go.mod is to blame:

https://github.com/virtual-kubelet/virtual-kubelet/blob/release-1.1/go.mod#L41-L42


### Repo Steps

Set up a new go repo and import `github.com/virtual-kubelet/virtual-kubelet/log`, do whatever and run `go mod init example.com/foo/bar && go build` with go1.13.

sample code looks like following

```go
package main

import (
	"context"

	"github.com/virtual-kubelet/virtual-kubelet/log"
)

func main() {
	log.G(context.TODO()).Info("i am main")
}

```