I suppose that you can add one very usefull option or improve eyes training with some tip i've found.

When your model is trained enough but eyes are gone wild do this:
1. Change dst and src folders names (src->dst, dst->src)
2. Train for 1-2k iterations
3. Change folder names back
4. Train for kinda 300 iterations and convert - you will see that the most eyes are fixed but the problem is - face will be more similar to dst. So i think you can use it to make some new algorytm 
В документации написаны какие-то команды, а куда их писать - не написано. В торрентах валяется большой архив с теми батниками. Скачал подходящий для OpenCL.
У меня видюха RX 580 на 8 GB от Gigabyte. 
Запускал батники поэтапно, но каждый раз на 4-м этапе, в 3-м шаге программа останавливалась и ничего не делала. В "avatar only" всё прошло успешно, но лица не выделились вообще.
i find that the trained model hard to tranform skin color and using much time to eliminate the hard face boundary because their different skin color and light. so the convert result is also hard to get very really face and u can find the fake face traces.
Is possible that using the GAN model to tranform the dst face (skin, light ..) to the converted face, automatically eliminateing the converting fake traces and making the fake face with other areas integrated ?
Hi there
If i wanna load my "old" model files with the new Cuda Version (DeepFaceLab_CUDA_build_01_11_2020) i got some errors:

`Loading model...
Press enter in 2 seconds to override model settings.Using TensorFlow backend.
Error: Dimension 0 in both shapes must be equal, but are 1 and 3. Shapes are [1,1,128,3] and [3,128,5,5]. for 'Assign_68' (op: 'Assign') with input shapes: [1,1,128,3], [3,128,5,5].
Traceback (most recent call last):
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\framework\ops.py", line 1628, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 1 and 3. Shapes are [1,1,128,3] and [3,128,5,5]. for 'Assign_68' (op: 'Assign') with input shapes: [1,1,128,3], [3,128,5,5].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "N:\xy\_internal\DeepFaceLab\mainscripts\Trainer.py", line 52, in trainerThread
    device_args=device_args)
  File "N:\xy\_internal\DeepFaceLab\models\ModelBase.py", line 146, in __init__
    self.onInitialize()
  File "N:\xy\_internal\DeepFaceLab\models\Model_SAEHD\Model.py", line 432, in onInitialize
    loaded, not_loaded = self.load_weights_safe(not_loaded)
  File "N:\xy\_internal\DeepFaceLab\models\ModelBase.py", line 424, in load_weights_safe
    model.load_weights(filename)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\keras\engine\network.py", line 1166, in load_weights
    f, self.layers, reshape=reshape)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\keras\engine\saving.py", line 1058, in load_weights_from_hdf5_group
    K.batch_set_value(weight_value_tuples)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\keras\backend\tensorflow_backend.py", line 2465, in batch_set_value
    assign_op = x.assign(assign_placeholder)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\ops\variables.py", line 1718, in assign
    name=name)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\ops\state_ops.py", line 221, in assign
    validate_shape=validate_shape)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\ops\gen_state_ops.py", line 61, in assign
    use_locking=use_locking, name=name)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\util\deprecation.py", line 488, in new_func
    return func(*args, **kwargs)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\framework\ops.py", line 3274, in create_op
    op_def=op_def)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\framework\ops.py", line 1792, in __init__
    control_input_ops)
  File "N:\xy\_internal\python-3.6.8\lib\site-packages\tensorflow\python\framework\ops.py", line 1631, in _create_c_op
    raise ValueError(str(e))
ValueError: Dimension 0 in both shapes must be equal, but are 1 and 3. Shapes are [1,1,128,3] and [3,128,5,5]. for 'Assign_68' (op: 'Assign') with input shapes: [1,1,128,3], [3,128,5,5].`

Previous i used DeepFaceLab_CUDA_10.1_AVX_build_12_26_2019
How can i fix that? and please dont say me that i have to retrain :/
Thansk for u work. i have same problems in your work.
the option :"Enable 'true face' training, Is the samples without flip or warp translating when training ? why training the face with the extra background, not using the only faces(masked face)? 
Currently using DFL 10.1 for NVidia with 1080ti (11gb) on windows plaftorm, and achieving some nice results, using trainSAEHD and convertSAEHD to avoid out_of_memory errors

Is there a benefit (speed/accuracy) in moving to a later build AND/or the Open GL version?
THIS IS NOT TECH SUPPORT FOR NEWBIE FAKERS
POST ONLY ISSUES RELATED TO BUGS OR CODE

## Expected behavior

I want to run the program with my GPU, i bought a new graphic card for this, but it is not using GPU while training.

## Actual behavior
firstly, before i write here, i searched every topics.

When i run the Train SAEHD, it first says this error (photo 1):
![1](https://user-images.githubusercontent.com/59828194/72260992-055ea500-3625-11ea-81e2-9b4754d44a04.jpg)

tensorflow/stream_executor/cuda/cuda_driver.cc806] failed to allocate 2.43 G (2608267264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory

and i get rid of this error doing these-unfortunately it just helps the erase the error, nothing more.(before that photo, train was also not work, reducing batch size helped to work but..):
https://github.com/iperov/DeepFaceLab/issues/369#issuecomment-524539937

> try batch size of 2, dims 128
----
> Try lowering the batch size, i.e start from 4 and double until you get the error.
> 
> If this doesn't work, changing line 144 in `nnlib.py` to `config.gpu_options.allow_growth = False` seemed to stop this error appearing for me."

Train model is working but it's not using my GPU now. It uses RAM and CPU. Is it should be like this or how can i work my GPU? This is how i train now;
![2](https://user-images.githubusercontent.com/59828194/72261394-ca10a600-3625-11ea-9fda-45891aaa231a.png)

IT uses shared GPU Ram but not processor. Also not actual G-RAM it uses from my normal RAM.

## Other relevant information
Batch size=6 
 **Operating system and version:** 
AMD Ryzen 3600 processor
Nvidia RTX 2060 6GB Graphic card
DFL build is the latest one (10.1)
Windows 10 64-bit, (i formatted several days ago, is it possible any other driver or program missing?)
**Python version:**
Python 3.8 64 bit.




THIS IS NOT TECH SUPPORT FOR NEWBIE FAKERS
POST ONLY ISSUES RELATED TO BUGS OR CODE

## Behavior

When Training:

This seems to be somewhat random, but I get a "GPU Sync Failed" error.

Booting up training seems to allow things to go forward for anywhere between 10 minutes to 3 hours. Sometimes it works continually, but this is somewhat rare. Restarting my computer seems to allow a higher chance of success for a period.

![image](https://user-images.githubusercontent.com/57318447/72253199-0238ca00-35cf-11ea-84ac-a90a7f7cc733.png)


## Steps to reproduce

I'm not sure how to reproduce it, since it seems random. However, it does appear to increase in likelihood with each instance that I stop training and then start it up at some point before restarting my computer.

## Other relevant information
-Operating system: Windows 10 Pro
-Python version: Prebuilt Windows Binary
Hello,
now there is only the "M" key to apply the current config to only the previous frame. In my opinion would be very useful a key like the "/" key to apply the current config to ALL previous frames
Windows 10 64bit
Graphics card is a Radeon VII
Downloaded latest OpenCL version and when I try to train it hangs at this:

`INFO:plaidml:Opening device "opencl_amd_gfx906.0"`

EDIT 1: I downgraded to older version of DFL (11/14/19) and and it works fine now. So it seems the latest version of DFL OpenCL is still the culprit...