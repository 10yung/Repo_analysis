Hi all,

I tried this package to extract text from a simple picture, however, the results are not as good as expected, here is my pic with 300dpi:
![path_ziji_300](https://user-images.githubusercontent.com/19953005/62859279-40377680-bd2f-11e9-8f82-310ddfb2f746.jpg)

```{r}
library(tesseract)
eng <- tesseract("eng")
results2 <- tesseract::ocr_data("path_ziji_600.png", engine = eng)
results2
# A tibble: 18 x 3
   word            confidence bbox               
   <chr>                <dbl> <chr>              
 1 Hippo                 95.1 205,207,572,344    
 2 pathway               96.1 614,207,1122,344   
 3 DCHS1/2               88.9 468,515,919,631    
 4 FAT                   16.7 1237,522,1427,601  
 5 1/2/3/4               16.7 1426,515,1762,631  
 6 TAOK                  18.4 2037,514,2314,630  
 7 1/2/3                 18.4 2313,514,2581,630  
 8 SAV1                  82.5 1061,1156,1316,1237
 9 ||                    83.3 1345,1132,1525,1276
10 STK3/4                92.3 1573,1154,1933,1237
11 --                   55.0 2098,1288,2286,1344
12 CRB1/2                78.2 485,2040,860,2189  
13 an                    33.0 1795,1975,2077,2200
14 TEAD2                 91.9 1311,2624,1671,2704
15 Cell                  96.2 703,2995,891,3078  
16 proliferation         95.7 922,2995,1507,3101 
17 and                   96.5 1537,2995,1702,3078
18 differentiation       96.0 1734,2995,2398,3078
```

Actually, it does not recognize every text in this picture! A little strange (because this pic is not complex at all), anyone could give me some suggestions about this?

Thanks a lot^_^


Bests,
Shisheng
 
```{r}
> sessionInfo()
R version 3.6.0 (2019-04-26)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936  LC_CTYPE=Chinese (Simplified)_People's Republic of China.936   
[3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936 LC_NUMERIC=C                                                   
[5] LC_TIME=Chinese (Simplified)_People's Republic of China.936    

attached base packages:
[1] parallel  stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] magick_2.1           tesseract_4.1        DO.db_2.9            AnnotationDbi_1.46.0 IRanges_2.18.1       S4Vectors_0.22.0    
[7] Biobase_2.44.0       BiocGenerics_0.30.0
```
See upstream comment: https://github.com/tesseract-ocr/tesseract/issues/1670#issuecomment-515324015
Hi, 

I'm experiencing an issue using page segmentation mode on 1 (auto+osd), where the following call results in an error message: 

`engine <- tesseract("osd+eng", options = list(tessedit_pageseg_mode = 1))`
`text1 <- ocr("http://jeroen.github.io/images/testocr.png", engine = engine)`

> Failed loading language 'osd'
> Tesseract couldn't load any languages!
> Warning: Auto orientation and script detection requested, but osd language failed to load

As suggested in some related posts, I set TESSDATA_PREFIX to the tessdata directory. This does not seem to resolve the issue, even though the .traineddata files are located in this directory. 

`Sys.setenv(TESSDATA_PREFIX="/Users/name/Library/Application Support/tesseract4/tessdata")`

Setting the language argument to "osd" instead of "osd+eng" will actually prevent the error message, however, the quality of the text recognition will suffer:

> 丁h5s 5৪ а ന്ന or ｵ2 podnr reod ro test the
ocr соde аnd see ㅠ 耽 ννorкs оп аи types
or 佩е টিоrmat

Any ideas how to solve this? 
Thank you very much for your help! 

This is related to #8 and #39 (or more accurately, the underlying ideas within them).

With the upstream issue that the whitelist and blacklist are not implemented in tesseract 4 (discussed in #39), it is difficult to extract all-numeric values.  More generally, I have some text that follows very rigid formatting with columns of person identifiers (that are a mix of alpha-numeric and dash characters) and floating point numbers.  The person identifiers will be hard to limit the values for, but the floating point numbers are easy as they come from the set 0-9, ".", and "-".

Is it possible within the `ocr_data()` function to get a vector of all characters that matched with >x confidence and the confidence values of those characters (where x is input by the user)?

That way, I could manually implement whitelist or blacklist functionality.
Hi,
When i loop over my PDFs and use OCR_Data, after a while (about 2 hours) it produces the following error:

TIFFReadEncodedStrip Error
---------------------------
Read error at scanline 0; got 0 bytes, expected 9918
---------------------------
OK   


It is a popup in windows - it is NOT an R error. After hitting "OK" it doesn't go away and the same popup occurs. Thus it completely stops my script.

I did see another issue raised from using OCR_Data about memory leak - perhaps this is related?

Thanks
Oneiricer
Users installing on Linux machines may see:
```
Error opening data file /usr/share/tesseract-ocr/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
```
This is easily solved by first installing `tesseract-ocr` and related language packs (via apt-get or whatever). 
Hi all,

I'm working in recognize some pdf image  that haven't an excellent quality and I want to perform a better OCR using the third dictionary, called user-words, but I don't know wich is the procedure to do it.

I search it on the web but didn't find anything, could you help me?

Thank you very much, have a nice day
Thanks for a great package @jeroen! I have two suggestions regarding the vignette.

# Vignette access

To read the vignette one either has to go read the CRAN version or to install the package.  Would you be interested in a PR making a `pkgdown` website for `tesseract`? This way the vignette would be rendered.

# hOCR

I looked at the posts on rOpenSci blog via https://ropensci.org/tags/tesseract/ in particular https://ropensci.org/technotes/2018/02/14/tesseract-18/ -> should this mention of hOCR be added to the vignette? I see it is already mentioned very briefly in the README.
Hi, I was wondering if anyone can help me figure out how to use the user_patterns_suffix option when setting up the engine? I'd like to parse PDFs for a specific code that has a certain pattern, and have been trying to do something like what this guide does: http://www.philhack.com/ocr/.

What I've tried:
I tried setting up a file in my tessdata folder called eng.user-patterns that has my patterns, one pattern per line. I then tried doing `tes <- tesseract(options =  list(user_patterns_suffix = "user-patterns"))` but I see no differences in the output. I also tried disabling all other dawg's by using 
`list(load_system_dawg="F",load_freq_dawg="F",load_punc_dawg="F",load_number_dawg="F",load_unambig_dawg="F",load_bigram_dawg="F",load_fixed_length_dawgs="F")`, however again the results are the same. 

Any help much appreciated.
Nas
See https://github.com/tesseract-ocr/tesseract/wiki/APIExample