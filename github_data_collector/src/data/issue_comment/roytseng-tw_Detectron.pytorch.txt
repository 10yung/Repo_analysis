Hi,
I want to convert this model to tensorrt. If someone has done please share guidance. It would be great help. In addition to this I am using torch2trt and facing issue while building cuda engine. Its throws error. 
Unused input.
Kindly let me know the input and output names.

Thanks 

I followed your guidance and met the problem below when I run the code :
"python /home/liujianguo/jiguo/mask-rcnn.pytorch/tools/train_net_step.py --dataset coco2017 --cfg /home/liujianguo/jiguo/mask-rcnn.pytorch/configs/baselines/e2e_mask_rcnn_R-50-C4_1x.yaml --bs 2 --iter_size 1"

Traceback (most recent call last):
  File "/home/liujianguo/jiguo/mask-rcnn.pytorch/tools/train_net_step.py", line 454, in <module>
    main()
  File "/home/liujianguo/jiguo/mask-rcnn.pytorch/tools/train_net_step.py", line 256, in main
    maskRCNN = Generalized_RCNN()
  File "/home/liujianguo/jiguo/mask-rcnn.pytorch/lib/modeling/model_builder.py", line 124, in __init__
    self._init_modules()
  File "/home/liujianguo/jiguo/mask-rcnn.pytorch/lib/modeling/model_builder.py", line 128, in _init_modules
    resnet_utils.load_pretrained_imagenet_weights(self)
  File "/home/liujianguo/jiguo/mask-rcnn.pytorch/lib/utils/resnet_weights_helper.py", line 31, in load_pretrained_imagenet_weights
    pretrianed_state_dict = convert_state_dict(torch.load(weights_file))
  File "/home/liujianguo/anaconda3/envs/PANet/lib/python3.6/site-packages/torch/serialization.py", line 303, in load
    return _load(f, map_location, pickle_module)
  File "/home/liujianguo/anaconda3/envs/PANet/lib/python3.6/site-packages/torch/serialization.py", line 459, in _load
    magic_number = pickle_module.load(f)
_pickle.UnpicklingError: invalid load key, '\x0a'.

my operating environment:
cuda 8.0
cudnn 7.3.0
pytorch0.4.0
python3.6
my GPU is geforce gtx 1070ti
I have no idea how to deal with it and really hope you can give me some suggestions.
I would appreciate it if you could reply to me .Best wishes for you.
updated spelling of the default CUDA_PATH in readme
Hi, `torchvision 0.3` has been released and supports ops such as `nms`, `roialign`. It is now possible to support PyTorch 1.0.
Is it possible to run inference on CPU? In the forward function of the roi_Xconv1fc_gn_head_panet in fast_rcnn_heads.py, it relies on the gpu version of the roi align. How can this issue be solved?
This issue is somewhat related to #86. I understand that `TRAIN.SCALES` parameter allows us to show the scaled version of the image to the model. My question is will this also work in the case where object sizes vary but image size is constant?

In my case, the size of images is mostly consistent (1024 x 1024). But the sizes of my objects of interest can vary from 8x8 pixels to 128 x 128 pixels. Should I change the `FPN.RPN_ANCHOR_START_SIZE` to start from 8 or should I modify the set of `TRAIN.SCALES` or perhaps both?
add  compiler version note according to https://pytorch.org/tutorials/advanced/cpp_extension.html#using-your-extension
* fix typos on strings 75 & 277
* syntax issue on string 144
I need to test new backbone of faster-rcnn, it it a NAS model. 
Can you tell me how do I add new backone?
## PLEASE FOLLOW THESE INSTRUCTIONS BEFORE POSTING
1. **Read the README.md thoroughly ! README.md is not a decoration.**
2. Please search existing *open and closed* issues in case your issue has already been reported
3. Please try to debug the issue in case you can solve it on your own before posting

## After following steps above and agreeing to provide the detailed information requested below, you may continue with posting your issue
(**Delete this line and the text above it.**)

### Expected results

What did you expect to see?

### Actual results

What did you observe instead?

### Detailed steps to reproduce

E.g.:

```
The command that you ran
```

### System information

* Operating system: ?
* CUDA version: ?
* cuDNN version: ?
* GPU models (for all devices if they are not all the same): ?
* python version: ?
* pytorch version: ?
* Anything else that seems relevant: ?
