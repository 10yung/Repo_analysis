Hi, i am using the keras API and would like to initialize a layer at the first iteration of the first epoch and then update this layer by one of the output layer (output2) . something like this:
 
model <- function (...) {
inputs1 <- layer_input(shape = input_shape)

if (iteration==1 & epoch==1) {output2=inputs1}

inputs2=layer_concatenate(inputs = list(inputs1,output2), axis = 3)
....
....
output2=layer_conv_2d(up1, filters = 2, kernel_size = c(1, 1),  activation = "sigmoid")
....
}

Any idea on how to do this ? 
Thank you very much !

Hi all,

New to github! I'm currently working on a side project using the neural style transfer code with Keras. Just encountered an error when i got to the line referenced below: 

https://github.com/rstudio/keras/blob/687d341065fab82d585b8e7d642dea0bce106337/vignettes/examples/neural_style_transfer.R#L168-L174

Here is the log of the detailed traceback: 
```
Detailed traceback: 
  File "C:\Users\mts\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow_core\python\keras\backend.py", line 3065, in batch_flatten
    x = array_ops.reshape(x, array_ops.stack([-1, prod(shape(x)[1:])]))
  File "C:\Users\mts\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow_core\python\util\dispatch.py", line 180, in wrapper
    return target(*args, **kwargs)
  File "C:\Users\mts\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow_core\python\ops\array_ops.py", line 1165, in stack
    return gen_array_ops.pack(values, axis=axis, name=name)
  File "C:\Users\mts\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow_core\python\ops\gen_array_ops.py", line 6303, in pack
    "Pack", values=values, axis=axis, name=name)
  File "C:\Users\mts\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow_core\p
Called from: py_call_impl(callable, dots$args, dots$keywords)
```

I'm still a beginner in neural networks so I haven't delved much into the specifics of the code and what each package (i.e. keras, R6, purrr, tensorflow, etc.) does. In either case, any help would be much appreciated! 

AG


I'm using the code for the Keras R tutorial to attempt to classify a sample set of tweets. The data structure is as follows: 
```
Tweet_Text               Tag1    Tag 2
some tweet text          2          5
different tweet text     3          6
```

I'm just using the first set of tags for this classification. When I attempt to adapt the text vectorization layer, I get the following error: 

```
> text_vectorization %>% 
+   adapt(coded_clean$clean_text)
Error in py_call_impl(callable, dots$args, dots$keywords) : 
  ValueError: adapt() requires a Dataset or a Numpy array as input, got <class 'list'>

Detailed traceback: 
  File "/Users/mboogie/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/preprocessing/text_vectorization.py", line 401, in adapt
    type(data)))
```

Here is my session info:
 
```
>sessionInfo()
R version 3.6.2 (2019-12-12)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Catalina 10.15.2

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] plyr_1.8.5       tensorflow_2.0.0 forcats_0.4.0    stringr_1.4.0    tidyr_1.0.0      tibble_2.1.3    
 [7] tidyverse_1.3.0  readr_1.3.1      purrr_0.3.3      ggplot2_3.2.1    dplyr_0.8.3      keras_2.2.5.0   

loaded via a namespace (and not attached):
 [1] reticulate_1.14  tidyselect_0.2.5 haven_2.2.0      lattice_0.20-38  colorspace_1.4-1 vctrs_0.2.1     
 [7] generics_0.0.2   base64enc_0.1-3  rlang_0.4.2      pillar_1.4.3     glue_1.3.1       withr_2.1.2     
[13] DBI_1.1.0        dbplyr_1.4.2     modelr_0.1.5     readxl_1.3.1     lifecycle_0.1.0  munsell_0.5.0   
[19] gtable_0.3.0     cellranger_1.1.0 rvest_0.3.5      tfruns_1.4       fansi_0.4.1      broom_0.5.3     
[25] Rcpp_1.0.3       scales_1.1.0     backports_1.1.5  jsonlite_1.6     fs_1.3.1         hms_0.5.3       
[31] stringi_1.4.5    grid_3.6.2       cli_2.0.1        tools_3.6.2      magrittr_1.5     lazyeval_0.2.2  
[37] crayon_1.3.4     whisker_0.4      pkgconfig_2.0.3  zeallot_0.1.0    xml2_1.2.2       reprex_0.3.0    
[43] lubridate_1.7.4  assertthat_0.2.1 httr_1.4.1       rstudioapi_0.10  R6_2.4.1         nlme_3.1-142    
[49] compiler_3.6.2  
```
And the results of my tf_config(): 
```
> tf_config()
TensorFlow v2.1.0 ()
Python v3.6 (~/Library/r-miniconda/envs/r-reticulate/bin/python)
```
In connection with the new version of [reticulate v1.14](https://blog.rstudio.com/2019/12/20/reticulate-1-14/) and after quite a few problems to get [Keras available](https://community.rstudio.com/t/reticulate-1-14-together-with-miniconda3-and-tensorflow-not-working/49180), I encountered a rather serious problem. In an existing program written under `keras v2.2.0.9000`, `reticulate v1.10` and `tensorflow v1.9` and since then run successfully many times, the command 
```
model %>% compile(
  optimizer = "adam",
  loss = list(loss_mean_squared_error, loss_categorical_crossentropy)
)
```
now run under `reticulate 1.14`, `tensorflow 2.0.0` and `keras 2.2.5.0`, produce the following error message:

> error in UseMethod ("compile") : 
> not applicable method 'compile' applied for object of class "c('keras._impl.keras.engine.training.Model', 'keras._impl.keras.engine.topology.Network', 'tensorflow.python.layers.network.GraphNetwork', 'keras._impl.keras.engine.topology.Layer', 'tensorflow.python.layers.base.Layer', 'python.builtin.object')" 

Similarly, the command
```
model %>% fit(x = x,
              y = list(y1, y2),
              sample_weight = list(sample_weights, sample_weights),
              epochs = 10)
```
produces the error message

> error in UseMethod ("fit") : 
> not applicable method 'compile' applied for object of class  "c('keras._impl.keras.engine.training.Model', 'keras._impl.keras.engine.topology.Network', 'tensorflow.python.layers.network.GraphNetwork', 'keras._impl.keras.engine.topology.Layer', 'tensorflow.python.layers.base.Layer', 'python.builtin.object')" 

So - which method would then be applicable for compilation? Consulting the `keras 2.2.5.0` index w.r.t. command `compile` shows that `compile` as such doesn't exist as entry in the index any more, but only

> `compile.keras.engine.training.Model` ... Configure a Keras model for training

However, under this symbolic headline I find the same description as earlier under keyword `compile(...)` and I cannnot detect anything wrong within the command used as above. Correspondingly the situation for `fit()`.

Moreover, the function `to_categorical(y, num_classes = NULL, ...)` now seems to require specification of `num_classes` explicitely, since without this specification (as it was used up to now), a mysterious error message

> Error: Keras loaded from tensorflow v1.5, however version 1.9 is required. Please update with tensorflow::install_tensorflow()

appears. And, really, the command `tensorflow::tf_config()` shows, much to my surprise,

> TensorFlow v1.5.0 (C:\...\Local\conda\conda\envs\R-TENS~1\lib\site-packages\tensorflow\__init__.p)
> Python v3.6 (C:/.../Local/conda/conda/envs/r-tensorflow/python.exe)

Note that in my case actually `tensorflow v2.0.0` has been installed; the recommended command to install `tensorflow v1.9` (sic!) at this point sounds like a dire reminiscence to my (lost) previous era with Keras. And there is no way back: an attempt to reinstall `tensorflow 1.9` automatically leads to reinstallation of `tensorflow 2.0.0`, since `tensorflow 1.9` is not available for `R 3.6.2`. Catch 362, so to speak...

I am really at a loss how to proceed. Any useful hint would be highly appreciated.

Tnx in advance,
Leo Faltin






I want to learn how to perform LSTM of multivariate time series data to predict Y
Data have the following shape:
 ```
     Day         Y     x1   x2     x3   x4
   2019-01-01   3245   245  747   319   956
   .......................................
   2020-01-07   4367   523  332   642   123
```
I've found this tutorial for Python Online
https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/
but nothing for R. Is there a template for achieving this in R?
Hi! 

I managed to solve the problem, if I install the "r-studio" environment from anaconda it solves the problem; 

```
conda create -y --name r-tensorflow tensorflow keras python=3.6.8
```

and if I run: 

```
library(keras)
library(tensorflow)
library(tfestimators)
library(tfdatasets)
library(reticulate)
library(dplyr)
library(ggplot2)


use_condaenv("r-tensorflow")

sys <- import("sys")
np <- import("numpy")

### If we were working with the boston dataset
boston_housing <- dataset_boston_housing()
c(train.data, train.labels) %<-% boston_housing$train

tf$reset_default_graph()
k_set_session(tf$Session())

model <- keras_model_sequential() %>%
  layer_dense(units = 256, activation = "relu", input_shape = c(1000)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, activation = "softmax")

model %>% compile(loss = "mse", optimizer = "rmsprop", metrics = list("mean_absolute_error"))

```

everything works fine, but then when I try to fit the model I receive the following error: 

```
history_init <- model %>% fit(train.data, train.labels, epochs = 500, validation_split = 0.2, verbose = 0)
Error in py_call_impl(callable, dots$args, dots$keywords) : 
  Evaluation error: ModuleNotFoundError: No module named 'rpytools'.
```

Do you know what is the problem? 

Thank you 


Tullio

I'm learning Keras for regression. I want to figure out which of the 20 input variables have relatively stronger predictive importance with the 1 output variable? How may I achieve that technically with code in Keras?
I am building a multi-label keras model in R where the number of labels is stored in an integer. My goal is to create the last layer in a for-loop somethign like this. 

>for (i in 1:number_output_vars){
>  model_keras[i] <- model_keras_pre %>%
>    layer_dense(units = 1, kernel_initializer = "zeros") %>%
>    layer_activation("relu")
>}

model_keras_pre is output from a deep model. However, the above code generates an error 

> Error in model_keras[i] <- model_keras_pre %>% layer_dense(units = 1,  : 
>  object of type 'closure' is not subsettable

I want to have different loss function for different labels, hence need some kind of for-loop to create the last layer. Is there a better way to create layers in a for-loop? 
I'm learning Keras in R and want to test a NN regression model on a multivariate time series data set. The goal is to predict Y as a function of its lag and all the other X variables and their corresponding lags. The dataset has ~250 variables and ~4000 daily observations in the following format:

    Y   Y-1day  Y-2days .. Y-50days   X1-1day .. X1-2days ...  X5-50days
    ...................................................................
    56  49      42         98         49      .. 134      ...  345
    78  56      49         102        67      .. 155      ...  497
    89  78      56         134        88      .. 161      ...  412
    ...................................................................

As a 1st step, I split the dataset between `Predictors` (Y-1day...X5-50days) and `Predict` (only Y) matrixes. Then I normalize [min-max] `Predictors` between 0-1. Finally, I pass the 2 matrixes to Keras model with the implemented code below:

    #Create the model
    build_model <- function() {
        model <- keras_model_sequential() %>%
            layer_dense(units = 5, activation = "relu", input_shape = dim(Predictors)[2]) %>%
            layer_dense(units = 5, activation = "relu") %>%
            layer_dense(units = 1)
        model %>% compile(
            loss = "mean_absolute_percentage_error",
            optimizer = optimizer_rmsprop(),
            metrics = list("mean_absolute_percentage_error")
        )model}
    model <- build_model()
    model %>% summary()
    
    #Fit and train the model
    print_dot_callback <- callback_lambda(
        on_epoch_end = function(epoch, logs) {
            if (epoch %% 80 == 0) cat("\n")
            cat(".")})

    epochs <- 10000
    early_stop <- callback_early_stopping(monitor = "val_loss", patience = 500)
    model <- build_model()
    history <- model %>% fit(
        Predictors,
        Predict,
        epochs = epochs,
        validation_split = 0.3,
        verbose = 0,
        callbacks = list(early_stop, print_dot_callback))
    plot(history, metrics = "mean_absolute_percentage_error", smooth = FALSE) + coord_cartesian(xlim = c(0, 10000), ylim = c(0, 100))

After training is done, the last code line plots MAPE error for training and validation as shown below. We can notice that the MAPE on validation decreased down to ~1.3% which looks great. However, I'm am a bit skeptical as I don't see validation loss to increase, despite the high number of epochs. Does this indicate a hidden error or overlooked implementation in my model? How shall I interpret this?
![20G3h](https://user-images.githubusercontent.com/50983503/70126515-80718a80-1679-11ea-8ad8-5c4fd605211a.png)




Is there a way in R-keras to generate CAMs or Saliency Maps for one-dimensional input (e.g. a vector) as described for example for the "keras-vis" package for python?: https://github.com/raghakot/keras-vis/issues/93 

I trained a CNN using R-Keras and now want to visualize where the CNN is focusing on when performing class predictions. 

P.S.: Once I asked for the 2D option in R-Keras: https://github.com/rstudio/keras/issues/182 --> maybe the code proposed there is useful.