I am using anomalize with a tsibble object. Since the data is grouped using the function index_by from tsibble anomalize() cannot work. This is due to an unsupported indexClass of type yearmonth.

I bring in data that is daily with no gaps

Here is my code:
```
> # Lib Load ####
> install.load::install_load(
+   "tidyquant"
+   , "fable"
+   , "fabletools"
+   , "feasts"
+   , "tsibble"
+   , "timetk"
+   , "sweep"
+   , "anomalize"
+   , "xts"
+   # , "fpp"
+   # , "forecast"
+   , "lubridate"
+   , "dplyr"
+   , "urca"
+   # , "prophet"
+   , "ggplot2"
+ )
> # Get File ####
> fileToLoad <- file.choose(new = TRUE)
> arrivals <- read.csv(fileToLoad)
> View(arrivals)
> arrivals$Time <- mdy(arrivals$Time)
> # Coerce to tsibble ----
> df_tsbl <- arrivals %>%
+   as_tsibble(index = Time)
> df_tsbl
# A tsibble: 6,908 x 2 [1D]
   Time       DSCH_COUNT
   <date>          <int>
 1 2001-01-01         22
 2 2001-01-02         30
 3 2001-01-03         43
 4 2001-01-04         30
 5 2001-01-05         38
 6 2001-01-06         22
 7 2001-01-07         29
 8 2001-01-08         37
 9 2001-01-09         33
10 2001-01-10         52
# ... with 6,898 more rows
> interval(df_tsbl)
1D
> count_gaps(df_tsbl)
# A tibble: 0 x 3
# ... with 3 variables: .from <date>, .to <date>, .n <int>
> # Make Monthly ----
> df_monthly_tsbl <- df_tsbl %>%
+   index_by(Year_Month = ~ yearmonth(.)) %>%
+   summarise(Count = sum(DSCH_COUNT, na.rm = TRUE))
> df_monthly_tsbl           
# A tsibble: 227 x 2 [1M]
   Year_Month Count
        <mth> <int>
 1   2001 Jan  1067
 2   2001 Feb   919
 3   2001 Mar  1024
 4   2001 Apr  1010
 5   2001 May  1056
 6   2001 Jun   995
 7   2001 Jul  1002
 8   2001 Aug  1076
 9   2001 Sep   982
10   2001 Oct   971
# ... with 217 more rows

> # Anomalize ----
> df_monthly_tsbl %>%
+   time_decompose(Count, method = "twitter") %>%
+   anomalize(remainder, method = "gesd") %>%
+   clean_anomalies() %>%
+   time_recompose()
Converting from tbl_ts to tbl_time.
Auto-index message: index = Year_Month
Error in index.xts(x) : unsupported ‘indexClass’ indexing type: yearmonth

```

Session info:
```
> sessionInfo()
R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] ggplot2_3.2.1              urca_1.3-0                 dplyr_0.8.3               
 [4] anomalize_0.2.0            sweep_0.2.2                timetk_0.1.2              
 [7] tsibble_0.8.5              feasts_0.1.1               fable_0.1.1               
[10] fabletools_0.1.1           tidyquant_0.5.9            quantmod_0.4-15           
[13] TTR_0.23-6                 PerformanceAnalytics_1.5.3 xts_0.11-2                
[16] zoo_1.8-6                  lubridate_1.7.4           

loaded via a namespace (and not attached):
 [1] tidyselect_0.2.5   purrr_0.3.3        lattice_0.20-38    colorspace_1.4-1  
 [5] vctrs_0.2.1        generics_0.0.2     utf8_1.1.4         rlang_0.4.2       
 [9] pillar_1.4.3       tibbletime_0.1.3   glue_1.3.1         withr_2.1.2       
[13] lifecycle_0.1.0    stringr_1.4.0      Quandl_2.10.0      munsell_0.5.0     
[17] anytime_0.3.6      gtable_0.3.0       labeling_0.3       curl_4.3          
[21] fansi_0.4.1        broom_0.5.3        Rcpp_1.0.3         backports_1.1.5   
[25] scales_1.1.0       install.load_1.2.1 jsonlite_1.6       farver_2.0.2      
[29] gridExtra_2.3      digest_0.6.23      packrat_0.5.0      stringi_1.4.3     
[33] grid_3.5.3         quadprog_1.5-8     cli_2.0.1          tools_3.5.3       
[37] magrittr_1.5       lazyeval_0.2.2     tibble_2.1.3       crayon_1.3.4      
[41] tidyr_1.0.0        pkgconfig_2.0.3    zeallot_0.1.0      assertthat_0.2.1  
[45] httr_1.4.1         rstudioapi_0.10    R6_2.4.1           nlme_3.1-137      
[49] compiler_3.5.3    
```

Hello,

I received the warning below, but search your repo and didn't find any reference to it.  Can you add documentation or clarification on this warning? Does it mattter?

```
Warning message:
`cols` is now required.
Please use `cols = c(anomalies)`
```

Thanks,

Alfredo
When loading the library(anomalize) the following error was displayed

error: package or namespace load failed for ‘anomalize’:.onAttach failed in attack Namespace() for 'anomalize', details:call: NULL error: Function getThemeInfo not found in RStudio
Is there a way to easily pull out anomalies that are higher than expected compared with those that are lower than expected? I'm only interested in anomalies that are higher than expected and haven't figured out a way to filter out those that are lower than expected. 

Thanks. 
Just making a note for anyone else searching for help on the same problem I had.  I upgraded my R version and a lot of packages, and suddenly I got errors when running the standard anomalize package examples:  
```
tidyverse_cran_downloads_anomalized <- tidyverse_cran_downloads %>%
  time_decompose(count, merge = TRUE)
```

Result:  
```
Error in !.key : invalid argument type
```

This seems to be already reflected in the information at https://github.com/tidyverse/tidyr/blob/master/revdep/problems.md.

To tide people over until it gets straightened out, I was able to work around the problem by downgrading `tidyr`:
```
require(devtools)
install_version("tidyr", version = "0.8.3", repos = "http://cran.us.r-project.org")
```
This is just a suggestion - there are times when one-sided tests are of interest in anomaly detection. It would be nice to have that capability added to anomalize.
Thanks,
Aaron
I have arranged my own data into as close a tibble to the "tidyverse_cran_downloads" demonstration data as possible:

class(tidyverse_cran_downloads)
[1] "grouped_tbl_time" "tbl_time"         "grouped_df"       "tbl_df"           "tbl"              "data.frame"  
> class(isw_simple)
[1] "grouped_tbl_time" "tbl_time"         "grouped_df"       "tbl_df"           "tbl"              "data.frame"   

glimpse(tidyverse_cran_downloads)
Observations: 6,375
Variables: 3
Groups: package [15]
$ date    <date> 2017-01-01, 2017-01-02, 2017-01-03, 2017-01-04, 2017-01-05, 2017-01-06, 2017-01-07, 2017-01-08, 2017-01-09...
$ count   <dbl> 873, 1840, 2495, 2906, 2847, 2756, 1439, 1556, 3678, 7086, 7219, 0, 5960, 2904, 2854, 5428, 6358, 6973, 661...
$ package <chr> "tidyr", "tidyr", "tidyr", "tidyr", "tidyr", "tidyr", "tidyr", "tidyr", "tidyr", "tidyr", "tidyr", "tidyr",...
> glimpse(isw_tss)
Observations: 15,744
Variables: 4
Groups: staff_id_last_updt [9]
$ sample_date        <date> 2011-06-15, 2011-06-15, 2011-06-22, 2011-06-22, 2011-08-16, 2011-08-29, 2011-08-29, 2011-09-20,...
$ reported_value     <dbl> 68.0, 62.0, 38.0, 3.0, 35.1, 147.0, 147.0, 32.4, 1.0, 0.0, 0.0, 13.0, 130.0, 25.9, 10.4, 10.4, 2...
$ parameter_name     <chr> "Solids, Total Suspended (TSS)", "Solids, Total Suspended (TSS)", "Solids, Total Suspended (TSS)...
$ staff_id_last_updt <chr> "bolafso", "bolafso", "bolafso", "bolafso", "bolafso", "bolafso", "bolafso", "bolafso", "bolafso...

As you can see, both 'class()' and 'glimpse()' show very similar structures.  I can replicate the results with the demonstration data just fine. However, when I try and apply the 'time_decompose()' function to my data (isw_tss), I get the "Only year, quarter, month, week, and day periods are allowed for an index of class Date" error message. 

I  am confused by this as my date data are in the ymd format (same as the demonstration data). Any thoughts would be much appreciated.

I have attached a sample data file
[isw_tss.txt](https://github.com/business-science/anomalize/files/3570701/isw_tss.txt)

Here is the code I have modified up to the error message bits:

# load libraries
library(tidyverse)
library(tidyquant)
library(lubridate)
library(ggplot2)
library(ggpubr)
library(anomalize)
library(tibbletime)

# read in the data
isw_dmr <- read_csv('C:\\Users\\kwyther\\export_isw_dmr.csv')
# change to lower case and remove rows with no reported value
isw_dmr <- rename_all(isw_dmr, tolower) %>% 
  drop_na(reported_value)

# change sample_dates to date
isw_dmr$sample_date <- dmy(isw_dmr$sample_date)

# list of paramters
params <- isw_dmr %>% distinct(parameter_name)

# list of staff entering data
staff <- isw_dmr %>% distinct(staff_id_last_updt)

# simplify by parameter
# tss
isw_tss <- isw_dmr %>%
  select(sample_date, reported_value, parameter_name, staff_id_last_updt) %>% 
  filter(parameter_name == 'Solids, Total Suspended (TSS)')

isw_tss <- isw_tss %>%
  group_by(staff_id_last_updt) %>%
  as_tbl_time(sample_date)

isw_tss <- isw_tss %>% 
  arrange(sample_date, .by_group = TRUE)

isw_tss %>%
  ggplot(aes(sample_date, reported_value)) +
  geom_point(color = "#2c3e50", alpha = 0.25) +
  facet_wrap(staff_id_last_updt ~ .) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  labs(title = "TSS reported values by staff",
       subtitle = "Data from ISW_DMRs")

isw_tss %>%
  # Data Manipulation / Anomaly Detection
  time_decompose(reported_value, method = "stl") %>%
  anomalize(remainder, method = "iqr") %>%
  time_recompose() %>%
  # Anomaly Visualization
  plot_anomalies(time_recomposed = TRUE, ncol = 3, alpha_dots = 0.25) +
  labs(title = "TSS Anomalies", subtitle = "STL + IQR Methods") 

For this code block to calculate the critical limits, I don't see a difference when there are outliers or not since `limit_tbl$limit_lower` and `limit_tbl$limit_upper` come from `limits[1])` and `limits[2]` which are the same for each row.
```# Critical Limits
  if (any(vals_tbl$outlier == "No")) {
    # Non outliers identified, pick first limit
    limit_tbl <- vals_tbl %>%
      dplyr::filter(outlier == "No") %>%
      dplyr::slice(1)
    limits_vec <- c(
      limit_lower = limit_tbl$limit_lower,
      limit_upper = limit_tbl$limit_upper
    )
  } else {
    # All outliers, pick last limits
    limit_tbl <- vals_tbl %>%
      dplyr::slice(n())
    limits_vec <- c(
      limit_lower = limit_tbl$limit_lower,
      limit_upper = limit_tbl$limit_upper
    )
  }```
```
dfr <- tibble(ds = as.Date(c('2017-03-01', '2017-04-01', '2017-05-01', '2017-06-01', '2017-07-01', '2017-08-01', '2017-09-01',
                                  '2017-10-01', '2017-11-01', '2017-12-01', '2018-01-01', '2018-02-01', '2018-03-01', '2018-04-01', '2018-05-01', '2018-06-01',
                                  '2018-07-01', '2018-08-01', '2018-09-01', '2018-10-01', '2018-11-01', '2018-12-01', '2019-01-01', '2019-02-01', '2019-03-01',
                                  '2019-04-01', '2019-05-01', '2019-06-01')),
  
                  y=c(12.95, 1.12, 4.48, 17.85, 0.14, 0.7, 1.75, 3.43, 5.18, 14.91, 4.27, 1.82, 4.83, 2.94, 3.22, 6.72, 3.36, 2.52,
                      5.88, 23.1, 13.44, 1244.22, 1.26, 9.66, 22.05, 2.94, 6.3, 1.26))
# outlier in 2018-12-01
decmp <- time_decompose(data = dfr,target = y,method = "stl", frequency = "12 months",trend = "auto",message = FALSE)
fit <- decmp %>% anomalize(remainder,method = "gesd",max_anoms = .3,verbose = FALSE)
# 1244 in 2018-12-01 is seasonality!!!!! and remainder = -0.2793775
fit %>% time_recompose() %>% plot_anomalies()
fit %>% time_recompose() %>% plot_anomaly_decomposition()

#try native STL

t <- ts(data = dfr$y,start = c(2017,3),frequency = 12)
library(highcharter)
hchart(stl(t,s.window = "periodic"))
# in 2018-12-01  remainder is 558 and in this case is anomaly!!!!

# try twitter with same results
decmp <- time_decompose(data = dfr,target = y,method = "twitter", frequency = "12 months",trend = "auto",message = FALSE)
fit <- decmp %>% anomalize(remainder,method = "gesd",max_anoms = .3,verbose = FALSE)
fit

# try original twitter
# devtools::install_github("twitter/AnomalyDetection")
library(AnomalyDetection)
AnomalyDetectionTs(x = dfr)
# timestamp               anoms
# 1 2018-10-01 03:00:00   23.10
# 2 2018-12-01 03:00:00 1244.22

```
Hi folks.

First off, I'd like to give a big thank you to the maintainers and contributors of this package. It works great!

However, I do have a question: how would I go about identifying anomalous **trends** as opposed to **transactions** ?

Say I have 5 companies and I'm interested in identifying if, amongst those, there is one exhibiting an anomalous trend. Or if I'm selling a group of products, and I'm interested in identifying if any of those have anomalous trends compared to each other. How would I do that?

Again, thank you for the package.

Cheers