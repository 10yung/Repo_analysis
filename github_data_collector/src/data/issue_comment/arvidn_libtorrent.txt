This is a fairly significant change to how listen sockets and outgoing sockets are assigned to network interfaces and source IP addresses.

The commits all represent (mostly) independent changes all having the effect that:

* Trackers are only announced from a source IP address where it makes sense. e.g. only if the tracker is running on loopback does it make sense to announce to it from a socket bound to loopback.
* SOCKS5 UDP tunnels are only set up for listen sockets where it makes sense (same logic as for trackers)
* the UDP sockets dedicated for outgoing packets have been removed and folded into the listen sockets (for UDP). This simplifies things a bit and possibly improves reachability throught NATs.
* when listening on 0.0.0.0, multiple IPv4 sockets will be opened, one for each local IPv4 address, however, they will all be restricted to be used for their respective subnet. Like the example with the tracker above, a socket listening to loopback, will only be used for destinations over loopback. IPv6 addresses were already treated this way, but not IPv4.

I think this will improve SOCKS5 support, mainly in that only a single UDP tunnel will be opened (in the common case). But if you have both IPv4 and IPv6 connectivity for instance, and the SOCKS5 tunnel resolves to both IPv4 and IPv6, two tunnels will be opened. This is to take full advantage of all network paths.

There's some more discussion on this topic in [this ticket](https://github.com/arvidn/libtorrent/issues/4216#issuecomment-572535958).
Tron's BTT cryptocurrency has the potential to reduce leeching and cheating, improve fairness, and help some make extra money. Is it a good standard or good for LT? Will it benefit some or most users? Will it be hard to add to LT?

[Whitepaper](https://www.bittorrent.com/btt/btt-docs/BitTorrent_(BTT)_White_Paper_v0.8.7_Feb_2019.pdf).

**Please provide the following information**

libtorrent version (or branch):
1.2.3
platform/architecture:

compiler and compiler version:

please describe what symptom you see, what you would expect to see instead and
how to reproduce it.

Let’s say I have 500 torrents with the same SSL tracker and I just started my client. Libtorrent makes asynchronous announces for all of those torrents. Now my question is, does libtorrent use the same session/handshake to perform all these announces? Does it take advantage of cached sessions? Or it tries to do 500 asynchronous ssl handshakes to the same server? Asking this cause it seems like libtorrent is kinda slow when it comes to announcing to SSL trackers. Maybe this requires some optimisation. 

pass the whole listen_socket_t object to async_accept() and on_accept_connection(), instead of just the acceptor socket
Many <define> are printed out by the command "b2 toolset=msvc --debug-building". Which is used in vs?
There is <define> for compiling every file. Compiling samples in vs needs the same <define> as compiling libtorrent. How do you confirm? Here is my <define> for. torrent at compile time, but in the examples, the compilation fails.

> <define>BOOST_ALL_NO_LIB <define>BOOST_ASIO_ENABLE_CANCELIO <define>BOOST_ASIO_HAS_STD_CHRONO <define>BOOST_MULTI_INDEX_DISABLE_SERIALIZATION <define>BOOST_NO_DEPRECATED <define>BOOST_SYSTEM_NO_DEPRECATED <define>BOOST_SYSTEM_SOURCE <define>TORRENT_BUILDING_LIBRARY <define>TORRENT_BUILDING_SHARED <define>TORRENT_USE_I2P=1 <define>WIN32 <define>WIN32_LEAN_AND_MEAN <define>_CRT_SECURE_NO_DEPRECATE <define>_FILE_OFFSET_BITS=64 <define>_SCL_SECURE_NO_DEPRECATE <define>_WIN32 <define>_WIN32_WINNT=0x0600 <define>__USE_W32_SOCKETS
This is my appempt to build Python bindings and provide them as PyPI package. Note that it currently doesn't work.

It closes #319 and #3841.

---

This should be done in multiple parts. I will try to do all of them, but I will probably need some help...

- [x] Add more details to PyPI package (name, description, readme, classifiers, keywords, license...)

- [ ] Make building script (`setup.py`) that uses `Extension` by distutils/setuptools instead of `bjam` and is compatible with PyPI and easy to use.

- [ ] Add CI scripts that build and release package.

---

Also, installation process should be easy both for users which use wheels and users which don't use them:

* Installing with wheels (which should be provided for Windows, Linux and macOS and for supported Python versions) should be normal as with any other Python package.

* Installing without wheels would be a bit more compilated but should be still easy to do:

  - Users would need to download and install Boost and set up a few environment variables.
  - Then they would just need to run `setup.py` which would build and install libtorrent and Python bindings.

---

When building on CI, the root `setup.py` should be run with `python setup.py --pypi sdist bdist_wheel`. This would:

* Copy `bindings/python/setup-pypi.py` to `bindings/python/setup.py`.
* Copy few project details to bindings folder.
* Copy libtorrent to bindings folder.
* Package bindings source code as well as package details and libtorrent code to `sdist`.
* Build bindings and libtorrent and package to wheel.

The reason for copying libtorrent into bindings folder is to make distrubution and instllation of `sdist` easier, which will make instllation easier for users which can't use wheels.

When users without wheels would want to install package, process would be similar, but without copying things, because they would already been copyied and distributed. so they would just need building.

---

I managed to build Python bindings with `Extension`, but they don't work. The problem is that binaries aren't actually linked to `libtorrent`, so they won't work:

```
>>> import libtorrent
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ImportError: /usr/local/lib/python3.8/site-packages/libtorrent-2.0.0-py3.8-linux-x86_64.egg/libtorrent.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZTIN10libtorrent13torrent_alertE
```

To fix this, `libtorrent` need to be pre-built into `.a` file. However, I don't know how to implement this in `setup.py` in a way that it would be easy to use.

I also haven't tested this yet on Windows, but it probably fails because of similar problem.
We need to collect traits of illegal clients for building a better anti-leeching algorithm as dicussed in #4192. 

So far I have noticed that progress reported from leechers would be stuck at 0% even after  receiving gigabytes of data from me.

![图片](https://user-images.githubusercontent.com/32929636/71642314-7c6e7200-2ce4-11ea-99fa-d5b9fae9dccd.png)


libtorrent version (or branch): RC_1_2

Currently, if one has multiple network interfaces and listens on `[::]` (which is done by default). That address is expanded to all IPv6 addresses the machine has. One reason for having multiple IPv6 addresses is by running a VPN, where there's a `tun0` device with an IPv6 address assigned to it.

The current logic opens a listen socket for both the VPN interface *and* the underlying "direct" interface. I don't think this is intuitive behavior. It's explained in the code with this comment:

```
      // To comply with BEP 45 multi homed clients must run separate DHT nodes
      // on each interface they use to talk to the DHT. For IPv6 this is enforced
      // by prohibiting creating a listen socket on [::]. Instead the list of
      // interfaces is enumerated and sockets are created for each of them.
      // This is not enforced for 0.0.0.0 because multi homed IPv4 configurations
      // are much less common and the presence of NAT means that we cannot
      // automatically determine which interfaces should have DHT nodes started on
      // them.
```

This is why it's not done with the IPv4 counterpart, 0.0.0.0.

My first thought of making this more intuitive was to only expand it to the single *main* IPv6 interface. To find the main interface:

1. find the first entry in the routing table with `[::]` as the destination. remember the associated device name.
2. find the first IP address in the interfaces list associated with this device, and whose gateway is specified.

If no entry in the routing table can be found, ignore the `[::]` entry in the `listen_interfaces` setting. This same algorithm could be used to treat the unspecified IPv4 address the same as well.

The idea is that in the (presumably rare) case of having a machine actually hooked up to two or more internet connections, one would have to explicitly add both to the `listen_interfaces` setting.

After having implemented this behavior though, it occurred to me that it really seems that the behavior I'm looking for is to preserve the unspecified listen addresses, and let the OS figure it out. The question in that scenario is what to do about the DHT nodes.

Perhaps the DHT node could be made to allow the unspecified IPv6 address, but use the algorithm above to find its concrete IP.

In either case, I should also add a section in the documentation talking about multi-homed support and explain this logic in detail, to make it clear how it works.

@ssiloti I'm hoping you have some thoughts or opinions on this. I'm not sure what the best solution is, but I really hope it involves reducing complexity.
**Please provide the following information**

libtorrent version (or branch): 1.2.3

platform/architecture: OpenBSD/amd64

compiler and compiler version: clang 8.0.1

please describe what symptom you see, what you would expect to see instead and
how to reproduce it.

I have patches to get test_web_seed_http* and test_url_seed unit tests to pass. [unit test report on OpenBSD](https://gist.github.com/namtsui/3f935dc120431d3063a85e0b833d4ce6)

In libtorrent-rasterbar, two types of HTTP seeding are supported. "URL
seed" implements BEP 19 and "HTTP seed" implements BEP 17. HTTP seeding
is when a HTTP server assists in the seeding.

Sources:
https://www.libtorrent.org/manual.html#http-seeding
http://www.getright.com/seedtorrent.html
http://bittorrent.org/beps/bep_0019.html
http://bittorrent.org/beps/bep_0017.html

test_url_seed tries to run:
- url_seed_ssl_keepalive
- url_seed_ssl
- url_seed_keepalive
- url_seed
- url_seed_keepalive_rename

test_url_seed manages to run url_seed_ssl_keepalive correctly and then once it gets to url_seed_ssl, which does not use keepalive, it silently returns. I found that it quits at send_header("Connection", "close").

`patch-test_web_server_py' fixes url seed tests as explained in the
diff. This allows the test_url_seed test to "pass," but I am very unsure of this patch.
- What does keepalive do?
- Does my patch defeat the purpose of the test?

```
Index: patches/patch-test_web_server_py
===================================================================
RCS file: patches/patch-test_web_server_py
diff -N patches/patch-test_web_server_py
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ patches/patch-test_web_server_py	30 Dec 2019 01:00:45 -0000
@@ -0,0 +1,20 @@
+$OpenBSD$
+
+Needed for test_url_seed because tests without keepalive (url_seed_ssl and
+url_seed) quit at send_header("Connection", "close"), causing the unit test to
+fail.
+
+Index: test/web_server.py
+--- test/web_server.py.orig
++++ test/web_server.py
+@@ -164,10 +164,6 @@ class http_handler(BaseHTTPRequestHandler):
+                 s.send_header('Content-Length', end_range - start_range)
+                 if filename.endswith('.gz'):
+                     s.send_header('Content-Encoding', 'gzip')
+-                if not keepalive:
+-                    s.send_header("Connection", "close")
+-                    if not use_ssl:
+-                        s.request.shutdown(socket.SHUT_RD)
+ 
+                 s.end_headers()
+ 

```

test_web_seed_http tests fail. `patch-test_http_py' fixes these by making the socket timeout by the default "None." This makes it blocking. I feel more confident about this patch.
https://docs.python.org/3/library/socket.html#socket-timeouts

```
Index: patches/patch-test_http_py
===================================================================
RCS file: patches/patch-test_http_py
diff -N patches/patch-test_http_py
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ patches/patch-test_http_py	30 Dec 2019 01:00:45 -0000
@@ -0,0 +1,18 @@
+$OpenBSD$
+
+Needed for test_web_seed_http and test_web_seed_http_pw to pass. socket has
+soc.settimeout(None) by default.
+
+https://docs.python.org/3/library/socket.html#socket-timeouts
+
+Index: test/http.py
+--- test/http.py.orig
++++ test/http.py
+@@ -217,7 +217,6 @@ def start_server(host='localhost', port=8080, IPv6=Fal
+     else:
+         soc_type = socket.AF_INET
+     soc = socket.socket(soc_type)
+-    soc.settimeout(120)
+     print("PROXY - Serving on %s:%d." % (host, port))  # debug
+     print('python version: %s' % sys.version_info.__str__())
+     soc.bind((host, port))

```
