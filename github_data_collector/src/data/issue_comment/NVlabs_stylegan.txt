Since we know that installing CUDA on newly created instance is a complex tasks because there will be many errors related to version conflicts. Especially while installing NVIDIA drivers and cuDNN. Also, it is a big headache downloading files in cloud instance. I have added **CUDA_INSTALLATION_INSTRUCTION.md** file which helps users in installing CUDA and setting up environment to run stylegan project. I have tested this on **Azure**, **AWS** and **GCP**. Works fine. Below md file explains everything about the installation. 
Also added requirements.txt file since it's useful while creating virtualenv on cloud VM instance.
@tkarras, Please review this PR. And reply if you find it useful.
*Why?*
Adding a Docker image based on the Tensorflow Docker image to create the installation and setup process easy and breezy.

*What?*
Adding `Dockerfile.gpu` which can easily be called using a `Makefile` that has the following commands:
- `make build` build the docker container
- `make example` run the `pretained_example.py` in the container
- `make shell` open bash inside the container
- `make jupyter` to run jupyter notebooks inside the container (would love to add notebook examples in a separate PR)

> The setup uses the latest version of [`nvidia-docker`](https://github.com/NVIDIA/nvidia-docker) and requires Docker 19.03 or newer
Including a SoTA badge for this implementation that highlights the performance of the paper, and allows people to compare StyleGAN to alternative methods on CelebA HQ.
If the behavior of this function is to map `[0,255]` to `drange`, I believe there is a bug.
Makes it easier to control image generation from command line, generate multiple images, and use a local network file.
