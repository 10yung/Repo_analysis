Hi,
I'm fairly new to coding and using mice (3.7.0) on a large (900+ observations) data set. I'm trying to conduct an ordinal logistic regression on a variable with 14 levels (which I imputed using the "polr" method) against a multitude (~50) of other numeric and binomial variables. I've gotten as far as trying to use the polr() function from the MASS package with the mice with() function and get the following error. I get the same error regardless of including the argument for Hess= TRUE which I assume is needed when planning to use the summary() function. I tried searching for similar errors but didn't find any that were helpful to this situation. Thanks in advance.

olr <- with(imputed, polr(14_level_factor ~ var 1+var2+var3+varN), Hess= TRUE)

Error in optim(s0, fmin, gmin, method = "BFGS", ...) : 
  initial value in 'vmmin' is not finite
In addition: Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred
Since the `tidyr` package also contains the `complete()` function, I would suggest to add an S3 method for `complete.mids` so it wouldn't make a difference if `tidyr` is loaded after `mice`.

Something like (not tested myself):

```r
#' @exportMethod complete.mids
#' @importFrom tidyr complete
#' @export
#' @noRd
complete.mids <- function (data, action = 1L, include = FALSE, mild = FALSE, ...) {
  mice::complete(data = data, action = action, include = include, mild = mild, ... = ...)
}
```

This could collide with your existing `complete()` function, but that can be solved to define your own `complete.default` and use `UseMethod("complete")` in your current `complete()` function.

Many thanks for your work the last decades! It's awesome!
Running mice on a data frame with about 11,000 rows and 42 columns, ~12 of which have missing values ranging to 10% of the observations. After running multiple tests, I consistently have a longer time running `parlmice()` and 5 cores vs just `mice()`, and it is not clear to me why. I am wondering if this is a known behavior? I understand that in cases where the size of the job and computation time is low that parallelization can slow down overall computation, but in this case, even using `cl.type = 'FORK'`, the speed is about half when I use multiple cores. 
For instance: 

`parallel::clusterEvalQ(cl, {library(mice); library(miceadds)})`
It seems some strange things happen with environments when parlmice is wrapped in a function, e.g.

```R
library(mice)
test.parlmice <- function() {
  dat <- nhanes
  
  parlmice(dat, cl.type='FORK', maxit = 5, n.core = 2, n.imp.core = 2)
}
```

Calling test.parlmice() results in:

>  Error in get(name, envir = envir) : object 'dat' not found 

The environment is still broken, even after the parlmice call, e.g.

```R
test.parlmice2 <- function(someVal = T) {
  parlmice(nhanes, cl.type='FORK', maxit = 5, n.core = 2, n.imp.core = 2)
  
  print(someVal)
}
```

Result:

> Error in get(name, envir = envir) : object 'someVal' not found 

Session info:

```
R version 3.6.1 (2019-07-05)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3
LAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C               LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8     LC_MONETARY=en_NZ.UTF-8   
 [6] LC_MESSAGES=en_NZ.UTF-8    LC_PAPER=en_NZ.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mice_3.6.0      lattice_0.20-38

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.1        rstudioapi_0.10   magrittr_1.5      splines_3.6.1     MASS_7.3-51.4     tidyselect_0.2.5  R6_2.4.0          rlang_0.4.0      
 [9] jomo_2.6-9        minqa_1.2.4       dplyr_0.8.3       tools_3.6.1       parallel_3.6.1    nnet_7.3-12       grid_3.6.1        mitml_0.3-7      
[17] broom_0.5.2       nlme_3.1-141      pan_1.6           survival_2.44-1.1 yaml_2.2.0        lme4_1.1-21       assertthat_0.2.1  tibble_2.1.3     
[25] crayon_1.3.4      Matrix_1.2-17     nloptr_1.2.1      purrr_0.3.2       tidyr_0.8.3       rpart_4.1-15      glue_1.3.1        compiler_3.6.1   
[33] pillar_1.4.2      generics_0.0.2    backports_1.1.4   boot_1.3-23       pkgconfig_2.0.2  
```
Hi!

I am trying to setup parlMice in the following way:

```
mdf <- parlMice(...)
isNotConverged<-any(Rhats(mdf) > 1.1)
while (isNotConverged) {
    mdf<- parlMice(mdf,...)
   isNotConverged<-any(Rhats(mdf) > 1.1)
}
```

Is there any way this could be done? As far as I can see, I would have export the mice.mids interface.

```
imp1 <- mice(nhanes, maxit=1, seed = 123)
imp2 <- mice.mids(imp1)

# yields the same result as
imp <- mice(nhanes, maxit=2, seed = 123)

# verification
identical(imp$imp, imp2$imp)
```
from : https://rdrr.io/cran/mice/man/mice.mids.html
I would like to use some functions in the package `miceadds` while running `mice` in parallel, but `parlmice` returns an error because they are not being exported.

I can see that the code for `parlmice` calls:
```
parallel::clusterEvalQ(cl, library(mice))
```
Would it be possible to change the function so that wrapper packages to `mice` such as `miceadds` or `micemd` are also exported and loaded in each cluster?

Thank you,

K.
`mice 3.1.3` overwrites the `base::cbind()` and `base::rbind()` functions. 

This is not elegant, and it throws a warning when the package is loaded. I am looking for a better way to implement dispatch. See #114 

For more background see https://stackoverflow.com/questions/47967264/dispatch-of-rbind-and-cbind-for-a-data-frame.
  
Martin Maechler suggested a solution. Does anyone have time to dive in?
When using mice multiple imputation to generate multiple imputed sets and then running a model on each one of them (like elastic-net from the `glmnet` package) and then pooling the estimates to a single set - its not possible to use `predict.glmnet()` (or `predict()`) on the object that comes out of `mice::pool()`. 
The prediction functions expect a fitted model object while `mice::pool()` returns 
> An object of class mipo, which stands for 'multiple imputation pooled outcome'.

Is it possible to add the ability to make predictions from the return object of `mice::pool()`?
Dear Stef,

Another problem I encountered today showed itself when I was trying to reproduce some of your code from your book "Flexible Imputation of Missing Data" (fantastic book!).

At page 135-136 you present two code-solutions to the same post-processing setting:

```
library(mice)
ini <- mice(airquality[, 1:2], maxit = 0)
post <- ini$post
post["Ozone"] <- "imp[[j]][,i] <- squeeze(imp[[j]][,i], c(1,200))"
imp <- mice(airquality[, 1:2], method = "norm.nob", m = 1, maxit = 1, seed = 1, post = post)
```

Alternative to line 4:
`post["Ozone"] <- "ifdo(c(Ozone < 1, Ozone > 200), c(1, 200))"`

The former works fine but the latter gives the `OzoneFunction ifdo() not yet implemented.`

Has the "ifdo" function been withdrawn from the package?


Best regards,
Mikkel