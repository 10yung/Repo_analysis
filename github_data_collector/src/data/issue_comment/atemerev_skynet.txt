
It would be interesting to see performance of Intel TBB with your microbenchmark.
I ran into an [issue](https://github.com/commercialhaskell/stack/issues/2022) when I tried to get stack to generate .prof files with the +RTS flags.  It seems like the stack/ghc on windows swallows the +RTS flags meant for the application!  This bug means the windows code never even got the -N flag and wasn't even parallelized.  One workaround is to run the benchmarks against the executable directly without calling stack (somewhere in .stack-work\install\xxxxxxx\bin) until this is resolved.

Project Orleans is the actor framework for .net.
https://github.com/dotnet/orleans

With Rust 1.8.0 installed by Linuxbrew on Linux Mint 17.4 Rosa x64 (based on Trusty), when running `cargo build --release`:

```
/home/fabio/.cargo/registry/src/github.com-88ac128001ac3a9a/fs2-0.2.2/src/unix.rs:63:67: 63:79 error: mismatched types:
 expected `i64`,
    found `u64` [E0308]
/home/fabio/.cargo/registry/src/github.com-88ac128001ac3a9a/fs2-0.2.2/src/unix.rs:63     let ret = unsafe { libc::posix_fallocate(file.as_raw_fd(), 0, len as off_t) };
                                                                                                                                                       ^~~~~~~~~~~~
```

Sorry, not knowledgeable enough in Rust to open a PR but wanted to give it a try nevertheless.

clojure-core-async ➜ lein run
"Elapsed time: 5494.564275 msecs"
499999500000

Haskell went from being one of the slowest (on Macbook) to the fastest in the Linux test case. Any indication of what's causing this relative slowdown? Memory/CPU? Perhaps even OS?

There is rphmeier/skynet-jobsteal implementation of this kata, which is much better and faster than my own (~5× faster on my laptop).

It would be very cool to see those results in the repo's readme.

I looked at the code, found it a bit weird and went on to debug it. 

![](http://julianobs.co/screencloud/16-02-18_11-13-36.png)

It seems we have one task running parallel to the Main task and doing, if I understand it correctly, only an asynchronous reduce (aggregate) over all synchronous and recursive results.

Can anyone help me understand this?

I've created a [stackoverflow question](http://stackoverflow.com/questions/35482762/tpl-sample-on-skynet-benchmarks-not-really-parallel) hoping for more attention.

Out of interest I have included my own implementation in Prolog. This is written in my own Prolog ( https://github.com/infradig/yxtrang ) which implements Erlang-style processes and message-passing. It is quite slow as I haven't done too much optimisation in this area (in fact I just got it working well-enough to run the test at all).

```
:-module(skynet).
:-export([start/2]).

start(Size,Div) :-
        spawn(skynet(0,Size,Div)),
        recv(Tot),
        writeln('###=> ',Tot).

skynet(Num,1,Div) :- send(Num).

skynet(Num,Size,Div) :-
    NewSize is Size div Div,
    between(1,Div,Idx),
        NewNum is Num+((Idx-1)*NewSize),
        spawn(skynet(NewNum,NewSize,Div)),
        fail.

skynet(Num,Size,Div) :- process_sum(0,Div).

process_sum(Tot,0) :- send(parent,Tot).

process_sum(Tot,Idx) :-
    recv(N),
    NewTot is Tot+N,
    NewIdx is Idx-1,
    process_sum(NewTot,NewIdx).
```

It would be trivially easy  to distribute the skynet processes over multiple nodes, as send/recv work transparently over networks as well.
