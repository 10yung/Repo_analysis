The handling of [textql](https://github.com/dinedal/textql) looks much more reasonable:

```txt
$ cat a.csv
id,name
1,john
2,lisa

$ cat b.csv
color,date
red,2020-01-01
blue,2020-01-03T14:42:35

$ csvsql --query 'select * from a join b' a.csv b.csv
id,name,color,date
1.0,john,red,2020-01-01 00:00:00.000000
1.0,john,blue,2020-01-03 14:42:35.000000
2.0,lisa,red,2020-01-01 00:00:00.000000
2.0,lisa,blue,2020-01-03 14:42:35.000000

$ textql -header -output-header -sql 'select * from a join b' a.csv b.csv
id,name,color,date
1,john,red,2020-01-01
1,john,blue,2020-01-03T14:42:35
2,lisa,red,2020-01-01
2,lisa,blue,2020-01-03T14:42:35
```
An idea, have a sed like module within csvkit. This would allow grepping based on columns, and also (more importantly) replacing values in certain columns based on regex.

Must haves:
- Ability to find lines matching the regex (for testing, appreciate this overlaps with csvgrep)
- Ability to replace the found regex

Nice to haves:
- User can provide a list of regex replacements by file
- Ability to use replacement groups

I may have a use-case for this in the near future but logging it here incase someone thinks its needed and wants to take a crack before me!
I'd love to be able to remove embedded newlines from the header row when converting an Excel file. (May even need ability to remove embedded newlines from all rows, but I haven't encountered that issue yet...)

I see issue #929 is related and may be implemented soon. The sed 1d workaround for that issue doesn't work with newlines in the header. 
I am trying to run csvstat on a simple CSV file containing sales data. I have run using `csvstat -v {csv_file_path}`. It is showing some random error. We are trying this very every other CSV we have. The same issue is being raised. We are very glad to use an awesome project in our codebase but got stuck here. 

```
Traceback (most recent call last):
  File "-----------------------/venv/bin/csvstat", line 11, in <module>
    load_entry_point('csvkit==1.0.4', 'console_scripts', 'csvstat')()
  File "-----------------------/venv/lib64/python3.6/site-packages/csvkit/utilities/csvstat.py", line 341, in launch_new_instance
    utility.run()
  File "-----------------------/venv/lib64/python3.6/site-packages/csvkit/cli.py", line 118, in run
    self.main()
  File "-----------------------/venv/lib64/python3.6/site-packages/csvkit/utilities/csvstat.py", line 140, in main
    **self.reader_kwargs
  File "-----------------------/venv/lib64/python3.6/site-packages/agate/table/from_csv.py", line 88, in from_csv
    return Table(rows, column_names, column_types, row_names=row_names)
  File "-----------------------/venv/lib64/python3.6/site-packages/agate/table/__init__.py", line 109, in __init__
    self._column_types = column_types.run(rows, self._column_names)
  File "-----------------------/venv/lib64/python3.6/site-packages/agate/type_tester.py", line 110, in run
    if len(row) > i and not column_type.test(row[i]):
  File "-----------------------/venv/lib64/python3.6/site-packages/agate/data_types/base.py", line 29, in test
    self.cast(d)
  File "-----------------------/venv/lib64/python3.6/site-packages/agate/data_types/date.py", line 76, in cast
    (value, ctx, _, _, matched_text), = self.parser.nlp(d, sourceTime=ZERO_DT)
  File "-----------------------/venv/lib64/python3.6/site-packages/parsedatetime/__init__.py", line 2233, in nlp
    version)
  File "-----------------------/venv/lib64/python3.6/site-packages/parsedatetime/__init__.py", line 1844, in parse
    retS, retTime, matched = parseMeth(s, sourceTime)
  File "-----------------------/venv/lib64/python3.6/site-packages/parsedatetime/__init__.py", line 1408, in _partialParseQUnits
    sourceTime = self._evalQUnits(parseStr, sourceTime)
  File "-----------------------/venv/lib64/python3.6/site-packages/parsedatetime/__init__.py", line 1100, in _evalQUnits
    sourceTime = self._buildTime(sourceTime, quantity, modifier, units)
  File "-----------------------/venv/lib64/python3.6/site-packages/parsedatetime/__init__.py", line 389, in _buildTime
    ctx.updateAccuracy(realunit)
  File "-----------------------/venv/lib64/python3.6/site-packages/parsedatetime/context.py", line 137, in updateAccuracy
    acc = self._ACCURACY_REVERSE_MAPPING[acc]
KeyError: 's'
```

[store.csv.zip](https://github.com/wireservice/csvkit/files/4045481/store.csv.zip)
 I have also attached the file. Please help us in this.
Is there any way to run the above command and get all CSV to a particular directory. For now, it is creating all-new CSV file to the directory where my xlsx file is present. I want to create all csv files to my desired directory.
I am a heavy user of csvsql. Thanks for creating this great tool and for making it publicly available. I am not a programmer, I created this account at Github only to contact the maintainers of csvsql.

I had a small database with about 200 lines. It always worked fine with csvsql. I added over 5000 new lines all at once, it works great like that as well. Then I added about 31.000 new lines. I can't have csvsql to process it. I checked the integrity of the csv file, and it is OK. It has no quoted cell whatsoever. It is a personal file for personal use, my personal policy is to automatically remove quotation marks.

The csv file has over 35.000 lines and when I run a query it returns an error message which does not apply to the situation: "Row 0 has 2 values, but Table only has 1 columns." Which is simply not true.

Is this a known issue? Is it solvable? Has anyone ever reported it? I can submit the csv file if you want.

I may not log in to Github soon (or ever), I only created the account to post this feedback. But you can reach me at gasconheart@rawtext.club

Greetings from Spain.
Just like the regular grep command, it would be great if csvgrep supported multiple files. The implementation would need to take in to account the column headers present in each file.

Currently, I'm using cat to achieve what I need:

`cat Files*.csv | csvgrep -c 4 -m "foo"`

This could potentially match a column header in column 4 though, which wouldn't be the desired result.
how can i  use csvkit in my python script?
I want to convert a CSV file to SQL `CREATE TABLE` and `INSERT` statements. However, `csvsql` insists on providing `--db` together with `--insert`. This is strange, as `csvsql` produces `CREATE TABLE` itself, so it knows the schema and should be able to create `INSERT` statements without any additional information.
It would be great to be able to pass in bind parameters for parameterized queries when using ```sql2csv```. Something along the lines of:

query.sql
```sql
select * from phone_book where last_name=:p_last_name;
```

Script:
```shell
sql2csv query.sql -b "p_last_name='Jones'" --db <connection string>
```
