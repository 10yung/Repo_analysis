## Issue description

Section 5 of the spam tutorial shows example of the use of the Keras classifier with labels generated by the label model (https://www.snorkel.org/use-cases/01-spam-tutorial#keras-classifier-with-probabilistic-labelskeras ). However, the test accuracy of the logreg is **90.0%**, while test accuracy of the logreg trained on the dev set only is 89.6%.  The accuracy of the Scikit-Learn with Rounded Labels is 92.8%. In addition, accuracy of the label model alone (section 4) is 92.4%.

As the test accuracy of the logreg with the label model is not great, it's difficult to see how it supports the tutorial's conclusion: "We observe an additional boost in accuracy over the LabelModel by multiple points! By using the label model to transfer the domain knowledge encoded in our LFs to the discriminative model, we were able to generalize beyond the noisy labeling heuristics."

Can you please check whether the spam tutorial is correct ?

## Code example/repro steps
See the spam tutorial

## Expected behavior
I expected a multipoint increase in test accuracy over LabelModel, as described in the tutorial.

## System info
N/A - this issue is about the spam tutorial 

## Description of proposed changes
save() and load() method for Trainer to serialize the optimizer + trainer config (dependent on whether model has been fitted with that Trainer instance)
## Related issue(s)
1416
Fixes # (issue)
1416
## Test plan
test_trainer.py adapted save_load_test()
## Checklist

Need help on these? Just ask!

* [x] I have read the **CONTRIBUTING** document.
* [ ] I have updated the documentation accordingly.
* [x] I have added tests to cover my changes.
* [ ] I have run `tox -e complex` and/or `tox -e spark` if appropriate.
* [x] All new and existing tests passed.

I have seen the tutorial on the spam classification where among other things, it is taught how to use labeling and transformation functions. But I see a limitation of the features snorkel provides when it comes to multi-class classification, as this example is strictly meant for a binary classification problem.

Isn't it better to include more features or perharps add an example where we can see the use of snorkel in order to label more than 3 classes.  

For instance I have a problem involving 20 classes. For what I see as work around is to use labeling functions per each class, for instance treating each class one at a time as if it is a binary case.

The best would be to tackle all in one go, any suggestion besides the one I am thinking about?
I first used `conda install snorkel -c conda-forge` to install snorkel on Windows 10, Anaconda 2019.10. It went successfully. Unfortunately, I got `ModuleNotFoundError: No module named 'snorkel.labeling'` error when I try to use it. Following other issues who have the same problem, I tried to use `conda install snorkel==0.9.0 -c conda-forge` to install the 0.9.0 as indicated in the readme. But I got the UnsatisfiableError:
```
UnsatisfiableError: The following specifications were found to be incompatible with each other:



Package tqdm conflicts for:
snorkel==0.9.0 -> tqdm[version='>=4.29.0,<5.0.0']
Package sqlite conflicts for:
python=3.6 -> sqlite[version='>=3.25.3,<4.0a0|>=3.26.0,<4.0a0|>=3.29.0,<4.0a0|>=3.30.1,<4.0a0']
Package numpy conflicts for:
snorkel==0.9.0 -> numpy[version='>=1.16.0,<2.0.0']
Package vc conflicts for:
python=3.6 -> vc[version='14.*|>=14,<15.0a0|>=14.1,<15.0a0']
Package pandas conflicts for:
snorkel==0.9.0 -> pandas[version='>=0.24.0,<0.25.0']
Package pip conflicts for:
python=3.6 -> pip
Package scikit-learn conflicts for:
snorkel==0.9.0 -> scikit-learn[version='>=0.20.2,<0.22.0']
Package scipy conflicts for:
snorkel==0.9.0 -> scipy[version='>=1.2.0,<2.0.0']
Package vs2015_runtime conflicts for:
python=3.6 -> vs2015_runtime[version='>=14.16.27012,<15.0a0']
Package pytorch conflicts for:
snorkel==0.9.0 -> pytorch[version='>=1.1.0,<1.2.0']
Package networkx conflicts for:
snorkel==0.9.0 -> networkx[version='>=2.2,<3.0']
Package tensorboardx conflicts for:
snorkel==0.9.0 -> tensorboardx[version='>=1.6,<2.0']
```
Hi, was wondering if there are any examples of snorkel classifier out of the box? The tutorials showcase the keras api with probabilistic labels, but curious to compare with the snorkel package. Any help appreciated. Thanks.
## Is your feature request related to a problem? Please describe.
Other dependencies for my project like torchvision==0.4.2, fast-bert==1.5.0, allennlp==0.9.0 all require that at least torch>=1.2.0, some require torch>=1.3.1, while snorkel uses 1.1.0

## Describe the solution you'd like
Update torch dependency to 1.3.1

## Describe alternatives you've considered
I can have separate environments for running snorkel and running actual NLP, but that's a messy solution and dependencies should be up to date anyways

## Is your feature request related to a problem? Please describe.

I love `snorkel.labeling.filter_unlabeled_dataframe()`. I want a pyspark equivalent: `snorkel.labeling.filter_unlabeled_spark_rdd` or `snorkel.labeling.filter_unlabeled_spark_dataframe`.

## Describe the solution you'd like

Implement the same filtering for `pyspark.sql.DataFrame`s or `pyspark.RDD`s.

## Describe alternatives you've considered

I am just implementing this myself at the moment. I don't see an alternative to this function.

## Additional context

The `numpy.ndarray` in for example `L_train` returned by `SparkLFApplier` may have to be serialized into something else so Spark can use it. `SparkLFApplier` could then optionally return this format, if it makes that easier.

## Issue description

I wanted to specify the reliability of different weakly supervised LFs to the `LabelModel`. I noticed that we can specify these as precision priors through the `prec_init` parameter to the `LabelModel.fit()` method 

https://github.com/snorkel-team/snorkel/blob/master/snorkel/labeling/model/label_model.py#L45

However, `prec_init` parameter seems to only accept scalar values. Providing an array with precision value of each LF throws the following error:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-18-e1744ea2ad84> in <module>
      7 
      8 lm = snorkel.labeling.LabelModel()
----> 9 lm.fit(L_train, prec_init=prec_init, n_epochs=1000, lr=0.001, log_freq=1, seed=123)
     10 y_pred = lm.predict(L_train)
     11 

~\AppData\Local\Continuum\anaconda3\envs\snorkel\lib\site-packages\snorkel\labeling\model\label_model.py in fit(self, L_train, Y_dev, class_balance, **kwargs)
    749             logging.info("Computing O...")
    750         self._generate_O(L_shift)
--> 751         self._init_params()
    752 
    753         # Estimate \mu

~\AppData\Local\Continuum\anaconda3\envs\snorkel\lib\site-packages\snorkel\labeling\model\label_model.py in _init_params(self)
    260         if isinstance(self.train_config.prec_init, (int, float)):
    261             self._prec_init = self.train_config.prec_init * torch.ones(self.m)
--> 262         if self._prec_init.shape[0] != self.m:
    263             raise ValueError(f"prec_init must have shape {self.m}.")
    264 

~\AppData\Local\Continuum\anaconda3\envs\snorkel\lib\site-packages\torch\nn\modules\module.py in __getattr__(self, name)
    537                 return modules[name]
    538         raise AttributeError("'{}' object has no attribute '{}'".format(
--> 539             type(self).__name__, name))
    540 
    541     def __setattr__(self, name, value):

AttributeError: 'LabelModel' object has no attribute '_prec_init'
```

## Code example/repro steps

Below is a short code snippet to reproduce this error within a jupyter notebook:

```python
import numpy as np
import snorkel.labeling

num_lfs = 10
num_samples = 10**6

L_train = np.random.randint(-1, 2, size=(num_samples, num_lfs), dtype=np.int8)

prec_init = np.random.rand(10)

lm = snorkel.labeling.LabelModel()
lm.fit(L_train, prec_init=prec_init, n_epochs=1000, lr=0.001, log_freq=1, seed=123)
y_pred = lm.predict(L_train)

df_lf_summary = snorkel.labeling.LFAnalysis(L_train).lf_summary(Y = y_pred, est_weights=lm.get_weights())
display(df_lf_summary)
```

## System info

* How you installed Snorkel (conda, pip, source): conda
* OS: Windows 10
* Python version: 3.7.4
* Snorkel version: 0.9.0


I'm trying  to extend slicing functions to  multi label classification tasks.
For the moment, snorkel only supports binary classification.
Here is the computation of slice attention
```
predictor_confidences = torch.cat(
    [
        # Compute the "confidence" using score of the positive class
        F.softmax(output, dim=1)[:, 1].unsqueeze(1)
        for output in predictor_outputs
    ],
    dim=-1,
)

attention_weights = F.softmax(
       indicator_preds * predictor_confidences / self.temperature, dim=1
)
```
My questions:
1/ Why using the prediction of the positive class as confidence score ?
2/ What should we use in multi class/ label case ?
## Is your feature request related to a problem? Please describe.
The first time a user tries to use the SpacyPreprocessor, they hit they following error:
```
  File "<stdin>", line 1, in <module>
  File "/Users/braden/anaconda3/lib/python3.7/site-packages/spacy/__init__.py", line 27, in load
    return util.load_model(name, **overrides)
  File "/Users/braden/anaconda3/lib/python3.7/site-packages/spacy/util.py", line 139, in load_model
    raise IOError(Errors.E050.format(name=name))
OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.
```

## Describe the solution you'd like
We know the line where the spacy model is called (https://github.com/snorkel-team/snorkel/blob/9af1c77cb68a31258a476e234a67d3f5e9587f53/snorkel/preprocess/nlp.py#L62) and should be able to catch that Exception and download it if its missing.
