It appears that in the rewrite of the Sonarqube Dockerfiles, the beta images no longer perform any form of validation of the artifacts being downloaded and placed into the Docker image - the only security remaining is that of the use of TLS for the HTTP connection wherein the Sonarqube zip file is downloaded.  

While there is a code path which may provide implicit trust in the event that the image is built with the zip itself locally, the other branch wherein the zip is downloaded is used as a silent failover should the zip not be correctly loaded into the image by the Dockerfile.

A correct fix would be reimplementing GPG verification of any downloaded artifacts.  Yes, GPG is a pain to deal with, but it's far better than the consequences of a successful supply chain attack.  [The docker-library org has some guidance on effective use of fault-tolerant GPG verification here.](https://github.com/docker-library/faq#openpgp--gnupg-keys-and-verification)
Please ensure your issue adheres to the following guidelines: 
when i use command "

docker run  --name local-sonarqube  -e sonar.web.context=/sonarqube  -p 8083:9000   -d sonarqube
"  i got  error info like this 
![image](https://user-images.githubusercontent.com/8716969/71436295-c75a1980-2727-11ea-8e59-e5611709bfc7.png)

the point is , when i find this , i want to edit the sonar.web.context through sonar.properties, but i con't do that, because i can't use vi/vim. also i can't use apt-get to install vim, this is so bad.

- [x] Please check the problem is not already reported, or a known issue documented in [`develop.md`](develop.md)
- [x] Please include enough details to reproduce the problem: the command executed, the host platform, error messages or relevant logs

See #360 
with SONAR-12969 the fix was only backported to 8 but not 7..

... i really need to have to have the svg-badges on the current LTS version which is not possible ATM

In the latest `7.9.x` version of SonarQube the `/opt/sonarqube/lib/bundled-plugins` directory is missing and bundling plugins in for automatic installation in a Docker image doesn't to work anymore.
This used to work fine up to 6.7.7, I haven't tried anything in-between 6.7.7 and 7.9.1.

### How to reproduce
Use the following Dockerfile:
```
FROM sonarqube:lts

RUN mkdir /opt/sonarqube/lib/bundled-plugins

ADD https://github.com/Coveros/zap-sonar-plugin/releases/download/sonar-zap-plugin-1.2.0/sonar-zap-plugin-1.2.0.jar /opt/sonarqube/lib/bundled-plugins
```

Build the image using the following command: `docker build -t sonarqube .` 
Run the new image using `docker run --name sonarqube -p 9000:9000 sonarqube`.

No plugins other than the default ones will be available.



Default plugins also used to ship in the `bundled-plugins` directory, allowing a persistent volume to be mounted  on `/opt/sonarqube/extensions/plugins` without clearing them, however this is not the case anymore (a new sonarqube instance with a volume mounted on the plugins directory results in no pre-installed plugins).

This option disables installation of recommended dependencies of the installed packages.

Canonical itself recommends using it (see https://ubuntu.com/blog/we-reduced-our-docker-images-by-60-with-no-install-recommends).

However, given the package we currently do install (`curl` `unzip` `libfreetype6` and `libfontconfig1`), the benefit are not obvious.

However, it's worth trying and confirming.
- [x] Please check the problem is not already reported, or a known issue documented in [`develop.md`](develop.md)
----------------------
Hi, 
I am facing an interesting issue where although (binaries and therefore) docker image contains (7.9.1) an initial set of plugins (check even at runtime), when container starts they are not initialized so that SQ can recognized them. Therefore SQ instance is empty, without any plugins.  

I admit to use official stable helm chart and postgres db. However, in chart i do not use any `plugins` setting. I have even tried to do this below but it still does not help. 

```
plugins:
  deleteDefaultPlugins: false
```

Did anybody else face same or similar issue. I can reproduce it in 100% of cases, both on 7.9.1 and 7.9. 
Thanks for any tips



I'm attempting to start SonarQube in an Azure Kubernetes Service environment, with a persistent volume claim, and the pod keeps failing to start with this error:

> 2019.04.11 20:21:03 INFO  app[][o.s.a.AppFileSystem] Cleaning or creating temp directory /opt/sonarqube/temp
> 2019.04.11 20:21:03 INFO  app[][o.s.a.es.EsSettings] Elasticsearch listening on /127.0.0.1:9001
> 2019.04.11 20:21:03 INFO  app[][o.s.a.p.ProcessLauncherImpl] Launch process[[key='es', ipcIndex=1, logFilenamePrefix=es]] from [/opt/sonarqube/elasticsearch]: /opt/sonarqube/elasticsearch/bin/elasticsearch
> 2019.04.11 20:21:03 INFO  app[][o.s.a.SchedulerImpl] Waiting for Elasticsearch to be up and running
> 2019.04.11 20:21:04 INFO  app[][o.e.p.PluginsService] no modules loaded
> 2019.04.11 20:21:04 INFO  app[][o.e.p.PluginsService] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
> 2019.04.11 20:21:09 WARN  app[][o.s.a.p.AbstractProcessMonitor] Process exited with exit value [es]: 1
> 2019.04.11 20:21:09 INFO  app[][o.s.a.SchedulerImpl] Process [es] is stopped
> 2019.04.11 20:21:09 INFO  app[][o.s.a.SchedulerImpl] SonarQube is stopped

A thorough internet search shows that many, many people have this exact issue, but no one has been able to solve it. It apparently relates to how elastic search refuses to be run as root user, yet this is running a docker container that runs as sonarqube user, not root, so this can't be my problem.

This is related to persistent volume use, as if I disable persistent volumes from the setup, it works just fine. This error emerges only when I try to mount a pvc with the deployment.
The sonarqube image cannot be run on an OpenShift or a secure Kubernetes cluster (https://kubernetes.io/blog/2016/08/security-best-practices-kubernetes-deployment/). Both run containers as non-root or an arbitrary user. 

For OpenShift the start of the container fails on `chown` in `run.sh`. Another problem is the `gosu` and `su-exec` (for alpine).

It would be great to change this images to support non-root containers.