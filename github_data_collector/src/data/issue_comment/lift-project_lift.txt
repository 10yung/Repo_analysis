Seems like the installation instructions are duplicated in https://lift-project.readthedocs.io/en/latest/getting-started/index.html?
I guess the later (https://lift-project.readthedocs.io/en/latest/getting-started/index.html) is much more thorough and importantly it gives quicker instructions using docker.
I propose removing the instructions in README.md and instead just pointing to https://lift-project.readthedocs.io/en/latest/getting-started/index.html.
Otherwise, it is missing step 6 onwards in [this section](https://lift-project.readthedocs.io/en/latest/getting-started/index.html#configuring-the-intellij-idea-ide-optional).
I fixed to build this Lift and [harness](https://github.com/lift-project/harness).
Dear Lift-developers,
I would like to use Lift for benchmarking the following BLAS routines:

1. asum
2. dot
3. gemm
4. gemv
5. axpy
6. scal

Can you please help me to configure Lift for these routines (especially the exploration process)?
Many thanks in advance!
Dear Lift-developers,
for benchmarking GEMM, I would like to use some self-defined input sizes. Is it sufficient to add these self-defined input sizes to the file https://github.com/lift-project/lift/blob/master/highLevel/mm.json before generating and running the OpenCL kernels? If so, can you please explain me the order of the matrix dimensions? Does each entry in the file (e.g., [512, 1024, 1024]) represent the parameters in the order 1) N (result matrix’s number of columns), 2) M (result matrix’s number of rows), and 3) K (first input matrix’s number of columns, and second input matrix’s number of rows), i.e., entries are of the form “[N,M,K]“?
Thanks in advance!
Dear Lift-developers,
I would like to gain experience with Lift. I was able to install Lift by following the instructions at http://lift-project.readthedocs.io/en/latest/. All unit tests were succesfull. I have now written a couple of high-level expressions but don't know how to generate high-performance OpenCL kernels from these. I couldn't find any documentation on this and would greatly appreciate your support.