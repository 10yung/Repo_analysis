I've upgraded my Kafka manager to 2.0.0.2 which is the latest version.
In the older version I was able to see the consumer lag and in the new version it says Lag unavailable lag. 
In the errors it says: "No jmx port but jmx polling is enabled!"
But I didn't have any issue with jmx polling in the earlier versions
It has only happened on 3 clusters out of 7
kafka cluster version v2.1.1
After 5 years, I'm glad we finally figured it out.

```
Hi, Hiral,

On behalf of the Apache Kafka PMC, I am emailing you about Yahoo Kafka manager (https://github.com/yahoo/kafka-manager).

You may not be aware of this, but Apache doesn't allow external parties to use our marks in their product names, unless a special permission is given. So, the name "kafka manager" is a misuse of Apache trademark and is not allowed. For details, please see https://www.apache.org/foundation/marks/faq/#poweredby

We understand that Kafka manager has been there for some time and has been helpful to the Kafka community. We want to thank you for the contribution. However, the trademark issue was just brought to our attention. We'd appreciate it if you could change the name accordingly. 

Thank you for your time and respect of Apache trademark. I am also cc-ing the Apache brand management for any further questions that you may have.

If you are not the right person for this, please let us know who we should contact directly.

Jun Rao
on behalf of the project management committee of Apache Kafka
```

Using docker image kafkamanager/kafka-manager:2.0.0.2. General operations work ok, but unable to connect to JXM to get metrics. Error in logs:

2020-01-09 08:16:30,657 - [ERROR] k.m.a.c.BrokerViewCacheActor - Failed to get broker metrics for BrokerIdentity(2,10.244.7.81,9192,false,true,Map(PLAINTEXT -> 9092))
java.rmi.UnknownHostException: Unknown host: ${host}; nested exception is:
java.net.UnknownHostException: ${host}
at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:616)
at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)
at sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)
at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:129)
at javax.management.remote.rmi.RMIServerImpl_Stub.newClient(Unknown Source)
at javax.management.remote.rmi.RMIConnector.getConnection(RMIConnector.java:2430)
at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:308)
at javax.management.remote.JMXConnectorFactory.connect(JMXConnectorFactory.java:270)
at kafka.manager.jmx.KafkaJMX$.doWithConnection(KafkaJMX.scala:57)
at kafka.manager.actor.cluster.BrokerViewCacheActor.$anonfun$updateBrokerMetrics$3(BrokerViewCacheActor.scala:359)
Caused by: java.net.UnknownHostException: ${host}
at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)
at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
at java.net.Socket.connect(Socket.java:589)
at java.net.Socket.connect(Socket.java:538)
at java.net.Socket.<init>(Socket.java:434)
at java.net.Socket.<init>(Socket.java:211)
at sun.rmi.transport.proxy.RMIDirectSocketFactory.createSocket(RMIDirectSocketFactory.java:40)
at sun.rmi.transport.proxy.RMIMasterSocketFactory.createSocket(RMIMasterSocketFactory.java:148)
at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:613)
at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)
Is there a way to bind the listen address to localhost instead of 0:0:0:0:9000 ?

sample logs:
[info] k.m.a.DeleteClusterActor - Scheduling updater for 10 seconds
[info] k.m.a.KafkaManagerActor - Adding kafka manager path cache listener...
[info] play.api.Play - Application started (Prod)
[info] p.c.s.NettyServer - Listening for HTTP on /0:0:0:0:0:0:0:0:9000
[info] k.m.a.KafkaManagerActor - Updating internal state...
when i use the function of delete topic it will discover this msg :"yikes! KeeperErrorCode = NoAuth for /admin/delete_topics/" ,i thought Is it related to Kerberos authenticationï¼Ÿmaybe or not
[root@master kafka-manager-2.0.0.2]# sbt clean dist
[info] Loading settings for project kafka-manager-2-0-0-2-build from plugins.sbt ...
[info] Loading project definition from /crt/kafka-manager-2.0.0.2/project
[info] Updating ProjectRef(uri("file:/crt/kafka-manager-2.0.0.2/project/"), "kafka-manager-2-0-0-2-build")...
[error] java.lang.NoClassDefFoundError: okio/Source
[error] 	at sbt.internal.librarymanagement.IvySbt.gigahorseUrlHandler$lzycompute(Ivy.scala:83)
[error] 	at sbt.internal.librarymanagement.IvySbt.gigahorseUrlHandler(Ivy.scala:83)
[error] 	at sbt.internal.librarymanagement.IvySbt.settings$lzycompute(Ivy.scala:100)
[error] 	at sbt.internal.librarymanagement.IvySbt.sbt$internal$librarymanagement$IvySbt$$settings(Ivy.scala:85)
[error] 	at sbt.internal.librarymanagement.IvySbt.ivyLockFile$lzycompute(Ivy.scala:190)
[error] 	at sbt.internal.librarymanagement.IvySbt.ivyLockFile(Ivy.scala:190)
[error] 	at sbt.internal.librarymanagement.IvySbt.withDefaultLogger(Ivy.scala:77)
[error] 	at sbt.internal.librarymanagement.IvySbt.withIvy(Ivy.scala:199)
[error] 	at sbt.internal.librarymanagement.IvySbt.withIvy(Ivy.scala:196)
[error] 	at sbt.internal.librarymanagement.IvySbt$Module.withModule(Ivy.scala:238)
[error] 	at sbt.internal.librarymanagement.IvyActions$.updateEither(IvyActions.scala:193)
[error] 	at sbt.librarymanagement.ivy.IvyDependencyResolution.update(IvyDependencyResolution.scala:20)
[error] 	at sbt.librarymanagement.DependencyResolution.update(DependencyResolution.scala:56)
[error] 	at sbt.internal.LibraryManagement$.resolve$1(LibraryManagement.scala:45)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$12(LibraryManagement.scala:93)
[error] 	at sbt.util.Tracked$.$anonfun$lastOutput$1(Tracked.scala:68)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$19(LibraryManagement.scala:106)
[error] 	at scala.util.control.Exception$Catch.apply(Exception.scala:224)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11(LibraryManagement.scala:106)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11$adapted(LibraryManagement.scala:89)
[error] 	at sbt.util.Tracked$.$anonfun$inputChanged$1(Tracked.scala:149)
[error] 	at sbt.internal.LibraryManagement$.cachedUpdate(LibraryManagement.scala:120)
[error] 	at sbt.Classpaths$.$anonfun$updateTask$5(Defaults.scala:2561)
[error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:44)
[error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:40)
[error] 	at sbt.std.Transform$$anon$4.work(System.scala:67)
[error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:269)
[error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16)
[error] 	at sbt.Execute.work(Execute.scala:278)
[error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:269)
[error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)
[error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
[error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
[error] 	at java.lang.Thread.run(Thread.java:745)
[error] Caused by: java.lang.ClassNotFoundException: okio.Source
[error] 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
[error] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
[error] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
[error] 	at sbt.internal.librarymanagement.IvySbt.gigahorseUrlHandler$lzycompute(Ivy.scala:83)
[error] 	at sbt.internal.librarymanagement.IvySbt.gigahorseUrlHandler(Ivy.scala:83)
[error] 	at sbt.internal.librarymanagement.IvySbt.settings$lzycompute(Ivy.scala:100)
[error] 	at sbt.internal.librarymanagement.IvySbt.sbt$internal$librarymanagement$IvySbt$$settings(Ivy.scala:85)
[error] 	at sbt.internal.librarymanagement.IvySbt.ivyLockFile$lzycompute(Ivy.scala:190)
[error] 	at sbt.internal.librarymanagement.IvySbt.ivyLockFile(Ivy.scala:190)
[error] 	at sbt.internal.librarymanagement.IvySbt.withDefaultLogger(Ivy.scala:77)
[error] 	at sbt.internal.librarymanagement.IvySbt.withIvy(Ivy.scala:199)
[error] 	at sbt.internal.librarymanagement.IvySbt.withIvy(Ivy.scala:196)
[error] 	at sbt.internal.librarymanagement.IvySbt$Module.withModule(Ivy.scala:238)
[error] 	at sbt.internal.librarymanagement.IvyActions$.updateEither(IvyActions.scala:193)
[error] 	at sbt.librarymanagement.ivy.IvyDependencyResolution.update(IvyDependencyResolution.scala:20)
[error] 	at sbt.librarymanagement.DependencyResolution.update(DependencyResolution.scala:56)
[error] 	at sbt.internal.LibraryManagement$.resolve$1(LibraryManagement.scala:45)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$12(LibraryManagement.scala:93)
[error] 	at sbt.util.Tracked$.$anonfun$lastOutput$1(Tracked.scala:68)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$19(LibraryManagement.scala:106)
[error] 	at scala.util.control.Exception$Catch.apply(Exception.scala:224)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11(LibraryManagement.scala:106)
[error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11$adapted(LibraryManagement.scala:89)
[error] 	at sbt.util.Tracked$.$anonfun$inputChanged$1(Tracked.scala:149)
[error] 	at sbt.internal.LibraryManagement$.cachedUpdate(LibraryManagement.scala:120)
[error] 	at sbt.Classpaths$.$anonfun$updateTask$5(Defaults.scala:2561)
[error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:44)
[error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:40)
[error] 	at sbt.std.Transform$$anon$4.work(System.scala:67)
[error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:269)
[error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16)
[error] 	at sbt.Execute.work(Execute.scala:278)
[error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:269)
[error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)
[error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
[error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
[error] 	at java.lang.Thread.run(Thread.java:745)
[error] (update) java.lang.NoClassDefFoundError: okio/Source



java version 1.8.0_121
3Q



First time trying Kafka-manager and off to a good start but I can't get it talking to zookeeper correctly. ...Here is my config:
```
# Copyright 2015 Yahoo Inc. Licensed under the Apache License, Version 2.0
# See accompanying LICENSE file.

# This is the main configuration file for the application.
# ~~~~~

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
play.crypto.secret="^<csmm5Fx4d=r2HEX8pelM3iBkFVv?k[mc;IZE<_Qoq8EkX_/7@Zt6dP05Pzea3U"
play.crypto.secret=${?APPLICATION_SECRET}
play.http.session.maxAge="1h"

# The application languages
# ~~~~~
play.i18n.langs=["en"]

play.http.requestHandler = "play.http.DefaultHttpRequestHandler"
play.http.context = "/"
play.application.loader=loader.KafkaManagerLoader

kafka-manager.zkhosts="zookeeper1t.eu-central-1.pipedrive.net:2181"
kafka-manager.zkhosts=${?ZK_HOSTS}
pinned-dispatcher.type="PinnedDispatcher"
pinned-dispatcher.executor="thread-pool-executor"
application.features=["KMClusterManagerFeature","KMTopicManagerFeature","KMPreferredReplicaElectionFeature","KMReassignPartitionsFeature"]

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "INFO"
}

akka.logger-startup-timeout = 60s

basicAuthentication.enabled=false
basicAuthentication.enabled=${?KAFKA_MANAGER_AUTH_ENABLED}

basicAuthentication.ldap.enabled=false
basicAuthentication.ldap.enabled=${?KAFKA_MANAGER_LDAP_ENABLED}
basicAuthentication.ldap.server=""
basicAuthentication.ldap.server=${?KAFKA_MANAGER_LDAP_SERVER}
basicAuthentication.ldap.port=389
basicAuthentication.ldap.port=${?KAFKA_MANAGER_LDAP_PORT}
basicAuthentication.ldap.username=""
basicAuthentication.ldap.username=${?KAFKA_MANAGER_LDAP_USERNAME}
basicAuthentication.ldap.password=""
basicAuthentication.ldap.password=${?KAFKA_MANAGER_LDAP_PASSWORD}
basicAuthentication.ldap.search-base-dn=""
basicAuthentication.ldap.search-base-dn=${?KAFKA_MANAGER_LDAP_SEARCH_BASE_DN}
basicAuthentication.ldap.search-filter="(uid=$capturedLogin$)"
basicAuthentication.ldap.search-filter=${?KAFKA_MANAGER_LDAP_SEARCH_FILTER}
basicAuthentication.ldap.group-filter=""
basicAuthentication.ldap.group-filter=${?KAFKA_MANAGER_LDAP_GROUP_FILTER}
basicAuthentication.ldap.connection-pool-size=10
basicAuthentication.ldap.connection-pool-size=${?KAFKA_MANAGER_LDAP_CONNECTION_POOL_SIZE}
basicAuthentication.ldap.ssl=false
basicAuthentication.ldap.ssl=${?KAFKA_MANAGER_LDAP_SSL}

basicAuthentication.username="admin"
basicAuthentication.username=${?KAFKA_MANAGER_USERNAME}
basicAuthentication.password="password"
basicAuthentication.password=${?KAFKA_MANAGER_PASSWORD}

basicAuthentication.realm="Kafka-Manager"
basicAuthentication.excluded=["/api/health"] # ping the health of your instance without authentification

kafka-manager.consumer.properties.file=${?CONSUMER_PROPERTIES_FILE}
```
The only change here is resolvable address zookeeper1t.eu-central-1.pipedrive.net:2181.

Im passing a jaas file to kafka-manager ( ./kafka-manager -Djava.security.auth.login.config=/Users/jesse/Desktop/zookeeper_jaas.conf)

```
Client {
  org.apache.zookeeper.server.auth.DigestLoginModule required
  username="cluster_admin"
  password="xxxx";
};
```
The only obvious error's i see are :
ERROR in ch.qos.logback.core.rolling.RollingFileAppender[FILE] - Failed to create parent directories for [/Users/jesse/Desktop/kafka-manager/kafka-manager-master/target/universal/kafka-manager-2.0.0.2/application.home_IS_UNDEFINED/logs/application.log]

And

ERROR in ch.qos.logback.core.rolling.RollingFileAppender[FILE] - openFile(application.home_IS_UNDEFINED/logs/application.log,true) call failed. java.io.FileNotFoundException: application.home_IS_UNDEFINED/logs/application.log (No such file or directory)

The connections looks good?
```
2019-12-05 14:13:06,449 - [INFO] o.a.z.ZooKeeper - Initiating client connection, connectString=zookeeper1t.eu-central-1.pipedrive.net:2181 sessionTimeout=60000 watcher=org.apache.curator.ConnectionState@5fa2e5f0
2019-12-05 14:13:06,477 - [INFO] k.m.a.KafkaManagerActor - zk=zookeeper1t.eu-central-1.pipedrive.net:2181
2019-12-05 14:13:06,477 - [INFO] k.m.a.KafkaManagerActor - baseZkPath=/kafka-manager
2019-12-05 14:13:06,630 - [INFO] o.a.z.Login - Client successfully logged in.
2019-12-05 14:13:06,634 - [INFO] o.a.z.c.ZooKeeperSaslClient - Client will use DIGEST-MD5 as SASL mechanism.
2019-12-05 14:13:06,704 - [INFO] play.api.Play - Application started (Prod)
2019-12-05 14:13:06,705 - [INFO] o.a.z.ClientCnxn - Opening socket connection to server zookeeper1t.eu-central-1.pipedrive.net/x.x.x.x:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
2019-12-05 14:13:06,801 - [INFO] o.a.z.ClientCnxn - Socket connection established to zookeeper1t.eu-central-1.pipedrive.net/x.x.x.x:2181, initiating session
2019-12-05 14:13:06,878 - [INFO] o.a.z.ClientCnxn - Session establishment complete on server zookeeper1t.eu-central-1.pipedrive.net/x.x.x.x:2181, sessionid = 0x101d358a7ed06e7, negotiated timeout = 40000
```

The basic UI loads but no clusters are shown. Any advice on how to proceed would be greatly appreciated, thanks!
I am trying to setup LDAP authentication with our AD environment. 

`
basicAuthentication.enabled=true
#basicAuthentication.realm="Kafka-Manager"
#basicAuthentication.username="admin"
#basicAuthentication.password="password"
basicAuthentication.excluded=["/api/health"] # ping the health of your instance without authentification

basicAuthentication.ldap.enabled=true
basicAuthentication.ldap.server="ad-server.domain.local"
basicAuthentication.ldap.port=389
basicAuthentication.ldap.username="CN=Kafka Service,OU=Kafka,OU=Prod,OU=Service,DC=Domain,DC=local"
basicAuthentication.ldap.password="password"
basicAuthentication.ldap.search-base-dn="dc=domain,dc=local"
basicAuthentication.ldap.connection-pool-size=10
basicAuthentication.ldap.ssl=false
`

For the search filter (which I think is where my issue is), I've tried a few different ways:
`basicAuthentication.ldap.search-filter="(uid=$capturedLogin$)"
basicAuthentication.ldap.search-filter="CN=Kafka 
Admins,OU=Groups,OU=Prod,OU=Service,DC=Domain,DC=local"
`
and
`basicAuthentication.ldap.search-filter="(&(cn=%u)(memberOf=CN=Kafka Admins,OU=Groups,OU=Prod,OU=Service,DC=Domain,DC=local))"
`
No matter what I try I end up in a login loop (no error), and do not believe it is querying the account from the group in the search filter properly. I've enabled DEBUG logging and it does not output anything at all. 

I also feel like there should be a setting for me to associate the sAMAccountName or userPrinipalName from the users attributes. 

Thanks for any help here! 