Does it only counts collisions or handle them as well?
If I want to build my own hash table with MurmurHash, how should I handle collisions...?

Thank you,
Is it possible to add Adler32 

Will there ever be a 256-bit version of MurMur for avoiding hash collisions in larger datasets?
In MurmurHash3.cpp, there's some care to point out that `getblock32 and `getblock64` are customization points for alignment and endianness as data is loaded from the `void* key`.

https://github.com/aappleby/smhasher/blob/61a0530f28277f2e850bfc39600ce61d02b518de/src/MurmurHash3.cpp#L52-L53

But there are alignment and endian issues with writing to the `void* out` parameters as well. For example, lines like: `((uint64_t*)out)[1] = h2;`. Maybe add analogous `putblock32`, `putblock64` functions as customization points.

    void putblock32( void* p, int i, uint32_t t ) {
      memcpy((char*)p + i * sizeof(t), &t, sizeof(t));
    }
    void putblock64( void* p, int i, uint64_t t ) {
      memcpy((char*)p + i * sizeof(t), &t, sizeof(t));
    }

    // ...so, 
    putblock64(out, 0, h1);  // formerly `((uint64_t*)out)[0] = h1;`
    putblock64(out, 1, h2);  // formerly `((uint64_t*)out)[1] = h2;`

I'm not sure it's technically ok to even form the unaligned pointers in the first place. That is, I don't think it's safe C++ to cast a `void*` to `uint32_t*` unless it's aligned appropriately.

I tried to test but it might take a while... 
Hi,
I was just looking at possibly using MurmurHash3 in a project and I'm assuming if I called MurmurHash3_x64_128 then each of the 64 bit values returned will contain a random value between 1 and the maximum value of an unsigned 64 value (i.e. 18446744073709551615). I wanted to check is there a way I could limit either or both 64 bit values to the maximum size of a signed 64 bit value (i.e. 9223372036854775807)?

Thanks

Hello, I noticed that when you compile with "-Wextra", "-Wall", etc., gcc complains that "this statement may fall through" in the `switch` cases. The idea is to warn the programmer that the "standard" is to use a `break` statement. Assuming you do want to go through all cases, maybe you can add a ` __attribute__ ((fallthrough));` in the cases?  ( https://developers.redhat.com/blog/2017/03/10/wimplicit-fallthrough-in-gcc-7/ ) Something like
```
switch(len & 15) {
    case 15: k2 ^= (uint64_t)(tail[14]) << 48;  __attribute__ ((fallthrough));
    case 14: k2 ^= (uint64_t)(tail[13]) << 40;  __attribute__ ((fallthrough));
//etc
```
`src/crc.cpp` is a very simple CRC-32 implementation. SIMD implementations can be more than 14x faster.

See https://fastcompression.blogspot.com/2019/03/presenting-xxh3.html?showComment=1552693962180#c8263190774970267162
The last mixing steps in the loops of murmur2 and murmur2A do:
```
h *= m; h ^= k;
```
And similar in murmur64B:
```
h1 *= m; h1 ^= k1;
.....
h2 *= m; h2 ^= k2;
```
But in murmur64A, they are reversed:
```
h ^= k;
h *= m;
```

Is that intentional?  If so, curious as to why.
Thanks!