
Thank you very much for your contribution but I have a question.
I need to train the RNN model for digital data( A time series in numerical form).Finally, I need to classify or predict the data.
But I don't know how to change the database and what parameters to modify.
First of all, I'm confused as of how the `save_dir` works: if I train a network pointing to a directory, and then eventually train another one pointing to that same one, it seems like it overwrites properly the older data, but does not clear the extra-data from the older model. I think this is what caused the `assert saved_chars == data_loader.chars, "Data and loaded model disagree on character set!"` to trigger.

Secondly, is this a correct way of using the command: `python sample.py -n=10000 --save_dir=testSave` ?

Thirdly, what is the `prime` attribute of the `sample` ? And why does `python sample.py` take so long to execute?

Lastly, I'm wondering if I'm using the code properly since I have only downloaded the CPU version of TensorFlow. However, your documentation mentions that I we are supposed to add some lines of code, but not where: would you mind explaining a bit more the process if I want to use the CPU way? :)

Thank you so much! This is pretty neat. Currently teaching the Network to come up with fake laws, haha.
sorry,this is a test.
Is it possible to export this model into TFlite? Would i have to convert the model into a TFLite flatbuffer
This PR is the same as https://github.com/sherjilozair/char-rnn-tensorflow/pull/28, but merge conflicts are fixed. I also got rid of the assignment to `self.probs` in the constructor (because it's overwritten) and moved the calculation out of the loop in `sample()`.

Someone did comment here about not wanting to overwrite the default (temperature = 1) probs: https://github.com/sherjilozair/char-rnn-tensorflow/pull/28#issuecomment-256207983. Not sure if this is still a concern.
I created a route localhost:5050/predict to run the model with the given statement.
```
{
    "statement": "You helped the customer in troubleshooting the Cable issue and you asked "
}
```

but It gives error below error:
```
  File "C:\Users\surinder.kumar01\AppData\Local\conda\conda\envs\tia\lib\site-packages\flask_restful\__init__.py", line 595, in dispatch_request
    resp = meth(*args, **kwargs)
  File "D:\surinder\ds\test\text_classification_projects\char-rnn-tensorflow\wordpredict.py", line 45, in post
    saver = tf.train.Saver()
  File "C:\Users\surinder.kumar01\AppData\Local\conda\conda\envs\tia\lib\site-packages\tensorflow\python\training\saver.py", line 1311, in __init__
    self.build()
  File "C:\Users\surinder.kumar01\AppData\Local\conda\conda\envs\tia\lib\site-packages\tensorflow\python\training\saver.py", line 1320, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File "C:\Users\surinder.kumar01\AppData\Local\conda\conda\envs\tia\lib\site-packages\tensorflow\python\training\saver.py", line 1345, in _build
    raise ValueError("No variables to save")
ValueError: No variables to save
```

Here is the code:

```
from __future__ import print_function
import os
from six.moves import cPickle
import tensorflow as tf
from model import Model

from flask import Flask, request
from flask_restful import Resource, Api

app = Flask(__name__)
api = Api(app)

params = {
    'save_dir': 'save',
    'prime': '',
    'n': 500,
    'sample': 2
}


def get_model():
    with open(os.path.join(params['save_dir'], 'config.pkl'), 'rb') as f:
        saved_args = cPickle.load(f)
    with open(os.path.join(params['save_dir'], 'chars_vocab.pkl'), 'rb') as f:
        chars, vocab = cPickle.load(f)
    return chars, vocab, Model(saved_args, training=False)


class predict(Resource):

    chars, vocab, model = get_model()

    def sample(self, statement, args, chars, vocab, model, saver, ckpt):
        with tf.Session() as sess:
            if ckpt and ckpt.model_checkpoint_path:
                saver.restore(sess, ckpt.model_checkpoint_path)
                result = model.sample(sess, chars, vocab, args['n'], statement, args['sample']).encode('utf-8')
                return result

    def post(self):
        statement = request.get_json(silent=True)['statement']
        result = None

        # tf.global_variables_initializer().run()
        saver = tf.train.Saver()
        ckpt = tf.train.get_checkpoint_state(params['save_dir'])
        # with tf.Session() as sess:
        result = self.sample(
            statement, params, predict.chars,
            predict.vocab, predict.model, saver, ckpt
        ).decode('utf-8').split(".")[0]
        return {
            'statement': statement,
            'full_statement': result
        }

api.add_resource(predict, '/')

if __name__ == "__main__":
    app.run(debug=True)
```

Please help.
I changed network size from 2 layers to 4 layers and I changed batch size to 1, now after about 30 epochs I see pelpxerity starting to increase, which is, I think, unexpected.

First about 25 epochs it decreases, but then it starts behaving weirdly, and resulting model is worse than before 25 epochs. Is this a bug?

Here is my tensorboard plot. As you can see at the botton graphs, perlexilty is fluctuating (bottom right plot). Why is that happening?

![](https://user-images.githubusercontent.com/38354752/38828951-e770b53c-41b7-11e8-848e-f7dfa67e8711.png)
I used the program all the day and it worked great but with my last experiment I got the following error message:

Traceback (most recent call last):
  File "sample.py", line 46, in <module>
    main()
  File "sample.py", line 27, in main
    sample(args)
  File "sample.py", line 43, in sample
    args.sample).encode('utf-8'))
  File "C:\Daten\Programmierung\Python\JokeGenerator\char-rnn-tensorflow-master\char-rnn-tensorflow-master\model.py", line 106, in sample
    x[0, 0] = vocab[char]
KeyError: ' '

Seems like anything is wrong with the arguments, but I haven't changed anything.
BTW, really nice program & fun to use. Thank you.
when generating texts from shakespeare's text as input text a lot of \n are present. Any solution for this ?