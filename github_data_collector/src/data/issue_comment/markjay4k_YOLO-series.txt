getting the below error while importing the darkflow.net.build import TFNet


ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-1-17de757420c4> in <module>
      1 import cv2
----> 2 from darkflow.net.build import TFNet
      3 import matplotlib.pyplot as plt
      4 
      5 get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'svg'")

~/darkflow/darkflow/net/build.py in <module>
      5 from .ops import op_create, identity
      6 from .ops import HEADER, LINE
----> 7 from .framework import create_framework
      8 from ..dark.darknet import Darknet
      9 import json

~/darkflow/darkflow/net/framework.py in <module>
----> 1 from . import yolo
      2 from . import yolov2
      3 from . import vanilla
      4 from os.path import basename
      5 

~/darkflow/darkflow/net/yolo/__init__.py in <module>
      1 from . import train
----> 2 from . import predict
      3 from . import data
      4 from . import misc
      5 import numpy as np

~/darkflow/darkflow/net/yolo/predict.py in <module>
      5 import os
      6 import json
----> 7 from ...cython_utils.cy_yolo_findboxes import yolo_box_constructor
      8 
      9 def _fix(obj, dims, scale, offs):

ModuleNotFoundError: No module named 'darkflow.cython_utils.cy_yolo_findboxes'

Hi, I am trying to train custom object detection to detect my company-logo, everything went well until this error, I also deleted and annotated images again but it no change in the outcome. Can someone please help me with this
Thank You


```
cfg/tiny-yolo-voc-1c.cfg parsing annotations_clean
Parsing for ['vodafone']
[====================>]100%  Image9.xml
Statistics:
vodafone: 28
Dataset size: 28
Dataset of 28 instance(s)
Image12.jpg
Traceback (most recent call last):
  File "flow", line 6, in <module>
    cliHandler(sys.argv)
  File "C:\Users\karanbari\Desktop\YOLO\darkflow-master\darkflow\cli.py", line 33, in cliHandler
    print('Enter training ...'); tfnet.train()
  File "C:\Users\karanbari\Desktop\YOLO\darkflow-master\darkflow\net\flow.py", line 39, in train
    for i, (x_batch, datum) in enumerate(batches):
  File "C:\Users\karanbari\Desktop\YOLO\darkflow-master\darkflow\net\yolo\data.py", line 114, in shuffle
    inp, new_feed = self._batch(train_instance)
  File "C:\Users\karanbari\Desktop\YOLO\darkflow-master\darkflow\net\yolov2\data.py", line 28, in _batch
    img = self.preprocess(path, allobj)
  File "C:\Users\karanbari\Desktop\YOLO\darkflow-master\darkflow\net\yolo\predict.py", line 62, in preprocess
    result = imcv2_affine_trans(im)
  File "C:\Users\karanbari\Desktop\YOLO\darkflow-master\darkflow\utils\im_transform.py", line 20, in imcv2_affine_trans
    h, w, c = im.shape
AttributeError: 'NoneType' object has no attribute 'shape'
```

This is the corresponding .xml file:

```
<annotation>
  <folder>images\train_clean</folder>
  <filename>Image12.jpg</filename>
  <segmented>0</segmented>
  <size>
    <width>446</width>
    <height>113</height>
    <depth>3</depth>
  </size>
  <object>
    <name>vodafone</name>
    <pose>Unspecified</pose>
    <truncated>0</truncated>
    <difficult>0</difficult>
    <bndbox>
      <xmin>0</xmin>
      <ymin>0</ymin>
      <xmax>115</xmax>
      <ymax>111</ymax>
    </bndbox>
  </object>
</annotation>
```

Hey Mark! Thank you for your tutorials on YOLO! But I am getting this error when I am going to train my own model and the error is:


cfg/tiny-yolo-voc-1c.cfg parsing new_model_dir/annotations
Parsing for ['gun'] 
[====================>]100%  000188.xml
Statistics:
gun: 235
Dataset size: 158
Dataset of 158 instance(s)
libpng warning: iCCP: known incorrect sRGB profile
Traceback (most recent call last):
  File "flow", line 6, in <module>
    cliHandler(sys.argv)
  File "/content/drive/My Drive/WHAT THE/darkflow/darkflow/cli.py", line 33, in cliHandler
    print('Enter training ...'); tfnet.train()
  File "/content/drive/My Drive/WHAT THE/darkflow/darkflow/net/flow.py", line 39, in train
    for i, (x_batch, datum) in enumerate(batches):
  File "/content/drive/My Drive/WHAT THE/darkflow/darkflow/net/yolo/data.py", line 114, in shuffle
    inp, new_feed = self._batch(train_instance)
  File "/content/drive/My Drive/WHAT THE/darkflow/darkflow/net/yolov2/data.py", line 27, in _batch
    img = self.preprocess(path, allobj)
  File "/content/drive/My Drive/WHAT THE/darkflow/darkflow/net/yolo/predict.py", line 71, in preprocess
    im = imcv2_recolor(im)
  File "/content/drive/My Drive/WHAT THE/darkflow/darkflow/utils/im_transform.py", line 11, in imcv2_recolor
    im = im * (1 + t * a)
ValueError: operands could not be broadcast together with shapes (520,1200,4) (3,) 

Any idea how to get rid of it please?
**code**
xml_str = ET.tostring(annotation)
	print(xml_str)
	root = etree.fromstring(xml_str)
	xml_str=etree.tostring(root, pretty_print=True)
	save_path = os.path.join(savedir, img.name.replace('jpg','xml'))
	with open(save_path,'wb') as temp_xml:
		temp_xml.write(xml_str)
**Error**
Traceback (most recent call last):
  File "C:\Users\subha\AppData\Local\Programs\Python\Python36\lib\site-packages\matplotlib\cbook\__init__.py", line 216, in process
    func(*args, **kwargs)
  File "make_annotation.py", line 31, in onkeypress
    write_xml(image_folder, img, object_list, tl_list, br_list, savedir)
  File "C:\VIT\SET\CODE\darkflow-master\new_model_data\generate_annotation.py", line 36, in write_xml
    root = etree.fromstring(xml_str)
  File "src\lxml\etree.pyx", line 3234, in lxml.etree.fromstring
  File "src\lxml\parser.pxi", line 1876, in lxml.etree._parseMemoryDocument
  File "src\lxml\parser.pxi", line 1764, in lxml.etree._parseDoc
  File "src\lxml\parser.pxi", line 1127, in lxml.etree._BaseParser._parseDoc
  File "src\lxml\parser.pxi", line 601, in lxml.etree._ParserContext._handleParseResultDoc
  File "src\lxml\parser.pxi", line 711, in lxml.etree._handleParseResult
  File "src\lxml\parser.pxi", line 640, in lxml.etree._raiseParseError
  File "<string>", line 1
lxml.etree.XMLSyntaxError: StartTag: invalid element name, line 1, column 237
**xml_str contains**
b'<annotation><folder>images</folder><filename>real_00001.jpg</filename><segmented>0</segmented><size><width>600</width><height>600</height><depth>3</depth></size><object><name>faces</name><pose>Unspecified</pose><truncated>0</truncated>< difficult>0</ difficult><bndbox><xmin>2</xmin><ymin>1</ymin><xmax>598</xmax><ymax>597</ymax></bndbox></object></annotation>'
Straightforward code.
Last part of my tiny-yolo-voc-1c.cfg file:

```
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=125
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=30
activation=linear

[region]
anchors = 1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52
bias_match=1
classes=1
coords=4
num=5
softmax=1
jitter=.2
rescore=1

object_scale=5
noobject_scale=1
class_scale=1
coord_scale=1

absolute=1
thresh = .5
random=1
```

Even after i trained for 6 hours on gpu the loss seems to reduce very slowly and it was above 90.
Here is a small sample after epoch 3 and epoch 16:

Right now the training goes like this:

Epoch 3:

step 100 - loss 105.87599182128906 - moving ave loss 105.92378855073041 step 101 - loss 105.90802001953125 - moving ave loss 105.92221169761049 step 102 - loss 105.96070861816406 - moving ave loss 105.92606138966585 step 103 - loss 105.91077423095703 - moving ave loss 105.92453267379497 step 104 - loss 105.89263916015625 - moving ave loss 105.9213433224311 step 105 - loss 105.79179382324219 - moving ave loss 105.9083883725122 step 106 - loss 105.97239685058594 - moving ave loss 105.91478922031959 step 107 - loss 105.93550109863281 - moving ave loss 105.91686040815092 step 108 - loss 105.82689666748047 - moving ave loss 105.90786403408389 step 109 - loss 105.89955139160156 - moving ave loss 105.90703276983565 step 110 - loss 105.97517395019531 - moving ave loss 105.91384688787163 step 111 - loss 105.94683074951172 - moving ave loss 105.91714527403565 Finish 3 epoch(es) step 112 - loss 105.88888549804688 - moving ave loss 105.91431929643677 step 113 - loss 105.77619934082031 - moving ave loss 105.90050730087513 step 114 - loss 106.05404663085938 - moving ave loss 105.91586123387356 step 115 - loss 105.96916198730469 - moving ave loss 105.92119130921667 step 116 - loss 105.88710021972656 - moving ave loss 105.91778220026767 step 117 - loss 105.81925201416016 - moving ave loss 105.90792918165691 step 118 - loss 105.8878173828125 - moving ave loss 105.90591800177248 step 119 - loss 105.89876556396484 - moving ave loss 105.90520275799172 step 120 - loss 105.86831665039062 - moving ave loss 105.90151414723161 step 121 - loss 105.82453918457031 - moving ave loss 105.89381665096549 step 122 - loss 105.72496795654297 - moving ave loss 105.87693178152324 step 123 - loss 105.88580322265625 - moving ave loss 105.87781892563655

Epoch 16:

step 592 - loss 104.63841247558594 - moving ave loss 104.63666866604511 Finish 16 epoch(es) step 593 - loss 104.696533203125 - moving ave loss 104.6426551197531 step 594 - loss 104.6519775390625 - moving ave loss 104.64358736168404 step 595 - loss 104.64488220214844 - moving ave loss 104.64371684573048 step 596 - loss 104.63302612304688 - moving ave loss 104.64264777346212 step 597 - loss 104.54460144042969 - moving ave loss 104.63284314015887 step 598 - loss 104.62289428710938 - moving ave loss 104.63184825485394 step 599 - loss 104.47380065917969 - moving ave loss 104.61604349528652 step 600 - loss 104.67867279052734 - moving ave loss 104.6223064248106 step 601 - loss 104.47022247314453 - moving ave loss 104.60709802964399 step 602 - loss 104.56214904785156 - moving ave loss 104.60260313146475 step 603 - loss 104.53447723388672 - moving ave loss 104.59579054170695 step 604 - loss 104.71623229980469 - moving ave loss 104.60783471751672 step 605 - loss 104.48993682861328 - moving ave loss 104.59604492862638 step 606 - loss 104.55252838134766 - moving ave loss 104.59169327389851 step 607 - loss 104.4090576171875 - moving ave loss 104.57342970822742 step 608 - loss 104.76617431640625 - moving ave loss 104.5927041690453 step 609 - loss 104.65669250488281 - moving ave loss 104.59910300262905 step 610 - loss 104.4439697265625 - moving ave loss 104.5835896750224 step 611 - loss 104.50250244140625 - moving ave loss 104.57548095166078 step 612 - loss 104.66641235351562 - moving ave loss 104.58457409184626 step 613 - loss 104.51042175292969 - moving ave loss 104.57715885795461 step 614 - loss 104.57950592041016 - moving ave loss 104.57739356420016 step 615 - loss 104.4698257446289 - moving ave loss 104.56663678224304 step 616 - loss 104.62855529785156 - moving ave loss 104.5728286338039 step 617 - loss 104.53482818603516 - moving ave loss 104.56902858902703 step 618 - loss 104.41508483886719 - moving ave loss 104.55363421401105 step 619 - loss 104.50767517089844 - moving ave loss 104.5490383096998

So As you can see its taking too much time and their is no significant progress.
I have also posted in stackoverflow #57143339
import os
import urllib.request as ulib
from bs4 import BeautifulSoup as Soup
import json

url_a = 'https://www.google.com/search?ei=1m7NWePfFYaGmQG51q7IBg&hl=en&q={}'
url_b = '\&tbm=isch&ved=0ahUKEwjjovnD7sjWAhUGQyYKHTmrC2kQuT0I7gEoAQ&start={}'
url_c = '\&yv=2&vet=10ahUKEwjjovnD7sjWAhUGQyYKHTmrC2kQuT0I7gEoAQ.1m7NWePfFYaGmQG51q7IBg'
url_d = '\.i&ijn=1&asearch=ichunk&async=_id:rg_s,_pms:s'
url_base = ''.join((url_a, url_b, url_c, url_d))

headers = {'User-Agent': 'Chrome/41.0.2228.0 Safari/537.36'}


def get_links(search_name):
    search_name = search_name.replace(' ', '+')
    url = url_base.format(search_name, 0)
    request = ulib.Request(url, None, headers)
    json_string = ulib.urlopen(request).read()
    page = json.loads(json_string.decode("utf-8"))
    new_soup = Soup(page[1][1], 'lxml')
    images = new_soup.find_all('img')
    links = [image['src'] for image in images]
    return links


def save_images(links, search_name):
    directory = search_name.replace(' ', '_')
    if not os.path.isdir(directory):
        os.mkdir(directory)

    for i, link in enumerate(links):
        savepath = os.path.join(directory, '{:06}.png'.format(i))
        ulib.urlretrieve(link, savepath)


if __name__ == '__main__':
    search_name = 'fidget kid spinner toys'
    links = get_links(search_name)
    save_images(links, search_name)

 error after running the above code:

---------------------------------------------------------------------------
HTTPError                                 Traceback (most recent call last)
<ipython-input-27-0ff39af2af56> in <module>
     37 if __name__ == '__main__':
     38     search_name = 'fidget kid spinner toys'
---> 39     links = get_links(search_name)
     40     save_images(links, search_name)

<ipython-input-27-0ff39af2af56> in get_links(search_name)
     17     url = url_base.format(search_name, 0)
     18     request = ulib.Request(url, None, headers)
---> 19     json_string = ulib.urlopen(request).read()
     20     page = json.loads(json_string.decode("utf-8"))
     21     new_soup = Soup(page[1][1], 'lxml')

C:\ProgramData\Anaconda3\lib\urllib\request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)
    220     else:
    221         opener = _opener
--> 222     return opener.open(url, data, timeout)
    223 
    224 def install_opener(opener):

C:\ProgramData\Anaconda3\lib\urllib\request.py in open(self, fullurl, data, timeout)
    529         for processor in self.process_response.get(protocol, []):
    530             meth = getattr(processor, meth_name)
--> 531             response = meth(req, response)
    532 
    533         return response

C:\ProgramData\Anaconda3\lib\urllib\request.py in http_response(self, request, response)
    639         if not (200 <= code < 300):
    640             response = self.parent.error(
--> 641                 'http', request, response, code, msg, hdrs)
    642 
    643         return response

C:\ProgramData\Anaconda3\lib\urllib\request.py in error(self, proto, *args)
    567         if http_err:
    568             args = (dict, 'default', 'http_error_default') + orig_args
--> 569             return self._call_chain(*args)
    570 
    571 # XXX probably also want an abstract factory that knows when it makes

C:\ProgramData\Anaconda3\lib\urllib\request.py in _call_chain(self, chain, kind, meth_name, *args)
    501         for handler in handlers:
    502             func = getattr(handler, meth_name)
--> 503             result = func(*args)
    504             if result is not None:
    505                 return result

C:\ProgramData\Anaconda3\lib\urllib\request.py in http_error_default(self, req, fp, code, msg, hdrs)
    647 class HTTPDefaultErrorHandler(BaseHandler):
    648     def http_error_default(self, req, fp, code, msg, hdrs):
--> 649         raise HTTPError(req.full_url, code, msg, hdrs, fp)
    650 
    651 class HTTPRedirectHandler(BaseHandler):



please help


`"/home/bhavesh/Object Detection/env/bin/python" "/home/bhavesh/Object Detection/YOLO-series/part5 - get_images.py"
Traceback (most recent call last):
  File "/home/bhavesh/Object Detection/YOLO-series/part5 - get_images.py", line 41, in <module>
    links = get_links(search_name)
  File "/home/bhavesh/Object Detection/YOLO-series/part5 - get_images.py", line 21, in get_links
    json_string = ulib.urlopen(request).read()
  File "/usr/lib/python3.6/urllib/request.py", line 223, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/lib/python3.6/urllib/request.py", line 532, in open
    response = meth(req, response)
  File "/usr/lib/python3.6/urllib/request.py", line 642, in http_response
    'http', request, response, code, msg, hdrs)
  File "/usr/lib/python3.6/urllib/request.py", line 570, in error
    return self._call_chain(*args)
  File "/usr/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/lib/python3.6/urllib/request.py", line 650, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
`
i get this problem 
`AttributeError                            Traceback (most recent call last)
<ipython-input-17-ba99d5ade11f> in <module>
     16         fig, ax = plt.subplots(1)
     17         mngr = plt.get_current_fig_manager()
---> 18         mngr.window.setGeometry(250, 120, 1280, 1024)
     19         image = cv2.imread(image_file.path)
     20         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

AttributeError: 'FigureManagerBase' object has no attribute 'window'`
on this line of code 

`mngr.window.setGeometry(250, 120, 1280, 1024)`

why i get this error ?

i run the code in jupyter in i get this 
![Screenshot 2019-06-15 02 32 25](https://user-images.githubusercontent.com/15304379/59544822-f3454880-8f15-11e9-8fdf-c5afb327f49b.png)

when i click on the photo no rectangular is appear 

any help ?

This error I am getting when I tried to run training:
![2019-01-22 22_44_50-](https://user-images.githubusercontent.com/36526221/51615606-478f6200-1f4e-11e9-965a-3153e8d75d63.png)
