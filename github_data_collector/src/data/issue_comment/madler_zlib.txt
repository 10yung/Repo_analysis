Building with configure `--zprefix` is a nice feature because it prefixes all exported symbols with `z_`. This allows linking a zlib built in such a way with a program which already uses e default zlib which is nice for experimenting with new versions.

Unfortunately there's one symbol, namely `z_errmsg` which is not prefixed (in this case `z_` is already in the original name), leading to duplicate symbols in the scenario described above.

The fix is trivial - just prefix `z_errmsg` with another `z_` as well in `zconf.{h,h.in,zconf.h.cmakein}`
Building with `configure --zprefix` is a nice feature because it prefixes all exported symbols with `z_`. This allows linking a zlib built in such a way with a program which already uses e default zlib which is nice for experimenting with new versions.

Unfortunately there's one symbol, namely `z_errmsg` which is not prefixed (in this case `z_` is already in the original name), leading to duplicate symbols in the scenario described above.

The fix is trivial - just prefix  `z_errmsg` with another `z_` as well in `zconf.{h,h.in,zconf.h.cmakein}`

Compile Zlib on windows 64. After the command "cmake -G"Visual Studio 14 2015 Win64" .."  is typed in, errors occur as folllows:
-- Selecting Windows SDK version  to target Windows 10.0.18362.
CMake Error at CMakeLists.txt:4 (project):
  Failed to run MSBuild command:

    MSBuild.exe

  to get the value of VCTargetsPath:

    用于 .NET Framework 的 Microsoft (R) 生成引擎版本 16.4.0+e901037fe
    版权所有(C) Microsoft Corporation。保留所有权利。

    生成启动时间为 2020/1/8 6:47:21。
    节点 1 上的项目“C:\Users\Administrator\source\repos\zlib\zlib-1.2.8\build\CMakeFiles\3.15.19101501-MSVC_2\VCTargetsPath.vcxproj”(默认目标)。
    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Microsoft\VC\v160\Microsoft.CppBuild.targets(382,5): error MSB8020: The build tools for Visual Studio 2015 (Platform Toolset = 'v140') cannot be found. To build using the v140 build tools, please install Visual Studio 2015 build tools.  Alternatively, you may upgrade to the current Visual Studio tools by selecting the Project menu or right-click the solution, and then selecting "Retarget solution". [C:\Users\Administrator\source\repos\zlib\zlib-1.2.8\build\CMakeFiles\3.15.19101501-MSVC_2\VCTargetsPath.vcxproj]
    已完成生成项目“C:\Users\Administrator\source\repos\zlib\zlib-1.2.8\build\CMakeFiles\3.15.19101501-MSVC_2\VCTargetsPath.vcxproj”(默认目标)的操作 - 失败。

    生成失败。

    “C:\Users\Administrator\source\repos\zlib\zlib-1.2.8\build\CMakeFiles\3.15.19101501-MSVC_2\VCTargetsPath.vcxproj”(默认目标) (1) ->
    (PrepareForBuild 目标) ->
      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Microsoft\VC\v160\Microsoft.CppBuild.targets(382,5): error MSB8020: The build tools for Visual Studio 2015 (Platform Toolset = 'v140') cannot be found. To build using the v140 build tools, please install Visual Studio 2015 build tools.  Alternatively, you may upgrade to the current Visual Studio tools by selecting the Project menu or right-click the solution, and then selecting "Retarget solution". [C:\Users\Administrator\source\repos\zlib\zlib-1.2.8\build\CMakeFiles\3.15.19101501-MSVC_2\VCTargetsPath.vcxproj]

        0 个警告
        1 个错误

    已用时间 00:00:00.16


  Exit code: 1



-- Configuring incomplete, errors occurred!
See also "C:/Users/Administrator/source/repos/zlib/zlib-1.2.8/build/CMakeFiles/CMakeOutput.log".

C:\Users\Administrator\source\repos\zlib\zlib-1.2.8\build>cmake -G"Visual Studio 15 2017 Win64" ..
CMake Error: Error: generator : Visual Studio 15 2017 Win64
Does not match the generator used previously: Visual Studio 14 2015 Win64
Either remove the CMakeCache.txt file and CMakeFiles directory or choose a different binary directory.
On unrelated work, this piece of code in `zconf.h` tripped really unfun to trace compiler errors:

```
#ifndef STDC
#  ifndef const /* cannot use !defined(STDC) && !defined(const) on Mac */
#    define const       /* note: need a more gentle solution here */
#  endif
#endif
```

That code apparently [dates back to Zlib 0.93 (25 June 95)](https://github.com/madler/zlib/commit/6b834a58bdef976383cff6e2a83f353e668a9cf1), and i would hope is not needed anywhere for anything these days. Regardless of why STDC might end up being undefined at some point during porting, defining language keywords to nothing should probably not be necessary. An `#error "Please have _the talk_ with your compiler"` would maybe suffice ?

 Hello again,

This optimization uses VSX vector (SIMD) instructions to try to match multiple bytes at the same time during the search for the longest match. A vector load + comparison (16 bytes) has just a small overhead  if compared to their regular versions, so the optimized longest_match tries to match as many bytes as possible on every comparison.

This PR shares 1 commit with #457 and #458, which can be removed if either one gets merged first. It also uses GNU indirect functions to choose which function version (optimized or default) to run on the first call to longest_match during runtime.

To test the performance improvement, we used [Chromium's zlib_bench.cc](https://cs.chromium.org/chromium/src/third_party/zlib/contrib/bench/) with input files from [jsnell/zlib-bench](https://github.com/jsnell/zlib-bench/tree/master/corpus).

The results below show compression throughput in MB/s using RAW deflate, for all compression levels:

- pngpixels

    | comp lvl | default | optimized |    gain |
    |----------|---------|-----------|---------|
    |        1 |    67.5 |      73.0 |  +8.15% |
    |        2 |    59.0 |      65.3 | +10.68% |
    |        3 |    38.8 |      45.2 | +16.49% |
    |        4 |    42.0 |      46.0 |  +9.52% |
    |        5 |    26.7 |      31.6 | +18.35% |
    |        6 |    13.8 |      16.5 | +19.57% |
    |        7 |     8.9 |      10.6 | +19.10% |
    |        8 |     2.8 |       3.4 | +21.43% |
    |        9 |     1.3 |       1.5 | +15.38% |


- jpeg

    | comp lvl | default | optimized |   gain |
    |----------|---------|-----------|--------|
    |        1 |    20.0 |      20.5 | +2.50% |
    |        2 |    20.2 |      20.3 | +0.50% |
    |        3 |    20.2 |      20.3 | +0.50% |
    |        4 |    20.3 |      20.4 | +0.49% |
    |        5 |    20.3 |      20.4 | +0.49% |
    |        6 |    20.3 |      20.4 | +0.49% |
    |        7 |    20.3 |      20.4 | +0.49% |
    |        8 |    19.9 |      20.4 | +2.51% |
    |        9 |    20.3 |      20.4 | +0.49% |


- executable

    | comp lvl | default | optimized |   gain |
    |----------|---------|-----------|--------|
    |        1 |    41.2 |      43.1 | +4.61% |
    |        2 |    37.8 |      39.2 | +3.70% |
    |        3 |    28.9 |      29.9 | +3.46% |
    |        4 |    28.3 |      28.9 | +2.12% |
    |        5 |    20.2 |      21.4 | +5.94% |
    |        6 |    12.5 |      13.1 | +4.80% |
    |        7 |     9.5 |       9.9 | +4.21% |
    |        8 |     5.4 |       5.6 | +3.70% |
    |        9 |     4.1 |       4.2 | +2.44% |


- html

    | comp lvl | default | optimized |    gain |
    |----------|---------|-----------|---------|
    |        1 |    43.0 |      46.2 |  +7.44% |
    |        2 |    38.5 |      42.2 |  +9.61% |
    |        3 |    27.8 |      30.8 | +10.79% |
    |        4 |    28.3 |      30.8 |  +8.83% |
    |        5 |    18.1 |      20.1 | +11.05% |
    |        6 |    12.2 |      13.2 |  +8.20% |
    |        7 |    10.6 |      11.4 |  +7.55% |
    |        8 |     8.0 |       8.7 |  +8.75% |
    |        9 |     7.9 |       8.6 |  +8.86% |

Hi,

This PR introduces a optimization for Adler32 checksum for POWER8+ processors that uses VSX (vector) instructions.

If adler32 do 1 byte at time on the first iteration s1 is s1\_0 (\_n means iteration n) is the initial value of adler, at beginning  \_0 is 1 unless adler initial value is different than 1. So s1\_1 = s1\_0 + c[0] after
the first calculation. For the next iteration s1\_2 = s1\_1 + c[1] and so on. Hence, for iteration N, s1\_N = s1\_(N-1) + c[N] is the value of s1 on after iteration N. Therefore, for s2, s2\_N = s2\_0 + N*s1\_N + N*c[0] + N-1*c[1] + ... + c[N] In a more general way:

s1\_N = s1\_0 + sum(i=1 to N)*c[i]

s2\_N = s2\_0 + N*s1 + sum (i=1 to N)(N-i+1)*c[i]

Where s1_N, s2_N are the values for s1, s2 after N iterations. So if we can process N-byte at time we can obtain adler32 checksum for N-byte at once.  Since VSX can support 16-byte vector instructions, we can process 16-byte at time using N = 16 we have:

s1 = s1\_16 = s1\_0 + sum(i=1 to 16)c[i]

s2 = s2\_16 = s2\_0 + 16*s1 + sum(i=1 to 16)(16-i+1)*c[i]

The VSX version starts to improve the performance for buffers with size >= 64. The performance is up to 10x better than Adler32 version from adler32 non-vectorized version (average cpu time in ns on 100000 iterations):

| buffer size | adler32 baseline | adler32 power | speedup |
|-------------|------------------|---------------|---------|
| 64          | 44.921875        | 41.015625     | -       |
| 1024        | 943.359375       | 130.859375    | 7.2     |
| 10*5552     | 42519.531250     | 3974.609375   | 10.7    |

For buffer with length <= than 64 the performance is almost the same of
the non-vectorized implementation (with a small performance degradation in some cases):

| buffer size | adler32 baseline | adler32 power |
|-------------|------------------|---------------|
| NULL | 5.859375 | 6.812500 |
| 1 | 3.906250 | 4.859375 |
| 15 | 11.718750 | 12.625000 |
| 48 | 35.156250 | 33.203125 |

Hi,

During performance tests, we noticed that slide_hash consumes considerable CPU during compression on Power processors. This PR introduces an optimized version using VSX vector instructions to make it faster. The main difference is that it slides 8 elements at a time, instead of just one as the standard code does.

The implementation uses GNU indirect function (ifunc) feature to choose the correct function version to be used on the first call during runtime. Later calls will all go directly to the selected function. This way, the same binary can be used for all Power processor versions. The ifunc helper code, however, is not limited to Power, and can be reused by other archs if wanted, so it was placed under `contrib/gcc`.

I tried to make as few changes as possible to top-level files (`deflate.c`), and instead place most Power-specific code under `contrib/power`.

To measure the performance improvement, we used [Chromium's zlib_bench.cc](https://cs.chromium.org/chromium/src/third_party/zlib/contrib/bench/) with input files from [jsnell/zlib-bench](https://github.com/jsnell/zlib-bench/tree/master/corpus).

The results below show compression throughput in MB/s using RAW deflate, for all compression levels:

- jpeg

    | comp lvl | default | optimized |    gain |
    |----------|---------|-----------|---------|
    |        1 |    20.4 |      27.4 | +34.31% |
    |        2 |    20.2 |      26.4 | +30.69% |
    |        3 |    20.2 |      27.1 | +34.16% |
    |        4 |    20.3 |      27.3 | +34.48% |
    |        5 |    20.3 |      27.3 | +34.48% |
    |        6 |    20.3 |      27.3 | +34.48% |
    |        7 |    20.3 |      27.3 | +34.48% |
    |        8 |    20.3 |      27.3 | +34.48% |
    |        9 |    20.3 |      27.3 | +34.48% |


- pngpixels

    | comp lvl | default | optimized |    gain |
    |----------|---------|-----------|---------|
    |        1 |    67.0 |      98.6 | +47.16% |
    |        2 |    58.7 |      79.8 | +35.95% |
    |        3 |    38.8 |      46.7 | +20.36% |
    |        4 |    42.1 |      48.8 | +15.91% |
    |        5 |    26.6 |      29.2 |  +9.77% |
    |        6 |    13.8 |      14.5 |  +5.07% |
    |        7 |     8.9 |       9.2 |  +3.37% |
    |        8 |     2.8 |       2.8 |  +0.00% |
    |        9 |     1.3 |       1.3 |  +0.00% |


- executable

    | comp lvl | default | optimized |    gain |
    |----------|---------|-----------|---------|
    |        1 |    41.3 |      57.6 | +39.47% |
    |        2 |    37.9 |      50.9 | +34.30% |
    |        3 |    29.0 |      36.1 | +24.48% |
    |        4 |    28.4 |      34.8 | +22.54% |
    |        5 |    20.2 |      23.2 | +14.85% |
    |        6 |    12.5 |      13.7 |  +9.60% |
    |        7 |     9.5 |      10.1 |  +6.32% |
    |        8 |     5.4 |       5.6 |  +3.70% |
    |        9 |     4.1 |       4.2 |  +2.44% |


- html

    | comp lvl | default | optimized |    gain |
    |----------|---------|-----------|---------|
    |        1 |    43.1 |      59.3 | +37.59% |
    |        2 |    38.6 |      50.7 | +31.35% |
    |        3 |    27.8 |      33.8 | +21.58% |
    |        4 |    28.3 |      33.1 | +16.96% |
    |        5 |    18.1 |      20.1 | +11.05% |
    |        6 |    12.2 |      13.0 |  +6.56% |
    |        7 |    10.6 |      11.2 |  +5.66% |
    |        8 |     8.0 |       8.4 |  +5.00% |
    |        9 |     7.9 |       8.3 |  +5.06% |

(note: resolving #205 might avoid the issue in many cases in practice as well, but might not fully resolve it in case of different build configs)
When loading libz.so.1 with dlopen and RTLD_LOCAL it can happen that you end up with mysterious crashes.
The reason is that your library is run inside a program that ALSO uses zlib, but a different version and does not hide the symbols (loads it RTLD_GLOBAL, depends on it, ...).
The end result is that deflateInit2_ when calling deflateReset() ends up calling deflateReset from that INCOMPATIBLE version of zlib.
The normal solution to that is to link with -Wl,-Bsymbolic.
Alternatively (e.g. if one wanted to avoid depending on non-generic compiler options) it would be possible to forbid calling any exported functions from zlib code itself. This will be more difficult to do though, I do not know if there are any other pieces of code with this same issue.
e.g. 
trees.c(1174,19): warning C4131: 'bi_flush': uses old-style declarator,
inffas8664.c(112,48): warning C4210: nonstandard extension used: function
given file scope
trees.c(724,45): warning C4244: '+=': conversion from 'int' to 'ush', possible loss of dat
a
gzwrite.c(212,27): warning C4267: '=': conversion from 'size_t' to 'unsigned int',
...

Hello,

I created this pull request to gauge your attitude towards continuous fuzzing and upstream support for it. Presently all fuzzer harnesses are in the oss-fuzz repo (https://github.com/google/oss-fuzz/tree/master/projects/zlib) or inside the chromium codebase (https://cs.chromium.org/chromium/src/third_party/zlib/contrib/tests/fuzzers/)

CC @inferno-chromium @Dor1s (via https://github.com/google/oss-fuzz/issues/402#issuecomment-364628081)

Thank you
Bhargava