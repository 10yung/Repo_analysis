## Expected Behavior
We build offline amis for our servers, and we'd like to install sensu client in advance. We can't unless we have a way to do it without ui or any prompts, in silent mode. 


## Current Behavior
Current 1.8 installer doesn't support silent installer, it always opens the UI.

## Possible Solution
Not sure how to add this support.

## Steps to Reproduce (for bugs)
1. Try to install it silently

## Context
We prebuild the windows images for our servers to expedite deployment of our application. We currently have to install sensu manually after the server instance is created.

## Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Sensu version used: 1.8
* Active Sensu extensions (e.g. WizardVan 0.1.0): 
* Operating System and version (e.g. Ubuntu 14.04): Windows Server 2012
* Transport and runtime versions (e.g. RabbitMQ 3.6.2 on Erlang 18.2): RabbitMQ


Thanks in advance!

Please release sensu core package for Debian 10(buster).
Hello, 
what are the required steps to delete checks that are no longer needed? 
Deleting a check and restarting services doesn't seem to work.  A step by step guide to deleting checks will be very helpful. 

Thank you
<!--- Provide a general summary of the issue in the Title above -->
I have some sensu clients running sensu version 0.29.0. The clients disconnect and reconnect to rabbitmq with a different queue name but do not remove their old queues. I understand that I am running a really old version of sensu, so has this been fixed in a newer version?

## Expected Behavior
<!--- If you're looking for help, please see https://sensuapp.org/support for resources --->
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->
The sensu client should have its queue removed after it disconnects or establish connection back to the old queue. Their queue names had the same SERVER_NAME-VERSION- but with a different timestamp.

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->
The sensu client disconnects from rabbitmq, reconnects to rabbitmq, and creates a new queue as SERVER_NAME-VERSION-TIMESTAMP. The sensu client runs fine without problems because it is consuming messages from a different queue while its old queue keeps collecting check request messages.

```
$ rabbitmqctl list_queues
test123-0.29.0-1547845302	12287
test123-0.29.0-1554852830	0
```

## Possible Solution
<!--- Not obligatory, but suggest a fix/reason for the bug, -->
<!--- or ideas as to the implementation of the addition or change -->
Make the sensu client check for any duplicate queues when it first connects.

## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code or configuration to reproduce, if relevant -->
It's a bit hard to reproduce. I have over 12k sensu clients.
1. Disconnect a sensu client
2. Allow the sensu client to reconnect
3. It creates a new queue for its message while leaving the old queue up.

## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context (e.g. links to configuration settings or log data) helps us come up with a solution that is most useful in the real world -->
I run my RabbitMQ servers on ec2 instances that will eventually run out of memory, start writing to disk, fill up quickly and crash the rabbitmq-server service.

## Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Sensu version used: 0.29.0
* Active Sensu extensions (e.g. WizardVan 0.1.0):
* Operating System and version (e.g. Ubuntu 14.04): RHEL 6
* Transport and runtime versions (e.g. RabbitMQ 3.6.2 on Erlang 18.2): RabbitMQ 3.3.5 on Erlang R16B03-1

When I hit /results for the current status of a check with the api, the history of the last few checks can be seen as expected as a list of int's:

```
$ curl http://test-sensu-instance/results

[
  {
    "client": "testclient.net",
    "check": {
      "thresholds": {
        "warning": 120,
        "critical": 180
      },
      "name": "keepalive",
      "issued": 1551287799,
      "executed": 1551287799,
      "output": "No keepalive sent from client for 1599 seconds (>=180)",
      "status": 2,
      "type": "standard",
      "history": [
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2
      ]
    }
  }
]
```

What I would have expected was this checks data would match what is provided with the /events api and it mainly is, with one notable exception. The history array is switched to a list of strings:

```
$ curl http://test-sensu-instance/events
[
  {
    "id": "f78b9b80-bdb1-41f7-a389-9542487c3b1d",
    "client": {
      "name": "testclient.net",
      "address": "xxx.xxx.xxx.xxx",
      "subscriptions": [
        "client:testclient.net"
      ],
      "redact": [],
      "socket": {
        "bind": "127.0.0.1",
        "port": 3030
      },
      "safe_mode": false,
      "keepalive": {},
      "version": "1.4.2",
      "timestamp": 1551286200
    },
    "check": {
      "thresholds": {
        "warning": 120,
        "critical": 180
      },
      "name": "keepalive",
      "issued": 1551287709,
      "executed": 1551287709,
      "output": "No keepalive sent from client for 1509 seconds (>=180)",
      "status": 2,
      "type": "standard",
      "history": [
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2",
        "2"
      ],
      "total_state_change": 0
    },
    "occurrences": 45,
    "occurrences_watermark": 45,
    "last_ok": 1551286299,
    "action": "create",
    "timestamp": 1551287709,
    "last_state_change": 1551286389,
    "silenced": false,
    "silenced_by": []
  }
]

```
## Expected Behavior
The datatypes returned for history from /results and /events should match.

## Current Behavior
As described above, different datatypes are shown for check history

## Steps to Reproduce (for bugs)
1. hit /events for any event with history
2. hit /results and look up that same check

## Context
Discovered while writing a go application talking to sensu. The json lib failed to unmarshal responses where the same struct was used for both endpoints.

## Your Environment
* Sensu version used: 1.4.2
* Operating System and version: CentOS 7
* RabbitMQ version: 3.6.9-1
Is there any google chat module to send alerts via sensu's google chat handler to more than one room (chat room)? Ex: As like in Slack we have multi-slack-handler.rb handler is there to trigger alerts on multiple channels via subscriptions which we defined./ Is this same kind of thing Possible with google chat??

In my case, I have created two channels in Sensu (sensu-core open source edition) but I am getting alerts in only one channel after few minutes I am getting alerts on another channel as well but it sends alerts in only one channel at a time. How can we get alerts in all the channels on sensu with google hangout handler?
When `sensu-client` receives a service stop signal while processing a check, it will wait for the check to complete before shutting down. 

However, during that "completing checks in progress" state, if a service start signal is issued, service still return a message saying that `sensu-client` is already running, even though it is in process of shutting down.

## Expected Behavior
`sensu-client` service should have a state equivalent to "in progress of shutting down". That way when service start signaled, it can wait for the shut down before starting back again. 

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->
`sensu-client` service reports a running state, and then proceeds to shut down. 

## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code or configuration to reproduce, if relevant -->
1. Initiate a long running check in Sensu
2. Issue `service sensu-client stop`. Tail `sensu-client.log` in a separate window to see that TERM signal is received, and it's waiting for the check to complete. 
3. In another separate window, issue `service sensu-client start`. Upstart will inform that the service is already running.
4. Wait a bit for the long running check to complete. Now `sensu-client` is stopped.


## Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Sensu version used: 1.5.0
* Operating System and version (e.g. Ubuntu 14.04): Ubuntu 14.04

EDIT: I mistakenly thought Upstart was involved; it's not. This is probably just the init script. You can replace `service sensu-client stop|start` with `/etc/init.d/sensu-client stop|start` and reproduce the same result.
I found #884 while searching for this issue, but since it's closed and the last update says about creating a new issue, so that's what I'm doing here ðŸ˜ƒ 

We're running Sensu 1.5 on 50 prod Windows servers, OS is a mixture of Windows 2008R2, 2012R2 & 2016. This has only happened on the 2008R2 servers so far (18/50).

It's not often that we see the message, but it does appear randomly across various different checks. Since 1 December it seems to have occurred about 50 times, bearing in mind that there's about 5 checks per server, and most of those checks run once every 2 minutes.
There's no particular server that it seems to happen more on, and there's no specific check that seems to be more troublesome.

## Current Behavior
I initially thought it was one of the system calls that we being run from within the script that we trigger (the check actually runs a script against local install of Perl on the server). I tried redirecting all stderr messages from the script to Windows' equivalent of /dev/null (nul), but the error still appears... This leads me to think that the agent is getting the error when it's trying to run the actual command (Perl in this case)

There's not much online, as this error doesn't appear to be particularly specific... The only good thing is that the agent recognises that it has failed and we get a non-zero return code back, which triggers our handler.

Nothing appears in the Event Log in Windows, and the Sensu log just shows the info messages with the check result. Not sure whether turning debug logging on would help... But whether we'd catch it on the same server again is anyone's guess.

```
{"timestamp":"2018-12-31T12:00:20.449004+0000","level":"info","message":"received check request","check":{"alert_message":"Service ::id:: is down. ::additional_text::","command":"c:/opt/perl-5.26/perl/bin/perl.exe c:/opt/sensu/plugins/check-services-windows.pl 2> nul","handlers":["snmp"],"name":"check-services-windows","issued":1546257620}}

{"timestamp":"2018-12-31T12:00:30.327991+0000","level":"info","message":"publishing check result","payload":{"client":"MYCLIENT","check":{"alert_message":"Service ::id:: is down. ::additional_text::","command":"c:/opt/perl-5.26/perl/bin/perl.exe c:/opt/sensu/plugins/check-services-windows.pl 2> nul","handlers":["snmp"],"name":"check-services-windows","issued":1546257620,"executed":1546257620,"duration":9.879,"output":"Unexpected error: The parameter is incorrect. (87)","status":3}}}
```

Not sure what status 3 is... it's nothing that my script would set, so I guess it's some error detection in the sensu-client itself.

Any help/suggestions would be much appreciated. Happy to try something out if it'll help get to the bottom of the cause.
## Expected Behavior

When failing to connect to Redis or Redis Sentinel instances, Sensu will use a backoff mechanism to slow the rate of reconnect attempts.

## Current Behavior

Retrying connections to Redis or Redis Sentinel occurs at a fixed interval.

## Possible Solution

Implement a backoff mechanism to control reconnect attempts to Redis and Redis Sentinels.

## Steps to Reproduce (for bugs)

1. Configure sensu-server with a Redis hostname that does not resolve 
2. Start Sensu, monitor /var/log/sensu/sensu-server.log for errors
3. Note that sensu-server consistently attempts to resolve the non-existent DNS name twice or more per second

## Context

As described in https://github.com/sensu/sensu/issues/1889 the lack of backoff mechanism can lead to denial of service in cases where a sufficient volume of DNS lookups might overwhelm resolver infrastructure. 

Similarly, errors received from Redis after opening the connection may cause Sensu services to drive up the number of connections to the Redis server, leading to another denial of service scenario.

## Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Sensu version used: Sensu Core 1.6
* Operating System and version (e.g. Ubuntu 14.04): Centos 7
* Transport and runtime versions (e.g. RabbitMQ 3.6.2 on Erlang 18.2): RabbitMQ 3.7.9, Erlang 21.1.4

I installed sensu on a Debian host without IPv4 addresses. I expected everything to work because I noticed Sensu was doing IPv6 nicely with RabbitMQ, but it caused me some time to debug why It wouldn't start.

I got the following errors:
```
{"timestamp":"2018-12-06T16:01:18.568431+0100","level":"info","message":"configuring sensu spawn","settings":{"limit":12}}
{"timestamp":"2018-12-06T16:01:18.854121+0100","level":"warn","message":"transport connection error","reason":"tcp connection lost"}
/opt/sensu/embedded/lib/ruby/gems/2.4.0/gems/eventmachine-1.2.7/lib/eventmachine.rb:531:in `start_tcp_server': no acceptor (port is in use or requires root privileges) (RuntimeError)
        from /opt/sensu/embedded/lib/ruby/gems/2.4.0/gems/eventmachine-1.2.7/lib/eventmachine.rb:531:in `start_server'
        from /opt/sensu/embedded/lib/ruby/gems/2.4.0/gems/sensu-1.6.1/lib/sensu/client/process.rb:472:in `setup_json_socket'

etc. etc.
```

## Expected Behavior
I expected Sensu to start nicely, without any issues.

## Current Behavior
I got the error above.

## Possible Solution
I managed to work around this issue by adding the following configuration in client.conf:
```
    "socket": {
      "bind": "::1",
      "port": 3030
    },
    "http_socket": {
      "bind": "::1",
      "port": 3031
    }
```

## Steps to Reproduce (for bugs)
1. Create a IPv6 only machine
2. Install and configure Sensu
3.
4.

## Context
Sensu in an IPv6-only environment.

## Your Environment
```
root@db02:/etc/sensu/conf.d# lsb_release -a
Distributor ID:	Debian
Description:	Debian GNU/Linux 9.6 (stretch)
Release:	9.6
Codename:	stretch
root@db02:/etc/sensu/conf.d# dpkg -l | grep sensu
ii  sensu                          1.6.1-1                        amd64        A monitoring framework that aims to be simple, malleable, and scalable.
root@db02:/etc/sensu/conf.d# for i in `ls`; do cat $i; done
{
  "client": {
    "name": "REDACTED",
    "address": "fc00:0:0:1::8",
    "environment": "production",
    "subscriptions": ["linux", "level2_support", "ssh"],
    "socket": {
      "bind": "::1",
      "port": 3030
    },
    "http_socket": {
      "bind": "::1",
      "port": 3031
    }
  }
}
{
  "rabbitmq": {
    "ssl": {},
    "host": "REDACTED",
    "port": 5671,
    "vhost": "/sensu",
    "user": "REDACTED",
    "password": "REDACTED"
  }
}
{
    "transport": {
        "name": "rabbitmq",
        "reconnect_on_error": true
    }
}
```

