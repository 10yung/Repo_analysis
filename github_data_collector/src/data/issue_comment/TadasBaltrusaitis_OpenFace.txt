Dear author
  Recently, I tried to use openface to do head pose estimation. I met an problem which confuse me. That is some pictures result value in which the person's head is more partial than others is smaller than other pictures in which the head is straight. That's weird. Can you help me? Thanks! 
**Describe the bug**
Make has 2 errors

**To Reproduce**
followed all non-optional steps under Wiki/Mac-installation

**Expected behavior**
binaries in the 'bin' directory

**Screenshots**
see full terminal output below

**Desktop (please complete the following information):**
 - OS: MacOS Mojave 10.14.6
 - Version [e.g. 22]
 - Compiler [if compilation or linker error]

**Additional context**
Terminal output in response to 'make':

CNC-100:build dap$ make
Scanning dependencies of target LandmarkDetector
[  2%] Building CXX object lib/local/LandmarkDetector/CMakeFiles/LandmarkDetector.dir/src/CCNF_patch_expert.cpp.o
In file included from /Users/dap/Downloads/OpenFace-master/lib/local/LandmarkDetector/src/CCNF_patch_expert.cpp:35:
In file included from /Users/dap/Downloads/OpenFace-master/lib/local/LandmarkDetector/include/stdafx.h:28:
In file included from /usr/local/include/dlib/opencv.h:10:
/usr/local/include/dlib/image_processing/../opencv/cv_image.h:37:22: error: no viable conversion from 'const cv::Mat' to 'IplImage' (aka '_IplImage')
            IplImage temp = img;
                     ^      ~~~
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/types_c.h:327:1: note: candidate constructor (the implicit copy constructor) not viable: no
      known conversion from 'const cv::Mat' to 'const _IplImage &' for 1st argument
_IplImage
^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/types_c.h:327:1: note: candidate constructor (the implicit move constructor) not viable: no
      known conversion from 'const cv::Mat' to '_IplImage &&' for 1st argument
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1642:28: note: candidate template ignored: could not match
      'vector<type-parameter-0-0, allocator<type-parameter-0-0> >' against '_IplImage'
    template<typename _Tp> operator std::vector<_Tp>() const;
                           ^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1643:35: note: candidate template ignored: could not match
      'Vec<type-parameter-0-0, cn>' against '_IplImage'
    template<typename _Tp, int n> operator Vec<_Tp, n>() const;
                                  ^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1644:42: note: candidate template ignored: could not match
      'Matx<type-parameter-0-0, m, n>' against '_IplImage'
    template<typename _Tp, int m, int n> operator Matx<_Tp, m, n>() const;
                                         ^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1646:45: note: candidate template ignored: could not match
      'array<type-parameter-0-0, _Size>' against '_IplImage'
    template<typename _Tp, std::size_t _Nm> operator std::array<_Tp, _Nm>() const;
                                            ^
In file included from /Users/dap/Downloads/OpenFace-master/lib/local/LandmarkDetector/src/CCNF_patch_expert.cpp:35:
In file included from /Users/dap/Downloads/OpenFace-master/lib/local/LandmarkDetector/include/stdafx.h:28:
In file included from /usr/local/include/dlib/opencv.h:10:
/usr/local/include/dlib/image_processing/../opencv/cv_image.h:136:22: error: no viable conversion from 'const cv::Mat' to 'IplImage' (aka '_IplImage')
            IplImage temp = img;
                     ^      ~~~
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/types_c.h:327:1: note: candidate constructor (the implicit copy constructor) not viable: no
      known conversion from 'const cv::Mat' to 'const _IplImage &' for 1st argument
_IplImage
^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/types_c.h:327:1: note: candidate constructor (the implicit move constructor) not viable: no
      known conversion from 'const cv::Mat' to '_IplImage &&' for 1st argument
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1642:28: note: candidate template ignored: could not match
      'vector<type-parameter-0-0, allocator<type-parameter-0-0> >' against '_IplImage'
    template<typename _Tp> operator std::vector<_Tp>() const;
                           ^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1643:35: note: candidate template ignored: could not match
      'Vec<type-parameter-0-0, cn>' against '_IplImage'
    template<typename _Tp, int n> operator Vec<_Tp, n>() const;
                                  ^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1644:42: note: candidate template ignored: could not match
      'Matx<type-parameter-0-0, m, n>' against '_IplImage'
    template<typename _Tp, int m, int n> operator Matx<_Tp, m, n>() const;
                                         ^
/usr/local/Cellar/opencv/4.2.0_1/include/opencv4/opencv2/core/mat.hpp:1646:45: note: candidate template ignored: could not match
      'array<type-parameter-0-0, _Size>' against '_IplImage'
    template<typename _Tp, std::size_t _Nm> operator std::array<_Tp, _Nm>() const;
                                            ^
2 errors generated.
make[2]: *** [lib/local/LandmarkDetector/CMakeFiles/LandmarkDetector.dir/src/CCNF_patch_expert.cpp.o] Error 1
make[1]: *** [lib/local/LandmarkDetector/CMakeFiles/LandmarkDetector.dir/all] Error 2
make: *** [all] Error 2

First of all, I would like to thank you for your work!
I wanted to train my eye model, but you did not provide the training code.  your ccnf_eye model in model\model_eye\patch_experts\ ccnf_patches_1.50_synth_lid only have scale in 1.0 and 1.5. when my face small, whether it will lead to the poor detection effect , and whether the model scale in 0.25 0.3and 0.5 can be provided.
Thank you very much!
I place two images in dir in_dir, and execute the following commands, and get different results. Both gaze and AU feature are different.

What is the reason? Many thanks.

```bash
FeatureExtraction -fdir "./in_dir"
FaceLandmarkImg -fdir "./in_dir"
```
![11](https://user-images.githubusercontent.com/26863591/71977083-c9fb4b00-31cc-11ea-8f0e-10fdaa5d65f6.jpg)
![12](https://user-images.githubusercontent.com/26863591/71977088-ca93e180-31cc-11ea-9813-ff7d77bb5055.jpg)


Hi TadasBaltrusaitis,

Landmark failed when yawning, showed below:

![Snipaste_2020-01-06_09-59-19](https://user-images.githubusercontent.com/29856952/71790511-d61bc700-306b-11ea-91c7-30932798990b.png)

Can I just adjust some parameters to solve this problem without retraing the pdm model?

thanks a lot!
Hello, thank you for your wonderful software. I am using OpenFaceOffline (windows 10) to process a video with 2 faces. One face is always in the left half and one face is always in the right half of the frame. The csv it produced contains data for face_id 0 and 1. Is there anyway to tell which face in the video is 0 and which is 1? 

Hi Tadas,

I'm working on the pain score. Which one would be more accurate to study (AU_r or AU_c)?
Hello,

My aim is to use Kinect v2 RGB data to perform feature extraction from a live feed. However, I couldn't figure out how to give only the RGB camera of Kinect v2 as a device from command line since it isn't seen as a video device (/dev/videoX) on Ubuntu. 

I'm using libfreenect2 (https://github.com/OpenKinect/libfreenect2) as the driver.

Thank you in advance.
Hello, 
          I found that FeatureExtraction.exe has a negative value when performing visualization, but AU should be between 0 and 5, and a negative value appears in the saved csv file
![image](https://user-images.githubusercontent.com/23525739/70714735-be2e7d00-1d23-11ea-9bbc-df499f8b45ac.png)
![image](https://user-images.githubusercontent.com/23525739/70714877-09e12680-1d24-11ea-9665-69c07a5e5719.png)

Hi

I'm a newbie and have modified the FaceLandmarkVid main function slightly to view the detected_landmarks values. I'm looking at taking forward some Unity integration work I have found ( https://blog.hosni.me/2018/05/pfa-unity3d-realtime-face-tracking.html ).

But when I run my modified FaceLandmarkVid it provides huge values inside detected_landmarks. The code segment is below: 

bool detection_success = FALSE;
double g_doubleArray[140];
...
detection_success = LandmarkDetector::DetectLandmarksInVideo(rgb_image, face_model, det_parameters, grayscale_image);
if (detection_success)
{
	for (int i = 0; i < 136; i++) {
		g_doubleArray[i] = face_model.detected_landmarks.at<double>(i);
	}
	std::cout << "=================== Face detected ===================" << std::endl;
	cout << "t[51] : " << g_doubleArray[51] << "\n";
	cout << "t[57] : " << g_doubleArray[57] << "\n";
}


The values shown are:

=================== Face detected ===================
t[51] : 1.00108e+18
t[57] : 1.22781e+17
=================== Face detected ===================
t[51] : 1.0026e+18
t[57] : 1.23031e+17
=================== Face detected ===================
t[51] : 9.83617e+17
t[57] : 1.20321e+17
=================== Face detected ===================
t[51] : 9.84516e+17
t[57] : 1.20864e+17

Do you know any reason why these values would be so high?

Thanks

Darren