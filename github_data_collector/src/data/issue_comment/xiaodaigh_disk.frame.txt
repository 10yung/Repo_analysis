https://github.com/dcooley/sfheaders

https://github.com/dcooley/sfheaders/issues/40
The following code fails:

```r
library(dplyr)
library(disk.frame)

setup_disk.frame()

aggregate_expressions <- list(n = quote(n()))

iris %>% 
  as.disk.frame() %>% 
  group_by(Species) %>%
  summarise(!!!(aggregate_expressions))
```

It throws the error:
```
There must be at least one summarization function in !!!(aggregate_expressions)
```

Could you enable disk.frame to recognize that the unquoted list `!!!(aggregate_expressions)` does in fact contain at least one summarization function? Thanks!
http://freerangestats.info/blog/2019/12/22/nyc-taxis-sql
```r
library(disk.frame)
a = data.frame(id = sample(1:100, 1000, replace=TRUE), values = runif(1000))
adf = as.disk.frame(a, nchunks = 6)

adf_sharded = adf %>% 
  mutate(rand_chunk = sample(1:2,n(), replace=TRUE)) %>% # create a new column to sharding into sub-shards
  shard(shardby =  c("id", "rand_chunk")) 

adf_with_bloomfilter = adf_sharded %>% 
  make_bloomfilter("id")

adf_with_bloomfilter %>% 
  bf_likely_in_chunks("id", 1)

adf_with_bloomfilter %>% 
  use_bloom_filter("id", 1) %>% 
  collect



a = data.frame(id3 = sample(letters, 1000, replace=TRUE), values = runif(1000))
adf = as.disk.frame(a, nchunks = 6)

adf_sharded = adf %>% 
  #mutate(rand_chunk = sample(1:2,n(), replace=TRUE)) %>% # create a new column to sharding into sub-shards
  #shard(shardby =  c("id3", "rand_chunk"))
  shard(shardby =  c("id3"))

df = adf_sharded %>% 
  make_bloomfilter("id3")

df %>% 
  bf_likely_in_chunks("id3", "a")

df %>% 
  use_bloom_filter("id3", "a") %>% 
  collect
```

https://www.youtube.com/watch?v=NDHSBUN_rVU
- [x] Assess [xor filters](https://lemire.me/blog/2019/12/19/xor-filters-faster-and-smaller-than-bloom-filters/)  *Notes:* The paper is quite confusing. It takes much longer to create a filter.

- [ ]  Write tutorial on bloomfilter

- [ ]  Proper indexing

Both issues #211 & #200 seem related to this enhancement, I have a similar problem it that it would be nice to be able to effectively have index columns that can spread across multimple chunks. I my case I have some large datasets where 'sub-shards' would be useful as my groups are too big to practicaly fit in a single chunk. I also have coordinates that it would to be nice to be able to perform a quick check of which chunks the value's i'm trying to look up are in as well as exploiting fst's random access feature to just read out sections of interest based on their indices.

_Originally posted by @RichardJActon in https://github.com/xiaodaigh/disk.frame/issues/102#issuecomment-567026839_

If can't be higher, list down the reasons to track
Consider donating some funds to SFC