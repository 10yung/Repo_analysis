We are now [automatically generating pkgdown docs](https://ropensci.org/technotes/2019/06/07/ropensci-docs/) for all rOpenSci packages. If you'd like you can use this as the homepage. But if you prefer to host your own, that's fine too.
I originally had the same issue @PranavPable was experiencing (below), and I figured out a solution that I thought I'd document. To make the `writeWave` output compatible with `gl_speech`, just set the parameter `extensible` equal to `FALSE`.
```r
#Doesn't work:
readWave("foo.wav")) %>%
  writeWave("bar.wav") #by default extensible = TRUE
gl_speech("bar.wav", sampleRateHertz = 8000L)
# 2019-12-07 22:29:51> Request Status Code: 400
# Error: API returned: WAV header indicates an unsupported format.

#Works:
readWave("foo.wav")) %>%
  writeWave("bar.wav", extensible = FALSE)
gl_speech("bar.wav", sampleRateHertz = 8000L)
```

_Originally posted by @PranavPable in https://github.com/ropensci/googleLanguageR/issues/34#issuecomment-444760187_

"I am getting this error on passing a wav file into readwave function.
**API returned: WAV header indicates an unsupported format.**"

Hi, I'm new to GitHub and APIs so I apologise if this isn't a proper issue.
I'm running googleLanguageR out of Rstudio and trying to transcribe (speech to text) a sound file about 5 minutes long, 2 speakers, but the speaker diarization option won't run. Code below:

```
longtest = "gs://[bucket]/longtest.wav"
async = gl_speech(longtest,
                  languageCode = "en-GB",
                  sampleRateHertz = 44100,
                  asynch = TRUE,
                  encoding = "LINEAR16",
                  enableSpeakerDiarization = TRUE,
                  diarizationSpeakerCount = 2)
```


Without the final 2 options it works fine but I need the speaker tags and with those options I get the below error:

```
Error in gl_speech(longtest, languageCode = "en-GB", sampleRateHertz = 44100,  : 
  unused arguments (enableSpeakerDiarization = TRUE, diarizationSpeakerCount = 2)
```

Am I missing something obvious or is there a problem with the speaker diarization options?
Got 400 error from https://stackoverflow.com/questions/51601697/invalid-argument-request-payload-size-exceeds-the-limit-10485760-bytes.  Added a simple check on the file size for the request.
Hi all,
I'm using the googleLanguageR package version 0.2.0.9 to transcribe German phone calls to text with the Google Speech-to-text API (speaker diarization is turned on, two speakers).
However, whenever I want to transcribe a file, which is longer than 60 seconds (i.e., I store it in a Cloud Bucket and then access it via the URI) it gives me a warning message.

Here is my code:
```
my_config <- list(encoding = "LINEAR16",
                  enableSpeakerDiarization = TRUE,
                  diarizationSpeakerCount = 2)

testcall <- "gs://[bucket]/testcall.wav"

apicall<- gl_speech(testcall, sampleRateHertz = 8000, languageCode = "de-DE", asynch = TRUE, customConfig = my_config)

testcall_transcript <- gl_speech_op(apicall)

```
The transcription is successful but R gives me this warning message.
```
Warning message:
In value[[3L]](cond) : Could not parse object with names: 
```
What this error causes is that the structure of the two returend dataframes seems to be a little mixed up.
When I call str(testcall_transcript) it gives me the following output:
```
List of 2
 $ transcript:Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	2 obs. of  2 variables:
  ..$ transcript: chr [1:2] "ja hallo ja und vergebe Zusatzdaten und zwar hat er was mache ich als nicht anzumerken ist einfach machen 815" "und wie heißt die Variable die drin da diese Datei ein Kratzer nennst Zusatzdaten Zusatzdaten vorgangs-id nicht"| __truncated__
  ..$ confidence: chr [1:2] "0.8421874" "0.8393924"
 $ timings   :List of 2
  ..$ :'data.frame':	1 obs. of  3 variables:
  .. ..$ transcript: chr "ja hallo ja und vergebe Zusatzdaten und zwar hat er was mache ich als nicht anzumerken ist einfach machen 815"
  .. ..$ confidence: num 0.842
  .. ..$ words     :List of 1
  .. .. ..$ :'data.frame':	20 obs. of  3 variables:
  .. .. .. ..$ startTime: chr [1:20] "0s" "17.600s" "18.100s" "18.200s" ...
  .. .. .. ..$ endTime  : chr [1:20] "17.600s" "18.100s" "18.200s" "19.100s" ...
  .. .. .. ..$ word     : chr [1:20] "ja" "hallo" "ja" "und" ...
  ..$ :'data.frame':	1 obs. of  3 variables:
  .. ..$ transcript: chr "und wie heißt die Variable die drin da diese Datei ein Kratzer nennst Zusatzdaten Zusatzdaten vorgangs-id nicht"| __truncated__
  .. ..$ confidence: num 0.839
  .. ..$ words     :List of 1
  .. .. ..$ :'data.frame':	43 obs. of  4 variables:
  .. .. .. ..$ startTime : chr [1:43] "0s" "17.600s" "18.100s" "18.200s" ...
  .. .. .. ..$ endTime   : chr [1:43] "17.600s" "18.100s" "18.200s" "19.100s" ...
  .. .. .. ..$ word      : chr [1:43] "ja" "hallo" "ja" "und" ...
  .. .. .. ..$ speakerTag: int [1:43] 1 1 1 1 1 1 1 1 1 1 ...
```
Looks all fine BUT...
when I try to access the $timings dataframe I'm having trouble to access the $speakerTag variable. I need to access the speakerTag and the respective start and Endtimes in order to determine the time stamps when a speaker turn happens. 

For a short file (less than 60sec) R gives me this output (perfectly working):
```
> transcript_short$timings$speakerTag
  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [68] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1
```
For the long file R gives me this output:
```
> testcall_transcript$timings$speakerTag
NULL
```
Any ideas on how this can be fixed? Extracting the speakerTags is crucial for my further data processing.
Thanks! :)
Hi guys, not a real user, but I just bumped to this repo.

Two of your headlines, [1] and [2] read "Google Cloud Speech-to-Text API", when I think you meant "Google Cloud Text-to-Speech API".


[1]:https://github.com/ropensci/googleLanguageR#googlelanguager---r-client-for-the-google-translation-api-google-cloud-natural-language-api-google-cloud-speech-api-and-google-cloud-speech-to-text-api
[2]:https://github.com/ropensci/googleLanguageR#google-cloud-speech-to-text-api
it would be a nice addition in the `gl_speech` function if you are working with audio files that have different hertz rates. Unfortunately, i was not able to find an r package that implements this function. 
I tried to use the package to translate some text. I checked the nchar amount, which is within the daily limit (https://cloud.google.com/translate/quotas)

```
sum(nchar(articles_to_translate))
[1] 1999332
```
I then used the command
```
articles_translated <- gl_translate(articles_to_translate, 
                                    target = "en",
                                    format = "text",
                                    source = "it")
```
which seemed to work until I received a daily limit exceeded error. Now Google already billed me, but no results were returned in R.
Is there a way to still get the result for example from temporary files somewhere on my harddisk?

Thanks for your help, sessioninfo below:

```
> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252    LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] googleLanguageR_0.2.0 rDNA_2.1.6            dplyr_0.7.5           rJava_0.9-9     
```
Its a good long wait in the Shiny app at the moment, as the API is more suited to batch calls.  For true babel fish goodness, streaming API is needed, but that is only supported via ["rpc"](https://grpc.io/)
https://cloud.google.com/speech/docs/streaming-recognize

Some possibilities for supporting that are:
* gRPC https://github.com/nfultz/grpc/issues/12
* rprotobuf https://github.com/eddelbuettel/rprotobuf
* Wrapping python:
https://cloud.google.com/speech/docs/streaming-recognize#speech-streaming-recognize-python
https://cloud.google.com/natural-language/docs/reference/rest/v1/documents/annotateText