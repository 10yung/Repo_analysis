Does anyone knows how to add a virtual hat on head. which is resizable according to the size of face?
Please help me
Change to allow not only `'FRONTALFACE_PLACEHOLDER'` but also `"FRONTALFACE_PLACEHOLDER"`.

This change is fix for failing replace when use web worker in `clmtrackr.min.js`,
because **double quotations** in `clmtrackr.min.js`.


clmtrackr.js is excellent library! Thank you.

hi i try the examples y put them on my web and even on the example when i use this on my cell phone, the mask never stays freeze on my face is always shaking, there is a way to stop the shaking on the face?
Is it possible to detect when someone blinks their eyes?
Hi i want to know if there is a way to increase the precision of the emotion detecto and new emotions, if the answer is yes where in the code can i add and create my own emotions thanks a lot
While loading your example I am seeing following error in console:
`Uncaught ReferenceError: module is not defined`
Referencing to jsfeat module. Do you experience the same issue?
Hi , i'm studying clmtrackr, and i want to add it to my symfony project .
I setup everything and seem i can get access to it , but when i run the project getCurrentPosition return false and i get a weird error  that maybe is related to the dependency of jsfeat , but i'm not sure.
I share some code , there is  my app.js file 

 ```
import clm from 'clmtrackr';


console.log('Hello Webpack Encore! Edit me in assets/js/app.js');


console.log("video hello");
const constraints = {
    video: true
};

const video = document.getElementsByTagName("video")[0];
console.log(video);
navigator.mediaDevices.getUserMedia(constraints).
then((stream) => {
    console.log(stream);
    video.srcObject = stream

    var ctrack = new clm.tracker();
    //debugger;
    console.log("START!");
    var canvas = document.getElementById('mycanvas');
    ctrack.init();
    console.log(document.querySelector('video'));
    ctrack.start(video);
    //let dueContext = this.canvas.getContext('2d');
    // console.log(document.getElementById("monaimage"));
    //this.ctrack.start(document);
    let update = () => {
        window.requestAnimationFrame(update);
        let positions = ctrack.getCurrentPosition();

        ctrack.draw(canvas);
        console.log("position: " + positions);
        // console.log("LOL!@#!$")

    };
    update();
});

```

and that's the error i get 

blob:http://localhost:8000/e5a722f8-80e3-4305-85b5-40e629b26fa5:5 Uncaught ReferenceError: module is not defined
    at blob:http://localhost:8000/e5a722f8-80e3-4305-85b5-40e629b26fa5:5
    at self.onmessage (blob:http://localhost:8000/e5a722f8-80e3-4305-85b5-40e629b26fa5:5)

I hope that someone can help me , thanks 

I believe I've cloned the repository correctly and installed the node packages correctly, but am receiving a ERR_SSL_PROTOCOL_ERROR when trying to run the examples in Chrome using http-server. I've looked up all the ways to resolve this, but haven't found anything that works. Has this been an issue for others?

Desktop Chrome71 browser is Working.
But Android 's Chrome has an alert.

This project of facesubstitution.html
```
if (webGLContext == null) {
 alert("Your browser does not seem to support WebGL. Unfortunately this face mask example depends on WebGL, so you'll have to try it in another browser. :(");
}

```
I'm stuck with the error here.

`if (!webGLContext || !webGLContext.getExtension('OES_texture_float')) {`

I think that the judgment here does not correspond to an Android device.
I deleted this judgment statement and it worked on Android as well.

Is there a good way to do it?