This is my Pytorch code:
https://github.com/Invokar/Pytorch_Universal-attack.

These days I implement your idea by pytorch. But I find that when I use the same dataset(10,000), my code can only fool 30% images in Validation set(50,000), but your code can fool 85%.I checked it many times but still couldn't find the problem. 
Could you help me? thank you!
Hi. 
Please be aware that imread/imresize under scipy.misc has been removed from 1.2.0/1.3.0.
.[https://docs.scipy.org/doc/scipy-1.2.1/reference/generated/scipy.misc.imread.html](url)
Thank you for the work!
My concept of targeted attack means we want to set specific target class to let the attacker to make such adversarial image. Can universal perturbation do that and how?

The perturbation file is saved for every pass on the dataset so we won't need to start fooling rate from zero but from the file saved in universal_partial.npy. This is similar to saving model after every epoch while training. Similarly the perturbation will be saved after every pass in universal_partial.npy and when starting the universal_pert.py each time it will look at universal_partial.npy and will load the perturbations from there and start fooling from that particular fooling_rate.
When finding the perturbation for MNIST dataset using 1000 samples for each pass the FOOLING_RATE doesn't increase beyond 0.002 even after 1100 passes . The fooling rate is not increasing rather oscillating between 0.0 and 0.002 . I have used 3 conv layers with batch norm  one max pool and 2 fc layers. The UAP calculated after 1100 passes with fooling rate of 0.001 has a mean of >8 as most of absolute value is 10. Please I need some help as I cant understand what is wrong in my implementation. Looking forward to your reply.  
Dear Mr:
I am a student now. I have just studied your codes for about one weeks. I am very interested in your finished paper . I think this paper is of great value to me in the process of studying universal adversarial perturbations.But I have some questions.I will appreciate it if you can explain these problems.

**Question 1:**
v = v + dr in universal_pert.py(Line 67),  the v is the perturbation vectors and dr is the minimal perturbation that fools the classifier. According your codes,  the dr have the dimensions with the input image which has three dimensions and v is the perturbation vectors but your setting is v = 0, which means a real value. why can they be added. I wonder the dimensions of v and dr.

**Question 2:**
dr,iter,_,_ = deepfool(cur_img + v, f, grads, num_classes=num_classes, overshoot=overshoot, max_iter=max_iter_df) in universal_pert.py(Line 63) in which  the function deepfool() is in deepfool.py. 
w = np.zeros(input_shape) (Line 27) which means the dimensions of w is same with that of input_shape which is 3.
w_k = gradients[k, :, :, :, :] - gradients[0, :, :, :, :] in deepfool.py(Line 40) which means the dimensions of w_k is 4.
w = w_k , why can w_k be assigned to w.

Thank you for taking time out of your busy schedule and look forward to hearing from you soon.
Yours faithfully,
   
Thank you very much for the code! Learned a lot from it.

The issue i am facing is that the value of 'v' after being computed is coming out to be NaN.
I am implementing this in Matlab. I have changed the value of 
opts.delta = 0.5 and opts.p = 2 (random changes), but in all the cases it outputs value NaN
The new fooling rate comes around 0.99733
Kindly advice.

P.S: To be more specific the output  
    dr = project_boundary_polyhedron(ddf,ff(idx),Q);  is turning out to be zero
Hi,
Thanks for your code, I learn a lot from it. 

When I run the python code with inception5h model, it works very well and I can reproduce perturbation maps. However, when I try the code with VGG or ResNet models, I always get GPU memory full errors. I used the tensorflow SLIM pretrained models, and freeze them into .pb file, just like the format of inception5h model in your example. Do you have any idea to work around this issue? I use a K40C 11G Mem GPU.

Thanks!

In demo_inception.py:
    path_train_imagenet = '/datasets2/ILSVRC2012/train'

is passed into create_imagenet_npy(). This path doesn't exist, so the rest of the function doesn't run. What is the best way to get the data so the universal perturbation vector can be created?