I am storing three values in userStorage. 
```
conv.user.storage.counter = 1;
conv.user.storage.remind = false;
conv.user.storage.share = false;

```
The values get stored normally and work on my account and for many other accounts of some of my alpha testers as well.
Unfortunately , for some of my alpha testers , even though they are verified users with all related settings like web activity etc enabled nothing is stored in their userstorage.
I have noticed that this happens for G Suite accounts. My own G suite account is facing this issue. 
Is this a bug or is it just that I am not aware of some setting ? 
Any help would be appreciated . 
Thank you.
## Or: Media responses: Handling callback BEFORE playback completion?

The issue is related to the closed issue: https://github.com/actions-on-google/actions-on-google-nodejs/issues/243

The UX scenario:
I experienced an issue, when trying to develop an action on google application (using Action SDK) 
 to replicate google assistant UX when a user listen a Spotify playlist... 

Specifically I would let the user interrupt the audio streaming asking something about what listening in a specific moment. That's appears not possible so far. 
 
I would like to play some audio file (media response), say a MP3 song long something like three minutes (00:03:00). Afterward, at the middle of the playing song, say at 00:01:45, I would let user ask for example: 

> **Ok Google, What's the name of the song?**  

or 

> **Ok Google, Who play the Rhodes piano?**

The actions would manage a Q/A, with these possible steps:
- PAUSE the playback (implicit)
- catch the user intent, 
- reply user with the answer
- RESUME the playback (TBD).

My test result fails:
When the media response plays, the action is able to interrupt the audio and it's able manage the question, but **the playback IS NOT RESUMED**. That's weird (for my ears)!

It's debatable, but **I think that's a BUG, or at least let's call a Change Request**: I would let developer the choice to resume or not the underlying streaming after a user interruption. 

> BTW, The fact interrupted audio streaming is resumed after a user Q/A, is in compliance with **what happens on Google Assistant/Google Home with live streaming or an long running playlist streaming**. By example, if a Google Home user say 

> **Ehi Google, play BBC Radio 4**
> _blablabla brexit ... blablabla brexit ... blablabla brexit ..._
 
> // interrupting the BBC streaming with a question: 
> **Ehi Google, what's the weather?**
> _Right now in Genoa, it's sunny blablabla ..._

> // end the answer, RESUME the BBC streaming
> _blablabla brexit ... blablabla brexit ... blablabla brexit ..._
 
> // until the user explicitly ask to close
> **Ehi Google, stop**

---

So, INTO THE THIRD PARTY APPS (ACTIONS) I would like the same UX for the final user. **The listener of an audio file (song/news/book, whatever) would be able to interrupt the audio streaming, ask a question and afterward the audio streaming would (**optionally**) be RESUMED.** 

So my request, from the developer perspective, is related on that possibility to OPT-IN an audio playback resume mode. My proposal is:
- to modify behavior of `actions.intent.MEDIA_STATUS` to catch the interrupt status (let's call it `STOPPED`). 
- allowing to playback an audio file from an offset time (to enable 'resume')

The event BEFORE playback completion would report the elapsed time from the start time of audio streaming (e.g.  00:01:45, or in milliseconds amount), to allow developer to understand the exact point of user interrupt.  **That's important to answer user on the precise context (e.g. in case audio was an audio book, or a news, etc.).**

See the following PSEUDO code:

```javascript
/*
 * MEDIA_STATUS intent
 * Track the elapsed time (milliseconds) until user stop playback
 */
app.intent('actions.intent.MEDIA_STATUS', (conv) => {

  const mediaStatus = conv.arguments.get('MEDIA_STATUS')
  
  // CHANGE REQUEST
  // suppose the event: 'STOPPED'
  if (mediaStatus && mediaStatus.status === 'STOPPED') {
     
     // memorize number of milliseconds playd until the user stop.
      offsetTime = mediaStatus.stopTime 
   }      
  else if (mediaStatus && mediaStatus.status === 'FINISHED') {
    response = 'Hope you enjoyed the tune!'
  }
}

/*
  * ON-PLAYBACK QUERIES intent
  */
app.intent('actions.intent.TEXT', (conv) => {

     // reply to query 
     // parse the query text and find an answer on a DB, etc.
     ...

    // CHANGE REQUEST
    // resume the playback after the reply
    // resuming playback from the offsetTime  
    // suppose having the method resume()
     conv.resume(mediaresponse, offsetTime)
}

```
 
> **A last note: The request for me is crucial to develop a new generation of conversational UX, where user can interact with a "static" content streaming (music, book, news, any audio file or streaming) interacting and conversating with that "content"... (using metadata, etc,etc. ;-) )**. 

Please let me know if there is something obscure in my rant or I missing something about an already possible configuration.

If you like my request, please vote +1 

Thanks for your patience.
giorgio
Currently, the behavior interfacing with the dialogflow API is if the `userStorage` does not change, `actions-on-google` does not send back the storage in the response. However, the next request no longer contains the `userStorage` properties. 

I assume something changed with the dialogflow API and this is a side effect. It has lead to many actions breaking on my end.

The intended behavior now seems we need to send the `userStorage` with every response to persist it to the next request.

https://github.com/actions-on-google/actions-on-google-nodejs/blob/c12e5da0c1585dec0b276a973393adc8ae291a0c/src/service/actionssdk/conversation/conversation.ts#L539
I had created one list in intent as shown below, but when I select any option nothing happened:


```
const express = require("express");
const bodyParser = require("body-parser");

'use strict';

const {
  dialogflow,
  List,
 } = require('actions-on-google');

const app = dialogflow({debug: true});

// List
app.intent('mylist', (conv) => {
  conv.ask('This is an example of a list.');
  conv.ask(new List({
    items: {
      'key_1': {
        title: 'Number one',
        synonyms: ['synonym of KEY_ONE 1', 'synonym of KEY_ONE 2'],
      },
     'key_2': {
        title: 'Number two',
        synonyms: ['synonym of KEY_TWO 1', 'synonym of KEY_TWO 2'],
      }
    }
  }));
});

// Created Dialogflow intent with `actions_intent_OPTION` event
app.intent('mylist-selected', (conv, input, option) => {
  conv.close(`${option} is a selected`);
  
});

const expressApp = express().use(bodyParser.json());
expressApp.post("/", app);
expressApp.get('/', (req, res) => {
  res.send('Dialogflow Server ')
})

expressApp.listen(process.env.PORT || 3000, () => {
  console.log("server is running");
});
```

Intent `mylist-selected` never called.
With oAuth2 account linking once the pop-up opens, and the data gets disconnected and reconnects back in some time, then the assistant get hanged, and shows loading constantly.

Hello, 

I'm trying to build an app that reminds users to take their medication at a specific time or Routine. Is there a way to create a routine from my custom app without the user leaving the app and creating the routine outside of it? 
I'm having a issue with AWS that I really can't understand. My app starts correct, using the simulator that will trigger an intent results in an error that I really don't understand. 

Code in AWS:
```
const { dialogflow, Table, Image } = require('actions-on-google');
const df = dialogflow({debug: true});

df.intent('nextdeparture', async (conv, params) => {
  conv.close('aws test');
});

exports.fulfillment = df;
```

From the logs in aws I can see a simpleResponse

```
{
    "status": 200,
    "headers": {
        "content-type": "application/json;charset=utf-8"
    },
    "body": {
        "payload": {
            "google": {
                "expectUserResponse": false,
                "richResponse": {
                    "items": [
                        {
                            "simpleResponse": {
                                "textToSpeech": "aws test"
                            }
                        }
                    ]
                }
            }
        }
    }
}
```

But this is what I'm getting in the simulator: 

**MalformedResponse**
Failed to parse Dialogflow response into AppResponse because of invalid platform response: Could not find a RichResponse or SystemIntent in the platform response for agentId: 0da3cbb2-f7db-4297-bb2c-4bbf18a73db1 and intentId: 9aa705a5-6984-4905-859e-9307d4af625e.
npm audit found 10 high severity vulnerabilities of Machine-In-The-Middle type on yours package.
The vulnerabilities is on https-proxy-agent package that yours package is dependent.
Other information is at this link: https://www.npmjs.com/advisories/1184
If response of the call to requestSync method is not in proper JSON then the response handler throws SyntaxError exception at [JSON.parse](https://github.com/actions-on-google/actions-on-google-nodejs/blob/1c9c56b1e837a7cc54bd1c8058d3ddbe2747863b/src/service/smarthome/smarthome.ts#L301), without rejecting the promise causing the whole node application to crash.
it should be wrapped around a try-catch block and rejected properly.

..