我在windows环境下运行了demo下的马蜂窝，然后抓完之后去哪里看？
有验证码登录的网站如何爬去，识别验证码没找到
页面数据超过3M爬虫不处理有什么解决办法吗？
我用爬虫爬的都是 json 数据，就是调用对方API返回 json数据，然后我需要 jsonpath 解析数据，看里面写支持 jsonpath，结果我用了始终都无法导出 csv 文件，去看了 selector.php 文件，里面有 xpath, css, regx ，但是没有 jsonpath ?

文档写错了？ 这会支持 jsonpath 吗？ 折腾了一天好不容易把爬虫写好了，结果发现文档中的功能没有，好悲伤 
 已经看了文档 
xpath 解析到a标签之前都是正常的
解析a标签就获取不到href属性了
a@href了
![}87JWN%L_YI`PI9TVQ1MRI6](https://user-images.githubusercontent.com/9668962/63395282-d0438300-c3f5-11e9-9f8a-725dc1c1fe3c.jpg)
挂着下了一晚上，才下了一千多条数据...但是任务还在继续，但是增长非常慢，是不是被网站限速之类了呢？

爬取不同域名这样写一直不走on_scan_page 和 on_list_page这两个方法，只走on_content_page

    'domains' => array(
        'zhongshang114',
        'detail.zhongshang114.com'
    ),
    'scan_urls' => array(
        'http://detail.zhongshang114.com/list.php?catid=91400'            
    ),
    'list_url_regexes' => array(
        "http://detail.zhongshang114.com/list.php\?catid=91400\&page=\d+"         // 公司列表页
    ),
    'content_url_regexes' => array(
//        "http://detail.zhongshang114.com/list.php\?catid=91400\&page=\d+",
        "http://.*?.zhongshang114.com/"
    ),

这个content_url_regexes该怎么写呢


https://github.com/jonnnnyw/php-phantomjs    考虑整合吗？
我测试了一下，在on_start中好像只能使用内置方法，操作requests的方法好像失效了。
比我在on_start中
requests::set_proxy(
		array('http://H858N4N1MUE530KD:1D71528FFEF66@http-dyn.abuyun.com:9020')
	);
那个代理地址没用的，居然照样跑。。。