'unarchiveObject(with:)' was deprecated in Mac Catalyst 13.0: Use +unarchivedObjectOfClass:fromData:error: instead
'archivedData(withRootObject:)' was deprecated in Mac Catalyst 13.0: Use +archivedDataWithRootObject:requiringSecureCoding:error: instead

I think it can support Mac Catalyst. iOS runs on Mac.
Here are a few small warnings to deal with.
<img width="683" alt="Screenshot 2019-12-06 at 12 25 28 PM" src="https://user-images.githubusercontent.com/37287616/70302626-8f943c00-1823-11ea-9135-06b67c403d6e.png">

Facing this issue while updating to swift 5.1
I recently experienced a crash.

I installed it using SwiftPM but it crashed. It's release build, not debug build.

To test this, I ran a manual / Cocoapods installation. But there was no problem.
So I reinstalled with Cocoapods.

Some other libraries(e.g. Parchment)  had same issue. Using generic seems to be the problem.
The library seems to prevent apps from running on iOS 12 (and possibly below) except when being run via Xcode.
Nether TestFlight nor Ad-Hoc build works when installed to a iOS 12 device. However, the same build works on a iOS 13 device.
I tested this with a newly created blank project only adding SwiftyUserDefaults via CocoaPods. Removing the pod makes the app work again.
**Keys.swift**
```
extension DefaultsKeys {
    enum Foo {
        enum Bar1 {
            var key: DefaultsKey<String> { .init("foo.bar1.key", defaultValue: "") }
        }
        enum Bar2 {
            var key: DefaultsKey<String> { .init("foo.bar2.key", defaultValue: "") }
        }
    }
}
```

**Test.swift**
```
Defaults.*?*
```

How can I work?
In the earlier 3.x version I had this:

```
class SomeClass: NSObject, NSCoding {
    var someVariable: String?
    
    init(bookIdentifier: String) {
        super.init()
        self.someVariable = someVariable
    }
    
    ///NSCoding
    func encode(with aCoder: NSCoder) {
        aCoder.encode(someVariable, forKey: "someVariable")
    }
    
    ///NSCoding
    required init?(coder aDecoder: NSCoder) {
        self.someVariable = aDecoder.decodeObject(forKey: "someVariable") as? String
    }
}
extension DefaultsKeys {
    static let someVariables = DefaultsKey<[String: SomeClass]>("someVariables")
}

extension UserDefaults {
    subscript(key: DefaultsKey<[String: SomeClass]>) -> [String: SomeClass] {
        get {
            if let someVariables =  unarchive(key) {
                return someVariables
            }
            else {
                return [:]
            }
        }
        set { archive(key, newValue) }
    }
}
```

According to migration guide it should be now just:
```
class SomeClass: NSObject, NSCoding, DefaultsSerializable {
    var someVariable: String?
    
    init(bookIdentifier: String) {
        super.init()
        self.someVariable = someVariable
    }
    
    ///NSCoding
    func encode(with aCoder: NSCoder) {
        aCoder.encode(someVariable, forKey: "someVariable")
    }
    
    ///NSCoding
    required init?(coder aDecoder: NSCoder) {
        self.someVariable = aDecoder.decodeObject(forKey: "someVariable") as? String
    }
}
extension DefaultsKeys {
    static let someVariables = DefaultsKey<[String: SomeClass]>("someVariables", defaultValue: [:])
}
```

But I'm getting following error:
```
[User Defaults] Attempt to set a non-property-list object {
    9789511310716 = "<AppName.SomeClass: 0x28085fc40>";
} as an NSUserDefaults/CFPreferences value for key someVariables
*** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: 'Attempt to insert non-property list object {
    9789511310716 = "<AppName.SomeClass: 0x28085fc40>";
} for key someVariables'
```

So it doesn't seems to support dictionary with NSCoding values, even though you state that `[String: Any]` is supported.
I am trying to store value (Date) in user defaults. 
This is the key
`    static let firstActivityDate = DefaultsKey<Date?>("firstActivityDate
`
And code responsible for storing
`    func setActivityDate() {
        if Defaults[AppRateDefaults.firstActivityDate] == nil {
                Defaults[AppRateDefaults.firstActivityDate] = Date()
        }
    }
`
I have to run it twice (in two sessions of application) to correctly store value. First attempt is showing value as long as app is up and running. After turning off and running once again it's once again empty. After second attempt value persists.

Edit:
It seems to be connected with thread. After running this part of code on the main it seems to work fine.
Is custom setter/getter for defaults currently supported?
I saw in #154 that it was initially planned but I don't see it in the docs.
When the UserDefaults return `nil`, SwiftyUserDefaults falls back to using the `defaultValue` by default.

But what if you set e.g. a `String?` that _can_ be nil?

I thought `defaultValue` would mean "the initial value", but apparently it doesn't. I think the current behavior is weird, though. Because you can sensibly use it to call `register(defaults:)` and have your initial fallback values be used on one hand, but then cannot get rid of it all all on the other.

I'd prefer to change the implementation to fall back to `defaultValue` for non-optional types, only.
I started with `UInt`, but the obvious next step would be to add Int64/32/16/8 and UInt64/32/16/8.

The code is pretty repetitive. In other projects, we used a code generator for this to prevent typos and code that's getting on one's nerves to maintain. But for 8 new types and their tests, we could stick with manual implementations just as well.

- Do you want to support the other types out of the box at all, anyway?
- Do you want manual or generated code?