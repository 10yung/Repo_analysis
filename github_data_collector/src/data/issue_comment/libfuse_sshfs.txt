Bruce Leidl (@brl) gave a detailed description of the reasons behind his proposal to obfuscate the handshake process of ssh connection. Go over it if you have the time. It's not long and fairly easy to understand. https://github.com/brl/obfuscated-openssh

It would be nice if sshfs would support this way of obfuscation. There are patches for openssh, so maybe it is not that much effort to add a "obfuscation option" for sshfs. https://zinglau.com/projects/ObfuscatedOpenSSHPatches.html

Thank you in advance.
I suspect this issue is known/understood, but I can't find an open issue for it.

This has been a problem for me for some time now, and chasing threads on Stack Overflow and the like (search sshfs "Transport endpoint is not connected") suggests to me this is a years old issue that has never been addressed. Whether the fix would be in sshfs or elsewhere I don't know, but I think it's fairly reasonable to expect a reconnection attempt to be made if the reconnect option has been passed and the mount point is no longer available.

The problem appears to be when the mount is still listed under `mount`, but there is no process for it under sshfs, e.g.:

Note that while I've changed some users/paths for anonymity, the issue is otherwise exactly as described, i.e. both mount points, the one currently working and the one currently not, are adjacent on both server and client (so you might expect them to either work or fail together, but they don't).


Autofs config:

`cat /etc/auto.sshfs`
`data1 -fstype=fuse,port=22,rw,nodev,nonempty,noatime,allow_other,max_read=65536,reconnect,workaround=all,ServerAliveInterval=15,ServerAliveCountMax=3 :sshfs\#user@server1\:/storage/data1`
`data2 -fstype=fuse,port=22,rw,nodev,nonempty,noatime,allow_other,max_read=65536,reconnect,workaround=all,ServerAliveInterval=15,ServerAliveCountMax=3 :sshfs\#user@server1\:/storage/data2`


Output of mount command:

`mount | grep server1`
`user@server1:/storage/data1 on /mnt/sshfs/data1 type fuse.sshfs (rw,nodev,noatime,user_id=0,group_id=0,allow_other)`
`user@server1:/storage/data2 on /mnt/sshfs/data2 type fuse.sshfs (rw,nodev,noatime,user_id=0,group_id=0,allow_other)`


Autofs status (note absence of data2 mount point specified above):

user@serverx:/home/user# systemctl status autofs
● autofs.service - Automounts filesystems on demand
   Loaded: loaded (/lib/systemd/system/autofs.service; enabled; vendor preset: enabled)
   Active: active (running) since Wed 2019-10-23 14:46:52 UTC; 2 months 13 days ago
 Main PID: 8524 (automount)
    Tasks: 17 (limit: 4915)
   Memory: 8.8M
      CPU: 18h 19min 6.124s
   CGroup: /system.slice/autofs.service
           ├─8524 /usr/sbin/automount --pid-file /var/run/autofs.pid
           ├─8718 ssh -X -a -oClearAllForwardings=yes -oport=22 -oServerAliveInterval=15 -oServerAliveCountMax=3 -2 user@server1 -s sftp
           └─8755 sshfs user@server1:/storage/data1 /mnt/sshfs/data1 -o rw,nodev,noatime,uid=0,gid=0,port=22,nonempty,allow_other,max_read=65536,reconnect,workaround=[truncated by terminal]


Now, if I `umount /mnt/sshfs/data2`, then attempt an `ls` of the same directory, the volume is automatically remounted. But without the `umount`, `ls` (here of the parent directory) yields:

user@serverx:/home/user# ls -l /mnt/sshfs/
ls: cannot access '/mnt/sshfs/data2': Transport endpoint is not connected
total 4
drwxr-xr-x 1 root root 4096 Jul 22 11:46 data1
d????????? ? ?    ?       ?            ? data2


So, why is the volume not remounted automatically, when attempts to access it are returning "not connected" errors?






Hi,

I'm running sshfs on top of osxfuse on macOS Catalina 10.15.2. I use sshfs to connect to our shared storage at my work. For some reason, sshfs seems to be trying to reconnect multiple times when disconnected, but it fails to reconnect. This is being flagged by my work's IT network, which is resulting in my IP address getting blocked. Here is the command-line I'm using:

```
sshfs "$user@$host:/" /ssh -o idmap=file -o uidfile=uidfile -o gidfile=gidfile -o nomap=ignore -o allow_other,extended_security,noappledouble
```

This is what my IT network's logs say:
```
2020-01-03 17:22:13 nullzero <my ip> syslog@pig.lbl.gov AUTO_DROP: SSH_BRUTEFORCE: ADVISE: HIGH_FAILED_LOGIN: PROTO=SSH USER=<my user> IP=<my ip>
```
where `<my ip>` is my IP address, and `<my user>` is my SSH username. I don't understand why sshfs is trying to reconnect when I did not give it the -o reconnect option. Is there some code in sshfs that causes it to try to reconnect by default? Is there some way to disable it?
So sshfs freezes whole user and will not react to CTRL+C signal. Only initiating kill -9 <sshfs_pid> as root user clears the freeze situation. It also causes the mount point to go stale:
#ls -l
d?????????  ? ?    ?            ?            ? some_dir

**Cause:** 
It took really long time to find the cause of this problem.

Local directory to be mounted: /home/user/some_dir

So let's say that we have e.g. this kind of path normally:
/home/user/bin:/home/user/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

If I add the directory to be mounted in the **beginning** of the PATH, **sshfs freezes on connect**.
**/home/user/some_dir**:/home/user/bin:/home/user/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

If I add the directory to be mounted in the **end** of the PATH, **sshfs works just fine**:
/home/user/bin:/home/user/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:**/home/user/some_dir**

Command used:
#cd ~
run as normal user:
#sshfs -o nonempty user@mgmt:/home/user/some_dir some_dir

System:
Ubuntu 16.04.6 LTS
sshfs 2.5-1ubuntu1
fuse 2.9.4-1ubuntu3.1

Debug:
#sshfs -o debug,sshfs_debug,loglevel=debug,nonempty user@mgmt:/home/user/some_dir some_dir
SSHFS version 2.5
FUSE library version: 2.9.4
nullpath_ok: 0
nopath: 0
utime_omit_ok: 0
executing <ssh> <-x> <-a> <-oClearAllForwardings=yes> <-ologlevel=debug> <-2> some_user@mgmt <-s> <sftp>
HANG....

Fix suggestion:
- Check if path in $PATH really exists before trying to access it OR check if local directory to be mounted is in PATH before trying to connect to the remote with ssh
- Give a proper error message rather than just freezing.

Hi,
sshfs only return fingerprint and visualhostkey if the host is unknown. After you accept the host key, he don't return the fingerprint and visualhostkey anymore and never show the banner message or personnal banner message. is it possible to make it show no-error message from ssh?
I'm looking at the code, but it's my first day looking at. Maybe someone can make a patch faster than me.
Thanks for reading, and I help if I can.
sshfs -o allow_other,IdentityFile=/home/user/.ssh/id_rsa user@serveur:/home/user/partage /home/localuser/Partage -o nonempty -o VisualHostKey=yes

fuse: unknown option `VisualHostKey=yes'

I have add this conf "VisualHostKey=yes" in :
sudo nano /etc/ssh/ssh_config
and
nano .ssh/config

I can't see any VirtualHostKey with sshfs.

Work for ssh.
This looks like a bug to me:

https://github.com/libfuse/sshfs/blob/eac420791c667b038817aaa481c67646e9654e15/sshfs.c#L1032-L1076

Why isn't `setsid()` called after the first `fork()`? By leaving it open daemonized process can still get at least `SIGINT`, which wasn't intended for it.

How to reproduce:

1. `mkdir ~/sshfs-tst`
2. `vim`
3. (in vim) `:!sshfs server: ~/tst`
4. (in vim) `:!read` and hit <kbd>CTRL-C</kbd>

`~/tst` gets unmounted, which shouldn't happen.

Moving `setsid()` should be enough to fix this.
I recently upgraded my system and in the process went from sshfs 3.0.0 to 3.3.1 and I can no longer use git over an sshfs mount.
```
$ git pull
error: cannot open .git/FETCH_HEAD: Permission denied
```
The file itself has no permission issues:
```
$ rm .git/FETCH_HEAD
$ echo create > .git/FETCH_HEAD
$ cat .git/FETCH_HEAD
create
$ git pull
error: cannot open .git/FETCH_HEAD: Permission denied
$ cat .git/FETCH_HEAD
[now a zero-length file]
```
Running git through strace says:
```
openat(AT_FDCWD, ".git/FETCH_HEAD", O_WRONLY|O_CREAT|O_APPEND, 0666) = -1 EACCES (Permission denied)
```
Why would `openat()` be returning `EACCES` when whatever functions the shell is using work just fine on the same file path?

Is anyone else able to run `git fetch` on a git repository accessed over sshfs?
In my local network, I am running the following command (user and remote name anonymised):

```
sshfs myself@remote:/home.net/myself ~/remote
myself@remote's password:
<CTRL+C>
```

When using CTRL+C while entering the password, the directory will be mounted with an unconnected endpoint, so it's there but not usable:

```
mount -l
[...]
myself@remote:/home.net/myself on /home/myself/remote type fuse.sshfs (rw,nosuid,nodev,user=myself)
ls ~/remote
ls: transport endpoint is not connected: /home/myself/remote
```

This means that re-trying to mount it will fail:

```
sshfs myself@remote:/home.net/myself ~/remote
fuse: bad mount point `/home/myself/remote': Transport endpoint is not connected
```

The workaround is to manually unmount it and then try again:

```
fusermount -u remote
sshfs myself@remote:/home.net/myself ~/remote
myself@remote's password:
```

However, it would be nice if `sshfs` failed gracefully and automatically unmounted the non-connected directory for me.
I'm wondering if the following could be done.  If I understand correctly sshfs/fuse seems to assign its own inode numbers to files and hard links are not assigned the SAME inode number and the link count is not incremented.    Would it be possible to do just that?   If it sees the same inode number from the orig filesystem for different filenames it assigns the existing inode number (not a new one) and increments the  link count for both. 