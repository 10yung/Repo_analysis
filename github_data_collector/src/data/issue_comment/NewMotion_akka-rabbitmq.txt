```
[ERROR] [12/11/2019 12:08:55.034] [fixture-cluster-akka.actor.default-dispatcher-4] [akka.tcp://cluster@127.0.0.1:2552/user/mq-connection/{queueName}] close com.rabbitmq.client.AlreadyClosedException: chan
nel is already closed due to channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '{queueName}' in vhost '{vhost}', class-id=50, method-id=20)
```
I have an interesting flow that I am trying to implement. 

Our business requires using one connection per VM to connect to RabbitMQ. What I have Implemented is the following flow.

Call our API -> GET queueLink/name -> have a single connection actor shared on the actorsystem -> spawn an actor in the cluster to handle the data events -> spawn a MQSubscriber for the data actor -> Connect the Subscriber which Heartbeats between Data event and Subscriber -> On connection failure, suspend data events and wait for reconnect -> on reconnect obtain new queueLink/name and use the MQSubscriber to connect. 

The issue I am having is the old channel actor is not dying when the connection drops and I cannot find a way to kill it. I do not care about keeping it around since our queueNames are generated dynamically. I need a way to kill the channel actor when the connection drops.

```scala
class MQSubscriber(receiver: ActorRef)(implicit val actorSystem: ActorSystem) extends Actor with ActorSystemLogging {
  private val exchange                                    = "amq.fanout"
  implicit val executionContext: ExecutionContextExecutor = context.dispatcher
  import context.become

  private def setupSubscriber(channel: Channel, self: ActorRef, queueName: String) {
    channel.queueBind(queueName, exchange, "")

    def fromBytes(x: Array[Byte]) = new String(x)

    val consumer = new DefaultConsumer(channel) {
      override def handleDelivery(consumerTag: String, envelope: Envelope, properties: BasicProperties, body: Array[Byte]) {
        receiver ! MQMessage(envelope.getDeliveryTag.toString, fromBytes(body))
        channel.basicAck(envelope.getDeliveryTag, false)
        super.handleDelivery(consumerTag, envelope, properties, body)
      }

      override def handleCancel(consumerTag: String): Unit = {
        receiver ! MQEvents.UnexpectedDisconnect
        super.handleCancel(consumerTag)
      }

      override def handleShutdownSignal(consumerTag: String, sig: ShutdownSignalException): Unit = {
        receiver ! MQEvents.UnexpectedDisconnect
        super.handleShutdownSignal(consumerTag, sig)
      }
    }
    channel.basicConsume(queueName, false, consumer)
    receiver ! MQEvents.Connected
  }

  def checkHeartBeat(connection: Option[ActorRef], heartbeatTime: Int)(implicit ex: ExecutionContext): Future[MQResponse] = {
    implicit val timeout: Timeout = Timeout(100.milliseconds)
    scheduleHeartBeat(heartbeatTime)
    connection match {
      case None =>
        log.error(s"No Connection found yet")
        Future.successful(MQEvents.NoConnection)
      case Some(connection) =>
        (connection ? ConnectionActor.GetState)
          .map {
            case ConnectionActor.Disconnected =>
              log.error(s"Connection $connection is Disconnected")
              MQEvents.Disconnected
            case ConnectionActor.Connected => MQEvents.HeartBeat
          }
          .recover {
            case _: AskTimeoutException | _: ActorNotFound =>
              log.error(s"Connection ${connection.path.name} Actor Timeout or not found!!!")
              MQEvents.Lost
          }
    }
  }

  def scheduleHeartBeat(heartbeatTime: Int): Cancellable =
    context.system.scheduler.scheduleOnce(FiniteDuration(heartbeatTime, SECONDS), self, MQEvents.CheckHeartBeat)

  override def receive: Receive = process(None, 1, "")

  def process(connection: Option[ActorRef], heartbeatTime: Int, queueName: String): Receive = {
    case MQSubscriber.Start(queueName, connection) =>
      connection ! CreateChannel(ChannelActor.props((channel, actor) => {
        setupSubscriber(channel, actor, queueName)
      }), Some(queueName))
      become(process(Option(connection), 1, queueName))
      scheduleHeartBeat(heartbeatTime)
    case MQSubscriber.Stop       => self ! PoisonPill
    case MQEvents.CheckHeartBeat => checkHeartBeat(connection, heartbeatTime).map(receiver ! _)
    case MQEvents.StartCircuitBreaker =>
      become(process(connection, 2, queueName))
    case MQEvents.CloseCircuitBreaker =>
      become(process(connection, 1, queueName))
    case _ =>
  }
}

object MQSubscriber {
  case class Start(queueName: String, connection: ActorRef)
  case object Stop
}
```


I have a problem with the logging implementation on the Connection and Channel Actors. As they use the same logger as the ActorSystem I cannot change it's level to be different from my ActorSystem?

Is there a way to set the level for the Actors by themselves?
We're currently having issues with some of our builds that still rely on fairly old versions of `akka-rabbitmq`
```
sbt.ResolveException: unresolved dependency: com.thenewmotion.akka#akka-rabbitmq_2.11;2.3: not found
```
even though we have the resolver configured to use the newmotion Nexus in our `build.sbt`s:
```
resolvers += "New Motion Repository" at "http://nexus.thenewmotion.com/content/groups/public/"
```

It looks like the jars are missing from the repository, but the folder structure is still intact:
<img width="987" alt="Screenshot 2019-04-08 at 11 14 15 AM" src="https://user-images.githubusercontent.com/1636981/55696469-a6ae3000-59ef-11e9-87b6-9ca9c05f70c2.png">
https://nexus.thenewmotion.com/content/groups/public/com.thenewmotion.akka/akka-rabbitmq_2.11/2.3/jars/


Hi, I am trying to test the following example but it doesn't work.
```
object PublishSubscribe extends App {
  implicit val system = ActorSystem()
  val factory = new ConnectionFactory()
  val connection = system.actorOf(ConnectionActor.props(factory), "akka-rabbitmq")
  val exchange = "amq.fanout"


  def setupPublisher(channel: Channel, self: ActorRef) {
    val queue = channel.queueDeclare().getQueue
    println(channel)
    channel.queueBind(queue, exchange, "")
  }

  connection ! CreateChannel(ChannelActor.props(setup), Some("publisher"))

  def setupSubscriber(channel: Channel, self: ActorRef) {
    val queue = channel.queueDeclare().getQueue
    println(channel)
    channel.queueBind(queue, exchange, "")
    val consumer = new DefaultConsumer(channel) {
      override def handleDelivery(consumerTag: String, envelope: Envelope, properties: BasicProperties, body: Array[Byte]) {
        println("received: " + fromBytes(body))
      }
    }
    channel.basicConsume(queue, true, consumer)
  }

  def setup(channel: Channel, self: ActorRef): Unit = {
    setupPublisher(channel, self)
    setupSubscriber(channel, self)
  }

  connection ! CreateChannel(ChannelActor.props(setup), Some("subscriber"))

  Future {
    def loop(n: Long) {
      val publisher = system.actorSelection("/user/rabbitmq/publisher")

      def publish(channel: Channel) {
        println("publish")
        channel.basicPublish(exchange, "", null, toBytes(n))
      }

      publisher ! ChannelMessage(publish, dropIfNoChannel = false)

      Thread.sleep(1000)
      loop(n + 1)
    }

    loop(0)
  }

  def fromBytes(x: Array[Byte]) = new String(x, "UTF-8")

  def toBytes(x: Long) = x.toString.getBytes("UTF-8")
}
```

The publish method is not called by 

`  publisher ! ChannelMessage(publish, dropIfNoChannel = false)` 
Hi
When I send many ChannelMessage with a high rate to ChannelActor with `dropIfNoChannel = false` if I stop rabbitmq and after a duration of time like 1 minute start rabbitmq again, the ChannelActor blocked for process many messages and can't process other message and throw heap space error.
I write this code:

```
import akka.actor.{ActorRef, ActorSystem}
import akka.pattern._
import akka.util.Timeout
import com.newmotion.akka.rabbitmq.{ChannelActor, ChannelCreated, ChannelMessage, ConnectionActor, ConnectionFactory, CreateChannel}
import com.rabbitmq.client.MessageProperties

import scala.annotation.tailrec
import scala.collection.mutable
import scala.concurrent.ExecutionContext
import scala.concurrent.duration._

object Exam1 extends App {

  val system = ActorSystem()

  implicit val timeout: Timeout = Timeout(2 second)
  implicit val executionContext: ExecutionContext = system.dispatcher

  val unconfirmed = mutable.Set.empty[Long]

  val connFactory = new ConnectionFactory()
  connFactory.setHost("127.0.0.1")
  connFactory.setPort(5672)
  connFactory.setUsername("amqp")
  connFactory.setPassword("pass")

  val pubConnActor = system.actorOf(ConnectionActor.props(connFactory))

  Thread.sleep(5000)

  @tailrec
  def produce(chActor: ActorRef): Unit = {
    chActor ! ChannelMessage({
      ch =>
        println("------------------------")
        ch.basicPublish("amq.direct", "me-topic", MessageProperties.PERSISTENT_BASIC, "message".getBytes("UTF-8"))
    }, dropIfNoChannel = false)
    produce(chActor)
  }

  (pubConnActor ? CreateChannel(ChannelActor.props().withMailbox("bounded-mailbox"))).mapTo[ChannelCreated] map {
    case ChannelCreated(chActor) =>
      produce(chActor)
  }

}
```

When I run my code and after a duration of time stop rabbitmq and after a duration of time start again I get heap space error and stop my program.
I think this is for loop function in ChannelActor.
Please fix it and choose another way.



In cluster environment usually it is possible to specify node's address in factory.newConnection(List<Address> addrs) method. Is it possible to do the same in Newmotion. 
Im trying to:
1. Create channel,
2. Bind things,
3. Publish a list of messages,
4. Close everything and wait for it to close,
5. Shut down system.

Here is my code:

```scala
import akka.actor.{ActorRef, ActorSystem}
import com.newmotion.akka.rabbitmq._

import scala.concurrent.duration._
import scala.concurrent.{Await, ExecutionContext}

val queueName = "my-queue"
val exchange = "my-queue"
val cf: ConnectionFactory = new ConnectionFactory()

val sys = ActorSystem("queue-system")
implicit val ec: ExecutionContext = sys.dispatcher
val conn = sys.actorOf(ConnectionActor.props(cf), "connection")

def setupProducer(channel: Channel, self: ActorRef) {
  val queue = channel.queueDeclare(queueName, true, false, false, java.util.Collections.emptyMap[String, AnyRef]()).getQueue
  channel.exchangeDeclare(exchange, "direct", true)
  channel.queueBind(queue, exchange, "")
}

val channel = conn.createChannel(ChannelActor.props(setupProducer), Some("publisher"))

val events = List("1", "2", "3")
events.map(_.getBytes) map { data =>
  channel ! ChannelMessage((c: Channel) => {
    c.basicPublish("",queueName, null, data)
  })
}

sys stop channel
sys stop conn
Await.result((for {
  c <- sys.whenTerminated
} yield c), 30 seconds)
```

I'm getting these errors:

```
[INFO] [08/07/2017 14:51:56.472] [queue-system-akka.actor.default-dispatcher-4] [akka://queue-system/user/connection/publisher] Message [com.newmotion.akka.rabbitmq.ChannelMessage] from Actor[akka://queue-system/deadLetters] to Actor[akka://queue-system/user/connection/publisher#1004003557] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [08/07/2017 14:51:56.472] [queue-system-akka.actor.default-dispatcher-4] [akka://queue-system/user/connection/publisher] Message [com.newmotion.akka.rabbitmq.AmqpShutdownSignal] from Actor[akka://queue-system/user/connection/publisher#1004003557] to Actor[akka://queue-system/user/connection/publisher#1004003557] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [08/07/2017 14:51:56.474] [queue-system-akka.actor.default-dispatcher-3] [akka://queue-system/user/connection] closing connection to amqp://user@localhost:5672//
[INFO] [08/07/2017 14:51:56.479] [queue-system-akka.actor.default-dispatcher-2] [akka://queue-system/user/connection] Message [com.newmotion.akka.rabbitmq.AmqpShutdownSignal] from Actor[akka://queue-system/user/connection#-1778410342] to Actor[akka://queue-system/user/connection#-1778410342] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
```

What is the best way to accomplish this? I guess when I want to shut down, the connection hasn't event published the messages, is there a way of waiting for it?

Thanks!!
Hi,

Is it possible to pause|resume consuming ? 
According to documentation of rabbitmq it can be achieved with `channel.basicCancel | channel.basicConsume`  but I can't see it available in this lib.

Cheers.
See #39 for more context and verification