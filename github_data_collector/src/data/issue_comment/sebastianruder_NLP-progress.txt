Adding the progress in dataset and application of seq-to-seq for marathi language.
added current best results as reported in:
**Neural Machine Translation for English to Hindi** (English->Hindi translation)
[https://www.researchgate.net/publication/327717152_Neural_Machine_Translation_for_English_to_Hindi ](url)
**LTRC-MT Simple & Effective Hindi-English Neural Machine Translation Systems at WAT 2019** (Hindi->English translation)
[https://www.aclweb.org/anthology/D19-5216.pdf](url)
According to the [List_of_unsolved_problems_in_computer_science](https://en.wikipedia.org/wiki/List_of_unsolved_problems_in_computer_science)

> Is there any perfect stemming algorithm in the English language?

I believe that [lemmatization](https://en.wikipedia.org/wiki/Lemmatisation) is not solved too.

It would be wonderful to add the states of the arts in both tasks.
BTW, lemmatization consists for example of transforming the conjugated verb: jumped to his noun form: jump.
Does a tool that takes in argument a word e.g fast and another argument specifying the requested part of speech form an e.g adverb
which would output fastly.
In fact, stemming and lemmatization are a special case of the NLP task I need.
If it exists, does someone know how it's called? Where could I ask?
Sorry for the digression.
https://github.com/kimiyoung/transformer-xl/blob/master/README.md

It has improved the state of the art.
https://github.com/WING-NUS/scisumm-corpus

This is a computational research papers summarization competition. 
Just looking at the NER scores for English Ontonotes. The top score is 89.71 for Flair, but I can't find where this number is reported. The original paper doesn't evaluate on Ontonotes, and their [github page](https://github.com/zalandoresearch/flair) shows 89.3.

Looks like @Separius added this -- can you confirm where the 89.71 number came from?
I didn't see anything on VAD, so maybe that should be a new category? I don't know enough about it to say if it could be considered a language independent task, nor what the current state of the art is (which is why I'm opening this issue ;-))

It does seem like webrtc-vad is used a lot, so that might be the de-facto baseline, while
https://ieeexplore.ieee.org/document/8309294 / https://github.com/jtkim-kaist/VAD seems like a contender for state-of-the-art (has a freely available dataset).

Thank you for your precious contribution for NLP. I am a candidate PHD in China and attracted by some new research topics mentioned in ‘Accepted Tutorial in ACL 2019’.
I really want to know that whether there is proper data for argument mining and storytelling.
Looking forward for your reply. Thank U.
Hi,

Is there any official result(included in summarization topic papers) on TextRank?

Thanks. 
for this list https://github.com/sebastianruder/NLP-progress/blob/master/english/relationship_extraction.md

I would like to point out a data issue 

a new model of Distantly Supervised Relationship Extraction using the same training dataset (**522611** ) is be able to compare with the same results of models (PCNN+ATT, PCNN+ONE etc.) reported Lin's paper (Lin et al., 2016).  
(the cleaned dataset was updated by Lin and could be downloaded from https://github.com/thunlp/NRE)

The problem is that, some new papers (e.g. two in EMNLP 2018 and one in AAAI2019) ) used the unprocessed data (**570088**), which contains duplicated instances in the test set. the unclean data will give higher unreliable results. 

issues already have been discussed in 
https://github.com/thunlp/NRE/issues/16
https://github.com/thunlp/OpenNRE/issues/27

the unclean data was tested and has effects on the results. 