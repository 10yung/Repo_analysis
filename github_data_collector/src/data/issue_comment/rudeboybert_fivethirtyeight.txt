Add following datasets to [Master Google Sheet](https://docs.google.com/spreadsheets/d/1IMWAHNPIDzplafWW6AGnGyHmB1BMjohEw_V5HmT70Gs/edit#gid=840984416)
+ By Natalia Iannucci: `media_mentions_cable`, `media_mentions_online`
+ By Marium Tapal: `state_index`, `state_words`
+ By Lizette Carpenter: `cabinet_turnover`
+ By Irene Ryan: `castle_solutions`, `castle_solutions_2`, `castle_solutions_3`
+ By Alina Barylsky: `dem_candidates`
+ By Rana Gahwagy:`quasi_winshares`
+ By Danica Miguel : `raptor_by_player`,`raptor_by_team`
+ By Sunni Raleigh: `wwc_2019_forecasts`, `wwc_2019_matches`
+ By Anna Ballou: `foul_balls` 
+ By Jane Bang: `nba_draymond`
+ By Jordan Moody: `fight_songs`
+ By Kara Van Allen: `nba_elo`, `nba_elo_latest`
+ By Jessica Keast: `nba_all_elo`
+ By Fatima Keita: `impeachment_polls
Some of the help/man files have `roxygen2` examples that convert data as originally given in [538's GitHub](https://github.com/fivethirtyeight/data) to "tidy" format using `tidyr::gather()`. However, `tidyr` now includes much more intuitively-named and easier to use functions `pivot_longer()` and `pivot_wider()`. See this tidyverse.org [blog post](https://tidyr.tidyverse.org/dev/articles/pivot.html) for more information.

In the case of `fivethirtyeight` package, we should replace all `gather()` code with `pivot_longer()`. For example, if you run `?drinks` you'll currently see in the examples:
```{r}
library(dplyr)
library(tidyr)
library(stringr)
drinks_tidy <- drinks %>%
  gather(type, servings, -c(country, total_litres_of_pure_alcohol)) %>%
  mutate(
    type = str_sub(type, start=1, end=-10)
  ) %>%
  arrange(country, type)
```
This needs to be updated with:
```{r}
library(fivethirtyeight)
library(dplyr)
library(tidyr)
library(stringr)
drinks_tidy <- drinks %>%
  pivot_longer(cols = ends_with("servings"), names_to = "type", values_to = "servings") %>%
  mutate(type = str_sub(type, start=1, end=-10)) %>%
  arrange(country, type)
```
A search of `gather` in all `R/data_X.R` files will locate the `roxygen2` code for all such cases. For example, the `roxygen2` code for `drinks` is in [`data_albert.R`](https://github.com/rudeboybert/fivethirtyeight/blob/42d2bbb21e4dce3492d5515f0934c7a435bfd831/R/data_albert.R#L129).

@beanumber Let me know if you have someone who can do this, and I'll explicitly make them an assignee. 
# Preparing CRAN release

- [ ] Make sure that all datasets listed when running `data(package = "fivethirtyeight")` are listed in [master Google Sheet of datasets](https://docs.google.com/spreadsheets/d/1IMWAHNPIDzplafWW6AGnGyHmB1BMjohEw_V5HmT70Gs/edit#gid=840984416) and in list of all datasets on [package webpage](https://fivethirtyeight-r.netlify.com/articles/fivethirtyeight.html).
- [ ] Check if any of the datasets in [master Google Sheet of datasets](https://docs.google.com/spreadsheets/d/1IMWAHNPIDzplafWW6AGnGyHmB1BMjohEw_V5HmT70Gs/edit#gid=840984416) with "DYNAMIC DATA THAT GETS UPDATED?" marked "Y" need to be updated by re-running appropriate `data-raw/process_data_sets_X.R` files 
- [ ] Edit version number in `DESCRIPTION` and `NEWS.md`.

The following steps ensure that all user-contributed vignettes are not included in the package on CRAN, but rather only in the development version on GitHub and on the package [webpage](https://fivethirtyeight-r.netlify.com):

- [ ] Temporarily remove all `.Rmd` vignettes from `vignettes/` except for `fivethirtyeight.Rmd` (includes a detailed list of all data), `tame.Rmd` (TISE article), and `user_contributed_vignettes.Rmd` (how to access user-contributed vignettes).
- [ ] Then clear all non-source files from `vignettes/`, in other words, all `.html` and `.R` files, so that they don't interfere with CRAN submission.
- [ ] Temporarily edit packages in `DESCRIPTION` to reflect above vignette changes. This will keep package dependency bloat down:
    - [ ] Keep the following packages needed for all `@Examples` in help files and the `fivethirtyeight`, `tame`, and `user_contributed_vignettes` vignettes. As of v0.5.0, these include: `ggplot2, dplyr, tidyr, curl, readr, tibble, lubridate, stringr, janitor, knitr, gridExtra, ggthemes, scales, broom, magrittr, rmarkdown`
    - [ ] Temporarily remove the following packages used in all other vignettes. As of v0.5.0, these include: `slam (>= 0.1-42), highcharter (>= 0.7), tidytext, textdata, hunspell, fmsb, wordcloud, corrplot, ggraph, igraph`

Standard package steps:

- [ ] Do one final check
- [ ] Run the following `devtools` functions: `spell_check()`, `check_rhub()`, `check_win_devel()`, and `check_win_release()`. You'll eventually be asked if you ran them when publishing release via `devtools::release()`
- [ ] Update `cran-comments.md`.

# After CRAN release

- [ ] Tag version in GitHub releases
- [ ] Return temporarily removed vignettes
- [ ] Return packages removed from `DESCRIPTION`
- [ ] Edit version number in `DESCRIPTION` and `NEWS.md`

I think that the description `category` column in the [rating](https://github.com/rudeboybert/fivethirtyeight/blob/master/data/ratings.rda) dataset might be ambiguous . 

```
> levels(ratings$category)
 [1] "Aged 18-29"         "Aged 30-44"         "Aged 45+"           "Aged under 18"      "Females"           
 [6] "Females Aged 18-29" "Females Aged 30-44" "Females Aged 45+"   "Females under 18"   "IMDb staff"        
[11] "IMDb users"         "Males"              "Males Aged 18-29"   "Males Aged 30-44"   "Males Aged 45+"    
[16] "Males under 18"     "Non-US users"       "Top 1000 voters"    "US users"    
```

Because there could be questions like:
- Is the `Males under 18` a subset of all `Males`, and if not, how do the categories differ?
- Is there any intersection between the categories?
- If the number of respondents in `'Females Aged 18-29'+'Females Aged 30-44'+'Females Aged 45+'+'Females under 18' are `less that the number of respondents in the `Female` category. Is the gap due to respondents with unknown age?

I checked an [example](https://www.imdb.com/title/tt0241527/ratings?demo) on IMDB, but I am not sure how things sum up in the dataset.

![demo](https://user-images.githubusercontent.com/13340411/47797736-c6de1280-dd1e-11e8-9900-2ff20edbd2e9.png)

Might need to unconvert all `ordered = TRUE` factors to unordered.
``` r
suppressPackageStartupMessages(library(tidyverse))
library(fivethirtyeight)
library(moderndive)

# clean_test is ordered factor
bechdel$clean_test[1:5]
#> [1] notalk ok     notalk notalk men   
#> Levels: nowomen < notalk < men < dubious < ok

# weird output for dummy variables in regression table
lm(domgross~clean_test, data = bechdel) %>% 
  get_regression_table()
#> Warning: package 'bindrcpp' was built under R version 3.4.4
#> # A tibble: 5 x 7
#>   term           estimate std_error statistic p_value   conf_low conf_high
#>   <chr>             <dbl>     <dbl>     <dbl>   <dbl>      <dbl>     <dbl>
#> 1 intercept     70491451.  2412903.    29.2    0.      65759017. 75223886.
#> 2 clean_test.L  -3804412.  5244171.    -0.725  0.468  -14089823.  6480999.
#> 3 clean_test.Q  -9916737.  5398245.    -1.84   0.0660 -20504334.   670861.
#> 4 clean_test.C    750590.  5353012.     0.140  0.889   -9748292. 11249471.
#> 5 clean_test^4  -9507099.  5580759.    -1.70   0.0890 -20452662.  1438464.
lm(domgross~clean_test, data = bechdel) %>% 
  summary()
#> 
#> Call:
#> lm(formula = domgross ~ clean_test, data = bechdel)
#> 
#> Residuals:
#>       Min        1Q    Median        3Q       Max 
#> -79345264 -52417225 -25031559  22438057 691533349 
#> 
#> Coefficients:
#>              Estimate Std. Error t value Pr(>|t|)    
#> (Intercept)  70491451    2412903  29.214   <2e-16 ***
#> clean_test.L -3804412    5244171  -0.725   0.4683    
#> clean_test.Q -9916736    5398245  -1.837   0.0664 .  
#> clean_test.C   750590    5353012   0.140   0.8885    
#> clean_test^4 -9507099    5580759  -1.704   0.0886 .  
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#> 
#> Residual standard error: 80100000 on 1772 degrees of freedom
#>   (17 observations deleted due to missingness)
#> Multiple R-squared:  0.008974,   Adjusted R-squared:  0.006737 
#> F-statistic: 4.012 on 4 and 1772 DF,  p-value: 0.003042

# should look like
bechdel %>% 
  mutate(clean_test = factor(clean_test, ordered = FALSE)) %>% 
  lm(domgross~clean_test, data = .) %>% 
  get_regression_table()
#> # A tibble: 5 x 7
#>   term            estimate std_error statistic p_value  conf_low conf_high
#>   <chr>              <dbl>     <dbl>     <dbl>   <dbl>     <dbl>     <dbl>
#> 1 intercept         6.62e7  6793664.     9.75   0.        5.29e7 79547620.
#> 2 clean_testnot…    1.31e7  7663750.     1.72   0.0870   -1.89e6 28172609.
#> 3 clean_testmen     2.75e6  8910344.     0.309  0.758    -1.47e7 20226986.
#> 4 clean_testdub…    9.79e6  9573562.     1.02   0.307    -8.99e6 28562779.
#> 5 clean_testok     -4.34e6  7364354.    -0.589  0.556    -1.88e7 10106207.
bechdel %>% 
  mutate(clean_test = factor(clean_test, ordered = FALSE)) %>% 
  lm(domgross~clean_test, data = .) %>% 
  summary()
#> 
#> Call:
#> lm(formula = domgross ~ clean_test, data = .)
#> 
#> Residuals:
#>       Min        1Q    Median        3Q       Max 
#> -79345264 -52417225 -25031559  22438057 691533349 
#> 
#> Coefficients:
#>                   Estimate Std. Error t value Pr(>|t|)    
#> (Intercept)       66223181    6793664   9.748   <2e-16 ***
#> clean_testnotalk  13141668    7663750   1.715   0.0866 .  
#> clean_testmen      2751095    8910344   0.309   0.7575    
#> clean_testdubious  9786117    9573562   1.022   0.3068    
#> clean_testok      -4337528    7364354  -0.589   0.5559    
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#> 
#> Residual standard error: 80100000 on 1772 degrees of freedom
#>   (17 observations deleted due to missingness)
#> Multiple R-squared:  0.008974,   Adjusted R-squared:  0.006737 
#> F-statistic: 4.012 on 4 and 1772 DF,  p-value: 0.003042
```

Created on 2018-04-04 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
Maybe a good task for a student? Create a table of all of the datasets and the types of problems each dataset would be good for:

- Descriptive (plots, summary stats)
- Inference (specify types of variables included and how many)
- Modeling (regression, multiple regression, etc.)