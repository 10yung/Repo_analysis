Using Behave 1.2.6

Running any feature file that contains example data containing unicode such as: アイウエオカキアイウエオカキアイイ
will cause Behave to exist with error:

UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-16: ordinal not in range(128)

The stack trace shows this:

/usr/local/bin/behave in <module>()
      6 if __name__ == '__main__':
      7     sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
----> 8     sys.exit(main())

/usr/local/lib/python3.5/dist-packages/behave/__main__.py in main(args)
    181     """
    182     config = Configuration(args)
--> 183     return run_behave(config)
    184 
    185 if __name__ == "__main__":

/usr/local/lib/python3.5/dist-packages/behave/__main__.py in run_behave(config, runner_class)
    125         reset_runtime()
    126         runner = runner_class(config)
--> 127         failed = runner.run()
    128     except ParserError as e:
    129         print(u"ParserError: %s" % e)

/usr/local/lib/python3.5/dist-packages/behave/runner.py in run(self)
    802         with self.path_manager:
    803             self.setup_paths()
--> 804             return self.run_with_paths()
    805 
    806     def run_with_paths(self):

/usr/local/lib/python3.5/dist-packages/behave/runner.py in run_with_paths(self)
    822         stream_openers = self.config.outputs
    823         self.formatters = make_formatters(self.config, stream_openers)
--> 824         return self.run_model()

/usr/local/lib/python3.5/dist-packages/behave/runner.py in run_model(self, features)
    624                         formatter.uri(feature.filename)
    625 
--> 626                     failed = feature.run(self)
    627                     if failed:
    628                         failed_count += 1

/usr/local/lib/python3.5/dist-packages/behave/model.py in run(self, runner)
    319                     continue
    320 
--> 321                 failed = scenario.run(runner)
    322                 if failed:
    323                     failed_count += 1

/usr/local/lib/python3.5/dist-packages/behave/model.py in run(self, runner)
   1112         for scenario in self.scenarios:     # -- REQUIRE: BUILD-SCENARIOS
   1113             runner.context._set_root_attribute("active_outline", scenario._row)
-> 1114             failed = scenario.run(runner)
   1115             if failed:
   1116                 failed_count += 1

/usr/local/lib/python3.5/dist-packages/behave/model.py in run(self, runner)
    709             for step in self.all_steps:
    710                 if run_steps:
--> 711                     if not step.run(runner):
    712                         # -- CASE: Failed or undefined step
    713                         #    Optionally continue_after_failed_step if enabled.

/usr/local/lib/python3.5/dist-packages/behave/model.py in run(self, runner, quiet, capture)
   1309         if not quiet:
   1310             for formatter in runner.formatters:
-> 1311                 formatter.match(match)
   1312 
   1313         if capture:

/usr/local/lib/python3.5/dist-packages/behave/formatter/pretty.py in match(self, match)
    130         self.print_statement()
    131         self.print_step(Status.executing, self._match.arguments,
--> 132                         self._match.location, self.monochrome)
    133         self.stream.flush()
    134
/usr/local/lib/python3.5/dist-packages/behave/formatter/pretty.py in print_step(self, status, arguments, location, proceed)
    299             self.stream.write(text_format.text(text))
    300             line_length += len(text)
--> 301             self.stream.write(arg_format.text(arg.original))
    302             line_length += len(arg.original)
    303             text_start = arg.end

Note:  This did not occur with Python 2.7 but does occur with Python 3.5.
I have some problems to confirm:
1: The features/ directory must needs a steps/ subdirectory?Can I change it to another name?【ps:when I change the name,if I run the program,  I will get an error such as :can't find the steps path】
2:could I design a directory structure like this:
+-- steps/*.py
+-- features/*.feature
3:enviroment.py file must under the features subdirectory?

I look forward to your reply，thank you very much!
I'm writing a test scenario with a step that requires a table of data. However the test is sensitive to whether there is a space at the start of a value or not. So " frog" needs to be treated differently to "frog". This doesn't work because behave strips whitespace at the start and end. So in this case the two frog strings end up the same:

|Column|
| frog|
|frog|

I appreciate that I can lay this out with quotes added and then strip the quotes off in my step code like this:

|Column|
|" frog"|
|"frog"|

However I was wondering if there is any built in way to handle this with behave that wouldn't require the extra step code?
In bash it is common to check if an executable has succeded or failed by checking the $? variable, powershell uses $LASTEXITCODE, windows command line has %ErrorLevel%.

Does behave set the Exit Status in any predicatble way so that a script can tell if a test run has failed?

If it does, some explanation of that might be helpful on this page:

https://behave.readthedocs.io/en/latest/behave.html#command-line-arguments
```
Traceback (most recent call last):
  File "C:\Program Files\JetBrains\PyCharm 2019.2\plugins\python\helpers\pydev\_pydevd_bundle\pydevd_xml.py", line 282, in frame_vars_to_xml
    xml += var_to_xml(v, str(k), evaluate_full_value=eval_full_val)
  File "C:\Program Files\JetBrains\PyCharm 2019.2\plugins\python\helpers\pydev\_pydevd_bundle\pydevd_xml.py", line 369, in var_to_xml
    elif hasattr(v, "__len__") and not is_string(v):
  File "C:\Users\Richard\PycharmProjects\translator-testing-framework\venv\lib\site-packages\behave\runner.py", line 315, in __getattr__
    return self.__dict__[attr]
KeyError: '__len__'
Unexpected error, recovered safely.
```
Right now, I am using `celery_always_eager=True` in environment.py file, which is just executing an asynchronous celery task like a function, but I got stuck at an API where we are doing some thing like below - 

```
def active_status(self, request, pk):
    obj = get_object_or_404(queryset, pk)
    obj.active = True
    obj.save()
    end_date_time = 5(sec)
    #......
    #......
    deactive_status.apply_async(kwargs=obj.__dict__, eta=end_date_time)
```
`deactive_status` is a celery task which update the status of object `obj` back to `False` after duration specified in `end_date_time`.

But right now due to `celery_alwasy_eager=True` setting it just picks that task and execute it right away without considering the delay duration.

I thought there must be some way to configure celery in behave but not sure how it gonna accomplished, I didn't found something similar in their docs as well as other available resources.

If anybody have any idea about the same or something similar that would be really helpful. Thanks!
This all started here: https://github.com/behave/behave-django/pull/100

I'm making a rather large test migration from Aloe to Behave. 

```
$ find . -name *.feature | xargs cat | wc -l
  157533
```

Currently, all our tests are inside our apps like so: (py + feature files all in the same folder inside EACH app)

```
<project>/<app>/features
                        /__init__.py
                        /sometest.feature
                        /sometest_steps.py
                        /steps.py
```

I do not want to make this migration any more painful than it needs to be, so my plan is to modify `behave.runner.Runner` ~`BehaviorDrivenTestRunner`~ to find my tests in the appropriate place. Right now there is no way for me to modify the way this works. ~This is the exact reason django exposes `--testrunner` and i was very surprised this was something overlooked in this project.~

Making this modification works great: `./manage.py behave --behave-runner myproject.runner.Runner`

```python
import os

from behave.runner import Runner as BaseRunner, load_step_modules
from django.conf import settings


class Runner(BaseRunner):

    def load_step_definitions(self, extra_step_paths=None):
        step_paths = [] + list(extra_step_paths or [])
        for root, dirs, _ in os.walk(settings.BASE_DIR):
            for dir in dirs:
                if dir.endswith('features'):
                    full_path = os.path.join(root, dir)
                    step_paths.append(full_path)

        load_step_modules(step_paths)
```
hi
I see that this is an issue already handled in #631, but I'm having difficulties in getting the parameter data.

I'm using behave to validate Cypher coverage for RedisGraph(https://github.com/RedisGraph/RedisGraph), using the openCypher TCK scenarios (https://github.com/opencypher/openCypher/tree/master/tck).

One of the scenarios is as follows:
```
    Scenario Outline: `percentileDisc()`
        Given an empty graph
        And having executed:
            """
            CREATE ({price: 10.0}),
            ({price: 20.0}),
            ({price: 30.0})
            """
        And parameters are:
            | percentile |  <p>  |
        When executing query:
            """
            MATCH (n)
            RETURN percentileDisc(n.price, $percentile) AS p
            """
        Then the result should be:
            | p        |
            | <result> |
        And no side effects

        Examples:
            | p   | result |
            | 0.0 | 10.0   |
            | 0.5 | 20.0   |
            | 1.0 | 30.0   |
```
Retreving the headings of the table 
```
| percentile |  <p>  |
``` 
returns the strings `percentile` and  `<p>` where I would expect to have the value of p instead.

please advise.

How to write a image to behave report
How to write a text to behave report
It would be nice to be able keep feature tests inside other markdown formats in order to include further documentation outside the scope of the actual feature test.  [TheRobotFramework](https://robotframework.org/) and [Guage](https://gauge.org/) do something similar.

The simplest way may be to parse markdown files for code-blocks annotated with `gherkin` formatting and to consider treat code-block and independent feature file.

**./features/my_feature.md**

    # My File

    Some markup outside of the scope of the feature background
    possibly including a history of design decisions, images, diagrams, etc ...

    ```gherkin
    Feature: showing off behave
    
      Scenario: run a simple test
         Given we have behave installed
          When we implement a test
          Then behave will test it for us!
    ```