/home/ubone/.gem/ruby/2.7.0/gems/wayback_machine_downloader-2.2.1/lib/wayback_machine_downloader.rb:271: warning: calling URI.open via Kernel#open is deprecated, call URI.open directly or use URI#open
When I run the script using "wayback_machine_downloader -s http://www.stclares.ac.uk" I end up with ~8500 directories, even though the website only has about 390 snapshots available. Most directories only contain one or a handful of files.
Any thoughts on what might be going wrong?
Hey! Lots of Wordpress sites have css and js with versions specified in the url, for example 

<script type='text/javascript' src='https://example.com/wp-includes/js/wp-embed.min.js?ver=4.9.8'></script>

When Wayback Machine Downloder downloads these files it includes that query string in the file name so it doesn't work! Just thought I might point this out for a potential improvement. 
For example, thingiverse.com has been down alot, and say i only wanted to download the .obj-files from it. Is there a possibility to do that?
I want to get the first snapshot of all the years, but I feel that it can't be set. Is there any other way to do this?Thanks!

Whatever timestamp I enter, I always get an error

```
/var/lib/gems/2.3.0/gems/wayback_machine_downloader-2.2.1/bin/wayback_machine_downloader:64:in `<top (required)>': invalid option: --timestamp (OptionParser::InvalidOption)
        from /usr/local/bin/wayback_machine_downloader:22:in `load'
        from /usr/local/bin/wayback_machine_downloader:22:in `<main>'
```
What could it be?
Hello

I am hesitant to post this because I am afraid it might fall within the realm of a feature request.

### Is there anyway to exclude "robots.txt"?

The `-x` option won't work because it's for directories only.

The reason for this call for help, if possible, is that two further processes need to be followed up after a download completes.

1. I have to find and delete robots.txt which results with many empty folders.
2. I have to find and remove empty folders (I have a solution for that though)
After running --help:

The word "provided" is misspelled:
-e, --exact-url                  Download only the url **provied** and not the full site

The word "download" is misspelled:
-c, --concurrency NUMBER			Number of multiple files to **dowload** at a time

In the future, the help file could be run through a spell-checker beforehand.
Thank you for a brilliant tool by the way!
How to fix this? I am ready to contribute to someone who can fix this.