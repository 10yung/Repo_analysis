Summary:
[NFC] Fix a bunch of compilation warnings (GCC)

Documentation: N/A

Test Plan: N/A
Summary:
Currently, due to assert in Loader::getModelOptPath, one cannot use `-m=model.onnx`, but have to do `-m=./model.onnx` instead. The patch removes the assert and makes the function return "." as the directory.

Documentation: N/A

Test Plan: manually tested
**Summary**
- Fix for #3827.
- Enable the constant folding by default.

**Documentation**
None

**Test Plan**
None


Summary: Previously if a Tensor was not partial we left `unpaddedSize_ =  0`, representing that the actual `unpaddedSize_` was that based on the Type. This PR changes this, so that `unpaddedSize_` is equal to the actual number of allocated bytes pointed to by `data_`. 

- This includes fixing `Tensor::assign()` so that it respects unpadded size, i.e. if you clone a partial tensor the new tensor is also partial.
- Additionally includes fixing `Tensor::reset()` so that if you reset a partial tensor with a type with the same number of bytes but without specifying it should be partial, that the old buffer is not reused (this could have caused buffer overflow).

Test Plan: Updated unpaddedSize unit test with a few more checks.

Alternative fix to https://github.com/pytorch/glow/pull/3986 with a couple other fixes

CC: @jsubag 

http://beefy10.nyi.freebsd.org/data/113i386-default/523196/logs/glow-nn-compiler-g20200115.log


Whenever I use the Glow front-end tools (model-compiler) on **Windows** I get the notification `libunwind: pc not in table, pc=0xFFFFFFFFFFFFFFFF` like below:
![image](https://user-images.githubusercontent.com/29785908/72515356-6e7a2e80-3858-11ea-833b-29f1884d1b9e.png)
The notification seems like a warning, the tool seems to work properly but I was wondering if I should worry about it?
Thanks!


Right now Image-classifier primary works with well image classification networks. There are other networks such as Segementation, Object Detection. The majority of the code to execute them is the same. Main differences are how some pre-processing stuff and outputs are handled.  For example for object detection not only they have multiple outputs, but also usually MAAP score is calculated by python scripts.

Would people be open to idea of refactoring common code in to a seperate file with some hooks for pre-processing and post processing. So that image-classifier, and maybe future apps like object-detection be a wrapper around it?

I am still thinking full implementation through, but wanted to open this to conversation to judge if there is an interest or none starter. Before I invest too much time in to it.
Using `-march=native` for Release build doesn't seem to be a good practice. If built on a top-end CPU, the compiler won't be able to run on older machines. I see two possible solutions for this:
1) Introduce a CMake flag to control `-march` value (can keep default to be `native`)
2) Use less aggressive march value, like `x86-64`/`core-avx`/`core-avx2` (I believe `-march=native` is passed only if built on x86). This should only affect Intrerpreter backend performance, as LLVM-based CPU backend would still use current machine target while JITing.

Any preferences or other suggestions?
clang-8 fails in this line:
https://github.com/pytorch/glow/blob/master/lib/LLVMIRCodeGen/LLVMCompiledFunction.cpp#L102

You need to replace ```NULL``` with ```0``` or nothing at all.

Summary:
By default let's test all 12 ICE cores if the test supports it by setting parallelCloneCount. Unit tests run pretty quickly so this doesn't cost much in runtime overhead and gets us better coverage on the NNPI HW and stack.

cl opt `-parallel-clone-count` will still work/override whatever the backend sets as its own default.

This included a fix to avoid std::moving a Tensor, which later led to a nullptr deref.

Differential Revision: D19401176

