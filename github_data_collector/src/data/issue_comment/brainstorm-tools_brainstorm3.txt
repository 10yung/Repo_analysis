Hey all, 

In this thread, we will discuss and finalize the integration of the FEM computation of the forward problem.

-We have finished the compilation of Duneuro on the main platforms: Windows, Linux, and MAC, and we have integrated all in one package. 
- We have also developed a whole Matlab toolbox, named 'bst-duneuro-toolbox', to test duneuro and to interface it to brainstorm with a minimal change on the main bst code.  
- We have tested and validated the EEG computation, 
MEG is in progress, and the other methods will be added later (seeg, ecog).

@ftadel : I checked how bst call openmeeg via  [Gain, errMsg] = bst_openmeeg(OPTIONS).
then I wrote a similar function for fem :   
[Gain, errMsg] = bst_duneuro(OPTIONS)  [[bst_duneuro.txt](https://github.com/brainstorm-tools/brainstorm3/files/3915007/bst_duneuro.txt)]

This function will use the same argument, OPTIONS, and it uses the 'bst-duneuro-toolbox'. 

However, some fields are missing in the OPTIONS and we need to add them. 
For this 'release', the most important is the path to the fem head model.

But there are some other steps that we need to modify, mainly related to the GUI. 
For now, I identified these functions : 
-process_headmodel
-panel_headmodel 
-bst_get
-panel_duneuro as panel_openmeeg
-bst_duneuro as bst_openmeeeg

There are some parameters for the FEM that should be tuned from the GUI panel, and we will set to the default value the others. 

Maybe we could discuss these points next meeting.

Kind regards 
Takfarinas 
Dec 2019:
* https://neuroimage.usc.edu/forums/t/normalization-of-coherence/15830
* https://neuroimage.usc.edu/forums/t/center-biased-activity-from-source-models/15603/7

Sept 2019:
* https://neuroimage.usc.edu/forums/t/calling-dics-from-ft-sourceanalysis/13977 (DICS)
* https://neuroimage.usc.edu/forums/t/source-modelling-and-subcortical-structures/10269/15 (source normalization)
* https://neuroimage.usc.edu/forums/t/diagonal-loading-value/13907
* https://neuroimage.usc.edu/forums/t/computing-connectivity-based-on-source-space/13678 (Connectivity for unconstrained sources)

August 2019:
* https://neuroimage.usc.edu/forums/t/calculating-cross-talk-functions/13485 (Min norm)
* https://neuroimage.usc.edu/forums/t/help-for-connectivity-pipeline/12558/7 (Connectivity for * unconstrained sources)
* https://neuroimage.usc.edu/forums/t/longitudinal-analysis/13047 (Statistics)

July 2019:
* https://neuroimage.usc.edu/forums/t/rank-deficiency-and-source-reconstruction/12758/9 (Min norm)

May 2019:
* https://neuroimage.usc.edu/forums/t/pvalues-for-spectral-granger-analysis/11045 (Granger spectral)

February 2019:
* https://neuroimage.usc.edu/forums/t/display-dipoles-across-subjects-on-default-anatomy/9779/10  (Dipole scanning)

October 2018:
* https://neuroimage.usc.edu/forums/t/source-estimation-options/8489 (LCMV)
* https://neuroimage.usc.edu/forums/t/error-in-simulate-recordings-from-scouts/8087/9 (SNR)

August 2018:
* https://neuroimage.usc.edu/forums/t/question-about-the-workflow-of-functional-connectivity-between-rois/7845 (Connectivity for unconstrained sources)

@jcmosher suggested we change the scaling factor applied in two functions: 

**Dipole scanning**

https://github.com/brainstorm-tools/brainstorm3/blob/master/toolbox/process/functions/process_dipole_scanning.m#L119
`Factor = sqrt(DataMatP.Leff / sResultP.Leff);`
Replaced with:
`Factor = sqrt(sResultP.Leff);`

Problem: When testing with the introduction tutorials, the goodness of fit of the dipoles drops to very small values, example for standard condition at 90ms (Leff=193):
![image](https://user-images.githubusercontent.com/6920058/61877817-13423180-aef0-11e9-87f6-b5c836e95fc6.png)

Current code (top) vs. John's suggestions (bottom):
![image](https://user-images.githubusercontent.com/6920058/61877875-294ff200-aef0-11e9-9665-e1289f0719c5.png)  
![image](https://user-images.githubusercontent.com/6920058/61877910-353bb400-aef0-11e9-9581-07b667b1f2d0.png)

**Whitened recordings**

https://github.com/brainstorm-tools/brainstorm3/blob/master/toolbox/tree/tree_callbacks.m#L3280
`Factor = sqrt(DataMat.Leff / ResultsMat.Leff);`
Replaced with:
`Factor = sqrt(sResultP.Leff);`

This looks more reasonable (but do we want to see Z=20 here?). Below, figures obtained by right-clicking on the MN source link for the standard condition (Leff=193) > Model evaluation > Save whitened data (top=before, bottom=after modification):
![image](https://user-images.githubusercontent.com/6920058/61878151-c1e67200-aef0-11e9-8bb6-225a626031a8.png)   
![image](https://user-images.githubusercontent.com/6920058/61878938-4e456480-aef2-11e9-84d5-869969c24e64.png)

@jcmosher @dimitriospantazis please validate whether this is what you want to obtain.
The raster plot shows the spiking activity of each neuron.  There is a problem though with the visualization of this activity. 
Since the raster plots are not binned (no temporal smoothing), the x-axis (time dimension) is a much larger vector than the y-axis (number of trials). This creates a rendering problem when the figure is scaled, as shown on the next two figures:

![image](https://user-images.githubusercontent.com/23224563/59953464-3475b500-944e-11e9-8c2e-9eec27d10801.png)

![image](https://user-images.githubusercontent.com/23224563/59953470-38a1d280-944e-11e9-9f57-cffa9771d70b.png)


Maybe a visualization with dots would be appropriate?

For example, it does not run on Matlab versions before R2014b: missing function histcounts() used in the scilearnlab library. Either see if such instances can be replaced or add warning to process.
Adding a callback to import & convert a timefreq.mat file obtain from fieldtrip.
This is a first attempt, if is ok, I will add some additional options and create a channel.mat to allow the topographic display.
- Identify the programs that would be interesting (and not too complicated) to interface with Brainstorm
- Find advanced users of these programs to define how to convert data structures
- Write online tutorials for each program
Improvements:
1. Used to give an error if number of channels didn't match.  It now deals properly with varying channels (matches them by name), with the options of keeping either all channels (default), only common channels, or those from the first file (similarly to bst_avg_files).
2. Averaging locations caused "shrinkage" towards origin.  Now MEG channels are averaged based on the dewar=>native transformations, separately averaging the "brain origins" (based on the cortex surface if available) and the head orientations.  EEG channel locations are still simply averaged, but with a correction to avoid "shrinkage".
3. There was a bug in averaging orientations: they were not normalized.  Fixed.

Following this, process_average should also be modified to always match channels by name.  This is only an option (why?) and only for files that contain RowNames (tf and matrix types).  I think this can easily lead to errors in group averaging.  There should at the very least be a warning or error if channels don't match and the code can't deal with it.  Now it just averages by channel index.
Additions, modifications or alterations both in Simbio or/and Brainstorm toolboxes to make these two work together. 

A long time ago, I did a study of various sphere fitting methods for MEG forward modelling.  I remembered that this approximation adds on the order of 10% error to the forward solution, so I switched to using Nolte's method when using Fieldtrip some years ago (it's called "single shell" in FT).  I just looked back at my [paper](https://iopscience.iop.org/article/10.1088/0031-9155/56/17/010/meta) and saw this comment which I had forgotten:
> "Other variations of these methods were tested but produced similar or worse results and are not shown here. For example, the NC method variation implemented in Brainstorm (with α = β = 2) had 27% mean field error and 7 mm mean localization bias as opposed to 12% and 3.5 mm, respectively, for the version with α = β = 1."

So I think it's worth considering changing the sphere fitting method used in Brainstorm.  It might also be a good idea to rethink the recommended method for MEG.  We can discuss at our next video meeting.