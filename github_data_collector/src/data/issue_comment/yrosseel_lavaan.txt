The line referenced below is causing one or two blavaan tests to fail because x.cov is NULL. I haven't isolated the problem (have not looked hard), but I can remember having previous trouble with the difference between missing="ml" and missing="ml.x". I guess this might be related? (fwiw, I had been trying to stick with missing="ml" because "ml.x" was making my life difficult in various ways)

I am not expecting any changes in lavaan, but any extra info would be helpful for me to solve the problem in blavaan. Thanks...

https://github.com/yrosseel/lavaan/blob/4ecede812aef78d945981ed2873ba960e9c9388a/R/lav_mvnorm_missing.R#L137

When trying to estimate a model with latent/structured residuals as follows:
```
z =~ 1*x1 + 1*x2 + 1*x3

lx1 =~ 1*x1
lx2 =~ 1*x2
lx3 =~ 1*x3

z ~~ z
lx1 ~~ lx1
lx2 ~~ lx2
lx3 ~~ lx3
```

lavaan() with estimator="MML" yields `Error in DD$nu[num.idx, , drop = FALSE] : subscript out of bounds`, while all other estimators work fine.

Example code:
```
library(lavaan)

set.seed(123)

z <- rnorm(500)

x1 <- rnorm(500) + z
x2 <- rnorm(500) + z
x3 <- rnorm(500) + z

df = data.frame(x1, x2, x3)

lav_model <- '
z =~ 1*x1 + 1*x2 + 1*x3

lx1 =~ 1*x1
lx2 =~ 1*x2
lx3 =~ 1*x3

z ~~ z
lx1 ~~ lx1
lx2 ~~ lx2
lx3 ~~ lx3
'

lavaan(lav_model, data=df, estimator="ML")  # works
lavaan(lav_model, data=df, estimator="WLS") # works
lavaan(lav_model, data=df, estimator="GLS") # works
lavaan(lav_model, data=df, estimator="ULS") # works
lavaan(lav_model, data=df, estimator="MML") # Error in DD$nu[num.idx, , drop = FALSE] : subscript out of bounds
```
The function `mplus2lavaan.modelSyntax` unexpectedly does not convert syntax for means:

```
out <- "bfi BY bfi_1*1 (lab1);\nbfi BY bfi_2*1 (lab2);\nbfi BY bfi_3*1 (lab3);\nbfi BY bfi_4*1 (lab4);\nbfi BY bfi_5*1 (lab5);\n[bfi@0] (lab6);\nbfi@1 (lab7);"
mplus2lavaan.modelSyntax(out)
"bfi =~ lab1*start(1)*bfi_1\nbfi =~ lab2*start(1)*bfi_2\nbfi =~ lab3*start(1)*bfi_3\nbfi =~ lab4*start(1)*bfi_4\nbfi =~ lab5*start(1)*bfi_5\n0 ~ lab6*1\nbfi ~~ lab7*1*bfi"
```

Just to clarify: The unexpected bit is this syntax, `0 ~ lab6*1`, which is not correct syntax for means.
The functions `pc_gnorm` and `pc_PHI` appear to create a vector with the points `-Inf` and `Inf` on them, but then never use the `-Inf` values.  

I think this is an error, mostly because the values for `Inf` and `-Inf` will doubtless be 0 anyway.  I think the code should be as below, and this will also run a lot faster than the code in your package by avoiding loops. 
```
pc_PHI <- function(rho, th.y1, th.y2) {
  
  if (length(rho) > 1) stop("Not vectorized for rho")
  
  nr <- length(th.y1) + 1L; nc <- length(th.y2) + 1L
  th.y2 <- rep(th.y2, each=nr-1)
  
  ## work out densities
  phi <- matrix(0, nr, nc)
  tmp <- dbinorm(th.y1, th.y2, rho)
  dim(tmp) <- c(nr-1, nc-1)
  
  ## fill out with some zeros
  tmp <- cbind(0,tmp,0)
  tmp <- rbind(0,tmp,0)
  tmp[is.na(tmp)] = 0  
  if (!all.equal(dim(tmp), c(nr+1,nc+1))) stop("Dimension not as expected")   
  
  ## assumed correct approach
  phi <- tmp[-(nr+1), -(nc+1)] - tmp[-1, -(nc+1)] - tmp[-(nr+1), -1] + tmp[-1, -1]
  dim(phi) = c(nr, nc)
  
  # ## old code
  # for(i in seq_len(nr)) {
  #     for(j in seq_len(nc)) {
  #         p1 <- p2 <- p3 <- p4 <- 0
  #         if(i < nr && j < nc)
  #             p1 <- dbinorm(TH.Y1[i   +1L], TH.Y2[j   +1L], rho)
  #         if(i > 1L && j < nc)
  #             p2 <- dbinorm(TH.Y1[i-1L+1L], TH.Y2[j   +1L], rho)
  #         if(i < nr && j > 1L)
  #             p3 <- dbinorm(TH.Y1[i   +1L], TH.Y2[j-1L+1L], rho)
  #         if(i > 1L && j > 1L)
  #             p4 <- dbinorm(TH.Y1[i-1L+1L], TH.Y2[j-1L+1L], rho)
  #         phi[i,j] <- (p1 - p2 - p3 + p4)
  #     }
  # }
  
  phi
}

pc_gnorm <- function(rho, th.y1, th.y2) {
  
  if (length(rho) > 1) stop("Not vectorized for rho")

    # note: Olsson 1979 A2 contains an error!!
    guv <- function(u, v, rho) {
        R <- (1 - rho*rho)
        ( u*v*R - rho*((u*u) - 2*rho*u*v + (v*v)) + rho*R ) / (R*R)
    }

    if (length(rho) > 1) stop("Not vectorized for rho")
    
    nr <- length(th.y1) + 1L; nc <- length(th.y2) + 1L
    th.y2 <- rep(th.y2, each=nr-1)
    
    ## work out densities
    phi <- matrix(0, nr, nc)
    tmp <- dbinorm(th.y1, th.y2, rho) * guv(th.y1, th.y2, rho)
    dim(tmp) <- c(nr-1, nc-1)
    
    ## fill out with some zeros
    tmp <- cbind(0,tmp,0)
    tmp <- rbind(0,tmp,0)
    tmp[is.na(tmp)] = 0  
    if (!all.equal(dim(tmp), c(nr+1,nc+1))) stop("Dimension not as expected")   
        
    ## assumed correct approach
    gnorm <- tmp[-(nr+1), -(nc+1)] - tmp[-1, -(nc+1)] - tmp[-(nr+1), -1] + tmp[-1, -1]
    dim(gnorm) = c(nr, nc)
    
    
    # ## old code
    # for(i in seq_len(nr)) {
    #     for(j in seq_len(nc)) {
    #         g1 <- g2 <- g3 <- g4 <- 0
    #         if(i < nr && j < nc) {
    #             u <- TH.Y1[i   +1L]; v <- TH.Y2[j   +1L]
    #             g1 <- dbinorm(u, v, rho) * guv(u,v,rho)
    #         }
    #         if(i > 1L && j < nc) {
    #             u <- TH.Y1[i-1L+1L]; v <- TH.Y2[j   +1L]
    #             g2 <- dbinorm(u, v, rho) * guv(u,v,rho)
    #         }
    #         if(i < nr && j > 1L) {
    #             u <- TH.Y1[i   +1L]; v <- TH.Y2[j-1L+1L]
    #             g3 <- dbinorm(u, v, rho) * guv(u,v,rho)
    #         }
    #         if(i > 1L && j > 1L) {
    #             u <- TH.Y1[i-1L+1L]; v <- TH.Y2[j-1L+1L]
    #             g4 <- dbinorm(u, v, rho) * guv(u,v,rho)
    #         }
    #         gnorm[i,j] <- (g1 - g2 - g3 + g4)
    #     }
    # }

    gnorm
}


```
I imported a .sav (spss) dataset using the haven package, fit a model using sem(), and used lavPredict() on the fitted model. I got an error that says: `lavaan ERROR: unknown type: haven_labelled for variable: ...`. Just bringing this to someone's attention, because the issue goes away after saving the .sav as .csv.
EDIT at end.

Hi Yrosseel!

I have been trying out the lavaan package for some CFA an SEM modeling. I have run into a very strange issue where R gives me incorrect results only some of the time. I have been comparing the output to SPSS AMOS to make sure it is correct.

The issue I am having is that I get incorrect output based on the number of observations I am using, and I have narrowed it down to how the package is utilizing the covariance matrix. I have attached two files with covariance matrices. The "fullCov" is from the full sample of 210 observations and gives me incorrect output. The "subCov" is from a subsample of 199 observations and gives me correct output. I have tried recreating the covariance matrices in other programs as well to see if it is related to R creating the matrix, and I still get the same results.

This is the model I am testing:
BNS.model <- 'autonomy =~ BNSW_1 + BNSW_5 + BNSW_8 + BNSW_11 + BNSW_13 + BNSW_17 + BNSW_20
              competence =~ BNSW_3 + BNSW_4 + BNSW_10 + BNSW_12 + BNSW_14 + BNSW_19
              relatedness =~ BNSW_2 + BNSW_6 + BNSW_7 + BNSW_9 + BNSW_15 + BNSW_16 + BNSW_18 + BNSW_21'

The third file I attached has the estimates that I expect to get followed by the estimates I get from R utilizing the full 210 observations.

Anyway, I am not sure how to fix this. If I am doing something incorrectly, please let me know. Oh, and I have been testing this using the Mimic="EQS" option as well and still get incorrect results. I also considered rounding to be an issue, but the results are too far off to just be because of rounding.

_sumphatguy

Edit: I was able to get the correct values by specifying "start = 'simple'" Can anyone explain why this would change so much?

[estimates.xlsx](https://github.com/yrosseel/lavaan/files/3698640/estimates.xlsx)
[fullCov.xlsx](https://github.com/yrosseel/lavaan/files/3698641/fullCov.xlsx)
[subCov.xlsx](https://github.com/yrosseel/lavaan/files/3698642/subCov.xlsx)

Thank for your attention. The code was pasted below.
# install.packages('lavaan') 
# install.packages('ggplot2')
# install.packages('reshape2')


# install.packages('lavaan')  #grab package from the source
# install.packages('qpcR')    #grab package from the source
library(lavaan)               #load package
library(qpcR)                 #load package
library(ggplot2)              #load package

#Model comparison: Here we simulate data under one model (A) and fit two
#competing models (A and B). We then use model comparison to test which one
#best fits the data


#True model
samplesize<-500
ULCS_simulate<-'

#####     The following lines specify the core assumptions of the LCS 
#####     and should not generally be modified

COG_T2 ~ 1*COG_T1     # Fixed regression of COG_T2 on COG_T1
dCOG1 =~ 1*COG_T2     # Fixed regression of dCOG1 on COG_T2
COG_T2 ~ 0*1          # This line constrains the intercept of COG_T2 to 0
COG_T2 ~~ 0*COG_T2    # This fixes the variance of the COG_T2 to 0  


###### The following five parameters will be estimated in the model. 
###### Values can be modified manually to examine the effect on the model

dCOG1 ~ 40*1        # This fixes the intercept of the change score to 10 
COG_T1 ~ 50*1       # This fixes the intercept of COG_T1 to 50 

dCOG1 ~~ 5*dCOG1    # This fixes the variance of the change scores to 5. 
COG_T1 ~~ 8*COG_T1  # This fixes the variance of the COG_T1 to 8. 

dCOG1~-0.1*COG_T1   # This fixes the self-feedback parameter to -0.1. 
'
simdatULCS<-simulateData(ULCS_simulate,sample.nobs = samplesize,meanstructure = T) #Simulate data


#We first fit the true model
ULCS_A<-'

COG_T2 ~ 1*COG_T1     # Fixed regression of COG_T2 on COG_T1
dCOG1 =~ 1*COG_T2     # Fixed regression of dCOG1 on COG_T2
COG_T2 ~ 0*1          # This line constrains the intercept of COG_T2 to 0
COG_T2 ~~ 0*COG_T2    # This fixes the variance of the COG_T2 to 0 

dCOG1 ~ 1             # This estimates the intercept of the change scores 
COG_T1 ~  1           # This estimates the intercept of COG_T1 
dCOG1 ~~  dCOG1       # This estimates the variance of the change scores 
COG_T1 ~~   COG_T1    # This estimates the variance of COG_T1 
dCOG1~COG_T1          # This estimates the self-feedback parameter

'

fitULCS_A <- lavaan(ULCS_A, data=simdatULCS, estimator='mlr',fixed.x=FALSE,missing='fiml')
summary(fitULCS_A, fit.measures=TRUE, standardized=TRUE, rsquare=TRUE)

#We now fit a competing, simpler model that constraints the autoregressive
#parameter to 0

ULCS_B<-'

COG_T2 ~ 1*COG_T1     # Fixed regression of COG_T2 on COG_T1
dCOG1 =~ 1*COG_T2     # Fixed regression of dCOG1 on COG_T2
COG_T2 ~ 0*1          # This line constrains the intercept of COG_T2 to 0
COG_T2 ~~ 0*COG_T2    # This fixes the variance of the COG_T2 to 0 

dCOG1 ~ 1             # This estimates the intercept of the change scores 
COG_T1 ~  1           # This estimates the intercept of COG_T1 
dCOG1 ~~  dCOG1       # This estimates the variance of the change scores 
COG_T1 ~~   COG_T1    # This estimates the variance of COG_T1 
dCOG1~0*COG_T1          # This estimates the self-feedback parameter

'

fitULCS_B <- lavaan(ULCS_B, data=simdatULCS, estimator='mlr',fixed.x=FALSE,missing='fiml')
summary(fitULCS_B, fit.measures=TRUE, standardized=TRUE, rsquare=TRUE)


#Likelihood ratio test:
anova(fitULCS_A,fitULCS_B)
Hi Yves, I noticed some unexpected behavior when using the WLS estimator with missing data. The following gives an error for me:

```r
library("lavaan")
library("mvtnorm")

# Some data:
nVar <- 10
Rho <- matrix(0.5,nVar,nVar)
diag(Rho) <- 1
Data <- as.data.frame(rmvnorm(500,sigma = Rho))
names(Data) <- paste0("v",1:nVar)

# Simple model:
mod <- paste(apply(combn(colnames(Data),2),2,function(x)paste0(x[1],"~~",x[2])), collapse = "\n")

# Add some missings:
for (i in 1:ncol(Data)){
  Data[runif(500) < 0.1,i] <- NA
}

# Run model:
fit <- cfa(mod, Data, estimator = "WLS", missing = "pairwise")
```

Which results in:

```
Error in if (is.finite(fx) && fx < 0) fx <- 0 : 
  missing value where TRUE/FALSE needed
```
with traceback:
```
> traceback()
9: estimator.WLS(WLS.est = WLS.est[[g]], WLS.obs = lavsamplestats@WLS.obs[[g]], 
       WLS.V = WLS.V)
8: lav_model_objective(lavmodel = lavmodel, GLIST = GLIST, lavsamplestats = lavsamplestats, 
       lavdata = lavdata, lavcache = lavcache, verbose = verbose)
7: objective(.par, ...)
6: nlminb(start = start.x, objective = objective_function, gradient = GRADIENT, 
       lower = lower, upper = upper, control = control, scale = SCALE, 
       verbose = verbose)
5: lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable, 
       lavsamplestats = lavsamplestats, lavdata = lavdata, lavoptions = lavoptions, 
       lavcache = lavcache)
4: lavaan::lavaan(model = mod, data = Data, estimator = "WLS", missing = "pairwise", 
       model.type = "cfa", int.ov.free = TRUE, int.lv.free = FALSE, 
       auto.fix.first = TRUE, auto.fix.single = TRUE, auto.var = TRUE, 
       auto.cov.lv.x = TRUE, auto.cov.y = TRUE, auto.th = TRUE, 
       auto.delta = TRUE, auto.efa = TRUE)
3: eval(mc, parent.frame())
2: eval(mc, parent.frame())
1: cfa(mod, Data, estimator = "WLS", missing = "pairwise")
```
This came to my attention when you answered this question on the lavaan forum:

https://groups.google.com/d/msg/lavaan/RmMWGsfj_eQ/4OnP5UEbBQAJ

Do the `se` and `acov` attributes also need to be created per missing-data pattern?

```
data("HolzingerSwineford1939")
HolzingerSwineford1939$x1[1] <- NA
HS.model <- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '
fit <- cfa(HS.model, data = HolzingerSwineford1939, missing = "fiml")

lavPredict(fit)              # no problem
lavPredict(fit, acov = TRUE) # ERROR
```
I'm sure this is due to adjusted logic somewhere after adding the new `effect.coding=` argument.  Hopefully this is straight-forward to fix.

```
example(cfa)
update(fit, std.lv=TRUE)@Options[c("std.lv","auto.fix.first")] # both true
```
