i'm facing below error during execution 

[ahshan.md@xyz7030 bin]$ ./run
Detected project directory: /home/ahshan.md/spark-perf
Loading configuration from /home/ahshan.md/spark-perf/config/config.py
Traceback (most recent call last):
  File "./../lib/sparkperf/main.py", line 40, in <module>
    config = imp.load_source("config", "", cf)
  File "", line 50, in <module>

I run this test with default configs and jobs are running on 2 Spark nodes out of 5.
How can I force running it on multiple nodes?
Fix several 'NoSuchMethodError' during benchmark test in [Spark-2926](https://issues.apache.org/jira/browse/SPARK-2926)
type error
![image](https://cloud.githubusercontent.com/assets/23306275/25216203/1c3e6512-25d4-11e7-8864-a77c728bfac4.png)

when I use this spark workbench , In yran-client , only one executor runing everytime . Although I edit the testsuits.py by adding --num-executors and the cmd is as `/usr/hdp/2.5.0.0-1245/spark/bin/spark-submit --class spark.perf.TestRunner --master yarn --num-executors 2 --driver-memory 2g`  , but it still one executor working . 

From the commit history in master it has been almost a year since any activity, and some PRs have been un-merged for a very long time.

Who are the main contributors and can we add some folks with write privs so that some PRs can be addressed?
Can someone help me in running spark-perf's MLIB tests using OpenBLAS and MKL?

Hi, Adam,

How can you compare the value **MLLIB_SPARK_VERSION = 2.0.0**  -which is NOT a decimal value I suppose - in all the config.py file lines like (e.g.)   _**if MLLIB_SPARK_VERSION >= 1.1:**_

Thanks for a response.

A few API changes and lots of project file changes

The v2p0 folder contains the code that we'll run with Spark 2 so contains the API changes, it's hard to tell what's new as they're entirely new files but to summarise I have
- used foreachrdd not foreach for streaming
- used awaitTerminationOrTimeout
- reduced the defaults in config/config.py to a tiny scale factor (I think people will want to build it and see if it works in a tiny environment before scaling up, previous defaults included 20 G driver memory) and uses your $SPARK_HOME
