This PR removes the `io.LimitReader` that was throwing away server responses beyond an 8MB threshold.

The presence of that `LimitReader` was causing `pk-mount` to fail for me (with an unexpected EOF in JSON decoding) [here](https://github.com/perkeep/perkeep/blob/9a1336816afdfcf36ae0ec3705e5ae4053748f10/pkg/fs/mut.go#L139-L142) on directories with large subtrees.
Hello all,

Here is the situation where I am :

I'm looking to keep in Perkeep a note with words in bold, underlined words, italics words, etc… (so the note is not a .txt file but a .rtf file).

So after I uploaded this note on Perkeep, I find out that the web UI couldn't display it as "Document" like the web UI can for txt or pdf format file.

So I tried to convert the rtf note to the html format hopping that maybe the web UI would display it, but the same, he didn't.

So, I was wondering if there is a file format for formatted text (like .rtf, .html, .md, etc…) that the web UI could display as "Document" (in sort that we don't need each time to do a right click and then click to "View original" and then we are out of the webUI) like he does for .txt file ?
If there's not, I was wondering if it could be possible to add a .rtf reader (as there is for pdf files) to the web UI ?

Maybe, to display the rtf file, the webUI could convert the .rtf file to the html format and then display the html page as "Document" ? To display the html page, the webUI could maybe let the web navigator doing that.
Or maybe that there's others simpler solutions.

Thanks,

Gustav.
This PR adds some UI improvements to audio content blobs, and adds a "media" predicate that searches through all media tags.

Related to #202 

Some context:
I am hacking on the audio file handling a bit as I want to use perkeep to play music from my collection on my phone, and just wanted to share this early on. The next thing I wanted to do is have a central player element instead of a per-file one, so that I can navigate while it's playing.
Possible fix for #878. Have been running with this change for a little while, haven't seen the deadlock again yet, pretty sure I would have by now. Also, `go test -race ./...` reports no (new) race conditions.
Mostly this involved adding keys to composite literals, which `go vet` recently started requiring. However, there are a few legitimate bugfixes in here:

- Some structs were being copied with `a := *b` that should not have been, because they included `sync.Mutex`es.
- Some unreachable code was meant to be retrying indexing failures.
- Some context cancelers were not being called.

This PR also runs the whole tree through `go fmt`, producing a few additional diffs.
I've been encountering rate-limit-exceeded errors trying to dump a lot of files into a GCS backend (via `pk-mount`).

I thought what I needed was a rate limiter. That's https://github.com/perkeep/perkeep/pull/1285.

But the problem persisted and I discovered that the GCS blobserver was repeatedly re-uploading the same blob over and over (to wit: my PGP public key). So I wrote _this_ PR, to skip uploading a blob if it's already present.

~~But that's still not good enough to make the rate-limit-exceeded errors go away. I figure this change is still a good one anyway, so here it is while I dig a bit more.~~ Fixed in https://github.com/perkeep/perkeep/pull/1287/commits/18e8c5bc91dbe3f0ddf1dc5186c7d4d9babb475b by using an explicit call to `Attrs` before the call to `NewWriter`.
This solves rate-limit-exceeded errors when dumping large numbers of blobs into a Google Cloud Storage backend. The default limit is 1 request per 10ms and can be overridden with the new optional setting `rate_limit`.
Fixes https://github.com/perkeep/perkeep/issues/318. Maybe overkill? This compresses all server responses; that issue suggested compressing only JSON responses.
Run `go get -t -u` on direct dependencies in `go.mod` with semver versions > v0.0.0. Turns out that's just a few. Also rerun `go mod vendor`.

Among other things, this gets the upsert SQL changes in sqlite3, needed for https://github.com/perkeep/perkeep/pull/1282.
This PR is a **preliminary sketch** for a new blobserver type that uses files uploaded to it as their own storage.

When you add a file to an `fsbacked.Storage` that's within the directory tree it controls, an entry is added to a database that maps between files and blobrefs; but the file's contents are not copied anywhere. When fetching the file's content blob later, the database directs the `Storage` to the right local file and the data is served from there.

Adding files _outside_ the directory tree, or adding any other kind of blob, fails over to another blobserver nested inside the `fsbacked.Storage`.

This solves the problem of wanting to add a tree of large files (e.g., videos of my kids growing up) to a local Perkeep instance without storing all the data twice. This should be used only on directory trees whose files do not change, lest the blobrefs in the database become mismatched to their corresponding files.

A number of other changes throughout Perkeep would be needed to make this truly useful. The `io.Reader` presented to a blobserver's `ReceiveBlob` method is usually (always?) some wrapper object (like [checkHashReader](https://github.com/perkeep/perkeep/blob/d342b0e26632217a93a7b9a2ce85acca0c5cd00b/pkg/blobserver/receive.go#L71-L79)) that conceals the underlying `*os.File`, without which `fsbacked.Storage` cannot detect that a file within its tree is being uploaded. And in any case, Perkeep imposes [rather a low limit on blob sizes](https://github.com/perkeep/perkeep/blob/d342b0e26632217a93a7b9a2ce85acca0c5cd00b/pkg/constants/constants.go#L22-L23) for this purpose.

Presented for further discussion.