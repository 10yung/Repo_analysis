I am trying to run cadvisor globally on every node in my swarm. To visualize data properly in Prometheus I need a `hostname` to be along with metrics.

Stack config:
```
services:
  cadvisor:
    image: google/cadvisor
    command: -logtostderr -docker_only
    hostname: '{{.Node.Hostname}}'
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /:/rootfs:ro
      - /var/run:/var/run
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - 7778:8080
    networks:
      - prometheus_net
    deploy:
      mode: global
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  prometheus:
    ...
```

In this stack there's a Prometheus instance running that uses service discovery to get all nodes where cadvisor is running and get all metrics from them:

```
  - job_name: "cadvisor"
    dns_sd_configs:
     - names: ['tasks.cadvisor']
       type: 'A'
       port: 8080
```

Later on if we inspect `cadvisor_version_info` metrics, that should contain hostname, we can see that there are no labels with hostname (formatted a bit so not to be in one line):
```
cadvisor_version_info{
  cadvisorRevision="8949c822",
  cadvisorVersion="v0.32.0",
  dockerVersion="19.03.5",
  instance="10.0.11.9:8080",
  job="cadvisor",
  kernelVersion="3.10.0-693.el7.x86_64",
  osVersion="Alpine Linux v3.7"
}
```

No matter what I do I still cannot get a proper `hostname` to be somewhere within any metric collected from cadvisor.

Please help, I haven't found any documentation how to make it properly. 

Thank you!
TCP retransmits might indicate a network issue (see the discussion on this issue: prometheus/node_exporter#1023), but currently it only reported by node_exporter, on node level. Is it possible for cadvisor to collect it also so we can have those metrics per container?
As a newcomer, it is very much essential to bootstrap the local setup as quickly as possible.  If someone is inexperienced and encounter some errors, it consumes a lot of time and makes them hesitant to further continue to explore the project. I am proposing to create `make` commands in already present makefile to onboard developers much more quickly, with necessary checks for version and dependencies in place. 
I use overlay2+xfs as storage driver for docker. it work ok, but cannot get fs stats per container.

> [root@xxg merged]# cat /etc/docker/daemon.json 
{
  "registry-mirrors": ["http://127.0.0.1:65001"],
  "data-root": "/var/lib/docker",
  "storage-driver": "overlay2",
   "storage-opts": [
     "overlay2.size=10G"
   ],
  "log-opts": {
	"max-file": "5",
        "max-size": "50m"
  }
}


df -h look work ok
> tmpfs                         126G   12K  126G   1% /var/lib/kubelet/pods/17db5fd2-201f-11ea-ac72-6c92bf07426d/volumes/kubernetes.io~secret/default-token-gj6mr
overlay                        10G  8.0K   10G   1% /var/lib/docker/overlay2/c1b9c6bc043037a7737fcab5404344c6a68f7daa29b43b16cf8606b8454d80c3/merged
shm                            64M     0   64M   0% /var/lib/docker/containers/d6fb5b83ef0152ca3ccd92e8f4af249fc936b3faa3cbe3c94572d80568559692/mounts/shm
overlay                        10G  8.0K   10G   1% 

but cannot get container_fs_limit_bytes per container, which set overlay2.size=10G, it only the entire disk

>container_fs_limit_bytes{container="testnew2-sit-wildfly-97292",container_name="testnew2-sit-wildfly-97292",device="/dev/mapper/docker-thinpool",id="/kubepods/burstable/poda075185d-254f-11ea-82d8-6c92bf072a49/6cea1864932b22b0e1d8e0a8aff10076dc3172f8350183fdd0b6d8c3a989575c",image="sha256:ec9c0eccac34b51574470eb0f1ba1228209054de352138771adc573fe8af7dfa",name="k8s_testnew2-sit-wildfly-97292_testnew2-sit-wildfly-97292-648487d57b-lz4s5_testnew2_a075185d-254f-11ea-82d8-6c92bf072a49_2",namespace="testnew2",pod="testnew2-sit-wildfly-97292-648487d57b-lz4s5",pod_name="testnew2-sit-wildfly-97292-648487d57b-lz4s5"} 1.073217536e+12 1577712011496

When I start cAdvisor (v0.33.0) in docker, the startup fails and the log prompts: "manager.go:341] Registration of the raw container factory failed: inotify_init: too many open files. cadvisor.go:180] Failed to start container manager: inotify_init: too many open files". 
But 'openfiles' has been configured to 600,000 and it still fails to start until I adjust the 'openfiles' to 1 million. 
I don't know how many 'openfiles' it needs, or does it mistakenly think that the file handle is abnormal or I need adjust  the other system parameter?
Thanks for answer.
Actually, we are trying to test the cadvisor based disk i/o metrics collection (via prometheus) for different file system (esp. on block and nfs). 

We creating statefulset of sample application to collect those metrics. We tested by deploying the statefulset application using block storage and it works fine. means we could able collect the disk i/o related metrics.

By checking the cadvisor metrics code, we found that the supported file system of cadvisor to collect is ("btrfs", "overlay", "tmpfs", "xfs", "zfs".). 

So, when we create a statefulset based on NFS storage, we will not be able to see any disk i/o related metrics via cadvisor. Is this correct?

If yes, how do we collect the container based disk i/o metrics in which the container is using a NFS storage as a backend?

Please clarify.

1) Is all the network related metrics are reported per POD interface or on the host interface? How cadvisor collects the container network related metrics?

2) Is there any correlation between metrics named "container_network_receive/transmit_packets_dropped_total" and "container_network_receive/transmit_errors_total" [for ease, I made receive/transmit together]. Because in our lab, we observed there are packet drops for few "kube-system" pods, whereas there is no errors reported and the respective error related metrics is always '0'. Attached the graphs for reference.

![graph-1-receivepacketsdropped](https://user-images.githubusercontent.com/1535689/70695646-31b29900-1ce8-11ea-8a1e-f8abce165481.JPG)
![graph-2-receiveerrors](https://user-images.githubusercontent.com/1535689/70695647-31b29900-1ce8-11ea-8b8d-3d2e7ae6a1b0.JPG)


Ideally, when there is a packet drop it means there could be a transmission / format errors and so theoretically speaking both the metric should be populated right.

It would be great if the above metrics could be described in more detail.

3) Again, the metric type for network and disk i/o related metrics are of "Counter". In general, is it because GAUGE is only for values that have all the points until process lives ex: memory. Is this understanding correct?
A simple patch to allow the reading of a db password from a file as opposed to having to type the password on the command line when starting cadvisor.  This can be useful with e.g. docker secrets where you can specify "-storage_driver_password_file=/run/secrets/cadvisor_influxdb_password".

InfluxDB looks to be the only storage engine with authentication so it's only valid for that at the moment but would be trivial to extend to other storage engines if they gain authentication functionality e.g. #1570 

This should address #1633 

Tested with Docker 19.03.5 against InfluxDB 1.7.9

![graph_5m](https://user-images.githubusercontent.com/1535689/70493126-a5a84200-1b2c-11ea-995f-e047c5412652.JPG)
Did a small study to report the CPU usage in terms of MHZ.

To get the POD’s cpu usage (sum of the CPU usage of each container belonging to the pod), the below query is used that will give the number of cores that are being used by each pod.

sum by (pod_name) (rate (container_cpu_usage_seconds_total{namespace="default", name=~".*cpu-stress.*"}[5m]))

Attached the sample graph for reference. CPU simulation is done by deploying a sample deployment that uses stress tool to stress the CPU.
		
As in the above query, the final output per pod will be in terms of cores. To convert the cores into MHZ, there is no out of the box solution from Prometheus (through cAdvisor) even with queries as I understood.

As per the study, there would be a manual intervention required to convert the cores into MHZ because the meaning of CPU differs in various platform. Challenge here is to understand whether one CPU in Kubernetes is one physical core or one Hyper-thread and what is the corresponding clock speed? It varies based on the infrastructure that is being used to run Kubernetes.

One CPU, in Kubernetes, is equivalent to:
•	1 AWS vCPU
Each vCPU is a thread of a CPU core, except for T2 instances. For T2 instances, 1 vCPU = 1 physical core. For all others, 1 vCPU = 1 logical core.
Reference: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html ; https://aws.amazon.com/ec2/instance-types/
•	1 GCP Core
A vCPU is implemented as a single hardware Hyper-thread on one of the available CPU platforms.
Reference: https://cloud.google.com/compute/docs/machine-types ; https://cloud.google.com/compute/docs/cpu-platforms
•	1 Azure vCore
1 vCore = 1 hyper-thread, except for Gen4 hardware generation.
Reference: https://docs.microsoft.com/en-us/azure/sql-database/sql-database-service-tiers-vcore
•	1 Hyperthread on a bare-metal Intel processor with Hyperthreading

Let us take the bare-metal case as an example:
Hyper-thread: enabled
CPU: 2 sockets with 24 cores each (48 physical cores), yielding 96 Hyper-threads.
Clock-speed of each core: 2.7GHZ or (2700MHZ)
So, the clock-speed of single hyper-thread would be 2700MHZ / 2 threads = 1350MHZ
If in case, POD has used 100m core then the it can be converted as below to show in MHZ,
(100 * 0.001) * 1350MHZ = 135 MHZ

Any other solution in my scenario please? 

Also, I feel that this could be facilitated by cadvisor itself to have a metrics for CPU in MHZ. Do you agree?
Let's take we want to measure CPU usage in containers. cadvisor provides a metric named "container_cpu_usage_seconds_total" which is of a metric type: Counter. As the counter, is an accumulator we need to apply a function over it to see the type of values we need.

I saw in most of the articles, rate function is applied. As we know, the rate function "calculates the per-second average rate of increase of the time series in the range vector". Actually, the output of rate function query gives us a value that is an average value measure over the period of time.

Example: rate (container_cpu_usage_seconds_total{namespace="default"}[5m]) gives the average CPU usage in the last 5 mins.
That means, for each instant t in the provided instant vector the rate function uses the values from t - 5m to t to calculate its average value. So, for example, the value at 08:30 describes the average number of "container_cpu_usage_seconds_total" per second that were used between 08:25 and 08:30, the value at 08:31 describes the average number of "container_cpu_usage_seconds_total" per second that were created between 08:26 and 08:31, and so on…

Considering such values to identify the peak CPU usage at instant, as it is an average we might miss the peak spot.

The question here is:

1) Is it not possible to measure the absolute value of "container_cpu_usage_seconds_total"? Ex: What is the absolute current CPU usage at this instance of time?

2) Like, memory metric defined as Gauge "container_memory_usage_bytes", why "container_cpu_usage_seconds_total" could not be gauge metric type. In this case, we would get the absolute current value of CPU usage. Isn't? Correct my understanding if I am wrong?

3) In general to dimension an application, is it suggested to take the output of rate function.