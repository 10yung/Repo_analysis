I tried running `coz` on the inproc_lat benchmark program from zeromq/libzmq. This causes an interrupted system call I identified via strace as follows:
```
[pid 29215] poll([{fd=12, events=POLLIN}], 1, 0) = ? ERESTART_RESTARTBLOCK (Interrupted by signal)
[pid 29215] --- SIGPROF {si_signo=SIGPROF, si_code=SI_TIMER, si_timerid=0, si_overrun=0, si_value={int=0, ptr=NULL}} ---
```
While the code might be changed to work around this, this seems to quite heavily affect the analysis results, or doesn't it?
The coz paper states:


> 
> COZ’s profiler thread begins an experiment by selecting a line to virtually speed up, and a randomly-chosen percent speedup. **Both parameters must be selected randomly; any systematic method of exploring lines or speedups could lead to systematic bias in profile results.**
> One might assume that COZ could exclude lines or virtual speedup amounts that have not shown a performance effect early in previous experiments, but prioritizing experiments based on past results would prevent COZ from identifying an important line if its performance only matters after some warmup period.
> 

I'd like to understand your thinking on this. I only see two reasons to do this:

1) Functions need to warm up. Doesn't coz already wait a little bit before starting experiments?

2) Path dependence.  Maybe speeding up a line a lot forces something else to get JIT-ed , or you fill up a queue and the program changes algorithms, and future results depend on past ones.

In this case, would a permutation of `range(0,100,5)` for the speedups also work?

For collecting data for a graph, I think randomly sampling from the range makes it take a lot more samples to collect all 21 data points.
I think this is the "coupon's collector problem", and taking aside the 50% chance of speedup=0, the other 20 increments should take `20*(1+1/2 + 1/3 + ... + 1/20)` = 72 samples to fill the range on average.

So combined with the fact that 50% of  the time the speedup is 0, I think this means you need to run an experiment 144 times on average instead of 21 to collect a full graph?

Let me know if there's no way around this, or it doesn't matter because, eg, it already takes a number of experiment samples to get good information.

I've mostly been running coz with `--fixed-line`, but sometimes the way it doesn't get data for a particular point in the plot makes me want to run it with `seq 0 100 5 | while read $i; do coz run --fixed-speedup $i --fixed-line ... `.

Should I just tweak my program to make more samples happen anyway?

Or is the random speedup only needed when a random line is picked, and could having coz use `permute(range(0,100,5))` would work fine when --fixed-line is selected?

Regards,
Amédée
It seems that `coz run ...` saves data only when profiling target reaches the end of main().

Some programs are designed to exit only when interrupted, or take a long time to terminate.   It would be nice if Coz could deal with signals, exit(), etc, and save the data collected up to that point.  
Heya,

I just found this via the @emeryberger's [Strange Loop](https://www.youtube.com/watch?v=r-TLSBdHe1A) talk and was super impressed!

I was wondering what would need to happen to enable profiling of NodeJS processes. Parallel execution isn't widespread in the JS world, but asynchronous execution is the norm. Getting this sort of profiling data would be invaluable.

NodeJS doesn't support macros, but it does support native c bindings via [node-gyp](https://github.com/nodejs/node-gyp). Maybe that could be leveraged? 

In case you toggle a progress point the UI will fail to update and some times switch to a canonical path - e.g. /path/to/file.c:1 instead of just file.c:1

Changing "Sort By" will update the UI correctly.

Sample programs
```
gcc -O0 -fno-omit-frame-pointer -gdwarf-4 -ldl -o linear linear.c
gcc -O0 -fno-omit-frame-pointer -gdwarf-4 -lpthread -ldl -o threads threads.c
```

Firefox 69, Fedora 30 x86_64.

[linear.txt](https://github.com/plasma-umass/coz/files/3712463/linear.txt)
[threads.txt](https://github.com/plasma-umass/coz/files/3712464/threads.txt)

When profiling the following programs coz will fail to find optimizations of the methods; showing a slowdown when optimizing -- in most cases.

Compile with

```
gcc -O0 -fno-omit-frame-pointer -gdwarf-4 -ldl -o linear linear.c
gcc -O0 -fno-omit-frame-pointer -gdwarf-4 -lpthread -ldl -o threads threads.c
```

Furthermore the profile.coz file won't contain all progress point definitions, and in the case of linear.c the `c()` data won't even show up.

[linear.txt](https://github.com/plasma-umass/coz/files/3712436/linear.txt)
[threads.txt](https://github.com/plasma-umass/coz/files/3712437/threads.txt)

I am unable to see any useful result when the dynamic library is loaded during execution time. 
### Steps to Reproduce

* Download and extract [round-trip.tar.gz](https://github.com/plasma-umass/coz/files/3649275/round-trip.tar.gz)
  * alternatively, if you don't want to run a random executable that I'm uploading, build [this branch](https://github.com/fitzgen/walrus/tree/coz-profiling) with `cargo build --release --features parallel --example round-trip` and you should get a binary at `target/release/examples/round-trip`
* Run `coz run -s '%walrus%' --- ./path/to/round-trip some-example.wasm 10` where `some-example.wasm` is any wasm file, eg https://github.com/rustwasm/walrus/blob/master/benches/fixtures/dodrio-todomvc.wasm

### Expected Results

Runs `coz` and creates a profile.

### Actual Results

```
$ coz run -s '%walrus%' --- target/release/examples/round-trip benches/fixtures/dodrio-todomvc.wasm 100000
[libcoz.cpp:100] bootstrapping coz
[libcoz.cpp:128] Including MAIN, which is /home/fitzgen/walrus/target/release/examples/round-trip
[inspect.cpp:325] /lib/x86_64-linux-gnu/ld-2.27.so is not in scope
[inspect.cpp:325] /lib/x86_64-linux-gnu/libdl-2.27.so is not in scope
[inspect.cpp:325] /lib/x86_64-linux-gnu/librt-2.27.so is not in scope
[inspect.cpp:325] /lib/x86_64-linux-gnu/libpthread-2.27.so is not in scope
[inspect.cpp:325] /lib/x86_64-linux-gnu/libgcc_s.so.1 is not in scope
[inspect.cpp:325] /lib/x86_64-linux-gnu/libm-2.27.so is not in scope
terminate called after throwing an instance of 'std::underflow_error'
  what():  cannot read past end of DWARF section
```
Hi,

Something is off, I am trying to run coz with CryptoMiniSat with ApproxMC but I am getting:

```
$ coz run --- ./approxmc blasted_case110.cnf.gz.no_w.cnf.gz -v2
[libcoz.cpp:100] bootstrapping coz
[libcoz.cpp:128] Including MAIN, which is /[...]/build/approxmc
terminate called after throwing an instance of 'dwarf::format_error'
  what():  DW_FORM_sec_offset not expected for attribute (DW_AT)0x2137
```

I am using latest `coz` and latest `libelfin` -- both compiled from git. Do you know what could be the issue? Both ApproxMC and CryptoMiniSat are open-source, see https://github.com/msoos/cryptominisat and https://github.com/meelgroup/approxmc

But I am getting the error with plain CryptoMiniSat too, so it's probably in CryptoMiniSat. I am compiling with `-g` and `mtune=auto`, and I am linking in boost, zlib and m4ri. All are dynamically linked. Should I try without linking all these? I am using Arch Linux, so I think the debug symbols should be available for all libraries.

Do you know what that issue above could mean?
While experimenting with a simple Intel TBB program (that checks for prime numbers in parallel) I noticed a difference in the projected speedup of the program while profiling for throughout and latency. While profiling for throughput, I placed a progress point at the end of a loop. The profile highlights a line in the program and projects an almost linear increase in speedup (see attached screenshot). But while profiling for latency, I placed progress points at the beginning and the end of loop. Coz highlights the same line as the throughput profile, but shows a decrease in the projected program speedup. In the attached screenshot, primes1 refers to the progress points for latency and detect_primes_tasks.cpp:53 refers to the progress point for throughput.

I expected both the latency and the throughput to increase since the highlighted link is within a region which is indeed the bottleneck in the program. Any idea on why I would be seeing different results? I have attached the TBB program (as a text file) that I used for testing.
![Screen Shot 2019-03-20 at 6 38 41 PM](https://user-images.githubusercontent.com/15932362/54724321-fe6c2080-4b40-11e9-82f2-e331bd7204c6.png)
[detect_primes_tasks.txt](https://github.com/plasma-umass/coz/files/2990395/detect_primes_tasks.txt)
