Hiii ,
First of all I want to know or see the expected output as the code doesn't  run with me ,so i can know where is the problem ,also i have this error if anyone can help me 

Error in suma_stitch (line 9)
[e, em, lst] = zglobb({sprintf('%s*', imaname)});
and this is the code 
function A = suma_stitch(imaname)
% A function to put together a series of suma recorder images
% Very crude, only for the intrepid.
% Example: A = suma_stitch('imageseries_');
%The would be the images as spat out by the recorder window after
% a suma 'r' key stroke with SUMA_SnapshotOverSampling > 1

figure(1); clf
[e, em, lst] = zglobb({sprintf('%s*', imaname)});
N_im = length(lst)
N_1 = round(sqrt(N_im))
k=1
figure(1); clf
for (i=1:1:N_1),
   for (j=1:1:N_1),
      %k = ((i-1)+(j-1)*N_1)+1
      lst(k).name
      a = imread(lst(k).name); size(a)
      if (k==1), A = zeros(N_1.*size(a,1), N_1.*size(a,2), size(a,3), 'uint8'); end
      istrt = (N_1-i)*size(a,1) + 1;
      istp = istrt + size(a,1) - 1;
      jstrt = (j-1)*size(a,2) + 1;
      jstp = jstrt + size(a,2) - 1;
      istrt, istp-istrt, jstrt, jstp-jstrt,
      A(istrt:istp,jstrt:jstp,:) = a;
      subplot (N_1, N_1, k); image(a); title(lst(k).name); drawnow; 
      k = k +1;
   end
end

figure(2); clf
image(A); axis square;  drawnow
info = imfinfo(lst(1).name);info.Format
imwrite(A, sprintf('%s_stitch.%s', imaname, info.Format), info.Format);

```
What steps will reproduce the problem?
In MATLAB 2014b, run "init_subj'. The function 'datetime(true)' is called in 
init_subj.m (line 40).


What is the expected output? What do you see instead?
The built-in function 'datetime' is used instead of the MVPA function 
'datetime'. Even if you are in the directory core\util, running 'which 
datetime' will still point to the built-in function.

The solution is to rename the MVPA version of 'datetime'.


What version of the product are you using? On what operating system?
MATLAB 2014b. Windows 7.


Please provide any additional information below.
No additional information. The solution is to rename the MVPA function.
```

Original issue reported on code.google.com by `markbruu...@gmail.com` on 11 Feb 2015 at 12:16

```
What steps will reproduce the problem?
1. subj = load_afni_mask(subj,'wholebrain','wholebrain+orig');

2. class_args.train_funct_name = 'train_gnb';
   class_args.test_funct_name = 'test_gnb';
   class_args.nHidden = 0;
3.

What is the expected output? What do you see instead?
The output I see is: Perf = [ 0.4793 0.4793 0.4793 0.4793     0.4793     0.4793 
0.4793 0.4793 0.4793 0.4793]
Perf_total = 0.4793 and I noticed the value of "acts" is all
NaN, please see the attachment!


What version of the product are you using? On what operating system?
Matlab R2014a.  Windows 7 (64bit)

Please provide any additional information below.
I just simply modify the "tutorial_easy.m" as follows
1) I change the mask to the intra-cranial"wholebrain" mask.
2) I change the Backprop Classifier to Gaussian Naive Bayes Classifier.
Then I run the code and find that MVPA toolbox did not account for the 
possibility of underflow.
I paste part of the result here. Please take a look at it!

```

Original issue reported on code.google.com by `smithli2...@gmail.com` on 29 Jan 2015 at 10:13

Attachments:
- [Capture.jpg](https://storage.googleapis.com/google-code-attachments/princeton-mvpa-toolbox/issue-5/comment-0/Capture.jpg)
- [Capture1.JPG](https://storage.googleapis.com/google-code-attachments/princeton-mvpa-toolbox/issue-5/comment-0/Capture1.JPG)

```
The number of hidden neurons should be defined. Changing the activation 
functions to linear. A 3-layer NN with linear activation units is equivalent to 
a 2-layer NN with nonlinear activation units. My tests has shown better 
accuracy with linear activation units than logistic activation units. 
Another addition is a random seed so that different NN weights are generated at 
each run. I am not sure if netlab handles this, but, it seems that netlab3.3 
does not have this feature.
Finally, we need few hidden neurons/units. The value nHidden=10 is a good 
choice. 

I would also suggest to reduce the defaults.epochs from 500 to 200 to speedup 
the training. I am using 100 now and it works pretty fine.

With very best regards,
Mohammed S. Al-Rawi,
Visual neuroscience lab, IBILI, University of Coimbra, Portugal
al-rawi(aaattt)uc(dddooottt)pt


With very best regards,
Mohammed S. Al-Rawi
```

Original issue reported on code.google.com by `ms.alr...@gmail.com` on 23 Jan 2014 at 10:59

Attachments:
- [train_bp_netlab.m.patch](https://storage.googleapis.com/google-code-attachments/princeton-mvpa-toolbox/issue-4/comment-0/train_bp_netlab.m.patch)

```
Hey,

after adding the paths to my matlab installation I got a warning that isrow has 
the same name as the built in isrow. Also the behavior of the two functions is 
slightly different. This  might produce some errors when using the toolbox and 
other scripts that rely on the original isrow. I usually add a prefix 
(pr_isrow) in front of my scripts to avoid such problems. Did you consider 
doing that or is there a more elegant solution?


What version of the product are you using? On what operating system?
Latest mvpa release, MATLAB R2012a, Windows 7 64 bit 

Please provide any additional information below.


```

Original issue reported on code.google.com by `julian.k...@googlemail.com` on 11 Jan 2013 at 8:52
