I want to train on custom dataset with VOC format


Hi! I downloaded VOC2012 dataset and ran a training with original train.py, but got an error

```
~/nefteprovod/ssd.pytorch$ python3 train.py 
/home/karina/nefteprovod/ssd.pytorch/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  self.priors = Variable(self.priorbox.forward(), volatile=True)
Loading base network...
Initializing weights...
train.py:214: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  init.xavier_uniform(param)
Loading the dataset...
Training SSD on: VOC0712
Using the specified args:
Namespace(basenet='vgg16_reducedfc.pth', batch_size=32, cuda=True, dataset='VOC', dataset_root='/home/karina/nefteprovod/ssd.pytorch/data/VOCdevkit/', gamma=0.1, lr=0.001, momentum=0.9, num_workers=4, resume=None, save_folder='weights/', start_iter=0, visdom=False, weight_decay=0.0005)
train.py:169: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  targets = [Variable(ann.cuda(), volatile=True) for ann in targets]
/usr/local/lib/python3.5/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Traceback (most recent call last):
  File "train.py", line 255, in <module>
    train()
  File "train.py", line 178, in train
    loss_l, loss_c = criterion(out, targets)
  File "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/karina/nefteprovod/ssd.pytorch/layers/modules/multibox_loss.py", line 97, in forward
    loss_c[pos] = 0  # filter out pos boxes for now
IndexError: The shape of the mask [32, 8732] at index 0does not match the shape of the indexed tensor [279424, 1] at index 0
```

do you have any ideas what to do?
I checked these two file and find many common codes, so I am confused about the differences.
Also, I find some Inconsistency in these codes, is someone have the same question with me?
thx
How to achieve real-time detection?Thanks
I only see the iters=120000 in the code 
and i find this thing : epoch_size = len(dataset) // args.batch_size  
but the value of  epoch_size is 2505, I feel it is too big. is this number the real epoch_size???

The following errors were encountered in training.
PyTorch 1.2.0
python 3.6
`Traceback (most recent call last):
  File "train.py", line 257, in <module>
    train()
  File "train.py", line 97, in train
    ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])
  File "/media/disk/wudi/ssd.pytorch/ssd.py", line 207, in build_ssd
    base_, extras_, head_ = multibox(vgg(base[str(size)], 3),
  File "/media/disk/wudi/ssd.pytorch/ssd.py", line 136, in vgg
    conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
  File "/media/disk/wudi/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 330, in __init__
    False, _pair(0), groups, bias, padding_mode)
  File "/media/disk/wudi/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 41, in __init__
    out_channels, in_channels // groups, *kernel_size))
RuntimeError: CUDA error: out of memory
`
What is the reason for this mistake? Thanks.
I met this error in training.
`Original Traceback (most recent call last):
  File "/media/disk/wudi/.local/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/media/disk/wudi/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/media/disk/wudi/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/media/disk/wudi/SSD/ssd/data/datasets/voc.py", line 50, in __getitem__
    boxes, labels = self.target_transform(boxes, labels)
  File "/media/disk/wudi/SSD/ssd/data/transforms/target_transform.py", line 21, in __call__
    self.corner_form_priors, self.iou_threshold)
  File "/media/disk/wudi/SSD/ssd/utils/box_utils.py", line 89, in assign_priors
    best_target_per_prior, best_target_per_prior_index = ious.max(1)
RuntimeError: cannot perform reduction function max on tensor with no elements because the operation does not have an identity
`
Why does this occur? Thanks.
Hi, the version of my pytorch is 1.3. and the python version is 3.6.  when I run the code 

y = net(x)

which is for the detection.
the warning is arise:
UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)

I am very confused about how to solve that problem, so is there anyone have a clue?
Dear all.
I am running SSD300 on a custom chest X-ray dataset preprocessed as VOC format, so far train.py, test.py and demo.py works well while for the eval.py, I am getting the results as follows,
VOC07 metric? Yes
Reading annotation for 1/264
Reading annotation for 101/264
Reading annotation for 201/264
Saving cached annotations to /home/yuyang/data/VOCdevkit/VOCNIH14/annotations_cache/annots.pkl
AP for atelectasis = 0.0000
AP for cardiomegaly = 0.0000
AP for effusion = 0.0000
AP for infiltrate = 0.0000
AP for mass = 0.0000
AP for nodule = 0.0000
AP for pneumonia = 0.0000
AP for pneumothorax = 0.0000
Mean AP = 0.0000
~~~~~~~~
Results:
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
~~~~~~~~

Does anyone know how may I solve the issue? Thanks. 