First of all, I would like to thank you! Browsing around the net could not find a seq2seq model as clear as yours. Nonetheless, I believe there is a minor issue in ipython-notebooks/tf/TF tutorial.ipynb In [26] the line:

`dec_inp = ([tf.zeros_like(enc_inp[0], dtype=np.int32, name="GO")]+ enc_inp[:-1])`

Should be:

`dec_inp = ([tf.zeros_like(labels[0], dtype=np.int32, name="GO")] + labels[:-1])`

This will enable you to have different sequence lengths and vocab sizes for dec_inp and enc_inp.
Would you have any ideas on what could be causing this?

```
magnitude = tf.sqrt(tf.reduce_sum(tf.square(dec_memory[1])))
tf.scalar_summary("magnitude at t=1", magnitude)

Truncated Traceback (Use C-c C-x to view full TB):
/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc in assert_has_rank(self, rank)
    596     """
    597     if self.ndims not in (None, rank):
--> 598       raise ValueError("Shape %s must have rank %d" % (self, rank))
    599 
    600   def with_rank(self, rank):

ValueError: Shape (?, 100) must have rank 1
```
