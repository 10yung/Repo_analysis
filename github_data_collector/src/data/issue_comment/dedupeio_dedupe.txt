- [ ] fastcluster
- [x] pyhacrf
- [x] hcluster
- [x] pylbfgs
- [ ] BTrees
- [x] affinegap
- [ ] levenshtein search
- [ ] doublemetaphone
- [ ] zope.index
- [ ] persistent
We use tuples extensively throughout the code base, mainly for memory reasons. It would make for easier to understand code if we used namedtuples, which apparently don't add memory overhead.

_(Whoops&mdash;originally posted this as dedupeio/dedupe-examples#101, whereas it is probably better for this repo. Moving it over here instead.)_

Thanks for this awesome project! We're really excited to start using it.

That said, we've had a lot of trouble understanding the documentation.  In particular for blocks, it appears to be a combination of missing information, out of date, and internally inconsistent.  The clearest example of this is in the documentation for `Gazetteer` ([link](https://docs.dedupe.io/en/latest/API-documentation.html#Gazetteer)).  We're using Gazetteer on a large quantity of data, so we're trying to use `matchBlocks()` instead of `match()`, but even with reading the source code, we haven't been able to figure out how to properly set up the blocks. As an initial example, the `Gazetteer` object in the docs actually defines `matchBlocks()` twice, with _different_ documentation that includes different examples.  

[First definition][1], with the final example block structure as follows (the example itself is also syntactically invalid, the parens don't match up):
![image](https://user-images.githubusercontent.com/1328961/71748322-2282bf00-2e40-11ea-9841-662cbae7d942.png)

The second redefinition doesn't have a direct page link, so go [here][2] and then scroll up slightly to see it.  Final example block structure it gives:
![image](https://user-images.githubusercontent.com/1328961/71748370-53fb8a80-2e40-11ea-99c2-90613ba5bf3b.png)

`StaticGazetteer` has the same issue, presumably due to inheritance.

Can you clarify what the right way to do blocking is? Thanks so much!

[1]: https://docs.dedupe.io/en/latest/API-documentation.html#Gazetteer.matchBlocks
[2]: https://docs.dedupe.io/en/latest/API-documentation.html#Gazetteer.writeSettings



would make life a bit easier.
Running into the error:
OverflowError: Python int too large to convert to C ssize_t

Referenced [722](https://github.com/dedupeio/dedupe/pull/722/files) and [723](https://github.com/dedupeio/dedupe/pull/723) and made changes to core.py to int64 which then causes the error:

ValueError: dimensions are too large; arrays and shapes with a total size greater than 'intp' are not supported.


Calls:
Traceback (most recent call last):
  File "f:/XXXXXXXXXX/XXX/XXX/third_party_dedupe_test.py", line 105, in <module>
    deduper.sample(temp_d, temp_z)
  File "C:\Python\Python37-32\lib\site-packages\dedupe\api.py", line 933, in sample
    index_include=examples)
  File "C:\Python\Python37-32\lib\site-packages\dedupe\labeler.py", line 438, in __init__
    sample_size)
  File "C:\Python\Python37-32\lib\site-packages\dedupe\labeler.py", line 78, in sample
    random_sample_size)
  File "C:\Python\Python37-32\lib\site-packages\dedupe\core.py", line 77, in randomPairsMatch
    i, j = numpy.unravel_index(random_pairs, (n_records_A, n_records_B))
  File "<__array_function__ internals>", line 6, in unravel_index
ValueError: dimensions are too large; arrays and shapes with a total size greater than 'intp' are not supported.


I am using MongoDB to get clusterids and passing the data "records" in the code to deduper.matchBlocks as below but I am not getting any cluster_ids back as  "clustered_dupes" is always empty, am I passing the data to match blocks in a wrong format? if this is  wrong format for match blocks please let me know the correct format
**Records with smaller_ids**:  
[('ETY1211', {'EtyNbr': 'ETY1211', 'block_id': 2, 'smaller_ids': [2], 'Alpha': 'A', 'City': 'EAST HARTFORD', 'ClusterInd': 'N', 'Cntry': 'US', 'Fname': 'A DALE & JUDY', 'FullAddr': '92 LANGFORD LN ', 'Lname': 'HUSTON', 'State': 'CT', 'Zip': '06118', 'cluster_conf': '-1', 'cluster_id': '-1'}, {2}), 
('ETY1213', {'EtyNbr': 'ETY1213', 'block_id': 2, 'smaller_ids': [2], 'Alpha': 'A', 'City': 'EAST HARTFORD', 'ClusterInd': 'N', 'Cntry': 'US', 'Fname': 'A DALE & JUDY', 'FullAddr': '92 LANGFORD LN ', 'Lname': 'HUSTON', 'State': 'CT', 'Zip': '06118', 'cluster_conf': '-1', 'cluster_id': '-1'}, {2})] 


When I pass the data to match blocks as below where with " set()" is empty then I am getting cluster_ids from clustered_dupes
**Records without smaller_ids**:
[('ETY1217', {'EtyNbr': 'ETY1217', 'block_id': 2, 'smaller_ids': [2], 'Alpha': 'A', 'City': 'EAST HARTFORD', 'ClusterInd': 'N', 'Cntry': 'US', 'Fname': 'A DALE & JUDY', 'FullAddr': '92 LANGFORD LN ', 'Lname': 'HUSTON', 'State': 'CT', 'Zip': '06118', 'cluster_conf': '-1', 'cluster_id': '-1'}, set()), 
('ETY1219', {'EtyNbr': 'ETY1219', 'block_id': 2, 'smaller_ids': [2], 'Alpha': 'A', 'City': 'EAST HARTFORD', 'ClusterInd': 'N', 'Cntry': 'US', 'Fname': 'A DALE & JUDY', 'FullAddr': '92 LANGFORD LN ', 'Lname': 'HUSTON', 'State': 'CT', 'Zip': '06118', 'cluster_conf': '-1', 'cluster_id': '-1'}, set())]





Hi, I upgraded the library and ran gazette but it's getting much slower than the previous versions.  I found it started to get slower since from version 1.9.7. And the function it's slower is dedupe.core.scoreGazette.

I compared the GitHub from 1.9.6 and 1.9.7 and cannot tell the reason why it's happening. 

After some investigation, I think it might be the multiprocessing in the later version is not working properly. I tried it with both multiprocessing and no multiprocessing and running no multiprocessing is even faster than the current one with multiprocessing.

Could you help investigate this? Thank you!! 
Hello. I'm trying to use mysql example with my data.
I have a db with fields fam,nam,snam,sex,dt_beth with full name, sex and date of birth. My task is to find doubles. 
To train the model I select 30 records from db and create manually 10 doubles (9 doubles and one marked as unsure). After training is complete, I try to use it on the whole database. I get the error below. I found closed issues with this problem, but I could not find a solution.

```
Traceback (most recent call last):
  File "D:\Distr\WPy64-3740\mysql_example.py", line 385, in <module>
    for cluster, scores in clustered_dupes :
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\dedupe\api.py", line 121, in matchBlocks
    threshold=0)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\dedupe\core.py", line 214, in scoreDuplicates
    raise BlockingError("No records have been blocked together. "
dedupe.core.BlockingError: No records have been blocked together. Is the data you are trying to match like the data you trained on?
```
When i was labeling I matched two records, but then in the output doesn't match. 
I remove the settings file and with deduper.markPairs(labeled_examples) I specify this match, but it still doesn't appear