The `/data/` path is the preferred way to access WQP data, so `https://www.waterqualitydata.us/data/Result/` instead of `https://www.waterqualitydata.us/Result/` 

Many of the newer WQP endpoints do not support the direct and as we move to new hosting solutions, we would like to move away from supporting the legacy mappings.

Add basic functionality examples or a 'quickstart' guide to the README.
The documentation shows a `/`...the data frame is a `.`.
For some of the larger data pulls...the site and parameter attribute calls can take as much time if not more than the data calls. Adding an argument to ignore the attributes would be pretty easy and could save a few of you power users a lot of time......

```r
StartDate <- "2018-02-01"; EndDate <- "2018-03-01"
sites <- c(430600089272001,430451089202201,431046087595401,425449088083101)
qw <- readNWISqw(siteNumbers = sites,parameterCd = "all",
                  startDate = StartDate,endDate = EndDate,
                  tz="CST6CDT")
qw$startDateTime[1]
[1] "2018-02-12 08:00:00 UTC"
```

Not sure if something's changed, or this is a bug that's been around, but dataRetrieval's looking for a column "sample_time_datum_cd" to match the sample_dt and sample_tm....but in this dataset, it's "sample_start_time_datum_cd" (to get the reference timezone). Happening here:
https://github.com/USGS-R/dataRetrieval/blob/master/R/importRDB1.r#L214

I think for sample, we'll need to check for both "sample_time_datum_cd" and "sample_start_time_datum_cd", that one's always been special....

Quick fix:
```r
qw <- dataRetrieval:::convertTZ(qw,
                        tz.name = "sample_start_time_datum_cd",
                        date.time.cols = "startDateTime",
                        tz = "CST6CDT")
qw$startDateTime[1]
[1] "2018-02-12 08:00:00 CST"
```


Similar to NWIS, give the users a way to use a single function for any service.
The Water Quality Portal now has summary services!

Currently, there are station summary services that allow you to see details at the characteristicgroup level, where you can query by the various site level parameters:

For Example, here is a huc12 query for data collected in the last 5 years:

https://www.waterqualitydata.us/data/summary/monitoringLocation/search?huc=020700080901&mimeType=geojson&summaryYears=5

the summaryYears parameter allows for "1","5", or "all"


and here is the response:

```
{
	"type": "FeatureCollection",
	"features": [{
		"type": "Feature",
		"geometry": {
			"type": "Point",
			"coordinates": [-77.5442000, 38.9594000]
		},
		"properties": {
			"ProviderName": "STORET",
			"OrganizationIdentifier": "21VASWCB",
			"OrganizationFormalName": "VIRGINIA DEPARTMENT OF ENVIRONMENTAL QUALITY",
			"MonitoringLocationIdentifier": "21VASWCB-1ABRB015.38",
			"MonitoringLocationName": "Rt. # 621 (Evergreen Mills Rd)",
			"MonitoringLocationTypeName": "River/Stream",
			"ResolvedMonitoringLocationTypeName": "Stream",
			"HUCEightDigitCode": "02070008",
			"siteUrl": "https://www.waterqualitydata.us/data/provider/STORET/21VASWCB/21VASWCB-1ABRB015.38/",
			"activityCount": "5",
			"resultCount": "28",
			"StateName": "Virginia",
			"CountyName": "Loudoun County",
			"characteristicGroupResultCount": {
				"Inorganics, Major, Non-metals": 2,
				"Microbiological": 1,
				"Nutrient": 6,
				"Physical": 19
			}
		}
	}, {
		"type": "Feature",
		"geometry": {
			"type": "Point",
			"coordinates": [-77.5356000, 38.9525000]
		},
		"properties": {
			"ProviderName": "STORET",
			"OrganizationIdentifier": "21VASWCB",
			"OrganizationFormalName": "VIRGINIA DEPARTMENT OF ENVIRONMENTAL QUALITY",
			"MonitoringLocationIdentifier": "21VASWCB-1ASOR000.59",
			"MonitoringLocationName": "Rt. # 621  (Evergreen Mills Rd)",
			"MonitoringLocationTypeName": "River/Stream",
			"ResolvedMonitoringLocationTypeName": "Stream",
			"HUCEightDigitCode": "02070008",
			"siteUrl": "https://www.waterqualitydata.us/data/provider/STORET/21VASWCB/21VASWCB-1ASOR000.59/",
			"activityCount": "5",
			"resultCount": "22",
			"StateName": "Virginia",
			"CountyName": "Loudoun County",
			"characteristicGroupResultCount": {
				"Microbiological": 1,
				"Nutrient": 6,
				"Physical": 15
			}
		}
	}, {
		"type": "Feature",
		"geometry": {
			"type": "Point",
			"coordinates": [-77.5344000, 38.9517000]
		},
		"properties": {
			"ProviderName": "STORET",
			"OrganizationIdentifier": "21VASWCB",
			"OrganizationFormalName": "VIRGINIA DEPARTMENT OF ENVIRONMENTAL QUALITY",
			"MonitoringLocationIdentifier": "21VASWCB-VAG406014-001",
			"MonitoringLocationName": "Evergreen Store",
			"MonitoringLocationTypeName": "Facility Industrial",
			"ResolvedMonitoringLocationTypeName": "Facility",
			"HUCEightDigitCode": "02070008",
			"siteUrl": "https://www.waterqualitydata.us/data/provider/STORET/21VASWCB/21VASWCB-VAG406014-001/",
			"activityCount": "2",
			"resultCount": "5",
			"StateName": "Virginia",
			"CountyName": "Loudoun County",
			"characteristicGroupResultCount": {
				"Nutrient": 5
			}
		}
	}]
}
```
There are a variety of ways that GETs can end up breaking, such as URLS being to long, problems escaping characters, to firewalls interpreting queries as attacks and blocking them, to apache routing getting all confused.   Many of these problems can be avoided by POSTing a JSON payload instead.  

The syntax is pretty reasonable, and is documented in the  [swaggerdocs](https://www.waterqualitydata.us/data/swagger-ui.html#!/Result/resultJsonPostRequestUsingPOST) and also below.  
you do need to send the headers, and include the mimetype in the URL.  here is an example curl:
`curl -X POST --header 'Content-Type: application/json' --header 'Accept: application/zip' -d '{"statecode":["US:55"],"countycode":["US:55:025","US:55:049"],"siteType":["Lake, Reservoir, Impoundment","Stream"],"sampleMedia":["Air","Water"]}' 'https://www.waterqualitydata.us/data/Station/search?mimeType=csv&zip=yes'`

```
{
  "analyticalmethod": [
    "string"
  ],
  "assemblage": [
    "string"
  ],
  "bBox": "string",
  "characteristicName": [
    "string"
  ],
  "characteristicType": [
    "string"
  ],
  "countrycode": [
    "string"
  ],
  "countycode": [
    "string"
  ],
  "dataProfile": "string",
  "huc": [
    "string"
  ],
  "lat": "string",
  "long": "string",
  "mimeType": "string",
  "minactivities": "string",
  "minresults": "string",
  "nldiurl": "string",
  "organization": [
    "string"
  ],
  "pCode": [
    "string"
  ],
  "project": [
    "string"
  ],
  "providers": [
    "string"
  ],
  "sampleMedia": [
    "string"
  ],
  "siteType": [
    "string"
  ],
  "siteid": [
    "string"
  ],
  "startDateHi": "string",
  "startDateLo": "string",
  "statecode": [
    "string"
  ],
  "subjectTaxonomicName": [
    "string"
  ],
  "within": "string",
  "zip": "string"
}
```

 
Hello,

I am the maintainer of the [tidyhydat](https://github.com/ropensci/tidyhydat/tree/master/R) package which does approximately the same thing as `dataRetrieval` but only for Canadian hydrometric data. Because rivers flow across borders, I've been thinking that it would be useful to have a function in `tidyhydat` that munges the USGS data into WSC formats and vice versa to facilitate combining the data for any cross-border hydrological analysis. A lovely side benefit for Canadian users is that our hydrometric data will then integrate seamlessly with tools like EGRET (I think).  I think the API would be two functions:

```
wsc_to_usgs()
```
and
```
usgs_to_wsc()
```
or something like that. I'm curious if you folks have ever thought about something like this and whether you see enough value in this to share these functions (assuming we can get it working properly) across the two packages (import package and re-exported functions). I plan to implement this for `tidyhydat` anyways because it is likely valuable for our purposes but before I went too far down this road, I wanted to reach out here.

what's the best way to get a human-readable list of WQP characteristicNames?
* I see `dataRetrieval::pCodeToName`, but it was updated in 2014.
* I see https://www.waterqualitydata.us/public_srsnames/?mimeType=json, which is probably the same as `pCodeToName`, is that right? It also appears to be NWIS specific, but there are characteristic names available through WQP that aren't listed here, right?
* I see https://www.waterqualitydata.us/services/codes/characteristicname?mimeType=xml, which I expect is more complete, but now I'm confused about why there are two lists - can anybody help me understand?
* is there a dataRetrieval equivalent to the services/codes/characteristicname query?