Here https://github.com/Sotera/spark-distributed-louvain-modularity/blob/72d80425e8c4614ad1eef19ce4ca46fe2eeb213d/dga-graphx/src/main/scala/com/soteradefense/dga/graphx/louvain/LouvainCore.scala#L152 you don't count vertices with negative modularities. Why so?

It's strange because it leads to different modularities for same compressed and not compressed graph. IfI am right modularities for such graphs must be equal. Or not?
Has anyone been successful in getting this to work on an EMR cluster, which is managed by YARN?  Everything is running fine locally, but I have not been able to get this to work with the cluster mode.
Command:

gradle clean dist -Pcdhversion=cdh4

Error:
Task :dga-giraph:compileJava FAILED
/home/hduser/distributed-graph-analytics/dga-giraph/src/main/java/com/soteradefense/dga/DGAYarnRunner.java:21: error: package org.apache.hadoop.yarn.conf does not exist
import org.apache.hadoop.yarn.conf.YarnConfiguration;
                                  ^
/home/hduser/distributed-graph-analytics/dga-giraph/src/main/java/com/soteradefense/dga/DGAYarnRunner.java:28: error: cannot find symbol
            UserGroupInformation.createRemoteUser(YarnConfiguration.DEFAULT_NM_NONSECURE_MODE_LOCAL_USER).doAs(new PrivilegedAction<Void>() {
                                                  ^
  symbol:   variable YarnConfiguration
  location: class DGAYarnRunner
Note: /home/hduser/distributed-graph-analytics/dga-giraph/src/main/java/com/soteradefense/dga/io/formats/DGAVertexOutputFormat.java uses unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
2 errors

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':dga-giraph:compileJava'.

Please help


in line 240 of LouvainCore.scala:   deltaQ = k_i_in - ( k_i * sigma_tot / M)
M is the total weight of the graph. My understanding is that M = 2m   (m: number of edges )
so, deltaQ may should be calculated  as  k_i_in - ( k_i * sigma_tot / (M/2))  instead? @eric-kimbrel 

hi,
i am trying to run your code in an ubuntu machine.
after compiling and packaging i tried the command louvian but i always get this error:

Error: Could not find or load main class com.soteradefense.dga.graphx.louvain.Main

what probably could be the cause and how can i fix it.

Regards
aljawarneh
After a couple of iterations the final graph to be saved is a compressed version of the original one. How can I assign communities to all the original nodes in my graph given some level.

Updated for Spark 1.2 as bundled with Cloudera 5.3.3 and fixed issue with saveAsTextFile failing to overwrite qvalues - now saving each level's qvalues separately. Also changed to allow parsing input with the third column being non-numeric (ignores). Added option to specify serialization.

In line 233 of ![This file](https://github.com/Sotera/spark-distributed-louvain-modularity/blob/master/dga-graphx/src/main/scala/com/soteradefense/dga/graphx/louvain/LouvainCore.scala#L233), when calculating k_i_in_L, the variable "internalWeight" is added if the community that the node is in and the community the node is testing is the same community. If I understand it correctly, variable "internalWeight" is the self-loop edge. If that is the case the weight of self loop should not be included in k_i_in because both ends of this edge are the same node, and therefore are always in the same community. @eric-kimbrel 
