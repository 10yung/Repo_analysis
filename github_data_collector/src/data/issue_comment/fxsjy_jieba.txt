预祝大家新春快乐，

请问jieba如何操作包含关键字的模糊匹配？如分割"北京市**办"?
感谢。
安装时报错，报错信息如下：
error: can't copy 'jieba/lac_small/model_baseline': doesn't exist or not a regular file
版本：0.41

全自动安装： easy_install jieba 或者 pip install jieba / pip3 install jieba
半自动安装：先下载 https://pypi.python.org/pypi/jieba/ ，解压后运行 python setup.py install
两种安装方式都试过了，一样的报错
[test_whoosh.py](https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py)
```
for keyword in ("水果世博园","你","first","中文","交换机","交换"):
    print("result of ",keyword)
    q = parser.parse(keyword)
    results = searcher.search(q)
    for hit in results:
        print(hit.highlights("content"))
    print("="*10)
```
其中parser.parse(keyword)，是否也可以先分词呢？
It would be nice to keep PyPI releases and git tags in sync :)
jieba.cut和jieba.lcut均支持jieba.cut，
jieba.posseg中的pseg.cut支持use_paddle，
但是pseg.lcut不支持use_paddle，是否方便统一一下，谢谢。
虽然用list(pseg.cut(sentence, use_paddle=True))也能解决问题。
当自定义词典与默认词典冲突时，目前自定义词典是无法覆盖掉默认词典的吧？比如自定义的词典中有`今天` 和`天气` 这两个词，但是发现默认的词典刚好有`今天天气`这个词，此时是无法通过自定义词典分词出`今天`和`天气`这两个词。即自定义词典并没有最高优先级，是如此的吗？来此确认下。谢谢！
Add enable_paddle  interface to enable paddle.
Use example:
import jieba
jieba.enable_paddle()
strs=[u"我来到北京清华大学",u"乒乓球拍卖完了",u"中国科学技术大学"]
for str1 in strs:
    seg_list = jieba.cut(str1,use_paddle=True)
    print(' '.join(list(seg_list)))

I get this warning every time using jieba

the imp module is deprecated in favour of importlib

It makes tests fail with warnings. Are there some workarounds?

```
============================================= warnings summary =============================================
.env/lib/python3.7/site-packages/jieba/_compat.py:4
  /Users/dc/dev/rnd/grafr/demos/spacy/.env/lib/python3.7/site-packages/jieba/_compat.py:4: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
    import imp

```

assuming it's a drop in replacement, I guess it would not be complicated to send a PR for this, but seems there are 38 PRs waiting in line ahead of me... 

![image](https://user-images.githubusercontent.com/514002/71567272-9d2f9100-2a72-11ea-8b55-367a3d23c09c.png)


当前词性标注，只支持中文吗，英文字母都会标注为eng吗？
有没有英文的词性标注接口呢？

```
import sys                                                                                 
import sys                                                                                 
reload(sys)                                                                                
sys.setdefaultencoding('utf-8')                                                            
import jieba.posseg as pseg                                                                
                                                                                            
words =pseg.cut("苹果官网iPhone降价！再次惊觉了神网友们的才华 一群同学 doc dog girl 小米 mi jidong")                                                                                                           
for w in words:                                                                            
    print w.word.encode("utf-8"), w.flag 
```

```
打印结果
苹果 n
官网 n
iPhone eng
降价 n
！ x
再次 d
惊觉 a
了 ul
神 n
网友 n
们 k
的 uj
才华 nr
  x
一群 m
同学 n
  x
doc eng
  x
dog eng
  x
girl eng
  x
小米 n
  x
mi eng
  x
jidong eng
```
如果用jieba.del_word('女装') 只会把”女装“里的“女“分出来。
那怎么把”女士“”女性“等等中的”女”都要分出来。
总不能写N个“jieba.del_word”吧？