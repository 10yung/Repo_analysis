Hi,thanks for your work. Did you ever try to put it together?  I think put it together shouldn't make it worse. But , when I use it to train lenet(dataset:mnist) , it actually  get worse result.
Hi, I found that the model trained with AMS may get higher similarity bettem a pair of abnormal enroll and probe images (the probe is low qulaity, wrong aligned, or even not a face, the enroll is not a good id photo). The similarity may be around 0.4 or even higher while the ones trained with softmax may be just around 0. So have you ever met the same problems? Is it because that the margin push the feature space much compact than softmax? 
Thanks!
Dear @happynear, first of all thanks for your work and uploaded results! I would like to ask about alignment step, is it really important to get good performance? I have not tried your code ( will do it this week ), but tried ResNet-18 with VGG2 without alignment step. SoftMax and CenterLoss gave about 90% both, CenterLoss also provided much better localization, but surprisingly ArcFace result was 70% only, I will try CosFace this week but I expect more or less the same. Did you try to train something without alignment?
Thank you! I will post my result with CosFace 
I set an image to `AMSoftmax`, which `net` prototxt is (`face_deploy_mirror_normalize.prototxt`) and weight is (`your pretrained weights`) . after loading weights I put an image to net input and run `forward()` method on it. Then I wanted to explore how the flip layer works but after plot the output of `flip_data` blobs I see something goes wrong, the flip layer has flipped data vertically(I mean up down) !! is it Okay? 
result of code:
![selection_027](https://user-images.githubusercontent.com/14973524/50560068-1be3d800-0d12-11e9-8658-28bb265d9a58.png)

The code is something like below:
```

net=caffe.Net(
        'face_deploy_mirror_normalize.prototxt',
        'face_train_test_iter_30000.caffemodel',
        caffe.TEST);

def return_layer_name(layer_name,i):
    output=net.blobs[layer_name].data[i]
    output=np.swapaxes(output,0,2)
    return output


img=caffe.io.load_image('Anthony_Hopkins_0002.jpg')
img=caffe.io.resize(img,(96,112))
img=np.expand_dims(img,0)
img=np.swapaxes(img,1,3)
net.blobs['data'].data[...]=img
net.forward()
output=net.blobs['norm1'].data[0]
out1=return_layer_name('data_input_0_split_0',0)
out2=return_layer_name('flip_data',0)
fig = plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.imshow(out1)
plt.subplot(1,2,2)
plt.imshow(out2)

```

I train my model[Webface] in parms of s=30, m=0.35. The Result in lfw is 98.53%. I try to change parms but it get worse result. Is the parms is the best in your tests?   Can data strength help me improve the effect?   thanks for your advice   
Hi, thanks for your great job. I wonder how I can debug the value of margin and scale to get better result.I use the default setting(m=0.35, scale=30)on my face recognition dataset, the final training loss  is about 3 and it can't decrease. So I come here to ask the quesion, thank you~