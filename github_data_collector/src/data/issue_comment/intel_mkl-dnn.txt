Hello
Would it be possible to have some early estimations whether DNNL will support the NNP processors (at least the Inference one) : 
https://www.intel.ai/nervana-nnp
From that page, the only supported devices today are CPU and GPU :
https://intel.github.io/mkl-dnn/dev_guide_data_types.html
Ref:
https://www.intel.ai/wp-content/themes/ai/inc/nnp-react-apps/images/interactive/nnpi/scene8B.jpg

# Summary
make test failed for several unit tests.

# Version
rls-v1.0 883133c3b97d27fc6eb976b2cea2a25252f0d911

# Environment

* CPU make and model 
Thread(s) per core:    2
Core(s) per socket:    32
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 85
Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz
* OS version (`uname -a`)
Linux iZ8vbi18phbt0xgofpsvomZ 3.10.0-327.ali2012.alios7.x86_64 #1 SMP Mon Oct 9 14:09:14 CST 2017 x86_64 x86_64 x86_64 GNU/Linux
* Compiler version (`gcc --version`)
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
* CMake version (`cmake --version`)
cmake version 3.14.3
* CMake output log
-- GPU support is disabled
-- Could NOT find Doxygen (missing: DOXYGEN_EXECUTABLE) 
-- Configuring done
-- Generating done
-- Build files have been written to: /home/jingwei.zhang/src/mkl-dnn/build_rls-v1.0
# Steps to reproduce
./tests/gtests/test_convolution_forward_u8s8fp

# Observed behavior
Note: Google Test filter = *:-*_GPU*
[==========] Running 4 tests from 1 test suite.
[----------] Global test environment set-up.
[----------] 4 tests from Forward_SimpleSmall_Blocked_Attributes_CPU/convolution_test
[ RUN      ] Forward_SimpleSmall_Blocked_Attributes_CPU/convolution_test.TestConvolution/0
Floating point exception (core dumped)
# Expected behavior
Test to pass

GDB result:
Program received signal SIGFPE, Arithmetic exception.
0x00007ffff7695483 in Xbyak::util::Cpu::getNumCores (this=0x7ffff7dcf540 <_ZN6mkldnn4impl3cpu12_GLOBAL__N_1L3cpuE>, level=Xbyak::util::CoreLevel)
    at /home/jingwei.zhang/src/mkl-dnn/src/cpu/xbyak/xbyak_util.h:253
253			case CoreLevel: return numCores_[level - 1] / numCores_[SmtLevel - 1];

=> 0x00007ffff77babc8 <+1816>:	divl   0x614bbe(%rip)        # 0x7ffff7dcf78c <_ZN6mkldnn4impl3cpu12_GLOBAL__N_1L3cpuE+12>
Greetings mkl-dnn developers and contributors,

We’re reaching out because your project is an important part of the open source ecosystem, and we’d like to invite you to integrate with our [fuzzing](https://www.owasp.org/index.php/Fuzzing) service, [OSS-Fuzz]( https://opensource.googleblog.com/2016/12/announcing-oss-fuzz-continuous-fuzzing.html ). OSS-Fuzz is a free fuzzing infrastructure you can use to identify security vulnerabilities and stability bugs in your project. OSS-Fuzz will:

- Continuously run at scale all the fuzzers you write.
- Alert you when it finds issues.
- Automatically close issues after they’ve been fixed by a commit.

Many widely used [open source projects]( https://github.com/google/oss-fuzz/tree/master/projects ) like OpenSSL, FFmpeg, LibreOffice, and ImageMagick are fuzzing via OSS-Fuzz, which helps them find and remediate [critical issues]( https://bugs.chromium.org/p/oss-fuzz/issues/list?can=1&q=status%3AFixed%2CVerified+Type%3ABug%2CBug-Security+-component%3AInfra+ ). 

Even though typical integrations can be done in < 100 LoC, we have a [reward program]( https://www.google.com/about/appsecurity/patch-rewards/ ) in place which aims to recognize folks who are not just contributing to open source, but are also working hard to make it more secure.

We want to stress that anyone who meets the eligibility criteria and integrates a project with OSS-Fuzz is eligible for a reward.

If you're not interested in integrating with OSS-Fuzz, it would be helpful for us to understand why—lack of interest, lack of time, or something else—so we can better support projects like yours in the future.

If we’ve missed your question in our [FAQ]( https://google.github.io/oss-fuzz/faq/ ), feel free to reply or reach out to us at oss-fuzz-outreach@googlegroups.com.


Thanks!

Tommy
OSS-Fuzz Team

# Summary
`SIMPLE_IMPL` preprocessor define in `cpu_reducer.cpp` seems fragile.

# Problem statement
`create_reduce_2d_drv` may return `nullptr` (if not mayiuse avx2 or better).
However a preprocessor define is used to select jit vs non-jit code path, which
allows the possibility of creating a jit impl and then not using it,
or (**worse**) not creating a jit impl, and calling via `nullptr`.
This affects the `reduce_nolock` and `reduce_block` methods.

# Preferred solution
Make `reduce_nolock` and `reduce_block` generic by replacing `#ifdef SIMPLE_IMPL` with
```
if(drv_) {
  /* existing code to call jit driver */;
} else {
  /* existing SIMPLE_IMPL code block*/;
}
```

Now `create_reduce_2d_drv` can independently decide whether to return `nullptr`
(separation of concerns, generic code, fewer ugly \#if blocks)

[opt.] If you wish to retain SIMPLE_IMPL for test compilations, just use it once, to force `create_reduce_2d_drv` to return `nullptr`. (I do something like this for non-xbyak compiles).

I am using the mkldnn v0.21. I find that  function mkldnn_deconvolution_forward_desc_init()  judge the param format must  be oihw, if my param is iohw format, should I must reorder the parma from iohw to oihw before the mkldnn_deconvolution_forward_desc_init function, Is there any else i can do, Is there any demo I can reference.
<del>

```
./benchdnn --matmul --stag=ab --wtag=ab --mode=p m16n1040k1040
total perf: min(ms):0.0354004 avg(ms):0.046758

./benchdnn --matmul --stag=ab --wtag=ba --mode=p m16n1040k1040
total perf: min(ms):0.110352 avg(ms):0.129114
```

</del>
# Summary 
Several of the files have header leaks (usage of functions without properly referencing/including at all or including the right header but not the path to the files)

Example : 
`/mkldnn/src/cpu/gemm/gemm_threading.hpp` is missing the  [`#include <assert.h>`](https://github.com/intel/mkl-dnn/blob/ed1cf723ee94cf95b77af55fe1309374363b8edd/src/cpu/gemm/gemm_threading.hpp#L17-L23)while using [`assert()`](https://github.com/intel/mkl-dnn/blob/ed1cf723ee94cf95b77af55fe1309374363b8edd/src/cpu/gemm/gemm_threading.hpp#L92).  

# Version
master

# Environment
Ubuntu 18.04
gcc7 
g++7
Intel Core i7-4790K 

# Steps to reproduce
Build from source without using specific flags

# Observed behavior
Build fails ... this also affects mxnet building from source [mxnet#17238](https://github.com/apache/incubator-mxnet/issues/17238)

# Expected behavior
Successful build
As described in README, libmkldnn.so depends on libgomp.so when compiled with GCC, and depends on libiomp5.so when compiled with Intel C/C++ Compiler.

Runtime configuration | Compiler | Dependency
-- | -- | --
DNNL_CPU_RUNTIME=OMP | GCC | GNU OpenMP runtime (libgomp.so)
DNNL_CPU_RUNTIME=OMP | Intel C/C++ Compiler | Intel OpenMP runtime (libiomp5.so)
DNNL_CPU_RUNTIME=OMP | Clang | Intel OpenMP runtime (libiomp5.so)
DNNL_CPU_RUNTIME=TBB | any | Threading Building Blocks (libtbb.so)
DNNL_GPU_RUNTIME=OCL | any | OpenCL runtime (libOpenCL.so)

But  libgomp.so is compiled with `STATIC_TLS` and libiomp5.so is not. So it will encounter 

> ImportError：dlopen：cannot load any more object with static TLS
when  using several DSOs with `STATIC_TLS`.

So, I wonder if there is any way to make libmkldnn.so depend on  libiomp5.so when compiled with GCC?

In addition, as far as I know, in commit aef88b, libmkldnn.so uses libiomp5.so if provided.

# Summary
Provide a short summary of the issue. Sections below provide guidance on what
factors are considered important to reproduce an issue.
primitive create and forward in different thread may lead to core dump

the error information
mkldnn/mkldnn/common/memory_tracking.hpp:240: void* mkldnn::impl::memory_tracking::registry_t::get(const key_t&, void*) const: Assertion `size() == 0' failed.

# Version
Report DNNL version and githash. Version information is printed to stdout
in [verbose mode](http://intel.github.io/mkl-dnn/dev_guide_verbose.html).
0.21.0
# Environment
DNNL includes hardware-specific optimizations and may behave
differently on depending on the compiler and build environment. Include
the following information to help reproduce the issue:
* CPU make and model (try `lscpu`; if your `lscpu` does not list CPU flags,
  try running `cat /proc/cpuinfo | grep flags | sort -u`)
intel xeon CPU E5-2630 V4 @2.2GHz
* OS version (`uname -a`)
Linux sdw2 2.6.32-696.16.1.el6.x86_64 #1 SMP Wed Nov 15 16:51:15 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
* Compiler version (`gcc --version`)
gcc version 8.2.0 (GCC) 
* CMake version (`cmake --version`)

cmake version 3.5.0-rc3
* CMake output log
* git hash (`git log -1 --format=%H`)

# Steps to reproduce
Please check that the issue is reproducible with the latest revision on
master. Include all the steps to reproduce the issue. 

You can use [verbose mode](http://intel.github.io/mkl-dnn/dev_guide_verbose.html)
and [benchdnn](https://github.com/intel/mkl-dnn/tree/master/tests/benchdnn)
to validate correctness of all primitives the library supports. If this does not
work a short C/C++ program or modified unit tests demonstrating the issue
will greatly help with the investigation.

# Observed behavior
Document behavior you observe. For performance defects, like performance
regressions or a function being slow, provide a log including output generated
by your application in
[verbose mode](http://intel.github.io/mkl-dnn/dev_guide_verbose.html). 

# Expected behavior
Document behavior you expect.
how to solve this problem
A while ago I was using the binary multiplication primitive using broadcasting for implementing a
channelwise multiplication. Just multiply two tensors  (N, C, H, W) * (N, C, 1, 1) in the same optimized blocked format. It still works as it used to work only the performance is now very very bad. So Source0 is the tensor (N,C,HW) in nChw8c format and Source1 is a tensor (N, C, 1, 1) also in nChw8c format wich should be broadcasted and multiplied together. I never changed my code and it used to be very fast. For some weird reason it is now the most time consuming primtive in the whole network. Very weird.

thanks

DNNL:
latest master build: 

Environment:
cpu: AMD 3900X
os: Windows 10 18363
compiler: Visual Studio 2019
cmake: 3.16.1

~~~
dnnl_verbose,info,DNNL v1.1.0 (commit 144f241bd3ba474afc9a495d9d312d8f5ed5ddfe)
dnnl_verbose,info,Detected ISA is Intel AVX2
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb8a:f0,,,64x3x3x3,0,4692
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb8a:f0,,,64x3x3x3,11,142
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:abcd:f0 src_f32::blocked:abcd:f0 dst_f32::blocked:abcd:f0,,alg:binary_add,128x3x32x32:128x3x32x32 128x3x32x32,25,5485
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x64x1x1,0,3945
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x64x1x1,0,4079
...
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x64x32x32:128x64x32x32 128x64x32x32,0,1988
nl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1672
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,forward_training,data_f32::blocked:aBcd8b:f0 diff_undef::undef::f0,,flags:,mb128ic256ih8iw8,0,4292
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,flags:,mb128ic256ih8iw8,0,3418
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1473
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1672
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1538
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1893
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,1726
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,055
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,142
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,3857
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,0148
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1426
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,2201
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,0173
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1484
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,4141
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,0244
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1448
dnnl_verbose,create,cpu,concat,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,axis:1,128x384x8x8:128x384x8x8:128x384x8x8:128x384x8x8 128x1536x8x8,0,018
dnnl_verbose,create,cpu,pooling,jit:avx,forward_training,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1338
dnnl_verbose,create,cpu,pooling,jit:avx,backward_data,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1371
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1209
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1443
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1674
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x1x1:128x1536x1x1 128x1536x1x1,0,1957
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,1958
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,1369
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x1x1:128x384x1x1 128x384x1x1,0,755
dnnl_verbose,create,cpu,binary,ref:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_mul,128x1536x8x8:128x1536x1x1 128x1536x8x8,0,0088
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1768
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1659
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1651
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,forward_training,data_f32::blocked:aBcd8b:f0 diff_undef::undef::f0,,flags:,mb128ic256ih8iw8,0,4304
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,flags:,mb128ic256ih8iw8,0,3435
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1493
dnnl_verbose,create,cpu,sum,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,,128x256x8x8,0,0145
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1608
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1471
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1676
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,1763
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,0552
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1491
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,3854
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,0149
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1389
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,2138
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,0176
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1558
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,4173
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,0183
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1356
dnnl_verbose,create,cpu,concat,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,axis:1,128x384x8x8:128x384x8x8:128x384x8x8:128x384x8x8 128x1536x8x8,0,0189
dnnl_verbose,create,cpu,pooling,jit:avx,forward_training,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1329
dnnl_verbose,create,cpu,pooling,jit:avx,backward_data,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1338
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1174
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1419
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1632
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x1x1:128x1536x1x1 128x1536x1x1,0,1948
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,2006
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,1356
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x1x1:128x384x1x1 128x384x1x1,0,2075
dnnl_verbose,create,cpu,binary,ref:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_mul,128x1536x8x8:128x1536x1x1 128x1536x8x8,0,00870001
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1797
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1788
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1711
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,forward_training,data_f32::blocked:aBcd8b:f0 diff_undef::undef::f0,,flags:,mb128ic256ih8iw8,0,4283
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,flags:,mb128ic256ih8iw8,0,3406
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1528
dnnl_verbose,create,cpu,sum,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,,128x256x8x8,0,0141
dnnl_verbose,create,cpu,reorder,simple:any,undef,src_f32::blocked:abcd:f0 dst_f32:p:blocked:ABcd8b8a:f0,,,10x256x1x1,0,0339
dnnl_verbose,exec,cpu,reorder,simple:any,undef,src_f32::blocked:abcd:f0 dst_f32:p:blocked:ABcd8b8a:f0,,,10x256x1x1,0,5078
~~~

(edited by @rsdubtso for formatting)