Hi @tomnomnom, thanks for the great tool. It was a great help to me on multiple occasions.

I just wanted to let you know that I've started the process of packaging gron for Fedora. It [is already accepted for the next release](https://src.fedoraproject.org/rpms/gron) and I'm hoping to get it in the current release in the next days. Once it's in, users will be able to just `dnf install gron`.

Let me know if you have any questions. If not, feel free to simply close this issue. Thanks, again, for creating gron.
Hello. I have a minor feature suggestion.

I'd like to have a `-v/--var` option that sets the name of the root output variable:
```
echo '[1,2]' | gron -v 'a'
a = [];
a[0] = 1;
a[1] = 2;
```

My use case is replacing a nested leaf with content from another json file,
so in this case I'd have a complicated var like 'json[0].key1' and replace the input line with multiple output lines.

(I can imagine just putting a compact single line chunk of json as a value, but that isn't permitted either currently.  There may also be other ways to tackle this problem)

Here's a more complicated example:
```
$ head input.json a.json b.json
==> input.json <==
[ { "key1": "a", "key2": 123}, { "key1": "b", "key2": 345} ]

==> a.json <==
{ "id": "a", "value": [1,2] }

==> b.json <==
{ "id": "b", "value": [3,4] }
```

Here's a pipeline that greps the "key1" lines and replaces them with the content from another file:
```
$ gron input.json | perl -ple 'if(/^(.*key1) = "(.*?)";$/) { $_ = `gron $2.json | sed "s/^json/$1/"`; chomp }' | gron -u | jq -c
[{"key1":{"id":"a","value":[1,2]},"key2":123},{"key1":{"id":"b","value":[3,4]},"key2":345}]
```

With this suggestion it the sed could be dropped:
```
gron input.json | perl -ple 'if(/^(.*key1) = "(.*?)";$/) { $_ = `gron -v $1 $2.json`; chomp }' | gron -u
```

Thank you
Implicitly depends on #66.  Feel free to comment on that one if you want me to make changes to it, or this one; whichever.
This is mostly to allow another upcoming PR (to allow least fuzzing gron.)  I would also modify the API a bunch but am not sure if that's helpful to anyone, at least yet.  I *would* suggest a struct based api (rather than flag based) if at some point this package becomes public, but while it's internal it's a moot point.
I recently got a multi-gigabyte [JSONL](http://jsonlines.org/) file, and before committing to a downstream pipeline that would run for many minutes before producing output, I ran:

```console
$ head -20 entries.jsonl | gron
```
and discovered that gron only interpreted the first line. So I ran:
```console
$ head -20 entries.jsonl | jq -s '.'  > 20entries.json
```

and used this temporary file as my test data.

It was only after this that I noticed the `-s` option which I had probably read in `--help` when I first tried gron but had since forgotten. This works equally as well:

```console
$ head -20 entries.jsonl | gron -s
```

I wonder if JSONL couldn’t be autodetected? At a minimum, if a filename is given and it ends with the suffix `.jsonl`, it should be possible to turn on stream mode. Perhaps if there’s a pattern matching `/[\/=&?]jsonl\b/` in a URL, too. 

Besides suffix matching, I don’t know whether it’s realistic to switch to stream mode if the first JSON object terminates, and there’s still a newline and another JSON object remaining in the input.

If this suggestion were implemented, a `--no-stream` option would need to be added in case somebody decided to name their files _xxx.jsona_, _xxx.jsonb_, _xxx.jsonc_, ... _xxx.jsonl_ for some pathological reason, or if autodetection of streams is done by analyzing the input text.
It would be nice to have `gron` available as a library in order to use it directly in other go projects without using the command line tool.
According to the `gron` documentation, "To preserve array keys, arrays are padded with null when values are missing".  For example, using the test data in the Git repo:

```
$ gron testdata/one.json | fgrep -w 'fum' | gron --ungron
{
  "five": {
    "alpha": [
       null,
       "fum"
    ]
  }
}
```

Would it be possible to add a command line option to exclude that artificial `null`, for example:

```
$ gron testdata/one.json | fgrep -w 'fum' | gron --ungron --nonull
{
  "five": {
    "alpha": [
       "fum"
    ]
  }
}
```

Thanks!

I have a deeply nested directory of archived JSON responses that I would like to analyze (extract fields from each of the response files)

`find -exec gron` would probably work, but the hierarchy holds important context so I'd want to have the file path included in the output.

I'm thinking something like `grep -r`

Using gron (even with --no-sort) on a ~180MB file (generated [here](https://www.json-generator.com/)) results in high mem utilization/cpu load and hanging.
hi @tomnomnom ,
there is an other set of tools (https://salsa.debian.org/debian/xml2) which makes similar transformation on html, xml, and on csv files as gron performs on json.
i've read you have been suggested other names, still i encourage you to consider renaming or at least make an alias to eg. `json2`.
cheers.
