1. "AGKMatrix.h"
```
- (NSNumber *)defaultMember {
	if (!_defaultMember) { // **Converting a pointer value of type 'NSNumber *' to a primitive boolean value; instead, either compare the pointer to nil or call -boolValue**
		_defaultMember = @0; 
	}
	
	return [_defaultMember copy];
}

- (void)resetMatrixToDefault:(NSNumber *)defaultValue {
    if (defaultValue) { // **Converting a pointer value of type 'NSNumber *' to a primitive boolean value; instead, either compare the pointer to nil or call -boolValue**
        self.defaultMember = defaultValue;
    }
	self.members = nil;
}

- (NSArray *)allMembers {
    NSMutableArray *allMembers = [NSMutableArray arrayWithCapacity:self.count];
    for (NSUInteger index = 0; index < self.count; index++) {
        [allMembers addObject:self[index]]; // **Argument to 'NSMutableArray' method 'addObject:' cannot be nil**
    }
    
    return allMembers;
}
```
2. "UIImage+AGKQuad.h"

```
- (UIImage *)imageByCroppingToRect:(CGRect)rect
{
    CGImageRef croppedImage = CGImageCreateWithImageInRect([self CGImage], rect);
    return [UIImage imageWithCGImage:croppedImage scale:self.scale orientation:self.imageOrientation]; // **Potential leak of an object stored into 'croppedImage'**
}
```


UIImage+AGKQuad.m
Line 53:
- (UIImage *)imageByCroppingToRect:(CGRect)rect

croppedImage is not released.
In your demo video you show an image with 4 corners being dragged and morphed. 
Is it possible to have more than one drag point to transform the view ? also is it possible to load a video inside instead of an image ?

I noticed an issue with UIImage scale and "imageWithPerspectiveCorrectionFromQuad". If I pass an image with scale factor 3.0f (iPhone6 Plus) it crops only portion of an image. As far as I traced the rects it appears to act weird here:

(Line 164:) UIImage *correctedImage = [self imageWithTransform:transform anchorPoint:CGPointZero];
(Line 165:) UIImage *resultImage = [correctedImage imageByCroppingToRect:destinationRect];

Here, imageWithTransform returns an image with scale 1.0f (so its size in points = size in pixels) and destinationRect is still in points. So the result image is 1/3 upper part of the source image.

Of course, you can always transform your @3x image into @1x by drawing it to image context with scale 1.0 and triple source size. However in situation where you're really low on available memory this could be a hussle. 

As of today we are just using [nearest neighbor](http://gis.stackexchange.com/questions/20353/how-does-nearest-neighbor-image-resampling-work-in-arcgis) algorithm. This looks really bad both when downsampling and upscaling. 

Creating an alternative version of AGKTransformPixelMapper using some more sophisticated algorithm would be awesome. [Here's some code](https://code.google.com/a/eclipselabs.org/p/bicubic-interpolation-image-processing/source/browse/trunk/libimage.c) hosted on google which does bicubic interpolation. 
