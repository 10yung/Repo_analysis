Currently the DIB-R only returns the differentiable color and mask, I wonder how to get depth from it?
Signed-off-by: Zheng Qin <clavichord93@hotmail.com>

Currently, `three_interpolate_grad` calls `three_interpolate_kernel_launcher`, which is a bug. This PR fixes this problem by calling `three_interpolate_grad_kernel_launcher` instead.

This PR is duplicated with #106 but is signed. Please close the old one.
As a proof of concept, I rendered an object in blender, and re-used the same object position and camera parameters to render an image in Blender. I tried to regress a texture in both Lambertian and VertexColor modes directly (without any networks). 

It seems like in VertexColor mode, the colors are jumping in large steps, and in the Lambertian mode, there are stuck pixels despite perfect object alignment. This is slightly concerning, as an experiment using neural mesh, the colors change very smoothly. 

GIFs of the optimization using DIB-R:
https://imgur.com/a/xfevKGO

@SteveJunGao @TommyX12 @wenzhengchen is this the correct behavior?
Signed-off-by: Avik Pal <avikpal@iitk.ac.in>
Does the present version of Kaolin works on a non GPU based Linux System?

If not is it planned to be supported?
I tried to run kal.visualize.show() on the server but it seems not working.
So is there an alternative way like saving the rendered images?

https://github.com/NVIDIAGameWorks/kaolin/blob/6d22f6c9cd399322df7c287dcf62c8ede1266975/kaolin/visualize/vis.py#L55

this should be inp.voxels
Hi, 

I can't find your Atlasnet implementation. Could you point me to it ?

Thanks!
Lucas
The default pytorch collate function cannot deal with pathlib objects. For this reason, substituted them with their string representations in the output dicts.