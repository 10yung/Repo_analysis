### Description
utils_nlp.models.bert is outdated and not supported anymore.
- remove/update related tests
- remove utils
- update examples


### Other Comments

### Description
Biweekly release.


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the code style of this project, as detailed in our [contribution guidelines](../CONTRIBUTING.md).
- [x] I have added tests.
- [x] I have updated the documentation accordingly.




### Description
The test machine runs out of space as pipeline data builds up.

https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/delete-files?view=azure-devops


### Other Comments

### Description
<!--- Describe your expected feature in detail -->
The code and [yaml file](https://github.com/microsoft/nlp-recipes/blob/master/tests/ci/azureml_integration_tests.yml) for the tests are available in the repo. 
To test the tests, create AML subscription and workspace first, then execute the pipeline. 

### Expected behavior with the suggested feature
<!--- For example:  -->
<!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->


### Other Comments

### Description
My machine has 8 GPUs, and I wanted to split them into two training jobs. Is it possible? I found the parameter to specify how many GPUs to use, but not their IDs. Therefore, each job competes to use the GPU with the ID 0, 1, 2, instead of the ones that are idle. Please advise.

### Other Comments

### Description
I am following "Text Classification of MultiNLI Sentences using BERT" to train a binary classifier on my data. One thing special about my data is that the training labels are noisy. Following the [paper ](https://arxiv.org/pdf/1812.00417v2.pdf) on weak supervision training, one solution is to use "noise-aware" loss function. I think it could be realized by allowing a "weight" to each training sample so that each sample is weighted differently when computing loss. But I didn't find anyway in the code to add this ability. Note that this is different from allowing weights on each label class as in [CrossEntropyLoss ](https://pytorch.org/docs/stable/nn.html#crossentropyloss)


### Other Comments

### Description

Changed the order of moving a model to a device and constructing the optimizer.
ref: https://pytorch.org/docs/master/optim.html

### Related Issues
#512 #532 


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the code style of this project, as detailed in our [contribution guidelines](../CONTRIBUTING.md).
- [x] I have added tests.
- [ ] I have updated the documentation accordingly.




### Description
The contents of two notebooks under *sentiment_analysis/absa*, **absa.ipynb** and **absa_azureml.ipynb** are the same.

### Expected behavior (i.e. solution)
No duplication

### Other Comments

### Description
<!--- Describe your bug in detail -->
pip installing utils_nlp brings none of the dependencies. After installation I ran into a dask issue, then a toolz issue related to needing dask[dataframe]

And after the toolz issue I ran into unknown module transformers

setup.py should include dependencies.

dask[dataframe]
transformers<=2.1.1  There is a bug with the repo when tranformers is above that version number

### How do we replicate the bug?
pip install the repository without installing the requirements. 
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for gpu -->
<!--- * Run unit test `test_timer.py` -->
<!--- * ... -->


### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for the timer should pass successfully. -->


### Other Comments
This behavior can be avoided with some of the requirements being listed in setup.py, system specific requirements can be omitted but the above requirements are not system specific and fail most code paths.
### Description
<!--- Describe your expected feature in detail -->


### Expected behavior with the suggested feature
<!--- For example:  -->
<!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->


### Other Comments
