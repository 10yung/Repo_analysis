Fixing infinite loop in tokens_to_root function
Hello,

Using the code from https://github.com/explosion/spacy-notebooks/blob/master/notebooks/conference_notebooks/modern_nlp_in_python.ipynb (I think, it is not loading right now)

I was attempting to run the tutorial on my own collection of documents with the following three functions:
```

def punct_space(token):
    """
    helper function to eliminate tokens
    that are pure punctuation or whitespace
    """
    
    return token.is_punct or token.is_space

def line_review(filename):
    """
    generator function to read in reviews from the file
    and un-escape the original line breaks in the text
    """
    
    with open(filename) as f:
        for review in f:
            yield review.replace('\\n', '\n')
            
def lemmatized_sentence_corpus(filename):
    """
    generator function to use spaCy to parse reviews,
    lemmatize the text, and yield sentences
    """
    
    for parsed_review in nlp.pipe(line_review(filename),
                                  batch_size=100, n_threads=2):
        
        for sent in parsed_review.sents:
            yield u' '.join([token.lemma_ for token in sent
                             if not punct_space(token)])

```
Called with the following:

```
%%time
with open(r'C:/users/User/Downloads/unigram_sentences_all.txt', 'w') as f:
    for sentence in lemmatized_sentence_corpus('C:/users/User/Downloads/all_bills.txt'):
        f.write(sentence + '\n')

```
Which leads to a kernel crash in Jupyter.  I have tried several different configs of batch size and threads, all leading to kernel crashes.

spacy.__version__ == 2.0.11
Windows 10
Python = 3.5.5

calling the above cell rapidly leads to 100% CPU usage and 12GB memory usage.

I will admit, my 'all_bills.txt' is a little unusual. 250 or so lines, average document length ~60k characters.

What other information can I provide that may be useful?

Edit 1:
judging from https://github.com/explosion/spaCy/issues/1476 I imagine it has something to do with document length? That issue didn't get 'resolved' exactly so it is hard to judge. 
Hello,

I have created a new notebook called features.ipynb of code taken from [linguistic features](https://spacy.io/usage/linguistic-features).

I have also update the lightning_tour.ipynb to the one on the website. However, about half of the examples are slow or do not work. I am submitting a pull request for lightning_tour.ipynb to see if y'all can figure out what is going wrong.

I have also created a new folder called examples. The only example that does not work in the training folder is ner_multitask_objective.ipynb. The error message is at the top of the notebook. 

Since all the already existing spaCy notebook examples are picked up, a nice next step would be to make notebooks out of the [examples](https://github.com/explosion/spaCy/tree/master/examples) . 

Applying some of these on small datasets would also be a nice way to show them off.

Edit: Noticed this is already mentioned in the readme. :) Still leaving it here so contributors have a direction to go in!