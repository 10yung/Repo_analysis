Can't stop infinite streaming. It shows modal window with message "No streaming session found". 
Have tried to clear all site data, cache, cookie, used incognito tab, different browsers, nothing helped. Any ideas how to solve this issue?

![image](https://user-images.githubusercontent.com/23012536/57357145-527ba480-7183-11e9-9015-26ab7fba86c8.png)
![image (1)](https://user-images.githubusercontent.com/23012536/57357131-4c85c380-7183-11e9-868a-70cb1042264d.png)

Hello,

I needed to build a debian package for Trifecta UI so I modified the build script.

I would be glad if you merged it so I could plug my CI on your repo instead of my fork. 

Thanks

Julien
Kafka 2.0.0 has been released. Can you support it?
It would be great to be able to provide custom decoders which should implement some interface and put as a jar in a plugin derectory.

What i really want is google protobuffers support, but I guess ability to support anything through plugins is much better for everyone.
Hi,

I am not scala developer and use only UI.

How export messages from the topic to any format to process in one go?

I'm using https://github.com/janschultecom/docker-trifecta.
Hi,

I am not scala developer and use only UI.

I go to debug topics, and click "Find a message". 
When I select the topic, whatever I will write in Criteria field - I always get a big pile of CSS  on page and 404 in the console.

Is this a bug?
What should I write to field "Criteria"?
The message count ignores offset 0, leading to 1 less per partition and in total p less, where p is the number of partitions.

E.g. if you publish 100K messages to a single topic with 2 partitions, a possible result will be:

99,998 total messages
* In partition 0: offsets between 0 and 50264 with total of 50,264 messages
* In partition 1: offsets between 0 and 49734 with total of 49,734 messages

Whereas expected result should be:

100,000 total messages
* In partition 0: offsets between 0 and 50264 with total of 50,265 messages
* In partition 1: offsets between 0 and 49734 with total of 49,735 messages

I found this issue in the following UI sections:
* Inspect-->Leaders
* Inspect-->Replicas
* Observe-->Message Topics
* Observe-->Topic Offsets
Trifecta v0.22.0rc8b (0.9.0.1)

It would be nice to be able to query by partition and offset (the auto generated fields added to each query row) in KQL. As I understand, currently if you specify these fields in the query, it searches for the fields with such name in the message.
Trifecta v0.22.0rc8b (0.9.0.1)

I have a partition  with plain text messages (created with apache kafka own test command line producers). I can see them fine one by one in Observe tab.

However, if I try to run KQL on the topic, I get various decoding error messages for each row, for example:

select * from test1
Malformed JSON message

select * from test1 with text
Incompatible decoder type com.github.ldaniels528.trifecta.messages.codec.MessageCodecFactory$PlainTextCodec$


Hi,
I'm getting the below error on the Trifecta UI:
           no content to map due to end-of-input at source line 1 column 1

What I've done:
 1> Pasted the **value.avsc** in the path -> .trifects/decoders/value  (where "value" is my topic)
 2> Started the Trifecta UI
 3> When I navigated to "Observer" tab, I see an error (just an red flash message) telling me - _no 
       content to map due to end-of-input at source line 1 column 1_
 4> Then I've clicked on the topic "value" and seeing that my entire message is being displayed as 
       "null" (before pasting the **value.avsc**, at least I can see the  entire message in a messy format)
 
Please let me know if I'm missing anything?

And I do not the see the way that we can query the topic by using the "_key_". Like I've _key_ and _value_ in my "_value_" topic. And I've two schemas for both of them. How can I place both the schemas in the decoder subfolder?

Thanks!