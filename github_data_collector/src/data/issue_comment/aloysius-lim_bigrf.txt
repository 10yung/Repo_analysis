When I tried to created second tree, I get following error: 

> forest2 <- bigrfc(x[1:60, ], y[1:60], ntree=50L, varselect=vars)
Error in filebacked.big.matrix(nrow = nrow, ncol = ncol, type = type,  :
  Backing file already exists! Either remove or specify
             different backing file

What is backing file? 
I used the following code to install bigrf:
url <- "https://cran.r-project.org/src/contrib/Archive/bigrf/bigrf_0.1-11.tar.gz"
pkgFile <- "bigrf_0.1-11.tar.gz"
download.file(url = url, destfile = pkgFile)
# Install dependencies

install.packages(c("bigmemory"))
# Install package

install.packages(pkgs=pkgFile, type="source", repos=NULL)
# Delete package tarball

unlink(pkgFile)

require(bigrf)

**example code***
# Load data.

data(Cars93, package="MASS")
x <- Cars93
y <- Cars93$Type
# Select variables with which to train model.

vars <- c(4:22)
# Run model, grow 50 trees on the first 60 examples.

forest1 <- bigrfc(x[1:60, ], y[1:60], ntree=50L, varselect=vars)

**Error in { : 
  task 1 failed - ""CGetType" not available for .Call() for package "bigmemory""**

Can anyone help to give some hints?

Thanks so much!

Changbin

I've had a persistent bug when using `predict` on a  `bigrf` model inside of RStudio. Essentially, there seems to be a memory leak which leads to RStudio sucking up all of my machine's RAM and forcing me to shutdown my computer. Curiously this does not happen when I run my script from the command line using `Rscript`.  

The restriction that y is an r vector hurts the big application of this package. If I'm working with over 45 million observations, then the y vector of only 0s and 1s take up about 180 mb vs. practically nothing under bigmemory object.
