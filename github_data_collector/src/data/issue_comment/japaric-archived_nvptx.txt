Compiling the kernels in the `examples` directory using 

```
xargo rustc \
    --manifest-path kernel/Cargo.toml \
    --release \
    --target nvptx64-nvidia-cuda \
    -- --emit=asm
```

I get the following error during the compilation of `core64`:

```
error[E0225]: only Send/Sync traits can be used as additional traits in a trait object
   --> C:\Users\Reiner\.cargo\git\checkouts\core64-98c99607e3b29655\0e29675\any.rs:133:27
    |
133 | impl fmt::Debug for Any + Send {
    |                           ^^^^ non-Send/Sync additional trait

error[E0225]: only Send/Sync traits can be used as additional traits in a trait object
   --> C:\Users\Reiner\.cargo\git\checkouts\core64-98c99607e3b29655\0e29675\any.rs:244:10
    |
244 | impl Any+Send {
    |          ^^^^ non-Send/Sync additional trait

error: aborting due to 2 previous errors
```

Any Idea what I am doing wrong?


I would wait till the next stdsimd release but at least with its master branch it is already possible to build `nvptx` on top of it.
```
╭ ➜ kimockb@gator3:~/kernel
╰ ➤ cat Xargo.toml 
[dependencies.core]
git = "https://github.com/japaric/core64"
╭ ➜ kimockb@gator3:~/kernel
╰ ➤ xargo rustc --target nvptx64-nvidia-cuda -- --emit=asm
   Compiling kernel v0.1.0 (file:///home/kimockb/kernel)
'bdver1' is not a recognized processor for this target (ignoring processor)
'bdver1' is not a recognized processor for this target (ignoring processor)
'bdver1' is not a recognized processor for this target (ignoring processor)
'bdver1' is not a recognized processor for this target (ignoring processor)
'bdver1' is not a recognized processor for this target (ignoring processor)
'bdver1' is not a recognized processor for this target (ignoring processor)
error[E0463]: can't find crate for `core`
  |
  = note: the `nvptx64-nvidia-cuda` target may not be installed

error: aborting due to previous error

error: Could not compile `kernel`.
```

What am I doing wrong here? It almost seems like xargo isn't picking up the crate URL
Open issues, etc. +
Currently the alpha channel from the input is not used anywhere, but it's still sent to the GPU. We could either discard the alpha when the input is loaded, or actually use the alpha channel and output a grayscale image with alpha.
The conversion on the CPU is single-threaded, making the comparison unfair. This isn't mentioned in the output of the example, nor in its section in the readme.
I noticed that you're manually calling wrapping_* for arithmetic operations in the PTX kernels. Shouldn't overflow wrap around already?

Note that I also noticed that it appears the intrinsics use signed for these variables (for which overflow would be undefined in C, although defined as wraparound in RFC 560 for Rust) but are defined as using unsigned (defined as wraparound in both C and Rust) in the CUDA programming manual. I filed a ticket in that library about this.

https://github.com/nox/rust-rfcs/blob/master/text/0560-integer-overflow.md
https://github.com/japaric/nvptx-builtins/issues/1

Feel free to close the ticket if it isn't relevant - I don't typically do GPGPU programming and this was the easiest way for me to provide feedback.