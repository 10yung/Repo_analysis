I'm having trouble running py-spy inside a venv on Windows 10 x64 1909, Python 3.8.1. It errors out with `Error: Failed to find python version from target process`. Admin privileges don't help. I presume the `python.exe` inside `venv\Scripts` is not what py-spy expects, so I copied over the actual EXE and DLL from the global Python38 folder. Profiling then works, but runs extremely slowly with considerable sampling lag.

Is this a known unsupported use-case?
Another argument to stop using `/usr/bin/python` that I think is useful to point out to users.
Using py-spy 0.3.2 release binary either musl or gnu panics with the following panic backtrace when adding the `--native` flag to either `dump` or `record` a PID running in a different container. Without `--native` works fine.

## Works

* `./py-spy dump --pid=(OTHER CONTAINER)` (correctly shows Python stacks)
* `./py-spy dump --pid=(SAME CONTAINER) --native` (correctly shows Python + native code stacks)
* `gdb attach (OTHER CONTAINER)` (shows 

## Crash

```
# RUST_BACKTRACE=full ./t/py-spy dump --pid=3511964 --native
Process 3511964: /venv2/bin/python2.7 -m staticbatch.worker --topic-name=gke-email-shadow-test --max-pull-messages=10 --max-workers=10 --sendgrid-sandbox-mode=true --use-datadog-client=true --use-recipe-rules-client=true --use-product-service=true --disable-mtbe=true
Python v2.7.16 (/venv2/bin/python2.7)

thread 'main' panicked at 'called `Option::unwrap()` on a `None` value', src/libcore/option.rs:378:21
stack backtrace:
   0:     0x555c589efa74 - backtrace::backtrace::libunwind::trace::h65597d255cb1398b
                               at /cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.3.40/src/backtrace/libunwind.rs:88
   1:     0x555c589efa74 - backtrace::backtrace::trace_unsynchronized::hd4f479d7150ec4a0
                               at /cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.3.40/src/backtrace/mod.rs:66
   2:     0x555c589efa74 - std::sys_common::backtrace::_print_fmt::h015072984a2b172c
                               at src/libstd/sys_common/backtrace.rs:77
   3:     0x555c589efa74 - <std::sys_common::backtrace::_print::DisplayBacktrace as core::fmt::Display>::fmt::h6df05d3335f32194
                               at src/libstd/sys_common/backtrace.rs:61
   4:     0x555c58a15f6c - core::fmt::write::h1f444f4312eb6c27
                               at src/libcore/fmt/mod.rs:1028
   5:     0x555c589ece97 - std::io::Write::write_fmt::h8d147888220078ef
                               at src/libstd/io/mod.rs:1412
   6:     0x555c589f1fee - std::sys_common::backtrace::_print::h8a6df0fa81d6af62
                               at src/libstd/sys_common/backtrace.rs:65
   7:     0x555c589f1fee - std::sys_common::backtrace::print::h6f05b4733407e509
                               at src/libstd/sys_common/backtrace.rs:50
   8:     0x555c589f1fee - std::panicking::default_hook::{{closure}}::h0d0a23bd02315dd8
                               at src/libstd/panicking.rs:188
   9:     0x555c589f1ce1 - std::panicking::default_hook::h8d15a9aecb4efac6
                               at src/libstd/panicking.rs:205
  10:     0x555c589f26eb - std::panicking::rust_panic_with_hook::hbe174577402a475d
                               at src/libstd/panicking.rs:464
  11:     0x555c589f228e - std::panicking::continue_panic_fmt::h4d855dad868accf3
                               at src/libstd/panicking.rs:373
  12:     0x555c589f2176 - rust_begin_unwind
                               at src/libstd/panicking.rs:302
  13:     0x555c58a11d5e - core::panicking::panic_fmt::hdeb7979ab6591473
                               at src/libcore/panicking.rs:139
  14:     0x555c58a11caa - core::panicking::panic::hb5daa85c7c72fc62
                               at src/libcore/panicking.rs:70
  15:     0x555c587b6e4c - py_spy::python_spy::PythonSpy::get_stack_traces::hf1034ae8c547c3fe
  16:     0x555c587a5ade - py_spy::dump::print_traces::ha3b7ff6b5d3dc615
  17:     0x555c58774ce9 - py_spy::run_spy_command::h9e10a2ee06576172
  18:     0x555c587781ae - py_spy::main::h65a100b9d2adcb81
  19:     0x555c58795853 - std::rt::lang_start::{{closure}}::hc7c20c46ab3745aa
  20:     0x555c589f2113 - std::rt::lang_start_internal::{{closure}}::h6ea535ec5c50fc3e
                               at src/libstd/rt.rs:48
  21:     0x555c589f2113 - std::panicking::try::do_call::h631c6408dfccc6f5
                               at src/libstd/panicking.rs:287
  22:     0x555c589fa01a - __rust_maybe_catch_panic
                               at src/libpanic_unwind/lib.rs:78
  23:     0x555c589f2bcd - std::panicking::try::hab539b2d1255d635
                               at src/libstd/panicking.rs:265
  24:     0x555c589f2bcd - std::panic::catch_unwind::hd5e0a26424bd7f34
                               at src/libstd/panic.rs:396
  25:     0x555c589f2bcd - std::rt::lang_start_internal::h3bdc4c7d98181bf9
                               at src/libstd/rt.rs:47
  26:     0x555c58779d72 - main
  27:     0x7f831245d2e1 - __libc_start_main
  28:     0x555c5870f3c9 - _start
  29:                0x0 - <unknown>
```


## Version Details

```
$ ./py-spy --version
py-spy 0.3.2
```

I'm running this on Google "Container OS" instance (running on a Google Kubernetes Engine cluster). My py-spy process is in a privileged container ([the "toolbox" environment](https://cloud.google.com/container-optimized-os/docs/how-to/toolbox)), and I'm trying to dump an unprivileged process in another container. These containers are almost certainly using different library versions etc, which I know sometimes causes debugging problems.

## gdb output

GDB manages to do the right thing but prints warnings:

```
warning: Expected absolute pathname for libpthread in the inferior, but got target:/lib/x86_64-linux-gnu/libpthread.so.0.
warning: Unable to find libthread_db matching inferior's thread library, thread debugging will not be available.
warning: Target and debugger are in different PID namespaces; thread lists and other data are likely unreliable.  Connect to gdbserver inside the container.
warning: Expected absolute pathname for libpthread in the inferior, but got target:/lib/x86_64-linux-gnu/libpthread.so.0.
warning: Unable to find libthread_db matching inferior's thread library, thread debugging will not be available.
```
It makes the left-heavy view confusing. Is it because of the sampling method, which just fetches the current line number?

I know about `-F`, but what if I have two classes in the same file with a method with the same name?

I think this tool is pretty incredible.  Unfortunately, it has worked only sporadically in my current project, and I'm not sure why it works/doesn't work.  My issues resemble some of the errors reported in #2, especially the "Failed to merge native and python frames" message.  I am using py-spy version 0.3.1 installed using pip, on Centos 7.5 x86_64.  I am compiling several Cython extensions (some of whom call each other), and the command-line for the compile stage indicates debugging is enabled:

```
gcc -pthread -Wno-unused-result -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DCYTHON_TRACE=0 -I/usr/include/python3.6m -c build/lib/project/lossy_compress_nodebug.c -o build/temp.linux-x86_64-3.6/build/lib/project/lossy_compress_nodebug.o
```

I then run the base python script through py-spy:

```
~/VENV3/bin/py-spy record  -o ~/tmp12.pyspy.svg --native  -- ~/VENV3/bin/python ~/tmp12.py --exitafterone
```

And the output is:

```
Sampling process 100 times a second. Press Control-C to exit.
1.01s behind in sampling, results may be inaccurate. Try reducing the sampling rate..
  Collected 57612 samples (56884 errors)
Stopped sampling because process exitted
Wrote flamegraph data to '/home/sg9/tmp12.pyspy.svg'. Samples: 57612 Errors: 56884
```

The successful samples are at the very beginning, before it hits any Cython extensions, and the failed ones all report the following errors (using RUST_LOG=info):

```
⠒ Collected 77 samples (22 errors)
[2019-12-31T21:43:47.435024222Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
[2019-12-31T21:43:47.465658980Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
[2019-12-31T21:43:47.480930106Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
⠠ Collected 81 samples (26 errors)
[2019-12-31T21:43:47.513377821Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 6 native and 3 python)
[2019-12-31T21:43:47.529921084Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
[2019-12-31T21:43:47.544238935Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
[2019-12-31T21:43:47.558172214Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
⠉ Collected 86 samples (31 errors)
[2019-12-31T21:43:47.587753753Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
[2019-12-31T21:43:47.602930263Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 8 native and 5 python)
[2019-12-31T21:43:47.617928596Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 8 native and 5 python)
[2019-12-31T21:43:47.631587547Z WARN  py_spy] Failed to get stack trace from 26617: Failed to merge native and python frames (Have 7 native and 4 python)
```

Note that the difference between native and python stack lengths is always 3.  I have compiled using gcc 4.8.5 and 8.3.1 with the same result.  I was not successful building straight from the repo using cargo, but it does not seem loading unwind_ptrace is the issue anyway.  I would love to figure out what's going on, and thought a first step might be to figure out what the actual stack frames are, before merging, and having them printed out -- would there be an easy way to do this?

Also, I did mention there were a few blissful moments when it worked perfectly, but I have no idea what I did to made it work, and then it suddenly stopped working again, with no obvious change on my part (aside from recompilation of the Cython extensions, and no software upgrades).  Any help appreciated!
Can I create a PR to add chinese README.md for many chinese developer?
On Windows 10 all other checks for the Python version number fail for me.
I know that `py-spy` works in general, since it is able to analyze a commerical product that has Python 2.7 embedded. It just fails for pure Python 2.7.

On Windows, Python's default installation path is `C:\pythonXY` and not `C:\pythonX.Y`.

Would you object to also covering this case?

The log: 

```
[2019-11-13T14:23:13.729494300Z INFO  py_spy::python_spy] Trying to get version from path: c:\python27\python.exe
[2019-11-13T14:23:13.745091000Z INFO  py_spy::python_spy] Failed to connect to process, retrying. Error: Failed to find python version from target process
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Got virtual memory maps from pid 12656:
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Found libpython binary @ C:\WINDOWS\SYSTEM32\python27.dll
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Getting version from python binary BSS
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Failed to get version from BSS section: failed to find version string
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Getting version from libpython BSS
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Failed to get version from libpython BSS section: failed to find version string
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Trying to get version from path: c:\python27\python.exe
[2019-11-13T14:23:13.767903800Z INFO  py_spy::python_spy] Failed to connect to process, retrying. Error: Failed to find python version from target process
[2019-11-13T14:23:13.814774900Z INFO  py_spy::python_spy] Got virtual memory maps from pid 12656:
[2019-11-13T14:23:13.814774900Z INFO  py_spy::python_spy] Found libpython binary @ C:\WINDOWS\SYSTEM32\python27.dll
[2019-11-13T14:23:13.814774900Z INFO  py_spy::python_spy] Getting version from python binary BSS
[2019-11-13T14:23:13.814774900Z INFO  py_spy::python_spy] Failed to get version from BSS section: failed to find version string
[2019-11-13T14:23:13.814774900Z INFO  py_spy::python_spy] Getting version from libpython BSS
[2019-11-13T14:23:13.814774900Z INFO  py_spy::python_spy] Failed to get version from libpython BSS section: failed to find version string
[2019-11-13T14:23:13.814774900Z INFO  py_spy::python_spy] Trying to get version from path: c:\python27\python.exe
[2019-11-13T14:23:13.830367000Z INFO  py_spy::python_spy] Failed to connect to process, retrying. Error: Failed to find python version from target process
[2019-11-13T14:23:13.869772000Z INFO  py_spy::python_spy] Got virtual memory maps from pid 12656:
[2019-11-13T14:23:13.869772000Z INFO  py_spy::python_spy] Found libpython binary @ C:\WINDOWS\SYSTEM32\python27.dll
[2019-11-13T14:23:13.882780600Z INFO  py_spy::python_spy] Getting version from python binary BSS
[2019-11-13T14:23:13.882780600Z INFO  py_spy::python_spy] Failed to get version from BSS section: failed to find version string
[2019-11-13T14:23:13.882780600Z INFO  py_spy::python_spy] Getting version from libpython BSS
[2019-11-13T14:23:13.882780600Z INFO  py_spy::python_spy] Failed to get version from libpython BSS section: failed to find version string
[2019-11-13T14:23:13.882780600Z INFO  py_spy::python_spy] Trying to get version from path: c:\python27\python.exe
Error: Failed to find python version from target process
```
Because normally each argument ends with one null, not seperated by one
null. Note that the cmdline could have been edited so it might not
always be the case.

The extra space caused by the last null can be seen on the first line of `py-spy top`.
Lines too long will break the display, making the first line confusing.