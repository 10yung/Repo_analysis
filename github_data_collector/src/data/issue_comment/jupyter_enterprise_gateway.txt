hi,
we had deployed the EG with SSL enabled. We would like to know how to configure the ssl at the KIP. Pls provide some pointers.

surya
Since updating the conditional volume mounts I have encountered a new issue. While having resource quotas and limits in any given namespace where the Enterprise Gateway is deployed. The EG and the Kernels are not spawning because the following specs are missing in the templates : 

kernel-pod.yaml.j2
```
    name: "{{ kernel_pod_name }}"
    resources:
      limits:
        cpu: "1"
        memory: "1Gi"
        nvidia.com/gpu: "0"
    {% if kernel_working_dir is defined %}
    workingDir: "{{ kernel_working_dir }}"
    {% endif %}
    volumeMounts:
```

Enterprise Gateway Deployment YAML snippet 
```
image: elyra/enterprise-gateway:dev
        resources:
          limits:
            cpu: "1"
            memory: "1Gi"
            nvidia.com/gpu: "0"
```

Image puller daemonset YAML snippet 
```
image: elyra/kernel-image-puller:dev
        resources:
          limits:
            cpu: "1"
            memory: "1Gi"
            nvidia.com/gpu: "0"
``` 

Basically in all the templates there is no definition for limits, this blocks the pods from spawning in a namespace where these limits and quotas are defined. 

I think this is something that can be catched with an Admission Controller, but might be a good idea to implement it in the templates? 

I'm not sure how to pass those variables, so in my own setup I hardcoded the limits in the templates. 

I browsed some issues but I don't think this is mentioned somewhere already? Correct me if I'm wrong @kevin-bates 


With NB 6.x we don't need the NB2KG dependency anymore, which can considerably simplify the image used when integrating with JupyterHub
## Description
The EG instance becomes unresponsive, returning HTTP 500: Internal Server Error to the client. In the EG logs, the EG is repeatedly querying for the state of the Spark Application (Every 3-4 second), which is failing.

I have not found a way to reproduce the issue. Restarting the EG instance works, but this is a frequently occurring issue (Once every 3-4 days). 

The YARN API it's using to query the state of the application (http://<rm-url>:<rm-port>/ws/v1/cluster/apps/application_1573339086213_974645/state), is working and returning the state of the spark application. 

Going through the stack trace, I observed that `resource_manager` object of _YarnClusterProcessProxy_ becomes `None`, because of which the query is failing.



## Screenshots / Logs
Stack trace of EG:
```
[W 2019-12-18 12:33:27.020 EnterpriseGatewayApp] Query for application 'application_1573339086213_974645' state failed with exception: 'HTTPConnectionPool(host=<rm-url>, port=<rm-port>): Max retries exceeded with url: /ws/v1/cluster/apps/application_1573339086213_974645/state (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f77d0408cf8>: Failed to establish a new connection: [Errno 11] Resource temporarily unavailable'))'.  Continuing...
[E 191218 12:33:27 ioloop:909] Exception in callback <bound method KernelRestarter.poll of <jupyter_client.ioloop.restarter.IOLoopKernelRestarter object at 0x7f782b480550>>
    Traceback (most recent call last):
      File "/usr/share/mlp-jeg/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
        return self.callback()
      File "/usr/share/mlp-jeg/lib/python3.7/site-packages/jupyter_client/restarter.py", line 93, in poll
        if not self.kernel_manager.is_alive():
      File "/usr/share/mlp-jeg/lib/python3.7/site-packages/jupyter_client/manager.py", line 453, in is_alive
        if self.kernel.poll() is None:
      File "/usr/share/mlp-jeg/lib/python3.7/site-packages/enterprise_gateway/services/processproxies/yarn.py", line 152, in poll
        state = self.query_app_state_by_id(self.application_id)
      File "/usr/share/mlp-jeg/lib/python3.7/site-packages/enterprise_gateway/services/processproxies/yarn.py", line 378, in query_app_state_by_id
        return response.data['state']
    AttributeError: 'NoneType' object has no attribute 'data'

```

## Environment

- Enterprise Gateway Version - 1.2.0
- Platform: Spark YARN Cluster Mode
- OS: Debian 8


kernel-image-puller is not supporting to pull images from private registries. I suppose that the best way would be to enable pulling images from private registries by passing KIP_IMAGE_REGISTRY_USER and KIP_IMAGE_REGISTRY_PASSWORD env variables... In a kubernetes setup this could be easily used in combination with a secret containing the user and login.

The python docker client supports this, using the auth_config parameter to docker.images.pull():

https://github.com/docker/docker-py/blob/master/docker/models/images.py

```

    def pull(self, repository, tag=None, **kwargs):
        Args:
            repository (str): The repository to pull
            tag (str): The tag to pull
            auth_config (dict): Override the credentials that are found in the
                config for this request.  ``auth_config`` should contain the
                ``username`` and ``password`` keys to be valid.
            platform (str): Platform in the format ``os[/arch[/variant]]``
```
How possible would it be to do this? 

I think the difficulty here is making a processproxy that does similar things to the ssh one and the docker one and also passing which docker image to run a notebook in. 

Is this something you would be interested in having a pull request if I get the time to implement it? Can you see any pitfalls, or reason this doesn't already exist?
Feature Request for configuring the request queue size in JEG

## Description

Due to the following [issue](https://github.com/jupyter/enterprise_gateway/issues/86), all subsequent requests are queued at JEG during Kernel Launch. 
In case of Spark kernels, kernel startup can take more than 10-15 seconds. If two users are using the same JEG instance, and if one user has launched a kernel, the other user's requests (which might not be a kernel launch request) are queued for that duration.
Gateway timeouts (generally set in the order of minutes) acts as a guardrail for not making the user wait indefinitely, but waiting for timeouts and eventually not getting a response from JEG still leads to a bad user experience.

I suggest a request queue size configuration is set at JEG level which takes in the number of requests (n) that can be queued at JEG. If (n+1)th request is received, it should be rejected and sent back with a proper Error message. (`HTTP 5XX: Gateway is busy executing other requests`).

## Environment

- Enterprise Gateway Version 1.2.0
- Platform: YARN


## Description

If the menu item "Restart kernel" is pressed in JupyterLab, the frontend loses connection to the kernel. After "restart" cells never return output.

I am playing with a custom class (derived from RemoteProcessProxy), but I am able to reproduce the issue with DistributedProcessProxy.

## Screenshots / Logs

From what I see from the logs on a start there are connections to all set of ports, while on restart hb and stdin is never being reconnected.
Start:
```
[D 2019-11-22 22:26:32.415 EnterpriseGatewayApp] Received connection info for KernelID '37d6233c-bae3-4ab0-8f91-365581b0bfd7' from host 'dc-c7u5': {'shell_port': 48838, 'iopub_port': 45250, 'stdin_port': 34335, 'control_port': 41070, 'hb_port': 49048, 'ip': '10.141.255.254', 'key': '0190b74b-342d-40b3-9514-9fb5f8a5a785', 'transport': 'tcp', 'signature_scheme': 'hmac-sha256', 'kernel_name': '', 'comm_port': 54264}...
[D 2019-11-22 22:26:32.416 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:41070
[D 2019-11-22 22:26:32.418 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:45250
[I 2019-11-22 22:26:32.420 EnterpriseGatewayApp] Kernel started: 37d6233c-bae3-4ab0-8f91-365581b0bfd7
[D 2019-11-22 22:26:32.420 EnterpriseGatewayApp] Kernel args: {'env': {'PATH': '/cm/shared/apps/jupyter/6.0.0/bin:/cm/shared/apps/cm-npm-configurable-http-proxy/4.0.1/bin:/cm/local/apps/python37/bin:/cm/local/apps/cm-setup/bin:/cm/local/apps/cluster-tools/bin:/cm/local/apps/cmd/sbin:/cm/local/apps/cmd/bin:/cm/local/apps/environment-modules/4.2.1//bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/cm/local/apps/environment-modules/4.2.1/bin:/bin:/sbin:/root/bin:/tmp/.dmitry.sshrc.WkYa', 'KERNEL_LAUNCH_TIMEOUT': '40', 'KERNEL_WORKING_DIR': '/home/cmsupport', 'KERNEL_USERNAME': 'cmsupport'}, 'kernel_name': 'python_slurm'}
[D 2019-11-22 22:26:32.834 EnterpriseGatewayApp] Opening websocket /api/kernels/37d6233c-bae3-4ab0-8f91-365581b0bfd7/channels
[D 2019-11-22 22:26:32.834 SingleUserNotebookApp handlers:155] Connection is ready: ws: <tornado.websocket.WebSocketClientConnection object at 0x2aaabe471b00>
[D 2019-11-22 22:26:32.834 EnterpriseGatewayApp] Getting buffer for 37d6233c-bae3-4ab0-8f91-365581b0bfd7
[D 2019-11-22 22:26:32.834 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:48838
[D 2019-11-22 22:26:32.835 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:41070
[D 2019-11-22 22:26:32.835 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:45250
[D 2019-11-22 22:26:32.836 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:34335
[D 2019-11-22 22:26:32.838 EnterpriseGatewayApp] activity on 37d6233c-bae3-4ab0-8f91-365581b0bfd7: status (busy)
[D 2019-11-22 22:26:32.840 EnterpriseGatewayApp] activity on 37d6233c-bae3-4ab0-8f91-365581b0bfd7: status (idle)
```
Restart:
```
[D 2019-11-22 22:27:47.316 EnterpriseGatewayApp] Received connection info for KernelID '37d6233c-bae3-4ab0-8f91-365581b0bfd7' from host 'dc-c7u5': {'shell_port': 47612, 'iopub_port': 59026, 'stdin_port': 43679, 'control_port': 56182, 'hb_port': 58337, 'ip': '10.141.255.254', 'key': 'bc692a35-da80-4223-a30b-84601cb6c043', 'transport': 'tcp', 'signature_scheme': 'hmac-sha256', 'kernel_name': '', 'comm_port': 37503}...
[D 2019-11-22 22:27:47.316 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:56182
[D 2019-11-22 22:27:47.317 EnterpriseGatewayApp] Clearing buffer for 37d6233c-bae3-4ab0-8f91-365581b0bfd7
[D 2019-11-22 22:27:47.318 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:59026
[D 2019-11-22 22:27:47.320 EnterpriseGatewayApp] Refreshing kernel session for id: 37d6233c-bae3-4ab0-8f91-365581b0bfd7
[I 2019-11-22 22:27:47.321 EnterpriseGatewayApp] Kernel restarted: 37d6233c-bae3-4ab0-8f91-365581b0bfd7
[D 2019-11-22 22:27:47.321 EnterpriseGatewayApp] Connecting to: tcp://10.141.255.254:47612
[D 2019-11-22 22:27:47.479 EnterpriseGatewayApp] activity on 37d6233c-bae3-4ab0-8f91-365581b0bfd7: status (busy)
[D 2019-11-22 22:27:47.480 EnterpriseGatewayApp] activity on 37d6233c-bae3-4ab0-8f91-365581b0bfd7: status (idle)
[D 2019-11-22 22:27:47.480 EnterpriseGatewayApp] Kernel info reply received: 37d6233c-bae3-4ab0-8f91-365581b0bfd7
[D 2019-11-22 22:27:47.482 SingleUserNotebookApp managers:461] Restart kernel response: 200 OK
```

`netstat` also shows a reduced set of opened connections.

## Environment
jupyter-client==5.3.4
jupyter-core==4.6.1
jupyter-enterprise-gateway==2.0.0
jupyter-kernel-gateway==2.4.0
jupyterhub==1.0.0
jupyterlab==1.1.4
jupyterlab-server==1.0.6
ipykernel==5.1.3
ipython==7.9.0

OS: Centos 7

One of the features added in PR #629 was the ability for users to specify per-user volume mounting by specifying `KERNEL_VOLUME_MOUNTS` and `KERNEL_VOLUMES` values in the `env` stanza of the api/kernels POST request's json body.  We need to document an example of how that would be accomplished.  It could be as simple as taking the example from #629 

This issue came up during the review of PR #749 - which references the location within the docs.
Why can't we use Skaffold to build the kernel images in a separate project? 
https://github.com/GoogleContainerTools/skaffold.


