Hey

I'm running multiple queue consumers and from time to time it happens that 2 consumers get the same job at the same time. (I'm not logging the time down to millisecond precision, but it does happen in the same second.)
Now multiple deliverers perse are not problematic unless they happen at the same time as everythen else then falls apart.

Looking to run this on a Raspberry PI 3+

Thanks!
Hi all,

many of you ask what will happen with Disque. Here is all the news:

1. The project is in the process of being translated to a Redis module. The code duplication with Redis was *impossible* to handle. I tried and I failed. So that was the plan.
2. I'm sitting in an alpha code base of Disque as a module of Redis that does not even compile but is a very good start... I translated most data structures in the past few months, but more importantly as a side effect I added to Redis modules all the APIs I needed (Cluster API and Timer API). I think I need yet another API to force replication out of context... but I'm not 100% sure.
3. Disque module will be released **under the AGPL license**, not BSD as Redis core.
4. Redis 6 **will not be released if we don't have an RC version of Disque** at least.
5. ETA: You should see Disque in beta version before the end of the year. RC in 6 months.
6. The new Disque should be mostly API compatible with the old one, and will have exactly the same guarantees. Will be AP, federated, and so forth. Same stuff. Just as a module.
7. It will live in a different repository compared to Redis. Very probably this same repository: at some point I'll force-push the new project, and leave the current implementation as a branch for historical reasons.

If you have questions I'm here.
ENV: cluster has three node of A,B,C
Case Step:
1. add 100 job to A, param: replicate=1, and other param with default.
 now result: A: info - registered_jobs=100,qlen=100; B:info - registered_jobs=0,qlen=0;C: same as B
2. clinet connect to C to consumer all of those jobs
 now result: A: info - registered_jobs=100,qlen=0; B:info - registered_jobs=0,qlen=0;C: same as B
Note: the  registered_jobs=100 at the time!
And consumer client connect to A, 100 jobs duplicate send to A!
But when A,C be connected at the same time, result is only be consumered once only
Unreasonable it is?
The [SHOW command doc](https://github.com/antirez/disque#show-job-id) is missing info about what fields are returned.
README says:
> Disque is a synchronously replicated job queue. By default when a new job is added, it is replicated to W nodes before the client gets an acknowledgement about the job being added. W-1 nodes can fail and the message will still be delivered.

What is W by default?
When I add a job without the REPLICATE parameter to a cluster with 3 nodes, job info gives me 'repl 3'. A cluster with 1 node gives me 'repl 1'.
By default REPLICATE=min(cluster-size, 3) or REPLICATE=cluster-size?
This is important because if you don't specify REPLICATE on a cluster with 3 nodes and 1 is down, you won't be able to add jobs.

[ADDJOB doc](https://github.com/antirez/disque#addjob-queue_name-job-ms-timeout-replicate-count-delay-sec-retry-sec-ttl-sec-maxlen-count-async) doesn't specify the REPLICATE default value and behavior:

> REPLICATE count is the number of nodes the job should be replicated to.

The anchor text in the README is also wrong. Should be addjob instead of 'addjob-queue...'.

Why is the syntax of command and info different?
'REPLICATE 3' in command.
'repl 3' in info. Lowercase and shorter word.

The version has not been updated for a long time,so
When the author decide to publish the stable version ï¼Ÿ
and if it will exist the new version?
I add a job with "ADDJOB" in the disque.
localhost:7711> addjob test "yaya"  10000
the scrreen console that:
D-351c426f-BAZ7uyDERGtv7ybjIz/19a1A-05a1

then I exec the getjob ,I get this job.
I exec the command: qlen 
the result returns 0  or empty

Whether I need to exec the  "FASTJOB" or "ACKJOB" to GC this channel in disque after I exec "GETJOB"?

in the disque.conf file -
there is a section which can control the memory of disque process.
-------------------------------------------------*************************-------------------------------------------------------
# Note on units: when memory size is needed, it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth:
#
# 1k => 1000 bytes
# 1kb => 1024 bytes
# 1m => 1000000 bytes
# 1mb => 1024*1024 bytes
# 1g => 1000000000 bytes
# 1gb => 1024*1024*1024 bytes
#
# units are case insensitive so 1GB 1Gb 1gB are all the same.
-------------------------------------------------******************************-----------------------------------------------------
Is it related to how much memory a disque-process can use?
If yes, how to increase memory size that can be used by disque process?
If no, is there any cap on the max_memory_used by disque?
  
Given the cluster of 3 nodes, shouldn't the QLEN return the same results regardless the node being asked? In my tests only original node returns proper queue length, but `GETJOB` on different node still works properly

```
$ redis-cli -h eu1-queue-3 -p 7712 addjob testqueue testjob 1000
D-54bdf6f9-2qZjI4HgYKs8vP0ZWSeAANbK-05a1

$ redis-cli -h eu1-queue-1 -p 7712 qlen testqueue
(integer) 0 # WHY?
$ redis-cli -h eu1-queue-2 -p 7712 qlen testqueue
(integer) 0
$ redis-cli -h eu1-queue-3 -p 7712 qlen testqueue
(integer) 1

$ redis-cli -h eu1-queue-1 -p 7712 getjob from testqueue
1) 1) "testqueue"
   2) "D-54bdf6f9-2qZjI4HgYKs8vP0ZWSeAANbK-05a1"
   3) "testjob"
```