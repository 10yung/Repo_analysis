**Version** : 2.9.1

**Stack trace**

> Exception in thread "main" java.lang.NoClassDefFoundError: org/slf4j/LoggerFactory
> 	at spark.Service.<clinit>(Service.java:56)
> 	at spark.Spark$SingletonHolder.<clinit>(Spark.java:51)
> 	at spark.Spark.getInstance(Spark.java:55)
> 	at spark.Spark.<clinit>(Spark.java:61)
> 	at Api.<init>(Api.java:5)
> 	at generator.main(generator.java:61)
> Caused by: java.lang.ClassNotFoundException: org.slf4j.LoggerFactory
> 	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
> 	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
> 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
> 	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
> 	... 6 more

**Steps to reproduce**

1. Download the jar from [here](https://repo1.maven.org/maven2/com/sparkjava/spark-core/) (2.9.1)
2. Create a simple class with a simple get:
import static spark.Spark.*;
```
public class Api {
	public Api() {
		get("test", (req, res) -> "hello, world");
	}
}
```
3. Use the api:
```
	public static void main(String[] args) throws InterruptedException {
		
		Api api = new Api();
```

------------------------

I had to the build path slf4j-simple-1.7.30, still the same problem.

Overview of the config:

![image](https://user-images.githubusercontent.com/10050024/72146879-ac311000-339d-11ea-8eab-1b665bbebc35.png)


Condition `path.contains("")` is always true.
https://github.com/perwendel/spark/blob/c697d981268c538dfeeb38786bd9eb0a03ab86f0/src/main/java/spark/resource/ClassPathResource.java#L104
(I found this with the [data-flow analyzer](https://github.com/Egor18/jdataflow) I'm working on.)
When using `Content-Encoding: gzip`, its not possible to set `Content-Length` header (which is useful when serving large files). 

I explained my situation at [stackoverflow](https://stackoverflow.com/questions/56404858/how-to-correctly-set-content-length-in-spark-java-after-gzip-header?noredirect=1#comment105151474_56404858). 

I think this issue could be solved with what has been proposed in #459 (finding a way to disable automatic gzip encoding) or in #742 . 
Other way is to set some option/flag to automatically calculate the content length, which could also solve #937 (which was closed without any comment). 

Thanks.
branch: remove-array-null-check
change-list:
- Removed redundant array null check after String.split. Method split never return null
Hi all,

First I would like to apologize for the recent inactivity. There are several reasons but the main one is that I've started studying at the university again. I thought I would be able to handle both that on the Spark project but it's not been the case.

Therefore, I want to find someone that wants to join the Spark project in the role of both developer, designer and maintainer. I would continue to help with API design and approval (at least for a period).

If you're interested email me at per.i.wendel@gmail.com and tell med a little bit about yourself.

Cheers,
Per
Good afternoon.

I created a PR to allow configuring the Jetty SSL: https://github.com/perwendel/spark/pull/1153
At the beginning, the travis CI failed because the project is using oraclejdk8; after upgrading to oraclejdk9, it started complaining about the certificate:
https://travis-ci.org/perwendel/spark/builds/619856630?utm_source=github_status&utm_medium=notification

I have found some posts that reported the same issue: http://blog2.vorburger.ch/2016/04/how-to-resolve-validatorexception-pkix.html Could you please try the fix mentioned in it? Thanks.

i create a sparkjava project ,and i create a websocket class, but when i create some route for javaweb api, the javaweb route can't  be accesss.
Hi there,

As title, is there a way to make route parameter optional?

```
// matches "GET /hello/foo" and "GET /hello/bar"
// does not match GET /hello
get("/hello/:name", (request, response) -> {
    return "Hello: " + request.params(":name");
});
```
How can i make above to match only `/hello`
I am trying to access URI params in filters and I'm getting zero sized map when calling Request.params(). The params() method works as expected in the route itself but not in before and after filters.


```
@Override
    public void handle(Request req, Response res) {
        if (req.uri().contains("/publish")) {
            if (NOTIFICATION.equals(req.params(":type").toLowerCase())) {
                Message m = JsonIterator.deserialize(req.body(), Message.class);
                req.attribute(PUBLISH_BODY, m);

                if (m == null || m.getN() == null)
                    Spark.halt(HttpStatus.SC_BAD_REQUEST);
            }
        }
    }
```

In the above example `req.params(":type")` returns null and `req.params()` is an empty map