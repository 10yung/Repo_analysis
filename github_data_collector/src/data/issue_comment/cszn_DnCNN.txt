您好，非常感谢您的代码。想问一下pytorch版本下有没有已经训练好的彩色模型，您提供的数据库链接是google云盘，国内上不了，能传一个百度网盘吗。
Hi, 
I am trying to reproduce the red graph provided in the paper which shows the Average PSNR vs epochs for the Set68:
![psnrvsepoch](https://user-images.githubusercontent.com/56032684/71247410-0566d000-2319-11ea-993a-807eef643a0f.png)

I am using the Keras implementation provided here (it includes Residual Learning and Batch Normalization, and Adam optimization as well), and I am training 50 epochs.

However, instead of a stable graph like the one in the paper, I get a graph with pronounced drops, similar to the blue and black graphs in the paper. Furthermore, even in the last epochs, where the network should be converging, the Average PSNR often shows significant drops, which are related to the presence of odd spots in some of the denoised images:
![01_dncnn](https://user-images.githubusercontent.com/56032684/71247561-4b239880-2319-11ea-8128-11f4b778fc6e.png)
![test001_dncnn](https://user-images.githubusercontent.com/56032684/71249945-ac9a3600-231e-11ea-8ac0-f752a8fd3ca2.png)

I have experimented with different settings, in particular with different BN momentum, and the situation becomes better when it is set to a high value, as 0.9. Even so, the graph I get is never something similar to the red one in the paper. I am afraid these spots in the denoised images appear quite randomly, with different shapes and locations for different trainings. 

Has anyone experienced the same or something similar? I would appreciate any help, thank you!!


Hi, Thanks for release the code. I have read your code. It's brilliant!
but I found a small problem in your pytorch code.
when get patches. you data augment have some problems about cv2.imresize. you can check you codes in ./DnCNN-master/TrainingCodes/dncnn_pytorch/data_generator.py  line 94.
The parameters used for batch normalization are not specified in [the original paper](https://arxiv.org/abs/1608.03981).

I don't know how batch norm works in Matlab (I have tried to read the codes but it's very difficult to me), so I tried looking in keras. The parameters used seemed very odd (in addition the batch normalisation is involved in a [code mess](https://github.com/cszn/DnCNN/issues/53)), so I looked in pytorch, and saw that they are different.
In keras the momentum is [`0.0`](https://github.com/cszn/DnCNN/blob/master/TrainingCodes/dncnn_keras/main_train.py#L69) or [`0.1`](https://github.com/cszn/DnCNN/blob/master/TrainingCodes/dncnn_keras/main_train.py#L68) depending on where you look, and in pytorch the momentum is [`0.95`](https://github.com/cszn/DnCNN/blob/master/TrainingCodes/dncnn_pytorch/main_train.py#L75).

Note that this differs from the [original unofficial keras implementation](https://github.com/husqin/DnCNN-keras/blob/master/models.py#L18).
 loss is inf !!!
When training in pytorch with SGD, loss is inf , how to do with it?
Hi, in your paper, u stated that MSE is used to optimized the network. However in your code, it is using Sum Square Error. It that a mistake or there is specific reason for that? Mind to share some experience?

On line 163 we have (loss = criterion(model(batch_y), batch_x))

batch_y = clean + noise 
model(batch_y) = x - output of the network. 

If so, shouldn't the loss function be loss = criterion(model(batch_y),noise)? 
In the paper, I see you proposed a DnCNN-3 model which can either denoise a picture or perform super resolution on a picture. However if I want to denoise a picutre and perform super resolution on it at the same time, is this model capable of this task? I trained a model by myself but the result is very poor if the input is both noisy and bicubic magnified. Could you offer me some advice on it? 
I wanted to know at which epoch did your loss started to converge?