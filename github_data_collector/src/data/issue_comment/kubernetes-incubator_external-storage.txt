I would like to update the [nfs-server-provisioner helm chart ](https://github.com/helm/charts/blob/master/stable/nfs-server-provisioner/values.yaml) to have at least the [nfs-provisioner v2.3.0](https://github.com/kubernetes-incubator/external-storage/tree/nfs-provisioner-v2.3.0). For that I would need the tag v2.3.0 to be released on [quay.io/repository/kubernetes_incubator/nfs-provisioner](https://quay.io/repository/kubernetes_incubator/nfs-provisioner?tab=tags).

## Additional Questions
* What's the process for new tags to be released on the image repository? 
* Is this is something that anyone could do or does it has to be a core contributor of external-storage?
I ran `git grep -l 'extensions/v1beta1' | xargs sed -i 's,extensions/v1beta1,apps/v1,'` and then double checked each replacement

- dameonset is also under apps/v1
- psp is under policy/v1beta1

We can configure efs-provisioner with region and `file.system.id` and `aws.region` or `dns.name`.

I would expect that `dns.name` is the only required property but it's not true. If I will omit this property I will received:
```
W0109 09:16:02.407526 1 efs-provisioner.go:60] environment variable FILE_SYSTEM_ID is not set! Please set it.
```

If i provide fake value i will received:

```
W0109 08:06:08.407526 1 efs-provisioner.go:91] couldn't confirm that the EFS file system exists: FileSystemNotFound: File system 'fs-12345678' does not exist.
```
Latest image of rbd-provisioner on quay.io is released at [2018.9](https://quay.io/repository/external_storage/rbd-provisioner?tab=tags). 

I want to create a Block PVC, which is supported in PR #1156. 

THX
* [issue1256](https://github.com/kubernetes-incubator/external-storage/issues/1256)
* [issue942](https://github.com/kubernetes-incubator/external-storage/issues/942)
* [issue1257](https://github.com/kubernetes-incubator/external-storage/issues/1257)
When using the image quay.io/external_storage/nfs-client-provisioner:latest, we can specify parameters as **PROVISIONER_NAME**, **NFS_SERVER** and **NFS_PATH**.

In case my NFS export requires an username/password authentication, I am not be able to use that area.

Is there any reason for not providing this kind of function?
If not, would it be possible to add to the roadmap or it is complicated and wouldn't bring advantages?

Thanks very much.

New ports have been added in f974aba435b44e812fca0b4687e57879de03f3f7, and if you try to create nfs-provisioner deployment by following instructions you'll end up with this error like this:

```
failed to provision volume with StorageClass "...": error getting NFS server IP for volume: service SERVICE_NAME=... is not valid; check that it has for ports map[{111 TCP}:true {111 UDP}:true {2049 TCP}:true {20048 TCP}:true] exactly one endpoint, this pod's IP POD_IP=...
```

That's because port endpoint validation uses reflect.DeepEqual for validation, and thus fails if there are all required ports AND MORE.

I've ended up manually building latest tag from master to my private registry and using that as image.

I think that docs should at least reference that ports were changed and older versions of container (including latest on quay) need older versions of service.
Is it possible for the volumes.nfs.server value to be read from configmap?  Or just use dns.name always.  