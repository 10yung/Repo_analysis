This isn't really an issue, but more of a request. 

I think it would be really nice to have a program (much like cache-hierarchy-bandwidth) which determine the cache line size. It is surprisingly difficult to isolate cache line size effect (prefetching makes everything hard). I tried to follow the advice mentioned in the top answer here: https://stackoverflow.com/questions/12675092/how-to-find-the-size-of-the-l1-cache-line-size-with-io-timing-measurements but it doesn't work on my computer.


I am curious what is the 'correct' perf counter for 4K aliasing. You have mentioned `ld_blocks.store_forward`, but I was wondering about the other counter `ld_blocks_partial.address_alias` as well. 

Here is the `perf list` description:

```
  ld_blocks.store_forward                           
       [loads blocked by overlapping with store buffer that cannot be forwarded]
  ld_blocks_partial.address_alias                   
       [False dependencies in MOB due to partial compare on address]
```

Here are the perf results on my machine:

```
$ perf stat -e ld_blocks_partial.address_alias,ld_blocks.store_forward ./a.out 4096
222

 Performance counter stats for './a.out 4096':

             6,852      ld_blocks_partial.address_alias:u                                   
                32      ld_blocks.store_forward:u                                   

       0.224647447 seconds time elapsed

```


```
$ perf stat -e ld_blocks_partial.address_alias,ld_blocks.store_forward ./a.out 4092
359

 Performance counter stats for './a.out 4092':

       132,139,399      ld_blocks_partial.address_alias:u                                   
         2,097,093      ld_blocks.store_forward:u                                   

       0.361229917 seconds time elapsed

```

As you can see, both of them are hugely different for `4092` and `4096`. 
I'm toying around with the cache-conflicts code, and I'm using a higher count than you did in your benchmark. However, the repetition count than makes the program run for absolutely forever. So maybe you could do:

```
#ifndef REPETITIONS
#define REPETITIONS 10000000
#endif
```

so that it becomes possible to override that count.

After that I can of course recompile by hand, but beats me if I can figure out how to use your build system and pass the `-DREPETITIONS=1000` to the compiler.

Thoughts?
Hi again,

here's my plot for the cache-memory-bound-test:

![screenshot from 2018-12-03 12-08-29](https://user-images.githubusercontent.com/6462223/49433702-e3082000-f7b2-11e8-9f3b-970d7b3e7455.png)

Do you have any explanation for the measurements after increment 32? The processor is a Xeon(R) Gold 6130 CPU @ 2.10GHz.
This is in reference to #4.  It makes direct use of perf events in Linux for measuring TLB misses, but also times each run.  Overall, the results I got seem to make sense and are outlined in the REAMDE.md, but there are a few cases that don't (like `./tlb-aliasing 2048 1` doesn't give close to 2048 misses per iteration, which I would expect in a 1024 entry TLB).

PTAL, thanks!
- [x] non-temporal stores
- [x] multiple threads saturating the memory bus
- [x] hardware prefetching with indexed accesses
- [x] floating point handling (denormals etc.)
- [x] 4k aliasing
- [x] store buffer capacity
- [ ] instruction cache misses
- [ ] TLB misses
- [ ] more multithreading examples (lock contention etc.)
- [ ] vector instructions
- [ ] critical word load
- [ ] CUDA examples