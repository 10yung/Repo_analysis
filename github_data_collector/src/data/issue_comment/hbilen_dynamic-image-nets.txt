Love the work, I am just having difficulty understanding the architecture for the SI + DI model.
From what I see in the architecture of the resnext.mat model,  the model uses a temporal max pooling layer just before the softmax layer. It says the input to the temporal max pooling layer are the merged conv7 features and Video2. I am assuming the merged conv7 features come from running the dynamic image through the ResNext model. Where does the Video2 come from?
Are we supposed to pass the whole video or just a single frame from the video clip?
 I am a newcomer to programming. After the fifth step, I want to compute approximate dynamic images and get the dynamic image, but I didn't find the relevant code.  I don't know what to do next. Thank you for your help.
Hi, I have two questions to ask youï¼Œthanks
1. How to extract the optical flow diagram
2. How to combine SI+DI+OF+DOF to get 95% accuracy
I am trying to train own data using your model. My dataset contains 29398 folders, each of which has 11 frames. There are two classes: normal and abnormal. I wrote the custom sepup_data.m for it. When I run main_train.m, some errors occurred as follow. How can I solve it? Will I need to change the parameters of architecture to fit this dataset? Thanks for your time!
![screenshot from 2018-06-14 11-22-24](https://user-images.githubusercontent.com/32732328/41389810-6c4d4500-6fc5-11e8-9d15-b292c6e96ab9.png)
