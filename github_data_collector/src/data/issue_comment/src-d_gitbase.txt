Hey,

when I try to run the following example in the db

```
SELECT repository_id, file_path,
       JSON_UNQUOTE(JSON_EXTRACT(bl, "$.linenum")),
       JSON_UNQUOTE(JSON_EXTRACT(bl, "$.author")),
       JSON_UNQUOTE(JSON_EXTRACT(bl, "$.text"))
FROM   (SELECT repository_id, file_path,
               EXPLODE(BLAME(repository_id, commit_hash, file_path)) AS bl
        FROM   ref_commits
               NATURAL JOIN blobs
               NATURAL JOIN commit_files
        WHERE  ref_name = 'HEAD'
               AND NOT IS_BINARY(blob_content)
        ) as p
WHERE  JSON_EXTRACT(bl, "$.text") LIKE '%// TODO%';
```
I get the following error

```
ERROR 1105 (HY000): unknown error: A function: 'blame' not found.
```

I'm new to source{d} and using the community edition. Could you guys point me in the right direction. For some reason ```SHOW FUNCTION STATUS```is working either so I'm having problems debugging this.

```
MySQL [gitbase]> select blob_hash, repository_id from blobs natural join repositories where blob_hash in ('93ec5b4525363844ddb1981adf1586ebddbc21c1', 'aad34590345310fe813fd1d9eff868afc4cea10c', 'ed82eb69daf806e521840f4320ea80d4fe0af435');
+------------------------------------------+-------------------------------------+
| blob_hash                                | repository_id                       |
+------------------------------------------+-------------------------------------+
| aad34590345310fe813fd1d9eff868afc4cea10c | github.com/bblfsh/javascript-driver |
| ed82eb69daf806e521840f4320ea80d4fe0af435 | github.com/src-d/enry               |
| aad34590345310fe813fd1d9eff868afc4cea10c | github.com/bblfsh/python-driver     |
| 93ec5b4525363844ddb1981adf1586ebddbc21c1 | github.com/src-d/go-mysql-server    |
| aad34590345310fe813fd1d9eff868afc4cea10c | github.com/bblfsh/ruby-driver       |
| ed82eb69daf806e521840f4320ea80d4fe0af435 | github.com/src-d/gitbase            |
+------------------------------------------+-------------------------------------+
6 rows in set (14.90 sec)

MySQL [gitbase]> select blob_hash, repository_id from blobs where blob_hash in ('93ec5b4525363844ddb1981adf1586ebddbc21c1', 'aad34590345310fe813fd1d9eff868afc4cea10c', 'ed82eb69daf806e521840f4320ea80d4fe0af435');
+------------------------------------------+-------------------------------------+
| blob_hash                                | repository_id                       |
+------------------------------------------+-------------------------------------+
| aad34590345310fe813fd1d9eff868afc4cea10c | github.com/bblfsh/python-driver     |
| aad34590345310fe813fd1d9eff868afc4cea10c | github.com/bblfsh/javascript-driver |
| ed82eb69daf806e521840f4320ea80d4fe0af435 | github.com/src-d/enry               |
| aad34590345310fe813fd1d9eff868afc4cea10c | github.com/bblfsh/ruby-driver       |
| 93ec5b4525363844ddb1981adf1586ebddbc21c1 | github.com/src-d/gitbase            |
| ed82eb69daf806e521840f4320ea80d4fe0af435 | github.com/src-d/gitbase            |
| 93ec5b4525363844ddb1981adf1586ebddbc21c1 | github.com/src-d/go-mysql-server    |
| ed82eb69daf806e521840f4320ea80d4fe0af435 | github.com/src-d/go-mysql-server    |
+------------------------------------------+-------------------------------------+
8 rows in set (0.13 sec)
```

also note that removing the natural join makes things go much faster- it was my understanding that normally we want to join with repositories to benefit from some specific optimizations (although I'm guessing that filtering with blob_hash makes those optimizations moot).
In gitbase 0.20 schema introspection is fast and full.

MySQL Connector/J JDBC metadata call that gets all columns for all tables at once
`metaData.getColumns("gitbase", "", "%", "%")`
is converted to calls like the following for each table
```SHOW FULL COLUMNS FROM `commit_trees` FROM `gitbase` LIKE '%'"```

In 0.23 and 0.24-rc the above queries are very slow (several minutes) and even fail for some tables completely in 0.23 (0.24 seems to fix that).

The above prevents from using gitbase in DB tools like JetBrains DataGrip.


The previous version was unable to bold the second-level title
I keep getting `unknown error: object not found` but there are no logs about this error for debugging.

Example:
```
$ docker exec -it 8633920ca611 mysql
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 50
Server version: 5.5.10-Vitess

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MySQL [(none)]> SELECT commit_author_name FROM commits;
ERROR 1105 (HY000): unknown error: object not found
```

But all I see in the logs:
```
time="2019-07-02T13:47:04Z" level=debug msg="executing query" query="SELECT commit_author_name FROM commits"
time="2019-07-02T13:47:04Z" level=info msg="audit trail" action=authorization address="127.0.0.1:60092" connection_id=50 permission=read pid=422 query="SELECT commit_author_name FROM commits" success=true system=audit user=root
time="2019-07-02T13:47:05Z" level=info msg="audit trail" action=query address="127.0.0.1:60092" connection_id=50 duration=1.7181277s err="object not found" pid=422 query="SELECT commit_author_name FROM commits" success=false system=audit user=root
```
I tried adding Gitbase as a MySQL database to metabase but unfortunately it got stuck trying to connect over and over again asking for some variables that weren't supported. 

This doesn't have high priority but would be a nice addition to make work. 
Error on gitbase side:
```
gsc-gitbase                        | time="2019-04-26T08:22:34Z" level=info msg="NewConnection: client 1"
gsc-gitbase                        | time="2019-04-26T08:22:34Z" level=error msg="Cannot parse client handshake response from client 1 (172.19.0.4:59740): Code: INTERNAL\nparseClientHandshakePacket: can't read connection attribute value\n"
```
Error from the client side:
```
gsc-gitbase-spark-connector-jupyter | Exception in thread "main" java.sql.SQLNonTransientConnectionException: Could not connect to gitbase:3306 : unexpected end of stream, read 0 bytes from 4 (socket was closed by server)
gsc-gitbase-spark-connector-jupyter |   at org.mariadb.jdbc.internal.util.exceptions.ExceptionMapper.get(ExceptionMapper.java:234)
gsc-gitbase-spark-connector-jupyter |   at org.mariadb.jdbc.internal.util.exceptions.ExceptionMapper.getException(ExceptionMapper.java:165)
gsc-gitbase-spark-connector-jupyter |   at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.connectWithoutProxy(AbstractConnectProtocol.java:1199)
gsc-gitbase-spark-connector-jupyter |   at org.mariadb.jdbc.internal.util.Utils.retrieveProxy(Utils.java:560)
gsc-gitbase-spark-connector-jupyter |   at org.mariadb.jdbc.MariaDbConnection.newConnection(MariaDbConnection.java:174)
...
```
Only happening with the latest v0.20.0-beta4 release
```sql
SELECT uast_extract(
    uast(blob_content, 'csharp', "(//csharp:BinaryExpression_AddExpression/Left/uast:String | //csharp:InterpolatedStringExpression//csharp:InterpolatedStringTextToken[1])[starts-with(normalize-space(@Value), 'SELECT') or starts-with(normalize-space(@Value), 'select') or starts-with(normalize-space(@Value), 'UPDATE') or starts-with(normalize-space(@Value), 'update') or starts-with(normalize-space(@Value), 'DELETE') or starts-with(normalize-space(@Value), 'delete') or starts-with(normalize-space(@Value), 'INSERT') or starts-with(normalize-space(@Value), 'insert') or starts-with(normalize-space(@Value), 'CREATE') or starts-with(normalize-space(@Value), 'create') or starts-with(normalize-space(@Value), 'ALTER') or starts-with(normalize-space(@Value), 'alter') or starts-with(normalize-space(@Value), 'DROP') or starts-with(normalize-space(@Value), 'drop')]"),
    '@pos') AS positions,
    repository_id,
    file_path
FROM (
    SELECT f.repository_id,
        f.file_path,
        b.blob_content
    FROM (
        SELECT *
        FROM refs r
        NATURAL JOIN commit_blobs cb
        NATURAL JOIN blobs
        WHERE r.ref_name = 'HEAD'
            AND NOT IS_BINARY(blob_content)
    ) b
    INNER JOIN (
        SELECT repository_id, file_path, blob_hash
        FROM refs r
        NATURAL JOIN commit_files cf
        WHERE r.ref_name = 'HEAD'
    ) f
    ON b.blob_hash = f.blob_hash
        AND b.repository_id = f.repository_id
    WHERE language(f.file_path, b.blob_content) = 'C#'
) t
WHERE positions IS NOT NULL
```

This could be parallelized adding an exchange over the topmost projection. Instead, we do this serially, causing extremely low performance on queries using uast functions on the topmost projects under certain conditions.
discovered at https://github.com/src-d/empathy-sessions/issues/37

_considering the old https://github.com/src-d/gitbase/issues/361#issuecomment-401838421, I'm not sure if you already discarded the interoperability with MySQL Workbench, so feel free to direct close if it makes no sense at all_ :dagger: 

I tried to connect to `gitbase` using [MySQL Workbench 6.3](https://dev.mysql.com/downloads/workbench) (even it's not explicitly supported by `gitbase`) and I found some issues that made Workbench to crash:

- `current_user()` is not supported
- `show status` is not supported
- `show engines` is not supported

I could mock data for all of them in local `gitbase`, and doing so Workbench was able to start with a warning:

```
Incompatible/nonstandard server version or connection protocol detected ().

A connection to this database can be established but some MySQL Workbench features may not work
properly since the database is not fully compatible with the supported versions of MySQL.

MySQL Workbench is developed and tested for MySQL Server versions 5.1, 5.5, 5.6 and 5.7

> Continue anyway           > Abort 
```

If you continue :wink: , Workbench opens the pannel with the connection, but there is no tables shown in the left panel, plus a log:
```sql
# 15:32:31  Error loading schema content
#           Error Code: 0
#           MySQL_ResultSet::getString: invalid value of 'columnIndex'
```

And fetching commits also fails:
```sql
select * from commits
# 15:35:27  select * from commits LIMIT 0, 10
#           Fetching...
# 15:35:27  select * from commits LIMIT 0, 10
#           Error Code: 0
#           0) . Please reportn charsetnr (
```

I wonder if you could give some hint to let someone work on this during some OSD :thinking: ... or just discourage it if you see it an impossible thing.
Right now, since 1 partition means 1 repository, we know joins (by repository) can only happen in the same partition.
Instead, we iterate and try to join with all of the partitions together.

Imagine we have 3 partitions.

These are the rows returned by each partition in the left side of a join.
- P1: 45
- P2: 5
- P3: 50

These are the rows returned by each partition in the right side of a join.
- P1: 55
- P2: 15
- P3: 30

We are joining 100 rows with 100 rows, which produces 10000 rows, that are then filtered by the join conditions (but we still make those 10k iterations).

Instead, if we did this per partition, these would be the produced rows (then filtered by conditions):

- P1: 2475
- P2: 75
- P3: 1500

The total amount of rows produced is 4050 rows, which is a 40% of the number of rows generated before. This number grows enormously as the number of partitions and rows grow.

What could we do?

A rule that runs at the end of the analysis and transforms joins (the ones left after the squash) into something like:

```
Concat
 |- InnerJoin
    |- PartitionTable(TableA)
    |- PartitionTable(TableB)
```

PartitionTable is a table that will only return the rows for one partition.
Concat is a node that will iterate over all partitions and transform all its `Table` children into `PartitionTable`. Then, all the rows of each partition will be put together and returned to the user. This will also happen in parallel.
Essentially, Concat is like an Exchange. The only thing it differs is the fact that it can handle binary nodes and not only unary nodes. This is something that cannot be done in go-mysql-server but can be done here, since we know for certain that partitions are the same for each table.

Called it Concat but the name is pretty lame so we should think of a better name, like PartitionExchange, BinaryExchange or something like that.

This should make (not squashed) joins —and in a real life applications you will have many of them because leaves will be subqueries— much much faster.