function stat_abline() doesn't work anymore in ggplot2, updating it to geom_abline()
`> spam.path <- file.path("C:\\03-Classification\\data", "spam")
> spam2.path <- file.path("C:\\03-Classification\\data", "spam_2")
> easyham.path <- file.path("C:\\03-Classification\\data", "easy_ham")
> easyham2.path <- file.path("C:\\03-Classification\\data", "easy_ham_2")
> hardham.path <- file.path("C:\\03-Classification\\data", "hard_ham")
> hardham2.path <- file.path("C:\\03-Classification\\data", "hard_ham_2")
> x <- runif(1000, 0, 40)
> y1 <- cbind(runif(100, 0, 10), 1)
> y2 <- cbind(runif(800, 10, 30), 2)
> y3 <- cbind(runif(100, 30, 40), 1)
> val <- data.frame(cbind(x, rbind(y1, y2, y3)),
+                   stringsAsFactors = TRUE)
> ex1 <- ggplot(val, aes(x, V2)) +
+   geom_jitter(aes(shape = as.factor(V3)),
+                   position = position_jitter(height = 2)) +
+   scale_shape_discrete(guide = "none", solid = FALSE) +
+   geom_hline(aes(yintercept = c(10,30)), linetype = 2) +
+   theme_bw() +
+   xlab("X") +
+   ylab("Y")
> ggsave(plot = ex1,
+        filename = file.path("C:\\03-Classification\\images", "00_Ex1.pdf"),
+        height = 10,
+        width = 10)
**Error in grDevices::pdf(..., version = version) : 
  cannot open file 'C:\03-Classification\images/00_Ex1.pdf'**

ggsave(plot = ex1,
+        filename = file.path("C:\\03-Classification\\images\\00_Ex1.pdf"),
+  		 height = 10,
+        width = 10)
**Error: Aesthetics must be either length 1 or the same as the data (1000): yintercept**

> getwd()
[1] "C:/Users/mm/Documents"

`

The problem lies in the ggplot function scale_x_date. In the original code this is coded as:
```
quick.hist <- ggplot(ufo.us, aes(x = DateOccurred)) +
  geom_histogram() + 
  scale_x_date(breaks = "50 years")
```
The breaks in scale_x_date has been adjusted to date_breaks. If you adjust the code to the following it works.

```
quick.hist <- ggplot(ufo.us, aes(x = DateOccurred)) +
  geom_histogram() + 
  scale_x_date(date_breaks = "50 years", date_labels = "%Y")
```
```

library(tm)
library(ggplot2)

#tm is the text mining package of R
#ggplot is for visualization
#there are 2 sets of files for each type of mail and one will be used for training while other will be for testing

spam.path<-"data/spam/"
spam2.path<-"data/spam_2/"
easyham.path<-"data/easy_ham/"
easyham2.path<-"data/easy_ham_2/"
hardham.path<-"data/hard_ham//"
hardham2.path<-"data/hard_ham_2/"

get.msg<-function(path){
  print(path)
  connection<-file(path,open="rt", encoding="Latin1")
  
  text<-readLines(connection)
  #the message begins after a full line break
   
  t<-which(text=="")[1]+1
  print(length(text))
  print(t)
  msg<-text[seq(t, length(text))]
 #print(msg) 
 
  close(connection)
  return (paste(msg, collapse="\n"))
  
}

#tdm=term document matrix

get.tdm<-function(doc.vec){
  doc.corpus<-Corpus(VectorSource(doc.vec))
  control<-list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE, minDocFreq=2)
  doc.dtm<-TermDocumentMatrix(doc.corpus, control)
  return (doc.dtm)
  
}



# create a vector of emails
#use apply function

spam.docs<-dir(spam.path)
#this returns a list of file names in the directory
spam.docs<-spam.docs[seq(1,length(spam.docs)-1)]
#spam.docs<-spam.docs[which(spam.docs!="")]
#cmds file is a UNIX file which we dont need
#spam.docs<-spam.docs[!startsWith(spam.docs, "cmds")]

all.spam<-sapply(spam.docs, function(p) get.msg(paste(spam.path,p, sep="")))

spam.tdm<-get.tdm(all.spam)

#use the command below for inspection
#head(all.spam)
#z<-TermDocumentMatrix(Corpus(VectorSource(all.spam)), list(stopwords=TRUE, removeNumbers=TRUE, removePunctuation=TRUE, minDocFreq=2))

spam.matrix<- as.matrix(spam.tdm)
spam.counts<-rowSums(spam.matrix)
spam.df<-data.frame(cbind(names(spam.counts), as.numeric(spam.counts)), stringAsFactors=FALSE)
names(spam.df)<-c("term", "frequency")
spam.df$frequency<-as.numeric(spam.df$frequency)
spam.occurence<-sapply(1:nrow(spam.matrix)
                       , function(i){
                          length(which(spam.matrix[i,]>0))/ncol(spam.matrix)
                       })
spam.density<-spam.df$frequency/sum(spam.df$frequency)
spam.df<-transform(spam.df, density=spam.density, occurence=spam.occurence)

head(spam.df[with(spam.df,order(-occurence)), ])
#constructuon of Ham dataset













easy_ham.docs<-dir(easyham.path)
#this returns a list of file names in the directory
easy_ham.docs<-easy_ham.docs[seq(1,500)]
#spam.docs<-spam.docs[which(spam.docs!="")]
#cmds file is a UNIX file which we dont need
#spam.docs<-spam.docs[!startsWith(spam.docs, "cmds")]

all.easy_ham<-sapply(easy_ham.docs, function(p) get.msg(paste(easyham.path,p, sep="")))

easy_ham.tdm<-get.tdm(all.easy_ham)


#use the command below for inspection
#head(all.spam)
#z<-TermDocumentMatrix(Corpus(VectorSource(all.spam)), list(stopwords=TRUE, removeNumbers=TRUE, removePunctuation=TRUE, minDocFreq=2))

easy_ham.matrix<- as.matrix(easy_ham.tdm)
easy_ham.counts<-rowSums(easy_ham.matrix)
easy_ham.df<-data.frame(cbind(names(easy_ham.counts), as.numeric(easy_ham.counts)), stringAsFactors=FALSE)
names(easy_ham.df)<-c("term", "frequency")
easy_ham.df$frequency<-as.numeric(easy_ham.df$frequency)
easy_ham.occurence<-sapply(1:nrow(easy_ham.matrix)
                       , function(i){
                         length(which(easy_ham.matrix[i,]>0))/ncol(easy_ham.matrix)
                       })
easy_ham.density<-easy_ham.df$frequency/sum(easy_ham.df$frequency)
easy_ham.df<-transform(easy_ham.df, density=easy_ham.density, occurence=easy_ham.occurence)
easy_ham.df$NA.<-NULL
head(easy_ham.df[with(easy_ham.df,order(-occurence)), ])


#Classification function

classify.email<-function(path, training.df, prior=0.5, c=1e-6){
  msg<-get.msg(path)
  msg.tdm<-get.tdm(msg)
  msg.freq<-rowSums(as.matrix(msg.tdm))
  #Find intersection of words
  msg.match<-intersect(names(msg.freq), training.df$term)
  if(length(msg.match)<1){
    return (prior*c^(length(msg.freq)))
    
  }
  else{
    match.probs<-training.df$occurence[match(msg.match, training.df$term)]
    return (prior*prod(match.probs) * c^(length(msg.freq)-length(msg.match)))
  }
}





hardham.docs<-dir(hardham.path)
hardham.docs<-hardham.docs[seq(1:length(hardham.docs))]

hardham.spamtest<-sapply(hardham.docs, function(p) classify.email(paste(hardham.path,p, sep=""), 
                                                                  training.df = easy_ham.df))

hardham.hamtest<-sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep=""), training.df = easy_ham.df))

hardham.res<-ifelse(hardham.spamtest>hardham.hamtest, TRUE, FALSE)
summary(hardham.res)

```
This code only returns false for all values
Hola! @fpcMotif has created a [ZenHub](http://www.zenhub.com) account for the **johnmyleswhite** organization. ZenHub is the only project management tool integrated natively in GitHub – created specifically for fast-moving, software-driven teams.

----

#### How do I use ZenHub?

To get set up with ZenHub, all you have to do is **[download the browser extension](https://www.zenhub.com?utm_source=ZHOnboarding)** and log in with your GitHub account. Once you do, you’ll get access to ZenHub’s complete feature-set immediately.

#### What can ZenHub do?

ZenHub adds a series of enhancements directly inside the GitHub UI:

- Real-time, customizable task boards for GitHub issues;
- Multi-Repository burndown charts, estimates, and velocity tracking based on GitHub Milestones;
- Personal to-do lists and task prioritization;
- Time-saving shortcuts – like a quick repo switcher, a “Move issue” button, and much more.

### [Add ZenHub to GitHub](https://www.zenhub.com?utm_source=ZHOnboarding)

_Still curious? See [more ZenHub features](https://www.zenhub.com/features?utm_source=ZHOnboarding) or read [user reviews](https://chrome.google.com/webstore/detail/zenhub-for-github/ogcgkffhplmphkaahpmffcafajaocjbd/reviews). This issue was written by your friendly ZenHub bot, posted by request from @fpcMotif._

![ZenHub Board](https://cloud.githubusercontent.com/assets/8771909/11153956/233ac4a8-89f1-11e5-94b1-1569d3f38b4d.png)

`data.dtm` -> `data.tdm`

the code are running from Rstudio with  R 3.3.0 under osx 10.11

issue 1: 

line 48 in email_classify.R:

> geom_hline(aes(yintercept = c(10,30)), linetype = 2) 

yintercept need to be put outside aes function , like this : 

> geom_hline(yintercept = c(10,30), linetype = 2) 

issue 2: 

error occurs when reading msg by sapply   at line 139-140 .. 

> all.spam <- sapply(spam.docs,
>                    function(p) get.msg(file.path(spam.path, p)))

here is the traceback

>  Error in seq.default(which(text == "")[1] + 1, length(text), 1) : 
>   'from' cannot be NA, NaN or infinite 
> 7 stop("'from' cannot be NA, NaN or infinite") 
> 6 seq.default(which(text == "")[1] + 1, length(text), 1) 
> 5 seq(which(text == "")[1] + 1, length(text), 1) 
> 4 get.msg(file.path(spam.path, p)) 
> 3 FUN(X[[i]], ...) 
> 2 lapply(X = X, FUN = FUN, ...) 
> 1 sapply(spam.docs, function(p) get.msg(file.path(spam.path, p))) 

seems some file does not have a blank line

In the following sentence,  strsplit won't feedback a error when no comma in ufo$Location. 
As a result, we cannot  extract the  "'City, State'"  from "City" by the trycatch-strsplit method.

split.location <- tryCatch(strsplit(l, ",")[[1]],
                             error = function(e) return(c(NA, NA)))

Suggest to revised to:

get.location<-function(l)
  {
  split.location<-strsplit(l,",")[[1]] 
  clean.location <- gsub("^ ","",split.location)
  if(length(clean.location)!=2)
    {
    return(c(NA,NA))
  }
  else
  {
    return(clean.location)
  }
}
