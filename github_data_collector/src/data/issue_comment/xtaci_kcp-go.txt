我要获取到链接的fd，然后对其进行处理，请问有什么方法获取fd
Some requirements may need to specify a local address, such as intranet penetration
https://github.com/xtaci/kcp-go/blob/2ed35ac44d08fb50259b1e2a97da23b2be02c6c0/sess.go#L792

@xtaci 这里使用 ip+端口 来索引 session，在特定情况下可能出现冲突：因为 udp 没法感知到对端退出，一般服务器会通过超时机制来关闭没有数据的session，这就意味着服务器的session在客户端退出以后还会维持住一段时间，如果在这段时间内，客户端重用了之前的端口发起新的连接，那么这里就会出现客户端连接不上的问题。这种现象在压测的时候还比较常见。请问这种问题如何解决呢？有没有考虑将 conv 加入 sessionkey？
Hi, most go packages have supported go mod.
It will be great if kcp-go supports it.
When using congestion control, packets continued to be queued up far past the congestion window, all the way to the send window. This cause extreme bufferbloat when congestion control is enabled.

Pull request #140 fixes this issue.
This prevents massive "bufferbloat" when the send window is large but the congestion window is not. It makes KCP with congestion control a *lot* more usable.
这个函数是连接的意思吧，里面怎么也是调用的 net.ListenUDP 方法？
我profile看了下 是卡在 sess.go:311 行。。
我自己用go语言实现了[iperf测速工具](https://github.com/ZezhongWang/iperf-go), 实现了基本的一些测速功能, 最主要的就是加上了对于自定义应用层协议的扩展, 所以也可以用来对kcp进行更精确地测速.因为 Fast.com 之类的还是涉及到了3个点的传输。

然后一个有趣的现象就是, 对于我自身的网络情况：

- PC: 广东某高校校园网, 时好时坏, 阿门~
- Server: Location: LA  Latency(Ping): 170ms 左右  搬瓦工 CN2, 号称百兆带宽
- KCP 版本:  May 8, 2019 最新版 ( go get 下来 )

在上行情况下，用适当的参数，确实 KCP 的表现会比 TCP 好一些，大约有40%-50%提升 ：

    // KCP 结果， 平均带宽在 17.69Mb/s 左右
    >.\iperf-go.exe -c <server_ip> -proto kcp -sw 512  // KCP 发送窗口512, 不开启FEC, 加密  
    09:55:23.790 0 ▶ INFO 001 Go-logging init finish
    Iperf started:
    addr:104.224.137.244    port:5201       proto:rudp      interval:1000   duration:10     NoDelay:false   burst:true      BlockSize:4096  StreamNum:1
    RUDP settting: sndWnd:512       rcvWnd:512      writeBufSize:4096Kb     readBufSize:4096Kb      noCongestion:true       flushInterval:10
    Connect to server 104.224.137.244:5201 succeed.
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)  Lost(%)  Early Retrans  Fast Retrans
    [  0] 0.00-1.00 sec      3.73 MB        29.81 Mb/s       165.0ms          11    0.39%   0.39%   0.00%   0.00%
    [  0] 1.00-2.00 sec      2.47 MB        19.78 Mb/s       169.0ms         600    31.84%  22.50%  9.34%   0.00%
    [  0] 2.00-3.00 sec      2.50 MB        20.03 Mb/s       166.0ms         356    18.66%  13.31%  5.35%   0.00%
    [  0] 3.00-4.00 sec      1.85 MB        14.78 Mb/s       169.0ms         844    59.94%  44.67%  15.27%  0.00%
    [  0] 4.00-5.00 sec      2.32 MB        18.56 Mb/s       165.0ms         606    34.27%  17.53%  16.74%  0.00%
    [  0] 5.00-6.00 sec      1.54 MB        12.34 Mb/s       174.0ms         922    78.41%  48.14%  30.28%  0.00%
    [  0] 6.00-7.00 sec      1.93 MB        15.41 Mb/s       199.0ms         852    58.06%  51.17%  6.88%   0.00%
    [  0] 7.00-8.00 sec      1.69 MB        13.50 Mb/s       167.0ms         499    38.80%  18.97%  19.83%  0.00%
    [  0] 8.00-9.00 sec      2.45 MB        19.56 Mb/s       183.0ms         842    45.19%  28.33%  16.85%  0.00%
    [  0] 9.00-10.04 sec     1.64 MB        13.16 Mb/s       181.0ms         996    79.48%  39.98%  39.50%  0.00%
    - - - - - - - - - - - - - - - - SUMMARY - - - - - - - - - - - - - - - -
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)  Lost(%)  Early Retrans  Fast Retrans
    [  0] 0.00-10.04 sec    22.12 MB        17.69 Mb/s       173.8ms        6528    38.73%  25.03%  13.71%  0.00%   [SENDER]

    // TCP 结果， 平均带宽在 12.10Mb/s 左右, 在发送端为windows系统的情况下拿不到 retrans 数据
    >.\iperf-go.exe -c 104.224.137.244 -proto tcp  
    09:56:23.161 0 ▶ INFO 001 Go-logging init finish
    Iperf started:
    addr:104.224.137.244    port:5201       proto:tcp       interval:1000   duration:10     NoDelay:false   burst:true      BlockSize:131072        StreamNum:1
    Connect to server 104.224.137.244:5201 succeed.
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)
    [  0] 0.00-1.00 sec      1.50 MB        12.00 Mb/s         0.0ms           0    0.00%
    [  0] 1.00-2.00 sec      5.38 MB        43.00 Mb/s         0.0ms           0    0.00%
    [  0] 2.00-3.01 sec      0.12 MB         1.00 Mb/s         0.0ms           0    0.00%
    [  0] 3.01-4.00 sec      0.00 MB         0.00 Mb/s         0.0ms           0    NaN%
    [  0] 4.00-5.00 sec      0.75 MB         6.00 Mb/s         0.0ms           0    0.00%
    [  0] 5.00-6.00 sec      2.62 MB        21.00 Mb/s         0.0ms           0    0.00%
    [  0] 6.00-7.00 sec      3.62 MB        29.00 Mb/s         0.0ms           0    0.00%
    [  0] 7.00-8.01 sec      0.12 MB         1.00 Mb/s         0.0ms           0    0.00%
    [  0] 8.01-9.00 sec      0.38 MB         3.00 Mb/s         0.0ms           0    0.00%
    [  0] 9.00-10.27 sec     0.62 MB         5.00 Mb/s         0.0ms           0    0.00%
    - - - - - - - - - - - - - - - - SUMMARY - - - - - - - - - - - - - - - -
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)
    [  0] 0.00-10.27 sec    15.12 MB        12.10 Mb/s         NaNms           0    0.00%   [SENDER]

但是在下行的情况下（TCP有BBR支持），TCP的表现则好很多，快有 KCP 的一倍。并且我也调整过KCP的一些参数，均未获得较好的效果（例如调整snd_wnd, buffer之类）

    // KCP 结果，大概在 8.05 Mb/s 左右（这还是经过几次尝试在比较好的结果下）
    
    >.\iperf-go.exe -c 104.224.137.244 -proto rudp -sw 512 –R (客户端）
    22:04:39.175 0 ▶ INFO 001 Go-logging init finish
    Server listening on 5201
    Accept connection from client: 221.4.34.225:42032
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)  Lost(%)  Early Retrans  Fast Retrans
    [  0] 0.00-1.00 sec	 1.23 MB	 9.84 Mb/s	 172.0ms	 713	76.04%	7.47%	68.57%	0.00%
    [  0] 1.00-2.00 sec	 0.99 MB	 7.91 Mb/s	 172.0ms	 956	126.94%	49.13%	77.81%	0.00%
    [  0] 2.00-3.00 sec	 0.96 MB	 7.69 Mb/s	 172.0ms	 766	104.60%	21.99%	82.62%	0.00%
    [  0] 3.00-4.00 sec	 0.84 MB	 6.75 Mb/s	 176.0ms	1201	186.79%	65.94%	120.84%	0.00%
    [  0] 4.00-5.00 sec	 0.95 MB	 7.59 Mb/s	 174.0ms	1125	155.53%	33.87%	121.66%	0.00%
    [  0] 5.00-6.00 sec	 1.30 MB	10.44 Mb/s	 174.0ms	 849	85.39%	36.21%	49.18%	0.00%
    [  0] 6.00-7.00 sec	 1.09 MB	 8.69 Mb/s	 173.0ms	 863	104.29%	48.34%	55.95%	0.00%
    [  0] 7.00-8.00 sec	 1.09 MB	 8.75 Mb/s	 172.0ms	 818	98.14%	34.91%	63.23%	0.00%
    [  0] 8.00-9.00 sec	 0.47 MB	 3.75 Mb/s	 171.0ms	 911	255.03%	106.10%	148.93%	0.00%
    [  0] 9.00-10.27 sec	 1.13 MB	 9.06 Mb/s	 180.0ms	1096	126.96%	65.10%	61.86%	0.00%
    - - - - - - - - - - - - - - - - SUMMARY - - - - - - - - - - - - - - - -
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)  Lost(%)  Early Retrans  Fast Retrans
    [  0] 0.00-10.27 sec	10.06 MB	 8.05 Mb/s	 173.6ms	9298	121.30%	42.56%	78.75%	0.00%	[SENDER]

    // TCP BBR结果, 大概在20.40Mb/s左右
    >.\iperf-go.exe -c 104.224.137.244 –R  (客户端)
    22:04:17.793 0 ▶ INFO 001 Go-logging init finish
    Server listening on 5201
    Accept connection from client: 221.4.34.225:22567
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)
    [  0] 0.00-1.00 sec	 1.50 MB	12.00 Mb/s	 172.6ms	   0	0.00%
    [  0] 1.00-2.00 sec	 3.12 MB	25.00 Mb/s	 169.1ms	   0	0.00%
    [  0] 2.00-3.00 sec	 2.75 MB	22.00 Mb/s	 205.3ms	 378	19.14%
    [  0] 3.00-4.00 sec	 2.00 MB	16.00 Mb/s	 164.8ms	1490	103.73%
    [  0] 4.00-5.00 sec	 4.75 MB	38.00 Mb/s	 162.9ms	 873	25.59%
    [  0] 5.00-6.00 sec	 1.25 MB	10.00 Mb/s	 163.3ms	   0	0.00%
    [  0] 6.00-7.00 sec	 2.50 MB	20.00 Mb/s	 163.3ms	   0	0.00%
    [  0] 7.00-8.00 sec	 2.62 MB	21.00 Mb/s	 163.5ms	   6	0.32%
    [  0] 8.00-9.00 sec	 2.38 MB	19.00 Mb/s	 162.7ms	   0	0.00%
    [  0] 9.00-10.19 sec	 2.50 MB	20.00 Mb/s	 163.1ms	   0	0.00%
    - - - - - - - - - - - - - - - - SUMMARY - - - - - - - - - - - - - - - -
    [ ID]    Interval        Transfer        Bandwidth        RTT      Retrans   Retrans(%)
    [  0] 0.00-10.19 sec	25.50 MB	20.40 Mb/s	 169.1ms	2747	0.15%	[SENDER]

通过其他参数可发现， KCP无论上行还是下行情况下丢包率都异常地高（30%，40%以上），再加上early resend的策略的话在下行的report中可以发现，重传的包量甚至已经超过了本身的包量（也就是说平均下来每个包都发了两次多）

这么来看在 UDP 上搭建可靠传输还是值得商榷的，这么高的丢包率可能与ISP对UDP流量的管制有关。

这里还想讨论的就是，

- 为什么上行下行丢包率会有这么大的差距？（KCP表现不好基本是由于丢包引起的）
- 对于这样的网络状况有没有什么优化策略？
- 然后我自己在 KCP 的基础上实现了 BBR 拥塞控制，包含了 pacing 和 cwnd 的调整策略，效果相较 KCP 有略微的提升（在丢包率和带宽上），但是依旧有较高的丢包率，感觉要摊手了 Orz

iperf-go 测试工具: https://github.com/ZezhongWang/iperf-go
欢迎使用！
