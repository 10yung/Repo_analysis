In the python `utils.py file`, the minimum components to analyze with PCA seems to be 1024. Why not use default sklearn setting PCA would use all 2800 samples, any reason to stick to 1024. This would also mean that if you have 1024+ samples(images ) you would always calculate the results only for 1024 PCs. Any reason for this choice? Am I missing something?  

I assume somewhere in the code there is stand-alone cvPCA function...  can you help me find it?
Thanks!
--
Dario

Hi,
thanks for making this data and code available. +1 for reproducible science!

In that spirit, I've run into a couple of easily fixable bugs in the code:

`loadproc2800.m` calls a function called `svdecon` that is not included in this repo . I've spotted that a function of that name is in `github.com/MouseLand/stringer-pachitariu-et-al-2018a/tree/master/utilities`, so I can see how this error came about. 

`fitGaborRFs` calls `gpuDevice` even if `useGPU` is set to 0, which gives out an error if cuda isn't installed. 

`estimageRFs` similarly calls `gpuArray` without checking if a gpu is available.

That's it (for now..!). 

All the best,

Mat 