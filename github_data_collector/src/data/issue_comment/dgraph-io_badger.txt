The test `TestL0Stall` and `TestL1Stall` would never fail because of error in the manifest file. This PR fixes it.

<!-- Reviewable:start -->
---
This change is [<img src="https://reviewable.io/review_button.svg" height="34" align="absmiddle" alt="Reviewable"/>](https://reviewable.io/reviews/dgraph-io/badger/1201)
<!-- Reviewable:end -->

<!-- Please answer these questions before submitting your issue. Thanks! -->

### What version of Go are you using (`go version`)?

<pre>
$ go version
go 1.13.6
</pre>

### What version of Badger are you using?
2

### Does this issue reproduce with the latest master?
probably

### What are the hardware specifications of the machine (RAM, OS, Disk)?
64GB ram, 1TB nvme

### What did you do?
used badger, probably ran out of disk space

<!--
If possible, provide a recipe for reproducing the error. A complete runnable program is good.
-->



### What did you expect to see?
no crashes


### What did you see instead?
```
unexpected fault address 0x7f7a96d5bb03
fatal error: fault
[signal SIGBUS: bus error code=0x2 addr=0x7f7a96d5bb03 pc=0x54e1b5]

goroutine 230 [running]:
runtime.throw(0x1c015dc, 0x5)
	/usr/lib/go/src/runtime/panic.go:774 +0x72 fp=0xc00055c948 sp=0xc00055c918 pc=0x51ca42
runtime.sigpanic()
	/usr/lib/go/src/runtime/signal_unix.go:391 +0x455 fp=0xc00055c978 sp=0xc00055c948 pc=0x532545
runtime.memmove(0xc01faf7300, 0x7f7a96d5a2b5, 0x18ce)
	/usr/lib/go/src/runtime/memmove_amd64.s:330 +0x3c5 fp=0xc00055c980 sp=0xc00055c978 pc=0x54e1b5
github.com/dgraph-io/badger/v2/y.SafeCopy(...)
	/home/why/go/pkg/mod/github.com/dgraph-io/badger/v2@v2.0.1/y/y.go:101
github.com/dgraph-io/badger/v2.(*Item).ValueCopy(0xc02064a420, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)
	/home/why/go/pkg/mod/github.com/dgraph-io/badger/v2@v2.0.1/iterator.go:129 +0x227 fp=0xc00055ca58 sp=0xc00055c980 pc=0xd183d7
github.com/ipfs/go-ds-badger2.(*txn).get(0xc00055cb78, 0xc020251c20, 0x4c, 0xc020251c20, 0xc020251c27, 0xc00055cb70, 0x45, 0x45)
	/home/why/go/pkg/mod/github.com/ipfs/go-ds-badger2@v0.0.0-20200108185345-7f650e6b2521/datastore.go:484 +0xe1 fp=0xc00055cac8 sp=0xc00055ca58 pc=0xd568a1
github.com/ipfs/go-ds-badger2.(*Datastore).Get(0xc02fa04180, 0xc020251c20, 0x4c, 0x0, 0x0, 0x0, 0x0, 0x0)
	/home/why/go/pkg/mod/github.com/ipfs/go-ds-badger2@v0.0.0-20200108185345-7f650e6b2521/datastore.go:277 +0x163 fp=0xc00055cba0 sp=0xc00055cac8 pc=0xd54ac3
github.com/ipfs/go-datastore/keytransform.(*Datastore).Get(0xc0002d6300, 0xc020251bd0, 0x45, 0xc020251bd0, 0x45, 0x3d, 0x3e, 0xc0204ea800)
	/home/why/go/pkg/mod/github.com/ipfs/go-datastore@v0.3.1/keytransform/keytransform.go:47 +0x76 fp=0xc00055cbf0 sp=0xc00055cba0 pc=0x9e2326
github.com/ipfs/go-datastore/keytransform.(*Datastore).Get(0xc0002d6320, 0xc0204ea840, 0x3e, 0xc0204ea840, 0x3e, 0x30, 0x20, 0x2a)
	/home/why/go/pkg/mod/github.com/ipfs/go-datastore@v0.3.1/keytransform/keytransform.go:47 +0x76 fp=0xc00055cc40 sp=0xc00055cbf0 pc=0x9e2326
github.com/ipfs/go-ipfs-blockstore.(*blockstore).Get(0xc0002d63e0, 0xc02995fa10, 0x26, 0x0, 0x0, 0x0, 0x0)
	/home/why/go/pkg/mod/github.com/ipfs/go-ipfs-blockstore@v0.1.1/blockstore.go:123 +0xaf fp=0xc00055cd10 sp=0xc00055cc40 pc=0x9e4d1f
github.com/ipfs/go-ipfs-blockstore.(*idstore).Get(0xc02f96fef0, 0xc02995fa10, 0x26, 0xc033347a70, 0xc02995f9b0, 0x26, 0xc02021db98)
	/home/why/go/pkg/mod/github.com/ipfs/go-ipfs-blockstore@v0.1.1/idstore.go:57 +0xd7 fp=0xc00055cd60 sp=0xc00055cd10 pc=0x9e6007
github.com/ipfs/go-ipfs-blockstore.(*gcBlockstore).Get(0xc000392a80, 0xc02995fa10, 0x26, 0x1f0f020, 0xc033347b00, 0x0, 0x0)
	<autogenerated>:1 +0x50 fp=0xc00055cda8 sp=0xc00055cd60 pc=0x9e6d70
github.com/ipfs/go-bitswap/decision.(*Engine).nextEnvelope(0xc02fa04c00, 0x1f0eca0, 0xc02fa5e480, 0x1, 0x0, 0x0)
	/home/why/go/pkg/mod/github.com/ipfs/go-bitswap@v0.1.8/decision/engine.go:206 +0x2c2 fp=0xc00055cee0 sp=0xc00055cda8 pc=0xe63582
github.com/ipfs/go-bitswap/decision.(*Engine).taskWorker(0xc02fa04c00, 0x1f0eca0, 0xc02fa5e480)
	/home/why/go/pkg/mod/github.com/ipfs/go-bitswap@v0.1.8/decision/engine.go:176 +0x1bd fp=0xc00055cfc8 sp=0xc00055cee0 pc=0xe6324d
runtime.goexit()
	/usr/lib/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc00055cfd0 sp=0xc00055cfc8 pc=0x54cc41
created by github.com/ipfs/go-bitswap/decision.NewEngine
	/home/why/go/pkg/mod/github.com/ipfs/go-bitswap@v0.1.8/decision/engine.go:128 +0x3bb
```

The rest of the software does a good job of handling the case where the system runs out of disk space, but badger seems to not deal with it that well. If we could get errors returned instead of faulting like this that would be fine.
In the current implementation, if you happen to always have at least one write transaction open the memory usage of the transaction oracle is unbounded. It is actually relatively easy to hit when batch importing data. If you have more than one `WriteBatch` active during the import the transaction oracle will never be cleaned up.

This is a RFC on an approach to fix this. The core idea is to:

* Avoid increasing contention on purely read transactions; so only clean up the transaction oracle when write transactions are committed even if technically we could free memory sooner;
* Split the big `oracle.commit` map into one map per previously committed transaction; (this allows Go to release memory sooner than when performing deletes on a single map);
* Take advantage of the fact that we have acquired the oracle lock in `oracle.newCommitTs` to do the cleanup

I am assuming here that the number of committed-but-still-tracked transactions is small, which makes an implementation based on a simple slice reasonable. If that's not the case we will need some form of a sorted data-structure (i.e. a b-tree) here.

Comments welcome.

<!-- Reviewable:start -->
---
This change is [<img src="https://reviewable.io/review_button.svg" height="34" align="absmiddle" alt="Reviewable"/>](https://reviewable.io/reviews/dgraph-io/badger/1198)
<!-- Reviewable:end -->

Travis build randomly fails with 
```
=== RUN   TestPagebufferReader2
--- FAIL: TestPagebufferReader2 (0.00s)
    y_test.go:185: 
        	Error Trace:	y_test.go:185
        	Error:      	Received unexpected error:
        	            	EOF
        	Test:       	TestPagebufferReader2
        	Messages:   	unable to read error
=== RUN   TestPagebufferReader3
--- PASS: TestPagebufferReader3 (0.00s)
=== RUN   TestPagebufferReader4
--- PASS: TestPagebufferReader4 (0.00s)
FAIL
coverage: 19.9% of statements
FAIL	github.com/dgraph-io/badger/y	0.022s

```
see https://travis-ci.org/dgraph-io/badger/jobs/636936684#L9192

I've seen the test fail multiple times on various PRs.
`Coverall.io` integration fails frequently which leads to a failed build. We should remove it.

See example build https://travis-ci.org/dgraph-io/badger/jobs/636936733?utm_medium=notification&utm_source=github_status

https://github.com/dgraph-io/badger/blob/5870b7b1975e031549f8a3d4309335f6b03f0fa4/.travis.yml#L24-L29
<!-- Please answer these questions before submitting your issue. Thanks! -->

### What version of Go are you using (`go version`)?

<pre>
$ go version
go1.13.5
</pre>

### What version of Badger are you using?

`2.0.1`

### Does this issue reproduce with the latest master?

yes


### What do you expect to see?

Hi, we are evaluating to migrate from embedded SQLCipher to Badger. As I understand Badger can enable AES encryption using ` Options.EncrpytionKey`.

Is it envisaged to add modern encryption algorithms as an option, like `XChaCha20Poly1305`?

According to cryptographers (https://latacora.singles/2018/04/03/cryptographic-right-answers.html) it's far better than AES for multiple reasons, the number one being it's simplicity.
Badger uses [`eventLog`](https://godoc.org/golang.org/x/net/trace#EventLog) to keep track of long-running background operations.
 https://github.com/dgraph-io/badger/blob/2a90c665f1e57fdc48256f222ed5d826c554043c/levels.go#L38-L42

https://github.com/dgraph-io/badger/blob/2a90c665f1e57fdc48256f222ed5d826c554043c/value.go#L828-L832

These `eventLogs` are expensive as seen in https://github.com/dgraph-io/badger/issues/938#issuecomment-513964707

All the trace/eventlog calls should be replaced with `logger.Debugf(...)` statements.
Level 15 is very slow for any practical use of badger. This PR reduces the compression level from 15 to 1 (1 is the fastest level)

```
no_compression-16              10	 502848865 ns/op	 165.46 MB/s
zstd_compression/level_1-16     7	 739037966 ns/op	 112.58 MB/s
zstd_compression/level_3-16     7	 756950250 ns/op	 109.91 MB/s
zstd_compression/level_15-16    1	11135686219 ns/op	   7.47 MB/s
```

<!-- Reviewable:start -->
---
This change is [<img src="https://reviewable.io/review_button.svg" height="34" align="absmiddle" alt="Reviewable"/>](https://reviewable.io/reviews/dgraph-io/badger/1191)
<!-- Reviewable:end -->

<!-- Please answer these questions before submitting your issue. Thanks! -->

### What version of Go are you using (`go version`)?
1.12.3

### What version of Badger are you using?
2.0.0

### What are the hardware specifications of the machine (RAM, OS, Disk)?
CoreOS Stable, 10gb ram for this service ( 128gb ram total ), RAID0 2tb samsung SSDs

### The issue
The disk writes are normal and consistent when writing data to the DB. However the disk reads spike dramatically ( I believe this is due to running the compactions & GC ). All of our data has a 48hr TTL.

My question: Is there anything we can do to cut down on the disk reads. It is negatively impacting other services which are running on this machine. We are currently running GC every 5min. Would changing the max levels or anything else relieve this pressure? Even if it takes up more space on disk. 

Thanks,
Move all access to `valueLog.maxFid` under `valueLog.filesLock`, while all mutations happen either with writes stopped or sequentially under `valueLog.write`.

Fixes a concurrency issue in `valueLog.Read` where the `maxFid` variable and the `writableLogOffset` variable could point to two different log files.

Fixes #1184 as a side effect.

<!-- Reviewable:start -->
---
This change is [<img src="https://reviewable.io/review_button.svg" height="34" align="absmiddle" alt="Reviewable"/>](https://reviewable.io/reviews/dgraph-io/badger/1187)
<!-- Reviewable:end -->
