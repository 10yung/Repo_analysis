Problem

bijection-core version is out of date, and there is no 2.13 release for the current version.

Solution

Update bijection-core version to 0.9.7

Result

Bijection-core dependency can be cross-built for 2.13
Problem

No cross-build for finagle-opencensus-tracing 2.13

Solution

include 2.13 in finagle-opencensus-tracing cross versions.
Problem

No cross-build for finagle-stats 2.13 and finagle-stats-core 2.13


Solution

include 2.13 in finagle-stats and finagle-stats-core cross versions.


Problem

B3Format is currently the only propagation method we can use.
Invalid or missing propagation headers result in a 500
response.

Solution

raised opencensusVersion in build.sbt to "0.24.0"

added optional TextFormat parameter to the withOpenCensusTracing for both Server
and Client that defaults to previously used B3Format

in StackServerOps.scala previous version seemed to expect SpanContext.INVALID as
a failure result from TextFormat.extract, which was incorrect.  This resulted in
missing or invalid propagation headers causing a 500 response.
TextFormat.extract throws an exception on bad or missing data, which is now
treated as SpanContext.INVALID

added a test dependency to opencensus-contrib-http-util which provides an
implementation of TextFormat for stackdriver style "x-cloud-trace-context"
headers.

added copy of existing test that uses the CloudTraceFormat from
opencensus-contrib-http-util

Result

You can now use other forms of tracing header propagation, i.e. the
CloudTraceFormat format from the opencensus-contrib-http-util package.
When 2.13 rolls around, performance should be considered. See https://github.com/twitter/finagle/pull/797#issuecomment-561329004

### Expected behavior

The same performance as 2.12

### Actual behavior

So far mostly unknown

### Discussion

From Scala 2.12 to 2.13 `scala.Seq` changed from an alias to `scala.collection.Seq` to `scala.collection.immutable.Seq`. In many places in finagle, Seqs are built up and returned through  `ArrayBuffer`'s, which are 2.12 `scala.Seq`s but not 2.13 `scala.Seq`'s. Returning these as `scala.Seq` is 0 cost in scala 2.12, but carries a significant cost in 2.13.

An attempted solution for this problem by using an `ArraySeq.newBuilder` and returning the `result` showed a significant and unacceptable performance degradation on 2.12. It's suspected that the degradation of `ArrayBuffer.toSeq` is going to be even worse on 2.13.

Some plausible solutions that could be tested on how they affect performance between 2.12 and 2.13 are

* Using a ListBuilder and returning a List. This is will not invoke any copying, but the resulting collection is not indexed.
* Using a custom builder around an Array that is cool with some unpruned slack space. Returning it as a Seq should be as cheap as wrapping it, and the slack space problem is also present in the mutable collection.
* Returning a `scala.collection.Seq` instead of a `scala.Seq`. This makes the mutable/immutable distinction go away on 2.13, but pushes the burden of dealing with a possibly unexpected possibly mutable Seq to the user. Also needs to deal with 
* Create an immutable facade around any `Seq`, so you can return the mutable collection immutably. This is a bit of a footgun, but if the mutation is localized, it shouldn't be too hard to reason about when it's safe to wrap and return.
ServiceClosedException during updatig Var

### Expected behavior

I'm no sure if it is proper behavior that something is closed during updating Var

### Actual behavior

```
com.twitter.finagle.ServiceClosedException: null
      at com.twitter.finagle.pool.WatermarkPool.$anonfun$close$1(WatermarkPool.scala:228)
      at com.twitter.finagle.pool.WatermarkPool.$anonfun$close$1$adapted(WatermarkPool.scala:227)
      at com.twitter.finagle.pool.WatermarkPool$$Lambda$1331.000000009A2C22F0.apply(Unknown Source)
      at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
      at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
      at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:194)
      at com.twitter.finagle.pool.WatermarkPool.close(WatermarkPool.scala:227)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.liveness.FailureAccrualFactory.close(FailureAccrualFactory.scala:455)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.Filter$$anon$2.close(Filter.scala:121)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.Filter$$anon$2.close(Filter.scala:121)
      at com.twitter.finagle.ServiceFactoryProxy.close(ServiceFactoryProxy.scala:16)
      at com.twitter.finagle.loadbalancer.LazyEndpointFactory.close(EndpointFactory.scala:146)
      at com.twitter.util.Closable.close(Closable.scala:21)
      at com.twitter.util.Closable.close$(Closable.scala:21)
      at com.twitter.finagle.ServiceFactory.close(ServiceFactory.scala:5)
      at com.twitter.finagle.loadbalancer.TrafficDistributor.$anonfun$weightEndpoints$6(TrafficDistributor.scala:187)
      at com.twitter.finagle.loadbalancer.TrafficDistributor$$Lambda$674.00000000950C1410.apply(Unknown Source)
      at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
      at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
      at scala.collection.TraversableOnce$$Lambda$156.00000000946CBAF0.apply(Unknown Source)
      at scala.collection.immutable.Set$Set1.foreach(Set.scala:95)
      at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
      at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
      at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104)
      at com.twitter.finagle.loadbalancer.TrafficDistributor.$anonfun$weightEndpoints$1(TrafficDistributor.scala:183)
      at com.twitter.finagle.loadbalancer.TrafficDistributor$$Lambda$655.0000000095069FB0.apply(Unknown Source)
      at com.twitter.finagle.loadbalancer.TrafficDistributor$.$anonfun$safelyScanLeft$1(TrafficDistributor.scala:68)
      at com.twitter.finagle.loadbalancer.TrafficDistributor$$$Lambda$656.000000009506A6D0.apply(Unknown Source)
      at com.twitter.util.Event$$anon$3.$anonfun$register$3(Event.scala:118)
      at com.twitter.util.Event$$anon$3.$anonfun$register$3$adapted(Event.scala:117)
      at com.twitter.util.Event$$anon$3$$Lambda$666.000000009506F7B0.apply(Unknown Source)
      at com.twitter.util.Function$.$anonfun$synchronizeWith$1(Function.scala:41)
      at com.twitter.util.Function$$$Lambda$667.00000000950706D0.apply(Unknown Source)
      at com.twitter.util.Witness$$anon$17.notify(Event.scala:499)
      at com.twitter.util.Var$$anon$3.$anonfun$register$1(Var.scala:135)
      at com.twitter.util.Var$$anon$3.$anonfun$register$1$adapted(Var.scala:134)
      at com.twitter.util.Var$$anon$3$$Lambda$624.0000000095012510.apply(Unknown Source)
      at com.twitter.util.Var$Observer.publish(Var.scala:189)
      at com.twitter.util.Var$Value.observe(Var.scala:265)
      at com.twitter.util.Var$$anon$2.$anonfun$observe$1(Var.scala:113)
      at com.twitter.util.Var$$anon$2.$anonfun$observe$1$adapted(Var.scala:101)
      at com.twitter.util.Var$$anon$2$$Lambda$668.00000000950BE7F0.apply(Unknown Source)
      at com.twitter.util.Var$Observer.publish(Var.scala:189)
      at com.twitter.util.UpdatableVar.$anonfun$update$3(Var.scala:512)
      at com.twitter.util.UpdatableVar.$anonfun$update$3$adapted(Var.scala:507)
      at com.twitter.util.UpdatableVar$$Lambda$606.0000000094FDC990.apply(Unknown Source)
      at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
      at scala.collection.TraversableLike$WithFilter$$Lambda$226.00000000948C0EF0.apply(Unknown Source)
      at scala.collection.immutable.RedBlackTree$._foreachKey(RedBlackTree.scala:109)
      at scala.collection.immutable.RedBlackTree$.foreachKey(RedBlackTree.scala:105)
      at scala.collection.immutable.TreeSet.foreach(TreeSet.scala:153)
      at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
      at com.twitter.util.UpdatableVar.update(Var.scala:507)

```

### Steps to reproduce the behavior

It might be hard to reproduce because it might happens during high workload
Support for [`touch`](https://github.com/memcached/memcached/blob/1939cf9edc0656f7b1cfab6365f313b56b07a333/doc/protocol.txt#L383), [`gat`](https://github.com/memcached/memcached/blob/master/doc/protocol.txt#L415) and [`gats`](https://github.com/memcached/memcached/blob/1939cf9edc0656f7b1cfab6365f313b56b07a333/doc/protocol.txt#L416) memcached commands

### Expected behavior

The memcached client provides methods for `touch`, `gat` and `gats` memcached commands.

### Actual behavior

The memcached client does not have support for the `touch`, `gat` and `gats` memcached commands.

---

This is a feature request and not a bug. Those commands are not documented in the [wiki](https://github.com/memcached/memcached/wiki/Commands) but are in the protocol description and are indeed supported by at least the latest version of memcached.

I would be happy to contribute a PR for this, but wanted to ask here first if this would be something that could be accepted of if there is some reason why you wouldn't want to add support for those commands.

Cheers :) 
Framed transport client saw out of order responses on the same connection from finagle server

### Expected behavior

As far as I understand, framed transport doesn't allow out of order responses on the same connection

### Actual behavior

Framed transport client saw out of order responses on the same connection from finagle server

### Steps to reproduce the behavior

We use fbthfit c++ client with binary protocol and Framed transport.
Hi, Finagle team!

The following commit https://github.com/twitter/finagle/commit/5201f6237ce5185c4208d5945b33813b47507570#diff-25ac72862be1af67114573d236a19433R51-R56 changed the behaviour of the method so that `HttpClientTraceInitializer` is always present even if the original client stack doesn't have the `TraceInitializerFilter#role`. So, now It's not possible to disable the `c.t.f.h.HttpClientTraceInitializer#role` in the clients. 

In our case, we remove `TraceInitializerFilter#role` from the client and server stacks so that the B3 tracing headers can be preserved in the original format because all of the headers are removed by `com.twitter.finagle.http.TraceInfo#removeAllHeaders`. 

What do you think about making the new logick conditional? For instance, creating overriding the filter only if the existing stack contains `TraceInitializerFilter#role`? I'm happy to send a PR if this sounds reasonable. 

### Expected behavior

The `HttpClientTraceInitializer#role` can be removed from the client stack.

### Actual behavior

The `HttpClientTraceInitializer#role` is always added when the client is created. 
There's a todo in code (https://github.com/twitter/finagle/blob/4863f23fbd5df339df159327d96fd05cac1023a5/finagle-core/src/main/scala/com/twitter/finagle/service/Retries.scala#L243)

This is only applied to RequeueFilter but not to RetryFilter. Is it valid at all?

If I use Mux then ThresholdFailureDetector will mark ClientSession as Closed after ping times out (5 seconds by default). Hence, RequeueFilter will stop retrying.

I might be missing something but when I pass precondition to always true it works fine and not affected by  ThresholdFailureDetector.

My point is in case of service downtime RequeueFilter might stop retrying before exhausting budget because ThresholdFailureDetector marked ClientSession as Closed.

If there's a problem when the stack returns non-restartable service why similar logic is not implemented for RetryFilter?