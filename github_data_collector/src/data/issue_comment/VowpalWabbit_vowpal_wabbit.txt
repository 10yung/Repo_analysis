Vcpkg is a C++ dependency management system that makes installation and consumption as a dependency very easy. We should support this for VW to allow consuming the lib as easy as possible.

Instructions for creating a new package can be found here: https://github.com/microsoft/vcpkg/blob/master/docs/examples/packaging-github-repos.md
#### Describe the bug
When input is a list of files, `--invert_hash` only includes the features in the last file. For the features only exist in previous files they are ignored in invert_hash file.

#### To Reproduce
1. Datasets:
    1) 100k.json contains 100k events
    2) split 100k.json into 2 files, 50k_0.json and 50k_1.json
2. Generate model and invert hash for 100k.json
     1) vw --cb_adf -l 0.01 --power_t 0 --dsjson -d 100k.json --invert_hash 100k.invert.txt -f 100k.vw --readable_model 100k.readable.txt
3. Generate model and invert hash for 50k.json
     1) vw --dsjson -d 50k_0.json --cb_adf -l 0.01 --power_t 0 -f 50k_0.vw --save_resume --preserve_performance_counters
     2)  vw --dsjson -d 50k_1.json --cb_adf -l 0.01 --power_t 0 -f 50k_combined.vw  --save_resume --preserve_performance_counters -i 50k_0.vw --invert_hash 50k_combined.invert.txt --readable_model 50k_combined.readable.txt

#### Expected behavior
hash exists in 100k.invert.txt should be in 50k_combined.invert.txt as well. Readable model and invert hash should be consistent between a large file and a large file breaking into small chunks.

#### Observed Behavior
if features only exist in 50k_0.json, it doesn't exist in 50k_combined.invert.txt, but exist in readable model.

#### Environment
What version of VW did you use?
8.7.0

What OS or language did you use?
Linux, C++
WinSdk version upgrade (to VS 2019 minimal one)
#### Describe the bug
Build fails when trying to install within python3.7 environment using poetry. 

#### Environment
What version of VW did you use?  
```
pip install vowpalwabbit
```
What OS or language did you use?
```
Linux - ubuntu 16.04
```

#### Additional context

getting the following error 

```
[ 97%] Built target vw                                                                               
    Scanning dependencies of target pylibvw                                                              
    [ 98%] Building CXX object python/CMakeFiles/pylibvw.dir/pylibvw.cc.o                                
    [100%] Linking CXX shared library ../../lib.linux-x86_64-3.7/pylibvw.so                              
    /usr/bin/ld: /home/user/.asdf/installs/python/3.7.0/lib/libpython3.7m.a(abstract.o): relocat  
ion R_X86_64_32S against `_Py_NotImplementedStruct' can not be used when making a shared object; recomp  
ile with -fPIC                                                                                           
    /home/user/.asdf/installs/python/3.7.0/lib/libpython3.7m.a: error adding symbols: Bad value   
    collect2: error: ld returned 1 exit status                                                           
    python/CMakeFiles/pylibvw.dir/build.make:102: recipe for target '../lib.linux-x86_64-3.7/pylibvw.so  
' failed                                                                                                 
    make[3]: *** [../lib.linux-x86_64-3.7/pylibvw.so] Error 1                                            
    CMakeFiles/Makefile2:708: recipe for target 'python/CMakeFiles/pylibvw.dir/all' failed               
    make[2]: *** [python/CMakeFiles/pylibvw.dir/all] Error 2                                             
    CMakeFiles/Makefile2:720: recipe for target 'python/CMakeFiles/pylibvw.dir/rule' failed              
    make[1]: *** [python/CMakeFiles/pylibvw.dir/rule] Error 2                                            
    Makefile:344: recipe for target 'pylibvw' failed                                                     
    make: *** [pylibvw] Error 2                                                                          
    error: command 'cmake' failed with exit status 2                                                     
                                                                                                         
    ----------------------------------------                                                             
Command "/home/user/Desktop/folder/.venv/bin/python -u -c "import setuptools, tokenize;__  
file__='/tmp/pip-install-2kigynje/vowpalwabbit/setup.py';f=getattr(tokenize, 'open', open)(__file__);co  
de=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))" install --record /tm  
p/pip-record-gv4xkwlu/install-record.txt --single-version-externally-managed --compile --install-header  
s /home/user/Desktop/folder/.venv/include/site/python3.7/vowpalwabbit" failed with error   
code 1 in /tmp/pip-install-2kigynje/vowpalwabbit/                                                        
You are using pip version 10.0.1, however version 19.3.1 is available.                                   
You should consider upgrading via the 'pip install --upgrade pip' command.   
```
Anything i am missing ?
See #1696 for more details

--cb_type dr is a mode of learning, but we should enable the ability to use the IPS estimator to compute the average loss
These performance fixes are critical for the next step in the label/prediction pr.

- Change to using references with `v_array` where shallow copies were being used
- Add new print functions that use `v_array` references and deprecate the old by value ones
- Use `std::sort` instead of `qsort` in `features::sort`. Is able to make use of inlining because of the template, giving better runtime performance.
This is the first change in a series for my prediction and label refactor.

The main change here is the move to `enum class` over direct `enum`.
Hi there!

I am trying to apply vowpalwabbit as a linear regression model (with the Boston housing toy dataset) and I came across this SO post reply (https://stackoverflow.com/questions/19187532/ordinary-least-squares-regression-in-vowpal-wabbit). Note that this SO post answer was in 2014, when the published version of vowpal was 7.3.1 while my current version is 8.5.0. 

As part of reproducibility, the command line code that I used is similar to what was suggested in the post:
```
vw -d train.txt -f linear_model -c --passes 50 --holdout_off --loss_function squared --invert_hash model_readable.txt
```
However, when I input the arguments for multi pass training with --invert_hash, it gave me an error:

> Error: invert_hash is incompatible with a cache file.  Use it in single pass mode only.


Alternatively, I also came across another SO post reply(https://stackoverflow.com/questions/24437152/vowpal-wabbit-inverted-hash-option-produces-empty-output-but-why) on Logistic Regression multi-pass by Martin who suggested creating the binary model file before converting to inverted hash. This post was also posted in 2014. 

When I used the following code (as suggested for creating the binary model of multi-pass before converting to inverted_hash on one-pass testing): 
```
vw -d train.txt -c --passes 10 -f model.binary
vw -d train.txt -t -i model.binary --invert_hash linear_model.humanreadable
```
This resulted in a model output that purely predicted 4.74 for the testing of every observation of the training data.

> only testing
> Num weight bits = 18
> learning rate = 0.5
> initial_t = 0
> power_t = 0.5
> using no cache
> Reading datafile = train.txt
> num sources = 1
> average  since         example        example  current  current  current
> loss     last          counter         weight    label  predict features
> 214.916992 214.916992            1            1.0  19.4000   4.7400       12
> 145.827717 76.738441            2            2.0  13.5000   4.7400       12
> 640.982603 1136.137489            4            4.0  19.7000   4.7400       12
> 459.218392 277.454182            8            8.0  23.1000   4.7400       12
> 521.886717 584.555042           16           16.0   8.7000   4.7400       12
> 472.089673 422.292630           32           32.0  18.3000   4.7400       12
> 452.764611 433.439549           64           64.0  27.5000   4.7400       12
> 388.353522 323.942433          128          128.0  18.1000   4.7400       12
> 387.781603 387.209684          256          256.0  20.8000   4.7400       12

The output of "linear_model.humanreadable" is:

> Version 8.5.0
> Id 
> Min label:0
> Max label:50
> bits:18
> lda:0
> 0 ngram:
> 0 skip:
> options:
> Checksum: 2309139350
> :0
> Constant:116060:3.52267
> 

I suspected that this was used some form of overfitting, so instead I adjusted the multi-pass to 1:
```
vw -d train.txt -c --passes 1 -f model.binary
vw -d train.txt -t -i model.binary --invert_hash linear_model.humanreadable
```
The trained single pass model still seemed to be predicting a constant value for testing of every training data.

> only testing
> Num weight bits = 18
> learning rate = 0.5
> initial_t = 0
> power_t = 0.5
> using no cache
> Reading datafile = train.txt
> num sources = 1
> average  since         example        example  current  current  current
> loss     last          counter         weight    label  predict features
> 252.089630 252.089630            1            1.0  19.4000   3.5227       12
> 175.818382 99.547134            2            2.0  13.5000   3.5227       12
> 693.371349 1210.924316            4            4.0  19.7000   3.5227       12
> 506.251062 319.130775            8            8.0  23.1000   3.5227       12
> 570.836604 635.422145           16           16.0   8.7000   3.5227       12
> 519.730976 468.625349           32           32.0  18.3000   3.5227       12
> 500.398302 481.065627           64           64.0  27.5000   3.5227       12
> 431.747640 363.096978          128          128.0  18.1000   3.5227       12
> 431.430.951856          256          256.0  20.8000   3.5227       12

The updated output of "linear_model.humanreadble" still reads similarly:

> Version 8.5.0
> Id 
> Min label:0
> Max label:50
> bits:18
> lda:0
> 0 ngram:
> 0 skip:
> options:
> Checksum: 2309139350
> :0
> Constant:116060:3.52267

This "single" multipass model seems different from the direct simple invert_hash model as shown:
```
vw -d train.txt --loss_function squared --invert_hash linear_model_IH 
```
where the outputs of the "linear_model_IH" reads:

> Version 8.5.0
> Id 
> Min label:0
> Max label:50
> bits:18
> lda:0
> 0 ngram:
> 0 skip:
> options:
> Checksum: 2309139350
> :0
> Constant:116060:3.51799
> Num_feat^AGE:191433:0.0242481
> Num_feat^B:82735:0.00921203
> Num_feat^CHAS:63356:0.874292
> Num_feat^CRIM:227021:-0.00192302
> Num_feat^DIS:61172:0.381227
> Num_feat^INDUS:218500:0.0596201
> Num_feat^LSTAT:52422:0.0507423
> Num_feat^NOX:209497:3.43052
> Num_feat^PTRATIO:246628:0.158207
> Num_feat^RAD:207988:0.0610307
> Num_feat^RM:85721:0.397752
> Num_feat^TAX:114825:0.0034895
> Num_feat^ZN:46011:0.0256615
> 

Is there a proper option for creating inverted hash outputs for multi-pass models? I suspect there might be an issue with my command line inputs, so I appreciate any corrections on my code. 

Thanks in advance!
#1935
By migrating our dependencies to using FetchContent we achieve several things:
- Users no longer need to worry about how to install dependencies on their system:
    - No Vcpkg, apt or anything like that
- Works the same way on all platforms
- We can specify dependency versions explicitly
- Boost can be automatically retrieved. See: https://github.com/Orphis/boost-cmake

In order for this to work we need to need to move to at least CMake 3.12, and ensure all projects are available under CMake. (C# is currently missing).

Requiring a newer version for CMake is not an issue as it is easy to build form source, simple to install on Windows and is also obtainable through an apt repo. I see the apt repo as the most likely consumption use case on Ubuntu. See here for instructions: https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Maintainer-Info#obtaining-new-cmake-version
   

