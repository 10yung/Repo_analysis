# Requirement - what kind of business use case are you trying to solve?
set of fields are not supplied on the query service search response

Service: jaeger query
API: `/apt/traces`
Current response: 
```
{
  data: "...",
  total: 0,
  limit: 0,
  offset: 0
}
```
Response struct: https://github.com/jaegertracing/jaeger/blob/886b96574253a005ee7ebe74140098f3fe183606/cmd/query/app/http_handler.go#L56
Response part: https://github.com/jaegertracing/jaeger/blob/886b96574253a005ee7ebe74140098f3fe183606/cmd/query/app/http_handler.go#L238

Fields `total`, `limit` and `offset` are not supplied on the response part.

I am ready yo submit a PR if someone guide me to get these fields.
<!--
Welcome to the Jaeger project! ðŸ‘‹ðŸŽ‰

- Please search for existing issues to avoid creating duplicate bugs/feature requests.
- Please be respectful and considerate of others when commenting on issues.
- Please provide as much information as possible so we all understand the issue.
- If you only have a question, you may get a faster response by asking in
    - our chat room https://gitter.im/jaegertracing/Lobby, or
    - the forum https://groups.google.com/d/forum/jaeger-tracing
    (but please don't double post)
-->

## Requirement - what kind of business use case are you trying to solve?

Support different sampling rates for the same endpoints in different environments (dev/staging/prod).

<!-- required section -->

## Problem - what in Jaeger blocks you from solving the requirement?

The sampling strategies config does not have a top level `env` construct. Ideally, we would like to do -
```curl http://jaeger-agent:5778/sampling?env='dev'&service='loki-gateway'``` 

<!-- required section -->
<!-- If possible, describe the impact of the problem. -->

## Proposal - what do you suggest to solve the problem or improve the existing situation?

Extend the config to include `env` construct, and expose it as an API parameter.

<!-- It's ok if you don't have one. -->

## Any open questions to address
-
<!-- Questions that should be answered before proceeding with implementation. -->

cc @joe-elliott @cyriltovena
By default, collection and query uses schema `jaeger_v1_test`, so schema creation job should also use this default value as schema and not `jaeger_v1_dc1`.

https://www.jaegertracing.io/docs/1.16/cli/

Here is the related discussion thread, where this change was done in operator.

https://github.com/jaegertracing/jaeger-operator/pull/837
<!--
Welcome to the Jaeger project! ðŸ‘‹ðŸŽ‰

- Please search for existing issues to avoid creating duplicate bugs/feature requests.
- Please be respectful and considerate of others when commenting on issues.
- Please provide as much information as possible so we all understand the issue.
- If you only have a question, you may get a faster response by asking in
    - our chat room https://gitter.im/jaegertracing/Lobby, or
    - the forum https://groups.google.com/d/forum/jaeger-tracing
    (but please don't double post)
-->

## Requirement - what kind of business use case are you trying to solve?

Hello everyone, I'm a gopher from China. When using jaeger, I found that there is no go mod . go mod can provide great help to developers in China.

<!-- required section -->

## Problem - what in Jaeger blocks you from solving the requirement?

<!-- required section -->
<!-- If possible, describe the impact of the problem. -->

## Proposal - what do you suggest to solve the problem or improve the existing situation?

<!-- It's ok if you don't have one. -->

## Any open questions to address

<!-- Questions that should be answered before proceeding with implementation. -->

## Requirement - what kind of business use case are you trying to solve?
We'd like to allow dev teams to control sampling strategies. This currently is quite involved since jaeger relies on a filesystem-file. In kubernetes this typically means a configMap volume, which requires us to restart all jaeger collector pods when the file is updated. Quite cumbersome.

I'd like Jaeger to support a `sampling.strategies.url` option, where the sampling strategies file was downloaded from a url. The cache timeout could be a separate parameter, or it could use the cache headers from the dowload to determine how often to retrieve updates. 

Imho this would allow much easier changing of the sampling strategies, as we would be able to build a super-simple rest api to provide the json payload.

## Problem - what in Jaeger blocks you from solving the requirement?
strategies.json is implemented as a filesystem-file only

## Proposal - what do you suggest to solve the problem or improve the existing situation?
See requirement secion

## Any open questions to address


As alternative to channel-based queue in #1985
<!--
Welcome to the Jaeger project! ðŸ‘‹ðŸŽ‰

- Please search for existing issues to avoid creating duplicate bugs/feature requests.
- Please be respectful and considerate of others when commenting on issues.
- Please provide as much information as possible so we all understand the issue.
- If you only have a question, you may get a faster response by asking in
    - our chat room https://gitter.im/jaegertracing/Lobby, or
    - the forum https://groups.google.com/d/forum/jaeger-tracing
    (but please don't double post)
-->

## Requirement - what kind of business use case are you trying to solve?

Tracing http calls of my microservice

## Problem - what in Jaeger blocks you from solving the requirement?

I launched agent and collector 1.14 in docker.
Recently i checked agent logs with docker container logs agent and find that:

`{"level":"info","ts":1578533821.070084,"caller":"base/balancer.go:140","msg":"base.baseBalancer: handle SubConn state change: 0xc0002a45b0, CONNECTING","system":"grpc","grpc_log":true}
{"level":"info","ts":1578533821.07017,"caller":"roundrobin/roundrobin.go:50","msg":"roundrobinPicker: newPicker called with readySCs: map[]","system":"grpc","grpc_log":true}
{"level":"info","ts":1578533821.0700924,"caller":"transport/log.go:30","msg":"transport: loopyWriter.run returning. connection error: desc = \"transport is closing\"","system":"grpc","grpc_log":true}
{"level":"info","ts":1578533821.0705376,"caller":"base/balancer.go:140","msg":"base.baseBalancer: handle SubConn state change: 0xc0002a45b0, READY","system":"grpc","grpc_log":true}
{"level":"info","ts":1578533821.0706186,"caller":"roundrobin/roundrobin.go:50","msg":"roundrobinPicker: newPicker called with readySCs: map[{127.0.0.1:14250 0  <nil>}:0xc0002a45b0]","system":"grpc","grpc_log":true}
{"level":"info","ts":1578534001.1125383,"caller":"base/balancer.go:140","msg":"base.baseBalancer: handle SubConn state change: 0xc0002a45b0, CONNECTING","system":"grpc","grpc_log":true}
{"level":"info","ts":1578534001.1126258,"caller":"roundrobin/roundrobin.go:50","msg":"roundrobinPicker: newPicker called with readySCs: map[]","system":"grpc","grpc_log":true}
{"level":"info","ts":1578534001.112556,"caller":"transport/log.go:30","msg":"transport: loopyWriter.run returning. connection error: desc = \"transport is closing\"","system":"grpc","grpc_log":true}
{"level":"info","ts":1578534001.1129324,"caller":"base/balancer.go:140","msg":"base.baseBalancer: handle SubConn state change: 0xc0002a45b0, READY","system":"grpc","grpc_log":true}
{"level":"info","ts":1578534001.1130183,"caller":"roundrobin/roundrobin.go:50","msg":"roundrobinPicker: newPicker called with readySCs: map[{127.0.0.1:14250 0  <nil>}:0xc0002a45b0]","system":"grpc","grpc_log":true}
`


It seems agent disconnected from collector every 10 minutes, is it a bug or just a normal case?

## Problem - what in Jaeger blocks you from solving the requirement?
https://github.com/jaegertracing/jaeger/blob/009b7f57fe54b54696a05fdd28cb445c597ca146/storage/spanstore/interface.go#L27-L29

The `spanstore.Writer` interface does not propagate context.

## Proposal - what do you suggest to solve the problem or improve the existing situation?

Add a new `WriteSpanWithContext(ctx context.Context, span *model.Span) error` to propagate context. 

Alternatively, we may update to `WriteSpan(ctx context.Context, *model.Span) error`. 

Unfortunately, both of these are breaking changes. Alternatively, we may create a `WriterV2` interface, and supply a converter from `Writer` to `WriterV2`. Such a converter would simply use `ctx.Background()` for the context parameter. 

<!-- It's ok if you don't have one. -->


## Requirement - what kind of business use case are you trying to solve?

We want to have accurate global measurements of the potential data loss in Jaeger clients. 

## Problem - what in Jaeger blocks you from solving the requirement?

Although Jaeger clients internally support integrations with metrics backends, not all users actually configure those, and even if they do, the metrics are often namespaced to the application, e.g. by including a tag `service=xyz` or using a custom prefix, which makes it more difficult to observe across the site.

## Proposal - what do you suggest to solve the problem or improve the existing situation?

Allow clients to report certain data loss metrics when submitting span batches to Jaeger backend. The data elements should include:
  * batch sequence number to detect possible dropped packets (especially with UDP transports)
  * count of spans dropped by the client due to internal queue overflow
  * count of spans dropped by the client due to exceeding max packet size (e.g. 65000 bytes cap for UDP transport)

The Jaeger clients (some, at least) are already including a `client-uuid` string tag in the Process, which will allow the agent/collector to monitor those reported stats and emit consistent metrics.

* [x] Thrift IDL change https://github.com/jaegertracing/jaeger-idl/pull/60
* [x] Go client prototype https://github.com/jaegertracing/jaeger-client-go/pull/482
* [ ] Agent prototype https://github.com/jaegertracing/jaeger/pull/2010
* [ ] Other clients
Context: https://github.com/jaegertracing/jaeger/pull/1985/files#r360514330 , we should consider whether the "bytes processed" and "number of spans" should be reset when a resize is triggered. Things to consider:

1. the effects of this as a metric (increase, increase, reset, increase, ...)
2. desirable/undesirable effects on quick bursts -- the way we have, quick bursts won't cause unnecessary resizes, which is a good thing if we are under heavy load (less processing), but if the burst is big enough, it might cause the collector to use more memory than it has available
