Seems like a great AI framework for iOS. I wish to use your framework on macOS.

My `podfile` looks something like this:

```
swift_version = "5.0"
platform :osx, '10.14'
pod 'MetalBender', :git => 'https://github.com/xmartlabs/Bender.git', :commit => '512ea171950d1ab997b05cf469908fbfc48060e6'
```

Doing install, says that `MetalBender` is not available for macOS.

```
PROMPT> pod install
Analyzing dependencies
Pre-downloading: `MetalBender` from `https://github.com/xmartlabs/Bender.git`, commit `512ea171950d1ab997b05cf469908fbfc48060e6`
[!] The platform of the target `FreeHongKong` (macOS 10.14) is not compatible with `MetalBender (0.5.0)`, which does not support `macOS`.
```

Best of luck. Thank you for open sourcing your project.

styleNet = Network(device: device, inputSize: inputSize, parameterLoader: loader) 

styleNet.start 
    ->> Convolution(size: ConvSize(outputChannels: 32, kernelSize: 9, stride: 1), id: “conv1”) 
    ->> Convolution(size: ConvSize(outputChannels: 64, kernelSize: 3, stride: 2), id: “conv2”) 
    ->> Convolution(size: ConvSize(outputChannels: 128, kernelSize: 3, stride: 2), id: “conv3”) 
    ->> Residual(size: ConvSize(outputChannels: 128, kernelSize: 3, stride: 1), id: “res_block1”) 
    ->> Residual(size: ConvSize(outputChannels: 128, kernelSize: 3, stride: 1), id: “res_block2”) 
    ->> Residual(size: ConvSize(outputChannels: 128, kernelSize: 3, stride: 1), id: “res_block3”) 
    ->> Residual(size: ConvSize(outputChannels: 128, kernelSize: 3, stride: 1), id: “res_block4”) 
    —>> ConvTranspose(size: ConvSize(outputChannles: 64, kernelSize: 3, stride: 2), id: “convt1”) 
    —>> ConvTranspose(size: ConvSize(outputChannles: 32, kernelSize: 3, stride: 2), id: “convt2”) 
    ->> Convolution(size: ConvSize(outputChannels: 3, kernelSize: 9, stride: 1), neuron: .tanh, id: “convFinal”)



1.I want to do two pool layers for the add operation
How to get the weight of each layer of neural network?
2.Model.run the self? .network. Run is going to be returned to tensor, I need to take care of it, don't return the label？

Im not sure why it shows all the commits, the real changes start with "trimmed whitespace" (including that one)
Cloning the repo with checkout on tag 0.4.0
Example has seven errors after pod installation (0.4.0)
Seems to be removed at compile but all three frameworks installed by cocoapods are not found at compil time

"PBXCp /Users/thibautnoah/Library/Developer/Xcode/DerivedData/Example-fheatxxixelckdgltxeulpnuyhru/Build/Products/Debug-iphoneos/MetalBender.framework /Users/thibautnoah/Library/Developer/Xcode/DerivedData/Example-fheatxxixelckdgltxeulpnuyhru/Build/Products/Debug-iphoneos/Example.app/Frameworks/MetalBender.framework
    cd /Users/thibautnoah/testing/Bender/Example
    export PATH="/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/usr/bin:/Applications/Xcode.app/Contents/Developer/usr/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin"
    builtin-copy -exclude .DS_Store -exclude CVS -exclude .svn -exclude .git -exclude .hg -exclude Headers -exclude PrivateHeaders -exclude Modules -exclude *.tbd -bitcode-strip replace-with-marker -bitcode-strip-tool /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/bitcode_strip -resolve-src-symlinks /Users/thibautnoah/Library/Developer/Xcode/DerivedData/Example-fheatxxixelckdgltxeulpnuyhru/Build/Products/Debug-iphoneos/MetalBender.framework /Users/thibautnoah/Library/Developer/Xcode/DerivedData/Example-fheatxxixelckdgltxeulpnuyhru/Build/Products/Debug-iphoneos/Example.app/Frameworks"


"error: /Users/thibautnoah/Library/Developer/Xcode/DerivedData/Example-fheatxxixelckdgltxeulpnuyhru/Build/Products/Debug-iphoneos/MetalBender.framework: No such file or directory"


Is there a batch inference API available? In our use case, we need to perform inference on several (up to 100+) cropped parts of an image. A batch inference API would make this operation efficient. Thanks.
I had met a problem, using blender for load some model's data from training framework,like pytorch.
I need to convert them from float32 into float16(half) in Metal kernel for processing, but I found it is very slow, so is any way to speed up for this.
I get the following error when converting the graph containing a concat node with axis `int_value` greater than 2.
```
fatal error: Cannot create ConcatV2. Missing or invalid attribute axis.: file <omited>/Pods/MetalBender/Sources/Adapters/Tensorflow/TFConverter+Mappers.swift, line 162
```

And the node in question from the `.pbtxt`:
```
node {
  name: "fire2/concat/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
```

And if I follow correctly the code it executes the `LayerConverter+Mappers.swift` calls the `LayerSize.fromTf` with the value 3. which in return is as follow:
```swift
    static func fromTF(index: Int) -> LayerSizeAxis? {
        switch index {
        case 0:
            return .w
        case 1:
            return .h
        case 2:
            return .f
        default:
            return nil
        }
    }
}
```
This evaluates as nil and throws an error.

Is there an error with the graph I'm trying to convert or is a bug in the Bender that it does not support concat indexes beyond axis=2 on a concat layer?


### Environment:
 - Xcode 8.3.3,
 - iOS: 10.3.2,
 - SDK version: 10.3

Hello,
I need **upsample** layer to implement U-net for segmentation.
Is there one? Will it be implemented?

Only when the image aspect ratio is not the expected:

1. The `scaledH` & `scaledW` seem to be calculated wrong.
2. I've seen some race conditions between the resize encode and the crop encode. Maybe something related to the `MPSTemporaryImage`. The image after the start node looks noisy.