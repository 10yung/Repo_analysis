Hi,
We are using FileHelpers to patch a multi-record file, reading it, processing the changes and writing the changes.
It works as smooth as possible, however, due the large amount of records, the writing process takes a long time until all records are written and we may use the resulting file.
Is there anything we can do to expedite the writing process and not wait for until the "buffer" is completely flush?
Thanks
Hello,

I would like to propose a new setting for fixed-length fields to control how an overflowing value is managed.

Basically, currently, the behavior is to discard characters at the end of the value.
I added a second option, which is to throw an exception when this occurs, as a way to ensure users can be warned if data was lost.
Of course, this could be the foundation to other strategies for handling this case.

Regards,
`
[FixedLengthRecord(FixedMode.AllowLessChars)]
public class Customer
{
    [FieldFixedLength(5)]
    public int CustId;

    [FieldFixedLength(30)]
    [FieldTrim(TrimMode.Both)]
    public string Name;

    [FieldFixedLength(8)]
    [FieldConverter(ConverterKind.DateMultiFormat, "ddMMyyyy", "MMyyyy")]
    public DateTime AddedDate;

   [???]
   public Address[] Adresses
  
}`

`[FixedLengthRecord(FixedMode.AllowLessChars)]
public class Address
{
    [FieldFixedLength(5)]
    public int AddId;

    [FieldFixedLength(30)]
    public string City;

	
    [FieldFixedLength(30)]
    public string Street;

    [FieldFixedLength(8)]
    public string Number;
}`

What I should make into Attributes for this part of class (array of Address[] class)

  [???]
   public Address[] Adresses


Visual Studio 2019, .Net Core 2.2 - getting the following error when debugging code to parse a csv file with 10 rows:

`{"Line: 2 Column: 593. Delimiter ',' found after the last field 'Taxonomy_Group_15' (the file is wrong or you need to add a field to the record class)"}`

I have checked the file and I don't see anything in column 593 (or anywhere else beyond the defined columns for that matter).  

Here is the code I'm testing with:

```
 public static void Main(string[] args)
        {
            var engine = new FileHelperEngine<Entity>();
           
            var result = engine.ReadFile(@"C:\Users\me\Desktop\pfile_20190902-20190908.csv");

                foreach (Entity subject in result)
                    {
                    Console.WriteLine("Subject Info:");
                    Console.WriteLine(subject.NPI + " - " + subject.Entity_Type_Code);
                    }
         }   
```
The error is thrown before the foreach loop is entered.  I've checked my Entity Class and all columns are present.  Can someone help me understand what's going on here?


As I have read here https://github.com/MarcosMeli/FileHelpers/issues/340

and in the readme:
Dynamic: ClassBuilder and CsvClassBuilder. ClassBuilder is difficult to maintain and a rewrite in .NET Core / Standard as is, would require to reference three NuGet packages. There must be better ways to write record structures at runtime.

So I need to downgrade to something below 3.3 and run full framework to use a dynamic ordering of columns? Or is it something that will be brought back any time soon?
Hi Team, 

Is there any way to write a file using Multi Record Engine. I have used it for reading, its works fine. Similarly I would like to write back. 

MergeTheChunks uses string comparison and not the comparer specified in class constructor. That results in file that is not sorted. Please note that correct comparison mechanism is used in WritePart.
I have a log file im reading that has the following format:

192.168.1.1 hostname "username" [18/Jun/2019:00:00:02 +0000] "Get....." 

im using space as the separator and treating the date as a string but it falls over as the [datetime field] has a space in it. Any ideas how i can work with this? 
Hello, 

I would like to be able to read a CSV to a DataTable. I do not know in advance the count and the name of the columns, so I would like to be able to automatically generate a DataTable structure with column names based on file header. 
The content to load is a Stream, not a physical file.

I have tried to figure how to do this with FileHelpers (last version) with various methods (CommonEngine.CsvToDataTable(), CsvEngine.CsvToDataTable(), FileHelperEngine.ReadStreamAsDT etc) but nothing worked (because these methods seems to be intended to work from physical files, or the structure needs to be known in advance, etc). 
Last month I created a StackOverflow question to explain what kind of problems I encountered but I didn't received any answer : https://stackoverflow.com/questions/56361716/using-filehelpers-to-read-a-dynamic-csv-to-datatable 

Could you please help me ?

Usually I use your library to load files to objects, as the structure is known in advance, and I really like it. So if it's possible to achieve something like this what I described previously with it, I'd be glad to use it.

Thank you very much.
I have a nullable type of date but I also require to add the date fromat.


        [FieldConverter(typeof(NullableDateConverter))]     
        public DateTime? ItemNextAvailabilityDate;

But I also need to mark it with the format as in dd/mm/yyyy

[FieldConverter(ConverterKind.Date, "dd-MMM-yyyy" )]  ? But still allow it to be nullable?

