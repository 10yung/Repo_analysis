
BLAKE3 is designed to be a very high performance cryptographic hash. The BLAKE3 team has shown significantly higher single-thread performance than SHA-512 on modern server hardware [1].

This change resulted in a minor improvement to observed local build times.

### Comparison

`cargo check` on sccache repo (at commit 32e40bba338020ae978cea5698aba35b4a710a88) with a warm cache for each hash. Ten samples were collected for each hash.

SHA512 mean: 60.06 seconds
BLAKE3 mean: 57.77 seconds

This data shows a mean improvement of 2.29 seconds (about 4%). My statistics skills are rough, but this appears to be a very statistically significant improvement.

This test was performed on an Intel i5-7600K and a fairly ancient SATA3 SSD. It would be interesting to see a test result from a higher performance machine. The BLAKE3 team's performance analysis shows 8.5x faster single threaded performance vs SHA-512 on an AWS `c5d.metal` instance.

<details>
<summary>Raw data</summary>
sha512 initial cold build: 1m 47s<br>
blake3 initial cold build: 1m 52s<br>
sha512 build times: 57.02s, 1m 03s, 1m 02s, 58.72s, 1m 00s, 59.48s, 1m 02s, 1m 01s, 58.54s, 58.85s<br>
blake3 build times: 54.87s, 59.82s, 56.72s, 56.91s, 1m 00s, 56.46s, 57.85s, 57.13s, 59.35s, 58.57s<br>
</details>

### Related issues & PRs:

- [#504: Reevaluate hash function used](https://github.com/mozilla/sccache/issues/504)
- [#310: Use RustCrypto crates](https://github.com/mozilla/sccache/pull/310)
- [#108: Faster hash algorithm?](https://github.com/mozilla/sccache/issues/108)
- [#109: Switch from SHA-1 to SHA-512](https://github.com/mozilla/sccache/pull/109)

### References:

1. [Blake3 repo](https://github.com/BLAKE3-team/BLAKE3)
2. [Blake3 paper](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf)

ldd (verson 2.30) prints different entry for interpreter '/lib64/ld-linux-x86-64.so.2' from old versoin.

package-toolchain will package /usr/lib64/ld-linux-x86-64.so.2, but what we need
is /lib64/ld-linux-x86-64.so.2 

this results in a very confusing error message "No such file or directory" when sccache try to run
rustc with bwrap.


```bash
$ ldd --version
ldd (GNU libc) 2.30

$ ldd /usr/bin/ls
        linux-vdso.so.1 (0x00007ffedc39a000)
        libcap.so.2 => /usr/lib/libcap.so.2 (0x00007f7bc85e6000)
        libc.so.6 => /usr/lib/libc.so.6 (0x00007f7bc841f000)
        /lib64/ld-linux-x86-64.so.2 => /usr/lib64/ld-linux-x86-64.so.2 (0x00007f7bc8649000)
```

```
$ ldd --version
ldd (GNU libc) 2.17

$ ldd /usr/bin/ls
        linux-vdso.so.1 =>  (0x00007ffc8f436000)
        libselinux.so.1 => /lib64/libselinux.so.1 (0x00001490ae68e000)
        libcap.so.2 => /lib64/libcap.so.2 (0x00001490ae489000)
        libacl.so.1 => /lib64/libacl.so.1 (0x00001490ae280000)
        libc.so.6 => /lib64/libc.so.6 (0x00001490adeb3000)
        libpcre.so.1 => /lib64/libpcre.so.1 (0x00001490adc51000)
        libdl.so.2 => /lib64/libdl.so.2 (0x00001490ada4d000)
        /lib64/ld-linux-x86-64.so.2 (0x00001490ae8b5000)
        libattr.so.1 => /lib64/libattr.so.1 (0x00001490ad848000)
        libpthread.so.0 => /lib64/libpthread.so.0 (0x00001490ad62c000)
```

These two commits together should fix the issue of broken builds requiring both a clobber and cache-clear when updating rust toolchain archives.
We have some code (see https://github.com/pytorch/pytorch/pull/31974) which has somehow been miscached by sccache and is causing compiler errors. We know that the problem goes away when we run the build without the cache. We'd like to delete JUST the bad cache product related to this compilation, and not any others. Is there a good way to do this? (If we nuke the entire cache it will affect other working uses of the cache.)
Brave browser calculates how much time has been saved avoiding all the trackers. It would be great if sccache could guestimate how much compile time has been saved by using it.
I've been trying to run sccache on an EC2 instance with the following config
**Note** I'm getting the same errors with IAM_ROLE and direct keys
```
AWS_ACCESS_KEY_ID=[[my_id]] AWS_SECRET_ACCESS_KEY=[[my_key]] SCCACHE_S3_USE_SSL=true SCCACHE_BUCKET=[[my_bucket]] RUST_LOG=sccache=trace SCCACHE_START_SERVER=1 SCCACHE_NO_DAEMON=1 SCCACHE_ERROR_LOG=./sccache_log  ./sccache
```

sccache log file
```
INFO 2019-12-30T18:11:26Z: sccache::server: start_server: port: 4226
 INFO 2019-12-30T18:11:26Z: sccache::server: No scheduler address configured, disabling distributed sccache
DEBUG 2019-12-30T18:11:26Z: sccache::cache::cache: Trying S3Cache([[my bucket]], [[my-bucket]].s3.amazonaws.com)
TRACE 2019-12-30T18:11:26Z: sccache::cache::cache: Using S3Cache
 INFO 2019-12-30T18:11:26Z: sccache::server: server started, listening on port 4226
TRACE 2019-12-30T18:13:21Z: sccache::server: incoming connection
TRACE 2019-12-30T18:13:21Z: sccache::server: handle_client
DEBUG 2019-12-30T18:13:21Z: sccache::server: handle_client: compile
TRACE 2019-12-30T18:13:21Z: sccache::server: compiler_info
TRACE 2019-12-30T18:13:21Z: sccache::server: compiler_info cache miss
TRACE 2019-12-30T18:13:21Z: sccache::compiler::compiler: detect_compiler: /usr/bin/gcc
TRACE 2019-12-30T18:13:21Z: sccache::compiler::compiler: detect_c_compiler
TRACE 2019-12-30T18:13:21Z: sccache::compiler::compiler: compiler Some("/usr/bin/gcc" "-E" "/tmp/sccache.Es1ro090eOOO/testfile.c")
DEBUG 2019-12-30T18:13:21Z: sccache::compiler::compiler: Found GCC
DEBUG 2019-12-30T18:13:21Z: sccache::server: check_compiler: Supported compiler
DEBUG 2019-12-30T18:13:21Z: sccache::server: parse_arguments: Ok: ["-c", "-o", "crap.o", "crap.c"]
DEBUG 2019-12-30T18:13:21Z: sccache::compiler::compiler: [crap.o]: get_cached_or_compile: ["-c", "-o", "crap.o", "crap.c"]
TRACE 2019-12-30T18:13:21Z: sccache::compiler::gcc: preprocess
TRACE 2019-12-30T18:13:21Z: sccache::compiler::gcc: preprocess: Some("/usr/bin/gcc" "-x" "c" "-E" "-P" "crap.c")
TRACE 2019-12-30T18:13:21Z: sccache::compiler::c: [crap.o]: Preprocessor output is 12971 bytes
TRACE 2019-12-30T18:13:21Z: sccache::util: Hashed 0 files in 0.021 s
DEBUG 2019-12-30T18:13:21Z: sccache::compiler::compiler: [crap.o]: generate_hash_key took 0.021 s
TRACE 2019-12-30T18:13:21Z: sccache::compiler::compiler: [crap.o]: Hash key: 3a1e6e85eebaf9db89b83029862e80508ba376af1b56e195566a874c75b2feb99778dc2639e0013480104e12b952b8416a7ba61a379c651dd66d028e351c0e5d
DEBUG 2019-12-30T18:13:21Z: sccache::simples3::credential: Using AWS credentials from environment
DEBUG 2019-12-30T18:13:21Z: sccache::simples3::s3: GET http://[[my-bucket]].s3.amazonaws.com/3/a/1/3a1e6e85eebaf9db89b83029862e80508ba376af1b56e195566a874c75b2feb99778dc2639e0013480104e12b952b8416a7ba61a379c651dd66d028e351c0e5d
 WARN 2019-12-30T18:13:21Z: sccache::cache::s3: Got AWS error: Error(BadHTTPStatus(400), State { next_error: None, backtrace: InternalBacktrace })
DEBUG 2019-12-30T18:13:21Z: sccache::compiler::compiler: [crap.o]: Cache miss in 0.008 s
TRACE 2019-12-30T18:13:21Z: sccache::compiler::gcc: compile
DEBUG 2019-12-30T18:13:21Z: sccache::compiler::compiler: [crap.o]: Compiling locally
DEBUG 2019-12-30T18:13:21Z: sccache::compiler::compiler: [crap.o]: Compiled in 0.053 s, storing in cache
TRACE 2019-12-30T18:13:21Z: sccache::server: CompileFinished retcode: exit code: 0
DEBUG 2019-12-30T18:13:21Z: sccache::simples3::s3: PUT http://[[my bucket]].s3.amazonaws.com/3/a/1/3a1e6e85eebaf9db89b83029862e80508ba376af1b56e195566a874c75b2feb99778dc2639e0013480104e12b952b8416a7ba61a379c651dd66d028e351c0e5d
TRACE 2019-12-30T18:13:21Z: sccache::simples3::s3: PUT failed with HTTP status: 400 Bad Request
DEBUG 2019-12-30T18:13:21Z: sccache::compiler::compiler: [crap.o]: Cache write error: Error(Msg("failed to put cache entry in s3"), State { next_error: Some(Error(BadHTTPStatus(400), State { next_error: None, backtrace: InternalBacktrace })), backtrace: InternalBacktrace })
DEBUG 2019-12-30T18:13:21Z: sccache::server: Error executing cache write: failed to put cache entry in s3
```

I assume that the issue is that the requests are made via HTTP and not HTTPS. Not that I added `SCCACHE_S3_USE_SSL=true` and it didn't seem to make any impact.

What am I missing?
Hi, I've created a private S3 bucket and verified that I can write to it:

```bash
export AWS_ACCESS_KEY_ID=...
export AWS_SECRET_ACCESS_KEY=...
export BUCKET=...
echo hi > hello.txt
aws s3 cp hello.txt s3://$BUCKET/test.txt
aws s3 cp s3://$BUCKET/test.txt /dev/stdout
```

It prints `hi` as expected.

With the same environment variables, I start an sccache server:

```bash
export SCCACHE_BUCKET=$BUCKET
SCCACHE_START_SERVER=1 SCCACHE_NO_DAEMON=1 RUST_LOG=sccache=trace sccache
```

Now when I try a `cargo build` somewhere, I get lots of failures like this:

```
 WARN 2019-12-27T23:25:54Z: sccache::cache::s3: Got AWS error: Error(BadHTTPStatus(403), State { next_error: None, backtrace: InternalBacktrace })
...
TRACE 2019-12-27T23:25:54Z: sccache::simples3::s3: PUT failed with HTTP status: 403 Forbidden
DEBUG 2019-12-27T23:25:54Z: sccache::compiler::compiler: [arrayvec]: Cache write error: Error(Msg("failed to put cache entry in s3"), State { next_error: Some(Error(BadHTTPStatus(403), State { next_error: None, backtrace: InternalBacktrace })), backtrace: InternalBacktrace })
DEBUG 2019-12-27T23:25:54Z: sccache::server: Error executing cache write: failed to put cache entry in s3
ERROR 2019-12-27T23:25:54Z: sccache::server: SccacheTransport::poll failed: io error.
ERROR 2019-12-27T23:25:54Z: sccache::server: io error.
...
```

Does sccache need anything other than AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY to write to s3?
The README says `sccache` includes "experimental Rust support". I'd like to be able to track the status of this so I have an idea when it will be production ready.