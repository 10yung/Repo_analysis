It is currently impossible to create a model without intercept for various linear regression models. I noticed this (for example) for lmStepAIC, leapSeq, leapForward, leapBackward. I have managed to create my own modelInfo for leapSeq that works (?) (shown below, it's the same as the generic one but with intercept/int set to F), but it would be nice if this could be done in a better way. 

No hurry, just an idea!

```
modelInfo <- list(label = "Linear Regression with Stepwise Selection",
                  library = "leaps",
                  type = "Regression",
                  parameters = data.frame(parameter = 'nvmax',
                                          class = "numeric",
                                          label = 'Maximum Number of Predictors'),
                  grid = function(x, y, len = NULL, search = "grid"){
                    if(search == "grid") {
                      out <- data.frame(nvmax = 2:(len+1))
                    } else {
                      out <- data.frame(nvmax = sort(unique(sample(2:(ncol(x) - 1), size = len, replace = TRUE))))
                    }
                    out
                  },
                  loop = function(grid) {   
                    grid <- grid[order(grid$nvmax, decreasing = TRUE),, drop = FALSE]
                    loop <- grid[1,,drop = FALSE]
                    submodels <- list(grid[-1,,drop = FALSE])
                    list(loop = loop, submodels = submodels)
                  },
                  fit = function(x, y, wts, param, lev, last, classProbs, ...) {   
                    theDots <- list(...)
                    if(any(names(theDots) == "nbest")) stop("'nbest' should not be specified")
                    if(any(names(theDots) == "method")) stop("'method' should not be specified")
                    if(any(names(theDots) == "nvmax")) stop("'nvmax' should not be specified")
                    
                    leaps::regsubsets(as.matrix(x), y,
                                      weights = if(!is.null(wts)) wts else rep(1, length(y)),
                                      nbest = 1, nvmax = param$nvmax, method = "seqrep", 
                                      intercept = F,
                                      int = F, ...)
                  },
                  predict = function(modelFit, newdata, submodels = NULL) {
                    newdata <- as.matrix(newdata)
                    foo <- function(b, x) x[,names(b),drop = FALSE] %*% b
                    
                    path <- 1:(modelFit$nvmax - 1)
                    betas <- coef(modelFit, id = 1:(modelFit$nvmax - 1))
                    
                    newdata <- cbind(rep(1, nrow(newdata)), as.matrix(newdata))
                    colnames(newdata)[1] <- "(Intercept)"
                    
                    out <- foo(betas[[length(betas)]], newdata)[,1]
                    
                    if(!is.null(submodels))
                    {
                      numTerms <- unlist(lapply(betas, length))
                      if(any(names(betas[[length(betas)]]) == "(Intercept)")) numTerms <- numTerms - 1
                      ## Need to find the elements of betas that 
                      ## correspond to the values of submodels$nvmax
                      
                      keepers <- which(numTerms %in% submodels$nvmax)
                      if(length(keepers) != length(submodels$nvmax))
                        stop("Some values of 'nvmax' are not in the model sequence.")
                      
                      ## The grid code sorted from largest to smallest, so 
                      ## to match them, reverse the order
                      keepers <- rev(keepers)
                      preds <- lapply(betas[keepers], foo, x= newdata)
                      preds <- do.call("cbind", preds)
                      
                      out <- as.data.frame(cbind(out, preds))
                      out <- as.list(out)
                    }
                    
                    out
                  },
                  tags = c("Linear Regression", "Feature Selection Wrapper"),
                  prob = NULL,
                  sort = function(x) x[order(x[,1]),])
```
Trying to use a `bartMachine` model, the following error appears with `caret 6.0-85` but not with `caret 6.0-84`

> Error in if (grepl("adaptive", trControl$method) & nrow(tuneGrid) == 1) { : 
  argument is of length zero

### Minimal, reproducible example:

```R
library(caret)
library(mlbench)
data(BostonHousing)

bartFit <- train(
  medv ~ .,
  data = BostonHousing,
  method = "bartMachine",
  trControl = trainControl(method = "cv")
)
```

### Session Info:
```R
R version 3.6.2 (2019-12-12)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS/LAPACK: /opt/OpenBLAS/lib/libopenblasp-r0.3.7.so

locale:
 [1] LC_CTYPE=en_US.UTF-8          LC_NUMERIC=C                  LC_TIME=en_GB.UTF-8          
 [4] LC_COLLATE=en_US.UTF-8        LC_MONETARY=en_GB.UTF-8       LC_MESSAGES=en_US.UTF-8      
 [7] LC_PAPER=en_GB.UTF-8          LC_NAME=en_GB.UTF-8           LC_ADDRESS=en_GB.UTF-8       
[10] LC_TELEPHONE=en_GB.UTF-8      LC_MEASUREMENT=en_GB.UTF-8    LC_IDENTIFICATION=en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mlbench_2.1-1   caret_6.0-85    ggplot2_3.2.1   lattice_0.20-38 sos_2.0-0       brew_1.0-6     

loaded via a namespace (and not attached):
 [1] bartMachine_1.2.4.2  splines_3.6.2        foreach_1.4.7        carData_3.0-3        prodlim_2019.11.13  
 [6] assertthat_0.2.1     stats4_3.6.2         cellranger_1.1.0     yaml_2.2.0           ipred_0.9-9         
[11] pillar_1.4.3         backports_1.1.5      glue_1.3.1           pROC_1.16.1          digest_0.6.23       
[16] randomForest_4.6-14  colorspace_1.4-1     recipes_0.1.9        htmltools_0.4.0      Matrix_1.2-18       
[21] plyr_1.8.5           timeDate_3043.102    pkgconfig_2.0.3      haven_2.2.0          purrr_0.3.3         
[26] bartMachineJARs_1.1  scales_1.1.0         itertools_0.1-3      openxlsx_4.1.4       gower_0.2.1         
[31] lava_1.6.6           rio_0.5.16           tibble_2.1.3         generics_0.0.2       car_3.0-6           
[36] withr_2.1.2          nnet_7.3-12          lazyeval_0.2.2       survival_3.1-8       magrittr_1.5        
[41] crayon_1.3.4         readxl_1.3.1         evaluate_0.14        nlme_3.1-143         MASS_7.3-51.5       
[46] forcats_0.4.0        foreign_0.8-74       class_7.3-15         tools_3.6.2          data.table_1.12.8   
[51] hms_0.5.3            lifecycle_0.1.0      stringr_1.4.0        munsell_0.5.0        zip_2.0.4           
[56] missForest_1.4       compiler_3.6.2       rlang_0.4.2          grid_3.6.2           iterators_1.0.12    
[61] rstudioapi_0.10      rmarkdown_2.0        gtable_0.3.0         ModelMetrics_1.2.2.1 codetools_0.2-16    
[66] abind_1.4-5          curl_4.3             reshape2_1.4.3       R6_2.4.1             lubridate_1.7.4     
[71] knitr_1.27           dplyr_0.8.3          zeallot_0.1.0        rJava_0.9-11         stringi_1.4.5       
[76] parallel_3.6.2       Rcpp_1.0.3           vctrs_0.2.1          rpart_4.1-15         tidyselect_0.2.5    
[81] xfun_0.12
```

- [x] Start a new R session
- [x] Install the latest version of caret: `update.packages(oldPkgs="caret", ask=FALSE)`
- [x] Write a minimal reproducible example
- [x] **Do not** use parallel processing in the code (unless you are certain that the issue is about parallel processing).
- [x] run `sessionInfo()`

I get this error with a train object of knn type in this code line:
```
pred <- extractPrediction(list(model_pls, model_lm, model_knn, model_rp), testX = testData, testY = testData$Close)
plotObsVsPred(pred)
```

" Error in knnregTrain(train = c(0.778538756778867, 0.729945810703869, 0.517766917579651, : dims of 'test' and 'train differ "

This is the code for knn with train(), the other models work with the plot function
```
model_knn <- train(Close~., data=trainData, method='knn', trControl = control,tuneGrid = hyper_grid)
ggplot(model_knn)
knn.predict <- predict(model_knn, testData)
postResample(knn.predict, testData$Close_eth) 
```
How can I solve this?
Many thanks!

Is it possible to add qrnn tau parameter (user specified quantiles) into train and predict function of the caret package? To my understanding, only tau = 0.5 parameter is automatically used. 
e.g.
`qneuron.cox <- train(cox ~ ., data = data.train.cox,
                    method = "qrnn",
                    tuneLength = 2,
                    #trControl = control,
                    metric = "RMSE")`
`predict(qneuron.cox, newdata = data.test.cox[,-88])`
Where to add tau parameter?

Hi, I am trying to recreate a random forest model from a paper, and the code doesnt seem to work, i am only just learning R and this is very much over my head, but i will try to explain as best I can. 

The source code from the paper can be found here: [(https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0181347.s002&type=supplementary)] 

The paper supplies two datasets: training and test, and then creates two subsets for each dataset (see attached notepad for a head() of the data 
[training.txt](https://github.com/topepo/caret/files/4027217/training.txt)
[test.txt](https://github.com/topepo/caret/files/4027223/test.txt)

(should be able to directly copy to a .csv) code is below:
```
sink("test.txt", split=TRUE)
print("#data process")
data_bin_train<-read.csv("training.csv", head=TRUE)
names(data_bin_train)
data_bin_test<-read.csv("test.csv", head=TRUE)
names(data_bin_test)
dspt_bin_train<-subset(data_bin_train,select=c(-Deamidation))
dspt_bin_test<-subset(data_bin_test,select=c(-Deamidation))
class_bin_train<-subset(data_bin_train, select=c(Deamidation))
class_bin_test<-subset(data_bin_test, select=c(Deamidation))

library("caret")
library("ROCR")
library("pROC")
fitControl <- trainControl(method = "CV",number = 10,returnResamp = "all", verboseIter = FALSE, classProbs = TRUE)
set.seed(2)
```
this bit works fine. Then the next bit of code is where i get the error: 

```
library("randomForest")
print("#Random Forest binary class via caret (randomForest)")
caret_rf_bin_randomf_cv10 <- train(Deamidation~., data=data_bin_train, method = "rf", preProcess = c("center", "scale"), tuneLength = 10, trControl = fitControl)
caret_rf_bin_randomf_cv10
varImp(caret_rf_bin_randomf_cv10)

rf_bin_Preds <- extractPrediction(list(caret_rf_bin_randomf_cv10),testX=dspt_bin_test[,1:13], testY=class_bin_test[,1]) 
Error in `[.data.frame`(newdata, , object$method$center, drop = FALSE) : 
  undefined columns selected
```

Any help would be amazing! The paper used R v 3.1.1 caret_6.0-35, whereas i am running  updated versions of both, which is where i believe the error is coming from, but i'm not sure how to fix it, or to be honest what the error even is.

Thank you 

TinoMass

below is the `sessionInfo()
```
R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] randomForest_4.6-14 pROC_1.15.3         ROCR_1.0-7          gplots_3.0.1.1      caret_6.0-84       
[6] ggplot2_3.2.1       lattice_0.20-38    

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3         pillar_1.4.3       compiler_3.5.3     gower_0.2.1        plyr_1.8.5         bitops_1.0-6      
 [7] iterators_1.0.12   class_7.3-15       tools_3.5.3        rpart_4.1-13       ipred_0.9-9        lubridate_1.7.4   
[13] lifecycle_0.1.0    tibble_2.1.3       nlme_3.1-137       gtable_0.3.0       pkgconfig_2.0.3    rlang_0.4.2       
[19] Matrix_1.2-15      foreach_1.4.7      rstudioapi_0.10    prodlim_2019.11.13 e1071_1.7-3        withr_2.1.2       
[25] stringr_1.4.0      dplyr_0.8.3        caTools_1.17.1.3   gtools_3.8.1       generics_0.0.2     recipes_0.1.8     
[31] stats4_3.5.3       grid_3.5.3         nnet_7.3-12        tidyselect_0.2.5   data.table_1.12.8  glue_1.3.1        
[37] R6_2.4.1           survival_2.43-3    gdata_2.18.0       lava_1.6.6         reshape2_1.4.3     purrr_0.3.3       
[43] magrittr_1.5       ModelMetrics_1.2.2 scales_1.1.0       codetools_0.2-16   MASS_7.3-51.1      splines_3.5.3     
[49] assertthat_0.2.1   timeDate_3043.102  colorspace_1.4-1   KernSmooth_2.23-15 stringi_1.4.3      lazyeval_0.2.2    
[55] munsell_0.5.0      crayon_1.3.4      
```
- [x] Start a new R session
- [x] Install the latest version of caret: `update.packages(oldPkgs="caret", ask=FALSE)`
- [x] [Write a minimal reproducible example](http://stackoverflow.com/a/5963610)
- [x] **Do not** use parallel processing in the code (unless you are certain that the issue is about parallel processing).
- [x] run `sessionInfo()`





### Overview

When using caret to train an XGBoost model with parallelization at the resample level, execution continues indefinitely (or at least, for more than several hours in my tests), when the first `summaryFunc` used is of type `twoClassSummary`.

For the same code, if a call is first made to `train()` on any arbitrary data, however, the executions proceeds as expected, and in the case of the example below, finishes in seconds.

This effect does not appear to depend on the parallelization back-end used; tested with:

- doParallel/PSOCK
- doMC
- doFuture

It also occurs if the `twoClassSummary` is used along-side of other summary functions as part of a yardstick `metric_set()`.

Based on this behavior, I'm guessing there is some kind of initialization of the interface with the parallelization back-end that normally occurs during the first invocation to `train()` which is not taking place as-expected, in the case below.

### Minimal, reproducible example:

To see the behavior in action, first run the code below _as-is_, and (at least in the linux environment I'm testing it in), it will likely continue running for a long time.

Next, uncomment the commented first call to `train()` and re-run the script. It will execute in parallel and finish quickly as expected.

```r
library(caret)
set.seed(1)

# create fake data
test_dat <- twoClassSim(20)

library("doFuture")
registerDoFuture()
plan(multiprocess, workers = parallel::detectCores() - 1)

# fast, when the lines below are uncommented...
# mod <- train(Class ~ ., data = test_dat, method = "xgbTree",
#              tuneLength = 1, nthread = 1,
#              trControl = trainControl(search = "random"))
# message("warm-up done...")

train_control <- trainControl(search = 'random',
                              classProbs = TRUE,
                              summaryFunction = twoClassSummary)

t1 <- Sys.time()
mod <- train(Class ~ ., data = test_dat, method = "xgbTree", tuneLength = 10,
             nthreads = 1, trControl = train_control,
             metric = 'ROC')
t2 <- Sys.time()
t2 - t1

# with warm-up: ~2 seconds
# without warm-up: > 3hrs
```

### Session Info:

Tested for two different versions of R/caret the same Linux machine:

**R 3.6.1**

- Using the current version of caret on CRAN, `6.0-84`.

```r
R version 3.6.1 (2019-07-05)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Arch Linux

Matrix products: default
BLAS:   /usr/lib/libopenblasp-r0.3.7.so
LAPACK: /usr/lib/liblapack.so.3.9.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] doFuture_0.8.2   iterators_1.0.12 foreach_1.4.7    future_1.15.1    globals_0.12.5  
[6] caret_6.0-84     ggplot2_3.2.1    lattice_0.20-38 

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3         pillar_1.4.2       compiler_3.6.1     gower_0.2.1        plyr_1.8.5        
 [6] tools_3.6.1        class_7.3-15       digest_0.6.23      rpart_4.1-15       ipred_0.9-9       
[11] lubridate_1.7.4    lifecycle_0.1.0    tibble_2.1.3       nlme_3.1-143       gtable_0.3.0      
[16] pkgconfig_2.0.3    rlang_0.4.2        Matrix_1.2-17      prodlim_2019.11.13 e1071_1.7-3       
[21] stringr_1.4.0      withr_2.1.2        dplyr_0.8.3        generics_0.0.2     recipes_0.1.7     
[26] xgboost_0.90.0.2   stats4_3.6.1       grid_3.6.1         nnet_7.3-12        tidyselect_0.2.5  
[31] data.table_1.12.8  glue_1.3.1         listenv_0.8.0      R6_2.4.1           survival_3.1-8    
[36] lava_1.6.6         reshape2_1.4.3     purrr_0.3.3        magrittr_1.5       ModelMetrics_1.2.2
[41] scales_1.1.0       codetools_0.2-16   MASS_7.3-51.4      splines_3.6.1      assertthat_0.2.1  
[46] timeDate_3043.102  colorspace_1.4-1   stringi_1.4.3      lazyeval_0.2.2     munsell_0.5.0     
[51] crayon_1.3.4      
```


**R nightly (2019-12-10)**

- Using latest version of Caret from the GH master branch, commit #22cdd34.

```
R Under development (unstable) (2019-12-10 r77549)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Arch Linux

Matrix products: default
BLAS:   /usr/lib/libopenblasp-r0.3.7.so
LAPACK: /usr/lib/liblapack.so.3.9.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] doFuture_0.8.2   iterators_1.0.12 foreach_1.4.7    future_1.15.1    globals_0.12.5  
[6] caret_6.0-84     ggplot2_3.2.1    lattice_0.20-38 

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3         pillar_1.4.2       compiler_4.0.0     gower_0.2.1        plyr_1.8.5        
 [6] tools_4.0.0        class_7.3-15       digest_0.6.23      rpart_4.1-15       ipred_0.9-9       
[11] lubridate_1.7.4    lifecycle_0.1.0    tibble_2.1.3       nlme_3.1-143       gtable_0.3.0      
[16] pkgconfig_2.0.3    rlang_0.4.2        Matrix_1.2-18      prodlim_2019.11.13 e1071_1.7-3       
[21] stringr_1.4.0      withr_2.1.2        dplyr_0.8.3        generics_0.0.2     recipes_0.1.7     
[26] xgboost_0.90.0.2   stats4_4.0.0       grid_4.0.0         nnet_7.3-12        tidyselect_0.2.5  
[31] data.table_1.12.8  glue_1.3.1         listenv_0.8.0      R6_2.4.1           survival_3.1-8    
[36] lava_1.6.6         reshape2_1.4.3     purrr_0.3.3        magrittr_1.5       ModelMetrics_1.2.2
[41] scales_1.1.0       codetools_0.2-16   MASS_7.3-51.4      splines_4.0.0      assertthat_0.2.1  
[46] timeDate_3043.102  colorspace_1.4-1   stringi_1.4.3      lazyeval_0.2.2     munsell_0.5.0     
[51] crayon_1.3.4      
```

Hi,
 I came across a weird problem, When I use the package in windows and it is okay. But when I use the package in linux there is some problems: the AUC is negative. Could you have some suggestions?

```r
> library(caret)
>
> set.seed(2969)
> imbal_train <- twoClassSim(1000, intercept = -20, linearVars = 20)
> ctrl <- trainControl(method = "repeatedcv", repeats = 5,
+                      classProbs = TRUE,
+                      summaryFunction = twoClassSummary)
>
> set.seed(5627)
> orig_fit <- train(Class ~ ., data = imbal_train,
+                   method = "treebag",
+                   nbagg = 50,
+                   metric = "ROC",
+                   trControl = ctrl)
> orig_fit
Bagged CART

1000 samples
  25 predictor
   2 classes: 'Class1', 'Class2'

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times)
Summary of sample sizes: 901, 901, 899, 899, 900, 899, ...
Resampling results:

  ROC        Sens       Spec
  -2.346135  0.9869595  0.3533333
```
Hello 
I got this warning message again when use Caret for ANN model
_Warning message:
In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance_ 
I checked the resample performance as suggested by [this](https://github.com/topepo/caret/issues/905) but find no NA
Could you please advise the reason for this issue? Is there by any chance I can ask Caret to output the performance matrics of every cross validation samples? 
When `returnData` is `TRUE` in `trainControl`, and the training data is a sparse matrix object, the following warning is generated:

`Warning train.default(x = train_x, y = as.factor(ifelse(train_y == 1,  :
    The training data could not be converted to a data frame for saving`

This fixes the problem (mentioned in #474) by adding a simple condition checking for `sparseMatrix` objects in `train.default` and converts it to regular `matrix` object before conversion to `data.frame`.
This fixes caret's glmnet model object so that sparse matrix objects are not converted to regular matrix anymore. I was experiencing extremely long CV and training times with caret in comparison to vanilla `glmnet::cv.glmnet` with sparse matrix data coming from text2vec.

This problem was mentioned in #474. Caret's code for training and testing a glmnet model currently checks if the input data is a sparse matrix using the `class` function. This is incorrect as sparse matrices from Matrix can be of different classes. For example, my object returned by text2vec is of class `dgCMatrix`. The fix relying on the `inherits` function instead of `class` should work with any sparse matrix returned by the Matrix package.

(Note that I didn't include in the commit the updated binary pkg/caret/inst/models/models.RData generated by models/parseModels.R)