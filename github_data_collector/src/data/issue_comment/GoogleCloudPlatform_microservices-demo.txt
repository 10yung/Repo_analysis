I follow the installation steps from option 3. I had already a running kubernetes cluster. So I only execute:

`kubectl apply -f ./release/kubernetes-manifests.yaml`

When I evaluate the result with `kubectl get pods` I get:

```
NAME                                     READY   STATUS             RESTARTS   AGE
adservice-55f9757757-9tb2h               1/1     Running            0          16m
cartservice-684bb46b44-b6dvk             0/1     CrashLoopBackOff   8          16m
checkoutservice-6fcc84467f-gm79f         1/1     Running            0          16m
currencyservice-6c7c479d45-qfnl6         1/1     Running            0          16m
emailservice-8dd9b76cc-7j6zj             1/1     Running            0          16m
frontend-7d8cfc75b5-dqnkc                1/1     Running            0          16m
loadgenerator-5db67d555-fq42k            0/1     CrashLoopBackOff   7          16m
paymentservice-84ffc75c55-mzwfx          1/1     Running            0          16m
productcatalogservice-d564bdf4c-bch2r    1/1     Running            0          16m
recommendationservice-76598d5889-p9qhm   1/1     Running            0          16m
redis-cart-5f59546cdd-rqqdf              1/1     Running            0          16m
shippingservice-b6db65f7f-t54ng          1/1     Running            0          16m
```
`cartservice` and `loadgenerator` are not able to start.

---

### Logs

`kubectl logs cartservice-684bb46b44-b6dvk`

```
Started as process with id 1
Reading host address from LISTEN_ADDR environment variable
Reading cart service port from PORT environment variable
Reading redis cache address from environment variable REDIS_ADDR
Connecting to Redis: redis-cart:6379,ssl=false,allowAdmin=true,connectRetry=5
StackExchange.Redis.RedisConnectionException: It was not possible to connect to the redis server(s). UnableToConnect on redis-cart:6379/Interactive, Initializing/NotStarted, last: NONE, origin: BeginConnectAsync, outstanding: 0, last-read: 5s ago, last-write: 5s ago, keep-alive: 180s, state: Connecting, mgr: 10 of 10 available, last-heartbeat: never, global: 10s ago, v: 2.0.601.3402
   at StackExchange.Redis.ConnectionMultiplexer.ConnectImpl(Object configuration, TextWriter log) in C:\projects\stackexchange-redis\src\StackExchange.Redis\ConnectionMultiplexer.cs:line 955
   at cartservice.cartstore.RedisCartStore.EnsureRedisConnected() in /app/cartstore/RedisCartStore.cs:line 80
   at cartservice.cartstore.RedisCartStore.InitializeAsync() in /app/cartstore/RedisCartStore.cs:line 60
   at cartservice.Program.<>c__DisplayClass4_0.<<StartServer>b__0>d.MoveNext() in /app/Program.cs:line 54
```

`kubectl logs loadgenerator-5db67d555-fq42k`

```
./loadgen.sh: 21: ./loadgen.sh: [[: not found
+ curl --silent --output /dev/stderr --write-out %{http_code} http://frontend:80
+ STATUSCODE=000
```

---

### Machine
Debian 10 behind a Proxy
Local Hosting
The package `go.opencensus.io/exporter/jaeger` has been moved to ` contrib.go.opencensus.io/exporter/jaeger`. This PR updates the dependencies, replacing instances of the old import across all Golang services with the recent package and also updating the deps dependency.
Update build.gradle to use plugin DSL instead of outdated buildscript
Update gradle wrapper to 6.0.1
Update jackson, opencensus, grpc & other dependencies to latest versions
Fix code warnings
Properly format source files using goJF task
Add default port to AdService
The deployment installs two services, frontend and frontend-external. Do we need to have two? Can we just have a single load balancer service? 

Otherwise the logs of pilot show

```
        "pilot_conflict_inbound_listener": {
            "frontend-b64f4c9bb-jt4k6.micro": {
                "proxy": "frontend-b64f4c9bb-jt4k6.micro",
                "message": "Conflicting inbound listener:10.28.0.29:8080. existing: frontend-external.micro.svc.cluster.local, incoming: frontend.micro.svc.cluster.local"
            }
        },
```

If there is a good reason to have both, we should explain why -- users presumably are looking at this for best practices, so if we are doing something non-standard it would make sense to explain why possible?
Hi all,

I have tried to deploy the microservice demo in a GKE using CloudShell. I ran out of space on Cloud Shell, so, following the docs, I have tried the following command:
`skaffold run -p gcb --default-repo=gcr.io/sandbox-altran`
The output is:
```
Generating tags...
 - emailservice -> gcr.io/sandbox-altran/emailservice:v0.1.2-6-g61dd049
 - productcatalogservice -> gcr.io/sandbox-altran/productcatalogservice:v0.1.2-6-g61dd049
 - recommendationservice -> gcr.io/sandbox-altran/recommendationservice:v0.1.2-6-g61dd049
 - shippingservice -> gcr.io/sandbox-altran/shippingservice:v0.1.2-6-g61dd049
 - checkoutservice -> gcr.io/sandbox-altran/checkoutservice:v0.1.2-6-g61dd049
 - paymentservice -> gcr.io/sandbox-altran/paymentservice:v0.1.2-6-g61dd049
 - currencyservice -> gcr.io/sandbox-altran/currencyservice:v0.1.2-6-g61dd049
 - cartservice -> gcr.io/sandbox-altran/cartservice:v0.1.2-6-g61dd049
 - frontend -> gcr.io/sandbox-altran/frontend:v0.1.2-6-g61dd049
 - loadgenerator -> gcr.io/sandbox-altran/loadgenerator:v0.1.2-6-g61dd049
 - adservice -> gcr.io/sandbox-altran/adservice:v0.1.2-6-g61dd049
Checking cache...
 - emailservice: Not found. Building
 - productcatalogservice: Not found. Building
 - recommendationservice: Not found. Building
 - shippingservice: Not found. Building
 - checkoutservice: Not found. Building
 - paymentservice: Not found. Building
 - currencyservice: Not found. Building
 - cartservice: Not found. Building
 - frontend: Not found. Building
 - loadgenerator: Not found. Building
 - adservice: Not found. Building
Building [emailservice]...
FATA[0003] failed to build: build failed: build failed: building [emailservice]: extracting projectID from image name: unable to guess GCP projectID from image name [emailservice]
```

I notices even tough my project is correctly set with gcloud config set project, the PROJECT_ID env var was not set. I manually adjusted the env var, but still, the error persists. 
[cartservice: move tests/ dir out of root](https://github.com/GoogleCloudPlatform/microservices-demo/issues/10)
Hi team,
Trying to deploy hipster shop on a local Kubernetes cluster.

Currency and payment services in CrashLoopbackOff:

**kubectl logs -f paymentservice-65bcb767c6-zcf94**
@google-cloud/trace-agent ERROR StackdriverTracer#start: Tracing might not work as the following modules were loaded before the trace agent was initialized: [@google-cloud/common, @google-cloud/profiler, @google-cloud/projectify, @google-cloud/promisify, @protobufjs/aspromise, @protobufjs/base64, @protobufjs/eventemitter, @protobufjs/float, @protobufjs/inquire, @protobufjs/pool, @protobufjs/utf8, abbrev, agent-base, ansi-regex, aproba, are-we-there-yet, arrify, balanced-match, base64-js, bignumber.js, brace-expansion, buffer-equal-constant-time, code-point-at, concat-map, console-control-strings, console-log-level, core-util-is, debug, delay, delegates, detect-libc, duplexify, ecdsa-sig-formatter, end-of-stream, ent, es6-promisify, extend, findit2, fs.realpath, gauge, gaxios, gcp-metadata, glob, google-auth-library, gtoken, has-unicode, https-proxy-agent, inflight, inherits, is-fullwidth-code-point, isarray, json-bigint, jwa, jws, long, lru-cache, mime, minimatch, ms, node-fetch, node-pre-gyp, nopt, npmlog, number-is-nan, object-assign, once, os-homedir, os-tmpdir, osenv, p-limit, p-try, parse-duration, parse-ms, path-is-absolute, pify, pprof, pretty-ms, process-nextick-args, protobufjs, readable-stream, retry-request, rimraf, safe-buffer, semver, set-blocking, signal-exit, source-map, split, stream-shift, string-width, strip-ansi, teeny-request, through, through2, util-deprecate, uuid, wide-align, wrappy, yallist]
D0917 23:37:12.992274043       1 env_linux.cc:71]            Warning: insecure environment read function 'getenv' used

**kubectl logs -f currencyservice-7f8658c69d-2xhg7**
@google-cloud/trace-agent ERROR StackdriverTracer#start: Tracing might not work as the following modules were loaded before the trace agent was initialized: [@google-cloud/common, @google-cloud/profiler, @google-cloud/projectify, @google-cloud/promisify, @protobufjs/aspromise, @protobufjs/base64, @protobufjs/eventemitter, @protobufjs/float, @protobufjs/inquire, @protobufjs/pool, @protobufjs/utf8, abbrev, agent-base, ansi-regex, aproba, are-we-there-yet, arrify, balanced-match, base64-js, bignumber.js, brace-expansion, buffer-equal-constant-time, code-point-at, concat-map, console-control-strings, console-log-level, core-util-is, debug, delay, delegates, detect-libc, duplexify, ecdsa-sig-formatter, end-of-stream, ent, es6-promisify, extend, findit2, fs.realpath, gauge, gaxios, gcp-metadata, glob, google-auth-library, gtoken, has-unicode, https-proxy-agent, inflight, inherits, is-fullwidth-code-point, isarray, json-bigint, jwa, jws, long, lru-cache, mime, minimatch, ms, node-fetch, node-pre-gyp, nopt, npmlog, number-is-nan, object-assign, once, os-homedir, os-tmpdir, osenv, p-limit, p-try, parse-duration, parse-ms, path-is-absolute, pify, pprof, pretty-ms, process-nextick-args, protobufjs, readable-stream, retry-request, rimraf, safe-buffer, semver, set-blocking, signal-exit, source-map, split, stream-shift, string-width, strip-ansi, teeny-request, through, through2, util-deprecate, uuid, wide-align, wrappy, yallist]
D0917 23:38:15.241807791       1 env_linux.cc:71]            Warning: insecure environment read function 'getenv' used
{"severity":"info","time":1568763495957,"message":"Starting gRPC server on port 7000...","pid":1,"hostname":"currencyservice-7f8658c69d-2xhg7","name":"currencyservice-server","v":1}

**Seems to be an issue with the liveness and readiness probes:**

Events:
  Type     Reason     Age                    From                                           Message
  ----     ------     ----                   ----                                           -------
  Normal   Scheduled  28m                    default-scheduler                              Successfully assigned default/currencyservice-7f8658c69d-2xhg7 to ddb3d636-12dc-4f86-9941-ddf3663f6b62
  Normal   Pulling    27m                    kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  pulling image "gcr.io/google-samples/microservices-demo/currencyservice:v0.1.2"
  Normal   Pulled     27m                    kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Successfully pulled image "gcr.io/google-samples/microservices-demo/currencyservice:v0.1.2"
  Warning  Unhealthy  27m                    kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Liveness probe failed: OCI runtime exec failed: exec failed: container_linux.go:348: starting container process caused "read init-p: connection reset by peer": unknown
  Normal   Created    26m (x4 over 27m)      kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Created container
  Normal   Started    26m (x4 over 27m)      kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Started container
  Normal   Pulled     26m (x3 over 27m)      kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Container image "gcr.io/google-samples/microservices-demo/currencyservice:v0.1.2" already present on machine
  Warning  Unhealthy  26m (x2 over 27m)      kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Readiness probe failed:
  Warning  Unhealthy  26m                    kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Liveness probe failed:
  Warning  BackOff    2m31s (x117 over 27m)  kubelet, ddb3d636-12dc-4f86-9941-ddf3663f6b62  Back-off restarting failed container

Any idea how to work around this ?
Changed httpError for failing to complete order to "http.StatusBadRequest"

Tested with Minikube+KVM (4 CPU; 4GB RAM).

Signed-off-by: Ihor Dvoretskyi <ihor@linux.com>