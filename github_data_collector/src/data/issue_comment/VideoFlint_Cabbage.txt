I have been working on to create a video collage with layer border, but even the library works fine I can not apply any transformation or border layer.
I'm creating a video editing app and I have functionality to add transitions and audios.

When adding transitions, without added audios, it renders fine, with transitions and all.

Also when adding audios, without added transitions, it renders fine, audio plays fine.

However, if I add a transition and audio on the timeline, only the audio plays and the video is only black. Here's my code.

	private func buildTracks() {
		var videoChannel: [TrackItem] = []
		var audioChannel: [TrackItem] = []
		
		for asset in assets {
			let resource = trackResource(for: asset)

			let trackItem = TrackItem(resource: resource)
			trackItem.videoConfiguration.contentMode = .aspectFit
			
			switch asset.transition {
			case 1:
				let transitionDuration = CMTime(seconds: 0.5, preferredTimescale: preferredTimeScale)
				let transition = CrossDissolveTransition(duration: transitionDuration)
				trackItem.videoTransition = transition
				print("CROSS DISSOLVE")
			case 2:
				let transitionDuration = CMTime(seconds: 0.5, preferredTimescale: preferredTimeScale)
				let transition = FadeTransition(duration: transitionDuration)
				trackItem.videoTransition = transition
				print("FADE BLACK")
			case 3:
				let transitionDuration = CMTime(seconds: 0.5, preferredTimescale: preferredTimeScale)
				let transition = FadeTransition(duration: transitionDuration)
				trackItem.videoTransition = transition
				print("FADE WHITE")
			default:
				trackItem.videoTransition = nil
				print("NONE")
			}
			
			if let asset = asset as? VVideoAsset {
				trackItem.audioConfiguration.volume = asset.volume
			}
			
			videoChannel.append(trackItem)
			audioChannel.append(trackItem)
			
			let filterConfigurations = videoEdit.filters.map { FilterConfiguration(filter: $0, totalDuration: totalDuration) }
			trackItem.videoConfiguration.configurations = filterConfigurations
		}
		
		timeline.videoChannel = videoChannel
		timeline.audioChannel = audioChannel
	}

	private func buildAudios() -> [AudioProvider] {
		var audios: [AudioProvider] = []
		
		videoEdit.audios.forEach { (audio) in
			guard let audioURL = audio.audioAsset.mp3Path else {
				return
			}
			
			let audioAsset = AVAsset(url: audioURL)
			let resource = AVAssetTrackResource(asset: audioAsset)
			let duration = audio.duration * totalDuration
			
			resource.selectedTimeRange = CMTimeRange.init(start: CMTime.zero, end: CMTimeMakeWithSeconds(duration, preferredTimescale: preferredTimeScale))
			let audioTrackItem = TrackItem(resource: resource)
			audioTrackItem.audioConfiguration.volume = audio.volume
			audioTrackItem.startTime = CMTimeMakeWithSeconds(audio.componentStart * totalDuration, preferredTimescale: preferredTimeScale)
			
			audios.append(audioTrackItem)
		}
		
		return audios
	}

	private func buildAddedComponents() {
		timeline.audios = buildAudios()
		timeline.overlays = buildOverlays()
	}
I want to build application add multi music to video. 
I have a video track item and some audio track item.
I need to misc some audio track (with different start time) and video.
Ref: I have referenced on page -->  https://github.com/vitoziv/VideoCat
Example: 
video: ___________[=======================] video track
audios : [--------===========] audio track 1
____________[-----========] audio track 2
__________________[=======================--------] audio track 3
____[-------------=======================---------] audio track 4
Note: 
====== : available
-------- : unavailable 

> 
         video: ______________________[=======================] video track
         audio track 1:___[~~~~~~~~===========] offsetTime < 0
         audio track 2:_______________~~~~~~~~[===========] offsetTime > 0
         ==> ~~~~~ : offsetTime

        
         video__:[========================60s===================] total
         result: 60s --> 20s with lowtime 20s, uptime 40s
         trimed_:[[-----20s-----][======20s=====][______20s_____]
         trimed_:[[+++++++++++++++++++++++++++++]
         ==> [----] lowtime
         ==> [+++] up time
        
       convenience init --> AudioData :
        self.offsetTime = offsetTime
        self.lowTime = lowTime > 0.0 ? lowTime : 0.0
        let upValue = max(upTime, lowTime)
        self.upTime = upValue
        let durationValue = upValue - lowTime
        self.duration = durationValue
        let startTime = lowTime + offsetTime
        self.startTime = startTime
        let distance = min(durationValue, videoDuration)
        let available = distance - startTime
        self.available = available
 
My code: 
Video track item: 
> 
        let asset = AVAsset(url: url)
        let resource = AVAssetTrackResource(asset: asset)
        let lowTime = CMTime(seconds: video.lowTime, preferredTimescale: 600) 
        //default lowtime = 0.0
        let durationTime = CMTime(seconds: video.duration, preferredTimescale: 600)
        //default video.duration = total time of video
        resource.selectedTimeRange = CMTimeRange(start: CMTime.zero, duration: durationTime)
        let videoTrackItem = TrackItem(resource: resource)
        videoTrackItem.startTime = lowTime
        videoTrackItem.videoConfiguration.contentMode = .aspectFill
        videoTrackItem.audioConfiguration.volume = video.volume

        context.viewModel.addVideoTrackItem(videoTrackItem)
        context.videoView.player.replaceCurrentItem(context.viewModel.playerItem)
        context.timelineView.reload(with: context.viewModel.videoTrackItems)

A Audio track item: 
> 
        let asset = AVAsset(url: url)
        let resource = AVAssetTrackResource(asset: asset)
        
        print("lowtime \(audio.lowTime)") // default low time = 0.0
        print("upTime \(audio.upTime)")
        print("startTime \(audio.startTime)")
        print("available \(audio.available)")
        print("videoDuration \(self.durationTimeOfVideo)")

        let startTime = CMTime(seconds: audio.startTime, preferredTimescale: 600)
        let availableTime = CMTime(seconds: audio.available, preferredTimescale: 600)

        resource.selectedTimeRange = CMTimeRange(start: CMTime.zero, duration: availableTime)
        let trackItem = TrackItem(resource: resource)
        trackItem.startTime = startTime
        trackItem.audioConfiguration.volume = audio.volume

TimelineViewModel
> 
     class TimelineManager {
           static let current = TimelineManager()
          var timeline = Timeline()
     }
     
     class TimelineViewModel {
    
          // MARK: - Vars
         private(set) var audioTrackItems = [TrackItem]()
         private(set) var videoTrackItems = [TrackItem]()
         private(set) var renderSize: CGSize = CGSize.zero
         private(set) var lut: String = "original_lut"
         private(set) var playerItem = AVPlayerItem(asset: AVComposition())

        func buildTimeline() -> Timeline {
               let timeline = TimelineManager.current.timeline
               reloadTimeline(timeline)
               return timeline
        }

        // MARK: - Add/Replace
    
        func addVideoTrackItem(_ trackItem: TrackItem) {
               videoTrackItems.append(trackItem)
               reloadPlayerItems()
        }

        func insertTrackItem(_ trackItem: TrackItem, at index: Int) {
             guard audioTrackItems.count >= index else { return }
             audioTrackItems.insert(trackItem, at: index)
             reloadPlayerItems()
        }

       func updateTrackItem(_ trackItem: TrackItem, at index: Int) {
           guard audioTrackItems.count > index else { return }
           audioTrackItems[index] = trackItem
           reloadPlayerItems()
      }
    
       func removeTrackItem(_ trackItem: TrackItem) {
            guard let index = audioTrackItems.index(of: trackItem) else { return }
            audioTrackItems.remove(at: index)
            reloadPlayerItems()
       }
    
       func removeTrackItem(at index: Int) {
             guard audioTrackItems.count > index else { return }
             audioTrackItems.remove(at: index)
             reloadPlayerItems()
       }
    
       func removeAllAudioTrackItems() {
            audioTrackItems.removeAll()
            reloadPlayerItems()
      }
    
      func removeAll() {
           audioTrackItems.removeAll()
           videoTrackItems.removeAll()
           reloadPlayerItems()
      }

       func reloadPlayerItems() {
              let timeline = TimelineManager.current.timeline
              timeline.renderSize = renderSize
             reloadTimeline(timeline)
             do {
                   try Timeline.reloadVideoStartTime(providers: videoTrackItems)
             } catch {
                  assert(false, error.localizedDescription)
             }
             build(with: timeline)
         }

       fileprivate func build(with timeline: Timeline) {
             let compositionGenerator = CompositionGenerator(timeline: timeline)
            let playerItem = compositionGenerator.buildPlayerItem()
            self.playerItem = playerItem
       }

       fileprivate func reloadTimeline(_ timeline: Timeline) {
            timeline.videoChannel = videoTrackItems
            timeline.audios = videoTrackItems + audioTrackItems
       }

> 

     extension TrackItem {
           func reloadTimelineDuration() {
                self.duration = self.resource.selectedTimeRange.duration
           }
    }

==> Errors: 
   - When offsettime < 0: 
video: ______________________[=======================] video track
audio track:___[~~~~~~~~~===========] offsetTime < 0
  --> audio track play incorrect starttime


同题，谢谢~
Basic example -
```
public class MyFilter: VideoConfigurationProtocol {
    
    var filter: TestFilter!
    public var setIntensity: CGFloat = 0.3
    
    public init() { }
    
    public func applyEffect(to sourceImage: CIImage, info: VideoConfigurationEffectInfo) -> CIImage {
        
        var finalImage = sourceImage
        
        filter = TestFilter()
        filter.inputImage = finalImage
        filter.intensity = setIntensity
        finalImage = filter.outputImage!
        
        return finalImage
    }
    
}
```

Then when appending this class into trackItem.videoConfiguration.configurations, would there be a preferred method to adjust the setIntensity variable with a UISlider? 
你好！

我们在你的中文说明当中看到以下信息：
对 CALayer 的支持，可以把 CALayer 所支持的所有 CoreAnimation 动画带入到视频画面中。比如使用 Lottie，设计师在 AE 中导出的动画配置，客户端用配置生成 CALayer 类，添加到 AVVideoCompositionCoreAnimationTool 中就可以很方便的实现视频中做贴纸动画的功能。

能否提供1～2个相应使用Lottie导出的动画配置做的视频合成的例子吗？

Jack
WeChat：15915895880
Hi, I find it support Pod install. but it seem to not support carthage.
Carthage is a good project that can help us manage other framework.
if Cabbage can support cartahge, I think it will be cool.
可以优化一下，兼容声音时间更多的情况