Not entirely sure this is the right place to do it but couldn't figure out where else it would go.
Updates [com.github.ben-manes.caffeine:caffeine](https://github.com/ben-manes/caffeine) [from 2.8.0 to 2.8.1](https://github.com/ben-manes/caffeine/compare/v2.8.0...v2.8.1).
[Release Notes/Changelog](https://github.com/ben-manes/caffeine/releases/tag/v2.8.1)

I'll automatically update this PR to resolve conflicts as long as you don't change it yourself.

If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below.

Have a fantastic day writing Scala!

<details>
<summary>Ignore future updates</summary>

Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:
```
updates.ignore = [ { groupId = "com.github.ben-manes.caffeine", artifactId = "caffeine" } ]
```
</details>

labels: library-update, semver-patch
Currently we wrap a failure to unmarshall with Jackson in an IllegalArgumentException with the text "Cannot unmarshal JSON as [type]" and then pass the exception with details as a cause, however when this ends up in the routing tree only the top level exception message is in the response body, and that isn't very useful for figuring out what is wrong with the request JSON.

I think we should provide the validation error details from Jackson in the exception message or have a specific exception type for the failure and handle that in the ExceptionHandler.
Refs #2895
As promised in its deprecation message
None
Refs #70

Before merging should be updated not to take a `Materializer` implicit but instead use either #2886 or https://github.com/akka/akka/pull/28494
As @surendarchandra noticed, our HPACK header tries to encode as many header values as possible into dynamic table entries. The effect can be that high entropy headers like `Date` or `Content-Length` evict more useful headers from the dynamic table.

The HPACK implementation from twitter that we use, allows to pass the `sensitive` flag to `encodeHeader` which prevents that the values are put into the dynamic table. We should consider to encode high entropy header using the `sensitive` flag for better use of the dynamic header table.
Fixes #2888.
I'm writing an application with the AKKA actors framework and I'm sending a message to a child actor which sends two HTTP requests to a unix domain socket (to query the Docker socket) using guidance from https://stackoverflow.com/questions/51565935/how-to-access-rest-api-on-a-unix-domain-socket-with-akka-http-or-alpakka. When I send the first round of HTTP requests I do not receive any errors. After this first round of HTTP requests is successful there is a check_in message sent to the parent actor. Once all child actors check in, the parent actor sends a broadcast to all child actors for the second round of HTTP requests. After attempting to send the first HTTP POST request I receive the following error:

```
[ERROR] [01/14/2020 19:10:40.458] [ScoringWorker-akka.actor.default-dispatcher-18] [akka.actor.ActorSystemImpl(ScoringWorker)] Outgoing request stream error
java.lang.IllegalStateException: Substream Source cannot be materialized more than once
        at akka.stream.impl.fusing.SubSource$$anon$13.setCB(StreamOfStreams.scala:796)
        at akka.stream.impl.fusing.SubSource$$anon$13.preStart(StreamOfStreams.scala:806)
        at akka.stream.impl.fusing.GraphInterpreter.init(GraphInterpreter.scala:292)
        at akka.stream.impl.fusing.GraphInterpreterShell.init(ActorGraphInterpreter.scala:568)
        at akka.stream.impl.fusing.ActorGraphInterpreter.tryInit(ActorGraphInterpreter.scala:675)
        at akka.stream.impl.fusing.ActorGraphInterpreter.finishShellRegistration(ActorGraphInterpreter.scala:718)
        at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$shortCircuitBatch(ActorGraphInterpreter.scala:733)
        at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:758)
        at akka.actor.Actor.aroundReceive(Actor.scala:539)
        at akka.actor.Actor.aroundReceive$(Actor.scala:537)
        at akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(ActorGraphInterpreter.scala:664)
        at akka.actor.ActorCell.receiveMessage(ActorCell.scala:610)
        at akka.actor.ActorCell.invoke(ActorCell.scala:579)
        at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268)
        at akka.dispatch.Mailbox.run(Mailbox.scala:229)
        at akka.dispatch.Mailbox.exec(Mailbox.scala:241)
        at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

java.lang.IllegalStateException: Substream Source cannot be materialized more than once
```

This is the psuedocode for the WorkerActor:

```
class WorkerActor() extends Actor {
  object DockerSockTransport extends ClientTransport {
    override def connectTo(host: String, port: Int, settings: ClientConnectionSettings)(implicit system: ActorSystem): Flow[ByteString, ByteString, Future[Http.OutgoingConnection]] = {
      // ignore everything for now

      UnixDomainSocket().outgoingConnection(new File("/var/run/docker.sock"))
        .mapMaterializedValue { _ =>
          // Seems that the UnixDomainSocket.OutgoingConnection is never completed? It works anyway if we just assume it is completed
          // instantly
          Future.successful(Http.OutgoingConnection(InetSocketAddress.createUnresolved(host, port), InetSocketAddress.createUnresolved(host, port)))
        }
    }
  }
  implicit val new_system = context.system
  implicit val mat = ActorMaterializer()(new_system)
  import new_system.dispatcher
  val settings = ConnectionPoolSettings(new_system).withTransport(DockerSockTransport).withMaxConnections(65535)
  import SprayJsonSupport._ 
  def handleResponse(response: HttpResponse): Future[String] =
      // TODO: create docker json model classes and directly marshal to them
  	  Unmarshal(response).to[String]

  def DockerClient(httpMethod: String, path: String) {
    if (httpMethod == "POST") {
      Http().singleRequest(HttpRequest(method = HttpMethods.POST, uri = "http://localhost" + path, entity = HttpEntity(ContentTypes.`application/json`, userData)), settings = settings)
        .flatMap(handleResponse)
        .onComplete { 
          case Success(res: String) =>
            println("Return: " + res)
            }
          case Failure(resp) =>
            println(resp)
        }
    } else {
      Http().singleRequest(HttpRequest(method = HttpMethods.GET, uri = "http://localhost" + path), settings = settings)
        .flatMap(handleResponse)
        .onComplete { res =>
          println(s"Got result: [$res]")
        }
    }
  }

  def receive = {
    case round() =>
  	  DockerClient("POST", "/containers/xxx/exec")
  }
```
These are the dependencies I am using:
```
  scalaVersion := "2.12.8",
  scalacOptions in ThisBuild ++= Seq("-unchecked", "-deprecation", "-feature"),
  resolvers += "Typesafe Repository" at "http://repo.typesafe.com/typesafe/releases/",
  libraryDependencies ++= Seq("com.typesafe.akka" %% "akka-actor" % "2.5.22"),
  libraryDependencies ++= Seq("com.typesafe.akka" %% "akka-remote" % "2.5.22"),
  libraryDependencies ++= Seq("com.typesafe.akka" %% "akka-stream" % "2.5.22"),
  libraryDependencies ++= Seq("com.typesafe.akka" %% "akka-http-spray-json" % "10.1.8"),
  libraryDependencies ++= Seq("com.lightbend.akka" %% "akka-stream-alpakka-unix-domain-socket" % "0.20")
```