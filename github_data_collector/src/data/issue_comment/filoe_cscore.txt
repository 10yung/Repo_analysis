I have an mp3 file which i load into a memorystream and then, after some code, i play it. How can i change the playback speed to x1.4?

Current code:
DirectSoundOut SoundOut = new DirectSoundOut();
byte[] TargetFile = File.ReadAllBytes("PathToFile");
MemoryStream ms = new MemoryStream(TargetFile);
SoundOut.Initialize(new CSCore.Codecs.MP3.DmoMp3Decoder(ms));
SoundOut.Volume = 1;
SoundOut.Play();
Main readme says: " CSCore.Ffmpeg project which is licensed under the LGPL".

[This file](https://github.com/filoe/cscore/blob/master/CSCore.Ffmpeg/FFmpeg/licenses/x264.txt) in CSCore.Ffmpeg says: "GNU GENERAL PUBLIC LICENSE"

And in general I found out that "The combination of GPL code and LGPL code must be licensed under the GPL." This means that CSCore.Ffmpeg can't use LGPL license. 

If FFmpeg is built for LGPL all GPL licenses should be deleted in https://github.com/filoe/cscore/tree/master/CSCore.Ffmpeg/FFmpeg/licenses as those features/libraries are not used.
Hello it might be a bit of a stupid question, but I can't seem to figure out how to specify an audio input/output device for a WaveCapture or WasapiCapture.

```
WasapiCapture input = new WasapiCapture();
input.Device = // This has to be an MMDevice
```

The problem is, I don't know where can I get an `MMDevice` from. I tried enumerating them, but I got to a dead end.

What I could achieve is enumerating all the `WaveInDevice`s and `WaveOutDevice`s.

Is there any way to convert a `WaveInDevice` to a `MMDevice` or somehow get a list of all input `MMDevice`s?

This class enables the programmer to manipulate Windows settings for audio devices, such as the default device for each role. It's rather messy due to the fact that the COM Interface IID changes with a considerable frequency, hence we need to try to support every possibility, falling back to an unknown interface (https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-dcom/2b4db106-fb79-4a67-b45f-63654f19c54c) as a last resort. This class is basically a mashup of many different implementations of the same feature across public repositories, extracting, to my best judgment, the best of each. It's most probably not following the project code standards so I'm kinda expecting for someone to help me on that :)

Sorry for any inconvenience!
As stated in the title, DirectSoundOut seems to be throwing a NullReferenceException on Finalize if it's been initialized before closing the app. No exceptions if it hasn't been initialized yet. It seems to be a DirectSound issue specifically, because I switched to Wasapi and it didn't throw any exceptions. I'm using v1.2.1.2 from NuGet.

Here's the error I got:
> System.NullReferenceException
  HResult=0x80004003
  Message=Object reference not set to an instance of an object.
  Source=CSCore
  StackTrace:
   at CSCore.DirectSound.DirectSoundBuffer.StopNative()
   at CSCore.DirectSound.DirectSoundBuffer.Stop()
   at CSCore.SoundOut.DirectSoundOut.CleanupResources()
   at CSCore.SoundOut.DirectSoundOut.Dispose(Boolean disposing)
   at CSCore.SoundOut.DirectSoundOut.Finalize()

Today i updated from V1.0.0.2 to the latest version.

I noticed that the output volume (when playing MP3s) got way more silent. (Didn't found a changelog)

The volume property description says that it has a range from 0.01 (1%) to 1 (100%).

I was able to set a maximum of 100 now. (Could not do it in the older version).
Now 1 in the latest version is the same as 0.01 in the older version.
Is this correct and an intended behaviour? If it is intended, maybe update the description of the property.

Second question:
If i start my application from a folder which isn't named "Debug" then volume 1-100 sounds like 100%.
When i just rename the folder back to "Debug" then volume 1 sounds like 1%.
Why does the behaviour change if i rename the folder??

Also if i start the application as release from visual studio, volume 1 is super loud.
If i start it as debug, volume 1 is quiet.
If i rename this debug folder and just start the exe, volume 1 is super loud again.

Now i don't know what to ship to my customers. Going back to V1.0.0.2 isn't rlly an option.
Thank you for helping :)

This is a code-snipped how i play MP3-files. (Using Windows 10, .NET Framework 4.6.2)
```
_WaveSource = CodecFactory.Instance.GetCodec(filename).ToSampleSource().ToMono().ToWaveSource()
_SoundOut = New WasapiOut() With {
	 .Latency = 100,
	 .Device = Me.Device
}
_SoundOut.Initialize(_WaveSource)
_SoundOut.Volume = 1
_SoundOut.Play()
```



I am trying to use this library to constantly record the currect audio and adjust the output audio based on the input volume level. While using this library on a Windows 10 machine, I found that sometimes the WaveIn object will unexpected call the Stopped event call back with an error condition. Below is the stack trace along with the Exceptions information:

Received MM Exception from recording stopped event call back Function:waveInUnprepareHeader; Result:StillPlaying; Exception:CSCore.MmException: Exception of type 'CSCore.MmException' was thrown.
   at CSCore.MmException.Try(MmResult result, String function)
   at CSCore.SoundIn.WaveInBuffer.AddBufferToQueue()
   at CSCore.SoundIn.WaveIn.FireUpBuffer(WaveInBuffer buffer)

After this occurs, the object will also throw the same exception when I try to dispose of it. Below is s an example of this:

Received MM Exception while disposing AGC meter. Function:waveInUnprepareHeader; Result:StillPlaying; Exception:CSCore.MmException: Exception of type 'CSCore.MmException' was thrown.
   at CSCore.MmException.Try(MmResult result, String function)
   at CSCore.SoundIn.WaveInBuffer.Dispose(Boolean disposing)
   at CSCore.SoundIn.WaveInBuffer.Dispose()
   at CSCore.SoundIn.WaveIn.DisposeBuffers()
   at CSCore.SoundIn.WaveIn.CleanupResources()
   at CSCore.SoundIn.WaveIn.Dispose(Boolean disposing)
   at CSCore.SoundIn.WaveIn.Dispose()

This is generally OK. Technically this would cause a small memory leak since I need to create a new object to start recording again but that is not a huge deal. What is a big deal, is that the Garbage Collector will still try to Finalize the WaveIn and WaveInBuffer objects. The finalization of these objects causes the same MMException to be thrown causing my entire application to crash. Below are the .Net Runtime logs form Windows Event Viewer.

**GC Crashing on WaveIn Finalization**
Application: myApp.exe
Framework Version: v4.0.30319
Description: The process was terminated due to an unhandled exception.
Exception Info: CSCore.MmException
   at CSCore.MmException.Try(CSCore.MmResult, System.String)
   at CSCore.SoundIn.WaveInBuffer.Dispose(Boolean)
   at CSCore.SoundIn.WaveInBuffer.Dispose()
   at CSCore.SoundIn.WaveIn.DisposeBuffers()
   at CSCore.SoundIn.WaveIn.CleanupResources()
   at CSCore.SoundIn.WaveIn.Dispose(Boolean)
   at CSCore.SoundIn.WaveIn.Finalize()

**GC Crashing on WaveInBufferFinalization**
Application: myApp.exe
Framework Version: v4.0.30319
Description: The process was terminated due to an unhandled exception.
Exception Info: CSCore.MmException
   at CSCore.MmException.Try(CSCore.MmResult, System.String)
   at CSCore.SoundIn.WaveInBuffer.Dispose(Boolean)
   at CSCore.SoundIn.WaveInBuffer.Finalize()

I was able to get around this a little bit by calling GC.SuppressFinalization on the WaveIn object. However, the library does not expose the WaveInBuffer to my application. So, that situation will still crash my application. 

**Is there any way I can prevent these MMExceptions from being thrown?**
**Could we change the logic so that the MMExceptions are never thrown from the Finalization method? Obviously, with the understanding, there would be a memory leak..**
I use CSCore.FFmpeg FfmpegDecoder as waveSource to open media file, playing is fine , but cannot get the playing time length (TimeSpan):  _waveSource.GetLength() return 0.  Then I went down codes and found the _stream.duration was a very big negative value, so the property LengthInSeconds of  class AvFormatContext in AvFormatContext.cs returned 0.

        public double LengthInSeconds
        {
            get
            {
                if (SelectedStream == null || SelectedStream.Stream.duration < 0)
                    return 0;
                var timebase = SelectedStream.Stream.time_base;
                if (timebase.den == 0)
                    return 0;
                return SelectedStream.Stream.duration * timebase.num / (double) timebase.den;
            }
        }

So, how to get the real duration of a media file in CSCore.FFmpeg ?  Thank you very much.

Does CScore support recording X frames at a time?

Similar to pyaudio. open where you can specify the frames per buffer, then call read to get those buffers.

Thanks
I tried to write samples of different wave format .When i am using WaveWriter.Write, I got clear audio but WaveWriter.Write does not take float values ,So I had to use the WaveWriter.WriteSamples but this time i got a different audio . I have to do this because I want to reduce the size of the audio captured by the wasapi loopback capture. Is there any way by which I can write samples with different format
Here is my code :
`	var soundIn = new WasapiLoopbackCapture();
			soundIn.Initialize();
			var soundInSource = new SoundInSource(soundIn);
			IWaveSource convertedSource = soundInSource
				  .ChangeSampleRate(32000) // sample rate
				  .ToSampleSource()
				  .ToWaveSource(16);
			var notificationSource = new NotificationSource(soundInSource.ToSampleSource());
			

			notificationSource.Interval = 5000;
			notificationSource.BlockRead += (s, e) =>
			{


				string directory = System.IO.Directory.GetCurrentDirectory();
				string filename = DateTime.Now.Ticks.ToString() /*"sample" */+ ".wav";
				directory = directory + "\\Cache\\";
				string fileName = System.IO.Path.Combine(directory + filename);
				
				using (var intercepts = new WaveWriter(fileName, convertedSource.WaveFormat))
				{

					
					Debug.Assert(e.Data.Length == e.Length);
					intercepts.WriteSamples(e.Data, 0, e.Length);
				}
				int length = TimeConverterFactory.Instance.GetTimeConverterForSource(notificationSource)
				  .ToTimeSpan(convertedSource.WaveFormat, e.Length).Seconds;
			



			};

			var waveSource = notificationSource.ToWaveSource();
			var writer = new WaveWriter("out.wav", waveSource.WaveFormat);
			byte[] buffer = new byte[waveSource.WaveFormat.BytesPerSecond / 2];

			soundInSource.DataAvailable += (s, e) =>
			{
				int read;
				while ((read = waveSource.Read(buffer, 0, buffer.Length)) > 0)
					writer.Write(e.Data, 0, read);
			};

			soundIn.Start();`