关于Input和Filter部分是否考虑增加persist的一些思考。
1. 多个Filter的话，可以引用其他的Filter的结果，但是如果不persist的话，又会重算一次，加一个持久化的选填配置会不会好一点呢。
2. 其实我也在思考，unpersist在哪里比较好，感觉好像没有地方放呢，如果不进行unpersist的话，这意味着在使用persist的时候需要小心，因为只有在程序结束退出后，进行回收。
1. SPARK>=2.3，waterdrop让下载1.4.2，TiSpark2.0+才支持spark2.3，并且TiSpark2.0+仅支持TiDB3.0+，看看工程build.sbt，TiSpark才1.1版本， 使用过程中各种BUG，spark-shell + TiSpark2.0感觉都比其中tidb模块好用。
2. 插件开发的文档里面貌似少东西吧，我没看到任何一个地方写明自定义插件名称在配置文件要以全路径类名的引用。

    
```
filter {
    ...

    sql {
        sql = "insert into hive_table  partition(partitions)  select field1, field2, field3 from source_table_name"
    }
}

output {
    stdout {
        limit = 10
    }
}
```

官方文档上input插件的"result_table_name" required显示为"yes","table_name"显示required为"no",但是当我只配置了"result_table_name"后却报了如下错误,使用的版本为1.4.2
![image](https://user-images.githubusercontent.com/36819187/70846860-c22fdb80-1e98-11ea-994f-41e2d6eb0f5f.png)
![image](https://user-images.githubusercontent.com/36819187/70846870-db388c80-1e98-11ea-9fdd-ab0dc679c6bc.png)
![image](https://user-images.githubusercontent.com/36819187/70846878-f7d4c480-1e98-11ea-9fde-d121199427f2.png)

可以利用oracle原生ora_hash(rowid,4)=1，2，3，4 进行并发搬迁，提高速度，切分相当均匀。当时使用自己改造的datax，速度相当快，已经用于生产。
这个语句是通过观测ibm的datastage后台发现的，可以把思路借来用用。
希望提供到waterdrop

* 写ClickHouse服务端异常Spark task失败导致重试ClickHouse数据重复
Fix #411 
