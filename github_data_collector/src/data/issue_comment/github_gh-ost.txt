We have a number of tables in our database that unfortunately use the `latin1` character set. We need to migrate these to `utf8mb4` and are hoping to use gh-ost to facilitate this. In doing some testing, I'm running into a problem when changes from the binlog are being applied. I can reliably produce the problem as follows:

1. SQL setup
```sql
create table test_charset(id int not null primary key auto_increment, answer text) default charset=latin1; # This is simpler than our real table but illustrates the problem
insert into test_charset(answer) values('Here’s an apostrophe'); # note that that's a "fancy" apostrophe
```
2. gh-ost command (the strange ports are for Docker containers running locally):
```bash
bin/gh-ost --user="root" --password="<the password>" --host="127.0.0.1" --port=5506 --database=loyalty --table="test_charset" --verbose --alter="modify column answer text charset utf8mb4" --exact-rowcount --assume-rbr --postpone-cut-over-flag-file="/tmp/gh-ost-cutover.flag" --max-lag-millis=7500 --assume-master-host="127.0.0.1:4406" --execute
```

The migration proceeds as expected when copying rows and then waits since the cutover flag file is present. If I then insert the same row again, gh-ost crashes:
```sql
insert into test_charset(answer) values('Here’s an apostrophe');
```

The gh-ost output is attached. It seems that the value of the `answer` column is coming through as `[]uint8` instead of `string` so the character set conversion in [types.go/convertArg](https://github.com/github/gh-ost/blob/master/go/sql/types.go#L42) isn't happening. The "fancy" apostrophe is valid in the `latin1` character set.

Any advice is appreciated.

[gh-ost.log](https://github.com/github/gh-ost/files/4042176/gh-ost.log)

we are facing an issue after an alter of a JSON column.
after the alter completed we found wrong data types in the JSON data:

* data after the alter : 
```sql
oot@localhost(mysql-0a.96):[gallery]> select date_updated,JSON_EXTRACT(metadata, '$.photoMetadata.focalPoint.x') from gallery.items_v2 where gallery_id = '61482ce3-9431-407c-8bc7-ad7408e1ff38';
+---------------------+--------------------------------------------------------+
| date_updated        | JSON_EXTRACT(metadata, '$.photoMetadata.focalPoint.x') |
+---------------------+--------------------------------------------------------+
| 2019-12-20 13:14:14 | "0.5"                                                  |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:46 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
+---------------------+--------------------------------------------------------+
14 rows in set (0.00 sec)

```
* where befor the alter the data was (this is from snapshot of the database befor the alter table )
```sql
(tbd-mysql.42) [gallery]> select date_updated,JSON_EXTRACT(metadata, '$.photoMetadata.focalPoint.x') from gallery.items_v2 where gallery_id = '61482ce3-9431-407c-8bc7-ad7408e1ff38';
+---------------------+--------------------------------------------------------+
| date_updated        | JSON_EXTRACT(metadata, '$.photoMetadata.focalPoint.x') |
+---------------------+--------------------------------------------------------+
| 2019-12-20 13:14:14 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:46 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
| 2019-12-20 13:12:45 | 0.5                                                    |
+---------------------+--------------------------------------------------------+
14 rows in set (0.17 sec)
````
* As you can see the FLOAT in the JSON converted into STRING  
* versions : 
```
> select @@version
    -> ;
+------------+
| @@version  |
+------------+
| 5.7.20-log |
+------------+
1 row in set (0.00 sec)
```
```bash
:~ # gh-ost --version
1.0.48
```
Thanks 

Imagine the migration alters two tables, but if I read the doc correctly gh-ost supports single table alteration. I understand that there's no "good way" of handling this kind of situation because even if you run migrations simultaneously (two instances of gh-ost), at some point you'll end up having one table migrated while the other one still in migration. 

Do I assume correctly that the only right way here is just not allowing such migrations in the first place if you care about zero downtime?
Hi,

./gh-ost --host=10.10.193.99 --user=root --password= --database=test --table=test_tab --alter="drop columns" --chunk-size=2000 --exact-rowcount --max-load=Threads_connected=100  --allow-on-master --assume-master-host=10.10.193.99 -assume-rbr --initially-drop-ghost-table --execute

Copy: 6066000/6078350 99.8%; Applied: 976; Backlog: 1/1000; Time: 9m54s(total), 9m54s(copy); streamer: mysql-bin.000354:142247281; State: migrating; ETA: 1s
Copy: 6076000/6078350 100.0%; Applied: 978; Backlog: 0/1000; Time: 9m55s(total), 9m55s(copy); streamer: mysql-bin.000354:145120989; State: migrating; ETA: 0s
Copy: 6078209/6078209 100.0%; Applied: 978; Backlog: 0/1000; Time: 9m55s(total), 9m55s(copy); streamer: mysql-bin.000354:145694651; State: migrating; ETA: due
 Migrating `iudp_zt_policy`.`policy`; Ghost table is `iudp_zt_policy`.`_policy_gho`
 Migrating i-b1nk89p8:3306; inspecting i-b1nk89p8:3306; executing on dlidcdbcopy2.aeonlife.com.cn
 Migration started at Thu Dec 26 15:23:13 +0800 2019
 chunk-size: 2000; max-lag-millis: 1500ms; dml-batch-size: 10; max-load: Threads_connected=100; critical-load: ; nice-ratio: 0.000000
 throttle-additional-flag-file: /tmp/gh-ost.throttle 
 Serving on unix socket: /tmp/gh-ost.iudp_zt_policy.policy.sock
Copy: 6078209/6078209 100.0%; Applied: 978; Backlog: 0/1000; Time: 9m56s(total), 9m55s(copy); streamer: mysql-bin.000354:146059231; State: migrating; ETA: due

Why the last rowcount 6078209 less than 6078350 ? I think the last rowcount will be the maximum number.

 Thanks.

This PR is not related to an issue, but is adding an error check where an err variable was set but not checked. This could potentially help find errors when developing in the future.

### Description

This PR adds an error checks for an err variable which was assigned but never checked.

> In case this PR introduced Go code changes:

- [X] contributed code is using same conventions as original code
- [X] `script/cibuild` returns with no formatting errors, build errors or unit test errors.

This issues was found using CodeLingo - [codelingo.io](url)
Initialize the test environment：
CREATE TABLE `test` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `chinese` double DEFAULT NULL,
  `math` double NOT NULL DEFAULT '0',
  `english` double NOT NULL DEFAULT '0',
  `total_score` double GENERATED ALWAYS AS (((`chinese` + `math`) + `english`)) STORED,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
insert into test(chinese, math, english) values(66, 72, 54);
insert into test(chinese, math, english) values(33, 44, 55);
(root@3306)[mydb]> select * from  test;
+----+---------+------+---------+-------------+
| id | chinese | math | english | total_score |
+----+---------+------+---------+-------------+
|  1 |      66 |   72 |      54 |         192 |
|  2 |      33 |   44 |      55 |         132 |
+----+---------+------+---------+-------------+

When you execute the alter statement directly, the total_score column data exists：
alter table test modify column total_score double;
(root@3306)[mydb]> select * from  test;
+----+---------+------+---------+-------------+
| id | chinese | math | english | total_score |
+----+---------+------+---------+-------------+
|  1 |      73 |   72 |      54 |         199 |
|  2 |      45 |   44 |      55 |         144 |
+----+---------+------+---------+-------------+
2 rows in set (0.00 sec)
But when you execute through gh-ost, the total_score column will lose data！
(root@3306)[mydb]> select * from  _test_gho;
+----+---------+------+---------+-------------+
| id | chinese | math | english | total_score |
+----+---------+------+---------+-------------+
|  1 |      73 |   72 |      54 |        NULL |
|  2 |      45 |   44 |      55 |        NULL |
+----+---------+------+---------+-------------+



Related issue: https://github.com/github/gh-ost/issues/806

### Description

This PR will support  `gh-ost` run on Azure Database for MySQL. Like GCP or Aliyun RDS, Azure Database also need to do some specific things with code modification. This PR including 3 things
1. Skip port validation for Azure Database for MySQL. It acts as GCP and Aliyun RDS.
2. Add document for how to use it on Azure Database for MySQL.

> In case this PR introduced Go code changes:

- [x] contributed code is using same conventions as original code
- [x] `script/cibuild` returns with no formatting errors, build errors or unit test errors.

This is an enhancement request.

Hi, I'm new to this. I try to use this greate tool for modifying table structure. When migrating completed 100%, but continuously pop up:

> Copy: 22102848/22102848 100.0%; Applied: 110; Backlog: 0/1000; Time: 3h22m0s(total), 3h6m12s(copy); streamer: mysql-bin.000018:912494008; State: postponing cut-over; ETA: due

and my command is this:

> ./gh-ost \
--max-load=Threads_running=25 \
--critical-load=Threads_running=1000 \
--chunk-size=1000 \
--max-lag-millis=1500 \
--user="xxxx" \
--password="xxxx" \
--host=xxxx \
--port=4223 \
--database="test" \
--table="t1" \
--verbose \
--alter="ADD COLUMN isBookmarkedThree TINYINT(1) NOT NULL DEFAULT 0" \
--allow-master-master \
--cut-over=default \
--exact-rowcount \
--concurrent-rowcount \
--default-retries=120 \
--panic-flag-file=./ghost.panic.flag \
--postpone-cut-over-flag-file=./ghost.postpone.flag \
-aliyun-rds \
--allow-on-master \
--execute

I try to delete ghost.postpone.flag file, it kept popping up:

> 2019-12-06 19:25:39 INFO Grabbing voluntary lock: gh-ost.319743.lock
2019-12-06 19:25:39 INFO Setting LOCK timeout as 6 seconds
2019-12-06 19:25:39 INFO Looking for magic cut-over table
2019-12-06 19:25:39 INFO Creating magic cut-over table `test`.`_t1_del`
2019-12-06 19:25:39 INFO Magic cut-over table created
2019-12-06 19:25:39 INFO Locking `test`.`t1`, `test`.`_t1_del`
2019-12-06 19:25:39 INFO Tables locked
2019-12-06 19:25:39 INFO Session locking original & magic tables is 319743
2019-12-06 19:25:39 INFO Writing changelog state: AllEventsUpToLockProcessed:1575631539838703726
2019-12-06 19:25:39 INFO Waiting for events up to lock
2019-12-06 19:25:42 ERROR Timeout while waiting for events up to lock
2019-12-06 19:25:42 ERROR 2019-12-06 19:25:42 ERROR Timeout while waiting for events up to lock
2019-12-06 19:25:42 INFO Looking for magic cut-over table
2019-12-06 19:25:42 INFO Will now proceed to drop magic table and unlock tables
2019-12-06 19:25:42 INFO Dropping magic cut-over table
2019-12-06 19:25:42 INFO Releasing lock from `test`.`t1`, `test`.`_t1_del`
2019-12-06 19:25:42 INFO Tables unlocked

serveral minutes later, ends like:

> 2019-12-06 19:27:39 ERROR Timeout while waiting for events up to lock
2019-12-06 19:27:39 ERROR 2019-12-06 19:27:39 ERROR Timeout while waiting for events up to lock
2019-12-06 19:27:39 INFO Looking for magic cut-over table
2019-12-06 19:27:39 INFO Will now proceed to drop magic table and unlock tables
2019-12-06 19:27:39 INFO Dropping magic cut-over table
2019-12-06 19:27:39 INFO Removing socket file: /tmp/gh-ost.test.t1.sock
2019-12-06 19:27:39 FATAL 2019-12-06 19:27:39 ERROR Timeout while waiting for events up to lock

Is there anything I missed? Thanks
Experience in existing solutions and paradigm migrations is the basis of gh-ost.

## A Pull Request should be associated with an Issue.

> We wish to have discussions in Issues. A single issue may be targeted by multiple PRs.
> If you're offering a new feature or fixing anything, we'd like to know beforehand in Issues,
> and potentially we'll be able to point development in a particular direction.

Related issue: https://github.com/github/gh-ost/issues/0123456789

> Further notes in https://github.com/github/gh-ost/blob/master/.github/CONTRIBUTING.md
> Thank you! We are open to PRs, but please understand if for technical reasons we are unable to accept each and any PR

### Description

This PR [briefly explain what it does]

> In case this PR introduced Go code changes:

- [ ] contributed code is using same conventions as original code
- [ ] `script/cibuild` returns with no formatting errors, build errors or unit test errors.
