For loop punctuation check can be replaced with a map for O(1) lookups. This lookup pattern is also used in [summarize/easy.go](https://github.com/jdkato/prose/blob/master/summarize/easy.go).
If you are for example using this to run a bot in a chat room, you'll likely have access to a list of participants and can suggest them as names to the parser.
Are there any plans to migrating this project to using go modules?  

The reason I am requesting it is that it would make it easier to manage dependence when contributing.  Additionally since this package doesn't appear to be utilizing any other dependence manager migrating it to a single go module should be a simple change.
Segmenting:
input:Mr. James told me Dr. Brown is not available today. I will try tomorrow.
output:
Mr. James told me Dr.
Brown is not available today.
I will try tomorrow.
Hi,

Is it possible to feed data from Doccano into Prose for Named entity ?

https://github.com/chakki-works/doccano

https://github.com/chakki-works/doccano/wiki/Import-and-Export-File-Formats


I read through the Prodigy tutorial, just asking if there are any known pitfalls with Doccano before I start and hit a brick wall :-)

I noticed that when a text has emoji (ðŸ˜€etc) that the IterTokenizer does not completely parse the text.  I'm prepping a pull request, if this seems worthwhile
Are EntityContext Start and End zero based?

I have the assumption that since golang is zero based on the index of the runes in a string, that the _Start_ and _End_ of the Spans in an EntityContext are zero based.  Could you confirm and perhaps update the godoc?  I traced into the UsingEntities method, and found the _adjustPos_ method that seemed to make up for off-by-one problems.  I'd like to be sure my training model is correct.

(to be clear, on the v2 branch)
 I am trying to build an entity recognition API around prose , but the issue seems to be that , for every API call a new model is loaded which takes up 100 MB of memory which seems to be an issue . Is there some way that model can be globally loaded ? 
I have a list of smiley codes eg :lough: which gets tokenized to ":lough" and ":".
How can I solve that " :lough:" will be " :lough:"?
Can we use this issue to document the pieces that will directly be impacted if we need to add support for _any_ other language?

I would be interested in working on this but I don't have *any* domain expertise so I could use all the help.

Thanks