Hi Mark, we found a behaviour that seems a bit strange. See the code below:

library(stringdist)
df <-c("IÑIGO")
df[amatch("INIGO", df, method="lv", maxDist=1)]
df[amatch("INIGO", df, method="lv", maxDist=2)]
stringdist("INIGO", "IÑIGO")

> library(stringdist) 
> df <-c("IÑIGO")
> df[amatch("INIGO", df, method="lv", maxDist=1)] 
[1] NA 
> df[amatch("INIGO", df, method="lv", maxDist=2)] 
[1] "IÑIGO"
 > stringdist("INIGO", "IÑIGO") 
[1] 1

As you can see, the distance between INIGO and IÑIGO is 1. However, in the first amatch execution with maxDist =1 results in NA and the second amatch execution with maxDist=2 a match is found and returns de position 1. We thought it was and encoding problem but we've read in the documentation strings are converted to utf32

Maybe we are missing something else or is this an issue?

Thank you very much.

Suggested by Tom Magerman by e-mail to add

- [Dice Coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)
- [Sorensen overlap](https://en.wikipedia.org/wiki/Overlap_coefficient)

to the q-gram distances

Let s_vec be some vector of N distinct strings. When N is too large, stringdistmatrix grows unwieldy (NxN), as does the "dist" struct returned by stringdistmatrix when called w a single arg.

Would like to request a new function, similar to stringdistmatrix, but which would return the information in a sparse way, for those cases one is only interested in (i,j) lower-triangular pairs satisfying a condition: 

```{r}
s_vec <- c("string1","string2", ...)
N <- length(s_vec)
df <- stringdist_thresh(s_vec, method="lv", thresh=2, op="<=") 
```
The above will return a tibble w/ columns "i", "j", and "dist". Each row will indicate that for some (i,j,dist) the predicate (in this case: dist <= 2) was satisfied. i in 1 to N-1, j in i+1 to N

"op" can be one of: "<", "<=", ">", ">=", "==", "!=".

As an example, consider: 

```{r}
s_vec <- c("aaa","aab", "aac","abc")
df <- stringdist_thresh(s_vec, method="lv", thresh=2L, op="<") 
#> tibble:
#> i, j, dist
#> 1 2 1
#> 1 3 1
#> 2 3 1
#> 3 4 1
```
Notice how the data frame indicates only those pairs for which the distance satisifies lv < 2.
 
For example

```
stringdist("hello","world",method="cosine", q=1:2)
```

would yield the cosine distance over the concatenation of 1-gram and 2-gram profiles.

This would also enhance compatibility, e.g. with the `textcat` package.

Why not, a bit of user-friendlyness :-).

At the moment `stringsim` assumes that all weights are equal to 1 for edit-based distances. Although this does yield a valid maximum (weights are maximally 1), using lower weights will lower the maximum possible similarity. It is probably more intuitive to scale the similarities taking weights into account.

I was wondering if you've thought of including qgram filtering for edit distance in the stringdist package. Oftentimes users are only concerned with comparing strings that pass a certain similarity threshold, and qgram filtering allows them to do this significantly quicker than just calculating the levenstein distance on all the strings. 


Adding support for [string kernel distances](http://www.jmlr.org/papers/volume2/lodhi02a/lodhi02a.pdf) would be nice.

