Added prometheus format and up/down property in json for `upstream_check_module` based on the implementation from [this fork](https://github.com/nginx-modules/nginx_upstream_check_module).
### Ⅰ. Issue Description
使用qat加速时，不开启异步模式，Tengine的CPU使用率跟不用qat一样，性能没有提升。我的理解是只要使用qat硬件加速，不管同步异步模式，握手的RSA计算都应该有硬件加速卡计算，不会占用CPU的资源，CPU的负载应该比不使用QAT硬件加速时低呀

### Ⅱ. Describe what happened
1、测试环境
1）服务端环境，Tengine作为作为LB，挂载三个后端实例
OS: CentOS7.6(3.10.0-957.21.3.el7.x86_64) 
Tengine环境
./sbin/nginx -V
Tengine version: Tengine/2.3.2
nginx version: nginx/1.17.3
built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC)
built with OpenSSL 1.1.1c  28 May 2019
TLS SNI support enabled
configure arguments: --prefix=/mypath/srv/tengine-2.3.2 --with-http_ssl_module --with-openssl-async --with-cc-opt='-DNGX_SECURE_MEM -I/mypath/srv/openssl/include -Wno-error=deprecated-declarations' --with-ld-opt='-Wl,-rpath=/mypath/srv/openssl/lib -L/mypath/srv/openssl/lib' 

开启10个进程：worker_processes 10;

OpenSSL-1.1.1c

QAT环境
qat1.7.l.4.7.0-00006
https://github.com/intel/QAT_Engine.git
编译时安装是成功的
service qat_service status
Checking status of all devices.
There is 1 QAT acceleration device(s) in the system:
 qat_dev0 - type: dh895xcc,  inst_id: 0,  node_id: 0,  bsf: 0000:13:00.0,  #accel: 6 #engines: 12 state: up

2）测试端
CentOS6.6
测试脚本
for((i=0;i<25;i++))
do
    ab -n 10000 -c 50 https://mydomain/ > logs/$i.txt&
done

2、测试三种情况
1）没有使用qat硬件加速卡
   service qat_service stop
   将配置中关闭ssl_engine，关闭ssl_async
   #ssl_engine qat;
   #ssl_async  on;

2）使用qat，但是不开启异步模式
   service qat_service start
   ssl_engine qat;
   #ssl_async  on;

3）使用qat，开启异步模式
   service qat_service start
   ssl_engine qat;
   ssl_async  on;  

从测试数据来看，第一种场景(不使用qat)和第二种场景(使用qat，但是不开启异步模式)，CPU的使用率一样呀，我的理解是只要使用qat卡，不管同步异步模式，握手的RSA计算都应该有硬件加速卡计算，不会占用CPU的资源，CPU的负载应该比不使用QAT硬件加速时低呀，但是从测试的数据来看不是这样。
第三种情况(开启异步模式)，CPU使用率可以节约50%，这个数据可以说的过去。
请问Tengine的同学，在使用qat时是否对比测试过这三种场景，结果是怎样的？  
### nginx配置文件
set $envflag "-lan";
if ( $http_cookie ~* "Env-flag=lv" ) {
        set $envflag "-lv";
}
location /itadmin {
       #  去掉/可以正常转发，请求的path不会丢失
        proxy_pass http://opCptApi$envflag/;
        proxy_redirect http://opCptApi$envflag/ /itadmin/;
}
upstream opCptApi-lan{
    server 172.17.194.208:8080;
}
upstream opCptApi-lv{
   server 172.17.194.208:8080;
}

### 问题描述
假定请求路径：/itadmin/message/platforms/page?pageSize=20&current=1
nginx的access日志：
58.251.1.132 - - [08/Jan/2020:12:03:41 +0800] "GET /itadmin/message/platforms/page?pageSize=20&current=1 HTTP/1.1" 404 114 "-" "PostmanRuntime/7.21.0" "-" TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 xxx.17.194.208:8080 0.009 0.009 crm-sadmin-dev.xxx.xxx
**nginx无error日志，后端服务收到的请求路径是“ /”，”message/platforms/page?pageSize=20&current=1“请求路径在nginx层丢失**

### nginx信息
Tengine version: Tengine/2.3.1
nginx version: nginx/1.16.0
built by gcc 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) 
built with OpenSSL 1.0.2k-fips  26 Jan 2017
TLS SNI support enabled
configure arguments: --with-http_ssl_module
## Question
<!-- You can ask any question about this project -->
环境：
centos6.6，内核： 2.6.32
qat驱动：qat1.7.l.4.7.0-00006
qat_engine：https://github.com/intel/QAT_Engine.git  
在编译驱动时，提示如下错误：应该是找不到“pci_ignore_hotplug”，不知道是否越到类似的问题？
make  all-am
make[1]: Entering directory `/root/qat/QAT-1.7'
make[2]: Entering directory `/root/qat/QAT-1.7/quickassist/qat'
make -C /lib/modules/2.6.32-431.17.1.el6.x86_64/build M=/root/qat/QAT-1.7/quickassist/qat modules
make[3]: Entering directory `/usr/src/kernels/2.6.32-431.17.1.el6.haproxy.x86_64'
  CC [M]  /root/qat/QAT-1.7/quickassist/qat/drivers/crypto/qat/qat_common/adf_aer.o
/root/qat/QAT-1.7/quickassist/qat/drivers/crypto/qat/qat_common/adf_aer.c: 在函数‘adf_reset_sbr’中:
/root/qat/QAT-1.7/quickassist/qat/drivers/crypto/qat/qat_common/adf_aer.c:109: 错误：隐式声明函数‘pci_ignore_hotplug’
make[6]: *** [/root/qat/QAT-1.7/quickassist/qat/drivers/crypto/qat/qat_common/adf_aer.o] 错误 1
make[5]: *** [/root/qat/QAT-1.7/quickassist/qat/drivers/crypto/qat/qat_common] 错误 2
make[4]: *** [/root/qat/QAT-1.7/quickassist/qat/drivers/crypto/qat] 错误 2
make[3]: *** [_module_/root/qat/QAT-1.7/quickassist/qat] 错误 2
make[3]: Leaving directory `/usr/src/kernels/2.6.32-431.17.1.el6.x86_64'
make[2]: *** [modules] 错误 2
make[2]: Leaving directory `/root/qat/QAT-1.7/quickassist/qat'
make[1]: *** [qat-driver-all] 错误 2
make[1]: Leaving directory `/root/qat/QAT-1.7'
make: *** [all] 错误 2
{
    "head":{
        "title":"411 Length Required"
    },
    "body":"Powered by Tengine"
}
post/put请求中如果没有带content_length，Tengine有什么配置可以绕过吗

Hi,

How to cache with tengine, if I write more in detail

response headers ty-cache = true  so it can cache, if the application writes cache time, then cache it.

cache only 120 seconds if the application does not write cache time.

caching if set-cookie exists in the application

response header: X-Cache= cached  X-Cache= nocached

how do I write a configuration file this way

Thanks,

## Why you need it?
<!-- Is your feature request related to a problem? Please describe in details  -->
目前我们使用使用健康检测功能，检测的使用的方式是HTTP
这里希望提供一个功能，如果检测后端无法进行连接时
直接下线，如果检测后端返回40x,50x再进行一定的次数后下线（保持现有逻辑不变）

## How it could be?
<!--A clear and concise description of what you want to happen. For a computer fan,  you can explain more about input of the feature, and output of it.-->
如果检测后端无法进行连接时
直接下线，如果检测后端返回40x,50x再进行一定的次数后下线（保持现有逻辑不变）

## Other related information
<!-- Add any other context or screenshots about the feature request here.-->

update
### Ⅰ. Issue Description

对etcd端口进行抓包(tcpdump -i any -A port 2379)发现一直有请求etcd，网关处没有任何请求，怀疑是在轮训etcd

### Ⅵ. Environment:

- apisix 0.7
- Mac

### Ⅰ. Issue Description
when use dynamic_resolve, have a error that is "shm_add_upstream::peer failed while logging request".

### Ⅱ. Describe what happened
```bash
upstream my-server {
          dynamic_resolve fallback=stale fail_timeout=10s;
          server my-server.myns.svc.cluster.hf:8091;
  }
server {
      ....
    location /smartCall {
               resolver 10.254.0.2 valid=3s ipv6=off;
               resolver_timeout 3s;
               proxy_connect_timeout       150;
               proxy_send_timeout          150;
               proxy_read_timeout          150;
               send_timeout                150;
               proxy_http_version 1.1;
               proxy_pass       http://my-server;
           }
}
```
error.log
```
2019/12/06 09:43:56 [error] 7#7: *56901 shm_add_upstream::peer failed while logging request...
2019/12/06 09:43:55 [error] 7#7: *57336 handler::shm_add_upstream() failed while logging request...
```
### Ⅲ. Describe what you expected to happen


### Ⅳ. How to reproduce it (as minimally and precisely as possible)

1.
2.
3.



### Ⅴ. Anything else we need to know?

1. If applicable, add nginx  [debug log doc](http://nginx.org/en/docs/debugging_log.html).
2.
3.

### Ⅵ. Environment:

- Tengine version (use `sbin/nginx -V`): tengine-2.3.2
- OS (e.g. from /etc/os-release): centos-7.7
- Kernel (e.g. `uname -a`): Linux 3.10.0-693.el7.x86_64
- Others:
```bash
# /data/apps/opt/tengine-2.3.2/sbin/nginx -V
Tengine version: Tengine/2.3.2
nginx version: nginx/1.17.3
built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
built with OpenSSL 1.0.2k-fips  26 Jan 2017
TLS SNI support enabled
configure arguments: --add-module=modules/ngx_http_upstream_check_module --add-module=modules/ngx_http_upstream_dynamic_module --add-module=modules/ngx_http_upstream_consistent_hash_module --add-module=modules/ngx_http_upstream_keepalive_module --add-module=modules/ngx_multi_upstream_module --add-module=modules/ngx_http_upstream_vnswrr_module --add-module=modules/ngx_http_reqstat_module --add-module=/usr/src/nginx-module-vts --prefix=/data/apps/opt/tengine-2.3.2 --conf-path=/data/apps/config/nginx/nginx.conf --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-http_xslt_module=dynamic --with-http_image_filter_module=dynamic --with-http_geoip_module=dynamic --with-http_slice_module --with-pcre --with-pcre-jit --with-google_perftools_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic' --with-ld-opt='-Wl,-z,relro -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -Wl,-E' --without-http_upstream_keepalive_module
```
