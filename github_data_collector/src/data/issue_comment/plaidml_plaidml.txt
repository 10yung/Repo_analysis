The remaining bits are in the conda runner wrapper and the `pmlc::util::math` stuff.

Seems good if we could remove the dependency entirely someday.
I'm happy to add the expected program strings as well, but I'm not sure how to generate them (printing the program locally seems doesn't have the `idxs, src, maps` info).
* python 3.6.8, 3.7.5 64bit
* windows 10 64bit

When **plaidml2-keras 0.7.0** is installed using pip, below error occurred.
**plaidml 0.7.0** is released but **plaidml2** is not released on pypi.

In [plaidml2/bridge/keras/setup.py](https://github.com/plaidml/plaidml/blob/master/plaidml2/bridge/keras/setup.py) **plaidml2 package is required**.

```
D:\myprj\pypackdown>py -3.7 -m pip download plaidml2-keras
Collecting plaidml2-keras
  Using cached https://files.pythonhosted.org/packages/a7/c1/345db520bf8c554892498e0c45e410f62036b36413507bae2dc781cf7814/plaidml2_keras-0.7.0-py2.py3-none-any.whl
  Saved d:\myprj\pypackdown\plaidml2_keras-0.7.0-py2.py3-none-any.whl
Collecting keras==2.2.4
  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl
  Saved d:\myprj\pypackdown\keras-2.2.4-py2.py3-none-any.whl
Collecting six
  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl
  Saved d:\myprj\pypackdown\six-1.14.0-py2.py3-none-any.whl
Collecting numpy
  Using cached https://files.pythonhosted.org/packages/a9/38/f6d6d8635d496d6b4ed5d8ca4b9f193d0edc59999c3a63779cbc38aa650f/numpy-1.18.1-cp37-cp37m-win_amd64.whl
  Saved d:\myprj\pypackdown\numpy-1.18.1-cp37-cp37m-win_amd64.whl
Collecting scipy
  Using cached https://files.pythonhosted.org/packages/61/51/046cbc61c7607e5ecead6ff1a9453fba5e7e47a5ea8d608cc7036586a5ef/scipy-1.4.1-cp37-cp37m-win_amd64.whl
  Saved d:\myprj\pypackdown\scipy-1.4.1-cp37-cp37m-win_amd64.whl
ERROR: Could not find a version that satisfies the requirement plaidml2 (from plaidml2-keras) (from versions: none)
ERROR: No matching distribution found for plaidml2 (from plaidml2-keras)
```


Hello there, 

I am unfortunately unable to find the implementation for **separable_conv1d** in plaidml. The main separable_conv function and separable_conv2d are available, but not separable_conv1d. When trying to use the 1D version with keras, this of course gives an error that the function is not found in the backend (i.e. plaidml).

**Code from `plaidml/plaidml/keras/backend.py`:**
```
def separable_conv(x,
                   depthwise_kernel,
                   pointwise_kernel,
                   strides=None,
                   padding='valid',
                   data_format=None,
                   dilation_rate=None):
      ... implementation

def separable_conv2d(x,
                     depthwise_kernel,
                     pointwise_kernel,
                     strides=(1, 1),
                     padding='valid',
                     data_format=None,
                     dilation_rate=(1, 1)):
    return separable_conv(x, depthwise_kernel, pointwise_kernel, strides, padding, data_format,
                          dilation_rate)
```


I also went back to the initial release of plaidml to try to figure out if it was possibly mistakenly erased, but I found the same above two functions and still no sign of separable_conv1d. Can I kindly find some help?
my computer windows 10 have two gpu 

GPU 0
thanks a lot please help me
	Intel(R) HD Graphics P530

	diriver version:	22.20.16.4799
	驱动程序日期:	2017/9/14
	DirectX 版本:	12 (FL 12.1)
	物理位置：	PCI 总线 0、设备 2、功能 0

GPU 1

	NVIDIA Quadro M4000M

	驱动程序版本:	24.21.14.1163
	驱动程序日期:	2018/9/18
	DirectX 版本:	12 (FL 12.1)
	物理位置：	PCI 总线 1、设备 0、功能 0







PS C:\Users\tryhard> plaidml-setup

PlaidML Setup (0.6.4)

Thanks for using PlaidML!

Some Notes:
  * Bugs and other issues: https://github.com/plaidml/plaidml
  * Questions: https://stackoverflow.com/questions/tagged/plaidml
  * Say hello: https://groups.google.com/forum/#!forum/plaidml-dev
  * PlaidML is licensed under the Apache License 2.0

Traceback (most recent call last):
  File "c:\python38\lib\runpy.py", line 193, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "c:\python38\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "C:\Python38\Scripts\plaidml-setup.exe\__main__.py", line 9, in <module>
  File "c:\python38\lib\site-packages\plaidml\plaidml_setup.py", line 63, in main
    devices, _ = plaidml.devices(ctx, limit=100, return_all=True)
  File "c:\python38\lib\site-packages\plaidml\__init__.py", line 1073, in devices
    enumerator = _Enumerator(ctx)
  File "c:\python38\lib\site-packages\plaidml\__init__.py", line 1030, in __init__
    self._as_parameter_ = _lib().plaidml_alloc_device_enumerator(
OSError: exception: access violation reading 0x0000000000000464
PS C:\Users\tryhard>


Hello, thank you for providing this great platform, hopefully you will find a way to keep a Keras API alive this year.

I am evaluating CIFAR10 through Keras on a MacBook Pro with an 8-core i9 CPU and an AMD Radeon 5500m (Navi) GPU. CPU beats GPU by 10%. With the GPU in plaidML, GPU utilization is only 0.5%, the machine is not breaking a sweat. On CPU with TensorFlow, it is correctly using 8 cores. How can I help assess this bottleneck?

Thanks!
This might be extension of the issues #173 
I having issues with the 'variational_autoencoder_deconv.py' examples from keras github
running the script keep getting what that look like all locations from the latent space, producing the same output and the distribution
PlaidML backend : https://imgur.com/a/8MmuOqU
Tensorflow backend : https://imgur.com/a/x1PJdWx

https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder_deconv.py
```
i=1
inputA = Input(shape=(i, n_features))
x4 = Input(shape=(1, 32))
        c=RepeatVector(i)(x4)
        print(c.shape)
        c= plaidml.op.reshape(c,(<tile.Value Operation UINT64()>,i,32) )
        print(c.shape)
        #c= Reshape((i,32) )(c)
        
        combined = concatenate([c, inputA])
```

print output
> Shape(dtype=<DType.FLOAT32: 50>, dims=(<tile.Value Operation UINT64()>, 1, 32))
> Shape(dtype=<DType.FLOAT32: 50>, dims=(1, 32))

> ~/opt/anaconda3/envs/MLPaid/lib/python3.7/site-packages/keras/layers/merge.py in concatenate(inputs, axis, **kwargs)
>     647         A tensor, the concatenation of the inputs alongside axis `axis`.
>     648     """
> --> 649     return Concatenate(axis=axis, **kwargs)(inputs)
>     650 
>     651 
> 
> ~/opt/anaconda3/envs/MLPaid/lib/python3.7/site-packages/keras/engine/base_layer.py in __call__(self, inputs, **kwargs)
>     429                                          'You can build it manually via: '
>     430                                          '`layer.build(batch_input_shape)`')
> --> 431                 self.build(unpack_singleton(input_shapes))
>     432                 self.built = True
>     433 
> 
> ~/opt/anaconda3/envs/MLPaid/lib/python3.7/site-packages/keras/layers/merge.py in build(self, input_shape)
>     360                              'inputs with matching shapes '
>     361                              'except for the concat axis. '
> --> 362                              'Got inputs shapes: %s' % (input_shape))
>     363 
>     364     def _merge_function(self, inputs):
> 
> ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(1, 32), (None, 1, 58)]