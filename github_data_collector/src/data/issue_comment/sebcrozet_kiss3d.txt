Right now, kiss3d only supports rendering to a single `<canvas>` element. I have a use case where I'd like to embed multiple instances of kiss3d on the same page (a blog post that goes through implementing a 3d simulation).

I've identified a few blockers:

* [WebGLCanvas always looks for a single canvas on the page](https://github.com/sebcrozet/kiss3d/blob/48985e838f4946aacf2db269909f8c5a95455f9c/src/window/webgl_canvas.rs#L46) (`#canvas`). This can be worked around on the JavaScript side by changing the id of the target canvas before creating the window, and then changing it back afterwards.
* [WebGLContext does the same thing](https://github.com/sebcrozet/kiss3d/blob/48985e838f4946aacf2db269909f8c5a95455f9c/src/context/webgl_context.rs#L27). Now this one is more complicated to work around because [kiss3d only ever keeps a single context in memory](https://github.com/sebcrozet/kiss3d/blob/48985e838f4946aacf2db269909f8c5a95455f9c/src/context/context.rs#L116). One solution to this is to instantiate one WASM module per canvas (+ the trick for supporting multiple canvases).
* Mouse and keyboard events are relayed to all canvases because [they all listen on window](https://github.com/sebcrozet/kiss3d/blob/48985e838f4946aacf2db269909f8c5a95455f9c/src/window/webgl_canvas.rs#L78). As a temporary fix on my fork, I've added the following check inside the event handlers:
```rust
if e.target()
    .and_then(|target| <CanvasElement>::try_from(target).ok())
    .map_or(true, |canvas| canvas != edata.canvas)
{
    return;
}
```
**EDIT:** For the last point, a better solution is to add event listeners to the canvas element directly (except for window resize / mouse up / mouse move (which needs to be modified to support the pointer leaving the canvas).
Hello, I am trying to develop a simple 3d first person shooter game, and I need these two functions.

**The problem:**
I cannot use the `set_cursor_grab` on its own, because if the mouse is already on a edge of the window (e.g. 0-300), and I move the mouse left, the `WindowEvent::CursorPos` will still return 0-300  so i canont detect the fact that the user is trying to move the mouse left (am I wrong?).

Using `set_cursor_position` in conjunction with `set_cursor_grab` solves the problem as I'm now able to center the mouse.


The Conrod TextBox Widget uses `WindowEvent::Char` for inputting characters and also depend on `Key::Back`  being mapped to `CKey::Backspace`.

These additions make the widget work when being used with Conrod UI inside of kiss3d.
Hello,
before I begin my question I want to state that this is **not** a feature request - I want to inquire whether what I am planning to do is at all feasible.

When prototyping graphical applications, immediate mode GUI libraries like [imgui](https://github.com/Gekkio/imgui-rs) or [nuklear](https://github.com/snuk182/nuklear-rust) often come in handy to me. These libraries are renderer agnostics, they just produce command lists that can be interpreted by any rendering system or library.

My question now is: Is it at all possible to gain access to the internals of the OpenGL state used by this library in order for me to implement rendering of these generated command lists, and therefore establish support for these GUI libraries? Is this worth getting into further?

Cheers


Is it possible to get the functionality of window.snap_image() without actually opening a window? I need to render a large number of simple geometric scenes, but I only need the ImageBuffers, and attempting to open a bunch of windows in parallelized threads isn't possible on MacOS.

I've tried window.snap_image() without window.render() and just get an empty black image.

If there's a way to do this that I'm just missing, I'm sorry. This is a great crate and is otherwise perfect for what I'm trying to do.

Thank you!
Everything seems to compile just fine, but I cannot find any binary to run in targets

I tried:
`/kiss3d/ci/build.sh`
`/kiss3d/> cargo build`

In both cases compilation finished without any erros

but when I go to `/kiss3d/target/debug/examples` it is empty

I cannot find anything about how to  run examples in the documentation


I've written a simple program that renders a set of cubes.  First I tried rendering them with the `FirstPerson` camera, then `FirstPersonStereo`. The FirstPerson view looks mostly how I'd expect:
![mono_diff](https://user-images.githubusercontent.com/1440229/62817106-d6785c00-bae5-11e9-93f0-40d395206639.png)

However, the stereo objects are strangely elongated in Y:
![stereo_diff](https://user-images.githubusercontent.com/1440229/62817109-d8421f80-bae5-11e9-8506-978107ab8b49.png)

([Link to the source code](https://github.com/tstellanova/explore-events-3d/blob/stereo_view/src/main.rs))

This is reproducible on Mac OSX 10.14.6.  I'll try on a linux system as well. 
I used `let mut g = window.add_group()` to create a `SceneNode`. Next, I added a bunch of spheres to this group using `let mut obj = g.add_sphere(10.0)`. Then I moved these spheres to random locations with `obj.set_local_translation`.

Now, I want to scale the entire group with respect to the origin. But the only scale function in the group I see is `set_scale`; which only scales the spheres individually, and doesn't affect their positions at all. How do I scale the entire group with respect to the origin?
Any way to detect which object is under the current mouse position -> what about callbacks on  objects to allow selection etc  via mouse.