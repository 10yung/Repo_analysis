### Which version of Elastic are you using?
[ ] elastic.v7 (for Elasticsearch 7.x)

### Please describe the expected behavior
I am overriding the JSON decoder with a customer decoder
``` go
type JSONIterDecoder struct {}

func (d *JSONIterDecoder) Decode(data []byte, v interface{}) error {
	return jsoniter.Unmarshal(data, v)
}
```

And then adding it to the client
``` go
return elastic.NewSimpleClient(
  elastic.SetURL(esUrl),
  elastic.SetDecoder(&JSONIterDecoder{})
)
```

I am expecting that the new decoder will be used for all processing with the client

### Please describe the actual behavior
The flame-graphs generated from profiling show that `v7.(*SearchService).Do` is using jsoniter, however, `v7.Aggregations.Terms` and `
v7.Aggregations.TopHits` are still using the encoding/json.

Are there further steps required to ensure that the decoder is replaced globally?


### Which version of Elastic are you using?

[ ] elastic.v6 (for Elasticsearch 6.x)

### Please describe the expected behavior
The MultiMatch query with empty fields should match the string to search in all eligible fields in documents.

### Please describe the actual behavior
If I not set the fields in query the library add double quote in fields array and this behaviour return wrong hits. 

### Any steps to reproduce the behavior?
Not set fields in NewMultiMatchQuery. E.g.:
`multiMatchQuery = NewMultiMatchQuery("string_to_match")`

### Which version of Elastic are you using?

[x] elastic.v7 (for Elasticsearch 7.x)
[ ] elastic.v6 (for Elasticsearch 6.x)
[ ] elastic.v5 (for Elasticsearch 5.x)
[ ] elastic.v3 (for Elasticsearch 2.x)
[ ] elastic.v2 (for Elasticsearch 1.x)

### Please describe the expected behavior
I have two questions about go.mod.
1) Has `go mod tidy` been run?
Here's git diff result after running `go mod tidy` for v7.0.10:
```
diff --git a/go.mod b/go.mod
index 64b6e55..ddddc8d 100644
--- a/go.mod
+++ b/go.mod
@@ -3,15 +3,24 @@ module github.com/olivere/elastic/v7
 go 1.13

 require (
+       github.com/VividCortex/gohistogram v1.0.0 // indirect
        github.com/aws/aws-sdk-go v1.27.0
+       github.com/codahale/hdrhistogram v0.0.0-20161010025455-3a0bb77429bd // indirect
        github.com/fortytw2/leaktest v1.3.0
-       github.com/golang/mock v1.2.0 // indirect
+       github.com/go-kit/kit v0.8.0 // indirect
        github.com/google/go-cmp v0.3.1
+       github.com/google/uuid v1.1.1
+       github.com/kr/pretty v0.2.0 // indirect
        github.com/mailru/easyjson v0.7.0
+       github.com/olivere/env v1.1.0
        github.com/opentracing/opentracing-go v1.1.0
        github.com/pkg/errors v0.8.1
        github.com/smartystreets/go-aws-auth v0.0.0-20180515143844-0c1422d1fdb9
+       github.com/smartystreets/gunit v1.1.1 // indirect
+       github.com/uber/jaeger-client-go v2.21.1+incompatible
+       github.com/uber/jaeger-lib v2.2.0+incompatible
        go.opencensus.io v0.22.2
-       google.golang.org/api v0.3.1 // indirect
+       go.uber.org/atomic v1.5.1 // indirect
+       golang.org/x/sync v0.0.0-20190423024810-112230192c58
        gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 // indirect
 )
```

2) Some modules like `github.com/olivere/env`, `github.com/uber/jaeger-client-go/log` are only used in recipe. In my opinion, these modules shouldn't be included in dependencies list of Elastic client.
One possible solution is to create an empty go.mod in recipe directory: 
https://github.com/golang/go/wiki/Modules#can-an-additional-gomod-exclude-unnecessary-content-do-modules-have-the-equivalent-of-a-gitignore-file.
Another option I can come up with is to move recipe to another repo.
What's your thoughts? Thank you very much in advance. :)

### Please describe the actual behavior
### Any steps to reproduce the behavior?
n/a

[Rollup search](https://www.elastic.co/guide/en/elasticsearch/reference/current/rollup-search.html) is basically Search with a limited subset.

The REST API spec for `rollup.rollup_search.json` can be found [here](https://github.com/elastic/elasticsearch/blob/v7.5.1/x-pack/plugin/src/test/resources/rest-api-spec/api/rollup.rollup_search.json).
 I used the version: [ ] elastic.v7 (for Elasticsearch 7.x)

### Please describe the expected behavior
When writing data in batches, 200 pieces of data are written each time. If the amount of data before writing is 1688 pieces of data, it is expected to be written to es in 9 times: 200 pieces of data are successfully written for the first time, 200 pieces of data are successfully written for the second time... And so on. 88 pieces of data are written for the last time, and 1688 pieces of data can be seen in ES at last

### Please describe the actual behavior
However, when I write for the first time, the refresh time is 10s, only 197 pieces of data are displayed in ES, 397 pieces of data are displayed in es after the second write, 597 pieces of data are displayed in es after the third write.... and so on, only 1685 pieces of data are displayed in es at the end. If I write only one piece of data at a time, 1688 pieces of data can be displayed in ES. I try not to write the three lost data into es, and write them in batches again, that is, 1685 pieces of data, 200 pieces of data are written in batches each time. When the result is written in batches for the first time, what's the reason?

### Any steps to reproduce the behavior?

I tried to use a relatively simple data test, and it's no problem. When I had this problem, I found that each data structure was relatively complex and large, and each data size was about 3.3kb
Please use the following questions as a guideline to help me answer
your issue/question without further inquiry. Thank you.

### Which version of Elastic are you using?

[ ] elastic.v7 (for Elasticsearch 7.x)

### Please describe the expected behavior
When the index changes to be read-only, write data to es should return an error. https://www.elastic.co/guide/en/elasticsearch/reference/7.x/disk-allocator.html

### Please describe the actual behavior
With the PUT RESTFUL api, the error can be shown with "cluster_block_exception [index [XXXXX] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)]". But with BulkSerivce.Do function no error was returned.

i use v5 and v6,they all about it. 
i have to add timer to slow the bulk update
```
bulkRequest := self.ElasticClient.Bulk()
for req := range self.BulkChUpdate {
	bulkRequest = bulkRequest.Add(req)
	if bulkRequest.NumberOfActions() >= ExecuteBulkUpdateNums {
		tc := time.NewTimer(50 * time.Millisecond)
		<-tc.C
		
		bulkResponse, err := bulkRequest.Do(context.TODO())
		if err != nil {
			fmt.Println(err)
		}
		if bulkResponse == nil {
			fmt.Println("expected bulkResponse to be != nil; got nil")
		}
		break
	}
}
```
```

goroutine 11 [running]:
runtime.throw(0xb9eba7, 0x26)
	/usr/local/go/src/runtime/panic.go:774 +0x72 fp=0xc0000f4e08 sp=0xc0000f4dd8 pc=0x430a42
runtime.mapiternext(0xc000148540)
	/usr/local/go/src/runtime/map.go:858 +0x579 fp=0xc0000f4e90 sp=0xc0000f4e08 pc=0x410c19
reflect.mapiternext(0xc000148540)
	/usr/local/go/src/runtime/map.go:1347 +0x2b fp=0xc0000f4ea8 sp=0xc0000f4e90 pc=0x411c2b
reflect.Value.MapKeys(0xa92540, 0xc00039e660, 0x15, 0x0, 0x40f66b, 0xc0000f5008)
	/usr/local/go/src/reflect/value.go:1214 +0x10a fp=0xc0000f4f38 sp=0xc0000f4ea8 pc=0x49308a
encoding/json.mapEncoder.encode(0xbb5438, 0xc0007880e0, 0xa92540, 0xc00039e660, 0x15, 0xa90100)
	/usr/local/go/src/encoding/json/encode.go:690 +0xff fp=0xc0000f5080 sp=0xc0000f4f38 pc=0x4fdbbf
encoding/json.mapEncoder.encode-fm(0xc0007880e0, 0xa92540, 0xc00039e660, 0x15, 0xc000390100)
	/usr/local/go/src/encoding/json/encode.go:682 +0x64 fp=0xc0000f50c0 sp=0xc0000f5080 pc=0x508f44
encoding/json.(*encodeState).reflectValue(0xc0007880e0, 0xa92540, 0xc00039e660, 0x15, 0xc000390100)
	/usr/local/go/src/encoding/json/encode.go:337 +0x82 fp=0xc0000f50f8 sp=0xc0000f50c0 pc=0x4fb0b2
encoding/json.interfaceEncoder(0xc0007880e0, 0xa8e460, 0xc0006b2490, 0x94, 0xc0006b0100)
	/usr/local/go/src/encoding/json/encode.go:619 +0xac fp=0xc0000f5140 sp=0xc0000f50f8 pc=0x4fd36c
encoding/json.mapEncoder.encode(0xbb5438, 0xc0007880e0, 0xa92540, 0xc00039e6c0, 0x15, 0xa90100)
	/usr/local/go/src/encoding/json/encode.go:706 +0x351 fp=0xc0000f5288 sp=0xc0000f5140 pc=0x4fde11
encoding/json.mapEncoder.encode-fm(0xc0007880e0, 0xa92540, 0xc00039e6c0, 0x15, 0xc000780100)
	/usr/local/go/src/encoding/json/encode.go:682 +0x64 fp=0xc0000f52c8 sp=0xc0000f5288 pc=0x508f44
encoding/json.(*encodeState).reflectValue(0xc0007880e0, 0xa92540, 0xc00039e6c0, 0x15, 0xc000780100)
	/usr/local/go/src/encoding/json/encode.go:337 +0x82 fp=0xc0000f5300 sp=0xc0000f52c8 pc=0x4fb0b2
encoding/json.(*encodeState).marshal(0xc0007880e0, 0xa92540, 0xc00039e6c0, 0xc0000f0100, 0x0, 0x0)
	/usr/local/go/src/encoding/json/encode.go:309 +0x10b fp=0xc0000f5380 sp=0xc0000f5300 pc=0x4fab5b
encoding/json.Marshal(0xa92540, 0xc00039e6c0, 0xc00039e6c0, 0x0, 0x0, 0x0, 0xb050e0)
	/usr/local/go/src/encoding/json/encode.go:161 +0x52 fp=0xc0000f53f8 sp=0xc0000f5380 pc=0x4fa2e2
gopkg.in/olivere/elastic%2ev5.easyjson1ed00e60EncodeGopkgInOlivereElasticV51(0xc0007881c0, 0x0, 0xa92540, 0xc00039e6c0, 0x0, 0xaed7e0, 0xc00039e6f0, 0x0, 0x0, 0x0, ...)
	/home/www/sy_go/pkg/mod/gopkg.in/olivere/elastic.v5@v5.0.82/bulk_update_request_easyjson.go:303 +0x646 fp=0xc0000f5450 sp=0xc0000f53f8 pc=0x7eacc6
gopkg.in/olivere/elastic%2ev5.bulkUpdateRequestCommandData.MarshalJSON(0x0, 0xa92540, 0xc00039e6c0, 0x0, 0xaed7e0, 0xc00039e6f0, 0x0, 0x0, 0x0, 0x0, ...)
	/home/www/sy_go/pkg/mod/gopkg.in/olivere/elastic.v5@v5.0.82/bulk_update_request_easyjson.go:374 +0x61 fp=0xc0000f54c0 sp=0xc0000f5450 pc=0x7eae11
gopkg.in/olivere/elastic%2ev5.(*bulkUpdateRequestCommandData).MarshalJSON(0xc000172320, 0xb2e100, 0xc000172320, 0x7fee1025a148, 0xc000172320, 0xc000172301)
	<autogenerated>:1 +0x85 fp=0xc0000f5598 sp=0xc0000f54c0 pc=0x8ce3b5
encoding/json.marshalerEncoder(0xc000788000, 0xb2e100, 0xc000172320, 0x99, 0x100)
	/usr/local/go/src/encoding/json/encode.go:453 +0xc4 fp=0xc0000f5618 sp=0xc0000f5598 pc=0x4fba44
encoding/json.(*encodeState).reflectValue(0xc000788000, 0xb2e100, 0xc000172320, 0x99, 0x100)
	/usr/local/go/src/encoding/json/encode.go:337 +0x82 fp=0xc0000f5650 sp=0xc0000f5618 pc=0x4fb0b2
encoding/json.(*encodeState).marshal(0xc000788000, 0xb2e100, 0xc000172320, 0x100, 0x0, 0x0)
	/usr/local/go/src/encoding/json/encode.go:309 +0x10b fp=0xc0000f56d0 sp=0xc0000f5650 pc=0x4fab5b
encoding/json.Marshal(0xb2e100, 0xc000172320, 0xb2e100, 0xc000172320, 0xc00078c5a0, 0x8f, 0x0)
	/usr/local/go/src/encoding/json/encode.go:161 +0x52 fp=0xc0000f5748 sp=0xc0000f56d0 pc=0x4fa2e2
gopkg.in/olivere/elastic%2ev5.(*BulkUpdateRequest).Source(0xc0007060f0, 0xc0006b0240, 0x2, 0x2, 0x0, 0x0)
	/home/www/sy_go/pkg/mod/gopkg.in/olivere/elastic.v5@v5.0.82/bulk_update_request.go:287 +0x4a4 fp=0xc0000f5910 sp=0xc0000f5748 pc=0x7e88b4
gopkg.in/olivere/elastic%2ev5.(*BulkService).estimateSizeInBytes(0xc0000f5f10, 0xc6c300, 0xc0007060f0, 0x148)
	/home/www/sy_go/pkg/mod/gopkg.in/olivere/elastic.v5@v5.0.82/bulk.go:155 +0x31 fp=0xc0000f5950 sp=0xc0000f5910 pc=0x7e1441
gopkg.in/olivere/elastic%2ev5.(*BulkService).EstimatedSizeInBytes(0xc0000f5f10, 0x0)
	/home/www/sy_go/pkg/mod/gopkg.in/olivere/elastic.v5@v5.0.82/bulk.go:145 +0xa7 fp=0xc0000f5998 sp=0xc0000f5950 pc=0x7e1397
gopkg.in/olivere/elastic%2ev5.(*BulkService).bodyAsString(0xc0000f5f10, 0x0, 0x0, 0x0, 0x0)
	/home/www/sy_go/pkg/mod/gopkg.in/olivere/elastic.v5@v5.0.82/bulk.go:172 +0x40 fp=0xc0000f5a38 sp=0xc0000f5998 pc=0x7e14e0
gopkg.in/olivere/elastic%2ev5.(*BulkService).Do(0xc0000f5f10, 0xc725e0, 0xc000028148, 0x1, 0xc000062f10, 0x0)
	/home/www/sy_go/pkg/mod/gopkg.in/olivere/elastic.v5@v5.0.82/bulk.go:198 +0x4e fp=0xc0000f5e70 sp=0xc0000f5a38 pc=0x7e174e
tools/Uprofile/components.(*EsDataService).bulkUpdate(0xc000101260)
	/home/www/go_project/tools/Uprofile/components/Es.go:96 +0xf6 fp=0xc0000f5fd8 sp=0xc0000f5e70 pc=0x9e45e6
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:1357 +0x1 fp=0xc0000f5fe0 sp=0xc0000f5fd8 pc=0x45db51
created by tools/Uprofile/components.(*EsDataService).OpenBulkUpdate
```

### Which version of Elastic are you using?

[ 7.0.9] elastic.v7 (for Elasticsearch 7.x)
### Please describe the expected behavior
Bulk request should insert the record with out any error

### Please describe the actual behavior
Bulk request Do() function returns error:
 invalid character '<' looking for beginning of value

### Any steps to reproduce the behavior?
Code:
        req := elastic.NewBulkIndexRequest().Index("test").Type("test1").Id("12").Doc("Hello") //
	fmt.Printf("Request: %+v\n", req)
	bulkrequest = bulkrequest.Add(req)
	fmt.Println("Number of request",bulkrequest.NumberOfActions())

	fmt.Printf("%+v", bulkrequest)
	fmt.Println(" ")
	fmt.Println(getType(*bulkrequest))


	//bulkrequest = bulkrequest.Retrier(elastic.Retrier{})
	resp, err := bulkrequest.Do(esDB.NetContext)
	if err != nil {
		fmt.Println("Error while Bulk dumping batch data in elastic: ", err)
		fmt.Println("Bulk response:", resp)
	}
	fmt.Println("Number of request",bulkrequest.NumberOfActions())

Output: 

> Request: {"index":{"_index":"test","_id":"12","_type":"test1"}}
Hello
Number of request 1
&{client:0xc0000f2820 retrier:<nil> pretty:<nil> human:<nil> errorTrace:<nil> filterPath:[] headers:map[] index: typ: requests:[0xc000162000] pipeline: timeout: refresh: routing: waitForActiveShards: sizeInBytes:0 sizeInBytesCursor:0}
BulkService
Error while Bulk dumping batch data in elastic:  invalid character '<' looking for beginning of value
Bulk response: <nil>
Number of request 1

> 

Please let me know what could be the issue in the code?
### Which version of Elastic are you using?

elastic.v7 (for Elasticsearch 7.x)
elastic.v6 (for Elasticsearch 6.x)

### Please describe the expected behavior
The `maxDocsPerValue` and `executionHint` fields do not belong here. The Sampler aggregation was broken into 2 different aggs in v5.0, and the diversity part was moved to the [Diversified Sampler](https://www.elastic.co/guide/en/elasticsearch/reference/master/search-aggregations-bucket-diversified-sampler-aggregation.html) aggregation.

### Any steps to reproduce the behavior?
For example, this:
```go
agg := elastic.NewSamplerAggregation().MaxDocsPerValue(2);
childAgg := elastic.NewSumAggregation().Field("some_field");
agg.SubAggregation("sub_agg", childAgg);
```
will result in:
```
Error 400 (Bad Request): Unsupported property "max_docs_per_value" for aggregation "agg [type=parsing_exception]
```

The same goes for `execution_hint`
### Which version of Elastic are you using?
[ ] elastic.v7 (for Elasticsearch 7.x)
[x] elastic.v6 (for Elasticsearch 6.x)
[ ] elastic.v5 (for Elasticsearch 5.x)
[ ] elastic.v3 (for Elasticsearch 2.x)
[ ] elastic.v2 (for Elasticsearch 1.x)

### Please describe the expected behavior
In case of any client side error from ES, bulk processor shouldn't retry that request. 

### Please describe the actual behavior
It's retrying forever for all the errors.

### Any steps to reproduce the behavior?
Generate a very large doc (> 10MB), it can cause 413 on AWS hosted ES.
