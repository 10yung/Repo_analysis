I have used the minimum Digital Ocean Droplet (512MB RAM), and the default userdata always gives me this error. 
![image](https://cloud.githubusercontent.com/assets/4648891/26295615/13a0e64c-3ea1-11e7-86ab-dd506989902c.png)

Solved changing both occurrences of `Environment="SWAPFILE=/2GiB.swap" ` to 1GiB and ExecStart=/usr/bin/fallocate -l 2048m ${SWAPFILE} to 1024m in userdata.


I have tried on stable, beta and alpha versions of CoreOS in Digital Ocean, and alway the same issue.

![image](https://cloud.githubusercontent.com/assets/4648891/26295378/f03903e8-3e9f-11e7-8cd1-a8f59c604393.png)

Is this normal?

I have installed paz on digital ocean, but how to access the web app? Entering the ip direct in the URL (port 80) doesn't work. Tested on stable, beta and alpha versions of CoreOS.
Hi, I would like to ask if this project is still active since I am evaluating Docker related Paas. Thanks.
The instructions say to run the following command:

```
brew install etcdctl fleetctl
```

Which promptly causes brew to complain that etcdctl doesn't exist. A little more digging suggested that this library was merged into etcd:

https://github.com/Homebrew/legacy-homebrew/issues/37236

I created a coreOS cluster with 3 nodes. I am able to manually run services and use docker builds. Can anyone help me to install paz? 
One more question, Is PAZ production ready now?

@lukebond : came to know about PAZ from your london presentation. can you please suggest something?

Currently the haproxy confd template is generated with run.sh in the haproxy container. This means that the only way to change the template is to eclipse the script with your own to generate a different config file. This works fine, but has the unfortunate side-effect of the template only updating when the container is restarted.

This is just a quality of life type of thing.

The leaks reported in the tests appears to be a `lab` issue, an update should fix:

https://github.com/hapijs/lab/issues/343

I started playing around with paz, and i am finding very useful for some side projects i am working on.  
One thing I am missing is the possibility to export the current cluster configuration in an external file , just to be able to reimport it later, instead of recreating everything anew via the UI.  
The service should be available both from the UI and via API.
I will give it a try to implement it this weekend , so wish me luck!
Any tip in particular to where should i start from?

https://github.com/gliderlabs/registrator
