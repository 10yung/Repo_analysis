## Expected Behavior
Hi，I want to know how does mitie deal with the segmentation of OOV.
In fact, two of my train example like this:
1.The daily life of the \[League Of Legends\](name) on November 10 (chinese:  \[英雄联盟\](name)11.10的日活)
2. The daily life of the \[Tomb Raider3\](name) on November 10  (chinese:  \[古墓丽影3\](name)11.10的日活)
My training sample is in Chinese which contains many entities related to the game name. Some game names contain numbers, some have no numbers，like "古墓丽影3" and ”英雄联盟“.In the example above , I want mitie to identify the entities as "古墓丽影3" and the ”英雄联盟“. 11.10 is a simple representation of the date,which should not be include.

## Current Behavior
I label the entity correctly.However, the first sample is often identified as ”英雄联盟11" rather than ”英雄联盟". How can I deal with this problem? I try to add several data,but It's work. Should I add more data ?


* **Version**: 0.7.0
* **Where did you get MITIE**: pip install
* **Platform**: windows64 and linux64


<!-- ================================================================ -->
<!-- =====================  BUG REPORT TEMPLATE ===================== -->
<!-- ================================================================ -->


<!-- Delete the above instructions and then provide a general summary of the issue in the Title above.  Then fill out the template below. -->

## Expected Behavior
<!--- Tell us what should happen.  What were you doing?  What part of MITIE are you using?  What do you think should happen? -->
So, I'm using the named_entity_extractor, trained it on some data, then extracting entities from some data the model has never seen before using the extract_entities. Expecting to get back the extracted entities with their scores ranging 0-1

## Current Behavior
The entities are extracted correctly, but the score is 0.


## Steps to Reproduce
<!--- Provide an unambiguous set of steps to reproduce this problem. Include code to reproduce, if relevant -->
Train model, give it new data, get back score == 0



* **Version**:  downloaded on 19th of July 2019
* **Where did you get MITIE**:  Github
* **Platform**: 64 bit

## Behaviour and Step to Reproduce
When I running on 8GB RAM, and 16GB swap, it uses full ram and 10GB swap. but still ~5GB free on the swap. Why It raises std::bad_alloc instead of using the rest of swap

* **Version**: 0.7.0
* **Where did you get MITIE**: Clone latest
* **Platform**: Ubuntu 16.04
* **Compiler**: GNU Make 4.1

Hi, @davisking, Is it possible to train my NER model using GPU?
How to annotate for large text file. 
Any suggestions for appropriate tools to be used.
We are using Windows 10 PRO  64 Bit, with RASA  .13.0  and Mitie .5.0  version.
My RAM is 16GB  and  Processor : CPU 2.30Ghz, 
PageFile says: 25677MB used, 938 available.

I'm running MITIE with 180 examples with 24 threads ,It took 4.5 hours and throw exception.
[ I have uploaded the exception message what i get.]
![mitie_issue](https://user-images.githubusercontent.com/20996760/45736167-caeb2080-bc07-11e8-8496-021db7657d75.jpg)

mitie.py,line 271, in save_disk
if(_f.mitie_save_named_entity_extractor_pure_model(filename, self._obj)!=0):
OSError: exception: access viloation reading 0x00000000000..0000030


Also my model_20180918-150254 contains only training_data.json,  other files like entity_extractor.dat,intent_classifier.dat, metadata.json,regex_feaurizer.json  are not generated.

But when i test the same with only 2-3 examples, it's all good.




Hi,
When I try to run ner.py, I get the following error
 File "C:\Users\xxxx\rasa_nlu\MITIE\examples\python\ner.py", line 15, in <module>
    from mitie import *
  File "C:\Users\xxxx\rasa_nlu\MITIE\examples\python\mitielib\mitie.py", line 61, in <module>
    _f.mitie_extract_entities_with_extractor.restype = ctypes.c_void_p
  File "C:\Program Files\Python37\lib\ctypes\__init__.py", line 369, in __getattr__
    func = self.__getitem__(name)
  File "C:\Program Files\Python37\lib\ctypes\__init__.py", line 374, in __getitem__
    func = self._FuncPtr((name_or_ordinal, self))
AttributeError: function 'mitie_extract_entities_with_extractor' not found

I see references to mitie_extract_entities_with_extractor in mitie.cpp and mitie.h which are in C:\Users\xxxx\rasa_nlu\MITIE\mitielib\src and C:\Users\xxxx\rasa_nlu\MITIE\mitielib\include

why is it not able to get to the function call?
need help ...

sorry guys it's not exactly issue. but it's information i need..

guys please tell me  **why default C = 300 used in mitie ?** when we are doing cross validation with taking input min_C = 0.0001 , max_C  = 5000 and epsilon = 1. i believe we are using cross validation for choosing best hyper parameter(C & epsilon). then what is the use of defining C=300 ?

i know what is the use of C (regularisation hyper parameter.)

my problem is : i tried with different value of C but keeping other value as it is. and every time i got same Accuracy and F1 score with different best C value. why is it so ?

please see log ..
 
=============================================== C=300
num training samples: 1441
C: 200 f-score: 0.734335
C: 400 f-score: 0.735081
C: 300 f-score: 0.731994
C: 500 f-score: 0.735241
C: 700 f-score: 0.734709
C: 520 f-score: 0.733273
C: 450.957 f-score: 0.733804
C: 483.4 f-score: 0.736308
C: 480.156 f-score: 0.735241
C: 490.078 f-score: 0.734653
C: 484.607 f-score: 0.735241
C: 482.381 f-score: 0.732305
C: 483.799 f-score: 0.734653
C: 483.236 f-score: 0.732149
best C: 483.4

test on train:
286 2 0 3
0 759 0 3
0 0 43 0
4 6 0 335

overall accuracy: 0.987509
Part II: elapsed time: 19417 seconds.
============================================== C=100
num training samples: 1420
C: 0.01 f-score: 0.673219
C: 200 f-score: 0.75807
C: 100 f-score: 0.758977
C: 148.954 f-score: 0.758783
C: 124.134 f-score: 0.759333
C: 121.721 f-score: 0.757521
C: 136.154 f-score: 0.760752
C: 134.952 f-score: 0.756639
C: 142.253 f-score: 0.757164
C: 138.668 f-score: 0.758945
C: 137.088 f-score: 0.756806
C: 136.031 f-score: 0.759333
C: 136.479 f-score: 0.759459
best C: 136.154
test on train:
286 2 0 3
0 761 0 1
0 0 43 0
4 9 0 311

overall accuracy: 0.98662
Part II: elapsed time: 6148 seconds.
============================================== C=50
num training samples: 1432
C: 0.01 f-score: 0.670678
C: 200 f-score: 0.754349
C: 100 f-score: 0.755016
C: 149.215 f-score: 0.753461
C: 121.914 f-score: 0.755938
C: 118.753 f-score: 0.753097
C: 134.168 f-score: 0.75631
C: 129.929 f-score: 0.756474
C: 129.128 f-score: 0.755917
C: 131.916 f-score: 0.754349
C: 130.128 f-score: 0.755402
C: 129.586 f-score: 0.755938
best C: 129.929
test on train:
286 2 0 3
0 761 0 1
0 0 43 0
5 10 0 321

overall accuracy: 0.985335
Part II: elapsed time: 5562 seconds.
df.number_of_classes(): 4
============================================== C=300
num training samples: 1455
C: 200 f-score: 0.73822
C: 400 f-score: 0.736475
C: 300 f-score: 0.738895
C: 271.805 f-score: 0.737705
C: 326.638 f-score: 0.735243
C: 292.355 f-score: 0.738378
C: 302.664 f-score: 0.733705
C: 296.35 f-score: 0.736475
C: 298.977 f-score: 0.737146
C: 300.35 f-score: 0.736944
C: 299.649 f-score: 0.738933
C: 299.804 f-score: 0.735961
best C: 299.649
test on train:
288 2 0 1
0 760 0 2
0 0 43 0
5 8 0 346

overall accuracy: 0.987629
Part II: elapsed time: 11576 seconds.
df.number_of_classes(): 4

============================================== C=500
Part II: train segment classifier
now do training
num training samples: 1358
PART-II C: 500
PART-II epsilon: 0.0001
PART-II num threads: 4
PART-II max iterations: 2000
C: 400 f-score: 0.774171
C: 600 f-score: 0.778615
C: 500 f-score: 0.779291
C: 538.343 f-score: 0.774471
C: 470.021 f-score: 0.779522
C: 480.425 f-score: 0.776386
C: 443.145 f-score: 0.774217
C: 463.96 f-score: 0.775954
C: 472.435 f-score: 0.775831
C: 468.168 f-score: 0.770751
C: 470.707 f-score: 0.772416
C: 469.493 f-score: 0.770333
C: 470.138 f-score: 0.779291
best C: 470.021
test on train:
287 2 0 2
0 761 0 1
0 0 43 0
6 9 0 247

overall accuracy: 0.985272
Part II: elapsed time: 18762 seconds.
df.number_of_classes(): 4

==============================================

from above log : why best C is coming nearer value of given "C" value ? no matter what C value i choose.

Thanks in advance. @baali @scotthaleen @avitale @kecsap @lopuhin @davisking @jinyichao @avitale 
I have a large amount of texts which I want to test through the python examples. My question is: The annotated data I am going to provide, does it have to be split up into sentences? Do I have the ability to pass a whole text with multiple sentences, paragraphs and lines, and thus, the range numbers of each entity be based on the word counting of the whole document and not each sentence separately? 

Based on the comment of the inner code (for example on train_ner.py): 
"When you train a named_entity_extractor you need to get a dataset of sentences (or sentence or paragraph length chunks of text) where each sentence is annotated with the entities you want to find." I would like to make clearer the part on the paragraph length chunks of text.

Thank you in advance.
how can i improve this situation 
give me some suggestion ，please