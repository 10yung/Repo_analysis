Here is the table struct:
```sql
CREATE TABLE public.t_org_goods (
	id bigserial NOT NULL, -- 自增主键
	goods_id int8 NOT NULL, -- 商品id
	org_id int8 NOT NULL, -- 企业id
	created_by int8 NOT NULL, -- 创建者id
	created_time timestamptz NOT NULL DEFAULT now(), -- 创建时间
	CONSTRAINT t_org_goods_pk PRIMARY KEY (id)
);
```
Here is the model
```go
type creatorInfo struct {
	CreatedTime *time.Time `json:"createdTime,omitempty"`
	CreatedBy   int64      `json:"createdBy,omitempty"`
	Creator     *UserInfo  `pg:"fk:created_by" json:"creator,omitempty"`
}
// the composited model 
type OrgGoods struct {
	creatorInfo // created_time and created_by
       GoodsID     int64  `json:"goodsId,omitempty,string" sql:",notnull"` // 商品id
       OrgID       int64  `json:"-" sql:",notnull"`                        // 企业id
       Code       string
       tableName struct{} `pg:",discard_unknown_columns"`
}
now := time.Now()
orgGoods.OrgID = user.OrgID
orgGoods.CreatedTime = &now
orgGoods.CreatedBy = user.ID // user.ID = 1
orgGoods.Code = goods.code

session := newPgConn()
db := session.Open().(*pg.DB)
defer session.Close()
q = db.Model(m)
if len(columns) > 0 {
   q.Column(columns...)
}
err = DB.AddModel(orgGoods, "code", "id", "goods_id", "org_id", "created_by", "created_time")
// err = DB.AddModel(orgGoods)  // if inserting without columns, it works fine, so weird
// function body
func (dbs *dbPg) AddModel(db interface{}, m interface{}, columns ...string) error {
	q := dbs.getQuery(db, m)
	if q == nil {
		session := newPgConn()
		db := session.Open().(*pg.DB)
		defer session.Close()
		q = db.Model(m)
	}
        // columns is alternative
	if len(columns) > 0 {
		q.Column(columns...)
	}
	_, err := q.Insert()
	dbs.checkTxErr(db, err)
	return err
}
```
The model has the value assigned for created_time and created_by definitely, but it does not be scaned out and saved into db. please see below the error message.
```sql
INSERT INTO "t_org_goods" ("code", "id", "goods_id", "org_id", "created_by", "created_time") VALUES ('1753468097978616987', DEFAULT, 23, 1, DEFAULT, DEFAULT) RETURNING "id", "created_by", "created_time" <nil>
2020-01-18T20:39:26+08:00 debug layer=debugger continuing
ROLLBACK <nil>
[ERRO] 2020-01-18 20:39:26 ERROR #23502 null value in column "created_by" violates not-null constraint
```
if there is no columns specified when q.insert(), everything is ok. so what's happening when adding the columns? so far, I am sure it should be a bug.
version: github.com/go-pg/pg/v9 v9.1.1
thanks.
Hi there,

Is there a way to generate foreign key automatically in many2many example?
I'm using v9 with postgres 12, after running the [example](https://godoc.org/github.com/go-pg/pg#example-DB-Model-ManyToMany). 

After that I found that no foreign keys have been created in table order_to_items.

```
\d order_to_items 
           Table "test.order_to_items"
  Column  |  Type  | Collation | Nullable | Default 
----------+--------+-----------+----------+---------
 order_id | bigint |           |          | 
 item_id  | bigint |           |          | 

 \d items
                            Table "test.items"
 Column |  Type  | Collation | Nullable |              Default              
--------+--------+-----------+----------+-----------------------------------
 id     | bigint |           | not null | nextval('items_id_seq'::regclass)
Indexes:
    "items_pkey" PRIMARY KEY, btree (id)

=> \d orders
                            Table "test.orders"
 Column |  Type  | Collation | Nullable |              Default               
--------+--------+-----------+----------+------------------------------------
 id     | bigint |           | not null | nextval('orders_id_seq'::regclass)
Indexes:
    "orders_pkey" PRIMARY KEY, btree (id)
```

And create table like this:

```
	models := []interface{}{
		(*Order)(nil),
		(*Item)(nil),
		(*OrderToItem)(nil),
	}
	for _, model := range models {
		err := db.CreateTable(model, &orm.CreateTableOptions{
			Temp:          false,
			FKConstraints: true,
		})
		if err != nil {
			panic(err)
		}
	}
```
Hi,

I'm running postgres 11.5 (via RDS, though I don't think it matters) and when I try to connect with pg I get the following error:
```
"pg: SASL: got \"SCRAM-SHA-256-PLUS\", wanted \"SCRAM-SHA-256\""
```

Is this possibly a known issue?

Thanks,

---

**edit:** putting in my notes for anyone else who finds this later. SCRAM-SHA-256-PLUS is used when the postgres server requires TLS to connect to it (as I have configured my RDS instance to do). Since go-pg doesn't support this method yet the 2 current options are to:
- update postgres to allow plaintext connections / stop requiring TLS
- or, downgrade the role's password to MD5 instead of SCRAM

I have opted for the latter solution. This can itself be done in one of two ways:
- Update your postgres [authentication settings](https://www.postgresql.org/docs/12/runtime-config-connection.html#RUNTIME-CONFIG-CONNECTION-AUTHENTICATION) and set the inappropriately named `password_encryption` parameter to `md5` (if you're using AWS RDS this is controlled via a parameter group). Then update the role's password via psql:
    ```
    postgres=> alter role myrole with password 'password';
    ```
- or, directly update the role's password. To allow dumping/restoring backups, postgres lets you assign a raw md5/scram value to the role's password column. The md5 format postgres uses is the string "md5" followed by the md5 hash of the password concatenated with the role's name. So for a role "myrole" and password "password", you can run:
    ```
    $ echo -n "passwordmyrole" | md5sum | awk '{print "md5"$1}'
    md519488a15bff1b244feb52d621ac8b965
    ```
    Then set this as the password value via psql:
    ```
    postgres=> alter role myrole with password 'md519488a15bff1b244feb52d621ac8b965';
    ```

Hope this helps someone
It allows to specify a schema name for particular model.
I.e. you can bravely list all columns in your database using
"information_schema" tables with such model:
```go
type Column struct {
  tableName struct{} `pg:"columns,schema:information_schema"`

  DBTableName string `pg:"table_name"`
  ColumnName  string `pg:"column_name"`
}
```
Should close #1468.
Is there any way to shoehorn tracing with [`ocsql`](https://godoc.org/contrib.go.opencensus.io/integrations/ocsql)?

If not, do you consider implementing it?
Currently to make a query from table located in non-default (or currently selected schema) I use this hack
```go
type queryResult struct {
		tableName struct{} `sql:"information_schema.columns,alias:columns"`
                Name string `sql:"name"`
}
```
 which generates a correct query.
I think it will be better to have posibility to set schema name using a tag in tableName (like ```sql:"columns,schema:information_schema"```) and in query builder (like ```db.Model().SchemaExpr(schema)...```.

I've added logger (*zerolog.Event) into my context and pass it arround for logging things.

I wanted to include my query in context, but I noticed that Before/AfterQuery get an empty context (context.Background). I tried changing my db calls to use `WithContext(ctx)`, but the hooks still got an empty context.

From `go.mod`:

```
github.com/go-pg/pg/v9 v9.0.3
```
I have defined Filter struct for WhereStruct and used the "required" tag as described.
```
type Filter struct {
	Status          int32 `pg:",required"`
}

...

filter = new(Filter)
db.Model(&books).WhereStruct(filter)
```
But it seems that this tag doesn't work if Status is 0. The field is missed in SQL query.
[Link to definition](https://github.com/go-pg/pg/blob/38f0d75d8fa3b1dff65a90a1641d7ea2c494b62b/orm/query.go#L591)
Here is my attempt to make recursive with ASAP. May be useful for someone.

A while back we tried the following change:
```
opts.ReadTimeout = 3 * time.Second // max time for SELECT
opts.WriteTimeout = 3 * time.Second // max time for INSERT, UPDATE, or DELETE
```

We would then get occasional errors along the lines of `pg: can't find column=foo in model=bar`. 
Our theory is that timed out queries can return their outputs to other queries.

This was an issue back when we were on v6.35, and I just managed to reproduce it on v8.06 by setting timeouts of 500 milliseconds. Got it 12 times in an hour of testing merely by cranking up the number of workers in a sandbox environment.

As far as I can tell, the way to reproduce this is to have a high volume of queries which are not all the same, and some of which time out and some of which don't.

Please let me know if you need any more information. I would very much like to have query timeouts, so this is a big blocker.