Although [mentat](https://github.com/mozilla/mentat) is not finished, it will be very useful at clients. It's based on SQLite.

If the client is going to be coded in Rust, then a RPC framework like [tarpc](https://github.com/google/tarpc) could be better.

Currently, the backend is defined in Rust. We should add a CMD backend to allow users to define their backend via small programs in PATH. This will make reuse of existing tooling around storage backends easier.

Listing all our hashes or keys is using linear memory and could potentially be too large for RAM.

Whenver we list the contents of an index, the result should be streamed out the underlying SQLite database. There is currently no way to do this with Diesel (except manually with limits), so we will revisit this later when Diesel and our codebase have both matured a bit more.

Currently, we abort when a hash from the index is not known, causing resume to auto-retry and abort again.

We should either skip files with unknown hashes (with a warning) or abort gracefully (without resume).

There should supposedly be many unnecessary calls to .clone(). Some of them should be removable directly while some could be removed by restructuring a few APIs.

The current benchmarks have very high variance -- it is almost impossible to assert whether a code change results better, worse or unchanged performance.

This could potentially be done as part of #23.

The current benchmarks only run on nightly. To be able to compile on stable, they have been put the feature-gate `benchmarks`. This is not ideal, as it would be nice to have benchmarks on stable as well.

Ideas:
- Visualize the tree
- A command-line option to get information about a specific hash
- `hat fsck`?

Currently not all threads propagate errors when handling incoming requests. Changing this should make the code easier to follow by removing premature panics and allow us to test the resume functionality.

The idea is to trigger an error, reset the hat system and then resume. At present, just triggering the error causes a panic, which wipes the in memory databases used during tests.

An alternate option: put the test databases in local temporary files and recover the panic. Error propagation seems cleaner, although a true panic would probably be more authentic.
