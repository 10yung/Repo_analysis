
PYSPARK_DRIVER_PYTHON="jupyter" PYSPARK_DRIVER_PYTHON_OPTS="notebook" ../spark-2.2.3-bin-hadoop2.7/bin/pyspark --driver-memory 4g --driver-class-path /application/search/es-spark-recommender/elasticsearch-hadoop-5.3.0/dist/elasticsearch-spark-20_2.11-5.3.0.jar
I'm extremely new to ES but I've been going through the notebook changing code where required to make it work (e.g multiple types per index are no longer supported). I'm now stuck at the retrieving/calculating the recommendations part of the example (after calculating the embeddings and bringing them back into ES).

Specifically in the fn_query this part of the ES query is out of date:

```
"script": {
"inline": "payload_vector_score",
"lang": "native",
"params": {
"field": "@model.factor",
"vector": query_vec,
"cosine" : cosine
}
}
```

fails and I get the error :
`RequestError: RequestError(400, 'search_phase_execution_exception', 'script_score: the script could not be loaded')`

And I'm not sure how to get this up to speed for ES 6.6.

Cheers!

EDIT: Ah, I'm assuming the script is a plugin written by MLnick in his other repository? Which I notice has a TODO for porting to latest ES.


I created a Dockerfile that install the vector plugin to elasticserch and create an image.
Hello,

I've added functions to display users similar to a given one, for user-user recommendation. Since we only use user IDs and not usernames, it is a bit raw, but it is still functional
`PYSPARK_DRIVER_PYTHON="jupyter"`` PYSPARK_DRIVER_PYTHON_OPTS="notebook" ../spark-2.2.0-bin-hadoop2.7/bin/pyspark --driver-memory 4g --driver-class-path ../../elasticsearch-hadoop-5.3.0/dist/elasticsearch-spark-20_2.11-5.3.0.jar`
 
This gives an error in command prompt 

> PYSPARK_DRIVER_PYTHON is not recognized as an internal or external command, operable command or a batch file

Downloaded and installed everything. When I'm running the `# check PySpark is running
spark` command. I get this:

> NameError                                 Traceback (most recent call last)
> <ipython-input-2-456c22950c2a> in <module>()
>       2 from IPython.display import Image, HTML, display
>       3 # check PySpark is running
> ----> 4 spark
> 
> NameError: name 'spark' is not defined

My commands:
```
SET PYSPARK_DRIVER_PYTHON=C:\Program Files (x86)\Python36-32\Scripts\jupyter.exe
SET PYSPARK_DRIVER_PYTHON_OPTS=notebook --no-browser
..\spark-2.2.0-bin-hadoop2.7\bin\pyspark --driver-memory 4g --driver-class-path ..\elasticsearch-hadoop-5.3.0\dist\elasticsearch-hadoop-5.3.0.jar
```