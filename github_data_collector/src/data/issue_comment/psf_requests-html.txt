Hi 
I am trying  to use requests_html lib for my code,but I am getting following ERROR.

    from requests_html import HTML
  File "/usr/lib/python2.7/site-packages/requests_html.py", line 20
    def __init__(self, *, element, html=None, url):

I am using Python 2.7.5 version. 
Can someone look into this issue and let me know what is wrong ? 
Hi, I'm learning about web scrapping stuffs, and I've started to experiment with the Async class from this library, until I've stumbled into the following problem.

This is my code, which is a function that receives a set of rules to know what to do when the AsyncHTMLSession() is open.


```

async def get_info_scrapp(data_id, base, css_selector, loading_time):
    asession = AsyncHTMLSession()
    request = await asession.get(f"{base}{data_id}")
            
    # rendering the JS on the page
    await request.html.arender(wait=loading_time)

    data = await request.find(css_selector, first=True)
    await request.asession.close()
    
    return data

```

Without finishing the first run, I receive the following error:

RuntimeError: Event loop is closed
sys:1: RuntimeWarning: coroutine 'Launcher.killChrome' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback

Do you have any ideias of what I did wrong? 
Thanks!

Hi all i am using this library to crawl angular website. i need only html page response and i am not even rendering the page only request for html raw response but after some time running fine it throw error as below.
**requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.example.com', port=443): Max retries exceeded with url: /example (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb37cc09940>: Failed to establish a new connection: [Errno -2] Name or service not known',))**
Please help me.
Multi url call with asyncio makes things complicated in our medium-size project. 

How can we bypass it ?

Is there any way to use requests_html within threads or maybe in in greenlets to make things simpler?

**Note:**

```python3

async def get_reddit():
    r = await asession.get('https://reddit.com/')
    return r
```
example is not a good idea in thousands of urls (:
Example:
`li[class="pageNav-page "]>a`:
![1576389936](https://user-images.githubusercontent.com/38200989/70859033-d9a4ae00-1f04-11ea-8293-8e6764d36420.png)
![1576389962](https://user-images.githubusercontent.com/38200989/70859034-d9a4ae00-1f04-11ea-8896-76e8459eb16f.png)
The response page received is stored locally in a file and does indeed contain the element but doing: `page.html.find('li[class="pageNav-page "]>a')` yields an empty list whereas it should be returning a list with at least one element

similar to https://github.com/psf/requests-html/issues/257
Most competent web servers would shut down your little scraper very quickly  
hi i want to visit one website with ip-proxy, i wonder how i could use ip-proxy in requests-html? 
when i use import this module use python 3.6.0 always has some mistaskes.

>>> from requests_html import HTMLSession
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/local/python3/lib/python3.6/site-packages/requests_html.py", line 9, in <module>
    import pyppeteer
  File "/usr/local/python3/lib/python3.6/site-packages/pyppeteer/__init__.py", line 30, in <module>
    from pyppeteer.launcher import connect, launch, executablePath  # noqa: E402
  File "/usr/local/python3/lib/python3.6/site-packages/pyppeteer/launcher.py", line 24, in <module>
    from pyppeteer.browser import Browser
  File "/usr/local/python3/lib/python3.6/site-packages/pyppeteer/browser.py", line 13, in <module>
    from pyppeteer.connection import Connection
  File "/usr/local/python3/lib/python3.6/site-packages/pyppeteer/connection.py", line 12, in <module>
    import websockets
  File "/usr/local/python3/lib/python3.6/site-packages/websockets/__init__.py", line 3, in <module>
    from .auth import *
  File "/usr/local/python3/lib/python3.6/site-packages/websockets/auth.py", line 15, in <module>
    from .server import HTTPResponse, WebSocketServerProtocol
  File "/usr/local/python3/lib/python3.6/site-packages/websockets/server.py", line 49, in <module>
    from .protocol import WebSocketCommonProtocol
  File "/usr/local/python3/lib/python3.6/site-packages/websockets/protocol.py", line 18, in <module>
    from typing import (
ImportError: cannot import name 'Deque'

Hi All
what's different between requests and requests html in python module?


Hi,

I'm trying to render JavaScript from webpages, but requests-html fails every time to do it.

This is my code:
`from requests_html import HTMLSession`
`s = HTMLSession()`
`r = s.get('https://httpbin.org')`
`r.html.render()`
`print(r.html.html)`

Some important points to make:
-Searching with CTRL+F in the output for the right version that's displayed when rendering the JavaScript; version 0.9.2 is for non-javascript, while 0.9.3 is for javascript - it always shows 0.9.2
-Searching the keyword "cookie" (it displays "0 matches" even when typing only "cook") doesn't show anything because that keyword is displayed when rendering the JavaScript

It prints out the only HTML code before executing the JavaScript. I've tried to put a bigger timeout to render:
`r.html.render(timeout=60)`

But it still waits the default 8 seconds.

When trying to put:
`r.html.render(sleep=60)`

It waits for those 60 seconds and then it doesn't do anything; more than that, it says that the connection's been lost.

I thought that maybe it didn't render the JavaScript because it didn't have any type of headers so I've added the Chrome's ones (I've tried with user-agent only & then with all headers displayed in the network tab from Chrome when accessing httpbin.org), but still with no success.

I've tried to render the JavaScript with Pyppeteer which is included in the requests-html library and it can render the JavaScript (I don't understand why since it's included in the requests-html library); the only downside of this is that I've to scrape lots of links, but I couldn't find a way to run multiple instances of Pyppeteer.

By the way, I'm using PyCharm on Windows 10 with Python 3.6.1 (3.6 throws an error regarding a 'Deque' thing that can't be imported) / 3.7; maybe this info helps in solving the issue.

I've tried to be as detailed as possible with the problems I'm facing right now and I hope I can get the solutions I'm looking for.

Thanks in advance!

P.S. Chromium is downloaded and it shows in task manager when running the render() function (same happens when running the Pyppeteer code).