When building with Bazel, deprecated warnings for CSV Reporter causes builds with warning as errors to fail. Similar to #608 

```
INFO: From Compiling external/googlebenchmark/src/benchmark.cc:
external/googlebenchmark/src/benchmark.cc: In function 'std::unique_ptr<benchmark::BenchmarkReporter> benchmark::internal::{anonymous}::CreateReporter(const string&, benchmark::ConsoleReporter::OutputOptions)':
external/googlebenchmark/src/benchmark.cc:300:24: warning: 'CSVReporter' is deprecated: The CSV Reporter will be removed in a future release [-Wdeprecated-declarations]
     return PtrType(new CSVReporter);
                        ^~~~~~~~~~~
In file included from external/googlebenchmark/src/benchmark.cc:15:0:
bazel-out/k8-opt/bin/external/googlebenchmark/_virtual_includes/benchmark/benchmark/benchmark.h:1520:61: note: declared here
     "The CSV Reporter will be removed in a future release") CSVReporter
```

Currently we're getting around this by patching the BUILD.bazel file with `copts = ["-Wno-deprecated-declarations"]`
The ```diagnostics_test``` crashes on macOS 10.15 Catalina. My toolchain uses CMake 3.16, MacPorts' LLVM Clang 9.0.0, and Ninja. Google Benchmark is built in debug mode.

I have included the stacktrace from LLDB below.
```
* thread #1, queue = 'com.apple.main-thread', stop reason = signal SIGABRT
  * frame #0: 0x00007fff669417fa libsystem_kernel.dylib`__pthread_kill + 10
    frame #1: 0x00007fff669febc1 libsystem_pthread.dylib`pthread_kill + 432
    frame #2: 0x00007fff668c8a1c libsystem_c.dylib`abort + 120
    frame #3: 0x0000000100114c4e libbenchmark.1.dylib`benchmark::internal::CallAbortHandler() + 14
    frame #4: 0x0000000100114ba4 libbenchmark.1.dylib`benchmark::internal::CheckHandler::~CheckHandler() + 36
    frame #5: 0x0000000100114b65 libbenchmark.1.dylib`benchmark::internal::CheckHandler::~CheckHandler() + 21
    frame #6: 0x000000010012a9f3 libbenchmark.1.dylib`benchmark::State::PauseTiming() + 115
    frame #7: 0x0000000100001905 diagnostics_test`try_invalid_pause_resume(benchmark::State&) + 21
    frame #8: 0x000000010000199a diagnostics_test`BM_diagnostic_test(benchmark::State&) + 42
    frame #9: 0x0000000100128e11 libbenchmark.1.dylib`benchmark::internal::FunctionBenchmark::Run(benchmark::State&) + 33
    frame #10: 0x0000000100132bac libbenchmark.1.dylib`benchmark::internal::BenchmarkInstance::Run(unsigned long long, int, benchmark::internal::ThreadTimer*, benchmark::internal::ThreadManager*) const + 108
    frame #11: 0x00000001001324a3 libbenchmark.1.dylib`benchmark::internal::(anonymous namespace)::RunInThread(benchmark::internal::BenchmarkInstance const*, unsigned long long, int, benchmark::internal::ThreadManager*) + 99
    frame #12: 0x0000000100131d82 libbenchmark.1.dylib`benchmark::internal::(anonymous namespace)::BenchmarkRunner::DoNIterations() + 562
    frame #13: 0x000000010012db96 libbenchmark.1.dylib`benchmark::internal::(anonymous namespace)::BenchmarkRunner::DoOneRepetition(long long) + 70
    frame #14: 0x000000010012d9b7 libbenchmark.1.dylib`benchmark::internal::(anonymous namespace)::BenchmarkRunner::BenchmarkRunner(benchmark::internal::BenchmarkInstance const&, std::__1::vector<benchmark::BenchmarkReporter::Run, std::__1::allocator<benchmark::BenchmarkReporter::Run> >*) + 391
    frame #15: 0x000000010012d0f5 libbenchmark.1.dylib`benchmark::internal::(anonymous namespace)::BenchmarkRunner::BenchmarkRunner(benchmark::internal::BenchmarkInstance const&, std::__1::vector<benchmark::BenchmarkReporter::Run, std::__1::allocator<benchmark::BenchmarkReporter::Run> >*) + 37
    frame #16: 0x000000010012cf8f libbenchmark.1.dylib`benchmark::internal::RunBenchmark(benchmark::internal::BenchmarkInstance const&, std::__1::vector<benchmark::BenchmarkReporter::Run, std::__1::allocator<benchmark::BenchmarkReporter::Run> >*) + 47
    frame #17: 0x000000010012c758 libbenchmark.1.dylib`benchmark::internal::(anonymous namespace)::RunBenchmarks(std::__1::vector<benchmark::internal::BenchmarkInstance, std::__1::allocator<benchmark::internal::BenchmarkInstance> > const&, benchmark::BenchmarkReporter*, benchmark::BenchmarkReporter*) + 792
    frame #18: 0x000000010012bd19 libbenchmark.1.dylib`benchmark::RunSpecifiedBenchmarks(benchmark::BenchmarkReporter*, benchmark::BenchmarkReporter*) + 1129
    frame #19: 0x000000010012b8ad libbenchmark.1.dylib`benchmark::RunSpecifiedBenchmarks() + 13
    frame #20: 0x0000000100001c1c diagnostics_test`main + 60
    frame #21: 0x00007fff667fa7fd libdyld.dylib`start + 1
    frame #22: 0x00007fff667fa7fd libdyld.dylib`start + 1
```
https://github.com/google/benchmark/blob/0811f1d782455b3c80285bebf934a7045d845ed3/src/CMakeLists.txt#L42

target_link_libraries(benchmark -lpthreads)

NAG Fortran Compiler had the compile flag -pthread in Version < 6.0.
Using a recent version with cmake ends up having -pthread in the linker command, which results in the error:

nagfor 6.2:
"Option error: Unrecognised option -pthread"

Using -lpthreads instead is working fine.

Closed cmake issue: https://gitlab.kitware.com/cmake/cmake/issues/20103#note_670921
I've been using Google benchmark 1.4.1 with Google test 1.8.1 successfully on multiple platforms. I build and install Google test, then build Google benchmark against the installed test.

Since switching to benchmark 1.5.0, this does not work anymore. I get an error that Google test is not found. Here is an excerpt from a build on Ubuntu 18.04 x86_64 with cmake 3.16.0. How can I help to debug this issue?

```
-- Looking for Google Test sources
-- Looking for Google Test sources in /data/Debug/googlebenchmark-release-1.5.0/googletest
CMake Error at CMakeLists.txt:34 (message):
  Did not find Google Test sources! Either pass correct path in
  GOOGLETEST_PATH, or enable ALLOW_DOWNLOADING_GOOGLETEST, or disable
  BENCHMARK_ENABLE_GTEST_TESTS / BENCHMARK_ENABLE_TESTING.

CMake Error at /data/Tools/share/cmake-3.16/Modules/ExternalProject.cmake:1783 (get_property):
  get_property could not find TARGET googletest.  Perhaps it has not yet been
  created.
Call Stack (most recent call first):
  CMakeLists.txt:54 (ExternalProject_Get_Property)


CMake Error at /data/Tools/share/cmake-3.16/Modules/ExternalProject.cmake:1785 (message):
  External project "googletest" has no SOURCE_DIR
Call Stack (most recent call first):
  CMakeLists.txt:54 (ExternalProject_Get_Property)


-- Configuring incomplete, errors occurred!
See also "/data/Debug/googlebenchmark-release-1.5.0-x86_64/third_party/googletest/CMakeFiles/CMakeOutput.log".
CMake Error at cmake/GoogleTest.cmake:13 (message):
  CMake step for googletest failed: 1
Call Stack (most recent call first):
  CMakeLists.txt:273 (include)

-- Configuring incomplete, errors occurred!
```
I am facing a build error with PyTorch with a custom path installed gcc (6.1.0). The build command fails at

```
CMake Error at third_party/benchmark/CMakeLists.txt:231 (message):
  Failed to determine the source files for the regular expression backend
```
and that is

```
# C++ feature checks
# Determine the correct regular expression engine to use
cxx_feature_check(STD_REGEX)
cxx_feature_check(GNU_POSIX_REGEX)
cxx_feature_check(POSIX_REGEX)
if(NOT HAVE_STD_REGEX AND NOT HAVE_GNU_POSIX_REGEX AND NOT HAVE_POSIX_REGEX)
  message(FATAL_ERROR "Failed to determine the source files for the regular expression backend")
endif()
```
However, it seems that there is not verbosity for [cxx checks](https://github.com/google/benchmark/blob/505be96ab23056580a3a2315abba048f4428b04e/cmake/CXXFeatureCheck.cmake).
Is there any idea on how to narrow the problem?

I'm trying the new environment variable support but environment variables seem to be ignored. 
```
$ ./build-test/debug/arrow-bit-util-benchmark --benchmark_filter=xxx
Failed to match any benchmarks against regex: xxx
$ BENCHMARK_FILTER=xxx ./build-test/debug/arrow-bit-util-benchmark 
[...]
-------------------------------------------------------------------------------------------------
Benchmark                                       Time             CPU   Iterations UserCounters...
-------------------------------------------------------------------------------------------------
BitmapReader/8192                         1184368 ns      1184102 ns          591 bytes_per_second=13.1957M/s
[etc.]
```

I'm using changeset 367119482ff4abc3d73e4a109b410090fc281337.


I'd like to use this library for micro-benchmarks but I am concerned about the possibility of this library taking on a dependency on Abseil, like Google Test is doing soon. On the Abseil website, i[t is mentioned](https://abseil.io/about/philosophy#compatibility-with-google-oss-projects) that many Google OSS projects will be incorporating Abseil. Is Google Benchmark planning on adding Abseil soon?
Currently, the number of iterations is determined dynamically, like 
"Concretely, the number of iterations is at least one, not more than 1e9, until CPU time is greater than the minimum time, or the wallclock time is 5x minimum time. The minimum time is set per benchmark by calling MinTime on the registered benchmark object."

A method to specify our own MinIterations and MaxIterations would be really helpful
1.) I added 2 tests with assembly check into donotoptimize_assembly_test.cc.
2.) I tested successfully with g++ 9.2 and clang++9 on my machine.
3.) Using Intel C++ (ICC) 19.0.5.281 20190815, the current master as this branch fails:
	 63 - run_donotoptimize_assembly_test_CHECK (Failed)
	 64 - run_state_assembly_test_CHECK (Failed)
	 65 - run_clobber_memory_assembly_test_CHECK (Failed)

... to also allow registers to be covered.
Corresponding Issue: https://github.com/google/benchmark/issues/903
GCC discussion:  https://gcc.gnu.org/bugzilla/show_bug.cgi?id=92597