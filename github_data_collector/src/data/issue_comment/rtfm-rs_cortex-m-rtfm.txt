
Mainly for use with task callbacks, see: https://github.com/rtfm-rs/cortex-m-rtfm/issues/247#issuecomment-571972834
Following up from the discussion on matrix about the stability of the `resources` module generated by the app macro, what would be the implications of making the  app generated `resources` public?

Issue that provoked this question: https://gist.github.com/MabezDev/ecbf8546fc59a55ea404513be15868e3

Maxtrix discussion
```
japaric: so no, you can't avoid the generic type in a generic enum (or struct), but it's OK to use the resources::$ResourceName type

japaric: RTFM guarantees that it's a stable type name / path
```

cc: @japaric 
When adding a comment to the app macro as such:

```rust
/// Some text <- this causes the error
#[app(device = stm32f4xx_hal::stm32, peripherals = true)]
const APP: () = {
    #[init]
    fn init(cx: init::Context) {}
};
```

Gives the error:

```
error: expected `const`

error: aborting due to previous error
```


I see from https://github.com/rtfm-rs/cortex-m-rtfm/issues/207 that right now you deliberately can't bind to HardFault for soundedness reasons. However, it would be really useful to have access to Resources during fault handling to force a system into a safe state or emit some terminal diagnostics. Right now I instead have to have a separate HardFault handler which uses unsafe access to peripherals directly, which is also inconvenient for HALs.

Is there anything to be done here? Or is the fact that the HardFault can occur in the middle of any other task enough to make it always unsound, even though it's itself divergent?
**The issue**

Coming from an FreeRTOS background, I am used to being able to pass Queue and task handles around such that none of the tasks need to know of the other tasks existance. I'd like to be able to do the same thing with RTFM.

**An example scenario:**

A Task offloads a HttpRequest to the HttpClient task by enqueing the request onto a queue that the HttpClient Task is listening to. The client performs the request but how does it pass the result back? The result could be a simple message to say it completed, or it could actually have data to return.

One option is having a queue on the Callee task that the client task can push the result onto, but how do we communicate to the client task which queue to send it back to?

I don't really have any strong thoughts on how to solve this (bar hardcoding values, which I am doing currently). I'm guessing there would be some sort of tagging system such that a tag or handle can resolve to a resource in a safe way.



- [ ] make book point to the latest release
- [ ] ???
- [x] move repos from japaric/ to rtfm-rs/
- [x] add CONTRIBUTING.md to this repo indicating that the rfcs repo is for RFCs and new features should be discussed there before opening a PR here
- [x] rtfm-rs README needs updating
- [x] the README in this repo (and thus the book) should point to the rfcs repository
- [x] the README in this repo (and thus the book) should point to the matrix channel
- [ ] add issue template indicating that this repo is for bug reports and that features should be discussed in the rfcs repository
- [x] get gh-pages working again (@japaric)  #234 
- [x] update Cargo.toml metadata in all repos to point to rtfm-rs/* URLs
 - [x] migrate feature related issues from this repo to the rfcs repo
the API / semantics are specified in RFCs in #204 and #211 and were implemented in #205 but we are still missing user level documentation.
This adds Instant.wrapping_duration_since for the case that some result is desired but the overhead of managing overflows is too big. Especially when handling it seems as complicated as adding 64bit support to Instant.

I also added a wrapping_elapsed but one could argue that elapsed has a bug and should be replaced with the wrapping version.

```rust
// pseudocodeish
init() {
  block((u32::max_value()/2).cycles());
  let t1 = Instant::new(); // t1 = i32::min_value() + 1
  block((u32::max_value()/2).cycles() + 10);
  t1.elapsed() // Instant::new() = t2 = 10
  // t1 - t2 = overflow = panic in debug build
}
```

While writing this i had an idea how to implement a 64bit timer.
```rust
struct BigInstant(u64);
static mut last_tick: Instant = Insant::new();
static mut total_ticks: BigInstant = BigInstant::new()
/// this must be executed before Instant overflows
fn BigInstant::tick() {
  let now = Instant::new();
  total_ticks += now.wrapping_sub(last_tick);
  last_tick = now;
}
fn BigInstant::now() -> BigInstant {
  total_ticks + Instant::new().wrapping_sub(last_tick)
}
```
while this snippet ignored atomicity/locking the general idea should be workable and avoids the need for a max priority interrupt to increment the high bits on overflow.
