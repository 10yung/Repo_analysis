
请问 https://github.com/Angel-ML/angel/blob/master/docs/overview/architecture.md 这个图是用什么画的？
Could not complete /tmp/hadoop-yarn/angel/.staging/application_1578635032972_0005/libjars/all-1.1.2.pom retrying...
`<property>
    <name>angel.job.libjars</name>
    <value>${ANGEL_HOME}/lib/angel-math-0.1.1.jar,${ANGEL_HOME}/lib/angel-format-0.1.1.jar,${ANGEL_HOME}/lib/angel-mlcore-0.1.1.jar,${ANGEL_HOME}/lib/jniloader-1.1.jar,${ANGEL_HOME}/lib/native_system-java-1.1.jar,${ANGEL_HOME}/lib/arpack_combined_all-0.1.jar,${ANGEL_HOME}/lib/all-1.1.2.pom,${ANGEL_HOME}/lib/core-1.1.2.jar,${ANGEL_HOME}/lib/netlib-native_ref-linux-armhf-1.1-natives.jar,${ANGEL_HOME}/lib/netlib-native_ref-linux-i686-1.1-natives.jar,${ANGEL_HOME}/lib/netlib-native_ref-linux-x86_64-1.1-natives.jar,${ANGEL_HOME}/lib/netlib-native_system-linux-armhf-1.1-natives.jar,${ANGEL_HOME}/lib/netlib-native_system-linux-i686-1.1-natives.jar,${ANGEL_HOME}/lib/netlib-native_system-linux-x86_64-1.1-natives.jar,${ANGEL_HOME}/lib/jackson-annotations-2.6.5.jar,${ANGEL_HOME}/lib/jackson-core-2.7.7.jar,${ANGEL_HOME}/lib/jackson-core-asl-1.9.13.jar,${ANGEL_HOME}/lib/jackson-databind-2.7.7.jar,${ANGEL_HOME}/lib/jackson-jaxrs-1.9.13.jar,${ANGEL_HOME}/lib/jackson-mapper-asl-1.9.13.jar,${ANGEL_HOME}/lib/jackson-module-paranamer-2.6.5.jar,${ANGEL_HOME}/lib/jackson-module-scala_2.11-2.6.5.jar,${ANGEL_HOME}/lib/jackson-xc-1.9.13.jar,${ANGEL_HOME}/lib/json4s-ast_2.11-3.2.11.jar,${ANGEL_HOME}/lib/json4s-core_2.11-3.2.11.jar,${ANGEL_HOME}/lib/json4s-jackson_2.11-3.2.11.jar,${ANGEL_HOME}/lib/netty-all-4.1.17.Final.jar,${ANGEL_HOME}/lib/angel-ps-mllib-${ANGEL_VERSION}.jar,${ANGEL_HOME}/lib/angel-ps-tools-${ANGEL_VERSION}.jar,${ANGEL_HOME}/lib/scala-reflect-2.11.8.jar,${ANGEL_HOME}/lib/memory-0.8.1.jar,${ANGEL_HOME}/lib/sketches-core-0.8.1.jar,${ANGEL_HOME}/lib/commons-pool-1.6.jar,${ANGEL_HOME}/lib/kryo-shaded-4.0.0.jar,${ANGEL_HOME}/lib/kryo-serializers-0.42.jar,${ANGEL_HOME}/lib/scala-library-2.11.8.jar,${ANGEL_HOME}/lib/angel-ps-core-${ANGEL_VERSION}.jar,${ANGEL_HOME}/lib/angel-ps-psf-${ANGEL_VERSION}.jar,${ANGEL_HOME}/lib/fastutil-7.1.0.jar,${ANGEL_HOME}/lib/sizeof-0.3.0.jar,${ANGEL_HOME}/lib/minlog-1.3.0.jar,${ANGEL_HOME}/lib/breeze_2.11-0.13.jar,${ANGEL_HOME}/lib/angel-format-0.1.1.jar,${ANGEL_HOME}/lib/angel-math-0.1.1.jar,${ANGEL_HOME}/lib/angel-mlcore-0.1.1.jar,${ANGEL_HOME}/lib/commons-math-2.2.jar</value>
  </property>`
sona0.1.0
angel3.0.1

If my train data has not 13 number of features, will have error below:
error log:
```
20/01/04 21:03:06 ERROR MatrixTransportClient: serialize request PutPartitionUpdateRequest [taskIndex=-1, rowsSplit size=0, updateClock=false, toString()=PartitionRequest{clock=-1, partKey=PartitionKey(matrixId=2, partitionId=4, startRow=0, startCol=8320, endRow=3, endCol=10400)indexNum=-1), comeFromPs=false} com.tencent.angel.ps.server.data.request.UpdateRequest@24] failed 
java.lang.ArrayIndexOutOfBoundsException: 8320
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serializeIntDoubleRow(RowsViewUpdateItem.java:822)
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serializeRow(RowsViewUpdateItem.java:499)
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serialize(RowsViewUpdateItem.java:70)
	at com.tencent.angel.ps.server.data.request.UpdateRequest.serialize(UpdateRequest.java:127)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient.serializeRequest(MatrixTransportClient.java:2150)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient.access$3300(MatrixTransportClient.java:123)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient$Requester.sendRequest(MatrixTransportClient.java:2033)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient$Requester.run(MatrixTransportClient.java:1943)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/01/04 21:03:06 ERROR MatrixTransportClient: serialize request PutPartitionUpdateRequest [taskIndex=-1, rowsSplit size=0, updateClock=false, toString()=PartitionRequest{clock=-1, partKey=PartitionKey(matrixId=2, partitionId=2, startRow=0, startCol=4160, endRow=3, endCol=6240)indexNum=-1), comeFromPs=false} com.tencent.angel.ps.server.data.request.UpdateRequest@22] failed 
java.lang.ArrayIndexOutOfBoundsException: 5600
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serializeIntDoubleRow(RowsViewUpdateItem.java:822)
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serializeRow(RowsViewUpdateItem.java:499)
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serialize(RowsViewUpdateItem.java:70)
	at com.tencent.angel.ps.server.data.request.UpdateRequest.serialize(UpdateRequest.java:127)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient.serializeRequest(MatrixTransportClient.java:2150)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient.access$3300(MatrixTransportClient.java:123)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient$Requester.sendRequest(MatrixTransportClient.java:2033)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient$Requester.run(MatrixTransportClient.java:1943)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/01/04 21:03:06 ERROR MatrixTransportClient: serialize request PutPartitionUpdateRequest [taskIndex=-1, rowsSplit size=0, updateClock=false, toString()=PartitionRequest{clock=-1, partKey=PartitionKey(matrixId=2, partitionId=3, startRow=0, startCol=6240, endRow=3, endCol=8320)indexNum=-1), comeFromPs=false} com.tencent.angel.ps.server.data.request.UpdateRequest@23] failed 
java.lang.ArrayIndexOutOfBoundsException: 6240
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serializeIntDoubleRow(RowsViewUpdateItem.java:822)
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serializeRow(RowsViewUpdateItem.java:499)
	at com.tencent.angel.psagent.matrix.transport.adapter.RowsViewUpdateItem.serialize(RowsViewUpdateItem.java:70)
	at com.tencent.angel.ps.server.data.request.UpdateRequest.serialize(UpdateRequest.java:127)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient.serializeRequest(MatrixTransportClient.java:2150)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient.access$3300(MatrixTransportClient.java:123)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient$Requester.sendRequest(MatrixTransportClient.java:2033)
	at com.tencent.angel.psagent.matrix.transport.MatrixTransportClient$Requester.run(MatrixTransportClient.java:1943)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
```
my daw.json:
```
{
  "data": {
    "format": "libsvm",
    "indexrange": 1111,
    "numfield": 7,
    "validateratio": 0.1
  },
  "model": {
    "modeltype": "T_DOUBLE_SPARSE_LONGKEY",
    "modelsize": 1111
  },
  "train": {
    "epoch": 10,
    "numupdateperepoch": 10,
    "lr": 0.1,
    "decay": 0.8
  },
  "default_optimizer": {
    "type": "momentum",
    "momentum": 0.9,
    "reg2": 0.01
  },
  "layers": [
    {
      "name": "wide",
      "type": "simpleinputlayer",
      "outputdim": 1,
      "transfunc": "identity"
    },
    {
      "name": "embedding",
      "type": "embedding",
      "numfactors": 8,
      "outputdim": 104
    },
    {
      "name": "fclayer",
      "type": "FCLayer",
      "inputlayer": "embedding",
      "outputdims": [
        100,
        100,
        1
      ],
      "transfuncs": [
        "relu",
        "relu",
        "identity"
      ]
    },
    {
      "name": "sumPooling",
      "type": "SumPooling",
      "outputdim": 1,
      "inputlayers": [
        "wide",
        "fclayer"
      ]
    },
    {
      "name": "simplelosslayer",
      "type": "simplelosslayer",
      "lossfunc": "logloss",
      "inputlayer": "sumPooling"
    }
  ]
}
```
my train data like:
```
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 35:1.0 1104:1.0 1108:1.0
```

sona0.1.0
Angel3.0.1

error log：
```
20/01/03 16:45:26 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 4, bj6-p-gryai-graph-spark03.ps.wps.cn, executor 1): java.lang.ArrayIndexOutOfBoundsException: 13
	at com.tencent.angel.mlcore.network.layers.Layer$$anonfun$gatherGradInput$1$$anonfun$apply$2$$anonfun$apply$mcVI$sp$2.apply(Layer.scala:134)
	at com.tencent.angel.mlcore.network.layers.Layer$$anonfun$gatherGradInput$1$$anonfun$apply$2$$anonfun$apply$mcVI$sp$2.apply(Layer.scala:133)
	at scala.collection.immutable.Range.foreach(Range.scala:160)
	at com.tencent.angel.mlcore.network.layers.Layer$$anonfun$gatherGradInput$1$$anonfun$apply$2.apply$mcVI$sp(Layer.scala:133)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at com.tencent.angel.mlcore.network.layers.Layer$$anonfun$gatherGradInput$1.apply(Layer.scala:129)
	at com.tencent.angel.mlcore.network.layers.Layer$$anonfun$gatherGradInput$1.apply(Layer.scala:111)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at com.tencent.angel.mlcore.network.layers.Layer.gatherGradInput(Layer.scala:111)
	at com.tencent.angel.mlcore.network.layers.InputLayer.backward(InputLayer.scala:43)
	at com.tencent.angel.mlcore.network.Graph$$anonfun$calBackward$1.apply(Graph.scala:160)
	at com.tencent.angel.mlcore.network.Graph$$anonfun$calBackward$1.apply(Graph.scala:160)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35)
	at scala.collection.mutable.ListBuffer.foreach(ListBuffer.scala:45)
	at com.tencent.angel.mlcore.network.Graph.calBackward(Graph.scala:160)
	at com.tencent.angel.sona.ml.common.Trainer.trainOneBatch(Trainer.scala:67)
	at com.tencent.angel.sona.ml.classification.AngelClassifier$$anonfun$train$1$$anonfun$apply$mcVI$sp$1$$anonfun$8.apply(AngelClassifier.scala:246)
	at com.tencent.angel.sona.ml.classification.AngelClassifier$$anonfun$train$1$$anonfun$apply$mcVI$sp$1$$anonfun$8.apply(AngelClassifier.scala:246)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$14.apply(RDD.scala:1021)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$14.apply(RDD.scala:1019)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2130)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2130)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
```
deepfm.json
```
{
  "data": {
    "format": "libsvm",
    "indexrange": 2218,
    "numfield": 13,
    "validateratio": 0.1,
    "sampleratio": 0.2
  },
  "model": {
    "modeltype": "T_DOUBLE_SPARSE_LONGKEY",
    "modelsize": 2218
  },
  "train": {
    "epoch": 5,
    "numupdateperepoch": 5,
    "lr": 0.5,
    "decayclass": "StandardDecay",
    "decayalpha": 0.01
  },
  "default_optimizer": "Momentum",
  "layers": [
    {
      "name": "wide",
      "type": "simpleinputlayer",
      "outputdim": 1,
      "transfunc": "identity"
    },
    {
      "name": "embedding",
      "type": "embedding",
      "numfactors": 8,
      "outputdim": 109,
      "optimizer": {
        "type": "momentum",
        "momentum": 0.9,
        "reg2": 0.01
      }
    },
    {
      "name": "fclayer",
      "type": "FCLayer",
      "outputdims": [
        100,
        100,
        1
      ],
      "transfuncs": [
        "relu",
        "relu",
        "identity"
      ],
      "inputlayer": "embedding"
    },
    {
      "name": "biinnersumcross",
      "type": "BiInnerSumCross",
      "inputlayer": "embedding",
      "outputdim": 1
    },
    {
      "name": "sumPooling",
      "type": "SumPooling",
      "outputdim": 1,
      "inputlayers": [
        "wide",
        "biinnersumcross",
        "fclayer"
      ]
    },
    {
      "name": "simplelosslayer",
      "type": "simplelosslayer",
      "lossfunc": "logloss",
      "inputlayer": "sumPooling"
    }
  ]
}
```
train data e.g.
```
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 535:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1650:1.0
1.0 1:1.0 6:1.0 14:1.0 19:1.0 198:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1313:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 198:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1313:1.0
-1.0 1:1.0 8:1.0 16:1.0 19:1.0 703:1.0 1105:1.0 1109:1.0 1114:1.0 1122:1.0 1125:1.0 1129:1.0 1134:1.0 1818:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 198:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1313:1.0
-1.0 3:1.0 7:1.0 13:1.0 19:1.0 728:1.0 1107:1.0 1110:1.0 1116:1.0 1119:1.0 1127:1.0 1130:1.0 1134:1.0 1843:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 957:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 2072:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 760:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1875:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 691:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1806:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 789:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1904:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 484:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1599:1.0
-1.0 3:1.0 7:1.0 13:1.0 19:1.0 882:1.0 1107:1.0 1110:1.0 1116:1.0 1119:1.0 1127:1.0 1130:1.0 1134:1.0 1997:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 762:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1877:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 469:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1584:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 1085:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 2200:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 198:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1313:1.0
-1.0 1:1.0 8:1.0 16:1.0 19:1.0 894:1.0 1105:1.0 1109:1.0 1114:1.0 1122:1.0 1125:1.0 1129:1.0 1134:1.0 2009:1.0
-1.0 1:1.0 8:1.0 16:1.0 19:1.0 513:1.0 1105:1.0 1109:1.0 1114:1.0 1122:1.0 1125:1.0 1129:1.0 1134:1.0 1628:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 883:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1998:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 285:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1400:1.0
-1.0 2:1.0 8:1.0 15:1.0 19:1.0 490:1.0 1106:1.0 1109:1.0 1115:1.0 1121:1.0 1126:1.0 1129:1.0 1134:1.0 1605:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 285:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1400:1.0
-1.0 2:1.0 7:1.0 13:1.0 19:1.0 705:1.0 1106:1.0 1109:1.0 1115:1.0 1119:1.0 1126:1.0 1129:1.0 1134:1.0 1820:1.0
-1.0 2:1.0 7:1.0 13:1.0 19:1.0 1025:1.0 1106:1.0 1109:1.0 1115:1.0 1119:1.0 1126:1.0 1129:1.0 1134:1.0 2140:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 33:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1148:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 33:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1148:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 33:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1148:1.0
1.0 1:1.0 6:1.0 14:1.0 19:1.0 33:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1148:1.0
-1.0 1:1.0 6:1.0 14:1.0 19:1.0 33:1.0 1105:1.0 1109:1.0 1114:1.0 1120:1.0 1125:1.0 1129:1.0 1134:1.0 1148:1.0
```




how to define java8 when submit application use spark-submit


---
name: Bug report/Feature request/Question
about: Create a report to help us improve
title: ''
label: bug/enhancement/question
assignees: ''
---

**Environment**:
- Java version:
- Scala version:
- Spark version:
- PyTorch and Python version:
- OS and version:


**Checklist**:
- Did you check if your bug/feature/question is answered in the FQA ?
- Did you search issues to find if somebody discuss your bug/feature/question before?
- If your bug/question is about install, did you read [this doc](../docs/deploy/source_compile_en.md)?
- If your bug/question is about parameter setting, did you read [this doc](../docs/deploy/config_details_en.md)?


**Your Bug/Feature request/Question**: Please describe bug/enhancement/question in detail. 
- For bugs, please post the submit *commands*, *error report logs* and related *code snippet* 
- For feature requests, please describe what's you scenario and why you need this feature. if you required feature is big please connect us email list.




Angel 3.0.1，运行DeepFM的demo（13列）正常运行，换成自己的数据集（14列）就报错，把自己数据集的最后一列删除，对齐到13列就能运行。
报错如下：
```
2020-01-02 10:02:04,800 INFO [main] com.tencent.angel.worker.Worker: angel.cluster.local.dir for child: /data2/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765,/data3/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765,/data4/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765,/data5/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765,/data6/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765,/data7/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765,/data8/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765,/data9/yarn/local/usercache/deepthought/appcache/application_1576380960005_3960765
2020-01-02 10:02:04,802 INFO [main] com.tencent.angel.worker.Worker: actual workergroup number:1
2020-01-02 10:02:04,802 INFO [main] com.tencent.angel.worker.Worker: actual task number:1
2020-01-02 10:02:04,859 INFO [main] com.tencent.angel.worker.Worker: Init and start worker
2020-01-02 10:02:04,862 INFO [main] com.tencent.angel.worker.Worker: Init and start psagent for worker
2020-01-02 10:02:05,568 INFO [main] com.tencent.angel.psagent.PSAgent: PSAgent get matrices from master,9
2020-01-02 10:02:05,612 INFO [main] com.tencent.angel.psagent.matrix.transport.MatrixTransportClient: Use nio channel
2020-01-02 10:02:05,654 INFO [main] com.tencent.angel.psagent.matrix.transport.MatrixTransportClient: ByteOrder.nativeOrder()=LITTLE_ENDIAN
2020-01-02 10:02:05,660 INFO [main] com.tencent.angel.worker.Worker: Init data block manager
2020-01-02 10:02:05,660 INFO [main] com.tencent.angel.worker.Worker: Init and start worker rpc server
2020-01-02 10:02:05,686 WARN [main] io.netty.bootstrap.ServerBootstrap: Unknown channel option 'TCP_NODELAY' for channel '[id: 0xd07fcd06]'
2020-01-02 10:02:05,687 WARN [main] io.netty.bootstrap.ServerBootstrap: Unknown channel option 'SO_KEEPALIVE' for channel '[id: 0xd07fcd06]'
2020-01-02 10:02:05,691 INFO [main] com.tencent.angel.worker.WorkerService: Starting workerserver service at 10.19.73.14:23030
2020-01-02 10:02:05,691 INFO [main] com.tencent.angel.worker.Worker: Init counter updater
2020-01-02 10:02:05,802 INFO [main] com.tencent.angel.psagent.CounterUpdater:  Using ResourceCalculatorProcessTree : [ 16173 15775 ]
2020-01-02 10:02:05,802 INFO [main] com.tencent.angel.worker.Worker: Register to master and start the heartbeat thread
2020-01-02 10:02:05,802 INFO [main] com.tencent.angel.worker.Worker: Get data splits from master
2020-01-02 10:02:05,803 INFO [Worker Heartbeat] com.tencent.angel.worker.Worker: Register to master
2020-01-02 10:02:05,830 INFO [Worker Heartbeat] com.tencent.angel.worker.Worker: worker register finished!
2020-01-02 10:02:06,984 INFO [main] com.tencent.angel.worker.Worker: Init and start task manager and all task
2020-01-02 10:02:06,984 INFO [main] com.tencent.angel.worker.task.TaskManager: start all tasks
2020-01-02 10:02:06,985 INFO [main] com.tencent.angel.worker.task.TaskManager: start task task_0 with context=TaskContext [taskId=task_0, taskIdProto=taskIndex: 0
, context=com.tencent.angel.psagent.task.TaskContext@5adb0db3TaskContext [index=0, matrix clocks=]]
2020-01-02 10:02:06,986 INFO [pool-5-thread-1] com.tencent.angel.worker.task.Task: task task_0 is running.
2020-01-02 10:02:06,996 INFO [pool-5-thread-1] com.tencent.angel.worker.task.Task: userTaskClass = class com.tencent.angel.ml.core.graphsubmit.GraphTrainTask task index = 0, name = Thread-28
2020-01-02 10:02:07,494 WARN [pool-5-thread-1] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-02 10:02:08,479 WARN [pool-5-thread-1] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
2020-01-02 10:02:08,569 WARN [pool-5-thread-1] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:deepthought (auth:KERBEROS) cause:org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error
2020-01-02 10:02:08,573 WARN [pool-5-thread-1] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error
2020-01-02 10:02:08,573 WARN [pool-5-thread-1] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:deepthought (auth:KERBEROS) cause:org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error
2020-01-02 10:02:08,755 INFO [pool-5-thread-1] com.hadoop.compression.lzo.GPLNativeCodeLoader: Loaded native gpl library
2020-01-02 10:02:08,761 INFO [pool-5-thread-1] com.hadoop.compression.lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev null]
2020-01-02 10:02:09,179 INFO [pool-5-thread-1] com.tencent.angel.ml.core.graphsubmit.GraphTrainTask: Task[0] preprocessed 40 samples, 36 for train, 4 for validation. processing time is 1850
2020-01-02 10:02:09,307 INFO [pool-5-thread-1] com.tencent.angel.ml.core.graphsubmit.GraphLearner: Task[0]: Starting to train ...
2020-01-02 10:02:09,307 INFO [pool-5-thread-1] com.tencent.angel.ml.core.graphsubmit.GraphLearner: Task[0]: epoch=10, initLearnRate=0.001
2020-01-02 10:02:09,723 INFO [pool-5-thread-1] com.tencent.angel.ml.core.graphsubmit.GraphLearner: Task[0]: epoch=0 start.
2020-01-02 10:02:09,973 WARN [pool-5-thread-1] com.tencent.angel.ml.math2.MatrixExecutors: angel.math.matrix.op.parallel.worker.num is not set, just use default worker number:48
2020-01-02 10:02:09,987 ERROR [pool-5-thread-1] com.tencent.angel.worker.task.Task: task runner error 
java.lang.Error: java.lang.Error
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:593)
	at java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:677)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:720)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.applyParallel(DotMatrixExecutor.java:790)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.apply(DotMatrixExecutor.java:610)
	at com.tencent.angel.ml.math2.ufuncs.Ufuncs.dot(Ufuncs.java:838)
	at com.tencent.angel.mlcore.network.layers.unary.FCLayer.doForward(FCLayer.scala:72)
	at com.tencent.angel.mlcore.network.layers.LinearLayer.forward(LinearLayer.scala:36)
	at com.tencent.angel.mlcore.network.layers.LinearLayer.forward(LinearLayer.scala:36)
	at com.tencent.angel.mlcore.network.layers.LinearLayer.forward(LinearLayer.scala:36)
	at com.tencent.angel.mlcore.network.layers.JoinLayer$$anonfun$2.apply(JoinLayer.scala:47)
	at com.tencent.angel.mlcore.network.layers.JoinLayer$$anonfun$2.apply(JoinLayer.scala:38)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at com.tencent.angel.mlcore.network.layers.JoinLayer.forward(JoinLayer.scala:38)
	at com.tencent.angel.mlcore.network.layers.LossLayer.forward(LossLayer.scala:62)
	at com.tencent.angel.mlcore.network.layers.LossLayer.calLoss(LossLayer.scala:55)
	at com.tencent.angel.mlcore.network.Graph.calForward(Graph.scala:149)
	at com.tencent.angel.ml.core.graphsubmit.GraphLearner.trainOneEpoch(GraphLearner.scala:70)
	at com.tencent.angel.ml.core.graphsubmit.GraphLearner.train(GraphLearner.scala:167)
	at com.tencent.angel.ml.core.graphsubmit.GraphLearner.train(GraphLearner.scala:109)
	at com.tencent.angel.ml.core.graphsubmit.GraphTrainTask.train(GraphTrainTask.scala:48)
	at com.tencent.angel.ml.core.TrainTask.run(TrainTask.scala:45)
	at com.tencent.angel.worker.task.Task.runUser(Task.java:92)
	at com.tencent.angel.worker.task.Task.run(Task.java:68)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.Error
	at org.j_paine.formatter.FormatParser.<init>(FormatParser.java:353)
	at org.j_paine.formatter.FormatParser.<init>(FormatParser.java:346)
	at org.j_paine.formatter.Parsers.<init>(Formatter.java:1748)
	at org.j_paine.formatter.Parsers.theParsers(Formatter.java:1739)
	at org.j_paine.formatter.Format.<init>(Formatter.java:177)
	at org.j_paine.formatter.Formatter.<init>(Formatter.java:30)
	at org.netlib.util.Util.f77write(Util.java:429)
	at org.netlib.err.Xerbla.xerbla(err.f)
	at org.netlib.blas.Dgemm.dgemm(blas.f)
	at com.github.fommil.netlib.F2jBLAS.dgemm(F2jBLAS.java:91)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.apply(DotMatrixExecutor.java:812)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.access$000(DotMatrixExecutor.java:55)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor$DotForkJoinOp.compute(DotMatrixExecutor.java:1752)
	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invokeAll(ForkJoinTask.java:759)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor$DotForkJoinOp.compute(DotMatrixExecutor.java:1769)
	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invokeAll(ForkJoinTask.java:759)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor$DotForkJoinOp.compute(DotMatrixExecutor.java:1769)
	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
2020-01-02 10:02:10,017 INFO [pool-5-thread-1] com.tencent.angel.worker.Worker: worker failed message : taskid=task_0, state=FAILED, diagnostics=[task runner error: java.lang.Error: java.lang.Error
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:593)
	at java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:677)
	at java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:720)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.applyParallel(DotMatrixExecutor.java:790)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.apply(DotMatrixExecutor.java:610)
	at com.tencent.angel.ml.math2.ufuncs.Ufuncs.dot(Ufuncs.java:838)
	at com.tencent.angel.mlcore.network.layers.unary.FCLayer.doForward(FCLayer.scala:72)
	at com.tencent.angel.mlcore.network.layers.LinearLayer.forward(LinearLayer.scala:36)
	at com.tencent.angel.mlcore.network.layers.LinearLayer.forward(LinearLayer.scala:36)
	at com.tencent.angel.mlcore.network.layers.LinearLayer.forward(LinearLayer.scala:36)
	at com.tencent.angel.mlcore.network.layers.JoinLayer$$anonfun$2.apply(JoinLayer.scala:47)
	at com.tencent.angel.mlcore.network.layers.JoinLayer$$anonfun$2.apply(JoinLayer.scala:38)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at com.tencent.angel.mlcore.network.layers.JoinLayer.forward(JoinLayer.scala:38)
	at com.tencent.angel.mlcore.network.layers.LossLayer.forward(LossLayer.scala:62)
	at com.tencent.angel.mlcore.network.layers.LossLayer.calLoss(LossLayer.scala:55)
	at com.tencent.angel.mlcore.network.Graph.calForward(Graph.scala:149)
	at com.tencent.angel.ml.core.graphsubmit.GraphLearner.trainOneEpoch(GraphLearner.scala:70)
	at com.tencent.angel.ml.core.graphsubmit.GraphLearner.train(GraphLearner.scala:167)
	at com.tencent.angel.ml.core.graphsubmit.GraphLearner.train(GraphLearner.scala:109)
	at com.tencent.angel.ml.core.graphsubmit.GraphTrainTask.train(GraphTrainTask.scala:48)
	at com.tencent.angel.ml.core.TrainTask.run(TrainTask.scala:45)
	at com.tencent.angel.worker.task.Task.runUser(Task.java:92)
	at com.tencent.angel.worker.task.Task.run(Task.java:68)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.Error
	at org.j_paine.formatter.FormatParser.<init>(FormatParser.java:353)
	at org.j_paine.formatter.FormatParser.<init>(FormatParser.java:346)
	at org.j_paine.formatter.Parsers.<init>(Formatter.java:1748)
	at org.j_paine.formatter.Parsers.theParsers(Formatter.java:1739)
	at org.j_paine.formatter.Format.<init>(Formatter.java:177)
	at org.j_paine.formatter.Formatter.<init>(Formatter.java:30)
	at org.netlib.util.Util.f77write(Util.java:429)
	at org.netlib.err.Xerbla.xerbla(err.f)
	at org.netlib.blas.Dgemm.dgemm(blas.f)
	at com.github.fommil.netlib.F2jBLAS.dgemm(F2jBLAS.java:91)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.apply(DotMatrixExecutor.java:812)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor.access$000(DotMatrixExecutor.java:55)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor$DotForkJoinOp.compute(DotMatrixExecutor.java:1752)
	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invokeAll(ForkJoinTask.java:759)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor$DotForkJoinOp.compute(DotMatrixExecutor.java:1769)
	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invokeAll(ForkJoinTask.java:759)
	at com.tencent.angel.ml.math2.ufuncs.executor.matrix.DotMatrixExecutor$DotForkJoinOp.compute(DotMatrixExecutor.java:1769)
	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
], send it to appmaster success
2020-01-02 10:02:10,017 INFO [pool-5-thread-1] com.tencent.angel.worker.Worker: start to close all modules in worker
2020-01-02 10:02:10,017 INFO [pool-5-thread-1] com.tencent.angel.worker.Worker: stop workerService
2020-01-02 10:02:10,017 INFO [pool-5-thread-1] com.tencent.angel.worker.WorkerService: stop rpc server
2020-01-02 10:02:10,018 INFO [pool-5-thread-1] com.tencent.angel.ipc.NettyServer: Stopping server on 23030
2020-01-02 10:02:10,045 INFO [pool-5-thread-1] com.tencent.angel.worker.Worker: stop psagent
2020-01-02 10:02:10,045 INFO [pool-5-thread-1] com.tencent.angel.psagent.PSAgent: stop heartbeat thread!
2020-01-02 10:02:10,045 INFO [pool-5-thread-1] com.tencent.angel.psagent.PSAgent: stop op log merger
2020-01-02 10:02:10,046 WARN [oplog-merge-dispatcher] com.tencent.angel.psagent.matrix.oplog.cache.MatrixOpLogCache: oplog-merge-dispatcher interrupted
2020-01-02 10:02:10,046 INFO [pool-5-thread-1] com.tencent.angel.psagent.PSAgent: stop clock cache
2020-01-02 10:02:10,047 INFO [pool-5-thread-1] com.tencent.angel.psagent.PSAgent: stop matrix cache
2020-01-02 10:02:10,047 INFO [clock-syncer] com.tencent.angel.psagent.clock.ClockCache: sync thread is interrupted
2020-01-02 10:02:10,047 INFO [pool-5-thread-1] com.tencent.angel.psagent.PSAgent: stop user request adapater
2020-01-02 10:02:10,048 INFO [pool-5-thread-1] com.tencent.angel.psagent.PSAgent: stop rpc dispacher
2020-01-02 10:02:10,048 INFO [pool-5-thread-1] com.tencent.angel.common.transport.ChannelManager2: Channel manager stop
2020-01-02 10:02:10,093 INFO [pool-5-thread-1] com.tencent.angel.worker.Worker: stop heartbeat thread
2020-01-02 10:02:10,097 INFO [pool-5-thread-1] com.tencent.angel.worker.Worker: stop taskmanager
2020-01-02 10:02:10,097 INFO [pool-5-thread-1] com.tencent.angel.worker.Worker: stop data block manager
```

原数据集如下格式：
```
-1 2 5 17 21 35 39 47 62 70 72 73 75 79 82
-1 4 5 14 20 34 39 49 62 66 72 73 75 79 82
-1 1 5 13 21 35 40 56 63 66 72 73 75 81 82
-1 1 5 15 23 37 41 53 64 66 71 73 75 77 82
-1 4 14 24 37 40 65 66 71 73 75 77 78 79 80
-1 1 5 16 30 34 39 56 62 66 72 73 75 79 82
-1 0 5 16 19 36 41 54 61 66 72 73 75 79 82
-1 1 5 17 21 35 39 53 60 66 71 73 75 79 82
-1 1 5 14 21 35 42 49 65 66 71 73 75 78 82
1 2 17 18 38 39 60 66 71 73 75 81 82 83 84
-1 1 13 18 38 41 63 67 71 73 75 81 82 83 84
1 2 5 16 31 38 39 51 62 66 72 73 75 81 82
1 4 5 17 18 38 39 50 62 67 72 73 75 81 90
-1 2 5 15 19 36 40 54 65 66 71 73 75 78 82
-1 0 5 17 27 34 41 58 61 70 72 73 75 78 82
1 2 5 15 18 38 41 50 63 66 71 73 75 81 82
-1 1 5 17 21 35 41 47 63 70 72 73 75 80 82
1 2 5 14 18 38 40 51 65 70 71 74 75 80 82
1 4 17 31 38 39 62 66 72 73 75 77 82 83 84
-1 3 10 16 21 35 42 54 61 66 71 73 75 79 82
-1 3 16 21 35 42 63 70 71 73 75 77 82 83 84
-1 4 14 21 35 39 62 66 72 73 75 77 82 83 84
-1 3 9 14 23 37 40 51 65 66 71 73 75 81 82
-1 1 5 16 28 38 40 48 63 69 71 73 75 77 82
1 2 9 14 23 37 39 54 60 66 71 73 75 77 82
-1 2 5 16 23 37 40 46 63 66 71 73 75 79 82
-1 3 5 17 21 35 39 53 62 66 72 73 75 79 102
-1 4 6 13 22 38 41 51 63 66 72 74 75 81 82
-1 3 10 16 19 36 40 54 64 66 71 73 75 79 82
-1 3 6 13 19 36 39 47 62 66 72 73 75 81 82
-1 1 5 13 30 34 39 52 62 68 72 73 75 79 82
-1 3 5 13 24 37 39 49 62 66 72 73 75 80 82
-1 1 5 14 28 38 41 46 63 67 72 73 75 77 109
1 4 5 17 28 38 39 50 62 66 72 73 75 79 82
-1 0 5 17 19 36 41 58 63 66 72 73 75 79 82
-1 1 5 16 23 37 39 46 60 66 71 73 75 78 82
1 2 5 14 21 35 39 53 62 66 72 73 75 79 82
-1 4 5 14 21 35 43 54 65 66 71 73 75 79 82
-1 0 5 16 21 35 41 54 61 66 72 73 75 77 82
1 4 7 17 21 35 39 50 60 66 71 74 75 79 82
```

json如下：
```
{
  "data": {
    "format": "dummy",
    "indexrange": 110,
    "numfield": -1,
    "useshuffle": true,
    "validateratio": 0.1
  },
  "model": {
    "modeltype": "T_DOUBLE_SPARSE_LONGKEY",
    "modelsize": 110
  },
  "train": {
    "epoch": 10,
    "numupdateperepoch": 10,
    "lr": 0.001,
    "decayclass": "ConstantLearningRate"
  },
  "default_optimizer": "Momentum",
  "layers": [
    {
      "name": "wide",
      "type": "simpleinputlayer",
      "outputdim": 1,
      "transfunc": "identity"
    },
    {
      "name": "embedding",
      "type": "embedding",
      "numfactors": 8,
      "outputdim": 104,
      "optimizer": {
        "type": "momentum",
        "momentum": 0.9,
        "reg2": 0.01
      }
    },
    {
      "name": "fclayer",
      "type": "FCLayer",
      "outputdims": [
        100,
        100,
        1
      ],
      "transfuncs": [
        "relu",
        "relu",
        "identity"
      ],
      "inputlayer": "embedding"
    },
    {
      "name": "biinnersumcross",
      "type": "BiInnerSumCross",
      "inputlayer": "embedding",
      "outputdim": 1
    },
    {
      "name": "sumPooling",
      "type": "SumPooling",
      "outputdim": 1,
      "inputlayers": [
        "wide",
        "biinnersumcross",
        "fclayer"
      ]
    },
    {
      "name": "simplelosslayer",
      "type": "simplelosslayer",
      "lossfunc": "logloss",
      "inputlayer": "sumPooling"
    }
  ]
}
```


![image](https://user-images.githubusercontent.com/50101159/71476254-146ce700-281f-11ea-9073-50e71ac1f5b2.png)

It is 404


Move the scala code into scala fold under the psf sub module.


Angel 3.0.1
training data: 20w cols, 1000w lines, 稀疏矩阵，文件大小23G
提交命令：
```
sh /data/angel/angel-3.0.1/bin/angel-submit \
-Dangel.app.submit.class=com.tencent.angel.ml.GBDT.GBDTRunner \
-Dangel.train.data.path=viewfs://hadoop-bd/user/deepthought/temp/deepthought_test_266_2306_1_0/data/part-00000 \
-Dangel.log.path=viewfs://hadoop-bd/user/deepthought/test/model/m_PSgbdt_266_2325_0/log \
-Dangel.save.model.path=viewfs://hadoop-bd/user/deepthought/test/model/m_PSgbdt_266_2325_0/model \
-Daction.type=train \
-Dml.data.type=dummy \
-Dml.feature.index.range=207512 \
-Dml.model.type=T_FLOAT_DENSE \
-Dml.learn.rate=0.2 \
-Dml.gbdt.task.type=classification \
-Dml.gbdt.class.num=2 \
-Dml.gbdt.tree.num=10 \
-Dml.gbdt.tree.depth=7 \
-Dml.gbdt.split.num=10 \
-Dml.gbdt.sample.ratio=1 \
-Dml.gbdt.min.child.weight=0.01 \
-Dml.gbdt.reg.alpha=0 \
-Dml.gbdt.reg.lambda=1 \
-Dml.gbdt.batch.size=5000 \
-Dml.gbdt.server.split=true \
-Dml.gbdt.cate.feat=none \
-Dml.data.validate.ratio=0.9 \
-Dml.data.label.trans.class=PosNegTrans \
-Dml.data.label.trans.threshold=0.5 \
-Dml.data.posneg.ratio=-1 \
-Dangel.compress.bytes=2 \
-Dangel.job.name=PSgbdt_266_2325_2927 \
-Dangel.workergroup.number=93 \
-Dangel.worker.memory.gb=4 \
-Dangel.worker.cpu.vcores=1 \
-Dangel.worker.task.number=1 \
-Dangel.ps.number=20 \
-Dangel.ps.memory.gb=5 \
-Dangel.ps.cpu.vcores=4 \
-Dangel.task.data.storage.level=memory \
-Dangel.am.cpu.vcores=2 \
-Dangel.am.memory.gb=2 \
-Dangel.output.path.deleteonexist=true
```

yarn日志的syslog见附件
[syslog.log](https://github.com/Angel-ML/angel/files/3943588/syslog.log)
标准输出的日志见附件
[stdout.log](https://github.com/Angel-ML/angel/files/3943599/stdout.log)
