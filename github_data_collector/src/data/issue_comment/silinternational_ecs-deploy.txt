This pull request allows to provide task definition from file (we use task definitions as part of source code in git). It addresses the Issue https://github.com/silinternational/ecs-deploy/issues/176

 It also adds support of built-in "healthCheck" from task definition. If this one specified, it will be used to detect, whether the service is running properly. Not sure if it solves the problem meant by author in https://github.com/silinternational/ecs-deploy/issues/187 , but it works good for me.
I use Terraform for my infrastructure and `ecs-deploy` for deployments and want to be able to deregister failed task definitions so that Terraform does not try to deploy them. My set up currently tries to find the latest task definition for a family and check if it is already deployed and if not, it considers that as something that needs to be done to "fix the state". 
Current code checks only for the number of deployments returned by AWS and flags a success if > 0.
But the task can be boot looping and never reaching steady state. This gives a false SUCCESS message if you consider that a successful deployment is a steady task and not only the deployment.
Hi Team,

Thanks for providing this wonderful script. I have been using your script for continuous deployment using jenkins. I recently moved my jenkins server to docker and configured your script. I am able to run the script at command line and it works without any issues but when configured it as a jenkins job it failed with below error message. Do I'm missing anything here.

ecs-deploy -c Cluster-1 -n service-v1 -i xxxxxx.dkr.ecr.eu-west-1.amazonaws.com/xxx:latest
Using image name: xxxxx.dkr.ecr.us-west-1.amazonaws.com/task-def-v2:latest

Current task definition: arn:aws:ecs:us-west-1:xxxx:task-definition/task-def-v2:7

Parameter validation failed:
Unknown parameter in input: "placementConstraints", must be one of: family, taskRoleArn, networkMode, containerDefinitions, volumes
â€¦d to ecs run-task

Hello guys,

I was thinking about rollback task version when container status is unhealthy after new version deploy.
How about waiting container stay health, to be successful deploy ?

Somebody has that kind of problem?

Maybe i can help to do...

What do you thing?
Ecs-deploy doesn't process '-k' and '-s' correctly. The work around is to define them with environment vars, but if the parameters are part of the app, they _should_ work.
Would be nice have the script default the profile to `AWS_DEFAULT_PROFILE` to be consistent with other params. This allows for assume role to be taken care of by aws cli itself.

Current workaround:
```bash
ecs-deploy ... --profile ${AWS_DEFAULT_PROFILE}
```
We ran into a problem over at @sparkpost with AWS ECS where AWS' API was returning `nextPage` tokens that were invalid, and this affected us downstream with ecs-deploy because the `list-tasks` command failed on a service we run with over 100 container instances.  But looking more into the code, I realized that the later call:

```
$AWS_ECS describe-tasks --cluster "$CLUSTER" --tasks $RUNNING_TASKS
```

would fail with this service because that `--tasks` command can take 100 container IDs max.  So `ecs-deploy` seemingly cannot work for ECS services with > 100 container instances.

This PR refactors the logic somewhat substantially, but there's a way to call into the `describe-service` command and pull the status of deployments, ensure that the new service successfully launched all containers, and then ensure that there is only 1 active deploy left.  I think this logic mirrors the original logic, but since it only calls the `describe-service` API, I think this will be gentler on AWS services as well as having a narrow surface area for errors on AWS' end.  And it'll also work for larger fleets of container instances ðŸ˜€ 