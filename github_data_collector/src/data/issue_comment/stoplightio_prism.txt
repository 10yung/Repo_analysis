I have a docker linux image with ngix which hosts the angular app. It is possible to run the prism mock server in the same docker image?

In other words, I would like to have ngix to host an Angular app and run the `prism-cli mock api.yaml -- port 4500` at the same time. Api requests would be proxied to the internal 4500 port.

If the above is not possible, I could actually create a new container to run the `prism-cli`... but I don't know how to build the image. The following doesn't work for me:

```
FROM stoplight/prism:3
EXPOSE 4010
COPY api.yaml .
ENTRYPOINT ["prism-cli" "mock", "api.yaml", "--port", "4010"]
```

after `docker run` I get 

```
internal/modules/cjs/loader.js:796
    throw err;
    ^

Error: Cannot find module 'micri'
Require stack:
- /usr/src/prism/packages/http-server/dist/server.js
- /usr/src/prism/packages/http-server/dist/index.js
- /usr/src/prism/packages/cli/dist/util/createServer.js
- /usr/src/prism/packages/cli/dist/commands/mock.js
- /usr/src/prism/packages/cli/dist/index.js
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:793:17)
    at Function.Module._load (internal/modules/cjs/loader.js:686:27)
    at Module.require (internal/modules/cjs/loader.js:848:19)
    at require (internal/modules/cjs/helpers.js:74:18)
    at Object.<anonymous> (/usr/src/prism/packages/http-server/dist/server.js:5:17)
    at Module._compile (internal/modules/cjs/loader.js:955:30)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:991:10)
    at Module.load (internal/modules/cjs/loader.js:811:32)
    at Function.Module._load (internal/modules/cjs/loader.js:723:14)
    at Module.require (internal/modules/cjs/loader.js:848:19) {
  code: 'MODULE_NOT_FOUND',
  requireStack: [
    '/usr/src/prism/packages/http-server/dist/server.js',
    '/usr/src/prism/packages/http-server/dist/index.js',
    '/usr/src/prism/packages/cli/dist/util/createServer.js',
    '/usr/src/prism/packages/cli/dist/commands/mock.js',
    '/usr/src/prism/packages/cli/dist/index.js'
  ]
}
```

Thank you.
**Describe the bug**
After updating @stoplight/prism-cli from 3.2.1 to 3.2.3 a property defined as type: string was returned as number. The example value was not encapsulated with quotes (") and only contained numbers

**To Reproduce**

1. Given this OpenAPI document
```
openapi: 3.0.0
info:
  title: example
  version: 0.0.1
paths:
  /path/:
    get:
      responses:
        '200':
          description: Successful operation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'

components:
  schemas:
    Response:
      type: object
      properties:
        stringTypeString:
          type: string
          example: string
        numberTypeString:
          type: string
          example: 10001
```

2. Run this CLI command 'prism mock api.aos3.yaml' (create file with contents of step 1)
3. See error -> When calling the endpoint path the property 'numberTypeString' will be returned as number

**Expected behavior**
I expect the response to be a string as type string is defined in the OpenAPI document

**Environment**
 - Library version: 3.2.1
 - OS: windows 10
 - Browser: Edge 81

**Additional context**
Encapsulating the type string example value with quotes (") fixed the issue for me but it is weird that the type is defined but not taken into account.

In OpenAPI v3 it is possible to define a minimum and a maximum for type number like that:
type: number
minimum: 0
exclusiveMinimum: true
maximum: 50

It would be great if the mocked data would reflect these boundaries to produce a more realistic data set. For example if I have a property holding a temperature I get values like -32532.345234 at the moment instead of random numbers in a realistic range
…se from upstream

## Checklist

- [x] Tests have been added (for bug fixes / features)
- [ ] Docs have been added / updated (for bug fixes / features)

## What kind of change does this PR introduce?

_Bug fix_

## What is the current behavior? What is the new behavior?

When running `prism proxy` it relays all headers from upstream source, even after adding new ones that might be incompatible with the original response. 

More specifically in my case, my application is sending the `Transfer-Encoding: chunked` header, but since Prism is buffering the whole response to do response validation, is also adds the `Content-Length` header. These headers are incompatible and causes certain clients to fail. For example, Postman fails with a «Parse error» without a decent cause description.

Read more about the `Transfer-Encoding` header [here](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding)

## Does this PR introduce a breaking change?

Should be no breaking changes with this PR as far as I can see

**User story.**
As an API mock tester, when I startup PRISM and my OpenAPI spec contains an unresolvable $ref, then I want to receive a notification, so that I can try to fix the problem without having to try to fire that request against the mock by myself.

**Is your feature request related to a problem?**
i have tried to get started with PRISM and I have a spec with DTO models externalized into a separate file. My spec is affected by [bug #390](https://github.com/stoplightio/prism/issues/390).
If you experiment with the $refs, you need to try some calls before you know if it works or not.
`[15:43:16] » [CLI] ►  start     Prism is listening on http://127.0.0.1:4010`
(...) I'm firing a call manually with Postman (...)
`[15:43:38] »     [NEGOTIATOR] √  success   Found a compatible content for */*
(node:10040) UnhandledPromiseRejectionWarning: Error: Your schema contains $ref. You must provide specification in the third parameter.`

**Describe the solution you'd like**
During startup, Prism tries to resolve the $refs and outputs a warning if calls use unresolvable $refs.

**Additional context**
Go with a "Fail fast" approach

Closes #775 

## Checklist

- [x] Tests have been added (for bug fixes / features)
- [x] Docs have been added / updated (for bug fixes / features)

## What kind of change does this PR introduce?

_feature_

## What is the current behavior? What is the new behavior?

This PR introduces two new cli options:
`--callback-delay=n(-m)?`, where:
- `n` is number of seconds to wait (defaults to `0`), 
- `m` is optional and if set means that time to wait is randomized between `n` and `m`

`--callback-count=n(-m)?`, where:
- `n` is number of times to run a callback (defaults to `1`, `0` means infinitely), 
- `m` is optional and if set means that number of calls is randomized between `n` and `m`

## Does this PR introduce a breaking change?

No
## Checklist

- [x] Tests have been added (for bug fixes / features)
- [ ] Docs have been added / updated (for bug fixes / features)

## What kind of change does this PR introduce?

_Feature_

## What is the current behavior? What is the new behavior?

Prism CLI has now `--verbose` flag which turns on request and response logging for mocking, proxy and callbacks.

<img width="948" alt="Screen Shot 2019-11-15 at 16 39 50" src="https://user-images.githubusercontent.com/7136002/68955649-be8c3480-07c6-11ea-8f08-79d3d9ccd7f8.png">


## Does this PR introduce a breaking change?

No
**User story.**
As a Prism CLI user, I can have more control over running callbacks, so that I can delay making callback request or run it several times.

**Is your feature request related to a problem?**
Running callbacks not immediately but after some time or running them several times makes Prism act more like a real server. That would help me prepare my applications to more real environment.

**Describe the solution you'd like**
Two options:
`--callback-delay=n(-m)?`, where:
- `n` is number of milliseconds to wait (defaults to `0`), 
- `m` if set means that time to wait is randomized between `n` and `m`

`--callback-count=n(-m)?`, where:
- `n` is number of times to run a callback (defaults to `1`, `0` means infinitely), 
- `m` if set means that number of calls is randomized between `n` and `m`

**User story.**
As a Prism CLI user, I can supply --verbose (or --debug) CLI option, so that I can see more verbose logs.

**Is your feature request related to a problem?**
There are occasions when I do not have easy access to request or response payload. For those cases, it would be helpful if I could see the actual request and response payloads together with headers. That should help me debug possible problems with spec or request data.

**Describe the solution you'd like**
A `-d|--debug` or `--verbose` CLI option which enables the above functionality.

**Additional context**
This could be also super helpful in debugging callbacks, which are performing asynchronous request based on previous req/res pair.
**User Story**
As a Prism CLI user, I am used to using Prism for improving the speed and accuracy of integrating with HTTP request/response APIs, but I would also love help integrating webhooks for my API.

**Details**
Prism is adding callbacks in #331, but there is another feature coming through the  OpenAPI proposals pipeline called [Webhooks](https://github.com/OAI/OpenAPI-Specification/blob/master/proposals/002_Webhooks.md) conceived and championed by @lornajane in https://github.com/OAI/OpenAPI-Specification/issues/1968.

The summary for callbacks vs webhooks is this: callbacks are events which are asynchronously responding to a request that happened. It's the observer pattern: you send a request, get. 201/202, then within some reasonable time-frame the callback URL is hit to confirm the thing was done, or failed, etc. 

Webhooks are more about general events. You may subscribe to receive webhooks via a UI, then that URL will be blasted with any and all relevant events which happen until the end of time. As such these events are not related to paths in any way, they are a new top-level concept which use the same structure as callbacks, so a lot of the same code can be used. 

Lorna wrote [a blog post about webhooks and callbacks](https://www.apisyouwonthate.com/blog/openapi-callbacks-and-webhooks) for more context.

**Implementation**

This will have nothing to do with the mock or proxy servers, as these events are sent by the server whenever events happen. They do not need a mock server running, we just need to emulate the triggering of these events, to hit the local developers code.

Using the [nexmo SMS example](https://github.com/Nexmo/api-specification/blob/master/definitions/sms.yml): 

```yaml
x-webhooks:
  inbound-sms:
    '{$request.body#/callback}':
      post:
        summary: Inbound SMS
        operationId: inbound-sms
        x-example-path: '/webhooks/inbound-sms'
        description: |
          If you rent one or more virtual numbers from Nexmo, inbound messages to that number are sent to your [webhook endpoint](https://developer.nexmo.com/concepts/guides/webhooks).
          When you receive an inbound message, you must send a 2xx response. If you do not send a 2xx response Nexmo will resend the inbound message for the next 24 hours.
        requestBody:
          required: true
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InboundMessage'
        responses:
          '200':
            description: Your server returns this code if it accepts the callback
```

TBD but maybe a command like this?

```bash
prism trigger openapi.yml inbound-sms http://localhost:5000/webhook
```

**Questions**

1. we have both webhook name `incoming-sms` and operationId of `incoming-sms`, is this redundant or will they sometimes be different? If so, for what reason?

2. '{$request.body#/callback}': what is this and where is it coming from?
