wiki: 语义匹配应用介绍 

https://github.com/baidu/Familia/wiki/%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E5%BA%94%E7%94%A8%E4%BB%8B%E7%BB%8D

你好 作者  这个包在python上安装不成功 大概是什么原因啊 可以帮我解答下吗  谢谢您了
从demo来看，得到的是整个文档的主题分布，如果想要得到每个句子的主题分布呢？
请问除了等待百度开发模型外,有没有办法自己训练自己行业的模型?

    Complete output (5 lines):
    Traceback (most recent call last):
      File "<string>", line 1, in <module>
      File "/Applications/anaconda3/lib/python3.6/tokenize.py", line 452, in open
        buffer = _builtin_open(filename, 'rb')
    FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/f6/7bydfp4s6bl9glg4zkpzhp9w0000gn/T/pip-req-build-uuyw7eml/setup.py'
    ----------------------------------------
ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
![image](https://user-images.githubusercontent.com/4702353/61934119-2ae5ec80-afba-11e9-95d3-d1880ee3cedf.png)

https://github.com/baidu/Familia/wiki/语义匹配应用介绍

在计算相似度的时候，我们规避对短文本直接进行主题映射，而是根据长文本的主题分布，计算该分布生成短文本的概率，作为它们之间的相似度
check fail: file open pretext file /familia/model/webo/lda.conf
我在运行sh download_model.sh的时候，显示的是not found。

是不是不在提供了呢