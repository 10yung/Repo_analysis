I've discovered why I'm not getting the monitor exits I expect. In ProcessAdapter.exit a test is made for the state of the process. If it's not alive, then the link break, monitor break code, is not triggered. However, it is possible for monitor to be registered during the call to exit. The subsequent call to exit then does not issue the rest of the monitor exit messages (and ditto for the link breaks). So, it seems process exit is not quite right. If I remove this check, then I get more monitor exit messages through to my erlang process.

Wall of text as it's late.

Attempts to monitor a non-live pid should send an immediate link break message to the other end, much as monitoring a non-existent process should send an immediate monitor exit message.

Could you possibly go back and update the README so that the example code is complete and it works?  Most of the code samples generate errors, and for the life of me I can't get the sample "echo" client to work quite right.

For example, this client-side code definitely doesn't work for echo:

``` scala
  val node = Node("remote", "cookie")
  node.spawn { mbox =>
    mbox.send(('kharon, Symbol("kharon@hypatia")), mbox.self, (mbox.self, "Hello!"))
    val received = mbox.receive
    println("Received = " + received)
  }
```

The server-side gets the message and returns a response, but the client never gets it.  

This revision to the above, however, does work:

``` scala
  val node = Node("remote", "cookie")
  val mbox = node.spawnMbox
  mbox.send(('kharon, Symbol("kharon@hypatia")), mbox.self, (mbox.self, "Hello!"))
  val received = mbox.receive
  println("Received " + received)
```

_But_ in both cases, the code hangs due to what I can only guess is a thread running in the background that isn't being cleaned up.  I've tried this:

``` scala
  node.shutdown
  println("Shutdown")
```

The "Shutdown" is output, but it doesn't really stop the node.  Is there an example for how you stop a node just making a quick remote call for information?

Thanks.

Default connection does retries and polls the connection automatically. Logs output to tell you what's up. The number of retries and a connection timeout are configurable.

According to the tests, this doesn't break the old interface. There's a new Epmd signature that lets you access a netty ChannelFuture if you want to go deep on retry logic yourself.

Need to unregister Metrics for Pids which can otherwise be destroyed, as these will hang around in the JVM and not be GC'd due to that dangling JMX reference.

Reverting ae851bb0bea091756a3037f6b6ad1d6bddb30d3d fixes 'mvn test'.

Classes like "MetricsRegistry" appear in both the newly introduced metrics-scala dependency and the existing overlock-scala dependency, which probably explains it.

  decode regular terms(scalang.terms.ScalaTermDecoderSpec): java.lang.NoSuchMethodError: com.yammer.metrics.core.MetricsRegistry.newTimer(Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/util/concurrent/TimeUnit;Ljava/util/concurrent/TimeUnit;)Lcom/yammer/metrics/core/Timer;
  decode full distribution packets(scalang.terms.ScalaTermDecoderSpec): java.lang.NoSuchMethodError: com.yammer.metrics.core.MetricsRegistry.newTimer(Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/util/concurrent/TimeUnit;Ljava/util/concurrent/TimeUnit;)Lcom/yammer/metrics/core/Timer;

Scalang needs a supervisor implementation equivalent to Erlang's.

Currently, link breakages are delivered cooperatively. This is undesirable behavior in the case of processes that have long running message handlers and processes spawned from an anonymous function, which might never yield execution to an error handler.  We need the ability to deliver an interrupt to the fiber running a particular process.
