There will ve a discourse post as well
There will ve a discourrse post as well
https://github.com/spotify/scio/releases/tag/v0.8.0
Hello! 

Since today (15-01-2020) we are not able to download the **commons-codec** from Maven, which means we cannot bootstrap our EMR. 

When checking the error logs, both from our application and Amazon, we saw that the bootstrap is failing on downloading that said library because it tries to connect via **HTTP**:

`--2020-01-15 18:12:38--  http://central.maven.org/maven2/commons-codec/commons-codec/1.5/commons-codec-1.5.jar                
Resolving central.maven.org (central.maven.org)... 151.101.4.209                                                              
Connecting to central.maven.org (central.maven.org)|151.101.4.209|:80... connected.                                           
HTTP request sent, awaiting response... 501 HTTPS Required                                                                    
2020-01-15 18:12:38 ERROR 501: HTTPS Required.`

With a quick research on the web, we found out that since today (15-01-2020) Maven no longer supports plain HTTP, so we tried to connect via **HTTPS**. However, that failed too with the message bellow:

`--2020-01-15 19:18:23--  https://central.maven.org/maven2/commons-codec/commons-codec/1.5/commons-codec-1.5.jar
Resolving central.maven.org (central.maven.org)... 151.101.204.209
Connecting to central.maven.org (central.maven.org)|151.101.204.209|:443... connected.
ERROR: no certificate subject alternative name matches
        requested host name central.maven.org.
To connect to central.maven.org insecurely, use `--no-check-certificate'. `

Then, we created another script to add as a custom Bootstrap. We managed to add this script, but it failed again, this time pointing out that it cannot remove **commons-codec-1.4.jar**.

Right now, we are trying to pass 1.5 as a parameter and see if it will work. We will try to update it here as soon as possible - no matter if it fixes or not. 

Also, I'd like to point out that we are on **sa-east-1**. 



**Project**:  
Stream Enrich

**Version**: 

**Expected behavior**: 

EMR Bootstraping builds the cluster. 

**Actual behavior**:
EMR fails at Bootstrap.

**Steps to reproduce**:

 1. Start a new EMR using **snowplow-ami4-bootstrap-0.2.0.sh** as the script. 
 
2. Change  **http://** to **https://** on **snowplow-ami4-bootstrap-0.2.0.sh**. Try to run it as you would. 

3. Change  **https://central** to **https://repo1** on **snowplow-ami4-bootstrap-0.2.0.sh**. Try to run it as you would normally.

4. Create a new self hosted bootstrap script and add it to your EMR's Bootstrap. Make sure the new script has the same changes as those above.  


Cheers!


<!--
Thank you for contributing to Snowplow!

You'll find a small checklist below which should help speed up the review process:

- [/] Have you signed the [contributor license agreement](https://github.com/snowplow/snowplow/wiki/CLA)?
- [/] Have you read the [contributing guide](https://github.com/snowplow/snowplow/blob/master/CONTRIBUTING.md)?
- [x] Have you added the appropriate unit tests?
- [x] Have you run the tests through `sbt test`?
- [/] Is your pull request against the `master` branch?
-->
 Hi folks, it just hotfix. my job's had crashed without that.

In SCE 1.0.0 in order to make it possible to compose IO we made a decision to switch all client libraries to final tagless like encoding:

```scala
trait Weather[F[_]] {
  def temperature: F[Int]
}
```

It works great with `IO`, `Task`, `ZIO` etc, but we cannot support them in Spark and Beam (or maybe we can and then we should!). We decided to use `Id` in Spark and Beam, which unfortunately makes SCE API not that composable as we would like to. Imagine following code:

```scala
implicit val idWeather = new Weather[cats.Id] {
  def temperature: Id[Int] = {
    println("Getting weather")
    20
  }
}

implicit def syncWeather[F[_]: cats.effect.Sync] = new Weather[F] {
  def temperature: F[Int] =
    cats.effect.Sync[F].delay {
      println("Getting weather")
      20
    }
}

def one[F[_]](implicit W: Weather[F], M: Monad[F]) = {
  val weather: F[Int] = W.temperature   // would be fine with def
  for {
    berlin <- weather
    moscow <- weather
  } yield moscow - berlin
}

def two[F[_]](implicit W: Weather[F], M: Monad[F]) = {
  val weather: F[Int] = W.temperature   // would be fine with def
  List.fill(5)(weather).sequence
}
```

`one[Id]` does a different thing from `one[cats.effect.IO].unsafeRunSync()`. As a result we just need to be very careful in with constructs like `val x: F[Something]` because in some cases it means it has been evaulated already and we cannot use many functional combinators, so the code is not much better than pre-1.0.0.

/cc @benjben 
Reasoning is that it becomes too cumbersome to release patch releases of individual components and split work between different engineers. Also I expect it should help with CI/CD process and external contributions.

We have came up with options on what to do with `snowplow/snowplow` as we don't want to lose this entrypoint.

1. Transform all projects into submodules as we did with `1-trackers` and periodically update them. That would also allow us to bring loaders back to a `snowplow/snowplow` as technically they're core part of pipeline.
2. Use this repo for documentation and publish it to GH pages
3. Combination of 1 and 2, where we have most of docs on a dedicated docs.snowplowanalytics.com and in repo just a summary of all components and links to extensive docs (my personal preference)
4. Make this repo a repo for one of core components (Scala Common Enrich most probably)

Regardless of above decision we need to:

1. Overhaul the main `README` and point to our commercial offer and Snowplow Mini for those who just wants to try out the technology.
2. Write a script that will move all (~600) existing issues into their appropriate projects with cross-reference to original ticket
AWS is removing Tomcat 8 support on Elastic Beanstalk, making our ClojureCollector incompatible.
AWS is changing its Cloudfront format.

> We are contacting you because your AWS account contains at least one CloudFront web distribution with logging enabled. Starting December 12, 2019, Amazon CloudFront is adding the following seven new fields to access logs:
> 
> • c-port – The port number of the request from the viewer.
> • time-to-first-byte – The number of seconds between receiving the request and writing the first byte of the response, as measured on the server.
> • x-edge-detailed-result-type – When the result type is an error, this field contains the specific type of error.
> • sc-content-type – The value of the HTTP Content-Type header of the response.
> • sc-content-len – The value of the HTTP Content-Length header of the response.
> • sc-range-start – When the response contains the HTTP Content-Range header, this field contains the range start value.
> • sc-range-end – When the response contains the HTTP Content-Range header, this field contains the range end value.

We often want to filter out events based on some configuration enabled, e.g. we updated version of Beam Enrich or MaxMind DB and got an unexpected behavior - we want to analyze only that set of events, but currently cannot do this in a predictable way.

Should it be a hash of all config files? How we can make sure the hash can be reversed?