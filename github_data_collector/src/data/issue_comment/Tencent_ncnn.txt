项目上一直采用的ncnn版本发布于2018.4月份（commit id = 356d018771b389b1efb6d810e1b8db5c803b6ad9，）。最近尝试更新的ncnn版本（commid = a50bcf10aa6b1e367222021534251d0e0acf607a），发布于2019.12月份。对几种设备做压测（Android 8.1, arm-v7），发现cpu性能均略有下降。但是在加载模型时，内存占用相比之前大了许多。一共五个模型，加载后，总计内存大约增长了50%。请问这是什么原因呢。会不会和allocator相关。如何解决。
Simplifying...
Ok!
Gather not supported yet!
  # axis=0
Gather not supported yet!
  # axis=0
Gather not supported yet!
  # axis=0
Gather not supported yet!
  # axis=0
Gather not supported yet!
  # axis=0
Gather not supported yet!
  # axis=0
Gather not supported yet!

但是文件正常生成了，不知道什么情况
lstm的arm版本有计划更新吗？
* fix int8 requant in `convolution_arm.cpp: 1163`,
* add int8 requant test

`top_blob_g` defined but not used, compile warning should be treated as error.
Add more mips layers.
it seems that the vulkan split layer is not correct. when I enable vulkan to inference, the output from split is always incorrect, but once disable vulkan, the output become correct. attached is the param and bin files I used.

[ERFNet_model.zip](https://github.com/Tencent/ncnn/files/4058403/ERFNet_model.zip)


When I check out the Android example "https://github.com/nihui/ncnn-android-squeezenet/", I find out that this sample code is using pre-compiled dynamic library "libsqueezenet.so" rather than compiled library from jni file. But when I try to reconstruct from jni cpp file, error is always there. I've commented  in relevant issues "https://github.com/nihui/ncnn-android-squeezenet/issues/5" but nobody replied. Would someone please give feedbacks about this issue, that would be very kind of you. Thanks!

很多算法如split-shuffle-non-bottleneck(REF:https://blog.csdn.net/jiaoyangwm/article/details/90402289 
 )，  需要1*3，3*1 kernel
另外，还需要支持dilation
https://github.com/hollance/BlazeFace-PyTorch
I am getting nan at output 
After converting via onnx simplifier 

Has anyone tried to port this to ncnn