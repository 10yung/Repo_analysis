您论文里写到 the magnitude of the gradients of thesetwo functions is1and|x|respectively, and the magnitudeof the corresponding optimal step sizes should be|x|and1.
第一个问题：L1的梯度是1，L2的loss不应该是2x吗？
第二个问题：这里面的最佳步长是什么，作用是什么，怎么计算的？
期待您的解答，这个问题困扰了我好久。。。
它可以代替由眼珠距归一化的点对点距离的损失函数吗，或者说哪一个更好呢
请问是对数据增强过后的样本进行pdb，还是对原始的样本pdb后再进行数据增强？
Could you please share the trained model of 68 landmarks so that we could evaluate on 300W test set and other dataset with 68 points? Or could you please share the landmark prediction results on 300W test set? Since we would like to compare with different metrics. Thank you very much. We will cite your paper if you could provide the results.

老师您好

我在使用tensorflow复现wing loss论文，我先使用CNN6模型和L1 loss训练，在但是精度始终不高，在300w数据库上只能达到NME=7.2%。想向您请教一下具体细节：

1. 数据预处理，根据landmark确定bbox（应该与数据库提供的gt bbox一致），增加bbox宽高中的短边使bbox变为方形，扩大bbox至1.2倍。

2. 每一个训练epoch都对训练集重新进行数据增强，-30°~30°随机旋转，50%随机水平翻转，-5%~5%bbox抖动，颜色抖动，高斯模糊。

3. 输入尺寸64x64x3，像素值为0到1，输出xy范围为0到63。

4. L1 loss的计算方式为：将预测关键点与gt求L1距离，然后对68*2个x、y值求和，再对一个batch求平均。

5. 模型为CNN6，每个卷积层和全连接层都加了5e-4的L2权重正则。

6. 训练优化器为SGD，momentum=0.9，学习率为3e-5到3e-7线性衰减，训练300epochs，batchsize=8。

请问有哪些细节我没注意到，谢谢您。
Could you please post your training set error on 300W (68 points landmark)?Thanks
can you share your trained model of 300w dataset, share your training or data augment script?

thank you for your job. I am interested in your work. Can you provide caffe version code of wingloss?
您好，您的方法十分高效准确，我正在复现您的工作，有两个小的细节想向您确认一下：
1. 您实验中用到的bounding box是根据landmarks边界确定的吗？是否向外扩展了。
2. 使用WFLW训练时，大概需要训练多少epochs，学习率如何设置。
谢谢

