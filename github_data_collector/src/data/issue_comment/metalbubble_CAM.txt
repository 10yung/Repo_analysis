
GoogLeNet-CAM model on ImageNet. 

I was not able to find the file: models/deploy_googlenetCAM.prototxt to use with the pre-trained weights. Is it possible to add this in?
Could you please share the python code that generate the bounding box according to the heatmap?

_Originally posted by @liu666666 in https://github.com/metalbubble/CAM/issues/18#issuecomment-410275672_
Does the VggNet apply the same data preparing (prepare_image.m) as GoogLetNet?
What if i want to visualize the intermediate feature map and its channel is difference from the last layer. For example, Visualize the layer3 in resnet18 in pytorch.
Thank you for sharing the code.but can it be used for detection task?
For example I have 2 classes and for single image I have heatmap with shape [H,W,N_CLASSES]. I train my model with sigmoid + binary crossentropy. At prediction time when I use larger image as network input, at each pixel I want my classes to be exclusive, so I need to compare heatmap values with `np.argmax` to get 'best' class, so my questions is values in heatmaps are really comparable?

I tried to dump min, max values of heatmap for single image:
```
i 0
np.min(heatmap[:,:,i]),np.max(heatmap[:,:,i]) -38.4533 19.9384
i 1
np.min(heatmap[:,:,i]),np.max(heatmap[:,:,i]) -20.2977 34.8101 
```
As I can see range of values are different and heatmaps are not normalized.

Is there a way to normalize all planes of heatmap to [0,1] range and make them comparable?
I am the developer of CAM. Recently I found this blog article (https://thehive.ai/blog/inside-a-neural-networks-mind) to introduce CAM and grad-CAM. The overview on the CAM and grad-CAM in the blog article is good, but  found there is some bias or misleading claim to CAM, compared to grad-CAM. This wrong claim has been existing for a while that I would like to clarify as below:

First of all, nowadays all the mainstream network architectures such as resnet, densenet, or other squeezenet use global average pooling at the end, so the class activation map (the heatmap) could be generated directly using CAM, without modifying any network architectures. So the claim that the grad-Cam is superior over CAM because of using grad-cam without modifying architecture is false. 

Meanwhile,  if you are using resnet or densenet or squeeznet or any modern networks, so you can basically generate heatmap using CAM directly (see example code at https://github.com/metalbubble/CAM/blob/master/pytorch_CAM.py), without needing the extra step to compute the gradient as in grad-CAM. Through that you save the backward computation, in which you save almost half of the computation. This is crucial in some application such as video processing that CAM is able to use the forward pass only to generate the prediction and heatmap for each frame. So in the associated code of that blog (https://github.com/hiveml/tensorflow-grad-cam), they are already using the resnet, but still use the gradient to generate CAM. It simply wastes the computation.

Matlab image layout is HxWxC
