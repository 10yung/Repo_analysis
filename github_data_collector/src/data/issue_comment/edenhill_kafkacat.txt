We have an issue using `kafkacat -C -b broker -t topic -o -10 -e` and `kafkacat -C -b broker -t topic -o -1 -e`. If we have just one message in the topic, the first command (`kafkacat -C -b broker -t topic -o -10 -e`) doesn't show anything, but the second command (`kafkacat -C -b broker -t topic -o -1 -e`) shows the event. 

It seems that only show the events if we specifies the exact number of events in the topic.
All this issue is related to 1.5.0 version.




I am trying to build the exact infra mentioned [here](https://medium.com/google-cloud/kubernetes-hpa-autoscaling-with-kafka-metrics-88a671497f07)

Basically, the article is specifically for scaling pods based on the reading the Stackdriver metrics(stack drive receives traffic from the Kafka server and scaling happens based on it.)

Everything is working fine until I create a producer deployment and it works fine as expected. It is able to connect to the Kafka server but when I run the consumer deployment, it is failing with the following error in the container logs.

`% Error: 10.128.0.9:9092/bootstrap: Connect to ipv4#10.128.0.9:9092 failed: Operation timed out (after 128991ms in state CONNECT)`

screenshot https://prnt.sc/q7hwvs

I just have one GKE cluster with 2 nodes + one Kafka compute engine instance. There is no special setup. I am just following the above article.

I don't know what should I debug because producer is working but consumer is not.

If anyone can help that would be really appreciated.
Dear Developers,

I came across #85 that asked to have -X override -b, but I wonder, if I have metadata.broker.list property in ~/.config/kafkacat.conf or in $KAFKACAT_CONFIG, why is -b still required? Is it something fundamental or just doesn't work for me?

For reference,  my config look like:

```
$ echo $KAFKACAT_CONFIG
metadata.broker.list=10.0.1.208:6667
$ cat ~/.config/kafkacat.conf 
bootstrap.servers=10.0.1.208:6667
metadata.broker.list=10.0.1.208:6667
```

Thanks in advance!
Hello everybody. 

I am trying to consume a topic with avro serialization and i keep get this error : 
 ERROR: Failed to format message in tpc_alertes.dc05 [2] at offset 623: Avro/Schema-registry message deserialization: REST request failed (code 404): {"error_code":404,"message":"HTTP 404 Not Found javax.ws.rs.NotFoundException: HTTP 404 Not Found\njavax.ws.rs.NotFoundException: HTTP 404 Not Found\n\tat org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:2 : terminating

I'm sure pretty sure my url is good since i get the schema when i try curl https://dev...../schemas/ids/3 
Anyone had this before ? 

Thank you 

kafkacat version 1.5 and librdkafka 1.2.2

Running kafkacat:
kafkacat -P -b 10.144.0.2:9092 -X "debug=protocol,broker,topic,msg" -X "message.timeout.ms=1" -t test

I am unable to trigger the message.timeout.ms value. The log mesages I see when I produce a message are as follows:

```
fgh
%7|1575053805.346|PRODUCE|rdkafka#producer-1| [thrd:kafkatestserver:9092/0]: kafkatestserver:9092/0: test [3]: Produce MessageSet with 1 message(s) (71 bytes, ApiVersion 7, MsgVersion 2, MsgId 0, BaseSeq -1, PID{Invalid}, uncompressed)
%7|1575053805.346|SEND|rdkafka#producer-1| [thrd:kafkatestserver:9092/0]: kafkatestserver:9092/0: Sent ProduceRequest (v7, 122 bytes @ 0, CorrId 4)
%7|1575053805.372|RECV|rdkafka#producer-1| [thrd:kafkatestserver:9092/0]: kafkatestserver:9092/0: Received ProduceResponse (v7, 48 bytes, CorrId 4, rtt 26.16ms)
%7|1575053805.372|MSGSET|rdkafka#producer-1| [thrd:kafkatestserver:9092/0]: kafkatestserver:9092/0: test [3]: MessageSet with 1 message(s) (MsgId 0, BaseSeq -1) delivered
```
Based on this I see the ProduceResponse is rtt 26.16ms so greater than the 1 ms timeout, so I would expect a "Local: Message timed out"

I'm aware that the Producer timeout should be set on a per topic basis, but through Kafkacat I'm unaware of how I can configure this. I have also tried adding the configurations to a configuration file and referenced it with -F flag. But the same outcome.

## Overview

We're seeing a strange issue related to DNS resolution with `kafkacat` 1.5.0 running on macOS Mojave and Catalina (possibly other versions too, haven't tried farther back). `kafkacat` is reporting DNS name resolution failures when trying to resolve the advertised hostnames of Kafka brokers, despite those DNS names resolving fine from the same host using other tools.

Here's an example of what this looks like (broker hostnames and topic names have been scrubbed in this and future examples):

```
▶ kafkacat -C -b kafka-a.example.com -t my-topic -c 1 -e
% ERROR: Local: Host resolution failure: kafka-xyz.example.com:9092/42: Failed to resolve 'kafka-xyz.example.com:9092': nodename nor servname provided, or not known (after 0ms in state CONNECT)
```

In this example:

* `kafka-a.example.com` is a 'seed' DNS record (CNAME) pointing at some arbitrary broker in the cluster (different from the one that hosts the topic we're trying to consume from)
* `kafka-xyz.example.com` is an A record, pointing at the broker with ID 42, which is leading the sole partition for `my-topic`. It's the name that broker 42 is advertising in ZooKeeper.

From what I can tell, this *only* happens on macOS. Running the same exact command from the same host in a Docker container or Linux VM yields the expected results, and no DNS resolution failure. Resolving both hostnames works fine using `dig` / `nslookup` locally on macOS.

The fact that `kafkacat` is able to even find `kafka-xyz.example.com` suggests that it was able to resolve `kafka-a.example.com` without issue. Interestingly, directly giving `kafka-xyz.example.com` (the advertised name of the lead broker) to `kafkacat` like this also yields working results:

```
▶ kafkacat -C -b kafka-xyz.example.com -t my-topic -c 1 -e # where kafka-xyz.example.com is the advertised name of the lead broker for the sole partition of my-topic
< ... message content ... >
```

... but if I use a topic that has leaders on more than one broker, DNS lookups for all but the first leader (the one specified with the `-b` flag) will fail in the same way.

## Diagnosis

It looks like `librdkafka` uses the native `getaddrinfo` to do DNS resolution, so I tried tracing the calls to `getaddrinfo` to confirm that the args looked correct. I used `dtrace` to do this, and here's what I found (output cleaned up a little bit):

```
▶ sudo dtrace \
   -n 'pid$target::getaddrinfo:entry { printf("  getaddrinfo(%s, %s, ...)", copyinstr(arg0), copyinstr(arg1)) }' \
   -n 'pid$target::getaddrinfo:return { printf("  getaddrinfo returned %d", arg1); }' \
   -n 'pid$target::rd_getaddrinfo:entry { printf("rd_getaddrinfo(nodesvc=%s, defsvc=%s, flags=0x%x, family=%d, socktype=%d, protocol=%d)\n", copyinstr(arg0), copyinstr(arg1), arg2, arg3, arg4, arg5); }' \
   -n 'pid$target::rd_getaddrinfo:return { printf("rd_getaddrinfo returned %d\n", arg1); }' \
   -c "kafkacat -C -b kafka-a.example.com -t my-topic -c 1 -e"

% ERROR: Local: Host resolution failure: kafka-xyz.example.com:9092/42: Failed to resolve 'kafka-xyz.example.com:9092': nodename nor servname provided, or not known (after 0ms in state CONNECT)

CPU     ID                    FUNCTION:NAME
  8  41983             rd_getaddrinfo:entry rd_getaddrinfo(nodesvc=kafka-a.example.com:9092, defsvc=9092, flags=0x400, family=0, socktype=1, protocol=6)

  8  41981                getaddrinfo:entry   getaddrinfo(kafka-a.example.com, 9092, ...)
  4  41982               getaddrinfo:return   getaddrinfo returned 0
  4  41984            rd_getaddrinfo:return rd_getaddrinfo returned 140546978879280

 10  41983             rd_getaddrinfo:entry rd_getaddrinfo(nodesvc=kafka-xyz.example.com:9092, defsvc=9092, flags=0x400, family=0, socktype=1, protocol=6)

 10  41981                getaddrinfo:entry   getaddrinfo(kafka-xyz.example.com, 9092, ...)
 10  41982               getaddrinfo:return   getaddrinfo returned 8
 10  41984            rd_getaddrinfo:return rd_getaddrinfo returned 0
```

(Note that I'm tracing both entry and exit from `rd_getaddrinfo` and `getaddrinfo` itself, just because it makes it easier to get at the flags, family, socktype, and protocol attributes, which are otherwise tucked away inside the `struct addrinfo` arg to `getaddrinfo`.)

Note that the *first* resolution attempt (for `kafka-a.example.com`) works fine. The second attempt (for `kafka-xyz`) fails with error code 8, which is `EAI_NONAME`, matching the error message.

Weirdly, using the exact same `getaddrinfo` args from a standalone test program on the same system also works just fine:

Test program (excuse my awful C):

```
#include <stdio.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <netdb.h>

void resolve(char *name) {
  printf("resolving %s\n", name);
  char *defsvc = "9092";

  int family = AF_UNSPEC;
  int socktype = SOCK_STREAM;
  int protocol = 6;
  int flags = AI_ADDRCONFIG;

  struct addrinfo *ais;
  struct addrinfo hints = { .ai_family = family,
          .ai_socktype = socktype,
          .ai_protocol = protocol,
          .ai_flags = flags };

  int r = getaddrinfo(name, defsvc, &hints, &ais);
  printf("got return code = %d\n", r);
}

int main(int argc, char **argv) {
  resolve("kafka-a.example.com");
  resolve("kafka-xyz.example.com");
  return 0;
}
```

Example output:

```
resolving kafka-a.example.com
got return code = 0
resolving kafka-xyz.example.com
got return code = 0
```

## More Diagnosis Than You Probably Want

I spent some time tracing through the `getaddrinfo` guts on macOS to try to figure out what's going on, and found the `RES_DEBUG` environment variable, which you can set to trigger lots of debugging messages from the DNS resolver implementation on macOS. Here's the log spew for the *first* resolution (the one that works):

```
▶ RES_DEBUG=1 kafkacat -C -b kafka-a.example.com -t my-topic -c 10 -e
;; mdns_addrinfo node kafka-a.example.com serv �#�xj
;; _mdns_search wait loop
;; mdns query kafka-a.example.com type 1 class 1 ifindex 0 [ctx 0x7000056a7420]
;; mdns query kafka-a.example.com type 28 class 1 ifindex 0 [ctx 0x7000056a7478]
;; set kevent timeout 35.0 [ctx 0x7000056a7420 0x7000056a7478]
;; _mdns_search calling DNSServiceProcessResult
;; _mdns_query_callback ctx 0x7000056a7420 flags=0x00000003 (kDNSServiceFlagsMoreComing is set)
;; _mdns_hostent_append_alias(0x7000056a7698, kafka-a.example.com.)
;; _mdns_hostent_append_addr(0x7000056a7698, 0x7fbd1aa000b5, 4)
;; [kafka-a.example.com. type 1 class 1] reply [ctx 0x7000056a7420]
;; _mdns_query_callback sending kevent wakeup
;; _mdns_query_callback ctx 0x7000056a7478 flags=0x00000002
;; cleared kDNSServiceFlagsMoreComing flag for ctx 0x7000056a7420
;; [kafka-a.example.com. type 28 class 1]: error -65554 [ctx 0x7000056a7478]
;; _mdns_query_callback sending kevent wakeup
;; DNSServiceProcessResult -> (null)
;; mdns is_complete type 1 ctx 0x7000056a7420 clear more coming - complete
;; mdns is_complete type 1 ctx 0x7000056a7420 host addr count 1 complete -> true
;; mdns is_complete type 1 ctx 0x7000056a7420  - complete
;; ctx 0 0x7000056a7420 error=0 complete=true
;; type ns_t_a got_a_response=GOT_DATA ctx 0x7000056a7420
;; [kafka-a.example.com type 0 class 1] finished processing ctx 0x7000056a7420
;; mdns is_complete type 28 ctx 0x7000056a7478 clear more coming - complete
;; mdns is_complete type 28 ctx 0x7000056a7478  - incomplete
;; ctx 1 0x7000056a7478 error=-65554 complete=false
;; [kafka-a.example.com type 0 class 1] finished processing ctx 0x7000056a7478
;; [kafka-a.example.com type 0 class 1] done [ctx 0x7000056a7420 0x7000056a7478]
;; finished _mdns_search loop [ctx 0x7000056a7420 0x7000056a7478]
;; mdns is_complete type 1 ctx 0x7000056a7420 clear more coming - complete
;; mdns is_complete type 1 ctx 0x7000056a7420 host addr count 1 complete -> true
;; mdns is_complete type 1 ctx 0x7000056a7420  - complete
;; _mdns_search ctx 0x7000056a7420 complete
;; mdns is_complete type 28 ctx 0x7000056a7478 clear more coming - complete
;; mdns is_complete type 28 ctx 0x7000056a7478  - incomplete
;; _mdns_search ctx 0x7000056a7478 incomplete
;; _mdns_search overall complete
;; _mdns_search exit res 0
```

... and here's what it shows for the second resoultion (the one that fails):

```
;; mdns_addrinfo node kafka-xyz.example.com serv �#�Ȼ
;; finished _mdns_search loop [ctx 0x0 0x0]
;; _mdns_search overall incomplete
;; _mdns_search exit res -1
% ERROR: Local: Host resolution failure: kafka-xyz.example.com:9092/43: Failed to resolve 'kafka-xyz.example.com:9092': nodename nor servname provided, or not known (after 0ms in state CONNECT)
;; mdns_addrinfo node kafka-xyz.example.com serv �#�Ȼ
;; finished _mdns_search loop [ctx 0x0 0x0]
;; _mdns_search overall incomplete
;; _mdns_search exit res -1
```

Note that it jumps straight from the `mdns_addrinfo` line to the 'finished' line. The code that generates these messages is [here](https://opensource.apple.com/source/Libinfo/Libinfo-517/lookup.subproj/mdns_module.c.auto.html) from what I can tell.

Based on some more poking around with `dtrace`, it looks like the proximate cause of the early return on the second call to `getaddrinfo` is that the `kevent()` call on line 1703 of the above-linked `mdns_module.c` returns a non-zero value (consistently 9 on my machine) on the second `getaddrinfo` call. As to *why* that happens or what it suggests about this bug, I'm pretty out of my depth.

## Wild Speculation

To be honest, this smells more like a macOS bug in the implementation of `getaddrinfo` than a bug in `kafkacat` or `librdkafka` to me, but I figured I'd start here.
I just want this API to be exposed for any cases when you need to set offset for group manually.
If there are any already working examples, it would be nice to see them
```
kafkacat -b kafka-cp-kafka:9092 -C -t test-xyz-does-not-exist
% ERROR: Topic test-xyz-does-not-exist error: Broker: Leader not available
```

That creates topic `test-xyz-does-not-exist` which previously did not exist. I wouldn't expect kafkacat to create topics when in consumer mode.

This is running the Docker image `confluentinc/cp-kafkacat:latest` with

```
kafkacat -V
kafkacat - Apache Kafka producer and consumer tool
https://github.com/edenhill/kafkacat
Copyright (c) 2014-2015, Magnus Edenhill
Version debian/1.3.1-1 (JSON) (librdkafka 1.2.0 builtin.features=gzip,snappy,ssl,sasl,regex,lz4,sasl_gssapi,sasl_plain,sasl_scram,plugins,sasl_oauthbearer)
```