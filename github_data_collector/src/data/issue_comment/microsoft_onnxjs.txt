I've exported an ONNX model from PyTorch using opset version 7 (the lowest version the PyTorch export supports), and it includes a LogSoftmax operator, which results in the following error when I try to use it in ONNX.js:

```
TypeError: cannot resolve operator 'LogSoftmax' with opsets: ai.onnx v7
```
This version of LogSoftmax has been available since version 1 of ONNX so it would be nice to support it.

Implemented Pad operator for cpu backend.
I am having trouble with https://vita-epfl.github.io/openpifpafwebdemo/ on a new iPhone with iOS 13. It only works when I disable "webgl 2.0" in the advanced settings of Safari. 

I cannot reproduce the problem with a desktop browser and I see no error messages when connecting a remote debug console to the mobile Safari.

Is there anything else I can try to get more information about the root of the problem?
Some suggested changes. Feel free to cherry-pick only some of them if you don't want to use all of them.

When is the next release of onnx.js scheduled? I am interested in support for more operators (especially Upsample, Shape and Max operators).
i use a model from https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/mask-rcnn mask-rcnn

and load the model in onnxjs

just follow the instructions.

  const model = new onnx.InferenceSession();
  await model.loadModel("./mask_rcnn_R_50_FPN_1x.onnx");

but errors occur, int64 is not supported.

why is that? how to solve it?
I exported a Pytorch model to ONNX, but I cannot load it on the browser for inference.
Details about my problem:

ONNX version: 1.5.0
Python version: Python 3.6.7 :: Anaconda, Inc.
Browser: Google Chrome 75.0.3770.100 
ONNX model: [https://drive.google.com/file/d/16JIuHKmp9vA-CL_6z6l8KjwZ1Qcnf-Jz/view?usp=sharing](https://drive.google.com/file/d/16JIuHKmp9vA-CL_6z6l8KjwZ1Qcnf-Jz/view?usp=sharing)

Code:
```
<html>
  <head> </head>

  <body>
    <!-- Load ONNX.js -->
    <script src="https://cdn.jsdelivr.net/npm/onnxjs/dist/onnx.min.js"></script>
    <!-- Code that consume ONNX.js -->
    <script>
       // Create an ONNX inference session with default backend.
       const session = new onnx.InferenceSession();
            
        // Load an ONNX model.
        session.loadModel("./NumberPredictor.onnx").then((success) => {
            console.log("success", success);
        }).catch((error) => {
            console.log("error", error);
        });
    </script>
  </body>
</html>
```

Error message: <b>Error: unrecognized input '' for node: unnamed_LSTM_0</b>
#### Uncaught (in promise) TypeError: cannot resolve operator 'BatchNormalization' with opsets: ai.onnx v6
    at Object.e.resolveOperator (onnx.min.js:3744)
    at t.resolve (onnx.min.js:6679)
    at e.initializeOps (onnx.min.js:16130)
    at onnx.min.js:16046
    at t.event (onnx.min.js:1283)
    at e.initialize (onnx.min.js:16044)
    at e.<anonymous> (onnx.min.js:16021)
    at onnx.min.js:15953
    at Object.next (onnx.min.js:15966)
    at a (onnx.min.js:15854)

I suspect that this has to do with BatchNormalization only being supported in opsets v7+ (the error indicates that the package is utilizing opset v6). However, per documentation it seems that version 0.1.7 of this package utilizes opset v7. I'm using a webgl backend in browser (Chrome).