**Feature request**: I'd love the ability to extract html from a CSS selector. Currently it seems there's no good way to do so. Perhaps like so:

```js
const extractedHtml = new HTMLRewriter().on('#my-id', {
  element(e) {
    e.extract();
  }
}).transform(response);
```

Not sure that'd be the most appropriate syntax given the nature of extracting vs. modifying/removing.

More context: https://community.cloudflare.com/t/htmlrewriter-extract-and-serve-single-dom-node/136769

We don't use it anywhere besides tests
Figure out the performance consequences of making content handlers `async`

We can expose the buffer size that we use for decoding text chunks.

Smaller size means text handler will be called more times with a smaller value, big size means text handler called less but with a bigger value.

One idea would be to use a LazyCell that will eventually hold the buffer. It integrates with the memory_limiter (which means allocation can fail). If the worker doesn't register any text handler the buffer and allocation will be skiped.
Currently we have a latency problem in the rewriter: we try to do as less work as possible in parser and flush content only when we produce tokens. This introduces latency problem: if we don't have any content that we need to rewrite in the chunk we wait for the whole chunk to be parsed before flushing it.

We can have few heuristics to improve it: for first chunk flush on `</head>`, for the remaining chunks flush based on time remained from the last flush.

We need to make all these heuristics adjustable via settings, to experiment with different parameters based on RUM. @sejoker working on that at the moment.
For proper CSS selector matching we need to maintain an open element stack. Then parser parses foreign content (`<svg>` or `<math>` elements and their content) self-closing flag of start tags has effect on the structure of the DOM-tree (it is ignored for the regular HTML).

So, currently we don't have any other choice than switching to lexer if we are in foreign content, because we need to consume whole start tag to check a self-closing flag. This leads to an unnecessary buffering and SVG tags tend to be quite big.

We can avoid this situation by providing additional event in tag scanner which will be invoked when scanner encounters an end of the start tag tells if self-closing flag is present.
Currently, if element modification involves rewriting of the end tag (e.g. `el.set_tag_name`) we implicitly create an end tag handler. This causes parser to run in the lexer mode in the search of the end tag.

This causes problem when we try to modify an end tag that covers the majority of the content of the page. E.g., if `el` is a `body` element:
```rust
el.append("foo", ContentType::Text);
```
will cause parser to run in the lexer mode for almost the whole page, even though we are interested only in the end tag to insert content before it.

If we need only an end tag we can keep parser running in the tag scanner mode and switch it to the lexer only if current end tag matched by a selector and we need to invoke a handler for it.
Currently, we need to decode all the incoming text chunks in the selector scope if text handler is assigned. This requirement comes from the fact that chunks that are fed to the rewriter may not contain a full sequence of valid bytes in the given encoding.

However, considering that we operate only with ASCII-compatible encodings, we can perform check for non-ASCII characters in parser. And, if we don't find any, just use `str::from_utf8_unchecked` instead of actual decoding.