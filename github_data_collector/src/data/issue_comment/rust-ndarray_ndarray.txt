I asked this question on reddit, but I didn't get any response over there. I'm currently using ndarray for a project of mine and one thing I need to quite frequently is to mutate the contents of two or more columns/rows based on each others contents. It isn't always the case that both lanes need to be mutable, but they usually need to be. I've figured out how to do it with `ndarray::Zip` and `iter_axis_mut` as follows
```rust
pub fn apply_two_lanes<T, F>(
    arr: &mut Array2<T>,
    axis: Axis,
    l1: usize,
    l2: usize,
    f: F,
) where
    F: Fn(&mut T, &mut T),
{
    assert_ne!(l1, l2);

    let mut lanes = arr.axis_iter_mut(axis);
    let (lane1, lane2) = if l1 < l2 {
        (lanes.nth(l1).unwrap(), lanes.nth(l2 - l1 - 1).unwrap())
    } else {
        let (lane2, lane1) =
            (lanes.nth(l2).unwrap(), lanes.nth(l1 - l2 - 1).unwrap());
        (lane1, lane2)
    };
    ndarray::Zip::from(lane1).and(lane2).apply(f);
}
```
However, as you can see, because I don't know if `l1` or `l2` comes first, I need the additional if test. I haven't managed to figure out how to do the above without some manner of checking of the ordering of `l1` and `l2`. Is there a way to accomplish the above without having to check which index is first?
I'm using ndarray for a project that I'm currently working on. I required to replace NaNs in a 1d array and I've recreated a similar function to [pandas ffill](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ffill.html).

I can share the code if this is something that might be helpful for ndarray?
Hi,

I'm just trying to get a sense of the level of interest from the ndarray developers regarding adopting the [Apache Arrow memory layout and padding](https://arrow.apache.org/docs/format/Columnar.html#buffer-alignment-and-padding).

I have been wanting to build integrations between Arrow and ndarray for some time.  Today it should be easy enough to build a zero-copy converter to ndarray types.  Arrow has a tensor type and this could be converted (with the optional names for dimensions in Arrow dropped).

However, without guarantees over the memory alignment and padding assumptions you could not go back to Arrow with zero-copy.  The easiest way to do this would be for ndarray to use the [Arrow functions that allocate memory](https://github.com/apache/arrow/blob/master/rust/arrow/src/memory.rs) through the Arrow [Buffer](https://github.com/apache/arrow/blob/master/rust/arrow/src/buffer.rs) type.

Arrow is attempting to make integrations between crates easier, I noticed [this](https://github.com/LukeMathWalker/linfa/issues/15) issue today.  This is the kind of issue we could avoid.

In general, I think that Arrow and ndarray fit together quite nicely where Arrow could provide alot of help processing data and ndarray provides all the algorithms once data is cleaned and in-memory.

I'm not very familiar with the ndarray codebase, if this sounds like a good idea could you point me to where you allocate memory etc. and any other information that might help?

Previously, the first paragraph of the docs indicated that any contiguous array was accepted, while the second paragraph indicated that only c- or f-contiguous arrays were accepted. The second paragraph is correct. This commit fixes the description in the first paragraph to match.

Fixes #766.
Apparently ArrayBase::all_close() has been deprecated in favor of approx crate and feature. 
I think this new method brings unnecessary complications to the workflow i.e. extra crate must be included and feature must be enabled by hand in Cargo.toml. So my question is: Is the deprecation really worth the benefits it brings? Or why is it deprecated at all?

There are lots of:

```
extern crate num_traits;
use self::num_traits::*;
```

Needed.

Same for `rawpointers` and `num_integers`.

This is on the master branch.
Are there any plans to add simple moving average to a 1-D array or at an axis level?
Currently if we need to do elementwise operation on array, we can create a result array, and wrap it together with parameters arrays in `Zip` and use `apply` to assign the result. However, since `Zip` have the shape information, can we add a helper function to allocate a result array with correct shape, so that we don't need to create the result array manually?
As adviced by @jturner314 in #749, I now use `as_slice_memory_order` in `zip_mut_with_same_shape` for same-order arrays. (I also wanted to optimize `zip_indexed` but it's more complex so I'll probably do it later)

I modified `zip_mut_with_same_shape` more than I intended at first because there were some useless statements. At that point, we have same-shape arrays, so they have the same length, which make the slicing useless.

The bench I added show that 'cc' is not slower than it was and 'ff' is as fast as 'cc'. On windows and WSL.
This PR implements `std` and `var` methods (see: #655) using the same method as used for `var_axis`, `std_axis`.
The variance is computed by flattening the array of N dimensions into a 1D array of the length `.len()` of the original array.

The return type is scalar A instead of Array<A, D:Smaller>

An attempt was made to refactor `var_axis` to use `var`, but this resulted in a performance regression so original implementation is kept and we accept some code duplication. :stuck_out_tongue: 

```rust
pub fn var_axis(&self, axis: Axis, ddof: A) -> Array<A, D::Smaller>
where
    A: Float + FromPrimitive,
    D: RemoveAxis,
{
    let mut sum_sq = Array::<A, D::Smaller>::zeros(self.dim.remove_axis(axis));

    for (lane, sum) in self.lanes(axis).into_iter().zip(sum_sq.iter_mut()) {
        *sum = lane.var(ddof);
    }
    sum_sq
}
```

Thanks @LukeMathWalker for the mentoring. :grinning: 