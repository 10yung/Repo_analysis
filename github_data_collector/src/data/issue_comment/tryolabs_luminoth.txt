Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 1.5.0 to 1.15.0.
<details>
<summary>Release notes</summary>

*Sourced from [tensorflow's releases](https://github.com/tensorflow/tensorflow/releases).*

> ## TensorFlow 1.15.0
> # Release 1.15.0
> This is the last 1.x release for TensorFlow. We do not expect to update the 1.x branch with features, although we will issue patch releases to fix vulnerabilities for at least one year.
> 
> ## Major Features and Improvements
> * As [announced](https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/iRCt5m4qUz0), `tensorflow` pip package will by default include GPU support (same as `tensorflow-gpu` now) for the platforms we currently have GPU support (Linux and Windows). It will work on machines with and without Nvidia GPUs. `tensorflow-gpu` will still be available, and CPU-only packages can be downloaded at `tensorflow-cpu` for users who are concerned about package size.
> * TensorFlow 1.15 contains a complete implementation of the 2.0 API in its `compat.v2` module. It contains a copy of the 1.15 main module (without `contrib`) in the `compat.v1` module. TensorFlow 1.15 is able to emulate 2.0 behavior using the `enable_v2_behavior()` function.
> This enables writing forward compatible code: by explicitly importing either `tensorflow.compat.v1` or `tensorflow.compat.v2`, you can ensure that your code works without modifications against an installation of 1.15 or 2.0.
> * `EagerTensor` now supports numpy buffer interface for tensors.
> * Add toggles `tf.enable_control_flow_v2()` and `tf.disable_control_flow_v2()` for enabling/disabling v2 control flow.
> * Enable v2 control flow as part of `tf.enable_v2_behavior()` and `TF2_BEHAVIOR=1`.
> * AutoGraph translates Python control flow into TensorFlow expressions, allowing users to write regular Python inside `tf.function`-decorated functions. AutoGraph is also applied in functions used with `tf.data`, `tf.distribute` and `tf.keras` APIS.
> * Adds `enable_tensor_equality()`, which switches the behavior such that: 
>   * Tensors are no longer hashable.
>   * Tensors can be compared with `==` and `!=`, yielding a Boolean Tensor with element-wise comparison results. This will be the default behavior in 2.0.
> * Auto Mixed-Precision graph optimizer simplifies converting models to `float16` for acceleration on Volta and Turing Tensor Cores. This feature can be enabled by wrapping an optimizer class with `tf.train.experimental.enable_mixed_precision_graph_rewrite()`.
> * Add environment variable `TF_CUDNN_DETERMINISTIC`. Setting to "true" or "1" forces the selection of deterministic cuDNN convolution and max-pooling algorithms. When this is enabled, the algorithm selection procedure itself is also deterministic.
> * TensorRT
>   * Migrate TensorRT conversion sources from contrib to compiler directory in preparation for TF 2.0.
>   * Add additional, user friendly `TrtGraphConverter` API for TensorRT conversion.
>   * Expand support for TensorFlow operators in TensorRT conversion (e.g.
>     `Gather`, `Slice`, `Pack`, `Unpack`, `ArgMin`, `ArgMax`,`DepthSpaceShuffle`). 
>   * Support TensorFlow operator `CombinedNonMaxSuppression` in TensorRT conversion which 
>      significantly accelerates object detection models.
> 
> ## Breaking Changes
> * Tensorflow code now produces 2 different pip packages: `tensorflow_core` containing all the code (in the future it will contain only the private implementation) and `tensorflow` which is a virtual pip package doing forwarding to `tensorflow_core` (and in the future will contain only the public API of tensorflow). We don't expect this to be breaking, unless you were importing directly from the implementation.
> * TensorFlow 1.15 is built using devtoolset7 (GCC7) on Ubuntu 16. This may lead to ABI incompatibilities with extensions built against earlier versions of TensorFlow.
> * Deprecated the use of `constraint=` and `.constraint` with ResourceVariable.
> * `tf.keras`:
>   * `OMP_NUM_THREADS` is no longer used by the default Keras config. To configure the number of threads, use `tf.config.threading` APIs.
>   * `tf.keras.model.save_model` and `model.save` now defaults to saving a TensorFlow SavedModel.
>   * `keras.backend.resize_images` (and consequently, `keras.layers.Upsampling2D`) behavior has changed, a bug in the resizing implementation was fixed.
>   * Layers now default to `float32`, and automatically cast their inputs to the layer's dtype. If you had a model that used `float64`, it will probably silently use `float32` in TensorFlow2, and a warning will be issued that starts with Layer "layer-name" is casting an input tensor from dtype float64 to the layer's dtype of float32. To fix, either set the default dtype to float64 with `tf.keras.backend.set_floatx('float64')`, or pass `dtype='float64'` to each of the Layer constructors. See `tf.keras.layers.Layer` for more information.
>   * Some `tf.assert_*` methods now raise assertions at operation creation time (i.e. when this Python line executes) if the input tensors' values are known at that time, not during the session.run(). When this happens, a noop is returned and the input tensors are marked non-feedable. In other words, if they are used as keys in `feed_dict` argument to `session.run()`, an error will be raised. Also, because some assert ops don't make it into the graph, the graph structure changes. A different graph can result in different per-op random seeds when they are not given explicitly (most often).
> 
> ## Bug Fixes and Other Changes
> * `tf.estimator`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to `tf.train.Checkpoint` format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Fix tests in canned estimators.
>   * Expose Head as public API.
>   * Fixes critical bugs that help with `DenseFeatures` usability in TF2
> * `tf.data`:
>   * Promoting `unbatch` from experimental to core API.
>   * Adding support for datasets as inputs to `from_tensors` and `from_tensor_slices` and batching and unbatching of nested datasets.
> * `tf.keras`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to tf.train.Checkpoint format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Saving a Keras Model using `tf.saved_model.save` now saves the list of variables, trainable variables, regularization losses, and the call function.
>   * Deprecated `tf.keras.experimental.export_saved_model` and `tf.keras.experimental.function`. Please use `tf.keras.models.save_model(..., save_format='tf')` and `tf.keras.models.load_model` instead.
>   * Add an `implementation=3` mode for `tf.keras.layers.LocallyConnected2D` and `tf.keras.layers.LocallyConnected1D` layers using `tf.SparseTensor` to store weights,  allowing a dramatic speedup for large sparse models.
></tr></table> ... (truncated)
</details>
<details>
<summary>Changelog</summary>

*Sourced from [tensorflow's changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md).*

> # Release 1.15.0
> This is the last 1.x release for TensorFlow. We do not expect to update the 1.x branch with features, although we will issue patch releases to fix vulnerabilities for at least one year. 
> 
> ## Major Features and Improvements
> * As [announced](https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/iRCt5m4qUz0), `tensorflow` pip package will by default include GPU support (same as `tensorflow-gpu` now) for the platforms we currently have GPU support (Linux and Windows). It will work on machines with and without Nvidia GPUs. `tensorflow-gpu` will still be available, and CPU-only packages can be downloaded at `tensorflow-cpu` for users who are concerned about package size.
> * TensorFlow 1.15 contains a complete implementation of the 2.0 API in its `compat.v2` module. It contains a copy of the 1.15 main module (without `contrib`) in the `compat.v1` module. TensorFlow 1.15 is able to emulate 2.0 behavior using the `enable_v2_behavior()` function.
> This enables writing forward compatible code: by explicitly importing either `tensorflow.compat.v1` or `tensorflow.compat.v2`, you can ensure that your code works without modifications against an installation of 1.15 or 2.0.
> * EagerTensor now supports numpy buffer interface for tensors.
> * Add toggles `tf.enable_control_flow_v2()` and `tf.disable_control_flow_v2()` for enabling/disabling v2 control flow.
> * Enable v2 control flow as part of `tf.enable_v2_behavior()` and `TF2_BEHAVIOR=1`.
> * AutoGraph translates Python control flow into TensorFlow expressions, allowing users to write regular Python inside `tf.function`-decorated functions. AutoGraph is also applied in functions used with `tf.data`, `tf.distribute` and `tf.keras` APIS.
> * Adds `enable_tensor_equality()`, which switches the behavior such that: 
>   * Tensors are no longer hashable.
>   * Tensors can be compared with `==` and `!=`, yielding a Boolean Tensor with element-wise comparison results. This will be the default behavior in 2.0.
> 
> ## Breaking Changes
> * Tensorflow code now produces 2 different pip packages: `tensorflow_core` containing all the code (in the future it will contain only the private implementation) and `tensorflow` which is a virtual pip package doing forwarding to `tensorflow_core` (and in the future will contain only the public API of tensorflow). We don't expect this to be breaking, unless you were importing directly from the implementation.
> * TensorFlow 1.15 is built using devtoolset7 (GCC7) on Ubuntu 16. This may lead to ABI incompatibilities with extensions built against earlier versions of TensorFlow.
> * Deprecated the use of `constraint=` and `.constraint` with ResourceVariable.
> * `tf.keras`:
>   * `OMP_NUM_THREADS` is no longer used by the default Keras config. To configure the number of threads, use `tf.config.threading` APIs.
>   * `tf.keras.model.save_model` and `model.save` now defaults to saving a TensorFlow SavedModel.
>   * `keras.backend.resize_images` (and consequently, `keras.layers.Upsampling2D`) behavior has changed, a bug in the resizing implementation was fixed.
>   * Layers now default to `float32`, and automatically cast their inputs to the layer's dtype. If you had a model that used `float64`, it will probably silently use `float32` in TensorFlow2, and a warning will be issued that starts with Layer "layer-name" is casting an input tensor from dtype float64 to the layer's dtype of float32. To fix, either set the default dtype to float64 with `tf.keras.backend.set_floatx('float64')`, or pass `dtype='float64'` to each of the Layer constructors. See `tf.keras.layers.Layer` for more information.
>   * Some `tf.assert_*` methods now raise assertions at operation creation time (i.e. when this Python line executes) if the input tensors' values are known at that time, not during the session.run(). When this happens, a noop is returned and the input tensors are marked non-feedable. In other words, if they are used as keys in `feed_dict` argument to `session.run()`, an error will be raised. Also, because some assert ops don't make it into the graph, the graph structure changes. A different graph can result in different per-op random seeds when they are not given explicitly (most often).
> 
> ## Bug Fixes and Other Changes
> * `tf.estimator`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to `tf.train.Checkpoint` format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Fix tests in canned estimators.
>   * Expose Head as public API.
>   * Fixes critical bugs that help with `DenseFeatures` usability in TF2
> * `tf.data`:
>   * Promoting `unbatch` from experimental to core API.
>   * Adding support for datasets as inputs to `from_tensors` and `from_tensor_slices` and batching and unbatching of nested datasets.
> * `tf.keras`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to tf.train.Checkpoint format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Saving a Keras Model using `tf.saved_model.save` now saves the list of variables, trainable variables, regularization losses, and the call function.
>   * Deprecated `tf.keras.experimental.export_saved_model` and `tf.keras.experimental.function`. Please use `tf.keras.models.save_model(..., save_format='tf')` and `tf.keras.models.load_model` instead.
>   * Add an `implementation=3` mode for `tf.keras.layers.LocallyConnected2D` and `tf.keras.layers.LocallyConnected1D` layers using `tf.SparseTensor` to store weights,  allowing a dramatic speedup for large sparse models.
>   * Enable the Keras compile API `experimental_run_tf_function` flag by default. This flag enables single training/eval/predict execution path. With this 1. All input types are converted to `Dataset`. 2. When distribution strategy is not specified this goes through the no-op distribution strategy path. 3. Execution is wrapped in tf.function unless `run_eagerly=True` is set in compile.
>   * Raise error if `batch_size` argument is used when input is dataset/generator/keras sequence.
> * `tf.lite`
>   * Add `GATHER` support to NN API delegate.
>   * tflite object detection script has a debug mode.
>   * Add delegate support for `QUANTIZE`.
>   * Added evaluation script for COCO minival.
>   * Add delegate support for `QUANTIZED_16BIT_LSTM`.
>   * Converts hardswish subgraphs into atomic ops.
> * Add support for defaulting the value of `cycle_length` argument of `tf.data.Dataset.interleave` to the number of schedulable CPU cores.
></tr></table> ... (truncated)
</details>
<details>
<summary>Commits</summary>

- [`590d6ee`](https://github.com/tensorflow/tensorflow/commit/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b) Merge pull request [#31861](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/31861) from tensorflow-jenkins/relnotes-1.15.0rc0-16184
- [`b27ac43`](https://github.com/tensorflow/tensorflow/commit/b27ac431aa37cfeb9d5c35cc50081cdb6763a40e) Update RELEASE.md
- [`07bf663`](https://github.com/tensorflow/tensorflow/commit/07bf6634f602757ef0b2106a92c519d09e80157e) Merge pull request [#33213](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33213) from Intel-tensorflow/mkl-dnn-0.20.6
- [`46f50ff`](https://github.com/tensorflow/tensorflow/commit/46f50ff8a0f099269ac29573bc6ac09d1bc6cab7) Merge pull request [#33262](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33262) from tensorflow/ggadde-1-15-cp2
- [`49c154e`](https://github.com/tensorflow/tensorflow/commit/49c154e17e9fdfe008f8b0b929d1a729e5939c51) Merge pull request [#33263](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33263) from tensorflow/ggadde-1-15-final-version
- [`a16adeb`](https://github.com/tensorflow/tensorflow/commit/a16adeb793b587a08958a72cbbf0d338e063a042) Update TensorFlow version to 1.15.0 in preparation for final relase.
- [`8d71a87`](https://github.com/tensorflow/tensorflow/commit/8d71a87b0e3de6d07588f9139660a77271d12498) Add saving of loaded/trained compatibility models in test and fix a compatibi...
- [`8c48aff`](https://github.com/tensorflow/tensorflow/commit/8c48affdf8ec0e5a9c5252f88e63aa5b97daf239) [Intel Mkl] Upgrading MKL-DNN to 0.20.6 to fix SGEMM regression
- [`38ea9bb`](https://github.com/tensorflow/tensorflow/commit/38ea9bbfea423eb968fcc70bc454471277c9537c) Merge pull request [#33120](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33120) from tensorflow/perf
- [`a8ef0f5`](https://github.com/tensorflow/tensorflow/commit/a8ef0f5d3bff3fe6f46b821832a4e9073dd7c01d) Automated rollback of commit db7e43192d405973c6c50f6e60e831a198bb4a49
- Additional commits viewable in [compare view](https://github.com/tensorflow/tensorflow/compare/v1.5.0...v1.15.0)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tensorflow&package-manager=pip&previous-version=1.5.0&new-version=1.15.0)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/tryolabs/luminoth/network/alerts).

</details>
I can predict in a dataset on top level of a folder, it's a great feature of Luminoth, but can I predict over all subfolders in a recursively way?
I imagine something like:
`lumi predict -r .`

Maybe it's not de purpose of this tool, then is there a way to do this in bash?
I want to modify the VGG layers (by changing some of them to atrous convolution) and am wondering if this library supports that? If so what is the best way on how to do that (I already have an idea but am curious if you guys who know the code know the best way)? 

After modifying the layers I'm also going to use the feature map from an earlier one but I know this is already supported because I read the code. 

Thank you very much people for beautiful clean library. I read the article on how frcnn works and ever since then I never forget.
I made a model using Luminoth, and it works well. But now I have to use the model.
In local, i used a python script :
`detector = Detector(checkpoint='GoogleModel')`
`result = detector.predict(image)`

All work well ! But now I have to use it on a webpage, so I used WampServer to make it in local.
A php file call the python script, but I have the error "Checkpoint not found. Check remote repository? [y/N]:".

I think it's because all my checkpoints are in local, but i don't know how use them online.
I tought download Luminoth on the WampServer and import the checkpoint but I don't know how do that.

Thank you for your help
The "--only-classes" option is not filtering out the classes I desire. Currently I have the following:

`lumi dataset transform --type pascal --data-dir datasets/pascal/2007/VOCdevkit/VOC2007/ --output-dir datasets/pascal/tf/2007/ --split train  --only-classes=car`

However, all classes are being read according to what is being outputted to my screen: 
```
I0814 18:33:38.137515 140095359665984 object_detection_writer.py:95] Saved 2501 records to "datasets/pascal/tf/2007/train.tfrecords"
I0814 18:33:38.137785 140095359665984 transform.py:65] Composition per class (train):
I0814 18:33:38.137905 140095359665984 transform.py:68]  person: 2705
I0814 18:33:38.137994 140095359665984 transform.py:68]  car: 826
I0814 18:33:38.138073 140095359665984 transform.py:68]  chair: 726
I0814 18:33:38.138149 140095359665984 transform.py:68]  bottle: 338
I0814 18:33:38.138223 140095359665984 transform.py:68]  pottedplant: 305
I0814 18:33:38.138297 140095359665984 transform.py:68]  bird: 294
I0814 18:33:38.138370 140095359665984 transform.py:68]  dog: 271
I0814 18:33:38.138443 140095359665984 transform.py:68]  sofa: 218
I0814 18:33:38.138517 140095359665984 transform.py:68]  boat: 208
I0814 18:33:38.138589 140095359665984 transform.py:68]  horse: 207
I0814 18:33:38.138692 140095359665984 transform.py:68]  bicycle: 202
I0814 18:33:38.138776 140095359665984 transform.py:68]  motorbike: 193
I0814 18:33:38.138851 140095359665984 transform.py:68]  cat: 191
I0814 18:33:38.138925 140095359665984 transform.py:68]  tvmonitor: 191
I0814 18:33:38.138999 140095359665984 transform.py:68]  sheep: 191
I0814 18:33:38.139070 140095359665984 transform.py:68]  cow: 185
I0814 18:33:38.139151 140095359665984 transform.py:68]  train: 158
I0814 18:33:38.139223 140095359665984 transform.py:68]  aeroplane: 156
I0814 18:33:38.139295 140095359665984 transform.py:68]  diningtable: 148
I0814 18:33:38.139367 140095359665984 transform.py:68]  bus: 131
```



lumi checkpoint info <id or alias> -config

displays the config info
The base_config.yml includes these options, under model: base_network:    

    # From which file to load the weights.
    weights:
    # Should we download weights if not available.
    download: True

As far as I can tell, these are not used in the code. What is the intended use of these settings? Is there any way to specify the location of the base network checkpoint, besides changing the LUMI_HOME environment variable to set a different default path? 
I have trained a **Faster R-CNN** model (including the final RCNN module). Now the final output contains bounding boxes and class probabilities. But I want to know the _class-independent_ bounding boxes and their _objectness scores_ (which is what the RPN module gives) from the same model. Can anyone help me how to get them in Luminoth?

Any help is much appreciated!
We have a special dataset about extreme weather. The dataset has 16 channels and the size of the image is 1000*700px, which is totally different from the ImageNet. We want to implement end to end training based on this dataset.
The Faster-RCNN is composed of three parts: base network + RPN + RCNN. The base network usually is a pre-trained CNN(e.g. ResNet , VGG) for extracting features, but only ImageNet-based pre-trained model can be found because our dataset is not common. So, the question is can we implement end to end training without a pre-trained base network? Or, does the end-to-end training of Faster-RCNN include the parameters in the base network? I have seen many works about end-to-end training, but they all use the pre-trained model as their base network and seems only train the RPN and RCNN. 
Hey, 
Firstly this is cool project!
I read that you've plans to implement Retinanet and MaskRCNN. If anyone is working on this i'd like to collaborate on it. If not, then I can try implementing these. 
I need a green signal from the maintainers to get started.

Thanks,
Christie

