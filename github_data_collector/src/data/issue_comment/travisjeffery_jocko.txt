Handle topic array length when it's -1
And adds some fields to the metadata response

closes #159
The protocol/api_versions.go says it supports metadata v 0..1 but it doesn't handle metadata requests where topic length is set to -1 (which is allowed in v1). 
It's also missing `rack` string for each broker and an internal flag for each topic in the metadata response.
This should fix CI ðŸ¤ž 
Will the project ever be moved to an organization dedicated to maintaining it and doing bug fixes? What is the long-term vision for it?

I really like the goals but it looks like it needs to gather a more robust community around it...
Fixes `protocol.CoordinatorTransaction` value plus error simplification. 
Hi

Just playing around with jocko. I tried pulling an image with

```
docker pull travisjeffery/jocko:latest
```

However it cannot find the image. Is there an image deployed anywhere, such as docker hub maybe?
Using both kafkacat and Sarama, I get errors both trying to subscribe to a topic and trying to publish.

(Topic was created)

```
mhiles@ln-mhiles > echo test | kafkacat -P -b localhost:9092 -c 1 -t auto-alert-raw
%3|1545247547.398|PROTOERR|rdkafka#producer-1| [thrd:main]: localhost:9092/bootstrap: Protocol parse failure at 31/77 (rd_kafka_parse_Metadata:299) (incorrect broker.version.fallback?)
%3|1545247547.398|PROTOERR|rdkafka#producer-1| [thrd:main]: localhost:9092/bootstrap: 65536 topics: tmpabuf memory shortage
%3|1545247548.287|PROTOERR|rdkafka#producer-1| [thrd:main]: localhost:9092/bootstrap: Protocol parse failure at 31/77 (rd_kafka_parse_Metadata:299) (incorrect broker.version.fallback?)

```

More or less the same story for consuming with kafkacat.

With sarama trying to publish I get this error:

```
kafka: insufficient data to decode packet, more bytes expected
```

Does jocko support compression? We're using 

```
config.Producer.Compression = sarama.CompressionSnappy
```

Although I just tried disabling it and still see the same error message.

Trying to subscribe to a topic, I get this error:

```
kafka server: Unexpected (unknown?) server error.
```

We use kafka for prod and I was really hoping I could get jocko working for dev/testing purposes. 
now have not record test coverage
Wrote a test for it, haven't determined if it's an issue with the index, or the what is written to the disk. If i'm doing something wrong, please let me know. Thanks!

```
func TestFailureInCommitLog(t *testing.T) {
	ff := func (err error) {
		if err != nil {
			panic(err.Error())
		}
	}
	path, err := ioutil.TempDir("", "commitlogtest")
	ff(err)
	os.RemoveAll(path)

	l := setupWithOptions(t, commitlog.Options{
		MaxSegmentBytes: 1024,
		MaxLogBytes:     -1,
	})
	defer cleanup(t, l)

	var offsets []int64
	var size int32
	for i := 0; i < 100; i++ {
		s := fmt.Sprintf("%d", i)
		bytes := []byte(s)

		ms := commitlog.NewMessageSet(uint64(i), commitlog.NewMessage(bytes))
		size = ms.Size()
		offset, err := l.Append(ms)
		offsets = append(offsets, offset)
		require.Equal(t, int64(i), offset)
		ff(err)
	}

	fmt.Println("about to read")
	b := make([]byte, size)
	for _, i := range offsets {
		rdr, err := l.NewReader(i, 0)
		ff(err)
		_, err = rdr.Read(b)
		ff(err)
		size := commitlog.MessageSet(b).Size()
		act := commitlog.MessageSet(b[:size])
		fmt.Println(i, act.Offset(), string(act.Payload()))
		require.Equal(t, int64(i),  act.Offset())
	}
}
```
Comparison benchmark vs kafka etc?