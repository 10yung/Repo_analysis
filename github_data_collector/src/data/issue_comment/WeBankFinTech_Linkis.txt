closes #271
**Is your feature request related to a problem? Please describe.**
Now, the metadata service depends on hive, which causes jar package conflicts when modifying the hive version

**Describe the solution you'd like**
1. Remove hive dependency related code and replace it with query DB operation
2. Specify the hive meta information as required in the install script

**Describe alternatives you've considered**
no

**Additional context**
no

我们的环境：

> 平台环境：ResourceManager version:2.6.1-adh2.4.4, Hadoop version:2.6.1-adh2.4.4
> Spark版本：2.4.4
> Hive版本：2.3.6

使用的Linkis版本：0.9.2

安装精简版的已经测试通过，可以使用scripts提交python脚本执行了，现在要安装标准版。

在编译时修改pom.xml文件如下：
```
        <hadoop.version>2.6.1</hadoop.version>
        <hive.version>2.3.6</hive.version>
```

没有找到修改spark版本的地方。。。

编译没有报错，按照wiki给出的方式执行，如下：

```
mvn -N  install
mvn clean install
```

把jar包： `wedatasphere-linkis-0.9.2-dist.tar.gz` 上传上去后安装启动，
发现启动linkis-metadata时出现异常如下：

![屏幕快照 2020-01-17 上午10 36 35](https://user-images.githubusercontent.com/16011475/72579880-5b796400-3915-11ea-8a90-a6ca3710bef9.png)

查看linkis-metadata中有关log的jar包，如下：
![屏幕快照 2020-01-17 上午10 39 09](https://user-images.githubusercontent.com/16011475/72579978-9d0a0f00-3915-11ea-8a20-dcd637cb09ec.png)

查看module下有关log的jar包如下：

![屏幕快照 2020-01-17 上午10 40 03](https://user-images.githubusercontent.com/16011475/72580025-bd39ce00-3915-11ea-986a-f4a095628a80.png)

两者的版本号不一致，曾尝试把两者的log4j版本都统一成2.6.2或2.10.0都没有成功。
repair wrong package name
**Describe the bug**
linkis-metadata start failed, java.lang.VerifyError: Cannot inherit from final class

**To Reproduce**
Steps to reproduce the behavior:
1.  setup all conf 
2. ./bin/start-all.sh > start.log 2>start_error.log

**Detail messages**
```
Start to Check if your microservice:linkis-metadata is normal via telnet
ERROR your linkis-metadata microservice is not start successful !!! ERROR logs as follows :
PLEAESE CHECK  DETAIL LOG,LOCATION:/opt/linkis-0.9.2/linkis-metadata/logs/linkis.out
<---------------------------------------------------->
Is local 0
2020-01-15 10:19:51,626 INFO  (background-preinit) INFO Version - HV000001: Hibernate Validator 5.1.2.Final
2020-01-15 10:19:52,922 INFO  (main) INFO AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@495083a0: startup date [Wed Jan 15 10:19:52 CST 2020]; root of context hierarchy
2020-01-15 10:19:53,903 INFO  (main) INFO AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2020-01-15 10:19:54,075 INFO  (main) INFO PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$ca25fa00] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.0.3.RELEASE)

2020-01-15 10:19:55,297 ERROR (main) ERROR SpringApplication - Application run failed
java.lang.VerifyError: Cannot inherit from final class
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:763)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
        at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        at com.fasterxml.jackson.datatype.jdk8.Jdk8Module.setupModule(Jdk8Module.java:30)
        at com.fasterxml.jackson.databind.ObjectMapper.registerModule(ObjectMapper.java:524)
        at org.springframework.http.converter.json.Jackson2ObjectMapperBuilder.registerWellKnownModulesIfAvailable(Jackson2ObjectMapperBuilder.java:734)
        at org.springframework.http.converter.json.Jackson2ObjectMapperBuilder.configure(Jackson2ObjectMapperBuilder.java:624)
        at org.springframework.http.converter.json.Jackson2ObjectMapperBuilder.build(Jackson2ObjectMapperBuilder.java:608)
        at org.springframework.http.converter.json.MappingJackson2HttpMessageConverter.<init>(MappingJackson2HttpMessageConverter.java:59)
        at org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter.<init>(AllEncompassingFormHttpMessageConverter.java:74)
        at org.springframework.web.client.RestTemplate.<init>(RestTemplate.java:179)
        at org.springframework.web.client.RestTemplate.<init>(RestTemplate.java:218)
        at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getSecureRestTemplate(ConfigServicePropertySourceLocator.java:256)
        at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:83)
        at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:94)
        at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:633)
        at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:373)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:325)
        at com.webank.wedatasphere.linkis.DataWorkCloudApplication.main(DataWorkCloudApplication.java:105)
```
**Eurkea service**

BML-SERVER | n/a (1) | (1) | UP (1) -                         bml-server:9113
-- | -- | -- | --
CLOUD-PUBLICSERVICE | n/a (1) | (1) | UP (1) -                         cloud-publicservice:9102
DATAWORKCLOUD | n/a (1) | (1) | UP (1) -                         DataWorkCloud:20303
DATAWORKCLOUD-GATEWAY | n/a (1) | (1) | UP (1) -                         DataWorkCloud-Gateway:9001
HIVEENTRANCE | n/a (1) | (1) | UP (1) -                         hiveEntrance:9108
JDBCENTRANCE | n/a (1) | (1) | UP (1) -                         jdbcEntrance:9111
PYTHONENGINEMANAGER | n/a (1) | (1) | UP (1) -                         pythonEngineManager:9109
PYTHONENTRANCE | n/a (1) | (1) | UP (1) -                         pythonentrance:9110
RESOURCEMANAGER | n/a (1) | (1) | UP (1) -                         ResourceManager:9104
SPARKENGINEMANAGER | n/a (1) | (1) | UP (1) -                         sparkEngineManager:9105
SPARKENTRANCE | n/a (1) | (1) | UP (1) -                         sparkEntrance:9106


**Desktop (please complete the following information):**
 - OS: Red Hat 7.3
 - linkis-0.9.2 (baiduwangpan: wedatasphere-linkis-0.9.2-dist-CDH5.7.6-spark2.0-2.2.tar.gz )
- jdk1.8.0_181


Hi, I am following the Getting Started of Linkis.
All the prerequisites are satisfied. Build and installation of the package didn't give me any problems.
During the starting of the services

>     sh  ./bin/start-all.sh

I am getting this error message
>ERROR your linkis-metadata microservice is not start successful !!! ERROR logs as follows :
>...
>Caused by: java.lang.RuntimeException: Create hadoop configuration failed.

You can see the complete error message from the following screenshot.

![image](https://user-images.githubusercontent.com/7315359/72335904-0264c280-36c0-11ea-8c9a-382558c4fc2a.png)

My current settings are the following:
- OS: Ubuntu 18.04
- Mysql 5.5.28
- Hadoop 2.7.2
- Hive 1.2.1

Moreover I can use hdfs, mysql and hive without any problems.


Thank you

1、ubuntu中执行该脚本要用bash命令而不是sh
2、脚本里似乎需要使用yum命令，而该命令在ubuntu系统中并不是默认存在的
3、同上脚本里需要dos2unix，ubuntu似乎也不支持。
4、似乎ubuntu在~目录下并不存在.bash_profile

暂时在ubuntu发现以上问题，希望开发团队可以测试下ubuntu兼容性，谢谢~
依赖hive-service thrift 协议进行coordinator和client通讯
运行spark报错
```
Caused by: java.lang.ClassNotFoundException: org.apache.htrace.Trace
```

问题原因：
CDH的Spark的classpath中引入的是/opt/cloudera/parcels/CDH/jars/htrace-core-3.0.4.jar，而这个版本的时候，htrace还是org.htrace，而3.1.0的时候已经贡献给Apache了，改叫org.apache.htrace了。
[参考地址](https://blog.csdn.net/leehbing/article/details/78479758)
运行spark sql 报错

Application run failed org.springframework.boot.web.server.WebServerException: Unable to start embedded Jetty server