Bumps `jackson.version` from 2.4.4 to 2.10.1.

Updates `jackson-annotations` from 2.4.4 to 2.10.1
<details>
<summary>Commits</summary>

- See full diff in [compare view](https://github.com/FasterXML/jackson/commits)
</details>
<br />

Updates `jackson-core` from 2.4.4 to 2.10.1
<details>
<summary>Commits</summary>

- [`60956fc`](https://github.com/FasterXML/jackson-core/commit/60956fccd24d6bdb66abb3182cb2234122039b7a) [maven-release-plugin] prepare release jackson-core-2.10.1
- [`05a025d`](https://github.com/FasterXML/jackson-core/commit/05a025d16b32bf69184811dcebae9e000a56e0cb) ...
- [`81a9952`](https://github.com/FasterXML/jackson-core/commit/81a9952a681f6f6e1fab6fa5216749cf75f4a7e9) prepare for 2.10.1
- [`ce0d5e1`](https://github.com/FasterXML/jackson-core/commit/ce0d5e10ddb290cdc6b107805fb15b5eed97f5f3) revert now unnecessary sonatype deploy plugin
- [`adf6fd0`](https://github.com/FasterXML/jackson-core/commit/adf6fd02a4aa0ba872f6857c6e1ac38d3b96c9dc) Add Sonatype deploy plugin to simplify releases
- [`7ca30ec`](https://github.com/FasterXML/jackson-core/commit/7ca30eccc96e8eb02bc6b1a4aab3d78c1bba1388) array index out of bounds in hex lookup ([#578](https://github-redirect.dependabot.com/FasterXML/jackson-core/issues/578))
- [`da5365e`](https://github.com/FasterXML/jackson-core/commit/da5365edc9b0644ed446ce8b227dadb62a8821e9) Fix [#578](https://github-redirect.dependabot.com/FasterXML/jackson-core/issues/578): non-blocking path still had potential problem, but changed method i...
- [`db0f586`](https://github.com/FasterXML/jackson-core/commit/db0f5860085425dbe08b3e2b81801fc0e5e62bba) ...
- [`243fadc`](https://github.com/FasterXML/jackson-core/commit/243fadc879345732a9a5bb18b2d587a0272e5ddc) Fix [#567](https://github-redirect.dependabot.com/FasterXML/jackson-core/issues/567)
- [`714df7b`](https://github.com/FasterXML/jackson-core/commit/714df7b5f3507d13ba7480c27b30e96d69fc076b) ...
- Additional commits viewable in [compare view](https://github.com/FasterXML/jackson-core/compare/jackson-core-2.4.4...jackson-core-2.10.1)
</details>
<br />

Updates `jackson-databind` from 2.4.4 to 2.10.1
<details>
<summary>Commits</summary>

- See full diff in [compare view](https://github.com/FasterXML/jackson/commits)
</details>
<br />

Updates `jackson-module-scala_2.10` from 2.4.4 to 2.10.1
<details>
<summary>Commits</summary>

- [`9abae8d`](https://github.com/FasterXML/jackson-module-scala/commit/9abae8d9b1d6734138be299c4f9f94ca19cff0aa) Setting version to 2.10.1
- [`380133f`](https://github.com/FasterXML/jackson-module-scala/commit/380133f974fc37ba0ada261697eb0f298459606e) jackson 2.10.1
- [`52ac832`](https://github.com/FasterXML/jackson-module-scala/commit/52ac8322421313279a0a9234cb82c25e831fd8fc) make test more robust by not relying on order of json elements
- [`574356d`](https://github.com/FasterXML/jackson-module-scala/commit/574356dcf72365857cfce9f0dc81b72d47171b64) add basic test for try
- [`f348186`](https://github.com/FasterXML/jackson-module-scala/commit/f348186a1220744404b206f04f0f29ad14837560) set version to 2.10.1-SNAPSHOT
- [`382deb1`](https://github.com/FasterXML/jackson-module-scala/commit/382deb1fd395910bf7a608c0a38a3cdac657a930) back to 2.10.0-SNAPSHOT builds
- [`a0c8d9c`](https://github.com/FasterXML/jackson-module-scala/commit/a0c8d9cb84ed38a449f69bf04fe0457aa87513bd) use scalatest in guava test
- [`81bdfdb`](https://github.com/FasterXML/jackson-module-scala/commit/81bdfdb68fa3646aa3abe4d7ab92e5e185df7ad7) prepare 2.10.0 release
- [`94215c3`](https://github.com/FasterXML/jackson-module-scala/commit/94215c37c00575a213e4d7e9fcdb0efdb20b926f) test with jackson 2.10.0-SNAPSHOT
- [`5f05875`](https://github.com/FasterXML/jackson-module-scala/commit/5f05875957824347a6160200cbc860eec317cd78) publish 2.10.0-SNAPSHOT
- Additional commits viewable in [compare view](https://github.com/FasterXML/jackson-module-scala/compare/jackson-module-scala-2.4.4...jackson-module-scala-2.10.1)
</details>
<br />

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/cloudera/livy/network/alerts).

</details>
19/07/30 14:42:28 ERROR SessionServlet$: internal error
java.lang.RuntimeException: java.io.IOException: Unable to connect to provided ports 10000~10010
	at org.apache.livy.rsc.Utils.propagate(Utils.java:60)
	at org.apache.livy.rsc.RSCClientFactory.createClient(RSCClientFactory.java:75)
	at org.apache.livy.LivyClientBuilder.build(LivyClientBuilder.java:124)
	at org.apache.livy.server.interactive.InteractiveSession$$anonfun$3.apply(InteractiveSession.scala:107)
	at org.apache.livy.server.interactive.InteractiveSession$$anonfun$3.apply(InteractiveSession.scala:77)
	at scala.Option.orElse(Option.scala:257)
	at org.apache.livy.server.interactive.InteractiveSession$.create(InteractiveSession.scala:77)
	at org.apache.livy.server.interactive.InteractiveSessionServlet.createSession(InteractiveSessionServlet.scala:56)
	at org.apache.livy.server.interactive.InteractiveSessionServlet.createSession(InteractiveSessionServlet.scala:40)
	at org.apache.livy.server.SessionServlet$$anonfun$16.apply(SessionServlet.scala:121)
	at org.apache.livy.server.SessionServlet$$anonfun$16.apply(SessionServlet.scala:120)
	at org.scalatra.ScalatraBase$class.org$scalatra$ScalatraBase$$liftAction(ScalatraBase.scala:270)
	at org.scalatra.ScalatraBase$$anonfun$invoke$1.apply(ScalatraBase.scala:265)
	at org.scalatra.ScalatraBase$$anonfun$invoke$1.apply(ScalatraBase.scala:265)
	at org.scalatra.ApiFormats$class.withRouteMultiParams(ApiFormats.scala:178)
	at org.apache.livy.server.JsonServlet.withRouteMultiParams(JsonServlet.scala:39)
	at org.scalatra.ScalatraBase$class.invoke(ScalatraBase.scala:264)
	at org.scalatra.ScalatraServlet.invoke(ScalatraServlet.scala:49)
	at org.scalatra.ScalatraBase$$anonfun$runRoutes$1$$anonfun$apply$8.apply(ScalatraBase.scala:240)
	at org.scalatra.ScalatraBase$$anonfun$runRoutes$1$$anonfun$apply$8.apply(ScalatraBase.scala:238)
	at scala.Option.flatMap(Option.scala:170)
	at org.scalatra.ScalatraBase$$anonfun$runRoutes$1.apply(ScalatraBase.scala:238)
	at org.scalatra.ScalatraBase$$anonfun$runRoutes$1.apply(ScalatraBase.scala:237)
	at scala.collection.immutable.Stream.flatMap(Stream.scala:446)
	at org.scalatra.ScalatraBase$class.runRoutes(ScalatraBase.scala:237)
	at org.scalatra.ScalatraServlet.runRoutes(ScalatraServlet.scala:49)
	at org.scalatra.ScalatraBase$class.runActions$1(ScalatraBase.scala:163)
	at org.scalatra.ScalatraBase$$anonfun$executeRoutes$1.apply$mcV$sp(ScalatraBase.scala:175)
	at org.scalatra.ScalatraBase$$anonfun$executeRoutes$1.apply(ScalatraBase.scala:175)
	at org.scalatra.ScalatraBase$$anonfun$executeRoutes$1.apply(ScalatraBase.scala:175)
	at org.scalatra.ScalatraBase$class.org$scalatra$ScalatraBase$$cradleHalt(ScalatraBase.scala:193)
	at org.scalatra.ScalatraBase$class.executeRoutes(ScalatraBase.scala:175)
	at org.scalatra.ScalatraServlet.executeRoutes(ScalatraServlet.scala:49)
	at org.scalatra.ScalatraBase$$anonfun$handle$1.apply$mcV$sp(ScalatraBase.scala:113)
	at org.scalatra.ScalatraBase$$anonfun$handle$1.apply(ScalatraBase.scala:113)
	at org.scalatra.ScalatraBase$$anonfun$handle$1.apply(ScalatraBase.scala:113)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at org.scalatra.DynamicScope$class.withResponse(DynamicScope.scala:80)
	at org.scalatra.ScalatraServlet.withResponse(ScalatraServlet.scala:49)
	at org.scalatra.DynamicScope$$anonfun$withRequestResponse$1.apply(DynamicScope.scala:60)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at org.scalatra.DynamicScope$class.withRequest(DynamicScope.scala:71)
	at org.scalatra.ScalatraServlet.withRequest(ScalatraServlet.scala:49)
	at org.scalatra.DynamicScope$class.withRequestResponse(DynamicScope.scala:59)
	at org.scalatra.ScalatraServlet.withRequestResponse(ScalatraServlet.scala:49)
	at org.scalatra.ScalatraBase$class.handle(ScalatraBase.scala:111)
	at org.scalatra.ScalatraServlet.org$scalatra$servlet$ServletBase$$super$handle(ScalatraServlet.scala:49)
	at org.scalatra.servlet.ServletBase$class.handle(ServletBase.scala:43)
	at org.apache.livy.server.SessionServlet.org$scalatra$MethodOverride$$super$handle(SessionServlet.scala:39)
	at org.scalatra.MethodOverride$class.handle(MethodOverride.scala:28)
	at org.apache.livy.server.SessionServlet.org$scalatra$GZipSupport$$super$handle(SessionServlet.scala:39)
	at org.scalatra.GZipSupport$$anonfun$handle$1.apply$mcV$sp(GZipSupport.scala:36)
	at org.scalatra.GZipSupport$$anonfun$handle$1.apply(GZipSupport.scala:19)
	at org.scalatra.GZipSupport$$anonfun$handle$1.apply(GZipSupport.scala:19)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at org.scalatra.DynamicScope$class.withResponse(DynamicScope.scala:80)
	at org.scalatra.ScalatraServlet.withResponse(ScalatraServlet.scala:49)
	at org.scalatra.DynamicScope$$anonfun$withRequestResponse$1.apply(DynamicScope.scala:60)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at org.scalatra.DynamicScope$class.withRequest(DynamicScope.scala:71)
	at org.scalatra.ScalatraServlet.withRequest(ScalatraServlet.scala:49)
	at org.scalatra.DynamicScope$class.withRequestResponse(DynamicScope.scala:59)
	at org.scalatra.ScalatraServlet.withRequestResponse(ScalatraServlet.scala:49)
	at org.scalatra.GZipSupport$class.handle(GZipSupport.scala:18)
	at org.apache.livy.server.interactive.InteractiveSessionServlet.org$scalatra$servlet$FileUploadSupport$$super$handle(InteractiveSessionServlet.scala:40)
	at org.scalatra.servlet.FileUploadSupport$class.handle(FileUploadSupport.scala:93)
	at org.apache.livy.server.interactive.InteractiveSessionServlet.handle(InteractiveSessionServlet.scala:40)
	at org.scalatra.ScalatraServlet.service(ScalatraServlet.scala:54)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:812)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:587)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
	at org.eclipse.jetty.server.Server.handle(Server.java:499)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257)
	at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Unable to connect to provided ports 10000~10010
	at org.apache.livy.rsc.rpc.RpcServer.<init>(RpcServer.java:101)
	at org.apache.livy.rsc.RSCClientFactory.ref(RSCClientFactory.java:92)
	at org.apache.livy.rsc.RSCClientFactory.createClient(RSCClientFactory.java:65)
	... 82 more



40个请求同时提交livy session，报错，是不是并发只能是10000-10010 ，同时并发数最多10个，这个可以修改吗，能不能增大并发数

Currently, Livy doesn't support LDAP Authentication from client(sparkmagic) to server(livy). We need to add LDAP authentication as that's preferable method due to security reasons. We won't be able to use Knox for this purpose. That is why I am raising this PR which contains LDAP authentication.

I am also adding config to disable batch endpoints. Due to security reasons, we don't want to keep batch endpoint open. I am adding config so that We can disable it.
Current LivyServer already supports SSL, but the functionality is not fully implemented, it cannot support client side authentication, also cannot specify advanced configurations. Also SSL support for Livy http client is missing.

So here propose to add a full functionality SSL support for Livy server and client.
*Changes Made:*
1. Added logs cacheing as config driven.
2. Fixed adding driver process logs livy logs for local and client mode in interactive mode.
Made code changes  for enabling multiple spark versions on Livy for spark batch jobs. User can pass sparkVersion on run time for batch jobs and SPARK_HOME and SPARK_CONF_DIR would be set  according to given sparkVersion.

Need to set path for livy.server.spark-home_$version in Livy.conf and those versions which are added would be supported. 

Assumption:
* bin/livy-env.sh will continue to have SPARK_HOME and SPARK_CONF_DIR which will be used as default spark version for batch and interactive

subprocess.call() commands in a PySpark snippet can potentially insert raw text into the sys_stdout in the fake_shell main(). This will then fail to be correctly parsed by PythonInterpreter in the sendRequest, as it will trigger a JsonParseException that is not caught. Added code to catch the JsonParseException and then retry reads of stdout until a valid line of JSON is reached, or 100 retries have been attempted.
Kerberos over http requires larger header sizes than the default,
or the HTTP Error 413 Request entity too large will be returned.
This patch increases the default for Livy to 128K and also allows
this to be configurable.
With LIVY-244, InteractiveSession bring in two session state, one is from yarn and another is from repl session, this bring the complexity of session state management compared to previous code. So here propose to simplify the state management code and unify these two states.
This PR propose to add a `SparkEnvironment` to isolate Spark's related configurations and libraries, also extend it to support multiple `SparkEnvironment` in LivyServer.

Why
---

Current Livy Supports different Sparks with one build, user could configure different spark home to choose the right Spark to run, but this still requires stopping LivyServer, updating configuration and restarting it. To further extend the usability of Livy, it would be better to support different Sparks in runtime, when user create a session, user could specify which Spark they wanted and Livy will pick right Spark and start application.

How to use
---

To enable it, we extend the Livy configurations to support multiple Spark profiles, user could configure:

```
livy.server.spark-env.default.spark-home = xxx or TEST_SPARK_HOME = xxx
livy.server.spark-env.default.spark-conf-dir = xxx or TEST_SPARK_CONF_DIR = xxx

and

livy.server.spark-env.production.spark-home = xxx or PRODUCTION_SPARK_HOME = xxx
livy.server.spark-env.production.spark-conf-dir = xxx or PRODUCTION_SPARK_CONF_DIR = xxx

```

Internally Livy will create two Spark environments "test" and "product", when user issue a session creation request, he could specify `sparkEnv` with "test" in JSON body. Livy will pick the right Spark environment and start application.

To be compatible with existing configuration and test, if user configured:

```
livy.server.spark-home = xxx or SPARK_HOME = xxx
```
This is equal to:

```
livy.server.spark-env.default.spark-home = xxx or DEFAULT_SPARK_HOME = xxx
```

Livy will treat these as "default" Spark environment. If user didn't specify `sparkEnv` in JSON body,  then the default one will be picked.

Implementation
---

To achieve this, I introduced a `SparkEnvironment` class, one LivyServer can have multiple `SparkEnvironment` based on configuration. Also I refactored the code to move Spark related codes into this class.

Limitation
---

Some configurations like spark master and deploy mode cannot be configured per Spark environment currently.

Works done and to be done
---

- [x] Code implementation for isolated spark environments.
- [x] Add unit tests.
- [x] Change launching scripts.
- [x] Change docs and configuration files.

Please review and suggest, thanks a lot.