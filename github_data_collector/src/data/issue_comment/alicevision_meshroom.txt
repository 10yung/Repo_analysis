**Describe the bug**
For [this set of photos](https://photos.app.goo.gl/4fpk2hbGuANhez1d9) it works fine. (108 photos each 8MB)
But for [this](https://photos.app.goo.gl/mVrDWMzxKgDTmr5UA) it fails with the following error. (191 photos each 8MB)

**To Reproduce**
```
./meshroom_photogrammetry --cache ~/MeshroomCacheDes07 --input ~/DemMorenaPixel/ --output ~/Out_DemMorenaPixel
```

**Log**

```
...
[19:20:01.532521][info] Create visibilities (62/190)
[19:20:02.373776][info] Create visibilities (63/190)
[19:20:03.075582][info] Visibilities created.
[19:20:03.079198][info] Compute max angle per point
[19:20:03.079209][info] angleFactor: 15
[19:20:06.345207][info] 400677 invalid points removed.
[19:20:06.983611][info] Filter by angle score and sim score
[19:20:06.983640][info] Build nanoflann KdTree index.
[19:20:08.639105][info] KdTree created for 7068817 points.
[19:20:09.303758][info] Filtering done.
[19:20:09.620360][info] 2896019 invalid points removed.
[19:20:09.850709][info] The number of points is below the max number of vertices.
[19:20:09.850740][info] 3D points loaded and filtered to 4172798 points (maxVertices is 5000000).
[19:20:09.850746][info] Create final visibilities
[19:20:10.755383][info] NANOFLANN: KdTree created.
[19:20:10.763677][info] Create visibilities (0/190)
[19:20:10.763702][info] Create visibilities (127/190)
[19:20:10.763717][info] Create visibilities (64/190)
...
[19:21:59.743710][info] Create visibilities (62/190)
[19:22:00.382480][info] Create visibilities (63/190)
[19:22:01.044536][info] Visibilities created.
[19:22:01.046813][info] fuseFromDepthMaps done: 4172798 points created.
[19:22:19.617412][info] 27095359 cells created by tetrahedralization.
[19:22:51.814679][info] coutInvalidVertices: 0
[19:22:51.814718][info] neighboringCellsPerVertexTmp: 4174129
[19:22:51.843078][info] verticesCoords: 4174129
[19:23:06.381526][info] Histogram of number of cams per point:
[19:23:06.381560][info]     0: 1331
[19:23:06.381581][info]     1: 0
[19:23:06.381585][info]     2: 168314
[19:23:06.381589][info]     3: 355577
[19:23:06.381593][info]     4: 445368
[19:23:06.381596][info]     5: 468705
[19:23:06.381600][info]     6: 461794
...
[19:23:14.259485][info]     529: 0
[19:23:14.259489][info]     530: 1
[19:23:18.243835][info] DelaunayGraphCut::reconstructExpetiments
[19:23:18.243873][info] fixesSigma: false
[19:23:18.243883][info] sigma: 4
[19:23:18.243898][info] Jancosek IJCV method ( delta*100 = 10 ):
[19:23:18.243902][info] Computing s-t graph weights.
[19:23:18.259995][info] setIsOnSurface nbSurfaceFacets: 0
[19:25:49.867962][info] Forcing t-edges
[19:27:07.159022][info] reconstructGC start.
[19:27:07.159062][info] Maxflow: start allocation.
[19:27:08.026908][info] Maxflow: add nodes.
[19:27:11.235413][info] Maxflow: add edges.
Killed

WARNING: downgrade status on node "MeshFiltering_1" from Status.SUBMITTED to Status.NONE
WARNING: downgrade status on node "Texturing_1" from Status.SUBMITTED to Status.NONE
WARNING: downgrade status on node "Publish_1" from Status.SUBMITTED to Status.NONE
Traceback (most recent call last):
  File "/opt/rh/rh-python36/root/usr/lib64/python3.6/site-packages/cx_Freeze/initscripts/__startup__.py", line 14, in run
  File "/opt/Meshroom/setupInitScriptUnix.py", line 39, in run
  File "bin/meshroom_photogrammetry", line 144, in <module>
  File "/opt/Meshroom/meshroom/core/graph.py", line 1131, in executeGraph
  File "/opt/Meshroom/meshroom/core/node.py", line 274, in process
  File "/opt/Meshroom/meshroom/core/desc.py", line 453, in processChunk
RuntimeError: Error on node "Meshing_1":
Log:
Program called with the following parameters:
 * addLandmarksToTheDensePointCloud = 0
 * angleFactor = 15
 * colorizeOutput = 0
 * contributeMarginFactor = 2
 * depthMapsFilterFolder = "/macierz/home/s160518/MeshroomCacheDes02/DepthMapFilter/a4f298481f423d4e41c712a36258f57c5fabe666"
 * depthMapsFolder = "/macierz/home/s160518/MeshroomCacheDes02/DepthMap/f714b011be4658118e75086b9cd3c7b7966af823"
 * estimateSpaceFromSfM = 1
 * estimateSpaceMinObservationAngle = 10
 * estimateSpaceMinObservations = 3
 * input = "/macierz/home/s160518/MeshroomCacheDes02/StructureFromMotion/57dc82b565a93f548e64363f719ffba61dd4f1e4/sfm.abc"
 * maxInputPoints = 50000000
 * maxPoints = 5000000
 * maxPointsPerVoxel = 1000000
 * minAngleThreshold = 1
 * minStep = 2
 * output = "/macierz/home/s160518/MeshroomCacheDes02/Meshing/e2f35e281db67be7cb65e055cfbdbc793a315cbf/densePointCloud.abc"
 * outputMesh = "/macierz/home/s160518/MeshroomCacheDes02/Meshing/e2f35e281db67be7cb65e055cfbdbc793a315cbf/mesh.obj"
 * partitioning =  Unknown Type "17EPartitioningMode"
 * pixSizeMarginFinalCoef = 4
 * pixSizeMarginInitCoef = 2
 * refineFuse = 1
 * repartition =  Unknown Type "16ERepartitionMode"
 * saveRawDensePointCloud = 0
 * simFactor = 15
 * simGaussianSize = 10
 * simGaussianSizeInit = 10
 * universePercentile = 0.999 (default)
 * verboseLevel = "info"
 * voteMarginFactor = 4

[19:16:18.238521][info] Found 1 image dimension(s):
[19:16:18.238631][info]         - [4032x3024]
[19:16:18.506061][info] Overall maximum dimension: [4032x3024]
[19:16:18.506115][warning] repartitionMode: 1
[19:16:18.506121][warning] partitioningMode: 1
[19:16:18.506125][info] Meshing mode: multi-resolution, partitioning: single block.
[19:16:18.506131][info] Estimate space from SfM.
[19:16:18.578780][info] Estimate space done.
[19:16:18.578802][info] pointToJoinPixSizeDist: 2
[19:16:18.699533][info] Estimated: 4 4 2
[19:16:18.699572][info] voxelNeighs.size(): 32
[19:16:18.959830][info] Creating dense point cloud.
[19:16:18.959849][info] fuseFromDepthMaps, maxVertices: 5000000
[19:16:19.606560][info] simFactor: 15
[19:16:19.606605][info] nbPixels: 2316625920
[19:16:19.606637][info] maxVertices: 5000000
[19:16:19.606641][info] step: 6
[19:16:19.606644][info] realMaxVertices: 64350720
[19:16:19.606647][info] Load depth maps and add points.
[19:17:50.228137][info] Filter initial 3D points by pixel size to remove duplicates.
[19:17:50.228180][info] Build nanoflann KdTree index.
[19:18:05.099482][info] KdTree created for 64350720 points.
[19:18:06.381574][info] Filtering done.
[19:18:06.629738][info] 56881226 invalid points removed.
[19:18:06.682256][info] 3D points loaded and filtered to 7469494 points.
[19:18:06.682279][info] Init visibilities to compute angle scores
[19:18:08.645518][info] NANOFLANN: KdTree created.
[19:18:08.666040][info] Create visibilities (64/190)
[19:18:08.666035][info] Create visibilities (0/190)
[19:18:08.666042][info] Create visibilities (127/190)
...
[19:20:01.532521][info] Create visibilities (62/190)
[19:20:02.373776][info] Create visibilities (63/190)
[19:20:03.075582][info] Visibilities created.
[19:20:03.079198][info] Compute max angle per point
[19:20:03.079209][info] angleFactor: 15
[19:20:06.345207][info] 400677 invalid points removed.
[19:20:06.983611][info] Filter by angle score and sim score
[19:20:06.983640][info] Build nanoflann KdTree index.
[19:20:08.639105][info] KdTree created for 7068817 points.
[19:20:09.303758][info] Filtering done.
[19:20:09.620360][info] 2896019 invalid points removed.
[19:20:09.850709][info] The number of points is below the max number of vertices.
[19:20:09.850740][info] 3D points loaded and filtered to 4172798 points (maxVertices is 5000000).
[19:20:09.850746][info] Create final visibilities
[19:20:10.755383][info] NANOFLANN: KdTree created.
[19:20:10.763677][info] Create visibilities (0/190)
[19:20:10.763702][info] Create visibilities (127/190)
...
[19:21:59.743710][info] Create visibilities (62/190)
[19:22:00.382480][info] Create visibilities (63/190)
[19:22:01.044536][info] Visibilities created.
[19:22:01.046813][info] fuseFromDepthMaps done: 4172798 points created.
[19:22:19.617412][info] 27095359 cells created by tetrahedralization.
[19:22:51.814679][info] coutInvalidVertices: 0
[19:22:51.814718][info] neighboringCellsPerVertexTmp: 4174129
[19:22:51.843078][info] verticesCoords: 4174129
[19:23:06.381526][info] Histogram of number of cams per point:
[19:23:06.381560][info]     0: 1331
[19:23:06.381581][info]     1: 0
[19:23:06.381585][info]     2: 168314
[19:23:06.381589][info]     3: 355577
...
[19:23:14.259485][info]     529: 0
[19:23:14.259489][info]     530: 1
[19:23:18.243835][info] DelaunayGraphCut::reconstructExpetiments
[19:23:18.243873][info] fixesSigma: false
[19:23:18.243883][info] sigma: 4
[19:23:18.243898][info] Jancosek IJCV method ( delta*100 = 10 ):
[19:23:18.243902][info] Computing s-t graph weights.
[19:23:18.259995][info] setIsOnSurface nbSurfaceFacets: 0
[19:25:49.867962][info] Forcing t-edges
[19:27:07.159022][info] reconstructGC start.
[19:27:07.159062][info] Maxflow: start allocation.
[19:27:08.026908][info] Maxflow: add nodes.
[19:27:11.235413][info] Maxflow: add edges.
Killed
```

**Desktop (please complete the following and other pertinent information):**
 - OS: Linux 5.0.0-37-generic #40~18.04.1-Ubuntu SMP
 - Python version: Python 2.7.17
 - Qt/PySide version not sure how to get it
 - Meshroom version: Meshroom-2019.2.0
   - Binary version (if applicable) 2019.2.0
Hello all, 

I am trying to  make a 3d model of my son for 3D printing. I used a DSLR camera and took about 80 pictures. All of the pictures were focused on the the upper body, since I do not want to make a model of the whole body. 

I loaded these images into Meshroom, but when all is processed, I end up with a hole where the person should be. See screenshot below. Do I need to take pictures of the whole body to make this work?
![image](https://user-images.githubusercontent.com/1497066/72645489-c3de3a80-3941-11ea-8e17-0751f128b7b9.png)

I've already unchecked the "Keep only the largest mesh" setting in MeshFiltering, which has been suggested for similar issues, but this does seem to have an effect. I suppose I could go out and retake the pictures including the whole person this time, but if there's another setting I'm missing,  that would be even better.

Thanks,

Julio
## Features list

- [X] Fix meshroom -i inputFolder
- [X] Add expression support: meshroom -i "folder/D*.JPG"
- [X] Add new command line option: meshroom --save /path/to/new/project.mg
- [X] Add verbose option to meshroom

when meshroom gets to the texturing phase, it loads all of the relevant info and then stops, with the node turning red. this is the log:

\`\Program called with the following parameters:
 * angleHardThreshold = 90
 * bestScoreThreshold = 0
 * downscale =  Unknown Type "unsigned int"
 * fillHoles = 0
 * flipNormals = 0
 * forceVisibleByAllVertices = 0
 * imagesFolder = "D:/Documents/meshroom/Naturall/rocks/rock 8/MeshroomCache/PrepareDenseScene/73ff6ecb5f2b76698d1ace95bfe5f19fa7bb168c"
 * input = "D:/Documents/meshroom/Naturall/rocks/rock 8/MeshroomCache/StructureFromMotion/e2ce29ba5dffd6734e4b5799f5c3eaa632430a77/sfm.abc"
 * inputDenseReconstruction = "D:/Documents/meshroom/Naturall/rocks/rock 8/MeshroomCache/Meshing/ca70afb88b3c19042b5a65b3cebde0bfc07d008b/denseReconstruction.bin"
 * inputMesh = "D:/Documents/meshroom/Naturall/rocks/rock 8/MeshroomCache/MeshFiltering/4a668633b114b8280b5cd97a5692f6217d81c39c/mesh.obj"
 * maxNbImagesForFusion = 3
 * output = "D:/Documents/meshroom/Naturall/rocks/rock 8/MeshroomCache/Texturing/974bbea0b54229f2bb7a757536a42c9218752583"
 * outputTextureFileType = "png"
 * padding =  Unknown Type "unsigned int"
 * textureSide =  Unknown Type "unsigned int"
 * unwrapMethod = "Basic"
 * verboseLevel = "info"
 * visibilityRemappingMethod = "PullPush"

[20:03:44.759035][info] Found 1 image dimension(s): 
[20:03:44.759035][info] 	- [5184x3456]
[20:03:46.534027][info] Overall maximum dimension: [5184x3456]`\`
![Screenshot (136)](https://user-images.githubusercontent.com/59890307/72378958-54323a80-370a-11ea-9cf1-e985ecdd1a9d.png)


this is the first time this has happened and all of my other projects have been successful

I'm on Windows 10 and I don't know what version of python it is


There are some question related to scanning of full human body. I have tried some setups but none give satisfying results.
I started with 32 images with smaller final length (larger fov) for saving time on photo shooting. In FeatureExtraction, "SIFT" and "High". The result is pretty noisy and the arms and legs are not recognized. 
Then I added AKAZE for extraction, matching and SfM which gives a little better result yet the arms and legs are still disconnect. 
I increased to 64 images with the previous 32 large fov and 32 high focal length (small fov). There are 1-3 poses are missed in SfM. The resulting mesh is still nosie but the arms are better. However the legs are still broken. I guess there skin cannot be identified well.
Any suggestion on what parameters are better for human body? Say dressed in beach-style. Or photo shooting techniques? Angle, lighting... etc.

Hello,

first of all, thanks to all contributors of Meshroom! This is seriously some great software! However, i have following problem: 

### The Scan
I scanned an quite simple object with a sum of **~3000 images** (yes that quite takes a while to process). I tried to get one perfect scan. I fixed the quite big object on a chair with a displacer between chair and object, so i can scan it **360x360 degrees**.  My plan was to remove the displacer in Post-Production. This is 100% stiff, so the construction did not move around while taking the images. **Light was also perfect** (no shadows at all). My images were shot automatically quite tight together (like 3cm distance between each photo on horizontal axis and 30cm distance on vertical axis - see images). I dont know if this matters? I am using Meshroom-2019.2.0 on Windows with a RTX2070. 

### The Issue
**The output of the "Meshing"-Node does not show the object.** It does also not show the chair and the displacer (which isnt a requirement at all). **Instead, it shows the whole "room" like the object and the steel rodes were never in the room at any time** ^^ It is like the object was "cut out". The room looks quite good meshed however, but of course that is not what I wanted to do. As this took 4 days to process, I thought i messed up some settings (which are nearly all standard - just changed downscale setting). I remembered the "Keep only the largest Mesh"-setting in the "MeshFiltering"-Node. **But the "Keep Only the Largest Mesh"-Setting is NOT activated.** 

### Images
![struc](https://user-images.githubusercontent.com/6267156/72206946-02807a80-3494-11ea-8145-7949f8555342.PNG)
On this image you can see the output of the "StructureFromMotion" node. I set the camera-size and the point-size to very low. You can even see the object here quite good. Everything looks fine. 

![meshing](https://user-images.githubusercontent.com/6267156/72206945-02807a80-3494-11ea-9177-e6ca6126d139.PNG)
This image however shows the output of the "Meshing"-node from the same perspective. You can see, that the chair and everything on it is just gone. Instead, there its a little whole on the floor (its actually grass - i propably never did a capture of this area). 

![both](https://user-images.githubusercontent.com/6267156/72206944-02807a80-3494-11ea-9715-8bb9157af858.PNG)
This image shows "StructureFromMotion" and "Meshing"-Node Output at the same time. You can see that there is absolutly no Mesh were the object is...

Does anyone have any idea on how to avoid/solve this? Do I need to make a new scan? Is it just a setting-thingy? Which settings could produce such a result? Is it maybe an real issue?  

Thanks for your help. Marc
**Describe the bug**
Exporting a PNG from darktable results in an image that fails to load metadata in meshroom. Exporting to JPG works. If I examine in GIMP, metadata is present for both images. (Both images taken with same camera/lens.)

Example images:
http://caseyconnor.org/pub/image/bugs/meshroom/IMG_8681.png
http://caseyconnor.org/pub/image/bugs/meshroom/IMG_8624.jpg

Screenshot: http://caseyconnor.org/pub/image/bugs/meshroom/meshroom_sshot.png

 - OS: Ubuntu 18.10, 4.18.0-25-generic #26-Ubuntu SMP Mon Jun 24 09:32:08 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
 - Python version 2.7.16 and 3.6.8
 - Qt/PySide version 5.11.1
 - Meshroom version: please specify if you are using a release version or your own build
   - Binary version 2019.2.0

## Description

The purpose of this is to make masks user guided within meshroom with minimal user interaction, which when combined with #708 and [alicevision/AliceVision #715](https://github.com/alicevision/AliceVision/pull/715) will get another option for masking workflow, rather than relying on thresholding which will only work for some setups.

## Features list

- Window overlay accessible from 'Edit' menu
- Masks generated using the GrabCut algorithm 
- The algorithm is sped up by setting iterations to 1 and lowering image resolution

![screenshot](https://user-images.githubusercontent.com/32775248/71666154-a745de00-2d57-11ea-930c-76e30dbd92a1.png)

## Implementation remarks

Given the structure of meshroom, it would probably make more sense to have the mask calculated in c++ and then the exe ran from python to avoid adding opencv dependency when it is already on AliceVision, so I will look into this possibility


**Describe the problem**
I wanna edit the GUI with QT creator,is there a [qt creator] 's project for meshroom?

**Screenshots**

![image](https://user-images.githubusercontent.com/170311/71655056-10395000-2d70-11ea-8c32-aec21223d657.png)



**Additional context**


In other photogrammetry programs I used I was able to export a model. Fix ugly / missing faces and then import the model back in the photogrammetry application so it could update for the textures.

Is it possible to do such thing in photogrammetry? And if so is there any tutorial availbe online? No matter what 3d modelling application they use for the fixes.