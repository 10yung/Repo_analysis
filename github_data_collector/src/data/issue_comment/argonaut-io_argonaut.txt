Hey folks,

I was wondering if someone had already extracted a JsonSchema (or similar) from encoders.

For example :
```
case class Data(id: UUID, a: Option[String])

object Data {
    implicit val encoder: EncodeJson[Data] =
        jencode2L((m: Data) => (m.id, m.a))(
          "id", "some_field_name"
        )
}
```

Is it possible to extract the JsonSchema from this encoder that could look like : 
```
{
  "title": "Data",
  "type": "object",
  "properties": {
    "id": {
      "type": "uuid"
    },
    "some_field_name": {
      "type": "string",
      "optional": true
    }
  }
}
```

It seems a bit hard to extract all this information from the current state of the code.
Do you have any clue?
Cheers
Hi, I have a private library and webapp both using Argonaut. With the library no 2.6.1 and the webapp using 2.6.3 I get the following error. I believe this is a binary compatibility issue.

```
Caused by: java.lang.NoSuchMethodError: argonaut.Argonaut$.ToJsonIdentity(Ljava/lang/Object;)Largonaut/JsonIdentity;
```

Running scala 2.12.8
Does it make sense to
```scala
sealed abstract class CodecJson[A] ... {
  override def mapJson(f: Json => Json): CodecJson[A] =
    CodecJson.derived(
      Encoder.mapJson(f),
      Decoder
    )
}
```
?
I've been programming with Scala for a few months now, but I still don't understand how (and if) can I get a better error messages from Argonaut. Currently, I have a codec and I use it as this:
```
val json: String = ...
val parsed = Parse.decodeEither[MyClass](json)
val checks = if (parsed.isRight) parsed.right.get
else sys.error("Unable to parse MyClass json: " + parsed.left)
```
However, I never get any useful error messages when I use this. All I get is `java.lang.RuntimeException: Unable to parse MyClass json: LeftProjection(Left(String: CursorHistory(List())))`.

What is the proper way to handle decoding errors?
_Sub-quadratic_ decreasing of throughput when number of JSON object fields (with keys that have the same hash code) is increasing

On contemporary CPUs parsing of such JSON object (with a sequence of 100000 fields like below that is ~1.6Mb) can took more than 100 seconds:

```
{
"!!sjyehe":null,
"!!sjyeiF":null,
"!!sjyej'":null,
"!!sjyfIe":null,
"!!sjyfJF":null,
...
}
``` 

Below are results of the benchmark where `size` is a number of such fields:

```
[info] REMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up on
[info] why the numbers are the way they are. Use profilers (see -prof, -lprof), design factorial
[info] experiments, perform baseline and negative tests that provide experimental control, make sure
[info] the benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.
[info] Do not assume the numbers tell you what you want them to tell.
[info] Benchmark                         (size)  (value)   Mode  Cnt        Score       Error  Units
[info] ExtractFieldsBenchmark.readArgonaut       1     null  thrpt    5  969947.719 ± 47977.521  ops/s
[info] ExtractFieldsBenchmark.readArgonaut      10     null  thrpt    5  220650.585 ± 27891.347  ops/s
[info] ExtractFieldsBenchmark.readArgonaut     100     null  thrpt    5    7580.773 ±  1298.528  ops/s
[info] ExtractFieldsBenchmark.readArgonaut    1000     null  thrpt    5      71.919 ±     7.111  ops/s
[info] ExtractFieldsBenchmark.readArgonaut   10000     null  thrpt    5       0.444 ±     0.089  ops/s
[info] ExtractFieldsBenchmark.readArgonaut  100000     null  thrpt    5       0.010 ±     0.002  ops/s
```

### Reproducible Test Case

To run that benchmarks on your JDK:
1. [Install latest version of `sbt`](https://www.scala-sbt.org/1.0/docs/Setup.html) and/or ensure that it already installed properly: 
```
sbt about
```

2. Clone `jsoniter-scala` repo: 
```
git clone https://github.com/plokhotnyuk/jsoniter-scala.git
```

3. Enter to the cloned directory and checkout for the specific branch:
```
cd jsoniter-scala
git checkout argonaut-DoS-by-hashmap-collisions
```

4. Run benchmarks using a path parameter to your JDK:
```
sbt -no-colors 'jsoniter-scala-benchmark/jmh:run -jvm /usr/lib/jvm/jdk-11/bin/java -wi 3 -i 5 .*ExtractFieldsBench.*Argonaut.*'
```
In the section, DecodeJson maintaining is spelled as mainting.
https://github.com/argonaut-io/argonaut/blob/8b1e26165b7ec667a566c8716a73fc6434327c1e/argonaut/shared/src/main/scala/argonaut/JsonNumber.scala#L262-L263

>   This document replaces [RFC7159].  [RFC7159] obsoleted [RFC4627],
   which originally described JSON and registered the media type
   "application/json".

https://tools.ietf.org/html/rfc8259
Lots of instances that `\/` has are missing in DecodeResult, for example, `scalaz.Plus` and `scalaz.Monoid`
Currently it's possible to encode a Map with a potentially arbitrary key if `EncodeJsonKey` is implemented, but it's not possible to decode in reverse.

Would be nice if there was a combinator that can descend into a JSON string as if it were JSON.  For example with the JSON:

```
{ "field": "\"{\"subField\": 1}" }
```

Be able to navigate a cursor like this:

```
c --\! "field" --\ "subField".as[Int]
```

Here's some example code as proof of concept:

``` scala
    implicit class ACursorOps(self: ACursor) {
      def --\!(fieldName: String): ACursor = (self --\ fieldName).parsed

      def parsed: ACursor = {
        self.as[String].result match {
          case Left((_, history)) =>
            self.history.failedACursor(self.any.cursor)
          case Right(text) =>
            Parse.parse(text) match {
              case Left(message) =>
                self.history.failedACursor(self.any.cursor)
              case Right(json) =>
                self.history.acursor(json.cursor)
            }
        }
      }
    }

    implicit class HCursorOps(self: HCursor) {
      def --\!(fieldName: String): ACursor = (self --\ fieldName).parsed
    }
```
