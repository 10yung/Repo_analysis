Apache Hudi  provides atomic upserts and incremental data streams on Big Data. 
Hi,

I am trying to use VerificationSuite with constraints manually defined in a config file, i.e. my constraints are not auto-generated from the ConstraintSuggestionRunner.

Though, for inspiration, I have investigated the output from ConstraintSuggestionsRunner (dataframe with the 3 columns: (1) column / (2) _constraintDescription / (3) _scalaCodeForConstraint ), and based on my manually defined config file, I have generated a sequence of strings with _scalaCodeForConstraint in the following format:

```
.isNonNegative("column_A")
.isComplete("column_B")
.isContainedIn("column_C", Array("validValue1", "validValue2"), _ >= 0.95, Some("It should be above 0.95!"))
```

I used your reply to https://github.com/awslabs/deequ/issues/140 as inspiration, and I would like to replace allConstraints (in your code example below with input from suggestionResult) with my sequence of _scalaCodeForConstraint.

```
   //-- How do I replace allConstraints below with _scalaCodeForConstraint based on config file??
   val allConstraints = suggestionResult.constraintSuggestions
      .flatMap { case (_, suggestions) => suggestions.map { _.constraint }}
      .toSeq  

    //-- probably also to be replaced ?? 
    val generatedCheck = Check(CheckLevel.Error, "generated constraints", allConstraints)

    val verificationResult = VerificationSuite()
      .onData(datasource)
      .addChecks(Seq(generatedCheck))
      .run()
```

Do you have a code example on how to use _scalaCodeForConstraint as input to the VerificationSuite?

Thank you very much in advance - your input is highly appreciated.
When I have a `VerificationSuite` with a `Check` like this:
```
      .addCheck(Check(CheckLevel.Error, "Sample check")
        .hasSize(_ > 10000).where("entity = 'A'")
        .hasSize(_ > 100000).where("entity = 'B'")
        .hasSize(_ > 100000).where("entity = 'C'")
      )
```

Run the suite and get the `VerificationResult` like this:
```
VerificationResult.successMetricsAsDataFrame(spark, distributionSuite).show()
```

I get back the following result:
```
+-------+--------+----+--------+
| entity|instance|name|   value|
+-------+--------+----+--------+
|Dataset|       *|Size|  5632.0|
|Dataset|       *|Size|422312.0|
|Dataset|       *|Size|126984.0|
+-------+--------+----+--------+
```

It's hard to differentiate these metrics. Is there any chance to add any description / name to the metrics? 
Have seen there is an `hint: Option[String]` param for the constraints, however if understand correctly it's not available in *Metrics* result. 

Adjusting the `name` column might be an option, like this:
```

+---------+----------+----------------------------+----------+
| entity  | instance |            name            |  value   |
+---------+----------+----------------------------+----------+
| Dataset | *        | Size (where: entity = 'A') |   5632.0 |
| Dataset | *        | Size (where: entity = 'B') | 422312.0 |
| Dataset | *        | Size (where: entity = 'C') | 126984.0 |
+---------+----------+----------------------------+----------+
```

Would it be possible to add this info to make the results more clear?
I am trying to figure out a case when the real fractional column contans a string value. 
 val rows = spark.sparkContext.parallelize(Seq(
      RawData("thingA", "13.0", "IN_TRANSIT", "true"),
      RawData("thingA", "5", "DELAYED", "false"),
      RawData("thingB", "Test",  "DELAYED", null),
      RawData("thingC", null, "IN_TRANSIT", "false"),
      RawData("thingD", "1.0",  "DELAYED", "true"),
      RawData("thingC", "7.0", "UNKNOWN", null),
      RawData("thingC", "20", "UNKNOWN", null),
      RawData("thingE", "20", "DELAYED", "false")
    ))

In the test I have added a "Test"  in second column. The inferred type is coming as String. Is there a way to to identify the distribution of column value is mostly Fractional so cast it to double   

Hi,

Trying to calculate a few quantiles, I've realised that the metric names are not clear.

If they are calculated individually:
```
ApproxQuantiles("fieldName", Seq(0.25), 0)
ApproxQuantiles("fieldName", Seq(0.5), 0)
ApproxQuantiles("fieldName", Seq(0.75), 0)
```

they end with three metrics with the same name and no clue about the quantile calculated:
```
DoubleMetric(Column,ApproxQuantile,fieldName,Success(0.0))
DoubleMetric(Column,ApproxQuantile,fieldName,Success(12.0))
DoubleMetric(Column,ApproxQuantile,fieldName,Success(30.0))
```

When they are calculated all at once:
```
ApproxQuantiles("fieldName", Seq(0.25, 0.5, 0.75),0)
```
the KeyedDoubleMetric is generated with all the information:
```
KeyedDoubleMetric(Column,ApproxQuantiles,fieldName,Success(Map(0.25 -> 0.0, 0.5 -> 12.0, 0.75 -> 30.0)))
```
Here, the problem is when the KeyedDoubleMetric is flattened in order to process the metrics individually. It ends with three metrics where the calculated quantile is displayed but there is not clue about the metric itself (approxQuantile):
```
DoubleMetric(Column,name-0.25,fieldName,Success(0.0))
DoubleMetric(Column,name-0.5,fieldName,Success(12.0))
DoubleMetric(Column,name-0.75,fieldName,Success(30.0))
```

My Suggestions are:

- At ApproxQuantile, when saving the metric, add the quantile. It is, from `"ApproxQuantile"` to `s"approxQuantile-$quantile"`

- At Metric / KeyedDoubleMetric, on the flatten method, update the instance value from
`s"name-$key` to `s"$name-$key` (actually, I think this is the original expected behaviour).


I'm open to help on the changes if you agree with them.
Hi Team,

I have been trying to understand if it is possible to implement your anomlay detection strategy not only on the full dataset but on the multiple subset.

Example: I have 150 warehouse generating data in my dataset (wharehouse_id being a column), and I want to apply BatchNormalStrategy for all these particular warehouses.

Can I achieve this ?
Hello Everyone , 

I would like to know  how we can persist the table profile results as data frame/ json format  , Currently  the return  type is a scala object ColumnProfilerRunner Type , 
Anyone implemented this scenario  ? 

thank you . 
Hi Team,

We have a use case where we want to collect some metrics for a grouped DataFrame, we want to see the collected metrics (e.g. Completeness, ApproxQuantiles, Histogram) separately for every group.
We also want to store the metrics in MetricsRepository.
Any best practices on this?

*I have the following idea:*
- filter a group of the DataFrame, pass it to *deequ* for analyis
- store the metrics in MetricsRepository, using the group value as a tag 
- repeat the above steps for every group

It might be working, but it's pretty time-consuming. Any idea to improve this approach?

Thanks in advance,
Robert


Hi Team,

We have a use case where we want to collect the following metrics:
_the proportion of rows which contain at least 1 null/missing value_

Do you have any suggestion to cover this use case using *deequ*? 

I have workaround idea:
- add a new `boolean` column (e.g. `has_null`) to the input DataFrame that is indicating whether we have any null / missing value in the given row
- use `Compliance("has_null == true")` analyzer

Is there a better solution to this? Maybe I could write a dynamic predicate for Compliance that iterates all the columns and checks if any of them null.

Thanks in advance,
Robert