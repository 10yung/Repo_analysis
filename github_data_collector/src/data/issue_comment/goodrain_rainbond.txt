1. use kubernetes job instead of docker container to build service
2. use pod.GetLogs() get build logs

 【BUG描述】基于应用市场的应用版本回滚功能不可用（此问题在console复现）

【部署环境】
- Rainbond版本(执行`grctl version`获取): [请填写此处]
- 操作系统类型和版本:[请填写此处]
- 离线部署/网络开放：[请填写此处]

![image](https://user-images.githubusercontent.com/50609288/72656225-e0778280-39d4-11ea-9725-6a92c171c863.png)

![image](https://user-images.githubusercontent.com/50609288/72656281-292f3b80-39d5-11ea-9e0b-49631621bc09.png)

app-ui日志
![image](https://user-images.githubusercontent.com/50609288/72656271-187ec580-39d5-11ea-9089-cb6d878323e7.png)


【BUG描述】10.63.4.23 10.63.74.92网关节点已删除，在添加tcp访问策略时，节点信息仍存在于列表中

【部署环境】
- Rainbond版本(执行`grctl version`获取): 5.1.10
- 操作系统类型和版本：ubuntu16.04
- 离线部署/网络开放：online

删除后已没有这两个节点
![image](https://user-images.githubusercontent.com/50609288/72656153-61824a00-39d4-11ea-89a5-eefa2fcb09cd.png)
添加tcp访问策略时，节点信息仍存在
![image](https://user-images.githubusercontent.com/50609288/72656106-1b2ceb00-39d4-11ea-99be-ac11930f926b.png)


【BUG描述】
背景说明：
1. rainbond从5.1.9升级到5.1.10
2. rbd-gateway组件使用了 #635 中的dev版（rainbond/rbd-gateway:V5.1-dev）
3. rainbond显示的整体请求量在50万/小时左右
4. 导入流量之前没有出现过问题，昨天下午开始导入流量并更新了dev版的gateway组件后开始出现
5. OOM仅发生于使用了依赖的组件

大概的依赖关系是：前端组件（多个）依赖同一个后端组件，后端组件提供http形式的接口供前端组件使用，见下图：
![image](https://user-images.githubusercontent.com/53854600/72588874-a191f000-3934-11ea-8d83-e6ff6d61db08.png)

单个前端组件的请求量并不高，大概在2万/小时左右，后端组件访问量在45万/小时左右（包括内部依赖以及外部域名直接请求），只要前端组件有访问，就会频繁出现OOM，当出现OOM的时候，前端组件访问后端接口就会出现502错误，后端组件暂无异常，增加前端组件的内存并没有效果，见下图：
![image](https://user-images.githubusercontent.com/53854600/72589123-43b1d800-3935-11ea-834c-41ba4e9e87e1.png)
![image](https://user-images.githubusercontent.com/53854600/72589141-53312100-3935-11ea-85bf-33c4355e15ca.png)
![image](https://user-images.githubusercontent.com/53854600/72590137-0c90f600-3938-11ea-8d13-c1aceb983528.png)
![image](https://user-images.githubusercontent.com/53854600/72590178-1d416c00-3938-11ea-83e6-5330634d1704.png)

以下是一个已经死掉的rbd-mesh-data-panel容器的日志：
```bash
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:206] initializing epoch 0 (hot restart version=10.200.16384.127.options=capacity=16384, num_slots=8209 hash=228984379728933363 size=2654312)
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:208] statically linked extensions:
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:210]   access_loggers: envoy.file_access_log,envoy.http_grpc_access_log
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:213]   filters.http: envoy.buffer,envoy.cors,envoy.ext_authz,envoy.fault,envoy.filters.http.header_to_metadata,envoy.filters.http.jwt_authn,envoy.filters.http.rbac,envoy.grpc_http1_bridge,envoy.grpc_json_transcoder,envoy.grpc_web,envoy.gzip,envoy.health_check,envoy.http_dynamo_filter,envoy.ip_tagging,envoy.lua,envoy.rate_limit,envoy.router,envoy.squash
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:216]   filters.listener: envoy.listener.original_dst,envoy.listener.proxy_protocol,envoy.listener.tls_inspector
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:219]   filters.network: envoy.client_ssl_auth,envoy.echo,envoy.ext_authz,envoy.filters.network.dubbo_proxy,envoy.filters.network.rbac,envoy.filters.network.sni_cluster,envoy.filters.network.thrift_proxy,envoy.http_connection_manager,envoy.mongo_proxy,envoy.ratelimit,envoy.redis_proxy,envoy.tcp_proxy
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:221]   stat_sinks: envoy.dog_statsd,envoy.metrics_service,envoy.stat_sinks.hystrix,envoy.statsd
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:223]   tracers: envoy.dynamic.ot,envoy.lightstep,envoy.tracers.datadog,envoy.zipkin
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:226]   transport_sockets.downstream: envoy.transport_sockets.alts,envoy.transport_sockets.capture,raw_buffer,tls
[2020-01-17 05:33:24.352][000008][info][main] [source/server/server.cc:229]   transport_sockets.upstream: envoy.transport_sockets.alts,envoy.transport_sockets.capture,raw_buffer,tls
[2020-01-17 05:33:24.354][000008][info][main] [source/server/server.cc:271] admin address: 0.0.0.0:65533
[2020-01-17 05:33:24.356][000008][info][config] [source/server/configuration_impl.cc:50] loading 0 static secret(s)
[2020-01-17 05:33:24.356][000008][info][config] [source/server/configuration_impl.cc:56] loading 2 cluster(s)
[2020-01-17 05:33:24.357][000008][info][upstream] [source/common/upstream/cluster_manager_impl.cc:132] cm init: initializing cds
[2020-01-17 05:33:24.357][000008][info][config] [source/server/configuration_impl.cc:67] loading 0 listener(s)
[2020-01-17 05:33:24.357][000008][info][config] [source/server/configuration_impl.cc:92] loading tracing configuration
[2020-01-17 05:33:24.357][000008][info][config] [source/server/configuration_impl.cc:112] loading stats sink configuration
[2020-01-17 05:33:24.357][000008][info][main] [source/server/server.cc:463] starting main dispatch loop
[2020-01-17 05:33:24.359][000008][warning][misc] [source/common/stats/thread_local_store.cc:254] Statistic 'cluster.f5bd915edc554fdb8db950a69e670aaf_grb74985_grfb8394_6379.outlier_detection.ejections_detected_consecutive_gateway_failure' is too long with 128 characters, it will be truncated to 127 characters
[2020-01-17 05:33:24.359][000008][warning][misc] [source/common/stats/thread_local_store.cc:254] Statistic 'cluster.f5bd915edc554fdb8db950a69e670aaf_grb74985_grfb8394_6379.outlier_detection.ejections_enforced_consecutive_gateway_failure' is too long with 128 characters, it will be truncated to 127 characters
[2020-01-17 05:33:24.359][000008][info][upstream] [source/common/upstream/cluster_manager_impl.cc:495] add/update cluster f5bd915edc554fdb8db950a69e670aaf_grb74985_grfb8394_6379 during init
[2020-01-17 05:33:24.359][000008][info][upstream] [source/common/upstream/cluster_manager_impl.cc:112] cm init: initializing secondary clusters
[2020-01-17 05:33:24.360][000008][info][upstream] [source/common/upstream/cluster_manager_impl.cc:136] cm init: all clusters initialized
[2020-01-17 05:33:24.360][000008][info][main] [source/server/server.cc:435] all clusters initialized. initializing init manager
[2020-01-17 05:33:24.446][000008][info][upstream] [source/server/lds_api.cc:80] lds: add/update listener 'f5bd915edc554fdb8db950a69e670aaf_grb74985_6379'
[2020-01-17 05:33:24.446][000008][info][config] [source/server/listener_manager_impl.cc:961] all dependencies initialized. starting workers
```

请大佬们帮忙分析分析是哪里的问题，rbd-mesh-data-panel容器是否能自行调整内存？
我们是真的把Rainbond用于生产了，目前的访问量不算高，因为还没有把所有项目迁移过来，勇于做小白鼠，问题比较多，希望大佬们不要见怪。
拜谢！

@barnettZQG 

【部署环境】
- Rainbond版本: [Rainbond grctl v5.1.10-release-f4c675d-2020-01-09-13]
- 操作系统类型和版本:[CentOS Linux release 7.6.1810 (Core)]
- 离线部署/网络开放：[离线部署]


 【BUG描述】
应用正常运行，但在日志界面不显示日志

【部署环境】
- Rainbond版本: [5.1.9]
- 操作系统类型和版本:[centos7.4]
- 离线部署/网络开放：[离线部署]

![401579163165_ pic_hd](https://user-images.githubusercontent.com/55137659/72510556-9d0dfe80-3884-11ea-8c42-4a97fbfcbb1a.jpg)
![541579165016_ pic_hd](https://user-images.githubusercontent.com/55137659/72510624-bca52700-3884-11ea-87dc-265d6d0d33b3.jpg)
![451579163385_ pic_hd](https://user-images.githubusercontent.com/55137659/72510646-c62e8f00-3884-11ea-8f5f-385ae8b3a8a8.jpg)
![481579164068_ pic_hd](https://user-images.githubusercontent.com/55137659/72510664-cc247000-3884-11ea-9f88-6803ae5cd3e6.jpg)
![501579164224_ pic_hd](https://user-images.githubusercontent.com/55137659/72510673-d21a5100-3884-11ea-8eac-24ec36cddd63.jpg)
【BUG描述】
![image](https://user-images.githubusercontent.com/53854600/72141073-144b1a80-33cd-11ea-8594-f4f2edec2dcc.png)

执行`journalctl -fu rbd-gateway`后，日志如上图所示，重启rbd-gateway服务无效，重启gateway节点服务器无效，将添加的域名删除后依然无效，访问绑定的所有域名均返回502错误。

进入rbd-gateway容器查看default_servers.conf文件，发现文件大小一直在变化，忽大忽小，里面的内容也一直在变化

请问这个情况应该如何处理才能恢复😭？

【部署环境】
- Rainbond版本: [Rainbond grctl v5.1.9-release-32cc2ba-2019-12-13-09]
- 操作系统类型和版本:[CentOS Linux release 7.6.1810 (Core)]
- 离线部署/网络开放：[离线部署]


【需求描述】
我们的业务经常需要绑定上百个域名，一个一个来实在太没效率，是否有可能增加批量绑定的功能？


【部署环境】
- Rainbond版本: [Rainbond grctl v5.1.9-release-32cc2ba-2019-12-13-09]
- 操作系统类型和版本:[CentOS Linux release 7.6.1810 (Core)]
- 离线部署/网络开放：[离线部署]

【BUG描述】(非需求请删除本行)
 
管理后台显示实例deployment运行内存83.88% 实际查看docker使用内存才33%，然后我把同个deployment下的三个Containers 实际使用内存大小 和百分比统计了一下 。内存达不到1.6G。但是三个内存使用率直接累加是到83.88%
![image](https://user-images.githubusercontent.com/43443722/71957249-38212b80-3228-11ea-846f-3dcfadfe9325.png)

![image](https://user-images.githubusercontent.com/43443722/71957627-415ec800-3229-11ea-942e-54470bcccd2b.png)

![image](https://user-images.githubusercontent.com/43443722/71957392-9e0db300-3228-11ea-8303-cc570ea5d754.png)
![image](https://user-images.githubusercontent.com/43443722/71957556-052b6780-3229-11ea-8834-ddd4bf5a32c8.png)
![image](https://user-images.githubusercontent.com/43443722/71957602-25f3bd00-3229-11ea-89f5-c11840374c18.png)



【部署环境】
- Rainbond版本(执行`grctl version`获取): v5.1.9-release-32cc2ba-2019-12-13-09
- 操作系统类型和版本:ubuntu16.04
- 离线部署/网络开放：私有化高可用部署



【BUG描述】(非BUG请删除本行)
从5.1.8升级到5.1.9 后发现控制台日志回显很慢，基本都要1分钟后才能回显。经常要来回切换页面或者是重新点击日志选项才能出来而且显示不全。调试发现有/grdata/logs/eventlog目录没有创建。重新安装5.1.9后测试eventlog 文件夹还是没有。

以下图片是5.1.8升级到5.1.9后
journalctl -fu rbd-api如下报错

![image](https://user-images.githubusercontent.com/43443722/71948251-61cb5a00-320a-11ea-8e3e-65ce9e37c914.png)

5.1.9全新安装完后的路径图片
![image](https://user-images.githubusercontent.com/43443722/71948439-f7ff8000-320a-11ea-84d3-2b31ea336da4.png)
手动创建eventlog 文件夹后日志回显恢复正常。

前置工作
wsurl 已修改为vip:6060

【部署环境】
- Rainbond版本(执行`grctl version`获取):v5.1.9-release-32cc2ba-2019-12-13-09
- 操作系统类型和版本:ubuntu16.04
- 离线部署/网络开放：私有化高可用部署


【BUG描述】
![image](https://user-images.githubusercontent.com/53854600/71790673-a28d6c80-306c-11ea-84ff-56bac72585be.png)

上图是构建的时候，新的实例已经起来了，旧的实例一直没法关闭，超过10分钟了，也不知道要看哪个平台组件的日志，最后尝试强制手动关闭，然后再启动才行。这个问题5.1.7时已存在，经常需要重启计算节点才行。

【部署环境】
- Rainbond版本: [Rainbond grctl v5.1.9-release-32cc2ba-2019-12-13-09]
- 操作系统类型和版本:[CentOS Linux release 7.6.1810 (Core)]
- 离线部署/网络开放：[离线部署]