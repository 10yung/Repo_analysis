Looks like the release changelog was completely removed from the readme with this commit 33c86dd7910fb4c743c5c7a511d699a69ead0d86 - Is there any reason for getting rid of it @sksamuel?

If maintaining release notes is too much effort, I'd suggest giving the [Release Drafter](https://probot.github.io/apps/release-drafter) bot a try.

I personally find the release notes very useful and I'm sure others will agree with me that having a changelog is a must-have these days.

I'm happy to help set this up, but someone with write permissions will need to install the Release Drafter Github app. @mccartney, do you want to give it a try?
When running scapegoat (through sbt-scapegoat, if that matters), it outputs each error with a description, e.g. "Catch exception" or "Unused parameter".

In cases where I want to suppress that specific error, I need the name of the inspection. Sometimes it directly matches the description, like "Catch exception" -> `CatchException`. However, other times it does not, such as "Unused parameter" -> `UnusedMethodParameter`.

It would be helpful if the output from scapegoat included the name of the inspection (or "the string I am supposed to write in `SuppressWarnings`, really). It could perhaps look something like:

```
[error] /path/to/Code.scala:61:7: [UnusedMethodParameter] Unused parameter
```
We're using Scapegoat 3.11. When running:

```
gradle build
```
It runs `compileScala` and `compileTestScala`, (among other tasks) and both of these are of type `ScalaCompile`. The documentation specifies that we should use:

```
tasks.withType(ScalaCompile) {
  scalaCompileOptions.additionalParameters = [
    "-Xplugin:" + configurations.scalaCompilerPlugin.asPath,
    "-P:scapegoat:dataDir:" + buildDir + "/scapegoat"
  ]
}
```

We did this and it overwrites the `scapegoat.xml` file of the sources with the one for the tests.

The documentation also states that `-P:scapegoat:sourcePrefix:` defaults to `src/main/scala` and that this is not a required setting. We've actually tried specifying this and it didn't help.

If you do the following, you will get a separate file for sources and unit tests:
```
  tasks.withType(ScalaCompile) {

        scalaCompileOptions.additionalParameters = [
                "-feature",
                "-Xplugin:" + configurations.scalaCompilerPlugin.asPath,
                "-P:scapegoat:dataDir:${buildDir}/reports/scapegoat",
                "-P:scapegoat:reports:xml",
                "-P:scapegoat:sourcePrefix:src/main/scala",
        ]
        options.compilerArgs << "-Xlint:all,-path" << "-Werror"

        doLast {
            def scapegoat_output = "${buildDir}/reports/scapegoat/scapegoat.xml"
            if(file(scapegoat_output).exists()) {
                try {
                    copy {
                        from(scapegoat_output)
                        into("${buildDir}/reports/scapegoat/")
                        rename("scapegoat.xml", "scapegoat-${name}.xml")
                        fileMode = 755
                    }
                    delete scapegoat_output
                } catch (GradleException e) {
                    throw new GradleException("$e.message: $e.cause", e.cause)
                }
            }
        }
    }
```

This looks like a bug.

Of course, if you're trying to be really strict, you might want to also check your tests, but, generally, you're mainly interested in your production sources.

Would it be possible to change this behaviour, or add an option to be able to control it?

Thanks! :)

```
    implicit val ec: ExecutionContext = ExecutionContext.global
    val foo = for {
      x <- Future[Any](5)
    } yield x match {
      case i: Int    =>
      case s: String =>
    }
```

Produces the error:
```
[error] Match instead of partial function
          A map match can be replaced with a partial function for greater readability: scala.concurrent.Future.apply[Any](5)(ec).map[Unit](((x: Any) => x match {
  case (i @ (_: Int)) => ()
  case (s @ (_: String)) => ()
}))
```

However, there is no way to do that, since the `map` is implicitly part of the yield.
Not been able to dig down what the problem is, but wanted to share for others.
In my project with this setup: `scapegoat 1.3.9` / `sbt-scapegoat 1.0.9` / `scala 2.11.12` (I know, but is Spark 2.4.0 on AWS EMR), I now get upon testing (`sbt it:test`) a runtime error:

```
[error] java.lang.NoClassDefFoundError: scala/collection/compat/Factory$
[error] 	at scalikejdbc.DBSession$class.list(DBSession.scala:295)
[error] 	at scalikejdbc.ActiveSession.list(DBSession.scala:837)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$list$1.apply(DBSessionWrapper.scala:52)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$list$1.apply(DBSessionWrapper.scala:52)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$withAttributesSwitchedDBSession$1.apply(DBSessionWrapper.scala:34)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$withAttributesSwitchedDBSession$1.apply(DBSessionWrapper.scala:33)
[error] 	at scalikejdbc.DBSessionAttributesSwitcher.withSwitchedDBSession(DBSessionAttributesSwitcher.scala:31)
[error] 	at scalikejdbc.DBSessionWrapper.withAttributesSwitchedDBSession(DBSessionWrapper.scala:33)
[error] 	at scalikejdbc.DBSessionWrapper.list(DBSessionWrapper.scala:52)
[error] 	at scalikejdbc.SQLToList$class.result(SQL.scala:931)
[error] 	at scalikejdbc.SQLToListImpl.result(SQL.scala:944)
[error] 	at scalikejdbc.SQLToListImpl.result(SQL.scala:944)
[error] 	at scalikejdbc.SQLToResult$$anonfun$14.apply(SQL.scala:811)
[error] 	at scalikejdbc.SQLToResult$$anonfun$14.apply(SQL.scala:811)
[error] 	at scalikejdbc.SQLToResult$class.apply(SQL.scala:817)
[error] 	at scalikejdbc.SQLToListImpl.apply(SQL.scala:944)
[error] 	at be.persgroep.ngage.wonka.Pipeline$$anonfun$5.apply(Pipeline.scala:471)
[error] 	at be.persgroep.ngage.wonka.Pipeline$$anonfun$5.apply(Pipeline.scala:460)
[error] 	at scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:242)
[error] 	at scalikejdbc.DB.autoCommit(DB.scala:60)
[error] 	at scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:216)
[error] 	at scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
[error] 	at scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
[error] 	at scalikejdbc.DB$.using(DB.scala:139)
[error] 	at scalikejdbc.DB$.autoCommit(DB.scala:215)
[error] 	at be.persgroep.ngage.wonka.Pipeline$.run(Pipeline.scala:460)
[error] 	at be.persgroep.ngage.wonka.PipelineTest.beforeAll(PipelineTest.scala:133)
[error] 	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:212)
[error] 	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
[error] 	at be.persgroep.ngage.wonka.PipelineTest.run(PipelineTest.scala:36)
[error] 	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:317)
[error] 	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:483)
[error] 	at sbt.TestRunner.runTest$1(TestFramework.scala:113)
[error] 	at sbt.TestRunner.run(TestFramework.scala:124)
[error] 	at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282)
[error] 	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246)
[error] 	at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282)
[error] 	at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282)
[error] 	at sbt.TestFunction.apply(TestFramework.scala:294)
[error] 	at sbt.Tests$.$anonfun$toTask$1(Tests.scala:309)
[error] 	at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46)
[error] 	at sbt.std.Transform$$anon$4.work(System.scala:67)
[error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:269)
[error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16)
[error] 	at sbt.Execute.work(Execute.scala:278)
[error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:269)
[error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)
[error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[error] 	at java.lang.Thread.run(Thread.java:748)
[error] Caused by: java.lang.ClassNotFoundException: scala.collection.compat.Factory$
[error] 	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
[error] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
[error] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
[error] 	at scalikejdbc.DBSession$class.list(DBSession.scala:295)
[error] 	at scalikejdbc.ActiveSession.list(DBSession.scala:837)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$list$1.apply(DBSessionWrapper.scala:52)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$list$1.apply(DBSessionWrapper.scala:52)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$withAttributesSwitchedDBSession$1.apply(DBSessionWrapper.scala:34)
[error] 	at scalikejdbc.DBSessionWrapper$$anonfun$withAttributesSwitchedDBSession$1.apply(DBSessionWrapper.scala:33)
[error] 	at scalikejdbc.DBSessionAttributesSwitcher.withSwitchedDBSession(DBSessionAttributesSwitcher.scala:31)
[error] 	at scalikejdbc.DBSessionWrapper.withAttributesSwitchedDBSession(DBSessionWrapper.scala:33)
[error] 	at scalikejdbc.DBSessionWrapper.list(DBSessionWrapper.scala:52)
[error] 	at scalikejdbc.SQLToList$class.result(SQL.scala:931)
[error] 	at scalikejdbc.SQLToListImpl.result(SQL.scala:944)
[error] 	at scalikejdbc.SQLToListImpl.result(SQL.scala:944)
[error] 	at scalikejdbc.SQLToResult$$anonfun$14.apply(SQL.scala:811)
[error] 	at scalikejdbc.SQLToResult$$anonfun$14.apply(SQL.scala:811)
[error] 	at scalikejdbc.SQLToResult$class.apply(SQL.scala:817)
[error] 	at scalikejdbc.SQLToListImpl.apply(SQL.scala:944)
[error] 	at be.persgroep.ngage.wonka.Pipeline$$anonfun$5.apply(Pipeline.scala:471)
[error] 	at be.persgroep.ngage.wonka.Pipeline$$anonfun$5.apply(Pipeline.scala:460)
[error] 	at scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:242)
[error] 	at scalikejdbc.DB.autoCommit(DB.scala:60)
[error] 	at scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:216)
[error] 	at scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
[error] 	at scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
[error] 	at scalikejdbc.DB$.using(DB.scala:139)
[error] 	at scalikejdbc.DB$.autoCommit(DB.scala:215)
[error] 	at be.persgroep.ngage.wonka.Pipeline$.run(Pipeline.scala:460)
[error] 	at be.persgroep.ngage.wonka.PipelineTest.beforeAll(PipelineTest.scala:133)
[error] 	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:212)
[error] 	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
[error] 	at be.persgroep.ngage.wonka.PipelineTest.run(PipelineTest.scala:36)
[error] 	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:317)
[error] 	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:483)
[error] 	at sbt.TestRunner.runTest$1(TestFramework.scala:113)
[error] 	at sbt.TestRunner.run(TestFramework.scala:124)
[error] 	at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282)
[error] 	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246)
[error] 	at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282)
[error] 	at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282)
[error] 	at sbt.TestFunction.apply(TestFramework.scala:294)
[error] 	at sbt.Tests$.$anonfun$toTask$1(Tests.scala:309)
[error] 	at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46)
[error] 	at sbt.std.Transform$$anon$4.work(System.scala:67)
[error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:269)
[error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16)
[error] 	at sbt.Execute.work(Execute.scala:278)
[error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:269)
[error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)
[error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[error] 	at java.lang.Thread.run(Thread.java:748)
[error] (IntegrationTest / executeTests) java.lang.NoClassDefFoundError: scala/collection/compat/Factory$
```

Reverting back to Scapegoat 1.3.8 fixes it....
Hi,
I'm getting the `VarCouldBeVal` warning using [monadic-html](https://github.com/OlivierBlanvillain/monadic-html).

I reproduced it and you can find the snippet [here](https://github.com/Grimalkin8675/scapegoat-false-positive).  
Thanks for your help!
Unlike #125, I think scapegoat really finds false positives for the **Empty if statement** warning.

When defining a function like this:
```
  def checkFoo(things: Future[Seq[String]]): Future[Unit] = {
    things.map(ts => if (ts.contains("foo")) () else throw new Exception("No foo!"))
  }
```
scapegoat will throw this warning:
```
[warning] com.mycom.foobar.File.scala:42: Empty if statement
          if (ts.contains[String]("foo"))
  ()
else
  throw new scala.`package`.Exception("No foo!")
```

The function is supposed to return `Future.unit` in case monadic `things` does contain `"foo"` and a failed future otherwise.
https://github.com/sksamuel/scapegoat/blob/243afff7d534b555e39807360ea30fb61072540a/src/main/scala/com/sksamuel/scapegoat/io/HtmlReportWriter.scala#L63

What you think about add constructor in this method with path to bootstrap.css?
In this case we can have opportunity work without internet because will use path to local bootstrap's file.

P.S.
If you agree with it, i can do pull request with this changes.
It would be good to have descriptions of all of the inspections available somewhere in a structured file (in resources) so it's possible to extract those easily in projects that depend on Scapegoat. Currently, the only way to extract those descriptions is by parsing the README file, which is far from ideal.
I'm thinking specifically about [sonar-scala](https://github.com/mwz/sonar-scala) where we use Scapegoat, but I'm sure that others would also find it useful.

I'm happy to open a PR if this sounds reasonable and we can agree on the approach.
I had to modify the Maven integration steps from the README.  I'd added the compilerPlugin under the org.scala-tools maven-scala-plugin, 2.15.2.  This works fine from Maven compile commands, but fails IntelliJ Builds.

> Error:scalac: Error: scala/xml/NamespaceBinding
> java.lang.NoClassDefFoundError: scala/xml/NamespaceBinding
>	at com.sksamuel.scapegoat.io.IOUtils$.writeHTMLReport(IOUtils.scala:24)

This seems to be the issue Martin Ford described [23 Feb 2015](https://youtrack.jetbrains.com/issue/SCL-8344) (resolved "Won't Fix") and in this other [Jetbrains issue](https://intellij-support.jetbrains.com/hc/en-us/community/posts/205994819-java-lang-NoClassDefFoundError-scala-xml-NamespaceBinding).  The former's workaround escapes me.  The latter's is â€¦ self-defeating.  

I would assume ideally I'd tell the build's VM to use the scala-xml.jar located within my .IdeaIC2018.2\config\plugins\Scala\lib, checked-in to git for others no matter where there vintage of IntelliJ actually puts the scala plugins.  

Could the missing step be added to the README?  