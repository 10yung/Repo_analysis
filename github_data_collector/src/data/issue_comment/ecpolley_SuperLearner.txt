Hi,

Since SuperLearner integrates with caret, I tried to search for a possibility to use the resampling method "timeslice" (for time series) instead of cross validation. However, it seems that only CV is possible in SuperLearner and I haven't found any ways for changing it. SuperLearner.control and SuperLearner.CV.Control don't seem to have this kind of possibility, for example.

Have I overlooked something? If the resampling method cannot be changed, are there any plans in the future for implementing timeslice in SuperLearner?
Thanks
The new method set for recombineCVSL was not being passed to the "call" object, which caused the risks to be calculated incorrectly when the new CV SL object was passed to summary.CV.SuperLearner. The edits to recombineCVSL fixes this.

Risks were calculated correctly for new SL objects created from recombineSL, and the edits to recombineSL only update the call object to reflect the new method used.
This fixes https://github.com/ecpolley/SuperLearner/issues/109 where SL.predict values were not being sorted correctly when using method.NNloglik with CV.SuperLearner.
The combination of 'CV.SuperLearner' with 'NNloglik' method appears to be shuffling the `SL.predict' values in the output. Example below:

    library(SuperLearner)
    set.seed(23432)
    ## training set
    n <- 50
    p <- 10
    X <- matrix(rnorm(n*p), nrow = n, ncol = p)
    colnames(X) <- paste("X", 1:p, sep="")
    X <- data.frame(X)
    Y <- X[, 1] + 5*sqrt(abs(X[, 2] * X[, 3])) + as.numeric(X[, 2] > 1) - as.numeric(X[, 3] < -1) + 2*as.numeric(X[, 3] > 0) + rnorm(n)
    
    ## build Library and run Super Learner
    SL.library <- c("SL.glm", "SL.gam", "SL.glmnet", "SL.lm")
    test <- CV.SuperLearner(Y = Y, X = X, SL.library = SL.library, method = "method.NNLS", cvControl = list(V= n), innerCvControl = list(list(V=n-1)))
    summary(test)
    coef(test)
    
    cor(test$SL.predict, test$library.predict)
    cbind(test$SL.predict, test$library.predict[, 2])
    plot(test$SL.predict, test$library.predict[, 2])
    
    
    Y2 <- as.numeric(Y > 5)
    SL.library <- c("SL.glm", "SL.randomForest", "SL.glmnet")
    test <- CV.SuperLearner(Y = Y2, X = X, SL.library = SL.library, method = "method.NNLS", family = binomial(), cvControl = list(V= n), innerCvControl = list(list(V=n-1)))
    summary(test)
    coef(test)
    
    cor(test$SL.predict, test$library.predict)
    cbind(test$SL.predict, test$library.predict[, 2])
    plot(test$SL.predict, test$library.predict[, 2])
    
    ## build Library and run Super Learner
    Y2 <- as.numeric(Y > 5)
    SL.library <- c("SL.glm", "SL.randomForest", "SL.glmnet")
    test <- CV.SuperLearner(Y = Y2, X = X, SL.library = SL.library, method = "method.NNloglik", family = binomial(), cvControl = list(V= n), innerCvControl = list(list(V=n-1)))
    summary(test)
    coef(test)
    
    cor(test$SL.predict, test$library.predict)
    cbind(test$SL.predict, test$library.predict[, 2]) # why did rows for the SL.predict get scrambled?
    plot(test$SL.predict, test$library.predict[, 2])
    
    
    # try SuperLearner directly
    test <- SuperLearner(Y = Y2, X = X, SL.library = SL.library, method = "method.NNLS", family = binomial(), cvControl = list(V= n))
    summary(test)
    coef(test)
    
    cor(test$SL.predict, test$library.predict)
    cbind(test$SL.predict, test$library.predict[, 2])
    
    test <- SuperLearner(Y = Y2, X = X, SL.library = SL.library, method = "method.NNloglik", family = binomial(), cvControl = list(V= n))
    summary(test)
    coef(test)
    
    cor(test$SL.predict, test$library.predict)
    cbind(test$SL.predict, test$library.predict[, 2])
Hi.

I am trying to do a number of analyses with snowSuperLearner and CV.SuperLearner.  CV.SuperLearner fails with this error:

Error in clusterApply(cl, x = splitList(X, length(cl)), fun = lapply,  : 
  formal argument "x" matched by multiple actual arguments
Calls: system.time ... CV.SuperLearner -> parLapply -> do.call -> clusterApply

The offending CV.SuperLearner call looks like this:

system.time(sl_cv_fit <- CV.SuperLearner(Y = Y, X = X, SL.library = SL.library, verbose = TRUE, method = "method.NNLS", cvControl=list(V=10), parallel=cl,control = list(saveFitLibrary = TRUE)))

cl is a FORK type cluster with 10 nodes.

The statement within CV.SuperLearner that fails appears to be'

cvList <- parLapply(parallel, x = folds, fun = .crossValFun, 
    Y = Y, dataX = X, family = family, SL.library = SL.library, 
    method = method, id = id, obsWeights = obsWeights, verbose = verbose, 
    control = control, cvControl = cvControl, saveAll = saveAll)

It is being run on 64 bit computer a very large memory capacity.  The R version is 3.3.3.

Oh.  This error occurs as soon as control hist that parLapply call.  On a different computer, with less memory (same R version) it fails with a "cannot allocate 4G vector" error -- after about 10 hours of computing.

Can you give me any advice?

Thanks.
      --Ted
I hope I'm not missing something

Is there any work on adding multi-class classification capabilities?  Maybe we could start something with gbm.

If X has only one column and SL.library includes screening algorithms, SL fails, and all algorithms are removed from the library even if they do not use screening.

I'm not sure if this is due to particular screening wrapper implementations or if it is an inherent issue for all screening algorithms, but it comes up with at least a handful of the built in screening wrappers.

This example reproduces the error:

```
Y=rbinom(100, 1, .5)
X=data.frame(X=runif(100))

#works
SuperLearner(Y, X, family=binomial(), SL.library=list("SL.mean", "SL.glm"))

#the following all fail, all algorithms removed
SuperLearner(Y, X, family=binomial(), SL.library=list("SL.mean", "SL.glm", 
     c("SL.glm", "screen.SIS")))
SuperLearner(Y, X, family=binomial(), SL.library=list("SL.mean", "SL.glm", 
     c("SL.glm", "screen.corP")))
SuperLearner(Y, X, family=binomial(), SL.library=list("SL.mean", "SL.glm",
     c("SL.glm", "screen.ttest")))
```

I think an easy solution would be to have SL ignore screening algorithms if ncol(X)==1.
