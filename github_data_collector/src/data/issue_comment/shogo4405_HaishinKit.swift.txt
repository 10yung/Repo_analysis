Dear HaishinKit Team
Â  I want to use your framework to convert the iPhone camera output in real time to .ts video files and save it in a local directory, but it only works with AVCaptureSession.Preset.medium.
  Is there any way to change the preset to 4k and have the correct .ts files without losing frames when switching from one segment of a video file to another?
Thanks in advance
**Describe the bug**
I'm running the example iOS app in iOS 13 and streaming with Mux (tried it with Wowza as well) and am having issues with the audio being incredibly choppy. Using different bitrates is not fixing the issue. This was not an issue in iOS 12.

**To Reproduce**
Steps to reproduce the behavior:
1. Launch HaishinKit example on device running iOS13
2. Start stream
3. Listen to stream playback, it is choppy

**Expected behavior**
Clear/smooth audio 


**Desktop (please complete the following information):**
 - OS: MacOS
- XCode 11.2.1

**Smartphone (please complete the following information):**
 - Device: iPhone X
 - OS: iOS 13.3

**Additional context**
This problem was not occurring in iOS12. 

**Is your feature request related to a problem? Please describe.**

Hi, I am moving my app (SeasonCast) from a custom modified version of LFLiveKit to HashinKit.swift due to it not being updated in 3 years and it's memory leak issues. I would like to have support for streaming while the app is in background mode (I know in the past this was not possible due to VideoToolBox but in recent versions of iOS it works). I got VideoToolBox library to work in the background of LFLiveKit by enabling audio in the background and a minor modification to its equivalence of the H264Encoder.swift class by removing its background observer (https://github.com/LaiFengiOS/LFLiveKit/blob/master/LFLiveKit/coder/LFHardwareVideoEncoder.m). I think it would be possible to do the same thing for this library since it's laid out in a similar matter. I have attempted to modify the code but it seems that the problem preventing it from working in background mode is before H264Encoder.swift and I can't seem to find the reason why.

**Describe the solution you'd like**

I would like the framework to behave in the same exact manner when background mode - audio is not enabled.

When the app has background mode - audio enabled. It should show the microphone recording icon when in background mode (because the microphone would still be active) and if the user is publishing the microphone should still be streaming but the camera should be muted (last frame).

1) Replay kit 2 broadcast extension always gives

width 886
height 1918 
regardless of orientation

Using the following 

 let width = CVPixelBufferGetWidth(imageBuffer)
                let height = CVPixelBufferGetHeight(imageBuffer)
                   broadcaster.stream.videoSettings = [
                       .width:  width,
                       .height: height ,
                       .profileLevel: kVTProfileLevel_H264_Baseline_AutoLevel
                   ]

And then changing the orientation of the device to landscape causes the stream to hang, there are no messages and from device side looks like all is ok.
I run HLS sample on macos. 
(https://github.com/shogo4405/HaishinKit.swift/tree/master/Examples/macOS). i get error "SocketStream write error [0x0]: 1 60." There is a solution any?
Hello ,

**Describe the bug**
When the stream is ON with local recording if the application pass in background the recording is broke without any error and the stream will never pass in any `DefaultAVRecorderDelegate` handler. 

**To Reproduce**
Steps to reproduce the behavior:
1. Start the steam
2. Go in background for 3 secondes 
3. Go back to the app
4. See the local recording which isn't present 

**Expected behavior**
Have an error callback or maintain the local recording. 

Thanks for your help ! 
**Describe the bug**
When I run example on macOS with HLS. Stream not display with version 1.0.0

**To Reproduce**
Steps to reproduce the behavior:
1. Start macOS demo
2. Select HLS
3. Start publishing
4. Open url on safari/vlc

**Expected behavior**
Display stream from camera

**Screenshots**
https://gyazo.com/46b142bbe9aef2ea0aa4b43c331a7de9

**Desktop (please complete the following information):**
 - OS: macOS
 - Browser safari
 - Version 1.0.0
**Describe the bug**

Since version 1.0 I am experiencing issues with the video produced by the framework when playing the video back with ffplay/ ffmpeg.

Although the video still appears to play fine, closes inspection reveals `Invalid timestamp` warnings.

**To Reproduce**
1. Stream to a RTMP or SRT server where you have access to the produced video files.
2. Either play the video via ffplay (`ffplay path/to/my/video.flv`) or convert to a ts stream with ffmpeg (`ffmpeg -i path/to/my/video.flv -codec copy ./out.ts`)
3. Either one of the process should produce warnings along the lines of `Invalid timestamps stream=1, pts=75077, dts=78080, size=12704` (see screenshot)

**Expected behavior**
The video should be playable and/ or convertable without issues.

**Screenshots**

<img width="1092" alt="Invalid Timestamps" src="https://user-images.githubusercontent.com/131222/67215470-cfdd5d80-f421-11e9-987f-8ac115a8b0a3.png">


**Desktop (please complete the following information):**
 - OS: macOS 10.14.6, ffplay version 4.1.4


**Smartphone (please complete the following information):**
 - Device: iPhone 6+, iPhone 7
 - OS: iOS 12, iOS 13

**Additional context**
I am experiencing similar behaviour when streaming via SRT.


Hello, 

**Describe the bug**
Crashlytics is reporting a crash on NetSocket.swift line 103 (`NetSocket.doOutputProcess(_:maxLength:)`). 

**To Reproduce**
I can't reproduce it but it occured 10 times in 1 week in production (not many users).

**Smartphone (please complete the following information):**
Exemple of impacted devices : 
-  12.4.1 (16G102) / iPhone 7
- 12.3.1 (16F203) / iPhone 6s
- 12.4.2 (16G114) / iPad Air
- 11.4.1 (15G77) / iPhone 6

**Additional context**
Here is the logs from Crashlytics : 

```
Crashed: com.haishinkit.HaishinKit.NetSocket.output
0  CoreFoundation                 0x1d8cdd3e0 CFHash + 372
1  CoreFoundation                 0x1d8d70780 CFBasicHashGetCountOfKey + 204
2  CoreFoundation                 0x1d8cde8bc CFSetContainsValue + 116
3  CoreFoundation                 0x1d8cd6e18 CFRunLoopRemoveSource + 164
4  CFNetwork                      0x1d93ebc98 SocketStream::write(__CFWriteStream*, unsigned char const*, long, CFStreamError*) + 592
5  CoreFoundation                 0x1d8cec0c0 CFWriteStreamWrite + 300
6  HaishinKit                     0x10138dba4 NetSocket.doOutputProcess(_:maxLength:) + 103 (NetSocket.swift:103)
7  HaishinKit                     0x10138d98c closure #1 in NetSocket.doOutput(data:locked:) + 49 (NetSocket.swift:49)
8  HaishinKit                     0x1013355d8 thunk for @escaping @callee_guaranteed () -> () (<compiler-generated>)
9  libdispatch.dylib              0x1d8788a38 _dispatch_call_block_and_release + 24
10 libdispatch.dylib              0x1d87897d4 _dispatch_client_callout + 16
11 libdispatch.dylib              0x1d8732320 _dispatch_lane_serial_drain$VARIANT$mp + 592
12 libdispatch.dylib              0x1d8732e3c _dispatch_lane_invoke$VARIANT$mp + 428
13 libdispatch.dylib              0x1d873b4a8 _dispatch_workloop_worker_thread + 596
14 libsystem_pthread.dylib        0x1d8969114 _pthread_wqthread + 304
15 libsystem_pthread.dylib        0x1d896bcd4 start_wqthread + 4
```
```
crash_info_entry_1
*** CFHash() called with NULL ***
```

Have you any idea how to fix it ?
Thanks ! 
This is a bug in https://github.com/shogo4405/HaishinKit.swift/pull/560 .
I need a long stream name with a lot of parameters and I don't save filename on device. 
