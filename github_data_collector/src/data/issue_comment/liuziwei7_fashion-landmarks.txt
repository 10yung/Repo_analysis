Dear Ziwei Liu
I am trying to run inference of the models available on github on some images. Please excuse if it's a naive question but can these models be loaded on cpu-machine to run inference ?
Dear Ziwei Liu:
       A problem confuses me.Can we use the bounding box position as  a konwn information in the testing set. I notice that you trian three network for upper,lower and full-body clothes. As I can not find the train code. Do you use the bounding box information to pre-process the training data.(crop the bounding box and then padding or resizing to 224*224?).If so,should we train a network to catch the bounding box position?(each class having an object detection network for the bounding box coordinate so that we can test a image and crop the information from the bounding box?).But the object detection network seems difficult to train because we can find that some images both having the upper clothing information and the lower clothing information, how can the network resolve  what is need to recognition?Thanks for your answer.
https://github.com/yysijie/DLAN/
Dear Ziwei Liu:
I have read your paper:DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotationsï¼Œ and it is very helpful for my research.
You mentioned four benchmarks in your paper but I only found "fashion-landmarks" and "landmark detection" models in your GitHub.
Could you release the model about "Consumer to Shop" ? 
It will very helpful for my research.
Thank you very much.
Where are the lossfunctions  of the net? I need help in setting up that weighted L2 loss for landmark localisation
Dear Ziwei,

Awesome and interesting work!

Do you mind shed some lights on what is purpose of the statement -get_orig_coordinate = @(p)((p+0.5)*224-repmat([offset(2),offset(1)]',[pipline.num_points,1]))/scale;?

I can not relate this to the paper, particularly (p+0.5)*224. I don't have matlab so I won't be able to debug the value but when I run pyCaffe those values of landmarks came out of stage 1 forward are very small, same as pseudo labels (all lower than 0.01). Any explanations will be greatly appreciated! Thanks. 