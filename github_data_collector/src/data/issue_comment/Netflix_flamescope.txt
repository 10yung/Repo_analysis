Mixing package managers is not recommended. Right now we have `package-lock.json` and `yarn.lock` on the project. We should keep only one and remove the other to avoid confusion and misuse.

Based on the README.md we should keep `yarn.lock` and remove `package-lock.json` (since that's what we recommend using).
Use the new StackProcessors introduced in `nflxprofile` to improve
visualization of Node.js FlameGraphs.

---

A new `Option` button was added to the interface, incorporating "Java Package Name" and "Layout":

![img-2019-12-27-100323](https://user-images.githubusercontent.com/4048656/71527429-423e4400-2890-11ea-8c75-2a81d7467f2c.png)

This button will open a modal with FlameGraph visualization options:

![img-2019-12-27-100331](https://user-images.githubusercontent.com/4048656/71527457-5da94f00-2890-11ea-8487-57629305a45b.png)

"Java Package Name" was incorporated in "FlameGraph Flavor" as "Group by Package (Java)":

![img-2019-12-27-100519](https://user-images.githubusercontent.com/4048656/71527472-79acf080-2890-11ea-95b4-3376ff9d62ea.png)

---

When using the new Node.js flavor, JS interpreted and compiled frames will be grouped together, and the V8 JIT prefixes will be removed to make it easier to understand the program flow. For example, the frames below:

![img-2019-12-27-100100](https://user-images.githubusercontent.com/4048656/71527527-b4af2400-2890-11ea-8459-39a58f8fc7d5.png)

Will become:

![img-2019-12-27-100128](https://user-images.githubusercontent.com/4048656/71527534-baa50500-2890-11ea-933e-5849b3b1489b.png)

The coloring represents how much time that frame executed as JIT (optimized) instead of interpreted. We can also see optimization info in the FlameGraph footer:

![img-2019-12-27-100906](https://user-images.githubusercontent.com/4048656/71527590-f3dd7500-2890-11ea-8a63-4907fcb0c279.png)

Node.js Flavor will also group "Argument Adaptor" frames with their following frame. We do that because Argument Adaptors are not part of the relevant execution flow, but they can incur performance penality (thus we also show this information on the footer):

![img-2019-12-27-101009](https://user-images.githubusercontent.com/4048656/71527697-5df61a00-2891-11ea-8e75-83dd121329bc.png)

![img-2019-12-27-101026](https://user-images.githubusercontent.com/4048656/71527698-60587400-2891-11ea-9499-609fe200b7cd.png)

![img-2019-12-27-101237](https://user-images.githubusercontent.com/4048656/71527708-6f3f2680-2891-11ea-8e85-2a49873b7213.png)

---

When using "Group by Package (Node.js)", we group frames by Native code, Kernel code, node_modules, Node.js API and app code:

![img-2019-12-27-095013](https://user-images.githubusercontent.com/4048656/71527119-d3142000-288e-11ea-9446-47870d8a50b9.png)

---

Depends on: https://github.com/Netflix/nflxprofile/pull/4, https://github.com/Netflix/nflxprofile/pull/5 and https://github.com/spiermar/d3-flame-graph/pull/145
We borrowed [`idle_regexp`](https://github.com/Netflix/flamescope/blob/74f75537558f165ea67eb8ced700e9f2d707fd6e/app/util/regexp.py#L79-L82) for our internal system and it looks like the regexp hides some legitimate stacks in softirq context.

Current filter produces the following flamegraph:

![image](https://user-images.githubusercontent.com/89186/62240327-926db480-b38b-11e9-9ace-4e59fde26db4.png)

If I make `idle_regexp` match nothing, I can see much more interesting stuff:

![image](https://user-images.githubusercontent.com/89186/62240417-ca74f780-b38b-11e9-9c87-d3adbe133ee3.png)

The trace comes from on Intel Skylake.


Is it possible to add a new record player or delete function on the web?
I can consider making a more functional platform, I think this will be a good idea.
It would be great to be able to just drop a performance profile file/URL into the UI to analyze it.
I'd really like filtering out some stacks in the GUI.. (probably it's possible in the perf cli somehow though I'm kinda newish to perf ).

Example usage:

Did whole system perf record, found out process `node_exporter` does its periodic work for 30s. Ok, I'm interested what the rest of the system is doing, so I could filter out matching regex (( e.g. if this stack or its parent stack match the regex ignore/include them ))
As has been mentioned elsewhere, a generic data file format would allow for converters to be written to support formats other than `perf`. Has there been any work towards this yet?

Another approach seems to be what it being implemented in the source with "native" support of various profilers, with [each format having its own parsing routine](https://github.com/Netflix/flamescope/blob/2ff2b1d50407dd080f17b9e5e4705936fcd30dba/app/controllers/heatmap.py#L39). I prefer this second approach, but it seems the interface should be formalized a bit more.

Has a decision been made on which approach to take? I would like to start sending some PRs to provide support for other profilers.
In some use cases, avoiding parsing perf data for multiple times contributes the flamescope server performance & its users' experience. flamescope already has an in-memory cache for the analyzed perf data, and this PR adds file-backed one in case of in-memory cache miss.
In our case, we render some graphs in a page by querying to flamescope which we run with three or a few more instances and the most simplest way to share processed data between them is file-backed cache.

To enable this feature, change `USE_HEATMAP_FILECACHE` in app/config.py to `True`. 

Related issue: https://github.com/Netflix/flamescope/issues/58
Every time people access the flamescope's heatmap, the server processes the perf output data which makes the user awaited. So I am considering to cache preprocessed or first-returned data.

Structure of the response is quite simple;
```
{
    "columns": [0, 1, .....],
    "rows": [980, 960....],
    "values": [ [2, 2, ...], [...], [...], ....],
    "maxvalue": 16,
}
```

The most quick hack to cache it is storing in sessionStorage in local browser. Better idea is to save the data as a metadata beside actual data (In that case, we need to decide naming convention for metadata). Other idea is to store data in DB.

I am going to implement a cache anyway, but I want to ask this before starting, which is,  _what kind of cache is easier to accept for you?_.
