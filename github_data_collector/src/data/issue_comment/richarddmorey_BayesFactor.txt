Something similar to the post hoc tests implemented in JASP for Bayesian ANOVA

![image](https://user-images.githubusercontent.com/11330453/64850585-eec42500-d615-11e9-9afa-ca4406851331.png)

Based on our Twitter discussion:
https://twitter.com/patilindrajeets/status/1142763129715208193
It would be great to be able to estimate contrasts / simple effects / simple slopes and their credible intervals from the posterior using [`emmeans`](https://cran.r-project.org/package=emmeans) (instead of doing this manually by summing up the correct combination of parameters)

This would require is adding (and exporting) two new functions: `recover_data.BFBayesFactor` and `emm_basis.BFBayesFactor`.  Some more info can be found [here](https://cran.r-project.org/web/packages/emmeans/vignettes/xtending.html).

Thanks!
It seems that you get different Bayes Factor values for `ttestBF()` and `generalTestBF()` when using a data set with an unused factor level whose underlying integer value is in between two of the actual used factor levels. I think this discrepancy is ultimately due to the fact that `generalTestBF()` calls `lmBF()`, which calls `reFactorData()` on the data set; however, this does not happen for `ttestBF()`.

Here's a way to reproduce this:

```r
my_data <- data.frame(group = c(rep("a", 50), rep("b", 50), rep("c", 50)),
                      score = rnorm(150))
my_data <- my_data[my_data$group != "b", ]
str(my_data)
#> 'data.frame':	100 obs. of  2 variables:
#>  $ group: Factor w/ 3 levels "a","b","c": 1 1 1 1 1 1 1 1 1 1 ...
#>  $ score: num  -1.153 -0.0543 0.9312 -1.3062 0.7689 ...
```

Note that `group` is a factor with three levels, since it hasn't been releveled after dropping "b".

Now, when you call `ttestBF()` vs. `generalTestBF()`, you get:

```r
ttestBF(formula = score ~ group, data = my_data)
#> Bayes factor analysis
#> --------------
#> [1] Alt., r=0.707 : 0.1833829 Â±0%
#> 
#> Against denominator:
#>   Null, mu1-mu2 = 0 
#> ---
#> Bayes factor type: BFindepSample, JZS

generalTestBF(formula = score ~ group, data = my_data)
#> |================================================================================================================| 100%
#> Bayes factor analysis
#> --------------
#> [1] group : 0.2485882 Â±0.03%
#> 
#> Against denominator:
#>   Intercept only 
#> ---
#> Bayes factor type: BFlinearModel, JZS
```

0.1833829 != 0.2485882 ðŸ‘Ž 

Compare this to when you drop "c" instead of "b":

```r
my_data <- data.frame(group = c(rep("a", 50), rep("b", 50), rep("c", 50)),
                      score = rnorm(150))
my_data <- my_data[my_data$group != "c", ]
str(my_data)
#> 'data.frame':	100 obs. of  2 variables:
#>  $ group: Factor w/ 3 levels "a","b","c": 1 1 1 1 1 1 1 1 1 1 ...
#>  $ score: num  -0.613 -1.569 -0.367 1.704 -1.508 ...
```

You still have an unused factor level, but now you get equivalent results with `ttestBF()` and `generalTestBF()`:

```r
ttestBF(formula = score ~ group, data = my_data)
#>  Bayes factor analysis
#>  --------------
#>  [1] Alt., r=0.707 : 0.2177451 Â±0.03%
#>  
#>  Against denominator:
#>    Null, mu1-mu2 = 0 
#>  ---
#>  Bayes factor type: BFindepSample, JZS
generalTestBF(formula = score ~ group, data = my_data)
#> |================================================================================================================| 100%
#> Bayes factor analysis
#> --------------
#> [1] group : 0.2177451 Â±0.03%
#> 
#> Against denominator:
#>   Intercept only 
#> ---
#> Bayes factor type: BFlinearModel, JZS
```

0.2177451 == 0.2177451 ðŸ‘ 
Basic issue: the Bayes Factor seems to depend on the arbitrary labeling of ANOVA factors. 

The attached code creates a data set with two factors. It then flips the labeling of the factors so that the first factor is the second factor and the second factor is the first. Finally, it computes BFs for the original data and the "flipped" data using the top-down approach. The BFs do not tie across the two outputs. 

One potential issue might be how I specify the rscaleEffects because the problem doesn't seem to exist when I use the defaults. Perhaps I am missing something, but this appears to be a bug.

[BayesFactor Issue.txt](https://github.com/richarddmorey/BayesFactor/files/1990349/BayesFactor.Issue.txt)



I've recently come across an issue where `ttestBF` fails if the BayesFactor package is not imported, it appears that this issue is resolved in the current version here on github. Is there any plan to release an updated version of the package to CRAN in the near future?

```
x = c(34.38, 39.33, 108.63, 88, 81, 49.25, 75, 82.86, 85, 86.6, 70, 
  81, 17.46, 50, 70.5, 58.38, 35.3, 45, 53, 38.75, 38, 31.69, 49, 
  34, 44, 50, 23.54, 35)
mu = 9.8
rscale = 0.707106781186548
nsim = 10000

test1 = BayesFactor::ttestBF(x=x,y=NULL, mu=mu, rscale=rscale,
                             posterior=TRUE, iterations=nsim)


library(BayesFactor)

test2 = BayesFactor::ttestBF(x=x,y=NULL, mu=mu, rscale=rscale,
                                posterior=TRUE, iterations=nsim)
```
`ttestBF` appears to have issues when a tibble is given as input. Consider this tibble:

```
tibble::tribble(
  ~value, ~group,
  4,    "a",
  1,    "b",
  5,    "a",
  2,    "b"
) -> df
```
And, in contrast, this data.frame version of the same data:

```
df2 <- data.frame(df)
````
To check:
```
class(df)
class(df2)
```

In `checking.R` this evaluation is performed (line 42):
```
is.numeric(df["value"])
is.numeric(df2["value"])

````
leading to a wrong conclusion for df, and to a right conclusion for df2. So, that's the problem.

Seen from a different perspective, tibble subsetting does *not* yield a vector, but a tibble, which is an unexpected behavior, see:

````
df[, "value"] %>% str
df2[, "value"] %>% str
````

I suggest replacing the code in `checking.R` by something like this (see line 42):

```
is.numeric(df[["value"]])
is.numeric(df2[["value"]])
```
That should solve the issue.


For reference, line 42:

```
if(!is.numeric(data[,dv])) stop("Dependent variable must be numeric.")
```
via email:

> Here is some code that should illustrate my question:


    IQ<-rnorm(10000,100,15)
    bf<-ttestBF(IQ, mu=100, posterior=TRUE, iterations=1000)
    summary(bf)

> The posterior of delta has a mean above 6.5 (~100/15). When I subtract 100 from the IQ scores and use mu=0, the posterior distribution of delta looks okay.
Hi Richard,

First of all, thank you very much for all the work with BayesFactor!

I've just started studing bayes data analysis and have little experience with fitting models to data, so my questions below may sound very noob.
Nevertheless, I'd be very grateful if you could help me with three questions concerning generalTestBF.

I've included some code below to (hopefuly) help you understanding my questions.

1. Can I use it to do a regression with one of the predictors being "time", i.e. repeated measures?
2. Considering the posterior for the predictor fb_type-1: a median of -1.06 means that for every "1" feedback received there is a reduction of 1 in performance (similarly to a linear regression estimate)? Is that expected that fb_type-1 and fb_type-2 posteriors have the same values (except for the signs)?
3. Given that my data is closer to "nonlinear" than "linear" (please, see the plot performance X block in the code below), is there a way of using a nonlinear model with generalTestBF?

Thank you very much in advance!

Best regards,
Flavio


# Libraries
library(ggplot2)
library(BayesFactor)

# Simulated data for 3 participants

# Performance in a timing task
y1 <- c(300, 230, 200, 190, 170, 165, 160, 157, 159, 155)
y2 <- c(280, 239, 210, 180, 160, 170, 172, 163, 158, 156)
y3 <- c(350, 237, 213, 183, 161, 173, 175, 167, 161, 160)

# Feedback type
fb_s2 <- c(1,1,1,1,2,2,1,1,2,1)
fb_s1 <- c(1,2,1,2,2,1,1,1,2,1)
fb_s3 <- c(1,1,1,1,1,1,2,1,1,2)

####
# Create data frame
df <- data.frame(id = c(rep(1, 10), rep(2, 10), rep(3, 10)), # Participants
           block = 1:10, # Blocks of trials (i.e. the repeated measures)
           performance = c(y1, y2, y3), # Accuracy in a timing task
           fb_type = c(fb_s1, fb_s2, fb_s3)) # Type of feedback received

# Plot performance X block
ggplot(data = df, aes(x = block, y = performance)) +
  geom_point()


# Bayes regression
df$fb_type <- as.factor(df$fb_type)
df$block <- as.factor(df$block)
df$id <- as.factor(df$id)

all_bfs <- generalTestBF(performance ~ block + fb_type + block:fb_type + id, 
                                 data = df, 
                                 whichRandom = 'id', 
                                 neverExclude='^id$')

# Considering effect of ID as random and additive on top of other effects
plot(all_bfs / all_bfs['id'])

# Get the posterior for one of the models
fit_bf <- lmBF(performance ~ block + fb_type + id, data = df, whichRandom = 'id')
fit_posterior <- posterior(fit_bf, iterations = 10000)
summary(fit_posterior)


# Posterior distribution for feedback type as a predictor variable
plot(fit_posterior[ ,'fb_type-1'])
plot(fit_posterior[ ,'fb_type-2'])
Hello,

Usually I have no problem to plot BFlinearModel, but in my last data analysis, I'm testing a model looking like that:
``` R
generalTestBF(initialDev ~ FixationSide*S1.Duration*Gap.Duration*Participant, 
                                 data=result, whichRandom="Participant")
```
on a dataset that uses trial-by-trial measures of initialDev on 11 participants (~65 measures by condition by Participant; that is 500-600 trials by participants).

R output is as follow when I plot the BFlinearModel:
```
Error in seq.default(floor(rng[1]), ceiling(rng[2]), 1) : 
  'from' cannot be NA, NaN or infinite
```