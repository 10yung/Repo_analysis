The readme has most of the essential information but is missing titles and sections as is used in most other tidymodels packages

- [ ] Name
- [ ] Bagdes  
- [ ] hex logo 
- [ ] Introduction 
- [ ] Installation
- [ ] examples/learning more/Usage
- [ ] Contributing

See https://github.com/tidymodels/broom for example
replace with `rlang::abort()` anfd `rlang::warn()`. 
I shouldn't need to explicitly load `earth` but I do.

``` r
library(parsnip)

mars(
  mode = "classification",
  num_terms = 1,
  prod_degree = 1,
  prune_method = "backward"
) %>% 
  set_engine("earth") %>% 
  fit(Species ~ ., iris)
#> Error in get(ctr, mode = "function", envir = parent.frame()): object 'contr.earth.response' of mode 'function' was not found
#> Timing stopped at: 0 0 0

library(earth)
#> Loading required package: Formula
#> Loading required package: plotmo
#> Loading required package: plotrix
#> Loading required package: TeachingDemos

mars(
  mode = "classification",
  num_terms = 1,
  prod_degree = 1,
  prune_method = "backward"
) %>% 
  set_engine("earth") %>% 
  fit(Species ~ ., iris)
#> parsnip model object
#> 
#> Fit time:  50ms 
#> GLM (family binomial, link logit):
#>            nulldev  df       dev  df   devratio     AIC iters converged
#> setosa     190.954 149   190.954 149          0     193     4         1
#> versicolor 190.954 149   190.954 149          0     193     4         1
#> virginica  190.954 149   190.954 149          0     193     4         1
#> 
#> Earth selected 1 of 15 terms, and 0 of 4 predictors
#> Termination condition: Reached nk 21
#> Importance: Sepal.Length-unused, Sepal.Width-unused, Petal.Length-unused, ...
#> Number of terms at each degree of interaction: 1 (intercept only model)
#> 
#> Earth
#>                  GCV       RSS GRSq RSq
#> setosa     0.2252151  33.33333    0   0
#> versicolor 0.2252151  33.33333    0   0
#> virginica  0.2252151  33.33333    0   0
#> All        0.6756452 100.00000    0   0
```

<sup>Created on 2020-01-05 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>

I'm attaching a zipped rds object that contains all the information to make this example reproducible. I'm essentially trying to make a prediction on a fitted workflow, but that gives me the following error. Could you please take a look?

```
library(recipes)
library(parsnip)

df_input <- diamonds[1, ]
pipeline <- readRDS("/pipeline.rds")

predict(pipeline$workflow, df_input)
```

Giving the following error:
```
Error in UseMethod("predict") : 
  no applicable method for 'predict' applied to an object of class "c('elnet', 'glmnet')"
```

[pipeline.rds.zip](https://github.com/tidymodels/parsnip/files/3977896/pipeline.rds.zip)

fixed the step numbers and a few more typos

also noticed that the pkgdown site still shows the typo from PR #233 
Though `early_stopping_rounds` argument of `xgb.train()` is accessible on `set_engine()`, it also requires `watchlist`, a named list of `xgb.DMatrix` datasets to use for evaluating model performance and it's a bit hard to create this. This is because how parsnip converts `data.frame` to `xgb.DMatrix` internally is not exposed to us. For this reason, I needed to peek at the code inside parsnip and create this function:

``` r
create_xgb_dmatrix <- function(d) {
  o <- parsnip:::convert_form_to_xy_fit(y ~ ., d, composition = "matrix")
  xgboost::xgb.DMatrix(data = o$x, label = as.integer(o$y == "yes"), missing = NA)
}

watchlist <- list(
  train = create_xgb_dmatrix(analysis(fold))),
  test = create_xgb_dmatrix(assessment(fold)))
)
```

Is it possible to add some interface for early stopping? Or can `convert_form_to_xy_fit()` be exposed eventually?
Hey there,

I _really_ want to use parsnip, but the dealbreaker thus far has been the inability to get verbosity going while fitting models. I've tried using the verbose command from `fit_control()` as well as setting the verbosity directly from the engine for `xgboost` to no avail. Any ideas as to why this might be occurring? 
```
ml_model_1_spec = boost_tree(mode = "classification", trees = 50)
ml_model_1_fit = ml_model_1_spec %>%
    set_engine(engine = "xgboost", verbose = 2, nthread = 8) %>%
    fit(formula = outcome ~ .,
        data = pvd_3 %>% mutate(outcome = outcome %>% as.numeric() %>% as.factor()),
        control = fit_control(verbosity = 2L))
```
In `get_model_env()` we document the original parameter names of the underlying engine

```r
> parsnip::get_model_env()$decision_tree_args
# A tibble: 6 x 5
  engine parsnip         original               func             has_submodel
  <chr>  <chr>           <chr>                  <list>           <lgl>       
1 rpart  tree_depth      maxdepth               <named list [2]> FALSE       
2 rpart  min_n           minsplit               <named list [2]> FALSE       
3 rpart  cost_complexity cp                     <named list [2]> FALSE       
4 C5.0   min_n           minCases               <named list [2]> FALSE       
5 spark  tree_depth      max_depth              <named list [2]> FALSE       
6 spark  min_n           min_instances_per_node <named list [2]> FALSE  
```

but we don't say anything about the default values of those parameters.

If we record the function that those original parameters go along with, we could have a function that does a dynamic lookup like this:

```r
lookup_default <- function(fn, arg) {
  arg_list <- formals(fn)
  
  has_arg <- arg %in% names(arg_list)
  if (!has_arg) {
    stop("Argument: `", arg, "` does not exist in the function.", call. = FALSE)
  }
  
  default_value <- formals(fn)[[arg]]
  default_value
}

lookup_default(rpart::rpart.control, "cp")
#> [1] 0.01

lookup_default(rpart::rpart.control, "cp_oops")
#> Error: Argument: `cp_oops` does not exist in the function.
```

It would be nice to expose this information to users in the form of a tibble like `parsnip::get_model_env()$decision_tree_args` that also has columns for the function that the original parameters come from, and the default values.
Right now, only main arguments can be set. 
Hi,

Trying to build my first ever `parsnip model` and getting a weird `error` both with `random forest` and `logistic regression`.

Here is my outcome variable and its `levels`:
```r
levels(df$IS_ESCALATED)

[1] "N" "Y"
```

When try to build the model:

```r
logistic_reg(mode = "classification") %>% 
  set_engine("glm") %>%
  fit(IS_ESCALATED ~ ., data = df)

Error in model.matrix.default(mt, mf, contrasts) : variable 1 has no levels
```

When try `random forest`:

```r
rand_forest(mode = "classification") %>%
set_engine("randomForest") %>%
   fit(IS_ESCALATED ~ ., data = df)

Error in randomForest.default(x = as.data.frame(x), y = y) : Need at least two classes to do classification.
```

Here is the `traceback()`

```r
17.
stop("Need at least two classes to do classification.")
16.
randomForest.default(x = as.data.frame(x), y = y)
15.
randomForest::randomForest(x = as.data.frame(x), y = y)
14.
eval_tidy(e, ...)
13.
eval_mod(fit_call, capture = control$verbosity == 0, catch = control$catch, env = env, ...)
12.
xy_xy(object = object, env = env, control = control, target = target)
11.
form_xy(object = object, control = control, env = eval_env, target = object$method$fit$interface, ...)
10.
fit.model_spec(., IS_ESCALATED ~ ., data = df)
9.
fit(., IS_ESCALATED ~ ., data = df)
8.
function_list[[k]](value)
7.
withVisible(function_list[[k]](value))
6.
freduce(value, `_function_list`)
5.
`_fseq`(`_lhs`)
4.
eval(quote(`_fseq`(`_lhs`)), env, env)
3.
eval(quote(`_fseq`(`_lhs`)), env, env)
2.
withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))
1.
rf_defaults %>% set_engine("randomForest") %>% fit(IS_ESCALATED ~ ., data = df)

```

Also, tried with `boost_tree()`

```{r}
boost_tree(mode = "classification") %>%
  set_engine("xgboost") %>%
  fit(IS_ESCALATED ~ .,data=df)

Error in check.booster.params(params, ...) : 'num_class' > 1 parameter must be set for multiclass classification
```

the `df` was created using `recipes`:

```r
base_recipe <- my_train_set %>%
            recipe(IS_ESCALATED ~ ., data = .) %>%       
 step_rm(INCIDENT_NUM,RNDSC,RNASC,BILL_DATE,SERVICE_ID,EASTING,NORTHING,CONSTITUENCY,PARISH) %>%
            step_string2factor(all_nominal()) %>%
            step_date(REPORT_DATE) %>%
            step_holiday(REPORT_DATE,holidays = c("NewYearsDay","ChristmasDay","GBBankHoliday","GBMayDay","GBMilleniumDay","GBSummerBankHoliday",
                                                  "BoxingDay","Easter","EasterSunday","GoodFriday")) %>%
            step_rm(REPORT_DATE)%>%
            step_other(REASON, other = "other_lumped")%>%
            step_other(SUB_REASON, other = "other_lumped")%>%
            step_other(CALL_MAPPED, other = "other_lumped")%>%
            step_other(MY_GROUP, other = "other_lumped")%>%
            step_other(SECONDARY_REASON, other = "other_lumped")%>%
            step_dummy(all_nominal(), -all_outcomes(),one_hot = TRUE,naming = partial(dummy_names,sep="__"))%>%
            step_center(all_numeric(), -all_outcomes())  %>%
            step_scale(all_numeric(), -all_outcomes()) %>%
            prep(verbose=TRUE,retain=TRUE)
```

then simply `juice`

```r
df<- juice(base_recipe)
```

Lastly, it works if i use `rpart`:

```r
fitTree <- rpart::rpart(IS_ESCALATED ~ .,data = df, method = "class")

library(caret)
test_baked <- bake(base_recipe,complaints_test)

fitTree_pred <- predict(fitTree,test_baked,type="class")

confusionMatrix(fitTree_pred,test_baked$IS_ESCALATED)
```

thanks