I am working on the 3DShapeNet now, however, I have no idea on the pretrained model, discriminative_40_class.mat and generative_40_class.mat.

Anyone can tell me where to find the pretrained models? or how to generate them by myself. Thanks a lot.
What is the format used for saving the voxels or the occupancy grid? Also, is the .raw or .tiff data considered as voxel data that can be processed using your framework? 
How can I run the code without a GPU?
It is just for a small test. Is it possible?
Thank you
I ran polygon2voxeldemo with example function below and receive error that array exceeds maximum array size preference. Any ideas? Thanks, Justin

> polygon2voxeldemo
Error using polygon2voxel_double
Requested 515396075640x140711718551672x140719189273184 (17179869184.0GB) array exceeds maximum array
size preference. Creation of arrays greater than this limit may take a long time and cause MATLAB to
become unresponsive. See array size limit or preference panel for more information.
Error in polygon2voxel (line 171)
Volume=polygon2voxel_double(FacesA,FacesB,FacesC,VerticesX,VerticesY,VerticesZ,VolumeSize,Wrap);


Error in polygon2voxeldemo (line 35)
  J = polygon2voxel(FV,[120, 120, 120],'none');

```
% Make A Volume with a few blocks
  I = false(120,120,120);
  I(40:60,50:70,60:80)=1; I(60:90,45:75,60:90)=1;
  I(20:60,40:80,20:60)=1; I(60:110,35:85,10:60)=1;

  % Convert the volume to a triangulated mesh
  FV = isosurface(I,0.8);

  % Convert the triangulated mesh back to a surface in a volume
  J = polygon2voxel(FV,[120, 120, 120],'none'); 
  % Fill the volume
  J=imfill(J,'holes');

  % Differences between original and reconstructed
  VD = abs(J-I);

  % Show the original Mesh and Mesh of new volume
  figure, 
  subplot(1,3,1),  title('original')
    patch(FV,'facecolor',[1 0 0],'edgecolor','none'), camlight;view(3);
  subplot(1,3,2), title('converted');
    patch(isosurface(J,0.8),'facecolor',[0 0 1],'edgecolor','none'), camlight;view(3);
  subplot(1,3,3), title('difference');
    patch(isosurface(VD,0.8),'facecolor',[0 0 1],'edgecolor','none'), camlight;view(3); 
```
There are 4 files, discriminative_10_class.mat, discriminative_40_class.mat, generative_10_class.mat and generative_40_class.mat, which I think are pre-trained models. But when I run call rec_test.m with any of these models, I get the following error:

Error using feval
Argument must contain a string or function_handle.

Error in myConvolve2 (line 32)
            target_gpu = feval(kConv,...

Error in rec_test (line 43)
            hidden_presigmoid = myConvolve2(kConv_forward2, batch_data, model.layers{l}.uw, stride,
            'forward'); 

My question is whether pre-training using run_pretrain.m is necessary for running rec_test.m. Also, from where do we get the accuracy of the test data? 

Thanks


Hey,

I really like your work and I would like to reproduce your results on the NYU dataset. How do you turn your point clouds into voxel representation? Do you have the code for this?

Thanks!
How do you read a model and class parameters to sample_test_classification(model,class) ?

The provided models are a struct and I receive an error

> Undefined function 'merge_model' for input arguments of type 'struct'.
> Error in sample_test_classification (line 9)
>     model = merge_model(model);
