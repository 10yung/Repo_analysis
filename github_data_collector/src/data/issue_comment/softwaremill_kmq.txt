In my tests I stumbled upon a case where actor system wouldn't shutdown. Turned out that ConsumeMarkersActor was blocked by polling from kafka (https://stackoverflow.com/questions/50268622/kafka-consumer-hangs-on-poll-when-kafka-is-down). It happens if you shut down kafka before shutting down actor. 

Reactive kafka already solved this issue (https://github.com/akka/alpakka-kafka/blob/master/core/src/main/resources/reference.conf#L57) so It would be good idea to use it. 
Just wanted to know the use of the disableRedeliveryBefore argument of the marker queue?

And as per the logic, I feel the following case scenario would be a failure.
for code reference : 
https://github.com/softwaremill/kmq/blob/391f9f9e72c09d8cd0b44bab0b5c9d776389c8dd/core/src/main/scala/com.softwaremill.kmq/redelivery/ConsumeMarkersActor.scala#L71 

Case Scenario:
For a Topic(X) there is a marker topic(MT). One redelivery tracker is listening to the marker topic.
The order of markers on a partition are SM1, SM2, EM1, EM2, where SMx is start-marker for some key x and EMx is end-marker for some key x.  the redelivery tracker commits on Kafka till EM2.
Then redelivery tracker disconnects and a new redelivery consumer is created, and in between a new SM3 is published.  But as the consumer connects after SM3, endOffset/ disabledRedeliveryBefore for MarkerQueue of partition is after the SM3 offset. 

Problem: 
SM3 would not be tracked by any redelivery tracker.

Possible Solution:
Rather than endOffset, the redelivery tracker can disable redelivery before the last committed offset.


Hi,
Great work, Just wanted to enquire about any way to restrict number of retries for redelivery a message to a queue. So in case the client is down parmanently, the topic would not populate beyond certain fixed number of redelivered messages. 
Hi!

Awesome project!  Can some information be added about how Kafka 0.11's exactly once functionality will or won't be incorporated into this work?  Are they complementary or orthogonal?