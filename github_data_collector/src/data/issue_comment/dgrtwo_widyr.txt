I've been benefited from `widyr::pairwise_count` for years. It is really fast, however, recently I need to get all the combinations within the group and I tried use it again, but this time I want to keep the group ID. Usually, I would `mutate` a new id (named "id2" usually) and group by this new column, and then use `pairwise_count`. But it is really slow!
Let me give an example:
```
> library(dplyr)
> dat <- tibble(group = rep(1:5, each = 2),
+                   letter = c("a", "b",
+                              "a", "c",
+                              "a", "c",
+                              "b", "e",
+                              "b", "f"))
> 
> # count the number of times two letters appear together
> pairwise_count(dat, letter, group)

# A tibble: 8 x 3
  item1 item2     n
  <chr> <chr> <dbl>
1 b     a         1
2 c     a         2
3 a     b         1
4 e     b         1
5 f     b         1
6 a     c         2
7 b     e         1
8 b     f         1
```

Any way I could get the group number? Just like below:
```
library(dplyr)
library(widyr)

dat <- tibble(group = rep(1:5, each = 2),
                  letter = c("a", "b",
                             "a", "c",
                             "a", "c",
                             "b", "e",
                             "b", "f"))

dat %>% 
  mutate(group2 = group) %>% 
  group_by(group) %>% 
  pairwise_count(letter,group2) %>% 
  ungroup()

# A tibble: 10 x 4
   group item1 item2     n
   <int> <chr> <chr> <dbl>
 1     1 b     a         1
 2     1 a     b         1
 3     2 c     a         1
 4     2 a     c         1
 5     3 c     a         1
 6     3 a     c         1
 7     4 e     b         1
 8     4 b     e         1
 9     5 f     b         1
10     5 b     f         1
```
But it is rather slow when there are more groups, any solutions to make it faster?
Thanks.
Hi There,

I love your package. I can't see anything about this in the current issues. I've been trying to create a function that uses `widyr::pairwise_cor()` using the new tidy eval method embrace, but it doesn't work. I can't see why. Here is a reproducible example:

```
library(dplyr)
library(gapminder)
library(tidyr)
library(widyr)

# this works
gapminder %>%
  pairwise_cor(country, year, lifeExp)

dummy_function <- function(data, var1, var2, var3) {
  data %>%
    pairwise_cor({{ var1 }}, {{ var2 }}, {{ var3 }}) %>%
    return()
}

# this doesn't work
dummy_function(gapminder, country, year, lifeExp)
```
This returns:
```
Error: Invalid column specification 
```


Are you able to help?
Many thanks

Session info:
```
- Session info ------------------------------------------------------------------------------------------------------
 setting  value                       
 version  R version 3.6.1 (2019-07-05)
 os       Windows 10 x64              
 system   x86_64, mingw32             
 ui       RStudio                     
 language (EN)                        
 collate  English_United Kingdom.1252 
 ctype    English_United Kingdom.1252 
 tz       Europe/London               
 date     2019-09-26                  

- Packages ----------------------------------------------------------------------------------------------------------
 package     * version date       lib source        
 assertthat    0.2.1   2019-03-21 [1] CRAN (R 3.6.0)
 backports     1.1.4   2019-04-10 [1] CRAN (R 3.6.0)
 broom         0.5.2   2019-04-07 [1] CRAN (R 3.6.0)
 cli           1.1.0   2019-03-19 [1] CRAN (R 3.6.0)
 crayon        1.3.4   2017-09-16 [1] CRAN (R 3.6.0)
 dplyr       * 0.8.3   2019-07-04 [1] CRAN (R 3.6.1)
 fansi         0.4.0   2018-10-05 [1] CRAN (R 3.6.0)
 gapminder   * 0.3.0   2017-10-31 [1] CRAN (R 3.6.0)
 generics      0.0.2   2018-11-29 [1] CRAN (R 3.6.1)
 glue          1.3.1   2019-03-12 [1] CRAN (R 3.6.0)
 janeaustenr   0.1.5   2017-06-10 [1] CRAN (R 3.6.0)
 lattice       0.20-38 2018-11-04 [1] CRAN (R 3.6.1)
 lifecycle     0.1.0   2019-08-01 [1] CRAN (R 3.6.1)
 magrittr      1.5     2014-11-22 [1] CRAN (R 3.6.0)
 Matrix        1.2-17  2019-03-22 [1] CRAN (R 3.6.1)
 nlme          3.1-140 2019-05-12 [1] CRAN (R 3.6.1)
 packrat       0.5.0   2018-11-14 [1] CRAN (R 3.6.0)
 pillar        1.4.2   2019-06-29 [1] CRAN (R 3.6.0)
 pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 3.6.1)
 plyr          1.8.4   2016-06-08 [1] CRAN (R 3.6.0)
 purrr         0.3.2   2019-03-15 [1] CRAN (R 3.6.0)
 R6            2.4.0   2019-02-14 [1] CRAN (R 3.6.0)
 Rcpp          1.0.2   2019-07-25 [1] CRAN (R 3.6.1)
 reshape2      1.4.3   2017-12-11 [1] CRAN (R 3.6.0)
 rlang         0.4.0   2019-06-25 [1] CRAN (R 3.6.0)
 rstudioapi    0.10    2019-03-19 [1] CRAN (R 3.6.0)
 sessioninfo   1.1.1   2018-11-05 [1] CRAN (R 3.6.0)
 SnowballC     0.6.0   2019-01-15 [1] CRAN (R 3.6.0)
 stringi       1.4.3   2019-03-12 [1] CRAN (R 3.6.0)
 stringr       1.4.0   2019-02-10 [1] CRAN (R 3.6.0)
 tibble        2.1.3   2019-06-06 [1] CRAN (R 3.6.0)
 tidyr       * 1.0.0   2019-09-11 [1] CRAN (R 3.6.1)
 tidyselect    0.2.5   2018-10-11 [1] CRAN (R 3.6.0)
 tidytext      0.2.2   2019-07-29 [1] CRAN (R 3.6.1)
 tokenizers    0.2.1   2018-03-29 [1] CRAN (R 3.6.0)
 utf8          1.1.4   2018-05-24 [1] CRAN (R 3.6.0)
 vctrs         0.2.0   2019-07-05 [1] CRAN (R 3.6.1)
 widyr       * 0.1.2   2019-09-09 [1] CRAN (R 3.6.1)
 withr         2.1.2   2018-03-15 [1] CRAN (R 3.6.0)
 zeallot       0.1.0   2018-01-28 [1] CRAN (R 3.6.0)
```
The latest version of `dplyr` on CRAN `v0.8.3` (and `rlang` on CRAN `v0.4.0`) throws such a warning that is a depreciation notice of the use of `data_frame`.

```
Warning message:
`data_frame()` is deprecated, use `tibble()`.
```

`tidyr::nest_()` and `tidyr::unnest_()` have been deprecated for some time and are defunct in dev tidyr, which is slated to become v1.0.0.

Here's what we see in revdep checks:

https://github.com/tidyverse/tidyr/blob/master/revdep/problems.md#widyr

I'm hoping that the recent updates in fuzzyjoin and the thread below give some good leads on how to adapt widyr. Let me know if I can be of help!

https://github.com/tidyverse/tidyr/issues/692#issuecomment-518422512


I was wondering if there was a function that takes the pairwise differences (A-B)... And then I realized maybe having a function that applies any function and applies it in a pairwise manner. Something like:

```
# subtract
df %>% 
  pairwise(.f = '-')

# add
df %>% 
  pairwise(.f = '+')

# multiply
df %>% 
  pairwise(.f = '*')
```

Would this be useful? If there's interest I might try implementing something like that.
I'm not totally sure if this is a feature or a bug but many pairwise comparisons drop 0s in the output. For instance, in the pairwise count example

```
dat <- data_frame(group = rep(1:5, each = 2),
                  letter = c("a", "b",
                             "a", "c",
                             "a", "c",
                             "b", "e",
                             "b", "f"))
count the number of times two letters appear together
pairwise_count(dat, letter, group, upper = FALSE)
```

The output only includes those with a count greater than 1
```
item1 item2     n
  <chr> <chr> <dbl>
1 a     b         1
2 a     c         2
3 b     e         1
4 b     f         1
```
It would be great to have an option to include all pairs of items. My actual use case is for having pairwise similarities of exactly 0 so it would be great to have that feature there as well.
a bit of a longwinded RepEx, but:

```
library(gutenbergr)
#> Warning: package 'gutenbergr' was built under R version 3.5.3
library(tidytext)
library(tidyverse)
#> -- Attaching packages ------------------------------------------------------------------- tidyverse 1.2.1 --
#> v ggplot2 3.1.0       v purrr   0.3.1  
#> v tibble  2.0.1       v dplyr   0.8.0.1
#> v tidyr   0.8.3       v stringr 1.3.1  
#> v readr   1.3.1       v forcats 0.3.0
#> -- Conflicts ---------------------------------------------------------------------- tidyverse_conflicts() --
#> x dplyr::filter() masks stats::filter()
#> x dplyr::lag()    masks stats::lag()
library(widyr)
#> Warning: package 'widyr' was built under R version 3.5.3

TI <- gutenberg_works(title == "Treasure Island") %>% pull(gutenberg_id) %>% 
  gutenberg_download(.) %>% unnest_tokens(., word, text) %>% 
  count(word, sort = TRUE) %>% mutate(source = "T.I.")
#> Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest
#> Using mirror http://aleph.gutenberg.org

Wi <- gutenberg_works(title == "The Wonderful Wizard of Oz") %>% pull(gutenberg_id) %>% 
  gutenberg_download(.) %>% unnest_tokens(., word, text) %>% 
  count(word, sort = TRUE)  %>% mutate(source = "Wiz")

Co <- gutenberg_works(title == "The United States Constitution") %>% pull(gutenberg_id) %>% 
  gutenberg_download(.) %>% unnest_tokens(., word, text) %>% 
  count(word, sort = TRUE)  %>% mutate(source = "Con")

JFK <- gutenberg_works(title == "John F. Kennedy's Inaugural Address") %>% pull(gutenberg_id) %>% 
  gutenberg_download(.) %>% unnest_tokens(., word, text) %>% 
  count(word, sort = TRUE)  %>% mutate(source = "JFK")

## Combine
df <- bind_rows(TI, Wi, Co, JFK)

## Do similarity
df %>% 
  bind_tf_idf(word, source, n) %>% arrange(desc(tf_idf)) %>%
  pairwise_similarity(source, word, tf_idf, upper = FALSE, sort = TRUE)
#> # A tibble: 6 x 3
#>   item1 item2 similarity
#>   <chr> <chr>      <dbl>
#> 1 Wiz   T.I.      0.349 
#> 2 Con   JFK       0.0513
#> 3 T.I.  JFK       0.0483
#> 4 Con   T.I.      0.0314
#> 5 Wiz   JFK       0.0301
#> 6 Con   Wiz       0.0155

## So far so good, but what if I wanted to see which is most likely to say "I love you"? 
Love <- tibble(word = rep("I love you", 10), source = "TEST") %>% unnest_tokens(word, word) %>% 
  count(source, word, sort = TRUE) 

## With four sources it's possible:
  bind_rows(Love, df) %>% 
  bind_tf_idf(word, source, n) %>% arrange(desc(tf_idf)) %>%
  pairwise_similarity(source, word, tf_idf, upper = FALSE, sort = TRUE) %>% 
  filter(item1 == "TEST") %>% select(-item1)
#> # A tibble: 4 x 2
#>   item2 similarity
#>   <chr>      <dbl>
#> 1 T.I.      0.0654
#> 2 Wiz       0.0526
#> 3 JFK       0.0267
#> 4 Con       0

## But with only two, it errors out:
df2 <- bind_rows(TI, Wi)

bind_rows(Love, df2) %>% 
  bind_tf_idf(word, source, n) %>% arrange(desc(tf_idf)) %>%
  pairwise_similarity(source, word, tf_idf, upper = FALSE, sort = TRUE) %>% 
  filter(item1 == "TEST") %>% select(-item1)
#> Error in `colnames<-`(`*tmp*`, value = c("item1", "item2", "value")): attempt to set 'colnames' on an object with less than two dimensions

## How come?
```

The limit should probably be documented no?

All examples I saw include only correlations between same variables. For example, correlations of sales between firms:
`correlations <- widyr::pairwise_cor(sample_of_firms, id, year, sales)`

What if I want to calculate correlations between different variables, for example, sales and costs columns:
`correlations <- widyr::pairwise_cor(sample_of_firms, id, year, c(sales, costs))`

If I understand it right this is not possible since argument value includes only one column?
Since ```widyr``` has two distance based functions, namely ```pairwise_delta``` and ```pairwise_dist```, I was wondering if we can take it a step further and add functionality for the data analyst/scientist to scale these pairwise distances to *k* dimensions. This is done in base R using ```cmdscale``` that takes a distance matrix and returns a matrix with each item as a row and each of the *k* dimensions as columns.  The points are calculated such that the distance is maintained.

Example:

```
euro_mat <- as.matrix(eurodist)[1:5, 1:5]

euro_mat
#>           Athens Barcelona Brussels Calais Cherbourg
#> Athens         0      3313     2963   3175      3339
#> Barcelona   3313         0     1318   1326      1294
#> Brussels    2963      1318        0    204       583
#> Calais      3175      1326      204      0       460
#> Cherbourg   3339      1294      583    460         0

cmdscale(euro_mat)
#>                [,1]       [,2]
#> Athens    2515.1944   14.68566
#> Barcelona -659.3761  961.30504
#> Brussels  -422.4595 -328.35478
#> Calais    -633.6209 -359.57342
#> Cherbourg -799.7379 -288.06249
```
In the tidy, widy way, I figured the following way to do this when we have a distance based result from a widyr method:

```
library(tidytext)
library(janeaustenr)
library(widyr)
library(tidyverse)
#> ── Attaching packages ───────────────────────────────────────────────────────── tidyverse 1.2.1 ──
#> ✔ ggplot2 2.2.1.9000     ✔ purrr   0.2.4     
#> ✔ tibble  1.4.2          ✔ dplyr   0.7.4     
#> ✔ tidyr   0.8.0          ✔ stringr 1.3.0     
#> ✔ readr   1.1.1          ✔ forcats 0.3.0
#> ── Conflicts ──────────────────────────────────────────────────────────── tidyverse_conflicts() ──
#> ✖ dplyr::filter() masks stats::filter()
#> ✖ dplyr::lag()    masks stats::lag()

austen_dist <- austen_books() %>%
  unnest_tokens(word, text) %>%
  count(book, word) %>%
  pairwise_dist(book, word, n)

## From utils.R in widyr package (private method), didnt want to use :::
col_name <- function(x, default = stop("Please supply column name", call. = FALSE))
{
  if (is.character(x))
    return(x)
  if (identical(x, quote(expr = )))
    return(default)
  if (is.name(x))
    return(as.character(x))
  if (is.null(x))
    return(x)
  stop("Invalid column specification", call. = FALSE)
}

multi_scale <- function(tbl, item1, item2, value, k = 2, ...) {
  multi_scale_(tbl,
               col_name(substitute(item1)),
               col_name(substitute(item2)),
               col_name(substitute(value)),
               k = 2, ...)
}


multi_scale_ <- function(tbl, item1, item2, value, k = 2) {
  tbl_matrix <- tbl %>%
    spread(item2, col_name(value), fill = 0) %>%
    as.data.frame() %>%
    remove_rownames() %>%
    column_to_rownames("item1") %>%
    as.matrix()

  cmdscale(tbl_matrix, k = k) %>%
    as.data.frame() %>%
    rownames_to_column("item") %>%
    as.tibble()
}

austen_dist %>%
  multi_scale(item1, item2, distance)
#> # A tibble: 6 x 3
#>   item                     V1      V2
#>   <chr>                 <dbl>   <dbl>
#> 1 Sense & Sensibility   211.    302. 
#> 2 Pride & Prejudice      36.7   -64.8
#> 3 Mansfield Park      -3942.   1325. 
#> 4 Emma                -3513.  -1525. 
#> 5 Northanger Abbey     3924.   -115. 
#> 6 Persuasion           3284.     77.5
```
This can be used for something as shown below, where we compare the distances between the austen books separated by euclidean distance:
```
austen_dist %>%
  multi_scale(item1, item2, distance) %>%
  ggplot(aes(V1, V2, color = item)) +
  geom_point(size = 3, alpha = 0.8) + 
  scale_y_continuous(limits = c(-4000, 4000)) + 
  theme_bw()
```
![multi_scale](https://user-images.githubusercontent.com/10777197/37742090-821f14a8-2d3a-11e8-8aa0-f22814108c4a.png)

I've also solved #13 by adding a ```fill_value``` argument in ```widely``` (previously used fill = 0 for all pairwise functions making correlations take 0 values for missing data instead of NAs) and in case of ```pairwise_cor```, it'll be NA and 0 otherwise.

Since ```widyr``` has two distance based functions, namely ```pairwise_delta``` and ```pairwise_dist```, I was wondering if we can take it a step further and add functionality for the data analyst/scientist to scale these pairwise distances to *k* dimensions. This is done in base R using ```cmdscale``` that takes a distance matrix and returns a matrix with each item as a row and each of the *k* dimensions as columns.  The points are calculated such that the distance is maintained.

Example:

```
euro_mat <- as.matrix(eurodist)[1:5, 1:5]

euro_mat
#>           Athens Barcelona Brussels Calais Cherbourg
#> Athens         0      3313     2963   3175      3339
#> Barcelona   3313         0     1318   1326      1294
#> Brussels    2963      1318        0    204       583
#> Calais      3175      1326      204      0       460
#> Cherbourg   3339      1294      583    460         0

cmdscale(euro_mat)
#>                [,1]       [,2]
#> Athens    2515.1944   14.68566
#> Barcelona -659.3761  961.30504
#> Brussels  -422.4595 -328.35478
#> Calais    -633.6209 -359.57342
#> Cherbourg -799.7379 -288.06249
```
In the tidy, widy way, I figured the following way to do this when we have a distance based result from a widyr method:

```
library(tidytext)
library(janeaustenr)
library(widyr)
library(tidyverse)
#> ── Attaching packages ───────────────────────────────────────────────────────── tidyverse 1.2.1 ──
#> ✔ ggplot2 2.2.1.9000     ✔ purrr   0.2.4     
#> ✔ tibble  1.4.2          ✔ dplyr   0.7.4     
#> ✔ tidyr   0.8.0          ✔ stringr 1.3.0     
#> ✔ readr   1.1.1          ✔ forcats 0.3.0
#> ── Conflicts ──────────────────────────────────────────────────────────── tidyverse_conflicts() ──
#> ✖ dplyr::filter() masks stats::filter()
#> ✖ dplyr::lag()    masks stats::lag()

austen_dist <- austen_books() %>%
  unnest_tokens(word, text) %>%
  count(book, word) %>%
  pairwise_dist(book, word, n)

## From utils.R in widyr package (private method), didnt want to use :::
col_name <- function(x, default = stop("Please supply column name", call. = FALSE))
{
  if (is.character(x))
    return(x)
  if (identical(x, quote(expr = )))
    return(default)
  if (is.name(x))
    return(as.character(x))
  if (is.null(x))
    return(x)
  stop("Invalid column specification", call. = FALSE)
}

multi_scale <- function(tbl, item1, item2, value, k = 2, ...) {
  multi_scale_(tbl,
               col_name(substitute(item1)),
               col_name(substitute(item2)),
               col_name(substitute(value)),
               k = 2, ...)
}


multi_scale_ <- function(tbl, item1, item2, value, k = 2, ...) {
  tbl_matrix <- tbl %>%
    spread(item2, col_name(value), fill = 0) %>%
    remove_rownames() %>%
    column_to_rownames("item1") %>%
    as.matrix()
  
  cmdscale(tbl_matrix, k = k) %>%
    as.data.frame() %>%
    rownames_to_column("item") %>%
    as.tibble()
}

austen_dist %>%
  multi_scale(item1, item2, distance)
#> Warning: Setting row names on a tibble is deprecated.
#> # A tibble: 6 x 3
#>   item                     V1      V2
#>   <chr>                 <dbl>   <dbl>
#> 1 Sense & Sensibility   211.    302. 
#> 2 Pride & Prejudice      36.7   -64.8
#> 3 Mansfield Park      -3942.   1325. 
#> 4 Emma                -3513.  -1525. 
#> 5 Northanger Abbey     3924.   -115. 
#> 6 Persuasion           3284.     77.5
```
This can be used for something like this:

```
austen_dist %>%
  multi_scale(item1, item2, distance) %>%
  ggplot(aes(V1, V2, color = item)) +
  geom_point(size = 3, alpha = 0.8) + 
  scale_y_continuous(limits = c(-4000, 4000)) + 
  theme_bw()
```
![multi_scale](https://user-images.githubusercontent.com/10777197/37742090-821f14a8-2d3a-11e8-8aa0-f22814108c4a.png)

Now, this method returns a warning because of `column_to_rownames()` that I would like to get rid of. I'm searching for one but wanted to know your thoughts before I submit a PR. 

