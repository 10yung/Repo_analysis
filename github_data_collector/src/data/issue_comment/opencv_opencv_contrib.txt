<!--
If you have a question rather than reporting a bug please go to http://answers.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)

- OpenCV => 4.2.0
- Operating System / Platform => Mac OSX 10.14.6
- Docker => 2.0.0.2

##### Detailed description

I'm trying to build opencv for javascript by following the Docker instructions in https://docs.opencv.org/3.4/d4/da1/tutorial_js_setup.html. 

I modify the `build_js.py` file to add the `open_cv/contrib` directory:

```
def get_cmake_cmd(self):
        cmd = ["cmake",
               "-DOPENCV_EXTRA_MODULES_PATH=/Users/me/opencv_contrib/modules", 
```

When I run `docker run --rm --workdir /code -v "$PWD":/code "trzeci/emscripten:latest" python ./platforms/js/build_js.py build` , I get the following error:

```
CMake Error at cmake/OpenCVModule.cmake:288 (message):
  No modules has been found: /Users/me/opencv_contrib/modules
```

But that directory exists, because when I `ls` the directory I get a result.

```
>>> ls -la /Users/me/opencv_contrib/modules

total 16
drwxr-xr-x  57 me  ANT\Domain Users  1824 Jan 15 13:28 .
drwxr-xr-x  13 me  ANT\Domain Users   416 Jan 15 13:28 ..
-rw-r--r--   1 me  ANT\Domain Users  5193 Jan 15 13:28 README.md
drwxr-xr-x  11 me  ANT\Domain Users   352 Jan 15 13:28 aruco
drwxr-xr-x  10 me  ANT\Domain Users   320 Jan 15 13:28 bgsegm
drwxr-xr-x  11 me  ANT\Domain Users   352 Jan 15 13:28 bioinspired
drwxr-xr-x   8 me  ANT\Domain Users   256 Jan 15 13:28 ccalib
etc...
```

##### Steps to reproduce

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->
- OpenCV => 4.2.0
- Operating System / Platform => Linux acer 4.15.0-74-generic #83~16.04.1-Ubuntu SMP Wed Dec 18 04:56:23 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
- Compiler => gcc (Ubuntu 6.5.0-2ubuntu1~16.04) 6.5.0 20181026

##### Detailed description
error: opencv-caffe.pb.h not found

##### Steps to reproduce
build with:
-DWITH_PROTOBUF:BOOL=ON
-DBUILD_PROTOBUF:BOOL=FALSE
-DPROTOBUF_UPDATE_FILES:BOOL=ON
-DOPENCV_DNN_EXTERNAL_PROTOBUF:BOOL=ON

**to fix**
in dnn/CMakeLists.txt

file(GLOB proto_files "${CMAKE_CURRENT_LIST_DIR}/src/tensorflow/*.proto" "${CMAKE_CURRENT_LIST_DIR}/src/caffe/opencv-caffe.proto" "${CMAKE_CURRENT_LIST_DIR}/src/onnx/opencv-onnx.proto")
set(PROTOBUF_GENERATE_CPP_APPEND_PATH ON) # required for tensorflow
protobuf_generate_cpp(fw_srcs fw_hdrs ${proto_files})
**set(fw_inc "${CMAKE_CURRENT_BINARY_DIR}/src/caffe" "${CMAKE_CURRENT_BINARY_DIR}/src/tensorflow" "${CMAKE_CURRENT_BINARY_DIR}/src/onnx")**


Hello,

I compiled OpenCV with CUDA because I wanted to try to offload to gpu some tasks on a jetson nano. I tried the most expensive part of my project of course, that involved background subtractor. I think I figured out how to use it from python but I cannot understand if I'm using it wrong or there's a bug.  I cannot get the background image back from the background subtractor 
##### System information (version)

- OpenCV => 4.1.1
- Operating System / Platform => Ubuntu 18.04
- Compiler => GCC
##### Detailed description

```python
Traceback (most recent call last):
  File "bgsegm.py", line 20, in <module>
    background = bg_subtractor.getBackgroundImage(stream)
cv2.error: OpenCV(4.1.1) /home/anas/opencv/modules/core/src/matrix_wrap.cpp:359: error: (-213:The function/feature is not implemented) getGpuMat is available only for cuda::GpuMat and cuda::HostMem in function 'getGpuMat'
```

##### Steps to reproduce

``` python
import cv2

image = cv2.imread('assets/S11.bmp')

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

gpu_gray = cv2.cuda_GpuMat()
gpu_gray.upload(gray)

bg_subtractor = cv2.cuda.createBackgroundSubtractorMOG2()

stream = cv2.cuda_Stream()

foreground_gpu = bg_subtractor.apply(gpu_gray, -1, stream)

foreground = foreground_gpu.download()


background = bg_subtractor.getBackgroundImage(stream)
```
##### System information (version)

- OpenCV => 4.2.0
- Operating System / Platform => Windows 10, 64 Bit
- Compiler => Visual Studio 16 2019
- Python => 3.7.6, using Anaconda

##### Detailed description

I would like to use the Tracker classes from Python on Windows, and it seems that in Python the only way to access algorithm parameters is by writing/reading the Tracker object to/from a .yaml file. When I try `Tracker.write()`, I get a cv2.error. Here is my test case:

##### Steps to reproduce

```.py
import cv2
import os

#Display OpenCV version
print(f"OpenCV version: {cv2.__version__}")

#Create tracker object
tracker = cv2.TrackerCSRT_create()

settings_file = "settings.yaml"

#Delete settings file if it exists
if os.path.isfile(settings_file): os.remove(settings_file)

#Create FileNode
fs = cv2.FileStorage(settings_file,cv2.FILE_STORAGE_WRITE)

#Write defaults
tracker.write(fs)

#Release file
fs.release()
```

When I tried this (Python 3.7.6, OpenCV 4.2.0… with prepackaged binaries, or when rebuilt from source code), it failed on the `tracker.write(fs)` line with this message:

`Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
cv2.error: OpenCV(4.2.0) C:\Users\dick\OpenCV\opencv-4.2.0\modules\core\src\matrix_wrap.cpp:112: error: (-213:The function/feature is not implemented) You should explicitly call mapHost/unmapHost methods for ogl::Buffer object in function 'cv::_InputArray::getMat_'`

On a slightly different test, I got this error message:

`Traceback (most recent call last):
  File "<stdin>", line 5, in <module>
cv2.error: OpenCV(4.2.0) C:\Users\dick\OpenCV\opencv-4.2.0\modules\core\src\matrix_wrap.cpp:130: error: (-213:The function/feature is not implemented) Unknown/unsupported array type in function 'cv::_InputArray::getMat_'`

I have a friend who is more C++/Linux/Visual Studio savvy than I am, and she confirmed for me that this `tracker.write()` works fine on Linux, writing a `.yaml` file, as does using `tracker.read()` to read it back as follows:

```.py
#Read in the settings
fs_settings = cv2.FileStorage(settings_file,cv2.FILE_STORAGE_READ)
tracker.read(fs_settings.root())

#Release file
fs_settings.release()
```

When I try `tracker.read()` with a known-good `.yaml` file, Python crashes straight to the command prompt—no error message at all. I guess this is a closely related issue.

My friend's assessment was "As far as I can tell, in Windows the Mat object being created is the wrong datatype (whether is it has an extra dimension or wrong type (i.e. float vs int) or it's an empty null pointer).", and I've imposed on her time quite enough to this point. Could someone please look into the C++ code to see what's going wrong, and perhaps why it works on Linux but not Windows?

In looking around for similar issues, I thought that #2393 looked somewhat familiar, where the Mat class wasn't behaving as expected.

[Note: This is my first time opening an issue, I'm not fluent in C++ or using VS (I got a lot of help to do the recompiling!), and I'm still learning Python—I hope the OpenCV team will support Python end-users like me to access tracking algorithm parameters, even if they have no option but Windows. :-) Thank you.]
According to the original paper of SURF, the list of box filter sizes is as follows : 
Octave 4 : 51, 99, 147, 195
Octave 3 : 27, 51, 75, 99
Octave 2 : 15, 27, 39, 51
Octave 1 : 9, 15, 21, 27
However, OpenCV SURF implementation has resulted in different values : 
Octave 4 : 72, 120, 168, 216
Octave 3 : 36, 60, 84, 108
Octave 2 : 18, 30, 42, 54
Octave 1 : 9, 15, 21, 27

<!-- Please use this line to close one or multiple issues when this pullrequest gets merged
You can add another line right under the first one:
resolves #1234
resolves #1235
-->

### This pullrequest changes

<!-- Please describe what your pullrequest is changing -->the list of filter sizes to become consistent with the SURF paper.

The new module, intensity_transform, implements the following intensity transformation algorithms: gamma correction, log transformation, autoscaling, and contrast stretching.

### This pullrequest changes

Adds a new module called intensity_transform.

**Main PR**: https://github.com/opencv/opencv/pull/16248

resolves #2159 #2393 #2407 
# This pullrequest changes

Adds overloads to C++ functions to generate the missing python bindings for cudaobjdetect, cudawarping, cudaarithm and cudabgsegm functions.

Python tests have been added for the missing functions and all module specific python tests have also been moved here from the main repo.


##### System information (version)

- OpenCV => 4.1
- Operating System / Platform => Linux Ubuntu 16.04 64 Bit (Nvidia Xavier)
- CUDA => 10.x 

- OpenCV => OpenCV cuda bindings for python seem receive wrong param types for [cudawarping/src/warp.cpp](https://github.com/opencv/opencv_contrib/blob/4.1.2/modules/cudawarping/src/warp.cpp).

##### Detailed description

The parameter `M` for `warpAffine`, `buildWarpAffineMaps`, `warpPerspective`, `buildWarpPerspectiveMaps` is all defined as cv::Mat? 
However, in python binding, they are expected as `cv.cuda_GpuMat`. (ohterwise `TypeError: Expected Ptr<cv::UMat> for argument '%s'` will be raised).
However, pass `cuda_GpuMat` will trigger error at [Mat M = _M.getMat();](https://github.com/opencv/opencv_contrib/blob/4.1.2/modules/cudawarping/src/warp.cpp#L82) with `xxx/opencv/modules/core/src/matrix_wrap.cpp:118: error: (-213:The function/feature is not implemented) You should explicitly call download method for cuda::GpuMat object in function 'getMat_'`

##### Steps to reproduce

 ```python
#!/usr/bin/env python3
# -*- encoding: utf-8 -*-
#
# Demo usage of cuda.warpAffine from OpenCV 4.x

import cv2 as cv
import numpy as np

mask = np.random.randint(low=100, high=255, size=(1000, 2000)).astype(np.uint8)
mapping = np.array([[1.0, 0.0, 400.0], [0.0, 1.0, 300.0]])

image_container = cv.cuda_GpuMat()
mapping_container = cv.cuda_GpuMat()
dsize = (100, 200)
stream = cv.cuda_Stream()

image_container.upload(mask)
mapping_container.upload(mapping)

crop_mask = cv.cuda.warpAffine(src=image_container,
                               M=mapping_container,
                               dsize=dsize,
                               flags=cv.WARP_INVERSE_MAP,
                               stream=stream).download()

cv.imshow('CropMask', crop_mask)
cv.waitKey()

```

##### Possible solutions

I am not so familiar with `InputArray` as once-for-all param type, so, maybe this can be some easy fix for you guys. Currently, I replace `Mat M = _M.getMat();` to `Mat M;  _M.download(M);` to make python happy (and will break cpp codes..)
Another gossip, the cuda version seems no good than CPU version -.-

<!-- Please use this line to close one or multiple issues when this pullrequest gets merged
You can add another line right under the first one:
resolves #1234
resolves #1235
-->
Fixes https://github.com/opencv/opencv_contrib/issues/2339
### This pullrequest changes

<!-- Please describe what your pullrequest is changing -->
This PR tries to fix the out of range error that occurs due to `numSamples=0` and hence `sampleStep` becomes `INT_MIN` which is the root cause of all the errors.
### This pullrequest changes

Minor change in the post-detect loop of `MultiTracker_TLD` to delay early exit in case of low Sc value in NN classification.

Instead of early exit, it continues for all trackers. Return value is `false` in case of failure for all trackers, not just one tracker.
