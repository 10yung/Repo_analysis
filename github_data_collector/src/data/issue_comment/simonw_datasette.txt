While it's sometimes valuable to know how a project has developed, there is usually little justification for including this information in the README, and certainly not immediately after other key information such as "what does this package do, and who might want to use it?"

Might I recommend that the feature history is migrated to an Appendix in the documentation?
Simon,

I'm trying to use the app.css (in static folder) as style sheet but the datasette on Heroku simply ignore it! I read everything about customization here and on readthedocs but still can't.

Is this possible?

Thanks!
Hi,
 
I've been experimenting with SQLite reading from huge datasets using this excellent Parquet extension from @cldellow.
https://cldellow.com/2018/06/22/sqlite-parquet-vtable.html
https://github.com/cldellow/sqlite-parquet-vtable

This works really well, but I was keen to see if I could combine datasette with this. Having previously experimented with the spatialite extension I knew that datasette supports loading extensions in the underlying sqlite instance.  However I hit a blocker as the current design only allows SELECT statements to be executed and so I am unable to execute the crucial 

CREATE VIRTUAL TABLE .........

command that is required to load the data from the parquet file into the table.

It seems like this would be a simple-ish change, but I don't know enough about the architecture of datasette to start implementing this myself?  Could this be done as a datasette plugin?  or would this require more fundamental changes at initialisation time?

My thoughts are that something at init time could detect that the user was loading a *.parquet file and then switch to a mode were it loads that via the "CREATE VIRTUAL TABLE..." rather than loading the *.db file in the default case??

I'm happy to contribute code and testing, I just need some pointers on the best approach.

Thanks
Darren
Hello,
Is the nice display of headers and definitions at the top of https://fivethirtyeight.datasettes.com/fivethirtyeight-ac35616/antiquities-act%2Factions_under_antiquities_act is configured in the metadata.json file ?
Thank you,
I'm having a lot of trouble copying and pasting from the codemirror editor on my iPhone.
this changes the SQL validation to allow for lines that are commented out

my main use case for this is that I like to write a succession of queries when trying to solve a problem.
In most native SQL clients there is a key binding that will run just the current highlighted query or the program is smart enough to run just the query that the cursor is in if it's properly delimited with a ';'.
Typically my workflow will start with a single simple query and I'll copy/paste it to a new query below when I want to make big changes while debugging.  This makes it easy to go back to a working version above when the query doesn't work.
Since datasette sends the whole query to the DB I have to comment out the older queries by prefixing each line with `--`.  This gets caught by the validators when I use my typical strategy of copy/pasting each successive query below the last one.   
so this is just a simple fix to allow for a query to be sent to the DB with leading comments.

As usual, I don't really know what I'm doing...  so this is just a suggested approach. I've not written tests, I've not run the tests, I don't know if I've missed some absolute URLs that would need to have the leading slash dropped.

BUT, I tested it with `--config base_url:http://127.0.0.1:8001/` on the command line and from what little I know about datasette it's at least working in some obvious cases.

My changes are based on what I saw in https://github.com/simonw/datasette/commit/8da2db4b71096b19e7a9ef1929369b8483d448bf (thanks!)

I'm happy to be more thorough on this if you think it's worth pursuing.

Fixes #394  (he said, optimistically).
Call it `glossary.rst` - it can use a definition list something like this:
```rst
.. _glossary:

Glossary
========

Term
  A definition of the term.

Another term
  Another definition.
```
Since #467 the index page has attempted to optimistically count times.

My personal Dogsheep has enough connected databases and tables that the page can still take way too long to load - sometimes more than twenty seconds.
For www.niche-museums.com I solved this by creating an empty `about.db` database file - see https://simonwillison.net/2019/Nov/25/niche-museums/

I want a neater mechanism for this.