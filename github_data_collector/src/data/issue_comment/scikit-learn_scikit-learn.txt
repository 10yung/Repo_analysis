Looking at how the `theta` property is computed in the abstract base class `Kernel` in `sklearn/gaussian_process/kernel.py`:
```Python
    @property
    def theta(self):
        theta = []
        params = self.get_params()
        for hyperparameter in self.hyperparameters:
            if not hyperparameter.fixed:
==>             theta.append(params[hyperparameter.name])
        if len(theta) > 0:
            return np.log(np.hstack(theta))
        else:
            return np.array([])
```
then it is apparent that the names of the hyperparameters are obtained from the `hyperparameters` property, while the values are looked up using the names from `params` as returned from `get_params()`.

However,  it looks like each `Hyperparameter` instance already contains a `value` field. As such, I wonder why this field is not used, leading to something like
```Python
    @property
    def theta(self):
        theta = []
        for hyperparameter in self.hyperparameters:
            if not hyperparameter.fixed:
==>             theta.append(hyperparameter.value)
        if len(theta) > 0:
            return np.log(np.hstack(theta))
        else:
            return np.array([])
```

Could someone help me understand this? @jmetzen @jnothman 
While using the boston_housing data set, a data set hosted by the Scikit-learn package and used to demo models on house price prediction, I came across a feature titled 'B'. This struck me as odd because all other features had been given descriptive names such as 'AGE' or 'TAX'. It turns out that B = 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town. I naively  assumed, as this data was being hosted by a prestigious package, that these data were in the data set because they offer significant explanatory value, which would point to a strongly pervasive racist mentality in the population at the time. However, after reading the blog post attached below, it appears as though the data in the B feature of the Boston housing data set were manufactured in an attempt to encourage segregation of the races. If true, this would be strong evidence of systemic institutional racism and by continuing to use this fraudulent data we would be perpetuating the effect desired by the author. I hope you will agree that we would be doing the scientific literature a service by investigating this issue further and ultimately consigning this data to historic reference archives and not encouraging its use in modern research by hosting it. 

I look forward to your response,

Jamie R. Sykes

https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8


#### Reference Issues/PRs

#15358 

#### What does this implement/fix? Explain your changes.

Use _check_sample_weight to validate sample_weight in KernelRidge.

I realised after #13971 and also a lecture that I gave that we don't add "True/False", "Yes/No" above the arrow in `plot_tree`. Therefore, we know the criterion for the decision and the further splits but we don't have any idea what path a sample will take (or at least it makes it more difficult to infer it).

I think that we should annotate the arrow depending if the comparison in the node is True/False.

@amueller @NicolasHug @thomasjpfan WDYT?

#### Describe the bug
When I try and run agglomerative clustering with a precomputed distance matrix, I get a ValueError as follows `ValueError: Precomputed metric requires shape (n_queries, n_indexed). Got (7, 57) for 50 indexed.` I looked up similar past bugs and they said it was because the distance matrix was not square. However I checked the shape and it is indeed square, I even ran the scikit learn `check_pairwise_arrays` function on it with `precomputed` set to True and confirmed that the matrix returned was the same. The code is attached below in a zip file
[agglomerative_test.zip](https://github.com/scikit-learn/scikit-learn/files/4079972/agglomerative_test.zip)
, any help would be appreciated 
#### Steps/Code to Reproduce


```
import numpy as np 
import sklearn.cluster
from sklearn.metrics.pairwise import check_pairwise_arrays


connectivity_matrix = np.load('connectivity_matrix_57.npy')

remapped_affinity_matrix = np.load('remapped_affinity_matrix_57.npy')


P = 1.0 
D = 0.25

remapped_distance_threshold = 0.25

updated_connectivity_matrix, _ = check_pairwise_arrays(connectivity_matrix, connectivity_matrix, precomputed=True)

updated_remapped_affinity_matrix, _ = check_pairwise_arrays(remapped_affinity_matrix, remapped_affinity_matrix, precomputed=True)

print('connectivity is same: ', np.all(np.equal(updated_connectivity_matrix, connectivity_matrix)))
print('remapped is same: ',  np.all(np.equal(remapped_affinity_matrix, updated_remapped_affinity_matrix)))


clusterer = sklearn.cluster.AgglomerativeClustering(n_clusters=None,
                                                    compute_full_tree=True,
                                                    affinity='precomputed',
                                                    connectivity=connectivity_matrix,
                                                    linkage='complete',
                                                    distance_threshold=remapped_distance_threshold,
                                                    )


print('remapped affinity matrix size: ', remapped_affinity_matrix.shape)
print('connectivity matrix size: ', connectivity_matrix.shape)
print('remapped affinity is symetric: ', np.all(np.equal(remapped_affinity_matrix, remapped_affinity_matrix.T)))
print('connectivity is symetric: ', np.all(np.equal(connectivity_matrix, connectivity_matrix.T)))

clusterer.fit(remapped_affinity_matrix)
```
The actual data is in the zip file attached
#### Expected Results
```
connectivity is same:  True
remapped is same:  True
remapped affinity matrix size:  (57, 57)
connectivity matrix size:  (57, 57)
remapped affinity is symetric:  True
connectivity is symetric:  True

```
and then the code would run without error
#### Actual Results
```
connectivity is same:  True
remapped is same:  True
remapped affinity matrix size:  (57, 57)
connectivity matrix size:  (57, 57)
remapped affinity is symetric:  True
connectivity is symetric:  True


/Users/humzaiqbal/Library/Python/3.7/lib/python/site-packages/sklearn/cluster/_agglomerative.py:478: UserWarning: the number of connected components of the connectivity matrix is 2 > 1. Completing it to avoid stopping the tree early.
  affinity=affinity)
Traceback (most recent call last):
  File "agglomerative_test.py", line 38, in <module>
    clusterer.fit(remapped_affinity_matrix)
  File "/Users/humzaiqbal/Library/Python/3.7/lib/python/site-packages/sklearn/cluster/_agglomerative.py", line 859, in fit
    **kwargs)
  File "/usr/local/lib/python3.7/site-packages/joblib/memory.py", line 355, in __call__
    return self.func(*args, **kwargs)
  File "/Users/humzaiqbal/Library/Python/3.7/lib/python/site-packages/sklearn/cluster/_agglomerative.py", line 584, in _complete_linkage
    return linkage_tree(*args, **kwargs)
  File "/Users/humzaiqbal/Library/Python/3.7/lib/python/site-packages/sklearn/cluster/_agglomerative.py", line 478, in linkage_tree
    affinity=affinity)
  File "/Users/humzaiqbal/Library/Python/3.7/lib/python/site-packages/sklearn/cluster/_agglomerative.py", line 72, in _fix_connectivity
    D = pairwise_distances(Xi, Xj, metric=affinity)
  File "/Users/humzaiqbal/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/pairwise.py", line 1714, in pairwise_distances
    force_all_finite=force_all_finite)
  File "/Users/humzaiqbal/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/pairwise.py", line 151, in check_pairwise_arrays
    (X.shape[0], X.shape[1], Y.shape[0]))
ValueError: Precomputed metric requires shape (n_queries, n_indexed). Got (7, 57) for 50 indexed.
```

#### Versions

```
System:
    python: 3.7.4 (default, Jul  9 2019, 18:15:00)  [Clang 10.0.0 (clang-1000.11.45.5)]
executable: /usr/local/opt/python/bin/python3.7
   machine: Darwin-17.7.0-x86_64-i386-64bit

Python dependencies:
       pip: 19.1.1
setuptools: 41.0.1
   sklearn: 0.22.1
     numpy: 1.16.3
     scipy: 1.2.1
    Cython: 0.28
    pandas: 0.25.0
matplotlib: 3.0.3
    joblib: 0.13.2


```

<!-- Thanks for contributing! -->

Reference Issues/PRs
In relation to this request
https://github.com/scikit-learn/scikit-learn/issues/16127


#### What does this implement/fix? Explain your changes.
Format of values plotted in confusion matrix
Attempting to reduce memory footprint of Birch.predict. Please see solution description  at issue
https://github.com/scikit-learn/scikit-learn/issues/16027#issuecomment-575671502

Benchmark script to be added soon
It's really nice that transformers such as `sklearn.preprocessing.OneHotEncoder` and `sklearn.preprocessing.StandardScaler` can operate on multiple data columns simultaneously.

`sklearn.feature_extraction.text.TfidfVectorizer` on the other hand, can only process one column at a time, so you need to make a new transformer for each text column in your dataset.  This can get a little tedious and in particular makes pipelines more verbose.

It'd be nice if `TfidfVectorizer` could also operate on multiple text columns, using the same settings for each column, perhaps with an option to make one vocabulary per column, or use a shared vocabulary across all the columns.

It might be easiest to implement this as a new class that wraps `TfidfVectorizer` [sagemaker-scikit-learn-extension](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/feature_extraction/text.py#L22) takes this approach.

If this seems like a good idea, I'd be happy to make a PR.
Within the RANSAC algorithm, a residual threshold is calculated:

`residual_threshold = np.median(np.abs(y - np.median(y))`

If more than half of the values of y are equal to the median of y, this returns a residual threshold of 0.  In that case, the line 

`inlier_mask_subset = residuals_subset < residual_threshold`

always returns zero inliers, causing a value error since `inlier_mask_best` is always None.
The current cross validation procedure adopted in the `CalibratedClassifierCV` does not follow the cross validation procedure described in the original Platt paper:
[Platt99] Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods, J. Platt, (1999)

I checked also the other papers cited in the references for the `CalibratedClassifierCV` class and none of them describes the cross validation process it implements.

`CalibratedClassifierCV` currently fits and calibrates an estimator for each fold (calibration is performed on the test part of the fold).
All the estimators fit at each fold are kept in a list.
At prediction time, every estimator makes a prediction and the average of the returned values is the final prediction.

The estimator produced by `CalibratedClassifierCV` is thus an ensemble and not a single estimator calibrated on the whole training set via CV.
When using cross validation the original `base_estimator` is not used to make the prediction.

Platt99, describes a cross validation procedure that fits an estimator on each fold and the predictions for the test fold are saved. 
Then the predictions from all the folds are concatenated in a single list, and calibration parameters for the `base_estimator` are determined using such list.

Cross validation should be only a mean to calibrate the `base_estimator` on the same data it has been fit, not to fit a different estimator.

The procedure described in Platt99 is what one would expect from a proper application of a cross validation procedure, as the cross validation only determines the parameters of the calibration and does not fit the estimator.
It is also more efficient, as is does not store the estimators for each fold and requires a single predict at prediction time.
