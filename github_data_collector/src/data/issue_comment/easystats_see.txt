https://twitter.com/hadleywickham/status/1160712230645784579?s=20

Autoscaling the dots would be  awesome!
I think this is doable, and also preferable. This is rather a slow process, with small steps.
- Remove annoying tableGrobs textual output
- Improve alignment (?)
``` r
library(rstanarm)
library(see)
library(bayestestR)
model <- stan_glm(mpg ~ wt + gear, data = mtcars, chains = 2, iter = 200)
x <- point_estimate(model, "all")
plot(x)
```

![](https://i.imgur.com/hKt4oQz.png)

<sup>Created on 2019-07-30 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>

@DominiqueMakowski `estimate_fit()` was renamed to `estimate_response()`, if I'm not mistaken. However, the plot now looks a bit different (I guess this is intended).

Could you please check https://github.com/easystats/see if plots are OK?
Hi @DominiqueMakowski and @strengejacke - There was a brand new journal just announced called "Journal of Data Science, Statistics, and Visualisation". I found out about it through the ASA listserv. They announced a call for the first round of papers to be published. There are no APCs and its open source! What do you guys think about preparing and submitting a paper covering an introduction and implementation of `see`? It could be a really cool thing to get easystats in on the ground level of a new journal related to what we all do. 

Here is the homepage: https://jdssv.org/index.php/jdssv

Let me know if you're on board. If so, I would be happy to take the lead on the paper and start drafting. If not, no worries.
Hi @strengejacke - apologies for my delay here. Yeah, I have some MWE for each. First, for the ePCP (expected proportion correctly predicted), we are looking for a higher value, bounded between 0 and 1, where 1 = a model that perfectly predicted all actual observations. Here is some sample code using `mtcars`:
```{R}
library(OOmisc) # for ePCP
library(ggplot2)

logitmod <- glm(vs ~ mpg, data = mtcars); summary(logitmod)
logitmod2 <- glm(vs ~ mpg + cyl, data = mtcars); summary(logitmod2)

y <- mtcars$vs
pred1 <- predict(logitmod, type="response")
pred2 <- predict(logitmod2, type="response")

# ePCP, expected proportion of correct prediction
epcp1 <- ePCP(pred1, y, alpha = 0.05) # define observed values and obtain predicted values
epcp2 <- ePCP(pred2, y, alpha = 0.05)

epcpdata <- data.frame(rbind(epcp1, epcp2))
epcpdata$model <- c(1,2)
epcpdata$count <- factor(c(1,2), label = c("Model1","Model2"))

# Now the plot
ggplot(epcpdata, aes(x=model,y=ePCP,colour=count)) +
  geom_bar(position=position_dodge(), stat="identity", fill = "darkgray") +
  geom_errorbar(aes(ymin=lower, ymax=upper),
                width=.2,
                position=position_dodge(.9)) +
  labs(x="Model Specification",
       y="Expected Proportion of Correct Prediction",
       title = "Comparing ePCP between Model 1 and Model 2",
       colour="Model Specification") +
  theme_bw()
```

And next, for the `heatmapFit`, which is a little less flexible, the goal is to compare model predictions with smoothed empirical predictions. The 45-degree line references a perfect fit. Any deviance from that line suggests a loss in goodness of fit. The “p-value” legend shows if any deviance is statistically significant (dark color means statistical significance). Using the same models as an example from `mtcars`, it would look something like:

```{R}
## heatmapfit
library(heatmapFit) # for heat maps

# quick rescale to bound predictions between 0 and 1
range <- function(x){
  (x-min(x))/(max(x)-min(x))
  }

pred1 <- range(pred1)
pred2 <- range(pred2)

heatmap.fit(y, pred1, reps = 1000, legend = TRUE)
heatmap.fit(y, pred2, reps = 1000, legend = TRUE)
```

** You can copy and paste this code to see the figures. Pretty clean, efficient renderings of model fit. 

** And of course, ROC curves are always great, simple model fit checks. Let me know thoughts if you have them. Hope this helps a bit!

_Originally posted by @pdwaggoner in https://github.com/easystats/performance/issues/38#issuecomment-487404535_
``` r
library(see)
library(bayestestR)
library(rstanarm)

junk <- capture.output(model <- rstanarm::stan_glm(mpg ~ wt + gear + cyl + disp, data = mtcars))
plot(equivalence_test(model, ci=0.5))
#> Warning: Possible multicollinearity between disp and wt (r = 0.63), disp
#> and cyl (r = 0.71). This might lead to inappropriate results. See 'Details'
#> in '?equivalence_test'.
#> Picking joint bandwidth of 0.0467
#> Warning: Removed 7996 rows containing non-finite values
#> (stat_density_ridges).
```

![](https://i.imgur.com/yHVkwAR.png)

<sup>Created on 2019-05-17 by the [reprex package](https://reprex.tidyverse.org) (v0.2.1)</sup>


Currently, if I understand, we start by keeping the samples of the posterior within the CI. Then, these remaining samples are passed to `density_ridges` which computes the density and plots it.

Unfortunately, the density estimation of a subsample done by `density_ridges` gives a distorted vision (especially in the tails, which is usually of interest) of the actual distribution, even compared to a regular `geom_density` (which is already distorted):


``` r
library(see)
library(bayestestR)
library(rstanarm)
library(ggplot2)
library(ggridges)

df <- data.frame(x = c(rnorm(10000), rnorm(10000)), 
                y = rep(c("a", "b"), each=10000))

df <- df[df$x < 1.5 & df$x > -1.5, ] # Let's say this is my HDI bounds
       

ggplot(df, aes(x = x, y=y)) +
  geom_density_ridges()
#> Picking joint bandwidth of 0.109
```

![](https://i.imgur.com/g9PSoEl.png)

``` r


ggplot(df[df$y == "a",], aes(x = x)) +
  geom_density()
```

![](https://i.imgur.com/zMuj67W.png)

<sup>Created on 2019-05-17 by the [reprex package](https://reprex.tidyverse.org) (v0.2.1)</sup>


One of the ways to address it is to do the density estimation beforehand, then select the HDI section, and pass that to `geom_ridgeline`:

``` r
library(see)
library(bayestestR)
library(rstanarm)
library(ggplot2)
library(ggridges)al
library(dplyr)


df <- data.frame(x = c(rnorm(10000), rnorm(10000)), 
                 y = rep(c("a", "b"), each=10000))

df2 <- rbind(
  bayestestR::estimate_density(df[df$y == "a", "x"]) %>% 
    dplyr::mutate(group="a"),
  bayestestR::estimate_density(df[df$y == "b", "x"]) %>% 
    dplyr::mutate(group="b")
)
df2 <- df2[df2$x < 1.5 & df2$x > -1.5, ] # Let's say this is my HDI bounds

ggplot(df2, aes(x = x, y=group, height=y)) +
  geom_ridgeline()
```

![](https://i.imgur.com/P2vrww8.png)

<sup>Created on 2019-05-17 by the [reprex package](https://reprex.tidyverse.org) (v0.2.1)</sup>



- [ ] Add median/mean difference
- [ ] Enable the plotting of individual draws as segments instead of CIs