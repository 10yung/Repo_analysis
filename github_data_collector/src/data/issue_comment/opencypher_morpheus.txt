Hi,

Not sure if correct place to ask so feel free to move.

Is there any material on installing morpheus in an offline environment? I can build and install at home locally but currently tasked with setting up a POC in enterprise environment with locked down machines to internet.

Many Thanks
Hi there, 
I'm trying to run this query (from teh LDBC SNB BI query workloads) in Morpheus, but it gives me the following error. 


      """
        |
        |MATCH (message:Message)
        |WHERE message.creationDate < 1313591219961
        |WITH count(message) AS totalMessageCountInt
        |WITH toFloat(totalMessageCountInt) AS totalMessageCount
        |MATCH (message:Message)
        |WHERE message.creationDate < 1313591219961
        |  AND message.content IS NOT NULL
        |WITH
        |  totalMessageCount,
        |  message,
        |  (message.creationDate/31556952000+1970) AS year
        |WITH
        |  totalMessageCount,
        |  year,
        |  message:Comment AS isComment,
        |  CASE
        |    WHEN message.length <  40 THEN 0
        |    WHEN message.length <  80 THEN 1
        |    WHEN message.length < 160 THEN 2
        |    ELSE                           3
        |  END AS lengthCategory,
        |  count(message) AS messageCount,
        |  floor(avg(message.length)) AS averageMessageLength,
        |  sum(message.length) AS sumMessageLength
        |RETURN
        |  year,
        |  isComment,
        |  lengthCategory,
        |  messageCount,
        |  averageMessageLength,
        |  sumMessageLength,
        |  messageCount / totalMessageCount AS percentageOfMessages
        |ORDER BY
        |  year DESC,
        |  isComment ASC,
        |lengthCategory ASC
      """

```
ERROR [task-result-getter-1] scheduler.TaskSetManager (Logging.scala:logError(70)) - Task 11 in stage 6.0 failed 4 times; aborting job
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 6.0 failed 4 times, most recent failure: Lost task 11.3 in stage 6.0 (TID 81, 172.17.64.231, executor 2): java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.rdd.MapPartitionsRDD.f of type scala.Function3 in instance of org.apache.spark.rdd.MapPartitionsRDD
```

How does Morpheus stores the graph on HDFS? does it layout the same way as neo4j would on disk?

I am just trying to figure out how to store and retrieve a graph from HDFS?
I'm trying to run the one of the examples inside morpheus on a spark cluster I have edited the creation of the morpheus session using the following lines of code:
```
 val conf = new SparkConf(true)
  conf.set("spark.sql.codegen.wholeStage", "true")
  conf.set("spark.sql.shuffle.partitions", "12")
  conf.set("spark.default.parallelism", "8")
  val spark = SparkSession
    .builder()
    .config(conf)
    .master("spark://172.17.67.122:7077")
    .appName(s"morpheus-local-${UUID.randomUUID()}")
    .enableHiveSupport()
    .getOrCreate()
  spark.sparkContext.setLogLevel("error")
  implicit val morpheus: MorpheusSession = MorpheusSession.create(spark)

 import spark.sqlContext.implicits._


  val nodesDF = spark.createDataset(Seq(
    (0L, "Alice", 42L),
    (1L, "Bob", 23L),
    (2L, "Eve", 84L)
  )).toDF("id", "name", "age")

  val relsDF = spark.createDataset(Seq(
    (0L, 0L, 1L, "23/01/1987"),
    (1L, 1L, 2L, "12/12/2009")
  )).toDF("id", "source", "target", "since")

  val personTable = MorpheusNodeTable(Set("Person"), nodesDF)
  val friendsTable = MorpheusRelationshipTable("KNOWS", relsDF)

  val graph = morpheus.readFrom(personTable, friendsTable)
  val result = graph.cypher("MATCH (n:Person) RETURN n.name")
  result.show
```
just by editing the sparksession with the master URL `'spark://172.17.67.122:7077'` rather than `'local' ` 
I have a problem while running the gradlew run example
`./gradlew morpheus-examples:runApp   -PmainClass=org.opencypher.morpheus.examples.DataFrameInputExample`

while debugging, The problem stated is with the `result.show` line:
 
```
Caused by: java.lang.NoSuchMethodError: scala.Predef$.refArrayOps([Ljava/lang/Object;)Lscala/collection/mutable/ArrayOps;
        at org.opencypher.okapi.trees.AbstractTreeNode.<init>(AbstractTreeNode.scala:69)
        at org.opencypher.okapi.ir.api.expr.Expr.<init>(Expr.scala:50)
        ... 88 more
```
But while I change the example to be with  `'local' `  it runs correctly, and no problems arise 

When I searched, It seems the problem is with the Scala version:
although I have the following on my cluster of 3 machines:
```
OS: Centos 7
Spark: version 2.4.2
Scala: Version 2.12.8
```
and I have put the required morpheus jars in the Spark class path (spark/jars) directory on all the cluster machines Master and Workers, such as:
-     morpheus-spark-cypher-0.4.3-SNAPSHOT.jar
-     okapi-api-0.4.3-SNAPSHOT.jar
-     okapi-relational-0.4.3-SNAPSHOT.jar


Please help me figuring out the problem, because I take a lot of time trying to solve this issue!
Thanks in advance for your help and support!


I have the following on my cluster of machines:
OS: Centos 7
Spark:  version 2.4.3
Scala: Version 2.12.8

I have run the (./gradlew allJar -x test) in the root directory of the Morpheus project with the following error:
Task 'allJar' not found in root project 'okapi'. Some candidates are: 'docJar', 'jar', 'jmhJar'.

So I had to run it with 'jar' option  and got jar file for all modules inside the /build/libs directory.

I want to submit spark job of one of the examples inside the generated 'morpheus-examples/build/libs/morpheus-examples-0.4.3-SNAPSHOT.jar' 

I have put the required jars in the Spark class path (spark/jars) directory, such as:
- morpheus-spark-cypher-0.4.3-SNAPSHOT.jar
- okapi-api-0.4.3-SNAPSHOT.jar
- okapi-relational-0.4.3-SNAPSHOT.jar

but when I submitted the job  like this 

spark/bin/spark-submit  --class 'org.opencypher.morpheus.examples.CaseClassExample'  --master  local  morpheus-examples/build/libs/morpheus-examples-0.4.3-SNAPSHOT.jar 

I always face this error:

Exception in thread "main" java.lang.NoSuchMethodError: scala.App.$init$(Lscala/App;)V
        at org.opencypher.morpheus.util.App.<init>(App.scala:34)
   ......


This problem I think because the Scala Version and Spark Version  comparability but I installed every thing like the versions inside the gradle parameters as stated in the beginning.
 

thanks in advance for your help !


[The deleteGraph method](https://github.com/opencypher/morpheus/blob/9f500f5364c0ba14933d96d088d5a8501d4644ad/morpheus-spark-cypher/src/main/scala/org/opencypher/morpheus/api/io/neo4j/Neo4jPropertyGraphDataSource.scala#L142) doesn't take into account created constraints on the metaLabel. Problem is that `DETACH DELETE` doesn't remove associated constraints and indexes. That causes an error when a PropertyGraph with the same name is deleted and written back again. See the following example:

```scala
val neo4jSource = GraphSources.cypher.neo4j(neo4jConfig)
val name = GraphName("arbitraryGraph")
neo4jSource.store(name, graph)
neo4jSource.delete(name)
neo4jSource.store(name, graph)
```

That causes the following exception:
```scala
Exception in thread "main" org.opencypher.okapi.impl.exception.GraphAlreadyExistsException: A graph with name arbitraryGraph is already stored in this graph data source.
```

Moreover, it doesn't allow write a PropertyGraph with `entireGraphName`, which makes no sense to me. What if I would like just store everything to the database and never restore that PropertyGraph (so metaLabel and related properties, i.e. `___morpheusID` are not desired to be saved), because I have other data sources and graph database is the destination of the processed data?
Is there any plan to support user-defined procedures and the CALL interface?


I am unable to read any data from Neo4j using this library and a custom schema.

Here is how I am setting up the connection:

```
object ExtractUsernames extends MorpheusApp {
  val neo4j = connectNeo4j("bolt://xx.xx.xx.xx:7687", "neo4j", "xxxxxxxxx")
  implicit val morpheus: MorpheusSession = MorpheusSession.local()

  val schemaFile = Source.fromFile(getClass.getResource("/schema.json").getPath).getLines.mkString
  val schema = PropertyGraphSchema.fromJson(schemaFile)
  private val datasource = GraphSources.cypher.neo4j(neo4j.config, Some(schema))

  morpheus.registerSource(Namespace("Neo4j"), datasource)
}
```

And this is what our schema.json looks like:
```
{
  "version": 1,
  "labelPropertyMap": [
    {
      "labels": [
        "User"
      ],
      "properties": {
        "username": "STRING"
      }
    }
  ],
  "relTypePropertyMap": []
}
```

This is the query I am trying to run:

```
 val result = morpheus.cypher(
    s"""
       |FROM Neo4j.graph
       |MATCH (i:User)
       |RETURN i.username
     """.stripMargin)

  result.show
```

However, when I run the query, I get an empty table:
```
╔════════════╗
║ i.username ║
╚════════════╝
(no rows)
```

I have verified that:

- [x] The schema file can be read.
- [x] Neo4j is accessible and the port is open to the machine running this code.
- [x] There is a graph called Neo4j.graph available in `morpheus.catalog.graphNames`
- [x] The same error is present in atleast 2 versions of Neo4j: 3.2.0 and 3.4.1

Morpheus version: `0.4.0`
Spark version: `2.4.3`
Neo4j version: `3.2.0` and `3.4.1`

Does anyone have any idea as to what is going on? 
