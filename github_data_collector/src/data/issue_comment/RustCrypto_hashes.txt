The build is failing due to a problem on `streebog.rs:149` but I haven't changed that.
This is not optimal yet when processing multiple blocks, but it does give a considerable speedup over the non intrinsic version already

Measurements were taken on an `AMD Ryzen 7 3700X 8-Core`.

## Baseline

```
test bench1_10    ... bench:          36 ns/iter (+/- 0) = 277 MB/s
test bench2_100   ... bench:         314 ns/iter (+/- 4) = 318 MB/s
test bench3_1000  ... bench:       3,096 ns/iter (+/- 16) = 322 MB/s
test bench4_10000 ... bench:      30,935 ns/iter (+/- 297) = 323 MB/s
```

## With asm-hashes
```
test bench1_10    ... bench:          33 ns/iter (+/- 0) = 303 MB/s
test bench2_100   ... bench:         291 ns/iter (+/- 1) = 343 MB/s
test bench3_1000  ... bench:       2,863 ns/iter (+/- 14) = 349 MB/s
test bench4_10000 ... bench:      28,597 ns/iter (+/- 191) = 349 MB/s
```

## With Intrinsics

```
test bench1_10    ... bench:           8 ns/iter (+/- 0) = 1250 MB/s
test bench2_100   ... bench:          54 ns/iter (+/- 0) = 1851 MB/s
test bench3_1000  ... bench:         511 ns/iter (+/- 8) = 1956 MB/s
test bench4_10000 ... bench:       5,079 ns/iter (+/- 29) = 1968 MB/s
```


[This is a very large change which I haven't discussed with anyone yet, so I'm
not sure it's the right choice for the project. But hopefully this is a good starting
point for discussion.]

This is mostly a large performance improvement. The BLAKE2b bench_10000
case is improved by about 30%. This implementation also detects SIMD
support at runtime, so the feature flags related to SIMD support are
removed.

The only performance loss is in the bench_10 cases, where the caller
repeatedly feeds input slices less than one block long. The BLAKE2s
bench_10 case is almost 20% slower. I'm not sure exactly why, but this
implementation optimizes for avoiding copies on long runs of input, so
it might just be that it's doing more math up front. This performance
issue disappears if the inputs are a full block or longer.

The only API consequence of this change is that the undocumented
with_parameter_block constructor is no longer supported. Callers who
need other parameters might prefer to use the blake2b_simd/blake2s_simd
APIs directly, which expose them in a safer way through a Params object.
I have a question about the hash memory management but also for other related repositories. As it seems `RustCrypto` use `GenericArray` and/or raw arrays for sensitive data like keys and internal buffers but the memory is not overwritten/zeroed on reset or when the buffer/struct is dropped for most crates, right? Are there any plans to change this?
Rust does [not](https://github.com/rust-lang/rust/issues/32966) ([yet](https://github.com/rust-lang/rust/pull/47954)) implement named return value optimisation, so `fixed_result` forces a copy.

How would you feel about adding a

```rust
fn fixed_result_into(mut self, out : &mut GenericArray<u8, Self::OutputSize>)
```

function to the `FixedOutput` trait so that the copy can be avoided.  I'm happy to create a PR.

(Background: I'm implementing the hash-based signature XMSSMT in rust, where lots of hashes are computed on on very short inputs.  These copies have a significant overhead.)

Signed-off-by: Igor Gnatenko <i.gnatenko.brain@gmail.com>
It's maybe worth adding support for blake2x eventually:  https://blake2.net/blake2x.pdf

I've no idea if anyone actually uses blake2x for anything or how its performance compares with the shake XOFs or blake2s/b + chacha. 
I know `ring` has it's [Context](https://briansmith.org/rustdoc/ring/digest/struct.Context.html) trait, but [digest::Digest](https://docs.rs/digest/0.8.0/digest/trait.Digest.html) seems be better to integrate other digest implementation, such as `openssl-digest` later.
Closes #75.
