
 **libarm_compute.so | grep arm_compute_version:****
arm_compute_version=v19.02 Build options: {'embed_kernels': '1', 'arch': 'arm64-v8a', 'opencl': '1', 'neon': '0', 'asserts': '0', 'debug': '0', 'os': 'linux', 'Werror': '0'} Git hash=514be65ad8d3340f53fd9591035352ed285811ba

**Platform:**
rockpro64 (RK3399) Arm-64

**Operating System:**
Ubuntu18.04
 uname -a
Linux rockpro64 4.4.138-1097-rockchip-ayufan-gb5128c0a1684 #1 SMP Sat Sep 29 15:08:06 UTC 2018 aarch64 aarch64 aarch64 GNU/Linux

Issue is -
While using "export ACL_NHWC=1" in mobilenetSSD(caffe) (91 classes), there is error-
terminate called after throwing an instance of 'cl::Error'
  what():  clEnqueueMapBuffer
Aborted


**Problem description:**
I am using Tengine with ACL in my rockpro64.
I followed this link-
https://github.com/OAID/Tengine/blob/master/doc/gpu_cpu_mssd.md
Tengine provides its 21-classes mobilenetSSD caffemodel.
*) Without using "export ACL_NHWC=1", GPU utilisation is 50-60%, FPS = 3 FPS.
*) With using "export ACL_NHWC=1", GPU utilisation is 60-70% , FPS = 9 FPS.

While using another 91-classes MobilenetSSD caffemodel.
*) Without using "export ACL_NHWC=1", GPU utilisation is 50-60%, FPS = 3 FPS.
*) With using "export ACL_NHWC=1", throws error-
terminate called after throwing an instance of 'cl::Error'
  what():  clEnqueueMapBuffer
Aborted

Not sure What is the exact issue here.
Any suggestion?
Can provide the caffemodel files if required.
Thanks in advance.




I have a task of performing regression learning on a target board (ARM Cortex A53 processor).

I have completed the tasks of data and feature extraction.

Now, i am analyzing the performances of different learning algorithms (GRUs and LSTM) in tensorflow.

However, my concern is that not all models has the software supports to be deployed on the target board.

Out of the software libraries provided by ARM for ML models, i found out that only ARM NN on top of ARM compute library is the way to go. 

Although ACL has the function defnitions needed for the basic defnition of LSTM, in the description of the compute library - it specifies that it supports only SVM (Binary Classification) and CNN models.

Can anyone confirm if the LSTM models translated by ARM NN works with ACL?

Thanks in advance

Can you add theh image segmentation example like U-net to examples for graph ?
Hi, 

I would like to do ImageNet evaluation using armcl with models such as alexnet, googlenet etc. 
There are example programs for single image predictions which uses common class from utils. 
What I want to make is custom program which can be used for multiple image predictions, loading weights just once. There I want to dump all the 1000 predictions for an input image. Any help will be greatly appreciated. ^^

Thanks. 

Best,
Deepak

Well I just want to know more  details about how to accelerate the inference of NN. Can someone tell me where  i can find it. 
So far I'm confused about something.
1. why use buffer instead of image_2d.
2. why not use get_local_id.(local mem)

Thanks in advanced.
<!--
Please fill the fields below in order to help us diagnose the issue. If you have a
general question or a problem with the scripts, you can ignore these fields.
-->

<!--
Please describe the issue (error, expected behaviour etc) and steps to reproduce it. If possible,
share the shortest code necessary that reproduces the issue.
-->

**Problem description:**
Hello I want to implement part of my processing chain which deals with discrete fourier transform using ACL. The result of applying DFT is mirrored at half the dimension and I don't need the other half. My problem is how should I eliminate it ? My DFT is a real to complex application so the end result has 2 channels. What I tried was CLReshapeLayer which doesn't work on on 2 channels tensors, CLSlice which also doesn't work on 2 channels Tensors. The following snippet illustrates my need (include paths need to be set)
```
void prototype_feat_extraction(int sizeFFt, int timeBins, const std::vector<float>& signalIn)
{
    //int overlapInSamples = sizeFFt * 3 / 4;
    sizeFFt = 512;
    timeBins = 65;
    CLTensor inputAudio = test::create_tensor<CLTensor>(TensorShape(sizeFFt, timeBins), DataType::F32);
    inputAudio.info()->set_data_layout(arm_compute::DataLayout::NHWC);
    CLTensor inputHannWindow = test::create_tensor<CLTensor>(TensorShape(sizeFFt,sizeFFt), DataType::F32);
    inputHannWindow.info()->set_data_layout(arm_compute::DataLayout::NHWC);
    CLLocallyConnectedMatrixMultiplyKernel multiplyWithHannWindow;
    CLFFT1D doFFT;
    CLSlice stripMirroredParts;
    FFT1DInfo defaultFFTSetting;
    CLTensor outputAudioWindowed = test::create_tensor<CLTensor>(TensorShape(sizeFFt, timeBins), DataType::F32);
    inputHannWindow.info()->set_data_layout(arm_compute::DataLayout::NHWC);
    multiplyWithHannWindow.configure(&inputAudio, &inputHannWindow, &outputAudioWindowed);
    CLTensor outputFFT1DComplex = test::create_tensor<CLTensor>(TensorShape(sizeFFt, timeBins), DataType::F32, 2);
    outputFFT1DComplex.info()->set_data_layout(arm_compute::DataLayout::NHWC);
    CLTensor outputFFT1DComplexHalf = test::create_tensor<CLTensor>(TensorShape(sizeFFt/2 + 1, timeBins), DataType::F32, 2); // only need half the data, the mirrored part needs to be discarded as it is redundant for my purposes
    outputFFT1DComplexHalf.info()->set_data_layout(arm_compute::DataLayout::NHWC);

    doFFT.configure(&outputAudioWindowed, &outputFFT1DComplex, defaultFFTSetting);
    stripMirroredParts.configure(&outputFFT1DComplex, &outputFFT1DComplexHalf, Coordinates(sizeFFt/2+1,0U), Coordinates(sizeFFt, timeBins));
// allocation and filling has been skipped
CLScheduler::get().enqueue(multiplyWithHannWindow, true);
    doFFT.run();
    stripMirroredParts.run();
}
```
Can this stripping be done with ACL somehow ?
Thank-you
**Platform:** Android

**Operating System:** Linux

**Problem description:** I want to use the binary release directly and execute my model on GPU.
I have already implemented things mentioned in issue #434 but there it is mentioned to add some extra LOC's to enable CL .

I am getting an error: "cl::error: clgetplatformids acl error" when I run my app via CL.
I have checked that all openCL libs are present on my device.

Any help will be appreciated!
Thanks :)

<!--
Please fill the fields below in order to help us diagnose the issue. If you have a
general question or a problem with the scripts, you can ignore these fields.
-->

**Output of 'strings libarm_compute.so | grep arm_compute_version':**
arm_compute_version=v19.11 Build options: {'cppthreads': '1', 'arch': 'armv7a', 'opencl': '0', 'neon': '1', 'build': 'cross_compile', 'debug': '0', 'openmp': '1', 'os': 'linux', 'Werror': '0'} Git hash=unknown

**Platform:** Raspberry Pi 3 Model-B quad core ARM Cortex @1.2GHz, 1GB RAM


**Operating System:** Linux


**Problem description:**
I have implemented LSTM layer using ACL NELSTMLayer API and OpenMP custom implementation.  I found that ACL performing 2 times slower than OpenMP implementation.

FYI, I have attached source code of both the implementations, you can download these implementation from this [link](https://drive.google.com/open?id=1pI-1kX6P0f33Ewk1NjKJ4wlSBPGxDA6b).

Please follow below steps to see the results:

1. Run toGithub/ACL/lstm_using_acl.cpp to see performance results of the LSTM layer using ACL.
2. Run toGithub/Ccode/lstm_without_acl.cpp to see the performance of the LSTM layer using OpenMp.

Let me know any help to reproduce this issue.

Thanks,
Hari






Hello, everyone! I've wrote an cblas_sgemm interface like openblas, and I replace it in https://github.com/apache/incubator-mxnet/blob/master/src/operator/linalg_impl.h#L73 , and I wonder if there have similar gemm api in ACL so that I can made some comparison. What's more is there have some tips that how can i use acl in mxnet or tensorflow with there new version. 
Anyone can help?  So much thanks!

**Output of 'strings libarm_compute.so | grep arm_compute_version':**
arm_compute_version: 19.05
**Operating System:**
Android

**Problem description:**

Hello ,all!

Arm compute library 19.05 introduced NEFFT2d  and NEFFT1d:
https://github.com/ARM-software/ComputeLibrary/blob/master/arm_compute/runtime/NEON/functions/NEFFT1D.h
https://github.com/ARM-software/ComputeLibrary/blob/master/arm_compute/runtime/NEON/functions/NEFFT2D.h

**I want to use NEFFT2D to process a image.  But the dst result is all zero!!!
Can someone point out where the error is？Very thankful！
Waiting online！**

 Code like this:

```
class NEONFFTTestExample : public Example
{
public:
bool do_setup(int argc, char **argv) override
{
const int width  = 20;
const int height = 20;

src.allocator()->init(TensorInfo(width, height, Format::F32));
dst.allocator()->init(TensorInfo(width, height, Format::F32));

nefft2d.configure(&src, &dst,config2d);

src.allocator()->allocate();
dst.allocator()->allocate();

for (unsigned int y = 0; y < height; y++) {
for (unsigned int x = 0; x < width; x++) {
*(src.buffer() + src.info()->offset_element_in_bytes(Coordinates(0,y)) +x) =  
(float)((rand()/(double)(RAND_MAX)) * 255);   
}
}

Window window;
window.use_tensor_dimensions(src.info()->tensor_shape());
Iterator it(&src, window);
execute_window_loop(window, [&](const Coordinates & )
{
std::cout << (*reinterpret_cast<float *>(it.ptr())) << " ";
},it);

return true;
}
void do_run() override
{
//Execute the functions:
nefft2d.run();
}
void do_teardown() override
{      
const int width  = 20;
const int height = 20;

Window window;
window.use_tensor_dimensions(dst.info()->tensor_shape());
Iterator it(&dst, window);
execute_window_loop(window, [&](const Coordinates & )
{
std::cout << (*reinterpret_cast<float *>(it.ptr())) << " ";
},it);
std::cout << std::endl;
}

private:
Tensor         src{}, dst{};
NEFFT2D nefft2d{};
FFT2DInfo config2d;
};
```





