how do you specify inpu channels and output channels in conv1d layer? 
So that this would be deployable in a [google deep learning container](https://cloud.google.com/blog/products/ai-machine-learning/introducing-deep-learning-containers-consistent-and-portable-environments)?

And thanks for developing speech-to-text-wavenet!
I am learning about CTC losses and wonder why the CTC losses are so high. I am doing your project but for another language and dataset and found that the loss is around 20-30. Is there any explanation about this?
WaveNet seems to classify a frame based on the samples within the frame where as RNN models infer information from the previous frames and current frame to classify the current frame. Is it true? If so, is it not inefficient ? How about adding RNNs after WaveNet and before classification ?

Thanks,
SR 
Hi-

This is excellent work. BTW, I wrote the 'sox' program in 1991 and it's nice to see people still using it.

Cheers,

Lance

I am running the pre-trained model in a docker container. After doing the speech-to-text conversion and printing the output, the code always dumps core.

# python recognize.py --file xxx.wav
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX512F instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.

speech to text conversion shows up here

Segmentation fault (core dumped)
hello. thanks for publish this code
i have compiled youre code in python2.7 in google colab service and enable gpu mode
i have installed requirements tensorflow == 1.0.0 and sugartensor == 1.0.0.2
when i compile train.py , i encounterd this message warning

>  tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.

the during of one epoch is 43 hours in VCTK ... 
can i help me to fix this problem ? very very thanks

> I 1222:14:22:43.327:data.py:146] TRAIN set loaded.(total data=43663, total batch=2728)
> I 1222:14:23:06.312:sg_train.py:327] Training started from epoch[000]-step[0].
> train:   0%|                       | 1/2728 [00:57<43:39:25, 57.63s/b]^C
Hello I pulled the docker image and run a docker container  when I am trying to run 

python recognize.py --file asset/data/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac

I get the following error

root@b344bfbeb103:~/speech-to-text-wavenet# python recognize.py --file asset/data/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac
Traceback (most recent call last):
  File "recognize.py", line 51, in <module>
    wav, _ = librosa.load(tf.sg_arg().file, mono=True, sr=16000)
  File "/usr/local/lib/python2.7/dist-packages/librosa/core/audio.py", line 107, in load
    with audioread.audio_open(os.path.realpath(path)) as input_file:
  File "/usr/local/lib/python2.7/dist-packages/audioread/__init__.py", line 78, in audio_open
    return rawread.RawAudioFile(path)
  File "/usr/local/lib/python2.7/dist-packages/audioread/rawread.py", line 49, in __init__
    self._fh = open(filename, 'rb')
IOError: [Errno 21] Is a directory: '/root/speech-to-text-wavenet'

any feedback would be great

thanks
Costas

When I try to load model for visualization using Tensorboard, I can see data from tabs Scalar, Distribution and Histogram. Although tab Graph is loaded, it shows me nothing but a big white picture. So I guess that it cannot read from file graph.pbtxt. PLEASE help me for fixing this. THANKS for advance.