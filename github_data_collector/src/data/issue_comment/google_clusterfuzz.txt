Continuation of https://github.com/google/clusterfuzz/issues/503.

The corresponding issue on OSS-Fuzz side is https://github.com/google/oss-fuzz/issues/1632
Corpus pruning already mostly-worked in  Fuchsia by virtue of the
`merge` command being a thing. However, the
sync-files-between-device-and-host step was missing a beat: corpora were
sync'd properly, but "bad units" (crashes, leaks, ooms, etc) weren't
getting pulled down.  (They do get pulled down in `fuzz`, of course, no
fears there.)

This commit pulls down those "bad units", and also adds a test for the
same.

Test can be run locally via:

INTEGRATION=1 FUCHSIA_TESTS=1 python butler.py py_unittest -t core -p "*corpus_pruning*" -u
This is from my bot.log file. A few debug statements have been added by myself.  Thanks.

2020-01-15 22:11:22,538 - run_bot - INFO - Keys file path /home/adrian/mybot/clusterfuzz/bot/build-urls/9ac05ed80077d44bc01a3d0ce4aacbea9bb924dd.list base url gs://chromium-browser-asan/linux-release
2020-01-15 22:11:22,539 - run_bot - ERROR - Error getting list of build urls from gs://chromium-browser-asan/linux-release/asan-linux-release-([0-9]+).zip.?
None
2020-01-15 22:11:22,539 - run_bot - ERROR - Unable to find a matching revision.!!!
None
2020-01-15 22:11:22,540 - run_bot - INFO - Checking for bad build.
2020-01-15 22:11:22,540 - run_bot - ERROR - Exception occurred when running command: .
Traceback (most recent call last):
  File "/home/adrian/clusterfuzz/src/python/system/process_handler.py", line 197, in run_process
    ignore_children=ignore_children)
  File "/home/adrian/mybot/clusterfuzz/src/third_party/mozprocess/processhandler.py", line 740, in __init__
    (self.cmd, self.args) = (self.cmd[0], self.cmd[1:])
IndexError: list index out of range

In Aug 2019 gRPC project disable AFL fuzzing engine: https://github.com/google/oss-fuzz/pull/2768/files

CF kept running AFL build and reported this issue: https://oss-fuzz.com/testcase-detail/5765765789122560

which remains open, but auto-CC logic, for example, does not recognize that job and does not add new users to it, e.g.: https://github.com/google/oss-fuzz/commit/ebcf4bcdf4fe8c8d763799b62ff2dd607377f6d2#diff-4ed7241f1a048d0a136dbd4702545266

there are only two entries in `ExternalUserPermission`, both are for libFuzzer jobs.

This is just a first draft of the changes to clusterfuzz needed to get in process radamsa as a strategy. Still waiting on getting the radamsa .so to test if it works, but I would appreciate it if you took a look to see if this looks like the right place to start, or if anything is missing. Thanks. 
I'm trying to fuzz  on the android platform (on an odroid) using a locally run version of clusterfuzz,  and it's unable to load path i set for LD_PRELOAD. e.g. bot error:
ERROR: ld.so: object '/system/lib/libclang_rt.asan-arm-android.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.

Can you please advise or provide suggestions on how i can resolve this? The LD_PRELOAD env variable is set in the UI in the "Edit or upload fuzzer" interface as follows:
LD_PRELOAD =/system/lib/libclang_rt.asan-arm-android.so
The path to libclang_rt.asan-arm-android.so is on the device and i've confirmed that permissions are all set and the device has been set to permissive mode. 

I deployed ClusterFuzz to google cloud after following the instructions [here](https://google.github.io/clusterfuzz/getting-started/prerequisites/) followed by [here](https://google.github.io/clusterfuzz/production-setup/clusterfuzz/) starting [here](https://google.github.io/clusterfuzz/production-setup/clusterfuzz/#create-a-new-google-cloud-project).

The failed step was:
```
python butler.py create_config --oauth-client-secrets-path=$CLIENT_SECRETS_PATH \
  --firebase-api-key=$FIREBASE_API_KEY --project-id=$CLOUD_PROJECT_ID $CONFIG_DIR
```

The last message I received was:
```
Running: python butler.py run setup --config-dir /home/qlyoung/cfconfig/ --non-dry-run
| DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details abou
t Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
| Traceback (most recent call last):                                                              
|   File "butler.py", line 337, in <module>                  
|     main()                                                                                                                                                                                                                            
|   File "butler.py", line 311, in main                      
|     command.execute(args)   
|   File "src/local/butler/run.py", line 42, in execute
|     script.execute(args)     
|   File "src/local/butler/scripts/setup.py", line 304, in execute
|     setup_config(args.non_dry_run)            
|   File "src/local/butler/scripts/setup.py", line 228, in setup_config
|     config = data_types.Config.query().get()
|   File "/home/qlyoung/clusterfuzz/src/python/datastore/ndb_patcher.py", line 146, in get
|     return _retry_wrap(result_func)()
|   File "/home/qlyoung/clusterfuzz/src/third_party/google/api_core/retry.py", line 286, in retry_wrapped_func
|     on_error=on_error,    
|   File "/home/qlyoung/clusterfuzz/src/third_party/google/api_core/retry.py", line 184, in retry_target
|     return target()
|   File "/home/qlyoung/clusterfuzz/src/python/datastore/ndb_patcher.py", line 145, in <lambda>
|     result_func = lambda: next(self.iter(limit=1), None)                               
|   File "/home/qlyoung/clusterfuzz/src/python/datastore/ndb_patcher.py", line 164, in iter
|     self, projection=projection, keys_only=keys_only)
|   File "/home/qlyoung/clusterfuzz/src/python/datastore/ndb_patcher.py", line 401, in _ndb_query_to_cloud_queries
|     subqueries.append(_client().query(
|   File "/home/qlyoung/clusterfuzz/src/python/datastore/ndb_patcher.py", line 203, in _client
|     init()                       
|   File "/home/qlyoung/clusterfuzz/src/python/datastore/ndb_patcher.py", line 420, in init         
|     creds = credentials.get_default()[0] 
|   File "/home/qlyoung/clusterfuzz/src/python/base/retry.py", line 89, in _wrapper       
|     result = func(*args, **kwargs)
|   File "/home/qlyoung/clusterfuzz/src/python/google_cloud_utils/credentials.py", line 52, in get_default
|     return google.auth.default(scopes=scopes)
|   File "/home/qlyoung/clusterfuzz/src/third_party/google/auth/_default.py", line 321, in default
|     raise exceptions.DefaultCredentialsError(_HELP_MESSAGE)                         
| google.auth.exceptions.DefaultCredentialsError: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see
 https://cloud.google.com/docs/authentication/getting-started  https://cloud.google.com/docs/authentication/getting-started
| Return code is non-zero (1).     
| Exit.                                                                                                                              
Traceback (most recent call last):                                                                                                                                                                                                      
  File "butler.py", line 337, in <module>                                                                                                                                                                                          
    main()                         
  File "butler.py", line 311, in main
    command.execute(args)          
  File "src/local/butler/create_config.py", line 287, in execute
    gcloud, args.new_config_dir, appengine_location=args.appengine_location)
  File "src/local/butler/create_config.py", line 204, in deploy_appengine
    '--prod', '--config-dir', config_dir
  File "/usr/lib/python2.7/subprocess.py", line 190, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command '['python', 'butler.py', 'deploy', '--force', '--targets', 'appengine', '--prod', '--config-dir', '/home/qlyoung/cfconfig/']' returned non-zero exit status 1
```
After this the program exited. When I try to log in to my deployed project (`project-id.appspot.com`), I receive the following message:

![2020-01-11-224752_918x319_scrot](https://user-images.githubusercontent.com/6827003/72213873-6c187d00-34c4-11ea-9b0e-4d5378e5a54d.png)

I then went back and made sure I had followed all the authentication setup steps correctly. To the best of my knowledge I have.

Having followed the instructions, I don't understand what is going on here. Truth be told, I also have no desire to learn how to debug Firebase, Google Compute Engine, Google Cloud, and Google App Engine to figure out what the issue is here. I am hoping someone knows what I have done wrong or can at least provide a suggestion.

It seems the documentation is incomplete or out of date because the provided steps do not work.

As an aside, I would be happy (*very* happy) to deploy ClusterFuzz on my own hardware, without any sort of Google Dollars integration at all, but the lack of statistics panes is a significant negative.

If these are known documentation issues, please tell me what needs to be done and I will update the docs myself.
Partially addresses #389 

Hi! Here's the Jira integration that we discussed back in Sep/Oct. Some things came up that caused this to get put on the back-burner for a bit.

At a high level, this PR introduces the following:
- support for intake of the Jira server URL and auth credentials through /configuration
- specification of the Jira project for a job through its job definition
- client logic for interfacing with Jira

This was tested with an on-prem instance of Jira; Atlassian's docs seem to indicate that there's no difference in APIs with the cloud version.

Some caveats/requests for feedback with this:
- I've (manually) done an end-to-end issue filing test (upload job, find crash, file issue for the corresponding testcase) but it still needs unit tests; I was running into a `No api proxy found for service "datastore_v3"` assertion error when trying to fetch a value from `db_config` in a test I was writing. Do I need to mock/spoof that in my tests?
- I'd appreciate help with lines 83 and 97 in `src/appengine/libs/issue_management/jira/issue_tracker_manager.py`. With the former, I'm trying to prevent updating status if it hasn't moved from the `new` state, because Jira complains if you try a status update that doesn't actually cause a transition that's defined in the project's workflow. For the latter, I'd like to be able to grab the testcase's `is_crash()` value, but I figured I'd run it by you all before I make significant changes to the `issue.save()` invocation .
- I did change the Monorail `new_issue()` signature and invocations in order to generalize and allow the Jira tracker to read the Jira project value from the job definition. Feels like the wrong way to address this, let me know what I should do.
- Finally, I didn't want to add documentation around the issue trackers before I found out whether that was in the works for Monorail already.

Thanks for your help!
https://clusterfuzz.com/testcase-detail/5764907531108352