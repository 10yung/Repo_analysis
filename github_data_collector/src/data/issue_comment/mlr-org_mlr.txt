Here I added the fregre.glm learner from package fda.usc and the corresponding test script.



Hello,
I am trying to add the learner fregre.glm from package fda.usc. For the integration I followed the code for the already implemented and very similar integration of classif.glm from the same package in RLearner_classif_fdausc.glm.R. But I am having troubles when it comes to using the implementation, because I get an error in the for the trainLearner function, which seems to have an error. In the following you can see the code for the integration. Maybe I am doing a beginner's :) mistake.
``` r
library(mlr)
library(fda.usc)
library(parallelMap)

makeRLearner.regr.fregre.glm = function() {
  makeRLearnerRegr(
    cl = "regr.fregre.glm",
    package = "fda.usc",
    par.set = makeParamSet(
      makeDiscreteLearnerParam(id = "family", default = "binomial()", values = list("binomial()", "gaussian()", "Gamma()", "inverse.gaussian()", "poisson()")),
      makeUntypedLearnerParam(id = "basis.x"),
      makeUntypedLearnerParam(id = "basis.b"),
      makeLogicalLearnerParam(id = "CV", default = FALSE)
    ),
    properties = c("functionals"),
    name = "Generalized Linear Models regression on FDA",
    short.name = "fregre.glm",
    note = "model$C[[1]] is set to quote(fregre.glm)"
  )
}

trainLearner.regr.fregre.glm = function(.learner, .task, .subset, .weights = NULL, ...) {

  # Get and transform functional data
  d = getTaskData(.task, subset = .subset, target.extra = TRUE, functionals.as = "matrix")
  fd = getFunctionalFeatures(d$data)
  # transform the data into fda.usc:fdata class type.
  data.fdclass = fda.usc::fdata(mdata = as.matrix(fd))
  # transform the data into fda.usc:fdata class type and save in a list
  dat = list(df = data.frame(d$target), x = data.fdclass)

  model = fda.usc::fregre.glm(d.target ~ x, data = dat)

  # Fix bug in package. The changed slot looks different when called with
  # `fda.usc::lassif.glm()` than just `classif.glm()`
  model$call[[1]] = quote(fregre.glm)

  return(model)
}

predictLearner.regr.fregre.glm = function(.learner, .model, .newdata, ...) {
  # transform the data into fda.usc:fdata class type.
  fd = getFunctionalFeatures(.newdata)
  nd = list(x = fda.usc::fdata(mdata = fd))

  predict(object = .model$learner.model, newx = nd, type = "response")

}



registerS3method("makeRLearner", "regr.fregre.glm",
                 makeRLearner.regr.fregre.glm)

registerS3method("trainLearner", "regr.fregre.glm",
                 trainLearner.regr.fregre.glm)

registerS3method("predictLearner", "regr.fregre.glm",
                 predictLearner.regr.fregre.glm)


parallelExport("trainLearner.regr.fregre.glm",
               "predictLearner.regr.fregre.glm")

```

<sup>Created on 2020-01-12 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>

## Prework

- [ ] Didn't find any duplicates on this.

## Description


After train and predict, arsq (adjusted r squared) gave result as 1 always. Also greater than rsq value. I guess the formula used for arsq is different from what I know of. I tried with custom r code and got the right answer. Tried to extend to arsq.v2 in my local system with required changes and got an answer equal to rsq and not arsq. I am currently using  mlr version 2.14.0 

## Reproducible example

Learned that the formula given in the [link](https://rdrr.io/github/mlr-org/measures/man/ARSQ.html)  
```
 1 - (1 - rsq) * (p / (n - p - 1L))
```

is not same as I expected it to be. My understanding of ARSQ is 
```
 1 - (1 - rsq) * ((n - 1) / (n - p - 1L))
```

This is the inbuilt arsq: https://github.com/mlr-org/mlr/blob/e12475364a8412e94b19b99d329ed98b5d174c8f/R/measures.R#L268 

I tried to change that as follows:
```
arsq.v2 = makeMeasure(id = "arsq.v2", minimize = FALSE, best = 1, worst = 0,
                   properties = c("regr", "req.pred", "req.truth"),
                   name = "Adjusted coefficient of determination",
                   note = "Defined as: 1 - (1 - rsq) * ((n - 1) / (n - p - 1L)). Adjusted R-squared is only defined for normal linear regression.",
                   fun = function(task, model, pred, feats, extra.args) {
                       n = length(pred$data$truth)
                       p = length(model$features)
                       if (n == p + 1) {
                           warning("Adjusted R-squared is undefined if the number observations is equal to the number of independent variables plus one.")
                           return(NA_real_)
                       }
                       1 - (1 - measureRSQ(pred$data$truth, pred$data$response)) * ((n - 1) / (n - p - 1L))
                   })

```
Compared both with this
```
meas = mlr::performance(testPred, measures = list(mlr::rmse, mlr::mae, mlr::rsq, arsq, arsq.v2)); meas
```
Got the following results.
```
    rmse      mae      rsq     arsq  arsq.v2 
3.147790 1.187279 0.479620 1.000000 0.479620 

```
Then tried arsq with custom rsq
```
preds = testPred$data$response
actual = testPred$data$truth
rss <- sum((preds - actual) ^ 2)  ## residual sum of squares
tss <- sum((actual - mean(actual)) ^ 2)  ## total sum of squares
rsq <- 1 - rss/tss; rsq

adj.r.squared = 1 - (1 - rsq) * ((n - 1)/(n-p-1)); adj.r.squared
```



## Expected output
```> preds = testPred$data$response
> actual = testPred$data$truth
> rss <- sum((preds - actual) ^ 2)  ## residual sum of squares
> tss <- sum((actual - mean(actual)) ^ 2)  ## total sum of squares
> rsq <- 1 - rss/tss; rsq
[1] 0.47962
> 
> adj.r.squared = 1 - (1 - rsq) * ((n - 1)/(n-p-1)); adj.r.squared
[1] 0.4594142
```
fixes #1755 

- update help page to use markdown syntax
Prepare for release: 
 
* [x] Check [current CRAN check results](https://cran.rstudio.org/web/checks/check_results_mlr.html) 
* [x] `devtools::check(remote = TRUE, manual = TRUE)` 
* [x] `devtools::check_win_devel()` 
* [x] Update `cran-comments.md` 
* [x] [Polish NEWS](https://style.tidyverse.org/news.html#news-release) 
 
Submit to CRAN: 
 
* [x] `usethis::use_version('minor')` 
* [ ] `devtools::submit_cran()` 
* [ ] Approve email 
 
Wait for CRAN... 
 
* [ ] Accepted :tada: 
* [ ] `usethis::use_github_release()` 
* [ ] `usethis::use_dev_version()` 
* [ ] Tweet 

```r
library(mlr)

train_data <- data.frame(
  A = runif(100), B = factor(sample(c("A", "B"), 100, replace = T)))

test_data <- data.frame(
  A = runif(100), B = factor(sample(c("A", "B", "C"), 100, replace = T)))

lrn <- makeLearner("regr.ranger", fix.factors.prediction = TRUE)

train_task <- makeRegrTask(
  data = train_data,
  target = "A"
)

model <- train(lrn, train_task)

predictions <- predict(model, newdata = test_data)
```

Gives `Error: Missing data in columns: B.`, although there is no missing data. Same for classification.

Kind regards

See this SO question: https://stackoverflow.com/questions/56553479/r-predicting-with-new-factor-levels-in-mlr-with-regr-svm-task/56587590#56587590

I did a very dirty fix in the `fix-factors` branch that works for this example but probably not if more factor levels in `newdata` have missing values.
In fact, ,`fix.factors.prediction` sets the missing level to `NA` rather than to a level existing in the training data.
We aim at releasing at new version at least every 3 months (if not earlier due to important bugfixes).

Release months:

- February
- May
- August
- November
```r
x <- data.frame(x = c(20, 20, NA))
impute(x, classes = list(numeric=imputeHist()))
#> Error in sample.int(x, size, replace, prob) : 
#>   incorrect number of probabilities
```
the problem is that `sample(...)` behaves differently when the first argument has length 1.
Many wrapper learners, e.g. `ImputeWrapper` or `CPO` learners, perform some processing on the data in the `trainLearner` function and then call `makeChainModel(train(...), ...)` to create a `ChainModel` object which will then be packaged inside a `BaseWrapperModel`. If the `train(...)` part inside the `trainLearner` function fails when `on.learner.error` is `"warning"` or `"quiet"`, then everything works correctly: `isFailureModel` on the resulting object reports `TRUE` because the model is a `BaseWrapperModel` that contains a `ChainModel` (`$learner.model`) that contains a `FailureModel` (`$next.model`). However, if the part before `makeChainModel` fails, then the resulting object is a `BaseWrapperModel` that does *not* contain a `ChainModel` but only a `character(1)` (i.e. the error message). `isFailureModel.BaseWrapperModel` then tries to get the `$next.model` slot of this atomic value and fails.

This can be triggered by using the `imputeHist()` function with only one data row in an `imputeWrapper` function: the `imputeHist()` part fails, and the resulting object triggers an error when `isFailureModel` is called, inside the `resample()` call here.

```r
> configureMlr(on.learner.error="warn")
> tsk <- makeClassifTask("t", data.frame(x = c("x", "y"), a = c(NA, 1)), "x")
> lrn <- makeImputeWrapper(makeLearner("classif.logreg"), classes = list(numeric = imputeHist()))
> resample(lrn, tsk, cv2)
Resampling: cross-validation
Measures:             mmce      
Warning in train(learner, task, subset = train.i, weights = weights[train.i]) :
  Could not train learner classif.logreg.imputed: Error in (function (data, target, col, breaks, use.mids)  : 
  All values missing. Unable to impute with Hist.

Error: $ operator is invalid for atomic vectors
```
