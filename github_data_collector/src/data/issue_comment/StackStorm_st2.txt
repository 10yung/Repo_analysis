Despite Ubuntu's popularity, Debian still remains present in production environments.  It would be useful to support this platform to expand the potential StackStorm user base by having native packaging and installation process for this distribution.

The current stable version is Debian 10 Buster which provides Python3.7 only, no Python 3.6 packages are provided by Debian.  Since Debian and Ubuntu are very similar I was able to build docker images and build system packages for StackStorm.  See the links below for details.

Build package docker images:
https://github.com/StackStorm/st2packaging-dockerfiles/pull/75

Build system packages:
https://github.com/StackStorm/st2-packages/pull/628

For the current experience of running StackStorm 3.2dev on Debian Buster, a large portion of the code base functions out of the box.  There is an issue with rule processing which prevents StackStorm from being using in production on Buster.

This feature request is to officially integrate Debian 10 Buster support into the packaging process and test against Python 2.7, 3.6 and 3.7 as part of the commit process to StackStorm.
Without this change I could not successfully run `make requirements` or `make lint` on python 2.7.

Something is pulling in more-itertools, but the metadata for more-itertools is confusing pip so it is selecting a version that is python 3 only when it should be installing more-itertools 5.0.0 or less on python 2.7.

This takes the shotgun approach to fixing that. It includes the dep for all st2 packages. If anyone cares to evaluate the tree of deps to only include this where needed, be my guest.

Note that this includes a fix for the fixate-requirements script to allow including the python_version marker.
Hello Stackstorm team,

We're noticing an issue with "st2 pack install file://$PWD" command with HTTPS endpoints.

For eg: if we set the below environment variables and try to install a pack , it works without any issues.

export ST2_API_URL=http://127.0.0.1:9101
export ST2_STREAM_URL=http://127.0.0.1:9102
export ST2_AUTH_URL=http://127.0.0.1:9100
export ST2_BASE_URL=http://127.0.0.1

But when we try to install a pack with the below environment variables wherein we route every request via Nginx reverse proxy/load balancer, the st2client fails to show the progress.

export ST2_BASE_URL=**https:**//127.0.0.1
export ST2_AUTH_URL=**https:**//127.0.0.1/auth
export ST2_API_URL=**https:**//127.0.0.1/api
export ST2_STREAM_URL=**https:**//127.0.0.1/stream
export ST2_CACERT=/etc/ssl/st2/st2.crt

Basically the pack install will show the progress like but the client won't exit and it would simply hang forever. But the pack install action chain would have really executed and completed without any issues.

![image](https://user-images.githubusercontent.com/2215990/72335082-6ac59b00-36e4-11ea-90a6-21dafb40e401.png)

Appreciate if any pointers to resolved this issue.

Regards
Harish
This is an example for an Orquesta workflow using the core.ask pack to query multiple parameters. I will also create a PR in the st2docs repository to include this into the documentation. 
## Summary

If a local pack has the same `ref` from a remote pack, the remote pack repository URL is set to the local pack meta data (in the interface).

### ST2 version

ST2 3.0.1, on Python 2.7.6

##### Environment

- Docker. Installed via Docker Compose.

## Steps to reproduce the problem

Create a local pack that has the same name from a remote pack, e.g **elasticsearch**, create the container and open the interface (pack -> see the meta data).

## Expected Results

A local pack should not get the metadata from a remote pack, that has the same name. This gives the impression that the person set in the local pack (e-mail, name, etc) is the mantainer from the remote pack.

## Actual results

The local pack has the repository URL from a remote pack.

The *pack.yaml*:

```
---
ref: elasticsearch
name: Elasticsearch
description: Elasticsearch CRUD
version: 0.0.1
author : X
email : Y
```

The interface:

![image](https://user-images.githubusercontent.com/19755014/71527958-57c96300-28bc-11ea-874c-15083ac1d2e6.png)

> I have edited the HTML to not show the sensitive information (name / e-mail)
Hey all, wanted to get this change in front of some eyeballs here to get some feedback.

We've (@punkrokk) had the need in many of our stackstorm packs to configure them such that they can be run against multiple instances or tenants of the service/API they're built against. Our sensors have typically be written to iterate over all of the tenant configurations in our pack configs, but actions tend to be run against only one tenant, and thus take a tenant name as a parameter in the action at runtime. 

Typically our pack config schema looks similar to this:

```yaml
---
service:
  type: "object"
  required: true
  patternProperties:
    "^\\w+":
      "$ref": "#/properties/credentials"
  additionalProperties: false
credentials:
  type: "object"
  properties:
    username:
      type: "string"
    password:
      type: "string"
      secret: true
```

Which results in a config file like:

```yaml
---
service:
  instance_one:
    username: {{ st2kv.service.instance_one.username }}
    password: {{ st2kv.service.instance_one.password | decrypt_kv }}
  instance_two:
    username: {{ ... }}
    password: {{ ... }}
...
```

We've been taking "credential names" or tenant names as parameters into our action, so that if an action should be run against `instance_one`, the parameter passed into the action would be `tenant=instance_one`. This has, however, resulted in a lot of reused boilerplate across all of our packs that support this kind of multi-tenancy for fetching all tenants, ensuring the provided tenant exists, and constructing the client object in our `lib` code for the requested tenant. We wanted to provide a simpler way to fetch entire objects of configuration details from the pack config, so we started first looking at the `PackConfigDict`. The simple implementation here was to just run a YAQL expression against the pack config to fetch the instance configuration, if present. This seemed pretty intuitive to us, since the query string could be parameterized to take in the instance name (since we have control over the pack schema against which the query is run, we're not worried about things moving around without us knowing), and we'd fetch the entire config object in a couple of lines plus some error handling, and send the config parameters to our client constructor in far less duplicated code across packs than before.

We wanted to get this up to get some feedback on it to see if we're on-base with where a change like this should exist, if it's enough of a change, or if there would be some consideration for changing pack schema to support the idea of a "tenant" object more natively. We posted some discussion about this in the community slack, but wanted to get the change more formalized here. 

(We also have [a variant on this](https://github.com/syncurity-exchange/st2/pull/2) that avoids the performance overhead of YAQL, but is a very naive solution - the idea could be fleshed out to be a more proper search on the dictionary for a key without a YAQL query, though - see https://github.com/syncurity-exchange/st2/pull/2)
## Background, Details

There is a known issue with some mongoengine operations (especially retrievals and to lesser extend, also insertions) being very slow when working with large documents (https://github.com/MongoEngine/mongoengine/issues/1230).

The primary reason for that is massive overhead mongoengine adds when converting native pymongo representation to the document class instance and vice versa.

There are multiple approaches on how to tackle that, including switching to something like pymodm which is much more efficient than mongoengine.

Most of those libraries claim very similar and compatible API to the mongoengine, but this doesn't help us at all. 

Our DB later abstraction is based heavily around mongoengine and we utilize a lot of low level mongoengine functionality and primitives (and also extend it in various places).

This means that switching the ORM library we use is pretty much impossible at the moment. It would simply require too much time and resources and it would likely also result in a lot of hard to catch / edge case bugs.

## Proposed Solution

While profiling and measuring hot code paths and trying to see which places we could optimize (switch directly to pymongo and avoid mongoengine layer all together), I found out that calling ``as_pymongo()`` on mongoengine QuerySet object results in massive performance improvements.

The nice thing is that it's much easier to make that change compatible with out existing code and DB layer compared to fully switching an ORM layer which would require rewriting very big chunks of the code.

The reason for that is that this method avoids very expensive mongoengine conversion and dereferrencing layer which we don't need anyway. It simply returns raw pymongo result aka dictionary.

In this proposed implementation, I updated our ``get()`` and ``query()`` method to utilize ``as_pymongo()`` method and manually convert those raw dictionaries to our database model class instances.

It turns out that approach is much more efficient.

As part of that changes, I also need to update various code to utilize ``query()`` in a manner that it expects that method to return actual DB model class instances and not a ``QuerySet`` object.

In fact, we already did that for a lot of the code in the past. If you check, 90% of the code which calls ``query()`` already expects it to return actual DB model objects and not a query set, so the change shouldn't be that big.

In places where there is not possible and where we need access to raw QuerySet (there should be very few of those), we can use ``raw_query()`` method directly.

Keep in mind that this approach is still not 100% ideal. In ideal world, we would avoid instantiating DB class all together and work directly with raw pymongo dictionaries (at least in critical code paths), but that change would be much harder and more involved.

## Profiling Data

Here is some profiling data when retrieving a single large object with and without utilizing as_pymongo.

```bash
Retrieve large execution with as_pymongo=False
99.9 percentile: 0.011759551286697398s
99 percentile: 0.011098940372467038s
95 percentile: 0.009706759452819822s
90 percentile: 0.011098940372467038s

Retrieve large execution with as_pymongo=True 
99.9 percentile: 0.005786781072616579s
99 percentile: 0.005684897899627685s
95 percentile: 0.005177915096282959s
90 percentile: 0.005684897899627685s
```

As you can see, the difference is substantial (aka as_pymongo + manual model object instantiation around 50% faster).

## TODO

Overall, I'm quite optimistic I can get all that change finished and call the tests passing compared to many other much more involved and complex approach (I already have a huge chunk of tests passing locally).

- [ ] Update affected code and make sure all the tests pass
This is just a quick experiment to see if we could use a more efficient fork of mongoengine (https://github.com/closeio/mongoengine) which reduces a lot of conversion overhead which is involved in regular mongoengine (which results in very slow operations with large documents).

The problem is that even though a lot of similar projects claim almost full mongoengine API compatibility, that doesn't really help us much since our DB abstraction is based heavily around mongoengine and also utilizes various low level APIs and functionality.

In addition to that, this fork is also based around older version of mongoengine.

So this means there will likely be no quick and easy wins for us. If that doesn't work out, probably the most reasonable approach is to try to incrementally optimize hot code paths (especially the ones which workflow results are saved and retrieved) one by one and use pymongo directly in those code paths.
## SUMMARY

Unable to connect Stackstorm to Mongo DB over SSL.
Stackstorm can't function correctly when connection to MongoDB is encrypted by SSL,
There is exception of "aximum recursion depth exceeded while calling a Python object"  in st2api.log and st2auth.log. In this conditions stackstorm is in non functional state at all.

### STACKSTORM VERSION

st2 3.1.0, on Python 3.6.9
:

##### OS, environment, install method

OS: Both the stackstorm and moongodb on Ubuntu 18.04 LTS but installed in diffrent VMs in the same subnet.

All Stackstorm components are installed on one VM but Mongo DB, RAbitMQ on the second VM.


## Steps to reproduce the problem

Without SSL all works fine, but after moving a connection to SSL, Stackstorm can't connect to Mongo.
1. Put ssl=true in st2.conf

2. Other parameters related to ssl ,don't really matter . Tested in all combinations of these parameters with and without client certificate authentication and so on.

3. mongo client can connect to monog over ssl without any problem.  Simple python script using mongoengine module can connect to mongo over ssl. So it seems as not a problem of underlying infrastructure because all other tools and components can connect to mongo wih SSL but staskstorm can't/


## Expected Results

Staskstoem should work with mongo over SSL. That a basic requirements .
## Actual Results

Stackstorm starting up but in the st2api. log and st2auth.log we can see every few seconds error 

2019-12-15 08:08:45,891 140651884441824 INFO (unknown file) [-] Connecting to database "somedatabase" @ "mongodb-host:27017" as user "someuser".
2019-12-15 08:08:45,892 140651884441824 WARNING (unknown file) [-] Retry on ConnectionError - Cannot connect to database default :
maximum recursion depth exceeded while calling a Python object


it seems like some bug in __init__py file in _db_connect function in line number 125 where the connection attempt goes to endless recursion or something likes this.

 


**ISSUE TYPE**

Bug Report

**STACKSTORM VERSION**

`st2 3.0dev (367e117), on Python 2.7.12`

**OS / ENVIRONMENT / INSTALL METHOD**

stackstorm-ha helm chart

**SUMMARY**

When trying to filter all the actions based on the tags field an empty list is returned.
For example with the following action definition.

```yaml
---
name: "restart"
runner_type: "local-shell-script"
description: "Restart Gameworld"
enabled: true
entry_point: "webistrano.py"
tags:
  - name: portal-visible
    value: "yes"
parameters:
  gameworld:
    type: "string"
    description: "Enter Gameworld"
    required: true
    position: 0
```

I get this response:

```
GET https://stackstorm/api/v1/actions?tags=portal-visible

HTTP/1.1 200 OK
Server: nginx/1.16.0
Date: Tue, 03 Dec 2019 16:36:29 GMT
Content-Type: application/json
Content-Length: 2
Connection: keep-alive
X-Total-Count: 0

[]

Response code: 200 (OK); Time: 97ms; Content length: 2 bytes
```