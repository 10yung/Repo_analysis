I am getting the following error when trying to train the model using the celebA dataset. Load fails to find a checkpoint, which makes sense since there are no checkpoints. Then the following error occurs. I have pasted some of the last output along with the stacktrace. I would appreciate any and all help
```
  Total size of variables: 9451908
    Total bytes of variables: 37807632
     [*] Reading checkpoints... ./out\20200116.161511 - data - celebA -x108.z100.uniform_signed.y64.b64\checkpoint
     [*] Failed to find a checkpoint
     [!] Load failed...
Traceback (most recent call last):
  File "main.py", line 147, in <module>
    tf.app.run()
  File "C:\Users\...\.conda\envs\py3\lib\site-packages\tensorflow\python\platform\app.py", line 125, in run
    _sys.exit(main(argv))
  File "main.py", line 120, in main
    dcgan.train(FLAGS)
  File "C:\Users\...\Documents\DCGAN-tensorflow-master\model.py", line 279, in train
    feed_dict={ self.inputs: batch_images, self.z: batch_z })
  File "C:\Users\...\.conda\envs\py3\lib\site-packages\tensorflow\python\client\session.py", line 929, in run
    run_metadata_ptr)
  File "C:\Users\...\.conda\envs\py3\lib\site-packages\tensorflow\python\client\session.py", line 1128, in _run
    str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (64, 218, 178, 3) for Tensor 'real_images:0', which has shape '(64, 64, 64, 3)'
```

Thank you

I try to train the DCGAN on the mnist dataset and I get this error:

`  File "main.py", line 102, in <module>
    max_to_keep=FLAGS.max_to_keep)
  File "C:\Users\felix\Documents\Python Scripts\DCGAN-tensorflow-master\model.py", line 104, in __init__
    self.build_model()
  File "C:\Users\felix\Documents\Python Scripts\DCGAN-tensorflow-master\model.py", line 126, in build_model
    self.G                  = self.generator(self.z, self.y)
  File "C:\Users\felix\Documents\Python Scripts\DCGAN-tensorflow-master\model.py", line 400, in generator
    s_w2, s_w4 = int(s_w/2), int(s_w/4)
TypeError: unsupported operand type(s) for /: 'NoneType' and 'int'`

The error same happend with a custom dataset.

The `global average pooling` is used in the discriminator, torch code and illustrated in the DCGAN paper. But here is `fully connection` in the discriminator.

i trained a model by using ` python main.py --dataset invoice   --batch_size=8 --train --crop --epoch 5000`
anyone knows  how to generate a picture by this trained generator?
 i tried `python main.py --dataset invoice   --batch_size=8`  but nothing comes out
I try to start train on my dataset with image.png image size 250*250
``Traceback (most recent call last):
  File "/home/mihuzz/anaconda3/envs/tf2/lib/python3.7/site-packages/PIL/Image.py", line 2645, in fromarray
    mode, rawmode = _fromarray_typemap[typekey]
KeyError: ((1, 1, 3), '<f8')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 147, in <module>
    tf.app.run()
  File "/home/mihuzz/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/mihuzz/anaconda3/envs/tf2/lib/python3.7/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/home/mihuzz/anaconda3/envs/tf2/lib/python3.7/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "main.py", line 120, in main
    dcgan.train(FLAGS)
  File "/home/mihuzz/Загрузки/DCGAN-tensorflow-master/model.py", line 195, in train
    grayscale=self.grayscale) for sample_file in sample_files]
  File "/home/mihuzz/Загрузки/DCGAN-tensorflow-master/model.py", line 195, in <listcomp>
    grayscale=self.grayscale) for sample_file in sample_files]
  File "/home/mihuzz/Загрузки/DCGAN-tensorflow-master/utils.py", line 44, in get_image
    resize_height, resize_width, crop)
  File "/home/mihuzz/Загрузки/DCGAN-tensorflow-master/utils.py", line 102, in transform
    resize_height, resize_width)
  File "/home/mihuzz/Загрузки/DCGAN-tensorflow-master/utils.py", line 94, in center_crop
    im = Image.fromarray(x[j:j+crop_h, i:i+crop_w])
  File "/home/mihuzz/anaconda3/envs/tf2/lib/python3.7/site-packages/PIL/Image.py", line 2647, in fromarray
    raise TypeError("Cannot handle this data type")
TypeError: Cannot handle this data type

Hey guys, i was stuck in such bug :"UnboundLocalError: local variable 'im' referenced before assignment" when i train the code with celebA. Need Help!
D:\DCGAN-tensorflow-master\DCGAN-tensorflow-master>python main.py --dataset img --input_height=765 --output_height=765 --train
{'G_img_sum': <absl.flags._flag.BooleanFlag object at 0x0000023496289390>,
 'batch_size': <absl.flags._flag.Flag object at 0x00000234909DFBA8>,
 'beta1': <absl.flags._flag.Flag object at 0x00000234930F2EB8>,
 'checkpoint_dir': <absl.flags._flag.Flag object at 0x000002349627FD30>,
 'ckpt_freq': <absl.flags._flag.Flag object at 0x0000023496289208>,
 'crop': <absl.flags._flag.BooleanFlag object at 0x000002349627FE80>,
 'data_dir': <absl.flags._flag.Flag object at 0x000002349627FB70>,
 'dataset': <absl.flags._flag.Flag object at 0x000002349627FA58>,
 'epoch': <absl.flags._flag.Flag object at 0x000002348CCF6748>,
 'export': <absl.flags._flag.BooleanFlag object at 0x000002349627FF60>,
 'freeze': <absl.flags._flag.BooleanFlag object at 0x000002349627FFD0>,
 'h': <tensorflow.python.platform.app._HelpFlag object at 0x0000023496289400>,
 'help': <tensorflow.python.platform.app._HelpFlag object at 0x0000023496289400>,
 'helpfull': <tensorflow.python.platform.app._HelpfullFlag object at 0x0000023496289470>,
 'helpshort': <tensorflow.python.platform.app._HelpshortFlag object at 0x00000234962894E0>,
 'input_fname_pattern': <absl.flags._flag.Flag object at 0x000002349627FAC8>,
 'input_height': <absl.flags._flag.Flag object at 0x00000234932BE748>,
 'input_width': <absl.flags._flag.Flag object at 0x000002349627F940>,
 'learning_rate': <absl.flags._flag.Flag object at 0x000002348DA8D860>,
 'max_to_keep': <absl.flags._flag.Flag object at 0x00000234962890B8>,
 'out_dir': <absl.flags._flag.Flag object at 0x000002349627FBE0>,
 'out_name': <absl.flags._flag.Flag object at 0x000002349627FC88>,
 'output_height': <absl.flags._flag.Flag object at 0x000002349627F898>,
 'output_width': <absl.flags._flag.Flag object at 0x000002349627F9E8>,
 'sample_dir': <absl.flags._flag.Flag object at 0x000002349627FDA0>,
 'sample_freq': <absl.flags._flag.Flag object at 0x0000023496289160>,
 'train': <absl.flags._flag.BooleanFlag object at 0x000002349627FDD8>,
 'train_size': <absl.flags._flag.Flag object at 0x00000234930FB748>,
 'visualize': <absl.flags._flag.BooleanFlag object at 0x000002349627FEF0>,
 'z_dim': <absl.flags._flag.Flag object at 0x00000234962892B0>,
 'z_dist': <absl.flags._flag.Flag object at 0x0000023496289358>}
2019-09-18 06:15:20.855231: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
---------
Variables: name (type shape) [size]
---------
generator/g_h0_lin/Matrix:0 (float32_ref 100x1179648) [117964800, bytes: 471859200]
generator/g_h0_lin/bias:0 (float32_ref 1179648) [1179648, bytes: 4718592]
generator/g_bn0/beta:0 (float32_ref 512) [512, bytes: 2048]
generator/g_bn0/gamma:0 (float32_ref 512) [512, bytes: 2048]
generator/g_h1/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]
generator/g_h1/biases:0 (float32_ref 256) [256, bytes: 1024]
generator/g_bn1/beta:0 (float32_ref 256) [256, bytes: 1024]
generator/g_bn1/gamma:0 (float32_ref 256) [256, bytes: 1024]
generator/g_h2/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]
generator/g_h2/biases:0 (float32_ref 128) [128, bytes: 512]
generator/g_bn2/beta:0 (float32_ref 128) [128, bytes: 512]
generator/g_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]
generator/g_h3/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]
generator/g_h3/biases:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]
generator/g_h4/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]
generator/g_h4/biases:0 (float32_ref 3) [3, bytes: 12]
discriminator/d_h0_conv/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]
discriminator/d_h0_conv/biases:0 (float32_ref 64) [64, bytes: 256]
discriminator/d_h1_conv/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]
discriminator/d_h1_conv/biases:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn1/beta:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn1/gamma:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_h2_conv/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]
discriminator/d_h2_conv/biases:0 (float32_ref 256) [256, bytes: 1024]
discriminator/d_bn2/beta:0 (float32_ref 256) [256, bytes: 1024]
discriminator/d_bn2/gamma:0 (float32_ref 256) [256, bytes: 1024]
discriminator/d_h3_conv/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]
discriminator/d_h3_conv/biases:0 (float32_ref 512) [512, bytes: 2048]
discriminator/d_bn3/beta:0 (float32_ref 512) [512, bytes: 2048]
discriminator/d_bn3/gamma:0 (float32_ref 512) [512, bytes: 2048]
discriminator/d_h4_lin/Matrix:0 (float32_ref 1179648x1) [1179648, bytes: 4718592]
discriminator/d_h4_lin/bias:0 (float32_ref 1) [1, bytes: 4]
Total size of variables: 128940420
Total bytes of variables: 515761680
2019-09-18 06:15:22.676660: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:22.915099: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:23.269142: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:23.507608: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:23.898754: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:24.174286: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:24.174551: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:24.252897: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
2019-09-18 06:15:26.392673: W tensorflow/core/framework/allocator.cc:101] Allocation of 471859200 exceeds 10% of system memory.
Traceback (most recent call last):
  File "main.py", line 147, in <module>
    tf.app.run()
  File "D:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py", line 126, in run
    _sys.exit(main(argv))
  File "main.py", line 120, in main
    dcgan.train(FLAGS)
  File "D:\DCGAN-tensorflow-master\DCGAN-tensorflow-master\model.py", line 195, in train
    grayscale=self.grayscale) for sample_file in sample_files]
  File "D:\DCGAN-tensorflow-master\DCGAN-tensorflow-master\model.py", line 195, in <listcomp>
    grayscale=self.grayscale) for sample_file in sample_files]
  File "D:\DCGAN-tensorflow-master\DCGAN-tensorflow-master\utils.py", line 44, in get_image
    resize_height, resize_width, crop)
  File "D:\DCGAN-tensorflow-master\DCGAN-tensorflow-master\utils.py", line 104, in transform
    im = Image.fromarray(image[j:j+crop_h, i:i+crop_w])
NameError: name 'j' is not defined

HI, can any body help me?
I'm training the model on over 15000 images but it's still outputting final test images like the one below: 

![train_00006000](https://user-images.githubusercontent.com/18582519/62664397-67fe9700-b949-11e9-886a-98fae42bf230.png)

I'm running the following command:

`python main.py --data_dir dataset --dataset food --input_height 128 --output_height 128 --train`

What can I do to get better results??