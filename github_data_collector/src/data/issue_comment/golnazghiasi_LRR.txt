Warning: DotProduct layer: the dimensions of the input variables is not the same. 
> In DotProduct>DotProduct.getOutputSizes at 33
  In DagNN.getVarSizes at 38
  In DagNN.print at 70
  In model2dot at 58
  In LRRTestOnCityScape at 48 
Warning: Sum layer: the dimensions of the input variables is not the same. 
> In Sum>Sum.getOutputSizes at 31
  In DagNN.getVarSizes at 38
  In DagNN.print at 70
  In model2dot at 58
  In LRRTestOnCityScape at 48 
Warning: DotProduct layer: the dimensions of the input variables is not the same. 
> In DotProduct>DotProduct.getOutputSizes at 33
  In DagNN.getVarSizes at 38
  In DagNN.print at 70
  In model2dot at 58
  In LRRTestOnCityScape at 48 
Warning: Sum layer: the dimensions of the input variables is not the same. 
> In Sum>Sum.getOutputSizes at 31
  In DagNN.getVarSizes at 38
  In DagNN.print at 70
  In model2dot at 58
  In LRRTestOnCityScape at 48 
Warning: DotProduct layer: the dimensions of the input variables is not the same. 
> In DotProduct>DotProduct.getOutputSizes at 33
  In DagNN.getVarSizes at 38
  In DagNN.print at 70
  In model2dot at 58
  In LRRTestOnCityScape at 48 
Warning: Sum layer: the dimensions of the input variables is not the same. 
> In Sum>Sum.getOutputSizes at 31
  In DagNN.getVarSizes at 38
  In DagNN.print at 70
  In model2dot at 58
  In LRRTestOnCityScape at 48 
Model exported to models/LRR4x-VGG16-CityScapes-coarse-and-fine/model-vis.dot.
visualization of the model saved to models/LRR4x-VGG16-CityScapes-coarse-and-fine/model-vis.png
[Please exit and restart MATLAB]>> [y or n]>>n

I try to fine tune LRR on my dataset an I set the training to the multi-gpu mode by setting : 
opts.train.gpus = [1:3] same as fcnTrain.m function which works on multi-gpu mode in this way.
But i got error while training process want to use "getBatch" function. How can i resolve this error and use multi-gpu mode?
Hi, i was trying to run the demo, i got this error:

```
Attempt to execute SCRIPT vl_nnconv as a function

Error in dagnn.Conv/forward (line 11)
      outputs{1} = vl_nnconv(...

Error in dagnn.Layer/forwardAdvanced (line 85)
      outputs = obj.forward(inputs, {net.params(par).value}) ;

Error in dagnn.DagNN/eval (line 91)
  obj.layers(l).block.forwardAdvanced(obj.layers(l)) ;

Error in LRRTestOnPascal (line 143)
        net.eval({inputVar, net_input});
```

any ideas? 
thanks.
Hello!

The LRR model trained on cityscapes works really well on my data and I would like to use it and deploy it as a ros node for use in a robot.

To do this I would prefer to have the trained LRR as a caffemodel. Do you know if it is possible to convert the LRR network to a caffemodel? 
When I run the training demo _LRR4xTrainVGG16Pascal_, it goes fine at the beginning. However, after several iterations, I got the following output:

> obj_dil_seg32x: NaN obj_ero_seg32x: NaN objective_32x: NaN

What's wrong with it? I didn't change anything expect for the directories of the dataset.
