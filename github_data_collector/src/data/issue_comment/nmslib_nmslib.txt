- This extends query server with batch knn query based on the batch knn query implementation in the python bindings.
Hi,

Even though we are able to see progress bar in terminal using this line:
`index.createIndex({'post': 2}, print_progress=True)` 
![SS](https://user-images.githubusercontent.com/32897657/67264697-825e0080-f4b4-11e9-811f-ffde533e65b4.png)

Progress bar cannot be seen in *Jupyter Notebook* cells. Could you please fix this issue?

Thank you!

For example, [tqdm](https://github.com/tqdm/tqdm)'s progress bar has another function for Jupyter Notebook like `from tqdm import tqdm_notebook as tqdm`.

I am using scispacy UmlsLinker which relies on nmslib. Upon trying to import nmslib, I get the following
'ImportError: /envs/<conda_directory>/lib/python3.6/site-packages/nmslib.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZTINSt6thread6_StateE'
Trace is the following:
`from scispacy.umls_linking import UmlsEntityLinker -> from scispacy.candidate_generation import CandidateGenerator -> import nmslib`

I used pip to install scispacy into my conda environment and exported that to a yml file. Subsequently, I created this conda environment in another machine using this yml file. There is no import issue in the original conda environment, but there is in this one. 
in c++，how to input the label ，the sample_data do not contain the label. who can help me?
Thanks for the effort you put in this library. 
I am facing two issues with loadIndex:

- A suffix .dat is added to the specified index name with no way to disable or change it.
- MemoryError for a relatively small index (2.0G) on a 32G server. 

First, I create and save the index as follows: 
```python
index = nmslib.init(method='hnsw', space='cosinesimil')
index.addDataPointBatch(data, _ids)
index.createIndex(['M=32', 'post=0', 'efConstruction=800'], print_progress=True)
index.saveIndex('saved_index.ndx')
```
the data contains roughly 6 million entries. 

### .dat suffix is added automatically to the filename

A `.dat` suffix is added to the file name `saved_index.ndx` with no way to disable or alter this behavior. This is not a blocker, I can rename the file. But I want to know if it's recommended to suffix the saved index filename with .dat?

### MemoryError

 As I mentioned, despite that the index index is relatively small (around 2.0G), when I try to load it, I get the error

```python
MemoryError: std::bad_alloc
```
The code I use to load the index is the following:

```python
index = nmslib.init(method='hnsw', space='cosinesimil')
index.loadIndex('saved_index.dat', print_progress=True)
```

I also tried loading the index with the following code: 

```python
In [3]: index = nmslib.loadIndex('saved_index.dat')
```
This fails with the error: 

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-6cc81673b456> in <module>()
----> 1 index = nmslib.loadIndex('saved_index.dat')

TypeError: loadIndex(): incompatible function arguments. The following argument types are supported:
    1. (arg0: object, arg1: object) -> object

Invoked with: 'saved_index.dat'
```

The error message and the function signature aren't very helpful to understand the input parameters or to debug.

I am using nmslib==1.8.1. 

Thanks. 
I am using pip 3.7.3 x64 on WIndows.
![image](https://user-images.githubusercontent.com/46515998/59814384-559bb000-933f-11e9-97ad-9ad74d5c743c.png)
I already have pyblind11 and numpy.
Thanks a lot.
Hi @Neoanarika ,,

It would be nice to have the function to retrieve all the nodes that are part of the existing index.
Was just wondering any reason we did not expose this function?

Thanks in Advance
Has anyone attempted to leverage this to us GPU's?

Jeff
I am getting a dlopen error when importing nmslib after tensorflow:

```
python -c "import tensorflow; print(tensorflow.contrib); import nmslib"
 File "<string>", line 1, in <module>
<module 'tensorflow.contrib' from ...>
ImportError: dlopen: cannot load any more object with static TLS
```

(printing tensorflow contrib simulates importing a module that uses tensorflow, e.g. extending its classes)

switching the order gives no error, and everything works correctly. But in the context of a large code base, it is hard to ensure that nmslib is always imported first, since there are many entry-points. The same thing happens with tensorflow, and it looks similar to this issue: https://stackoverflow.com/questions/50398358/import-error-when-unit-testing-flask-application-with-nmslib

This does not happen on my mac, but only on our Circle CI build, running in a `circleci/python:3.6` docker image. 

Any suggestions for how to fix this?
I have tried setting the env variable `CXXFLAGS="-fPIC -ftls-model=global-dynamic"` when pip installing nmslib.
Currently one can't save a optimized index for HNSW that was previously loaded.  Trying to load such a saved index causes NMSLib to crash.

As far as I can tell, it's cause it uses `ElList_.size()` to determine what to write: https://github.com/nmslib/nmslib/blob/aae2cbf315627e33e4475c7f4640252efa45c066/similarity_search/src/method/hnsw.cc#L754
but it never saves `ElList_`, nor does LoadOptimizedIndex restore `ElList_`:
https://github.com/nmslib/nmslib/blob/aae2cbf315627e33e4475c7f4640252efa45c066/similarity_search/src/method/hnsw.cc#L1002-L1050