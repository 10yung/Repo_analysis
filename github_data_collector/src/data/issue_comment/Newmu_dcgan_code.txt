
new line
Hi, recently I've been studying your code, especially on the conditional DCGAN you made for MNIST dataset.

I see that you concatenated the condition on every layer right after BatchNorm and ReLu, but I still get puzzled with the `conv_cond_concat` function that you use to concat the condition into hidden layer. On some layer, you simply use `T.concatenate` to join them, but on the other layer, you join them using `conv_cond_concat` function as described below

```
def conv_cond_concat(x, y):
    """ 
    concatenate conditioning vector on feature map axis 
    """
    return T.concatenate([x, y*T.ones((x.shape[0], y.shape[1], x.shape[2], x.shape[3]))], axis=1)
```

My questions are, 
 - why using this function, instead of simple `T.concatenate`?
 - judging from reshaping of `y`, I assume you are depth-concatenating it. Am I correct?
Hi,
I'm interested in the contents which is in section 6.2 VISUALIZING THE DISCRIMINATOR FEATURES of DCGAN paper.
I'm not sure I could understanding this part but, I failed to implement it.
I refered to #13 of the following page
https://github.com/Hvass-Labs/TensorFlow-Tutorials

please give me some tip or implementation code (doesn't matter at any code)
thanks in advance
@Newmu can you help me with sample code how to make this part?. I ask about the features of size 28672  how can i get this size and how to get features from it to every image.
Thanks in advance.
HI, new to python so I'm just poking around and the initial setup could use some help in the form of a requirements.txt file. Would love a ```pip freeze > requirements.txt``` if you've got a virtual env with the right deps.

Awesome project.


This is more of a doubt than an issue. 
Why you don't add batch norm to the last layer of your discriminator and generator?
Hi Alec,

I read from the Indico blog that you guys use docker a lot, just wondering if you have a docker copy of DCGAN handy to share? Thanks! Really cool work by the way!

Xinxin