Hello
I'm using Windows 10.
I'm stuck on the next script. I don't see a way out of it.
-----
Critical Start-up Failure: No module named 'cStringIO'
=================================
It appears you are missing a module required for SpiderFoot
to function. Please refer to the documentation for the list
of dependencies and install them.

Python modules required are:
 - netaddr
 - dns
 - cherrypy
 - mako
 - socks
 - whois
 - OpenSSL
 - PyPDF2
 - openxmllib
 - stem
 - bs4
 - gexf
 - phonenumbers
 - ipaddr
 - ipwhois

****************************************************************
Please note that if you are seeing this after doing a git pull
then you just need to do a `pip install -r requirements.txt` as
dependencies previously bundled with SpiderFoot are now
unbundled.
****************************************************************
-----
I understood that cStringIO doesn't exist anymore but I can't get around this problem.
Do you have a solution, please ?
Thank you

Sincerely

Dockerfile has missing some deps for Pillow and Docker image can`t build.
Fix: add missing deps in "RUN" section of Dockerfile.
Missing deps are: jpeg-dev zlib-dev freetype-dev lcms2-dev openjpeg-dev tiff-dev

Correct Dockerfile:
# Pull the base image.
FROM alpine:latest
COPY requirements.txt .

# Run everything as one command so that only one layer is created
RUN apk --update add --no-cache --virtual build-dependencies gcc git curl py2-pip swig jpeg-dev zlib-dev freetype-dev lcms2-dev openjpeg-dev tiff-dev tk-dev tcl-dev libxml2-dev libxslt-dev libffi-dev gcc musl-dev libgcc openssl-dev curl \
        tinyxml-dev python2-dev musl-dev openssl-dev libffi-dev libxslt-dev \
    && apk --update --no-cache add python2 musl openssl libxslt tinyxml \
    && pip --no-cache-dir install wheel \
    && pip --no-cache-dir install -r requirements.txt \
    && addgroup spiderfoot \
    && adduser -G spiderfoot -h /home/spiderfoot -s /sbin/nologin \
               -g "SpiderFoot User" -D spiderfoot \
    && rmdir /home/spiderfoot \
    && cd /home \
    && curl -sSL https://github.com/smicallef/spiderfoot/archive/master.tar.gz \
       | tar -v -C /home -xz \
    && mv /home/spiderfoot-master /home/spiderfoot \
    && chown -R spiderfoot:spiderfoot /home/spiderfoot \
    && apk del --purge build-dependencies \
    && rm -rf /var/cache/apk/* \
    && rm -rf /root/.cache

USER spiderfoot
WORKDIR /home/spiderfoot

EXPOSE 5001

# Run the application.
ENTRYPOINT ["/usr/bin/python"]
CMD ["./sf.py", "0.0.0.0:5001"]
It appears you are missing a module required for SpiderFoot
to function. Please refer to the documentation for the list
of dependencies and install them.

Python modules required are: 
 - netaddr
 - dns
 - cherrypy
 - mako
 - socks
 - whois
 - OpenSSL
 - PyPDF2
 - openxmllib
 - stem
 - bs4
 - gexf
 - phonenumbers
 - ipaddr
 - ipwhois

****************************************************************
Please note that if you are seeing this after doing a git pull
then you just need to do a `pip install -r requirements.txt` as
dependencies previously bundled with SpiderFoot are now
unbundled.

Running spiderfoot bound to all interfaces on server, would be great, if spiderfoot could be run as a service on windows.  

How difficult would it be to have the export file option grab the scan name instead of just using Spiderfoot.csv or whatever?

I want to drop scan results into Open Semantic Search, having a disciplined naming scheme would be invaluable.
Docker build failed on Pillow with 2 missing dependencies; jpeg-dev and zlib-dev. 
Request to add openxmllib dependency into requirements.txt file.
Modify the `sfp_spider` module to parse `/.well-known/apple-app-site-association` and store the associated links.
SpiderFoot plug-in to search [NetworksDB.io API](https://networksdb.io/api/docs) for IP address and domain information.

```python
    def watchedEvents(self):
        return ['IP_ADDRESS', 'IPV6_ADDRESS', 'INTERNET_NAME', 'DOMAIN_NAME']

    # What events this module produces
    def producedEvents(self):
        return ['INTERNET_NAME', 'IP_ADDRESS', 'IPV6_ADDRESS', 'NETBLOCK_MEMBER',
                'CO_HOSTED_SITE', 'GEOINFO', 'RAW_RIR_DATA']
```

Modify the `sfp_spider` module to parse the [Sitemap](https://en.wikipedia.org/wiki/Sitemaps) directive from `robots.txt` and store the associated links.
