
We would like to generate rendered images of all models in ModelNet40, however, the code released shows a missing of "vl_argparse" which defines the rendering parameters for the 12-view renderer, and I am wondering if you can update it on Github? Thank you.
I want to test the shaptnet55 dataset, but I can't seem to find the label of the test set.
Hi,

I wonder if you have the rendered images for shrec17? The provided shapenet55 dataset is rendered from ShapeNetCorev1, right? 

I would like to run some baselines. So it would be better if I use the same dataset for fair comparison.

Thanks
Hello,  
When 'git submodule update --init' , there's no error.
But when 'matlab -nodisplay -r "setup(true,struct('enableGpu',true,'enableCudnn',true));exit;"', the errors I got,
![image](https://user-images.githubusercontent.com/23699121/47409138-71d95400-d794-11e8-80b7-231d6f0c67a9.png)

I guess the dependencies installed unsuccessfully.
So should I install the dependencies independently？Or there are any better solutions?

Thanks.
Hi,

I am just trying to recreate the results of the fine-tuned CNN experiment that you showed on the paper, specifically that a a pre-trained CNN with finetuning on the ModelNet40 dataset  using 12x views for both testing and training can achieve 88.6% accuracy. 
When you say finetuned, did you retrain just the last layer as your number of classes decreased or did you retrain the entire classifier portion of the network?, and if so what parameters did you use when retraining?

I have currently tried both VGG and Alexnet, and only tuning the last layer due to class number changes, I can only get an accuracy of 78% for Alexnet, and 69% for VGG16. I believe it has something to do with my parameters or my understanding of fine-tuning, but any help on this matter would be phenomenal!

Thanks,
Manik
Hi，
You mentioned that there are 12,311 object instances in the ModelNet 40 dataset in your paper. However, in your provided dataset, I find there are only 3,983 object instances. Could you please provide more details about the dataset. Thank you for your help.
Sorry, I'm new to this area.

When I follow `README.md` finish the installation, I run this command `shape_compute_descriptor('airplane_0002.off');`
And I got a `.txt` file named `airplane_0002_descriptor.txt`.

What is the purpose of this file? And how can I get the predicted label with this file?

Thanks for any help.
Hi, I have seen the great power of 3d object classification MVCNN. And I wonder whether you have examined the network' s performance when the texture information of the 3d model is included? I have collected a bunch of models and some of them are in different class only due to their different color on the surface. So I wonder whether you have tried using colored rendered picture as the input? Thanks!
Hello @suhangpro !

Is there any way that I could visualize  layer weights,gradients  to see how well it is training?
Thanks