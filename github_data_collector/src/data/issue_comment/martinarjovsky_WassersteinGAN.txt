There are two questions. firstly, dose the discriminator have batchnormalization layer? secondly, if so, should the trainable parameters on batchnorm layer be clipped?


Thanks in advance.
In vanilla GANs, a sigmoid activation is applied on the output layer for G and D. 
See https://github.com/goodfeli/adversarial/blob/master/mnist.yaml

For WGAN, there is none for D, and we get a score instead of a probability.

However, in the code there is no activation (e.g sigmoid) for WGAN-MLP also for G, whereas there is tanh for WGAN-DCGAN. 
Is there a specific reason? 

Thanks in advance

Hello
I'm trying to train WGAN in order to increase the amount of images (3211 img) that I have from my own data-set. The size of my images are 1242x375, but only for testing purposes of this net I am resizing them to 256x256. 
To add my own data-set, I just added this code lines to the main.py file:

`elif opt.dataset == 'own':
        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
        dataset = dset.ImageFolder(root=opt.dataroot,
                                transform=transforms.Compose([
                                    transformaciones.Transformaciones(),
                                    transforms.RandomHorizontalFlip(0.1),
                                    transforms.Resize((opt.imageSize,opt.imageSize)),
                                    transforms.ToTensor(),
                                    normalize,
                                ]))` 

_Transformaciones_ is the data augmentation module that i have build.
I launch the training with 6 extra layers and 800 epoch. 
The thing is that generator net only produces noise. I tried to use the generator net when the results were like lossG: 0.08 approx, and I only had noise in the images. 
I am doing something wrong? Is because I have only a few images to train?
Someone has tried to use an own data-set and managed to made it work?

Thanks!
Hi,

I don't use torch a lot and I have a question regarding the implementation of the discriminator loss at line 211, errD = errD_real - errD_fake where errD_real is the gradient of real samples (line202: errD_real.backward(one)) and errD_fake is the gradient of fake samples (errD_fake.backward(mone)). However, in the paper it seems that errD needs to be maximized while it is minimized here?

Thanks
`Traceback (most recent call last):
  File "main.py", line 112, in <module>
    netG = dcgan.DCGAN_G(opt.imageSize, nz, nc, ngf, ngpu, n_extra_layers)
  File "/home/mali/WassersteinGAN-master/models/dcgan.py", line 69, in __init__
    nn.ConvTranspose2d(nz, cngf, 4, 1, 0, bias=False))
  File "/home/mali/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 180, in add_module
    raise KeyError("module name can't contain \".\"")
KeyError: 'module name can\'t contain "."'`
the version on my computer are: pytorch 1.0.0; torchvision 0.2.1. I guess it should be run in old version, could anyone tell me which version can run it?
https://github.com/martinarjovsky/WassersteinGAN/blob/f81eafd2aa41e93698f203732f8f395abc70be02/main.py#L73
The new version of torchvision has modified this parameter. [https://github.com/pytorch/vision/commit/73a29e02aff4f30c1d32bcdfa032f6bb72b1bcce#diff-deea30150565e331de97e6ba14a3e119](url) 
parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')
the default imagesize is 64*64ï¼Ÿhow to define a new image size like  m*n
For WGAN, it should maximize the loss of Discriminator, and minimize the loss of negative Generator. However, it did just in the opposite way in the codes. am I wrong?
I think it should like this:
errD_real.backward(mone)       in 189.
errD_fake.backward(one)   in 197.
errG.backward(mone)               in 213.

In the paper, you report a negative result that

> WGAN training becomes unstable at times when one uses a momentum based optimizer such as Adam [8] (with B1 > 0) on the critic, or when one uses high learning rates

You advocate using RMSProp for the discriminator instead. Yet in the implementation, although RMSProp is the default, there is an option to use Adam ([line 144](https://github.com/martinarjovsky/WassersteinGAN/blob/master/main.py#L144)). Is this included for consistency with your evaluation, or have you found settings for which Adam is effective with the WGAN?