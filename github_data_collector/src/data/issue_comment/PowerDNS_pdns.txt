### Short description
<!-- Write a small description of what this Pull Request fixes or provides, including the issue #s -->
This is slightly faster, especially with a larger number of entries.

### Checklist
<!-- please indicate if any of these things are done/included with this Pull Request. Not all boxes need to be checked for the Pull Request to be accepted -->
I have:
- [x] read the [CONTRIBUTING.md](https://github.com/PowerDNS/pdns/blob/master/CONTRIBUTING.md) document
- [x] compiled this code
- [x] tested this code
- [ ] included documentation (including possible behaviour changes)
- [ ] documented the code
- [ ] added or modified regression test(s)
- [ ] added or modified unit test(s)


### Short description
<!-- Write a small description of what this Pull Request fixes or provides, including the issue #s -->
This PR is a work-in-progress to reduce the number of temporary memory allocations and copies in the authoritative server. Comments welcome!

### Checklist
<!-- please indicate if any of these things are done/included with this Pull Request. Not all boxes need to be checked for the Pull Request to be accepted -->
I have:
- [x] read the [CONTRIBUTING.md](https://github.com/PowerDNS/pdns/blob/master/CONTRIBUTING.md) document
- [x] compiled this code
- [x] tested this code
- [ ] included documentation (including possible behaviour changes)
- [ ] documented the code
- [ ] added or modified regression test(s)
- [ ] added or modified unit test(s)


### Short description
<!-- Write a small description of what this Pull Request fixes or provides, including the issue #s -->
Before this change, both the query and packet caches in the authoritative server can exceed their maximum size by a lot, until the next cleaning cycle.
This is particularly nasty since the current cleaning algorithm will never remove entries from the cache until they expire, as opposed to what we do in the recursor, for example, where we nuke the least-recently used entries, even if they are still valid, when the cache is full.
This commit changes that by removing the least recently inserted or updated entry from the cache after inserting a new one when the cache is full, thus enforcing the maximum size more strictly.

Note that this is really the least recently inserted/updated and not the least recently used one, as is done in the recursor. Having a proper `LRU` in the auth would require acquiring a write lock for a
simple lookup, instead of a potentially concurrent read-lock at the moment. We might want to consider changing that at some point, as a `LRU` might be fairer and the lock contention might be very small since the caches are sharded.

### Checklist
<!-- please indicate if any of these things are done/included with this Pull Request. Not all boxes need to be checked for the Pull Request to be accepted -->
I have:
- [x] read the [CONTRIBUTING.md](https://github.com/PowerDNS/pdns/blob/master/CONTRIBUTING.md) document
- [x] compiled this code
- [x] tested this code
- [ ] included documentation (including possible behaviour changes)
- [x] documented the code
- [ ] added or modified regression test(s)
- [ ] added or modified unit test(s)


<!-- Hi! Thanks for filing an issue. It will be read with care by human beings. Can we ask you to please fill out this template and not simply demand new features or send in complaints? Thanks! -->
<!-- Also please search the existing issues (both open and closed) to see if your report might be duplicate -->
<!-- Please don't file an issue when you have a support question, send support questions to the mailinglist or ask them on IRC (https://www.powerdns.com/opensource.html) -->

<!-- Tell us what is issue is about -->
 - Program: Recursor
 - Issue type: Bug report

### Short description
Just a quick email to say that we're seeing an inconsistency in the PowerDNS (4.3.0 beta 2) output between lua and protobuf. When we request a domain that is listed in a whitelist RPZ, the response.appliedPolicy is not being set in the protobuf output. The lua scripting environment does appear to see the policy set, as shown by logging dq.appliedPolicy.policyName. Is it possible to confirm if this is a known and / or expected behaviour? Our assumption is that any RPZ policy matching applied and recorded in dq.appliedPolicy.policyName should also be reflected in the protobuf 'response' output.

### Environment
<!-- Tell us about the environment -->
 - Operating system: Not sure, Centos I think
 - Software version: 4.3.0 beta2
 - Software source: PowerDNS repository

### Steps to reproduce
See above.


<!-- Hi! Thanks for filing an issue. It will be read with care by human beings. Can we ask you to please fill out this template and not simply demand new features or send in complaints? Thanks! -->
<!-- Also please search the existing issues (both open and closed) to see if your report might be duplicate -->
<!-- Please don't file an issue when you have a support question, send support questions to the mailinglist or ask them on IRC (https://www.powerdns.com/opensource.html) -->

<!-- Tell us what is issue is about -->
 - Program: dnsdist <!-- delete the ones that do not apply -->
 - Issue type: Bug report

### Short description
<!-- Explain in a few sentences what the issue/request is -->
On response processing path, dnsdist ignores any value assigned into DNSQuestion.len field and sends on a buffer of the original size anyway.

### Environment
<!-- Tell us about the environment -->
 - Operating system: Fedora 31
 - Software version: commit d650d4b76b2bd7280b96153f9cd1f7b9becf1a84
 - Software source: compiled myself

### Steps to reproduce
<!-- Tell us step-by-step how the issue can be triggered. Please include your configuration files and any (Lua) scripts that are loaded. -->
1. Build dnsdist.
2. Create a configuration file `dnsdist.lua`, with the following contents:
```lua
addLocal("0.0.0.0", {reusePort=true})

setECSOverride(true)
setECSSourcePrefixV4(32)
setECSSourcePrefixV6(128)

function onresponse(dq)
	print('qname='..dq.qname:toString())
	print('  old_len='..dq.len)
	dq.len = 12 -- size of DNS message header
	print('  new_len='..dq.len)
	return DNSAction.None
end

addResponseAction(AllRule(), LuaResponseAction(onresponse))

newServer({address="8.8.8.8", useClientSubnet=false})
```
3. Start dnsdist up using the command `sudo ./dnsdist -C dnsdist.lua`
4. Start Wireshark and listen on the loopback interface.
5. Try to resolve www.google.com using the command `host -t a www.google.com 127.0.0.1`

### Expected behaviour
* `host` command fails because the DNS response contains only the header.
* In Wireshark, it can be seen that the DNS response only contains the header.

### Actual behaviour
<!-- What did happen? Please (if possible) provide logs, output from `dig` and/or tcpdump/wireshark data -->
* `host` command completes successfully, displaying multiple IPv4 addresses of www.google.com.
* In Wireshark, it can be seen that the DNS response was not modified, i.e. is not shortened to the size of a DNS header.

### Other information
<!-- if you already did more digging into the issue, please provide all the information you gathered -->

I'd like to request a way to serve Prometheus /metrics without authorization, which I haven't been able to accomplish (apparently due to the way all webServer access is hardcoded to require BasicAuth).
The reason is purely due to the way Prometheus jobs are configured. While this works fine for a single target (setting credentials in the Prometheus job config), it only sort-of works when jobs are dynamically discovered via any of the service discovery mechanisms (requiring all discovered targets to have the same credentials).
Most exporters do not require any auth since metrics are generally not considered confidential or security-sensitive.

In normal operations, in the database, the reverse entries have no trailing point, but it's possible to have one anyway
On our production server, we had about 10% of all PTR with a trailing point. We have no idea how or why it was added since we only change the DB via the API or via pdnsutil edit-zone, never via SQL edits.
The problem is that the DNS server doesn't care about the final point, but the API does

It caused some issues for our API client, which was blind to some records that actually existed. And doubling every search to cover the potential final point is a bit costly. We had to manually correct the records in the DB

Tested on the current master branch (as of Jan 16 2020). Installed via the ubuntu bionic package provided by pdns, on a amd64 bionic machine. 
pdns-auth-proxy version 4.3.0~alpha1+master.84.gd928cf204-1pdns.bionic, with a mysql backend
Bug first seen on a production 4.1 server

Example of the issue, with a manually crafted entry

```
mysql> select * from records where name = '10.2.0.192.in-addr.arpa' \G
*************************** 1. row ***************************
         id: 98
  domain_id: 8
       name: 10.2.0.192.in-addr.arpa
       type: PTR
    content: www.example.com.
        ttl: 172800
       prio: 0
change_date: NULL
   disabled: 0
  ordername: NULL
       auth: 1
1 row in set (0.00 sec)
```
The resolution is fine

```
% dig +short ptr 10.2.0.192.in-addr.arpa.  @127.127.0.1

www.example.com.
```
but the search API won't return this entry if I don't explicitely add the trailing point
```
% curl -s -H 'X-Api-Key: 123password'  'http://127.0.0.1:8081/api/v1/servers/localhost/search-data?max=5000&object_type=record&q=www.example.com' | jq
[
  {
    "content": "192.0.2.10",
    "disabled": false,
    "name": "www.example.com.",
    "object_type": "record",
    "ttl": 172800,
    "type": "A",
    "zone": "example.com.",
    "zone_id": "example.com."
  }
]

% curl -s -H 'X-Api-Key: 123password'  'http://127.0.0.1:8081/api/v1/servers/localhost/search-data?max=5000&object_type=record&q=www.example.com.' | jq
[
  {
    "content": "www.example.com.",
    "disabled": false,
    "name": "10.2.0.192.in-addr.arpa.",
    "object_type": "record",
    "ttl": 172800,
    "type": "PTR",
    "zone": "2.0.192.in-addr.arpa.",
    "zone_id": "2.0.192.in-addr.arpa."
  }
]
```
### Short description
This changes the serial from `0` to the correct value in a domain-specific API call such as `/api/v1/servers/localhost/zones/example.com.`.

`/api/v1/servers/localhost/zones` yields the right serial without this patch, and I see that `void LMDBBackend::getAllDomains(vector<DomainInfo> *domains, bool include_disabled)` uses more 'direct' code to get the serial. PRing this as draft until I figure out which code is right.

### Checklist
<!-- please indicate if any of these things are done/included with this Pull Request. Not all boxes need to be checked for the Pull Request to be accepted -->
I have:
- [ ] read the [CONTRIBUTING.md](https://github.com/PowerDNS/pdns/blob/master/CONTRIBUTING.md) document
- [ ] compiled this code
- [ ] tested this code
- [ ] included documentation (including possible behaviour changes)
- [ ] documented the code
- [ ] added or modified regression test(s)
- [ ] added or modified unit test(s)
- [ ] <!-- remove this line if your PR is against master --> checked that this code was merged to master

```
test-lua_auth4_cc.cc: In member function ‘void lua_auth4_cc::test_prequery::test_method()’:
test-lua_auth4_cc.cc:37:53: error: expected unqualified-id before ‘&’ token
   37 |   } catch (const LuaContext::ExecutionErrorException& e) {
      |                                                     ^
```

### Short description
<!-- Write a small description of what this Pull Request fixes or provides, including the issue #s -->

### Checklist
<!-- please indicate if any of these things are done/included with this Pull Request. Not all boxes need to be checked for the Pull Request to be accepted -->
I have:
- [ ] read the [CONTRIBUTING.md](https://github.com/PowerDNS/pdns/blob/master/CONTRIBUTING.md) document
- [ ] compiled this code
- [ ] tested this code
- [ ] included documentation (including possible behaviour changes)
- [ ] documented the code
- [ ] added or modified regression test(s)
- [ ] added or modified unit test(s)
- [ ] <!-- remove this line if your PR is against master --> checked that this code was merged to master

### Short description
<!-- Write a small description of what this Pull Request fixes or provides, including the issue #s -->
- Since 272e9a0 we scanned all policies for an exact match before looking for wildcard matches. It brokes the promise that filtering policies are evaluated in the order they are defined ;
- After a "pass-thru" match, we should not process any other RPZ rule ;
- Export the filtering policy type to `Lua`.

### Checklist
<!-- please indicate if any of these things are done/included with this Pull Request. Not all boxes need to be checked for the Pull Request to be accepted -->
I have:
- [x] read the [CONTRIBUTING.md](https://github.com/PowerDNS/pdns/blob/master/CONTRIBUTING.md) document
- [x] compiled this code
- [x] tested this code
- [ ] included documentation (including possible behaviour changes)
- [x] documented the code
- [x] added or modified regression test(s)
- [x] added or modified unit test(s)
