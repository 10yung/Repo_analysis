## Bug Report

**Describe the bug**
fluent-bit didn't create message field but concatenate to previous field

**Your Environment**
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Version used: td-agent-bit 1.3.5
* Configuration:
```
[PARSER]
    Name    head_log
    Format  regex
    Regex   ^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}) (?<level>[A-Z]+)
    Time_Format %Y-%m-%d %H:%M:%S
    Time_Key time
[PARSER]
    Name    rest_log
    Format  regex
    Regex   (?m-ix)^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}) (?<level>[A-Z]+)(?<message>.*)
    Time_Format %Y-%m-%d %H:%M:%S
    Time_Key time
[INPUT]
    Name tail
    Tag  sample.tag
    Path /etc/td-agent-bit/logs/pythonApp.log
    Multiline  On
    Parser_Firstline head_log
    Parser_1 rest_log
```
* Operating System and version:
debian 10
**To Reproduce**
https://rubular.com/r/fAZ2Lhl2y2P0qK
**Log sample**
```
2019-08-01 18:58:05 ERROR
Exception on main handler
Traceback (most recent call last):
  File "python-logger.py", line 9, in make_log
    return word[13]
IndexError: string index out of range
```
**Output**
```
td-agent-bit[1565]: Fluent Bit v1.3.5
td-agent-bit[1565]: Copyright (C) Treasure Data
td-agent-bit[1565]: [2020/01/18 15:22:18] [ info] [storage] initializing...
td-agent-bit[1565]: [2020/01/18 15:22:18] [ info] [storage] in-memory
td-agent-bit[1565]: [2020/01/18 15:22:18] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128
td-agent-bit[1565]: [2020/01/18 15:22:18] [ info] [engine] started (pid=1565)
td-agent-bit[1565]: [2020/01/18 15:22:18] [ info] [sp] stream processor started
янв 18 15:22:23 rabcons td-agent-bit[1565]: [0] sample.tag: [1564685885.000000000, {"level"=>"ERROR
td-agent-bit[1565]: Exception on main handler
td-agent-bit[1565]: Traceback (most recent call last):
td-agent-bit[1565]:   File "python-logger.py", line 9, in make_log
td-agent-bit[1565]:     return word[13]
td-agent-bit[1565]: IndexError: string index out of range"}]
```
* **Expected behavior**
message field created and multiline log is there
* **Addition info**
if i'm writing into ```rest_log``` something like ```(?<exception>Exception)(?<message>.*)``` it can create correct exception filed and multiline message field. But exactly i don't know what will be placed in second line.
if i'm writing into ```rest_log``` something like ```(?<message>.*)``` or even ```(?m-ix)(?<message>.*)``` it create multiple message fileds and only last one available in kibana/elastic



Currently fluent-bit logs can be redirected to a file using Log_File.
But there is no configuration option to limit the size of the file. Additionally, there is no log rotation that can be enabled for fluent-bit logs.
These might be useful when we want to collect fluent-bit process logs itself and also to debug.

Added new configuration parameters:
Log_File_Size - Size limit in MB for the file specified by Log_File.
Log_File_History - Max number of backups to be kept.
These backups are kept as <Log_File>.1, <Log_File>.2 etc.

Sample configuration.
[SERVICE]
    Flush        1
    Daemon       Off
    Log_Level    debug
    Log_File     ./fb_log.log
    Log_File_Size     1   
    Log_File_History  2

This PR has the corresponding changes.

online report
http://oracle.fly-server.ru/pvs-studio/fluent-bit
offline report
http://oracle.fly-server.ru/pvs-studio/fluent-bit.tar.bz2


## Bug Report

**Describe the bug**
Using nested wild cards in the Path gives the following error:

`[in_tail] Cannot read info from: C:\ProgramData\Docker\containers\**\*.log`

Running `dir **/*` in powershell works as expected and it lists out the said log files.

In Linux all '/var/log/containers/*.log' works as it searches the sub directories for log files too.

P.S. I've tried */*.log, *.log and it did not work for me.


**To Reproduce**
- Rubular link if applicable:
- Example log message if applicable:
```
`[in_tail] Cannot read info from: C:\ProgramData\Docker\containers\**\*.log`
```
- Steps to reproduce the problem:

**Expected behavior**
I expect Path should be able to recursively search for *.log files in the location that I'm pointing to similar to how `dir` does it.

**Screenshots**
<!--- If applicable, add screenshots to help explain your problem. -->

**Your Environment**
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Version used:
The current fluent-bit for windows exe on the official site: https://docs.fluentbit.io/manual/installation/windows gives an error related to missing DLL files.

I'm using the 64 bit version shared by @fujimotos : https://github.com/fluent/fluent-bit/issues/960#issuecomment-571906226 

* Configuration:
* Environment name and version (e.g. Kubernetes? What version?):
* Server type and version:
* Operating System and version:
* Filters and plugins:

**Additional context**
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

I'm trying to tail all of the docker container logs using fluent-bit for windows on a machine.

## Bug Report

Fluent-bit not able to send logs to aws hosted elastic search ,which port and url should be configured as the elastic serach host ?

$ kubectl logs pod/fluent-bit-9w82n -n logging
Fluent Bit v1.3.5
Copyright (C) Treasure Data

[2020/01/17 16:09:39] [ info] [storage] initializing...
[2020/01/17 16:09:39] [ info] [storage] in-memory
[2020/01/17 16:09:39] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128
[2020/01/17 16:09:39] [ info] [engine] started (pid=1)
[2020/01/17 16:09:39] [ info] [filter_kube] https=1 host=kubernetes.default.svc port=443
[2020/01/17 16:09:39] [ info] [filter_kube] local POD info OK
[2020/01/17 16:09:39] [ info] [filter_kube] testing connectivity with API server...
[2020/01/17 16:09:39] [ info] [filter_kube] API server connectivity OK
[2020/01/17 16:09:39] [ info] [http_server] listen iface=0.0.0.0 tcp_port=2020
[2020/01/17 16:09:39] [ info] [sp] stream processor started

Signed-off-by: Khem Raj <raj.khem@gmail.com>
Signed-off-by: Atibhi Agrawal <Atibhi.Agrawal@iiitb.org>
Issue #1672 
## Bug Report

**Describe the bug**
One pod from a daemonset is marked as not ready beacuse it fails its readiness probe

**To Reproduce**
Use the readiness probe in a DaemonSet as described in https://github.com/fluent/fluent-bit-kubernetes-logging/blob/1cdfc96be5c265364095d5b3525c5d992a320aa9/output/kafka/fluent-bit-ds.yaml#L30

**Expected behavior**
The readiness probe should not fail

**Your Environment**
Openshift 3.11 
Fluentbit 1.3.5

**Additional context**
In my case I have 4 pods running in the daemonset and only one is failing. If I perform a curl to the failing pod it returns a 404 error
```
fluent-bit-p6trq       0/1       Running   0          22m       192.168.241.112
```
The api is up
```
curl  http://192.168.241.112:2020/api/v1 -v
* About to connect() to 192.168.241.112 port 2020 (#0)
*   Trying 192.168.241.112...
* Connected to 192.168.241.112 (192.168.241.112) port 2020 (#0)
> GET /api/v1 HTTP/1.1
> User-Agent: curl/7.29.0
> Host: 192.168.241.112:2020
> Accept: */*
>
< HTTP/1.1 200 OK
< Server: Monkey/1.7.0
< Date: Thu, 16 Jan 2020 11:57:50 GMT
< Transfer-Encoding: chunked
<
* Connection #0 to host 192.168.241.112 left intact
{"fluent-bit":{"version":"1.3.5","edition":"Community","flags":["FLB_HAVE_PARSER","FLB_HAVE_RECORD_ACCESSOR","FLB_HAVE_STREAM_PROCESSOR","FLB_HAVE_TLS","FLB_HAVE_SQLDB","FLB_HAVE_METRICS","FLB_HAVE_HTTP_SERVER","FLB_HAVE_SYSTEMD","FLB_HAVE_FORK","FLB_HAVE_TIMESPEC_GET","FLB_HAVE_GMTOFF","FLB_HAVE_UNIX_SOCKET","FLB_HAVE_PROXY_GO","FLB_HAVE_SYSTEM_STRPTIME","FLB_HAVE_JEMALLOC","FLB_HAVE_LIBBACKTRACE","FLB_HAVE_REGEX","FLB_HAVE_LUAJIT","FLB_HAVE_C_TLS","FLB_HAVE_ACCEPT4","FLB_HAVE_INOTIFY"]}}
```
But the prometheus endpoint does not 

```
curl  http://192.168.241.112:2020/api/v1/metrics/prometheus -v
* About to connect() to 192.168.241.112 port 2020 (#0)
*   Trying 192.168.241.112...
* Connected to 192.168.241.112 (192.168.241.112) port 2020 (#0)
> GET /api/v1/metrics/prometheus HTTP/1.1
> User-Agent: curl/7.29.0
> Host: 192.168.241.112:2020
> Accept: */*
>
< HTTP/1.1 404 Not Found
< Server: Monkey/1.7.0
< Date: Thu, 16 Jan 2020 11:59:07 GMT
< Transfer-Encoding: chunked
<
* Connection #0 to host 192.168.241.112 left intact
```

set the logging to default but there are no errors:
```
Fluent Bit v1.3.5
Copyright (C) Treasure Data

[2020/01/16 12:26:23] [debug] [storage] [cio stream] new stream registered: tail.0
[2020/01/16 12:26:23] [debug] [storage] [cio stream] new stream registered: tail.1
[2020/01/16 12:26:23] [debug] [storage] [cio stream] new stream registered: tail.2
[2020/01/16 12:26:23] [debug] [storage] [cio stream] new stream registered: tail.3
[2020/01/16 12:26:23] [ info] [storage] initializing...
[2020/01/16 12:26:23] [ info] [storage] in-memory
[2020/01/16 12:26:23] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128
[2020/01/16 12:26:23] [ info] [engine] started (pid=1)
[2020/01/16 12:26:23] [debug] [engine] coroutine stack size: 24576 bytes (24.0K)
[2020/01/16 12:26:23] [debug] [in_tail] inotify watch fd=20
[2020/01/16 12:26:23] [debug] [in_tail] scanning path /var/log/containers/*_ns1_*.log
[2020/01/16 12:26:23] [debug] [in_tail] Cannot read info from: /var/log/containers/*_ns1_*.log
[2020/01/16 12:26:23] [debug] [in_tail] inotify watch fd=26
[2020/01/16 12:26:23] [debug] [in_tail] scanning path /var/log/containers/*_ns2_*.log
[2020/01/16 12:26:23] [debug] [in_tail] Cannot read info from: /var/log/containers/*_ns2_*.log
[2020/01/16 12:26:23] [debug] [in_tail] inotify watch fd=32
[2020/01/16 12:26:23] [debug] [in_tail] scanning path /var/log/containers/*_ns3_*.log
[2020/01/16 12:26:23] [debug] [in_tail] add to scan queue /var/log/containers/rpp-7-r72kw_ns3_rap-c68718b206170c12c1bf76a6ecd336534a39ec90192de00a339f876f7cddd354.log, offset=11141072
[2020/01/16 12:26:23] [debug] [in_tail] inotify watch fd=39
[2020/01/16 12:26:23] [debug] [in_tail] scanning path /var/log/containers/*_orchestrator_*.log
[2020/01/16 12:26:23] [debug] [in_tail] add to scan queue /var/log/containers/api-gw-12-lfk5k_orchestrator_api-gw-54384fc2175d084179bc15684aae6c2ad06ced314969c911cd4978fb2dbdbe2b.log, offset=32675
[2020/01/16 12:26:23] [debug] [upstream_ha] opening file /fluent-bit/etc/..2020_01_16_12_26_16.289066575/upstream.conf
[2020/01/16 12:26:23] [ info] [filter_kube] https=1 host=kubernetes.default.svc port=443
[2020/01/16 12:26:23] [ info] [filter_kube] local POD info OK
[2020/01/16 12:26:23] [ info] [filter_kube] testing connectivity with API server...
[2020/01/16 12:26:23] [debug] [filter_kube] API Server (ns=logging, pod=fluent-bit-srhn7) http_do=0, HTTP Status: 200
[2020/01/16 12:26:23] [ info] [filter_kube] API server connectivity OK
[2020/01/16 12:26:23] [debug] [router] match rule tail.0:forward.0
[2020/01/16 12:26:23] [debug] [router] match rule tail.0:forward.1
[2020/01/16 12:26:23] [debug] [router] match rule tail.1:forward.0
[2020/01/16 12:26:23] [debug] [router] match rule tail.1:forward.1
[2020/01/16 12:26:23] [debug] [router] match rule tail.2:forward.0
[2020/01/16 12:26:23] [debug] [router] match rule tail.2:forward.1
[2020/01/16 12:26:23] [debug] [router] match rule tail.3:forward.0
[2020/01/16 12:26:23] [debug] [router] match rule tail.3:forward.1
[2020/01/16 12:26:23] [ info] [http_server] listen iface=0.0.0.0 tcp_port=2020
[2020/01/16 12:26:23] [ info] [sp] stream processor started
```
Signed-off-by: Atibhi Agrawal <Atibhi.Agrawal@iiitb.org>
Related to issue #1672
This is my log message before parsing:

> {
> "container_id": "14927aae39875c1cbdae3e41e6a25b19968aba3f24f09404e76190ef61670202",
> "container_name": "/ecs-LogisticsLDWtest-Logistics-17-LogisticsLDWtest-Logistics-cef884afc6c2dbe0db01",
> "ec2_instance_id": "i-0a1e58472dc0e9e96",
> "ecs_cluster": "LDWtest-Logistics",
> "ecs_task_arn": "arn:aws:ecs:us-west-2:418338086575:task/5372b32a-0894-464d-9da1-601ba33fe77d",
> "ecs_task_definition": "LogisticsLDWtest-Logistics:5",
> "log": "{"thread":"http-nginx-8080-exec-3","level":"INFO","loggerName":"com.enterprise.cloud.Logistics.api.v1.KafkaConsumerV1","reqMsg":"{\"requestId\" : \"45da14d9-bbb2-4906-988c-9e8aead17f59\", \"message\" : \"Request to list consumer details.\"}","endOfBatch":false,"loggerFqcn":"org.apache.log4j.Category","instant":{"epochSecond":1578674283,"nanoOfSecond":74902000},"contextMap":{},"threadId":23,"threadPriority":5}\r",
> "source": "stdout"
> }

Then with JSON parsing it looks like this if I only use the  **json** parser

> {
> "container_id": "14927aae39875c1cbdae3e41e6a25b19968aba3f24f09404e76190ef61670202",
> "container_name": "/ecs-LogisticsLDWtest-Logistics-17-LogisticsLDWtest-Logistics-cef884afc6c2dbe0db01",
> "contextMap": {},
> "ec2_instance_id": "i-0a1e58472dc0e9e96",
> "ecs_cluster": "LDWtest-Logistics",
> "ecs_task_arn": "arn:aws:ecs:us-west-2:418338086575:task/5372b32a-0894-464d-9da1-601ba33fe77d",
> "ecs_task_definition": "LogisticsLDWtest-Logistics:5",
> "endOfBatch": false,
> "instant": {
> "epochSecond": 1578690446,
> "nanoOfSecond": 571551000
> },
> "level": "INFO",
> "loggerFqcn": "org.apache.log4j.Category",
> "loggerName": "com.enterprise.cloud.Logistics.api.v1.KafkaConsumerV1",
> "reqMsg": "{"requestId" : "45da14d9-bbb2-4906-988c-9e8aead17f59", "message" : "Request to list consumer details."}",
> "source": "stdout",
> "thread": "http-nginx-8080-exec-3",
> "threadId": 23,
> "threadPriority": 5
> }
> 

The reqMsg field is JSON in itself and I am not sure why this is not getting formatted as JSON. Is there a different parser I need to use or a different regex to parse this? Any help is appreciated.


I tried with the following custom-parsers.conf

> [PARSER]
> Name json
> Format json
> Time_Key time
> Time_Format %d/%b/%Y:%H:%M:%S %z
> Decode_Field_As json message
> 
> [PARSER]
> Name docker
> Format json
> Time_Key time
> Time_Format %Y-%m-%dT%H:%M:%S.%L
> Time_Keep On
> Decode_Field_As escaped log
> Decode_Field_As escaped reqMsg

I tried both **json** and **escaped** decoder types here

and the fluent-bit.conf is as below

> [SERVICE]
> Parsers_File /fluent-bit/parsers/custom-parsers.conf
> Flush 1
> Grace 30
> [FILTER]
> Name parser
> Match *
> Key_Name log
> Parser json
> Reserve_Data True
> [FILTER]
> Name parser
> Match *
> Key_Name log
> Parser docker
> Reserve_Data True