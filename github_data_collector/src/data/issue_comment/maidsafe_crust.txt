I note that crust depends on `mio` directly and doesn't use futures, which is a solid choice for a project that started many years ago (when futures in its present form didn't exist, and there were multiple competing async frameworks that were eventually abandoned).

Now that async/await is hitting stable (in 1.39), I was wondering if there were any plans to use it. Benefits would include better integration with other runtimes, leveraging executors with work-stealing threadpools like tokio, and easier to write state machines with async/await.

What do you think?
On stable 1.37 using a trait object without a dyn is a [warning](https://github.com/rust-lang/rust/pull/61203/)

That along with forbidding warnings in the [example](https://github.com/maidsafe/crust/blob/master/examples/secure_p2p_connection.rs#L52) causes the example to currently fail.

A quick fix locally is to either remove that line, or run `cargo fix --all`.

This is an easy fix, run `cargo fix`
Hello,

it would be very useful to provide some minimal usage example to the users of the crate that does not make use of internal structs like PeerId and at least mark examples that are not examples of the API functionality.

Cheers
The docs currently say: "Crust implements several NAT traversal techniques such as hole punching and use of IGD."

Since understanding the nat traversal techniques used is critical to understanding whether or not this package will work in a particular use case, please document all techniques used, ideally also summarizing the cases that are and aren't covered by those techniques. That kind of documentation is critical for understanding the expected behavior of this code.
    pub fn print_connected_nodes(&self, service: &Service) {
        println!("Node count: {}", self.nodes.len());
        for (id, node) in &self.nodes {
            let ip = service.get_peer_ip_addr(node).unwrap();
            let status = if service.is_connected(node) {
                "Connected   "
            } else {
                "Disconnected"
            };

            println!("[{} - {}] {} {:?}", id, ip, status, node);
        }

        println!();
    }

On the examples I've added the following line to obtain a peer IP
    let ip = sesion.get_peer_ip_addr(node).unwrap();

This method gives the IP but I can't find how to obtain the port. 
Is there any method that returns the peer port?

Thanks.

0. At any given time Crust will try and limit the max active connections/sessions to 100 (peers)
0. It will sever a connection if it needs to make another once there are 100 active ones in the pool.
0. Upper layer is not informed about any of these (details only internal to Crust)
0. Connects will happen either on calling `send()` API or indirectly by accepting a connection from peer
0. As usual, we should eventually have only one active connection to a peer if we are deciding to maintain/initiate a connection to it.
0. Currently the state of the socket in sock-coll crate has associated data. When a socket is destroyed (because say the pool wanted a new connection established and an existing connection is severed) the associated data would be lost by both ends when they realise the connection is dropped. This logic should change.
  **a.** Tx side should keep all the full or partial remaining data around to be delivered later. We will simplify this in (c) below
  **b.** Rx should keep all the partial data yet to be reconstructed and given to upper layer around and wait for Tx side to send more stuff in future by connecting to it. It should have a timer to not keep it around for always though ofc. This is a bit complex so we'll try avoiding this via the next point (c) below
  **c.** Since session resumption is going to be a bit complex for TCP we will simplify it to sever a connection for the purposes of dynamic connection preserving only full messages which are not yet written to the socket. Note the ones written are not guaranteed rxd by the peer but we are accepting the message loss at this point. Things could be made better by having Crust ACKs and duplicate detection but we are avoiding complications just now. Now the Rx either buffers data until it can reconstruct it at Crust level or discard it if the connection was dropped _before_ it could re-construct a single Crust message unit.
  **d.** Again, to keep things simple once we reach the limit for max connection and we want to send to a new peer we will simply displace the least recently used peer. It might happen that this peer was in the process of sending us something in which case it might attempt an immediate reconnection and displace someone else from our active pool. We will let this logic be like this for simplicity. This is going to be a problem where more than the active connections limit number of peers had something to send us and we keep severing as we get newer incoming connection (at the same time maybe wanting ourselves to send something) and the ones disconnected immediately attempt to connect back disconnecting yet someone else who attempts to connect and so on slowing things down greatly. Assuming this won't happen we will let the logic be simply to displace someone from the pool if there's a fresh send or an incoming connection.
  **e.** At this point there might be a few displaced connections which had something to send. Each of these will wait for a global tick of 10secs before displacing someone from the active pool. These pending ones should be in a FIFO queue.
0. Send will take a blob which will either help Crust identify which connected peer to send the message to OR will help it make such a connection and then send if not already connected. This will likely be the `PubConnectionInfo` blob.
0. Send will not return success or error. It will try connecting + sending for a max of 120secs after which it will silently fail
0. Apart from the connection blob it'll accept the message itself and the priority as usual.
0. Don't expose a `connect()` API anymore
0. Don't expose a `disconnect()` API anymore
0. Multiple `send()`s to the same peer while in process of establishing a connection should not try establishing more connections - wait for the one connection being established and then try sending all accumulated data to the peer. We say "try" because the connection could be severed before sending all the messages according to the dynamic connections rule (see dyn-conn pool issue)
Rename to `self_connection_info` as we only want `PubConnectionInfo` now from it.
Without HolePunching in Crust for Fleming `PubConnectionInfo` is identical to `PrivConnectionInfo`. Hence remove the latter and refactor all the related tests, examples and API accordingly.
We will no longer be using `CrustUser/CrustRole`. Remove from Crust