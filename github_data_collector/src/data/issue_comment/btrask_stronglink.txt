I tried building this and I got this error

```
[ 93%] Building C object src/CMakeFiles/libcmark_static.dir/houdini_href_e.c.o
[ 95%] Building C object src/CMakeFiles/libcmark_static.dir/houdini_html_e.c.o
[ 96%] Building C object src/CMakeFiles/libcmark_static.dir/houdini_html_u.c.o
[ 98%] Building C object src/CMakeFiles/libcmark_static.dir/cmark_ctype.c.o
[100%] Linking C static library libcmark.a
[100%] Built target libcmark_static
Binaries can be found in build/src
make yajl_s/fast -C ./deps/yajl/build --no-print-directory
make[1]: *** deps/yajl/build: No such file or directory.  Stop.
Makefile:218: recipe for target 'yajl' failed
make: *** [yajl] Error 2
```

Related to #110, we should strive to support all of the different content address formats:
- Our own hash URIs, of course
- [RCF 6920](https://tools.ietf.org/html/rfc6920) (`ni:`)
- Algorithm-prefixed hashes (e.g. as used by [Subresource Integrity](https://www.w3.org/TR/SRI/))

There is no reason we can't resolve these hashes and even generate them in our UI.

Unfortunately, supporting the addresses used by BitTorrent, Camlistore and IPFS (https://github.com/ipfs/go-ipfs/issues/1953) is nearly impossible, because each one generates its own unique hashes, which cannot even always be consistently derived without outside data.

As described in [this](https://bentrask.com/?q=hash://sha256/3a9950ed18cae3cbcdad36338b9f697be3fbcd3a1ba92c9f068e1b140da49ec7) post, our hash URI scheme is ambiguous when supporting multiple hash encodings (for example, hexadecimal and base-64).

Examples from the post:

> hash://sha256/9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08 (current hex format)
> hash://sha256/n4bQgYhMfWWaL-qgxVrQFaO_TxsrC4Is0V1sFbDwCgg (base-64-url, ambiguous)
> hash://sha256/b64-n4bQgYhMfWWaL-qgxVrQFaO_TxsrC4Is0V1sFbDwCgg (base-64 with encoding name prefix)
> hash://sha256/_n4bQgYhMfWWaL-qgxVrQFaO_TxsrC4Is0V1sFbDwCgg (leading underscore for simple disambiguation from hex)
> hash://b64.sha256/n4bQgYhMfWWaL-qgxVrQFaO_TxsrC4Is0V1sFbDwCgg (encoding as algorithm’s “subdomain”)
> hash://sha256.b64/n4bQgYhMfWWaL-qgxVrQFaO_TxsrC4Is0V1sFbDwCgg (encoding as algorithm’s “top level domain”)
> hash://sha256/b64/n4bQgYhMfWWaL-qgxVrQFaO_TxsrC4Is0V1sFbDwCgg (encoding as path component)
> hash://sha256/n4bQgYhMfWWaL-qgxVrQFaO_TxsrC4Is0V1sFbDwCgg?enc=base64 (encoding as query parameter; probably a terrible idea, only included for completeness)

Since then, I've become more fond of the path compoent version (`/b64/`). For hex, we'd probably use `/b16/` (due to unfortunate connotations of the word "hex"...). Unmarked encodings would be treated as hex for backward compatibility, and it would continue to be officially supported.

Unfortunately this labeling makes base-64 encoded URIs slightly longer (by 4 characters). Hash URIs are already the longest of the various content addressing schemes, and this negates some of the advantage of using base-64 in the first place. On the other hand, I think there's value in being very flexible with user input.

Related to #15.

It should be possible (and maybe not even that hard) to implement an [SQLite virtual table](https://sqlite.org/cvstrac/wiki?p=VirtualTables) for StrongLink's database schema. This would be handy for debugging, exploration, and who knows what else.

Related to #12.

Test with something like https://github.com/androm3da/libfaultinj

Probably useful for #106.

See [here](https://bentrask.com/?q=hash://sha256/7c8153cfb8879dbb2c470780f1c9fe1a2adc9e93dfaf28784e61570274dd07f8) for a full overview of plans.

Depends on #7. Also requires various optimizations to meta-files.

StrongLink seems to have some overlapping ideas/uses with CouchDB and PouchDB. The biggest difference is that we also (plan to) support _desynchronization_, AKA partial mirroring, AKA partial replication.

Given our intended use case, I'm not 100% sure CouchDB syncing makes sense, but it seems worth considering at least.

https://github.com/couchbase/couchbase-lite-ios/wiki/Replication-Algorithm

Google Query Language, supported by CouchDB.

https://github.com/pouchdb/pouchdb/wiki/Google-Query-Language-Documentation

Our `alogf` log function prefixes logged messages with a timestamp, which is very useful. Unfortunately, that requires two printf statements, which we don't want to get split up by concurrent writes. Right now we're using `flockfile(3)` which makes logging even slower than usual.

Possible approaches:
- Do all logging on a single thread
- Use `fputs_unlocked(3)` to write without locking
- Use `write(2)` (or libuv's equivalent) to write without locking

Not sure what the best (simplest/fastest) solution is.

Performance does in fact matter for traffic logging.
