Very happy new year from the easysteam team to the easyteam and the easystats users üéâ May this year be the wisdom year for us, with a perfecting and stabilising ecosystem. I wish us more awesome features and more outreach (blogposts, publications, tweets and word of mouth) so that more users are pulled from the dark side, where they are chained by their fear of stats and R, and brought to the light side of best practices and honest science. We will need all our and your help to defeat the challenges to come...

*Palpatine's maniacal laugh resonates*   

Looking forward to the future ‚ò∫Ô∏è 

@strengejacke @pdwaggoner @mattansb @IndrajeetPatil @humanfactors @jacob-long @lindeloev


Dear easystats friends
I'm planning some releases in January:

- insight
- parameters
- see (after implementing `plot.si()`

I think that all relevant issues are addressed and features implemented, or do you have any suggestions?

@DominiqueMakowski @mattansb @IndrajeetPatil 
Two of our packages that are on CRAN are already in task views (effectsize, parameters). We may think of recommending "bayestestR" for the Bayes task view as well?
@strengejacke @DominiqueMakowski Let's open this up here officially.

I think this paper can be quite short, really. Here I am pre-regestering my hypotheses:
1. For posterior-based indices (which is all but the BFs), the degree by which they are affected by priors looks like this:
![image](https://user-images.githubusercontent.com/35330040/68740383-9c8e8880-05f3-11ea-9f84-bad75ca21537.png)
That is, weak-to-flat priors have close to no effect on the indices, but as the priors grow more narrow, the indices become reflections of the prior, rather than the data (or a mix of the prior and the data). This is the reverse Jeffreys-Lindley-Bartlett paradox.

2. For BFs, we will get:
    1. the classic Jeffreys-Lindley-Bartlett "paradox", where more-flat priors result in BFs supporting the null
    2. The more the priors do not match the data (e.g., prior centered around -1, but data is centered around +2), the stronger BF will support the null.

When can then talk about why it is dangerous to treat the posterior based indices as "objective", and why BFs should only be used when researchers have informative (weak or strong) priors they want to *test*. That is, posterior indices are descriptive of the posterior (= prior + data, and **not** the data alone), while BFs are not descriptive of the data / posterior, they are indicative of the match between data + prior.

Where we might run into trouble is with reviewers asking we suggest priors - so we should emphasis that our focus is not on correct prior selection, but on correct inference using Bayesian indices.

---
As for who should take the helm on this paper... My plan is to leave academia post PhD (but of course I will be an r-developer 4EVA!), so first-authored papers will serve you two better than they will serve me. So this is up to you guys üòÅ
Number of functions associated with PCA/FA and cluster analysis is increasing in [parameters](https://easystats.github.io/parameters/reference/index.html#section-data-reduction-cluster-analysis), so I thought if it would make sense (in the near or far future) to move these into an own package?
This is sort of a question, but I do think any answers would be well placed in a wiki or some form of contribution guidelines documentation. In short, I'm actually not sure the best way to set setup `easystats` in a development environment. There's really two parts to this:

[‚úî - **Not issue for me**] Firstly, should a new user want to help contribute, my understanding is that they would need to first install all easystats packages on the dev branch

```
install_easystats_dev <- function(){
  devtools::install_github(c("easystats/insight",
                             "easystats/bayestestR",
                             "easystats/performance",
                             "easystats/parameters",
                             "easystats/effectsize",
                             "easystats/correlation",
                             "easystats/estimate",
                             "easystats/see",
                             "easystats/report"),
                           ref = "dev",
                           upgrade = "never")
}
```
This isn't documented on the main page, and while it's certainly not a big issue, the instructions in the `README.md` imply to me that you'd first ` devtools::install_github("easystats/easystats")`  and then call `install_easystats_dev`, but this seems excessive of course. I actually should note that I have had a few troubles installing with `install_easystats_dev` when I've already had dev packages installed, but I haven't really had time to debug

[‚ùì **My confusion**] For packages that I contribute too, or modify, I obviously have my own fork of the package. I then develop a branch on this, and make sure I am regularly updating the other packages to the dev branch. To be honest, this actually works fine, but it does make it hard to scale up to keeping track of developing multiple packages in this expanding and quite large ecosystem.

I'm guessing there's an alternative in which I can fork and then clone every single easystats package, but this is of course completely overkill and unmaintainable for my brain. I imagine this is what you have setup @DominiqueMakowski? ü§Ø

One issue here is in debugging problems users that users report on the master branches, or for creating an isolated environment for developing a package (and not ruining my existing install of easystats ‚Äî e.g., development of insight). I've been thinking about setting up an [renv](https://github.com/rstudio/renv), but given the cross dependencies, but I'm not sure if this is overkill again, and I'm sure there's a better solution. üò´

--------------------------------------------------

TL;DR: How do you set up your easystats development environment? How isolate production from development? I think whatever answers emerge here would be worth documenting a best practice to help contributors come up to speed.

_I landed at this because tonight I landed at a bug in report which effectively was caused by an older development version of parameters, and I just reinstalled everything from scratch._

Best all üòä
I'm just putting this there, but it would be super cool to have some money to 1) organize some kind of workshop to gather ourselves and spread the news and 2) to be able to decently pay some intern or student to contribute (there are many areas that could be easily improved in the context of a training, such as documentation, testing etc.) and 3) get filthy rich of course

If you hear of any grant call to which we could apply do let it know ‚ò∫Ô∏è 
Currently, for most of check_* the print is within the function. I.e., the printing occurs during function run rather than output printing (as there is no specific class nor printing methods for check_* objects).

For some check_* this is a limitation as the function might return stuff, or be possibly connected to a plot method. 

Thus I think we might want to create a generic "easystats_check" class, and all check_ functions would return a list containing at least a "text" and a "color" object. Then we could add a print method (in insight?) that would print the text with the right colour. This would make thing more flexible.

(an example implementation was added for [check_clusterstructure](https://github.com/easystats/parameters/pull/134))
Is there any particular reason why we are not checking package builds on Windows CI services like `AppVeyor`?

Currently, we only have `Travis` builds for `linux` and `macOS`, but it will be good to have the same for Windows platform. 

If you agree, I can set up `yaml` files for repos.
I was ~admiring~ looking at the [functions list](https://github.com/easystats/easystats#list-of-functions) and I thought, it would be funny to do some clustering/network analysis as they do with texts to visualise (and summarise) the different types and groups of functions... Unfortunately, I have no idea how to do that üòÖ 