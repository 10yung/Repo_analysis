I am trying to calibrate a tof camera（TI TINTIN)


the problem is that for every dataset  I always receive the error
[FATAL] [1572255263.563560]: No corners could be extracted for ...

the image below.
![1579229142506541000](https://user-images.githubusercontent.com/5019568/72592699-14ec2f80-393e-11ea-99d1-63c5b32c2f34.png)





Hi
I am trying to generate a Depth image using a RGB camera and a point cloud from 3D-depth sensor camera. In this case, it is quite essential to have correct extrinsic information between two cameras to register/overlay the data from both cameras accurately. I am using Kalibr multi-camera calibration tool to generate that extrinsic information where I feed gray scale image from RGB camera and IR images from from 3D-depth sensor. However, I see that Kalibr also generates the intrinsic information for all the cameras and I assume that it might be using this information to generate the extrinsic transformation between them. In my case, I already have the intrinsic information for both of these sensors which are factory calibrated and hence accurate. I wanted to know if there is any way where we can give the intrinsic value to the Kalibr multi-camera calibration tool as an input, so that it can use that information to compute the extrinsic between the camera?

Secondly, the IR images from the 3D-depth sensor are 224x172 in resolution and RGB camera has 640 x 480 resolution. Would the difference in resolution affect the accuracy of the result from multi-camera calibration tool? Also what should be a good re-projection error for cameras with such resolution?   
I notice that the number of threads is set according to cpu core [here](https://github.com/ethz-asl/kalibr/blob/14e47ea0edb7a42efa03533855e533f9e6ad7bb8/aslam_offline_calibration/kalibr/python/kalibr_imu_camera_calibration/IccCalibrator.py#L158), however when I really calibrate camera-imu, only one thread is been used as I make sure that with system monitor.
Hi，recently I have been reading the codes of `kalibr_calibrate_imu_camera`. When I read `addCameraChainErrorTerms()`, which the function is to add the reprojection error terms for all cameras, in the `IccSensors.py`, I have felt uncertainty. Here are the  codes 
```
    #add the reprojection error terms for all cameras in the chain
    def addCameraChainErrorTerms(self, problem, poseSplineDv, blakeZissermanDf=-1, timeOffsetPadding=0.0):
        
        #add the induviduak error terms for all cameras
        for camNr, cam in enumerate(self.camList):
            #add error terms for the first chain element
            if camNr == 0:
                #initialize the chain with first camerea ( imu to cam0)
                T_chain = cam.T_c_b_Dv.toExpression()
            else:
                T_chain = cam.T_c_b_Dv.toExpression() * T_chain
            
            #from imu coords to camerea N coords (as DVs)
            T_cN_b = T_chain
            
            #add the error terms
            cam.addCameraErrorTerms( problem, poseSplineDv, T_cN_b, blakeZissermanDf, timeOffsetPadding )
```
I have a question about T_cN_b. In its notes, T_cN_b is from imu coordinate systems (b) to the N-th camera coordinate systems(cN). There, we assume only two cameras and one imu. When the camera number is 0 (the first camera), `T_chain = T_c1_b`. Then, the camNr = 1 and `T_c2_b = T_c2_b * T_chain`, where T_chain is T_c1_b. 
I have no idea about the equation `T_chain = cam.T_c_b_Dv.toExpression() * T_chain`. In my case above, the matrix T from imu to second camera is equal to T_c2_b * T_c1_b? In my opinion. the T_c2_b should be _T_c2_c1? Thank you!
Mostly involves adding in boost and eigen includes to the various CMakeLists.txt. Perhaps there is a better way to do this using catkin_simple. It still builds fine in Ubuntu 16.04.

![eyeCamera-00L](https://user-images.githubusercontent.com/20368577/71439856-1a3acd80-2736-11ea-9a30-aec0f457374a.jpg)
![eyeCamera-00R](https://user-images.githubusercontent.com/20368577/71439858-1ad36400-2736-11ea-8ddd-15152643b88a.jpg)
I try to use Kalibr to calibrate two pointgrey Camera. These images almost have no distortion. The distance of two cameras is x=6.4~6.7cm , Y= Close to 0, Z= Close to 0. but the result is wrong.
 Cam resolution: [1920, 1200], Cam model : pinhole-fov
I dont know what problem cause the result wrong?
  
i had attached my result below,baseline my camera 60mm its give correctly but compare with imu distance between cam0 to imu is 15mm and imu to camera1 is 45 but kalibr result are incorrect. any idea for this results???     
Transformation (cam0):
-----------------------
T_ci:  (imu0 to cam0): 
[[-0.09063329  0.99570995  0.01863606  0.0004547 ]
 [-0.99546944 -0.09003956 -0.03055279  0.00031908]
 [-0.02874373 -0.02132073  0.99935941  0.00004048]
 [ 0.          0.          0.          1.        ]]

T_ic:  (cam0 to imu0): 
[[-0.09063329 -0.99546944 -0.02874373  0.00036001]
 [ 0.99570995 -0.09003956 -0.02132073 -0.00042316]
 [ 0.01863606 -0.03055279  0.99935941 -0.00003918]
 [ 0.          0.          0.          1.        ]]

timeshift cam0 to imu0: [s] (t_imu = t_cam + shift)
0.00495656047192


Transformation (cam1):
-----------------------
T_ci:  (imu0 to cam1): 
[[-0.09016874  0.99573806  0.01937282 -0.05960656]
 [-0.99562357 -0.08964452 -0.02641142  0.00019255]
 [-0.02456219 -0.02166952  0.99946342  0.00035414]
 [ 0.          0.          0.          1.        ]]

T_ic:  (cam1 to imu0): 
[[-0.09016874 -0.99562357 -0.02456219 -0.00517424]
 [ 0.99573806 -0.08964452 -0.02166952  0.05937746]
 [ 0.01937282 -0.02641142  0.99946342  0.00080589]
 [ 0.          0.          0.          1.        ]]

timeshift cam1 to imu0: [s] (t_imu = t_cam + shift)
0.00480246314822

Baselines:
----------
Baseline (cam0 to cam1): 
[[ 0.99999962 -0.00048748  0.00072233 -0.06006114]
 [ 0.00048449  0.99999133  0.00413473 -0.00012691]
 [-0.00072434 -0.00413438  0.99999119  0.00031531]
 [ 0.          0.          0.          1.        ]]
baseline norm:  0.0600621048591 [m]


Gravity vector in target coords: [m/s^2]
[-0.07590761  0.09258016 -9.80581918]

In the file BSplinePose.cpp, there is a word: The "box times" is the linearized transformation way of inverting the jacobian. But I don't know how to get this conclusion. Could anyone show me which paper refer to?
Hello, after I used kalibr_calibrate_imu_camera with scale-misalignment option, I got following result.
imu0:
  T_i_b:
  - [1.0, 0.0, 0.0, 0.0]
  - [0.0, 1.0, 0.0, 0.0]
  - [0.0, 0.0, 1.0, 0.0]
  - [0.0, 0.0, 0.0, 1.0]
  accelerometer_noise_density: 0.00668
  accelerometer_random_walk: 0.000917
  accelerometers:
    M:
    - [1.0075384850085152, 0.0, 0.0]
    - [0.017205839485902097, 1.0961938612921196, 0.0]
    - [-0.07519411884856604, 0.11078387285861767, 1.0208877441714266]
  gyroscope_noise_density: 0.00203
  gyroscope_random_walk: 0.000271
  gyroscopes:
    A:
    - [0.00033628818679622813, 0.00033989727403612715, 0.0023460575365993577]
    - [-0.00021309674291592032, -0.00026022043328967305, -0.0003105405149146512]
    - [-2.070095610881228e-06, 0.0003658263740224834, 0.0015392312208048244]
    C_gyro_i:
    - [0.997225320211812, -0.07420530203968216, 0.005935813141207369]
    - [0.07418323837859316, 0.9972371766621109, 0.003854948332391877]
    - [-0.006205471143484005, -0.00340391424394451, 0.9999749524341627]
    M:
    - [0.40473723961271335, 0.0, 0.0]
    - [0.0012193641786323738, 0.46467919471887387, 0.0]
    - [0.007563932319210696, -0.005224639240317598, 0.5023767098998477]
  model: scale-misalignment
  rostopic: /taraxl/imu/data_raw
  time_offset: 0.0
  update_rate: 26.0
And i had use this formal c=M*(R-B) to convert the raw to correct data. 
m=missaliment data ,R=raw data from camera(uncalibrated data) ,B= random_walk 
i got work result like (0.0045,11.4598,0.0087) instants  of (0.000,9.887,0.799).
its this right way to calculate the results ,or use any other formulas are avalible ??? 
