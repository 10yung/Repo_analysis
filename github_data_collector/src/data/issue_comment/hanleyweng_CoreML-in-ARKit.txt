I realised that using the continuous vision request creates a leak when the arviewcontroller is dismissed, it stays in the heap. 
Is it possible to get depth (z position) of the detected object without user tap ? 
Hi, how could I get the percentage of confidence or accuracy of the prediction?

Thanks
I cleaned up the code a bit. Large method in ViewController.swift has been split into few smaller ones. I also replaced flatMap method call with compactMap according to Swift 4.1 changes.
Prior to this commit, the "debug" text field was partially obscured by the rounded corner and notch of the iPhone X. This commit constraints the text field with the safe area instead of the whole view to make it clearly visible on all devices. 
Hi @hanleyweng 
I'm doing a same thing as your project and I'm dealing with a big performance problem when running with a bigger coreml model 200mb. Whenever the coreml perform its request the arkit camera previewer get a flick. It seems like the coreml performing is blocked the rendering for a few milliseconds. I tried to run the bigger model on your project as well and there was.the same issues ! do you have any idea ? 