Hello.
I'm newbie in grpc. I have some problems with gogoprotobuf.
After using command `protoc --gogo_out=. *.proto` I have this errors
![Screenshot from 2020-01-16 18-13-36](https://user-images.githubusercontent.com/26696198/72536895-3096fd80-388c-11ea-9bd8-018613ba4041.png)
I tried change Makefile and write path to gogoprotobuf, but it didn't help me. 
I will be very grateful if someone can help me. 
Sorry for my english
[protoc-gen-gogo/descriptor/descriptor.pb.go](https://github.com/gogo/protobuf/blob/master/protoc-gen-gogo/descriptor/descriptor.pb.go)  does not contain generated ProtoSize(), Marshal(), or Unmarshal() funcs.

This means that, if you generate code for some application message type that includes (e.g.) a DescriptorProto field and which has protosizer, marshaler, or unmarshaler enabled, then that generated code will not compile.

Worse, the problem is recursive: you can disable these plugins on the application message type, but then you also have to disable the plugins for any messages that *use* that message type as well.
Add a new extension "casttypewith" that could be used to define and use fields
of an non-local type, by using a custom caster type.

The caster should implement:
func (c *Caster) Equal(a, b *Castee) bool
func (c *Caster) Size(a *Castee) int
func (c *Caster) MarshalTo(a *Castee, buf []byte) (int, error)
func (c *Caster) Unmarshal(buf []byte) (*Castee, error)
func (c *Caster) NewPopulated() *Castee

The protobuf field type should be "bytes"
The feature is usable only with marshal and unmarshal plugins
and features like JSONPB and text marshaling is are incompatible.
The `castrepeated` extension changes the generated field type of a `repeated` field and expects that the whole array generated by a `repeated` field is castable to this type.

Example from the tests:
```
message CastRepeated {
	repeated ProtoType Field1 = 1 [(gogoproto.castrepeated) = "ProtoTypesPointer"];
}
```

```go
type ProtoTypesPointer []*ProtoType

// generated struct
type CastRepeated struct {
	Field1               ProtoTypesPointer `protobuf:"bytes,1,rep,name=Field1,castrepeated=ProtoTypesPointer" json:"Field1,omitempty"`
}

```
This adds support for using `customtype` with `string` fields along with corresponding test messages in `thetest.proto`.

Currently `customtype` supports `bytes` and `message` types. Strings have the same wire encoding and thus it seems logical to include support for them as well.

The immediate use case is for encoding big integers and decimals where the safest cross platform wire encoding is a string, for https://github.com/cosmos/cosmos-sdk.
`gogo/protobuf/types`.Timestamp is generated by `protoc-gen-gogo` and  imports `gogo/protobuf/proto`.

To avoid cycling import, gogo/protobuf implement a fake `timestamp` .

https://github.com/gogo/protobuf/blob/5628607bb4c51c3157aacc3a50f0ab707582b805/proto/timestamp_gogo.go#L38-L46

And it does not implement `newMarshaler` or `Marshaler` interface, which will cause the `Marshal` use the slowest path.

https://github.com/gogo/protobuf/blob/5628607bb4c51c3157aacc3a50f0ab707582b805/proto/table_marshal.go#L2951-L2954

Then the global marshal info lock will be performance bottleneck.

https://github.com/gogo/protobuf/blob/5628607bb4c51c3157aacc3a50f0ab707582b805/proto/table_marshal.go#L107-L116

![image](https://user-images.githubusercontent.com/9161438/72066680-2e78f000-331c-11ea-9402-58183014d4d6.png)

A simple workaround fix is https://github.com/gogo/protobuf/pull/655

A better solution is use a real Timestamp instead of a fake timestamp.

To avoid cycling import, we can import golang/protobuf and use Timestamp generated by golang protobuf.

```go

import ptimestamp "github.com/golang/protobuf/ptypes/timestamp"

type timestamp = ptimestamp.Timestamp

```

Then the performance will be highly improved.


This PR is also submitted to https://github.com/golang/protobuf/pull/1004

This is a workaround to #656

Signed-off-by: TennyZhuang <zty0826@gmail.com>

Thie PR Use `RWMutex` to optimize `getMarshalInfo` and `getUnmarshalInfo`, for these functions, only n (number of message type) will hit Write, and m(number of message) - n will hit Read, it's the best case to use RWMutex instead of Mutex.

This optimization introduce huge improvement in our scenario.

We have 1000 worker and 1 controller, and work and controller keep heartbeat with gRPC. They also exchange the job info with each other.

The message is like

```proto
message Job {
    uint64 job_id = 1;
    // Some other info
}

message Heartbeat {
    repeated Job jobs = 1;
}
```

About 10000 jobs in every Heartbeat, and the heartbeat QPS in controller is about 1000.

The controller handle the Heartbeat in about 10ms, and the network latency is about 10ms, but the client will use about 30s in maximum to finish a RPC call.

We use golang pprof block profile, and it seems that almost all block is caused by one global Mutex in protobuf package.

![image](https://user-images.githubusercontent.com/9161438/71443720-9c7fbd80-2747-11ea-9a35-1e6806984275.png)

After optimization, in our use case, the rpc call from client will only use about 30ms, as our expected.

**What version of protobuf and what language are you using?**
```
libprotoc 3.3.0
go version go1.13 darwin/amd64
```

**What did you do?**
```
package main

import (
	"fmt"
	"github.com/gogo/protobuf/proto"
	"github.com/sky-cloud-tec/proto/v1/eventti"
)

func main() {
	foo := &eventti.EmailServerCfg{
		Account:  "test@test.net",
		Password: "tes",
		Host:     "localhost",
		Port:     554,
		Protocol: eventti.EmailProtocol_SMTP,
	}

	req := &eventti.CreateNotificationChannelReq{
		Name:   "test",
		Etypes: []eventti.EventType{eventti.EventType_DEVICE_CONFIG_UPDATED},
		Type:   eventti.NotificationChannelType_EMAIL,
		Cfg:    &eventti.CreateNotificationChannelReq_EmailServerCfg{EmailServerCfg: foo},
		Target: nil,
	}

	fmt.Println(req.String())

	proto.Marshal(req)

}

```

**What did you expect to see?**
exit properly
**What did you see instead?**
```
name:"test" etypes:DEVICE_CONFIG_UPDATED type:EMAIL email_server_cfg:<account:"songtianyi@sky-cloud.net" password:"tes" host:"localhost" port:554 protocol:SMTP >
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x11134a9]

goroutine 1 [running]:
github.com/gogo/protobuf/proto.makeOneOfMarshaler.func1(0xc00004c108, 0x0, 0x3)
	/Users/work/go/pkg/mod/github.com/gogo/protobuf@v1.3.1/proto/table_marshal.go:2598 +0x129
github.com/gogo/protobuf/proto.(*marshalInfo).size(0xc0000c2000, 0xc00004c0c0, 0xc00000c0e0)
	/Users/work/go/pkg/mod/github.com/gogo/protobuf@v1.3.1/proto/table_marshal.go:200 +0x9d
github.com/gogo/protobuf/proto.(*InternalMessageInfo).Size(0xc00000c0e0, 0x120d2c0, 0xc00004c0c0, 0x0)
	/Users/work/go/pkg/mod/github.com/gogo/protobuf@v1.3.1/proto/table_marshal.go:131 +0x66
github.com/gogo/protobuf/proto.Marshal(0x120d2c0, 0xc00004c0c0, 0xc0000b1f40, 0x1, 0x1, 0xa3, 0x0)
	/Users/work/go/pkg/mod/github.com/gogo/protobuf@v1.3.1/proto/table_marshal.go:2952 +0xfe
main.main()
	/Users/work/trash/create_notification_req.go:28 +0x22e
```
**Anything else we should know about your project / environment?**

Got a grpc handler:
```
func (h *hello) Echo(ctx context.Context, req *pb.Payload) (*pb.Payload, error) {
	var res *pb.Payload    // <<<< typed nil or can be not typed
	return res, nil
}
```

With default grpc-library there is no panic, *protobuf 1.3.2* returns to a client an error:
```
	ErrNil = errors.New("proto: Marshal called with nil")
```

But with gogofaster grpc server crashes with a panic:
```
[signal SIGSEGV: segmentation violation code=0x1 addr=0x8 pc=0x14964a6]

goroutine 51 [running]:
github.com/myorg/hello/example/pb.(*Payload).MarshalToSizedBuffer(0x0, 0x1ab1d58, 0x0, 0x0, 0x100bd73, 0x15879e0, 0x15fca60)
        /Users/un0/go/src/github.com/myorg/hello/example/pb/hello.pb.go:192 +0x26
github.com/myorg/hello/example/pb.(*Payload).Marshal(0x0, 0x15fca60, 0x0, 0x4a000a0, 0x0, 0x15fca01)
        /Users/un0/go/src/github.com/myorg/hello/example/pb/hello.pb.go:175 +0xc3
google.golang.org/grpc/encoding/proto.codec.Marshal(0x15fca60, 0x0, 0xc000211070, 0x0, 0x100a9bb, 0xc000012000, 0x158b820)
        /Users/un0/go/pkg/mod/google.golang.org/grpc@v1.24.0/encoding/proto/proto.go:70 +0x194
google.golang.org/grpc.encode(0x4a00028, 0x1ab1d58, 0x15fca60, 0x0, 0x1ab1d58, 0x100a9bb, 0xc000012000, 0x1587f60, 0x1573ca0)
        /Users/un0/go/pkg/mod/google.golang.org/grpc@v1.24.0/rpc_util.go:543 +0x52
google.golang.org/grpc.(*Server).sendResponse(0xc0000eac60, 0x16f6840, 0xc000001e00, 0xc0001ba100, 0x15fca60, 0x0, 0x0, 0x0, 0xc0001a807c, 0x0, ...)
        /Users/un0/go/pkg/mod/google.golang.org/grpc@v1.24.0/server.go:833 +0x89
google.golang.org/grpc.(*Server).processUnaryRPC(0xc0000eac60, 0x16f6840, 0xc000001e00, 0xc0001ba100, 0xc00008fb90, 0x1a85230, 0x0, 0x0, 0x0)
        /Users/un0/go/pkg/mod/google.golang.org/grpc@v1.24.0/server.go:1030 +0x551
google.golang.org/grpc.(*Server).handleStream(0xc0000eac60, 0x16f6840, 0xc000001e00, 0xc0001ba100, 0x0)
        /Users/un0/go/pkg/mod/google.golang.org/grpc@v1.24.0/server.go:1275 +0xd97
google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc00002a5c0, 0xc0000eac60, 0x16f6840, 0xc000001e00, 0xc0001ba100)
        /Users/un0/go/pkg/mod/google.golang.org/grpc@v1.24.0/server.go:710 +0xbb
created by google.golang.org/grpc.(*Server).serveStreams.func1
        /Users/un0/go/pkg/mod/google.golang.org/grpc@v1.24.0/server.go:708 +0xa1

```


Generated code:
```
func (m *Payload) MarshalToSizedBuffer(dAtA []byte) (int, error) {
        // if m == nil { return nil, ErrNil }

	i := len(dAtA)    // if len(dAtA) == 0 we must exit with an error, .Size method makes nil check
	_ = i
	var l int
	_ = l

	if m.Number != 0 {      // <<<< nil-pointer panic  m
```

There should be the check for a backward compatibility.
The entire application must not to be crashed in the runtime, it must return an error.
The right logic was described here https://github.com/grpc/grpc-go/issues/532#issuecomment-268056152

References https://github.com/gogo/protobuf/pull/451#issuecomment-416857142

- added tendermint to the users list

Signed-off-by: Marko Baricevic <marbar3778@yahoo.com>