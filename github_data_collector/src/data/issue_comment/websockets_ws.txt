Follow the specification and close the connection when a non masked
frame is received on the server or a masked frame is received on the
client.

Refs: https://tools.ietf.org/html/rfc6455#section-5.1

Closes #1679
Recent versions of Node have added getters for some of the internal stream
properties and throws this state away when the stream is being ended. This
commit adds a polyfill for the internal properties that are now exposed
through getters, and checks for availability of properties that do not have
a corresponding getter before using them.
Is this module by default RFC 6455 compliant? Or must we do for example the utf-8 and safe buffer checking manually?

I was reading this section: https://github.com/websockets/ws#opt-in-for-performance-and-spec-compliance

So I'm guessing manual checking those two things. But are there any other things in the RFC 6455 yous are aware of that ws doesn't do out-of-the-box (that's if ws isn't RFC 6455 compliant ws out-of-the-box)?
Handle the breaking change introduced by https://github.com/nodejs/node/pull/29197.
Replace Travis with GitHub Actions.
Now that node core has added websocket support over http2 https://github.com/nodejs/node/pull/23284, It's nice to know when it will be added to WS?
I've read and followed the zlib "memory fragmentation" issue down to where people blaming the Linux kernel and glibc and whatnot.

My two cents:

* There is nothing wrong with the Linux kernel
* There is nothing wrong with glibc
* There is nothing wrong with Node.js

The issue is with websockets/ws.

Doing CPU-bound tasks "async" is nothing more than a delusion - there is no such thing as an async CPU-bound task. If it takes 1 second of CPU-time, it takes 1 second of CPU time no matter when you perform it. Passing a CPU bound task to some thread pool doesn't improve anything in fact it only adds more overhead:

* Threading overhead
* You need to copy the data one extra time (major overhead!)
* You're basically just procrastinating what you need to do right now.

If you cannot keep up with what you buffer up, you're obviously going to blow the process up from too much memory usage since you produce more than you consume.

You have two solutions:

1. Replace all zlib calls with sync calls and all problems go away and you will lower latencies and actually do work you need to do and not just fool yourself you're doing things "in the background".

OR if you _really_ want to try and use multithreading here (which goes against how Node.js is built and deployed):

2. Only buffer up NUMBER_OF_LOGICAL_CPU_CORES with the async version and after this do sync calls until the buffer contains less than NUMBER_OF_LOGICAL_CPU_CORES tasks. Aka - you NEED to block sometime because CPU work cannot be "async" like networking. This solution is more complex and goes against what Node.js is but you get to choose.
Is there any decent way to support safari's `x-webkit-deflate-frame` extension name for `permessage-deflate`?

AFAICT this is more or less an alias for permessage-deflate and I've just managed to get something working by rewriting incoming headers from `Sec-WebSocket-Extensions: x-webkit-deflate-frame` to `Sec-WebSocket-Extension: permessage-deflate; client_max_window_bits` and then rewriting associated outbound headers from `Sec-WebSocket-Extensions: permessage-deflate; server_no_context_takeover; client_no_context_takeover` to `Sec-WebSocket-Extensions: x-webkit-deflate-frame; no_context_takeover` which seems to work in fairly limited testing but is very awkward to do properly.

I've done this using a horrible combination of `httpServer.on('upgrade'`, `verifyClient` and `socket.on('headers'` to rewrite inbound and outbound headers but if there was any concurrency at all I'm pretty sure what I've done will fail and rewrite outbound headers on the wrong response.

Of course ideally safari would send the right extension name but even if they were to fix that it'll take a while before one could rely on it.
You have a `.close(code, data)` method here:
https://github.com/websockets/ws/blob/master/lib/WebSocket.js#L100

But you don't expose the callback here:
https://github.com/websockets/ws/blob/master/lib/WebSocket.js#L121

The `bufferedAmount` property doesn't work correctly.

This code:

``` js
var WebSocket = require('ws')

var socket = new WebSocket('wss://echo.websocket.org')

socket.onopen = function () {
  socket.send('abc')
  console.log('bufferedAmount after send: ' + socket.bufferedAmount)
}

socket.onmessage = function () {
  console.log('bufferedAmount after onmessage: ' + socket.bufferedAmount)
}

setInterval(function () {
  console.log('bufferedAmount on interval: ' + socket.bufferedAmount)
}, 1000)
```

Prints:

```
bufferedAmount after send: 10
bufferedAmount after onmessage: 1
bufferedAmount on interval: 1
bufferedAmount on interval: 1
bufferedAmount on interval: 1
bufferedAmount on interval: 1
bufferedAmount on interval: 1
bufferedAmount on interval: 1
bufferedAmount on interval: 1
...
```

In Chrome and Firefox, on the other hand, this is what gets output:

```
bufferedAmount after send: 3
bufferedAmount after onmessage: 0
bufferedAmount on interval: 0
bufferedAmount on interval: 0
bufferedAmount on interval: 0
bufferedAmount on interval: 0
bufferedAmount on interval: 0
bufferedAmount on interval: 0
...
```

Without a functioning `bufferedAmount` property, it's not possible to use the code I've written to implement backpressure in the browser on the server as well.

cc @mafintosh @maxogden
