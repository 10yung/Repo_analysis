I use function `addPixelBufferSource` to add a watermark image, but sometimes I have to update this watermark image. It means that I have to remove the old one and add a new one. To remove the old watermark image, I have added a new function in at `VCSimpleSession.mm`
```
-(void) removePixelBufferSource {
    m_videoMixer->unregisterSource(m_pixelBufferSource);
}
```
It does work.
However, sometimes it crash at `GLESVideoMixer.h`
<img width="980" alt="2017-06-06 16 31 51" src="https://cloud.githubusercontent.com/assets/16792577/26821030/9517a796-4ad7-11e7-91d9-7600d0bc79b2.png">
Is it means that the "texture" is a wild pointer? I can not fix this problem even thought I have  spent half of month, and I hope someone warm-hearted to help me.
'videocore/mixers/Apple/AudioMixer.h' file not found

After I pod install 

Always compile failure in this issue,

I already add ""${PODS_ROOT}/VideoCore" in Header Search Paths

thanks ~~
*** Fetching VideoCore
*** Checking out VideoCore at "0.3.2"
*** xcodebuild output can be found in /var/folders/v_/1s5t84c90j19sxtpqxx709zr0000gn/T/carthage-xcodebuild.yAbTGB.log
*** Skipped building VideoCore due to the error:
Dependency "VideoCore" has no shared framework schemes for any of the platforms: iOS

How can i add VideoCore using carthage or i have to go through pod?

When i add framrwork using pods and  i got below error when install boost and all other framework are installed well
Please see attached Screen shot.

![videocore](https://cloud.githubusercontent.com/assets/8135458/24800886/9da54068-1bbf-11e7-87f0-0b9affa5499c.png)

![image](https://cloud.githubusercontent.com/assets/183958/23740424/c2eb9b98-04a3-11e7-9f02-ba0c3220a7cf.png)

anyone else experiencing this issue? It worked fine under iOS 9, but after upgrading to iOS 10 I get the black area in the upper half of the screen...
I am unable to downgrade to 0.38.2 of the pod.can anyone help me
Hi @jgh- ,

The sample works perfectly, However i want HLS to be used rather than RTMP. How can i change this to HLS? Can you point out the functions that i can modify to add HLS support?

Thank you. Looking forward to your reply asap!
Hi @jgh- , I know the open source doc has been a long while here, And the sample works perfectly. However, I can't find a way to change the source from iPhone Camera to other source.

What can I change the source input for streaming? Are there a function changing the source ?

Thank you. Looking forward to your reply asap!
Hello,

Greetings of the day!!

We are the team of developers who want to implement Live Broadcast feature in one of our ongoing iOS project. Now to provide live streaming of that broadcast on Youtube/Facebook, we're using your code. when we apply this code in our project this is giving following errors:-

Undefined symbols for architecture x86_64:
  "_OBJC_CLASS_$_VCSimpleSession", referenced from:
      objc-class-ref in VideoUploadViewController.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)

Code which we've applied:-

    contentView=[[UIView alloc] init];
    [self.view addSubview:contentView];
    contentView.frame=self.view.frame;
    
//    _session=[VCSimpleSession new];
    _session=[[VCSimpleSession alloc] initWithVideoSize:CGSizeMake(1920, 1080) frameRate:30 bitrate:4000000 useInterfaceOrientation:NO];

//    _session=[_session initWithVideoSize:CGSizeMake(1920, 1080) frameRate:30 bitrate:4000000 useInterfaceOrientation:NO];
    [contentView addSubview:_session.previewView];

    _session.previewView.frame = contentView.bounds;
    _session.delegate = self;


Awaiting your response.

Thanks in advance.
Ramprakash
when i start new video broadcasting init some noise for 0.5 second. it appear in every new broadcasting.
We were having a problem with xcode throwing errors when trying to build due to file missing. Added the ${PODS_ROOT}/Headers/Public/glm/** to rectify that issue.