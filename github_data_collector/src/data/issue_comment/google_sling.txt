Guide for the task system.
Not sure if we want a guide for the task system. If we do, then once we agree on contents, I'll add a link to it as well.
Introduces a class that caches from a local file all relevant deleted triples and checks in that file first before it looks up in Wikidata, using the API, for more current possible deletions.

I didn't actually test it yet, I haven't come around to figure how to run it and test it, so it probably has errors. Feel free to ignore the PR until managed to run and test the code.
Connecting to conll.cemantix.org (conll.cemantix.org)|66.147.244.155|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 9912 (9.7K)
Saving to: ‘dev.ids’

dev.ids                      100%[=============================================>]   9.68K  --.-KB/s    in 0s      

2019-08-14 02:25:53 (184 MB/s) - ‘dev.ids’ saved [9912/9912]

--2019-08-14 02:25:53--  http://conll.cemantix.org/2012/download/ids/english/coref/test.id
Resolving conll.cemantix.org (conll.cemantix.org)... 66.147.244.155
Connecting to conll.cemantix.org (conll.cemantix.org)|66.147.244.155|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 9912 (9.7K)
Saving to: ‘test.ids’

test.ids                     100%[=============================================>]   9.68K  --.-KB/s    in 0s      

2019-08-14 02:25:54 (108 MB/s) - ‘test.ids’ saved [9912/9912]

--2019-08-14 02:25:54--  http://ontonotes.cemantix.org/download/conll-formatted-ontonotes-5.0-scripts.tar.gz
Resolving ontonotes.cemantix.org (ontonotes.cemantix.org)... 66.147.244.155
Connecting to ontonotes.cemantix.org (ontonotes.cemantix.org)|66.147.244.155|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 9241 (9.0K) [application/x-gzip]
Saving to: ‘conll-formatted-ontonotes-5.0-scripts.tar.gz’

conll-formatted-ontonotes-5. 100%[=============================================>]   9.02K  --.-KB/s    in 0s      

2019-08-14 02:25:54 (223 MB/s) - ‘conll-formatted-ontonotes-5.0-scripts.tar.gz’ saved [9241/9241]

Generate CoNLL files
----------------------------------------------------------------------------------------------------

could not find the gold parse [ontonotes-release-5.0/data/files/data/english/annotations/tc/ch/00/ch_0028.parse] in the ontonotes distribution ... exiting ...

----------------------------------------------------------------------------------------------------
~/sling
![Ontonotes](https://user-images.githubusercontent.com/55606/62993040-d8168c80-be23-11e9-8c70-0bb1b45c093c.PNG)

I just tested the parser with caspar.flow and this is what I got

python3 test.py
text: John Loves Mary
{=#1 
  :document
  text: "John Loves Mary"
  tokens: [{=#2 
    start: 0
    size: 4
  }, {=#3 
    start: 5
    size: 5
  }, {=#4 
    start: 11
    size: 4
  }]
  mention: {=#5 
    begin: 0
    evokes: {=#6 
      :thing
    }
  }
  mention: {=#7 
    begin: 1
    evokes: {=#8 
      :/pb/predicate
      /pb/ARG0: #6
      /pb/ARG1: {=#9 
        :thing
      }
    }
  }
  mention: {=#10 
    begin: 2
    evokes: #9
  }
}
mention John
mention Loves
mention Mary
Hi there! Are you aware of other open source projects using SLING? For example, this paper describes SLING-based system developed by one of you while at Google https://arxiv.org/abs/1811.00119
Parsing raw wiki text into structured format is hard, especially handling wiki documents that are not well-formed. This issue is for tracking problematic cases where the extraction is wrong or missing.
any detailed example on how to fine tune "caspar.flow" model on our own dataset?

having following output, how to parse it to get ARG0 and name of each predicate

[{=#1 :/pb/predicate /pb/ARG1: {=#2 :/pb/predicate /pb/ARG0: {=#3 :/pb/predicate}} /pb/ARG2: {=#4 :thing}}]
I was wondering if it was possible to get the possibility to restart the training processes from a previously saved checkpoint.
