Hi,

I hava a case in which my CSV contains a set of known fields plus an arbitrary number of other fields. I'd wish to map the known fields to the properties of a class in the usual way and put the others in a dictionary that is a property of that same class.

Is it possible with a ClassMap or something else to do this thing?

Thanks.
**Describe the bug**
Upgrading from 12.3.2 to 13.0.0 breaks this code:

![2020-01-16_22-38-57](https://user-images.githubusercontent.com/3047487/72565138-87fb9480-38b1-11ea-8cc3-6e6c5fe62539.png)
In my IQueryable I have some illegal characters, for instance, '\n' and ';' which I would like to replace. However, in the way I did it I can't do it as I'm writting the query directly `csv.WriteRecords(query)`. How could I do that?

```
 public static void ConvertLINQToCsv<T>(string path, IQueryable<T> query)
  {
    using (var sw = new StreamWriter(path))
            using (var csv = new CsvWriter(sw))
            {
                csv.Configuration.Delimiter = UniversalVariables.csvDelimiter.ToString(); ;
                csv.Configuration.HasHeaderRecord = true;
                csv.Configuration.UseNewObjectForNullReferenceMembers = true;

                csv.WriteHeader<T>();
                csv.NextRecord();
                csv.WriteRecords(query);

                sw.Flush();
            }
  }

```
Optimize TypeConverterCache constructor by delaying the adding of default double converter and float converter from the constructor to the GetConverter method (same as EnumConverter).
Seems like'$' character is missing.
Hello, before I knew about this project, I created my own (simple) csv helper ([source code here](https://github.com/leandromoh/uteis/blob/master/C%23/Estudos/GenericRecordParser%3CT%3E.cs)) and after knew about this project, tried to do some usage comparisons and found some points which my looks simpler, faster (i dont know if this last is true, maybe i didnt configure your csv library appropriately). here is one example of usage of my helper. hope it can give you some insight. 

here are some points that I found notable about my helper when comparatin:
1. my helper configuration is simpler, you create a new instance of `GenericRecordParser<T>` and pass to constructor a `IEnumerable<string>`, where each `string` is the name of a property of `T`. first property on list, will be filled with first column of csv line, second property on list with second column, and so on. if need ignore some column, simple pass `null`
2.  the previous point enforces POCO classes
3.  if I understood well, your helper becomes verbose when we have nested objects to configure. in my, we simple refers a nested column with a "X.Y" `string` in the list that we pass to constructor, where `X` is a property (nested object) of  `T` and `Y` is a property of `X`. that is, no need of different configuration for nested objects.
4.  in the exemple that follows bellow I used a circular reference to test my helper. when trying to use it with yours helper it throws an exception
5. when I did a simple benchamark reading a file with tons of records (where all lines was the same: the one in the example bellow), my helper was 10x faster 
6.  my helper parses strings, not streams. we choose this approach because all csv files can be converted into a sequence of csv records strings easily, but the opposite is not true. A csv string might not come from a csv file. in fact, the file that i needed to parse was a parcial csv. there was lines that are csv, others that not, so could not parse the whole file, need to parse just the lines that I found appropriate. in another case, each line represents an array of csv records. so for each line I need to split them in many, flatten them all, and finally parse each string.

exemple of class which csv line represents

```c#
        internal class Person
        {
            public Color Eye { get; set; }
            public Color Color { get; set; }
            public bool IsAlive { get; set; }
            public char Gender { get; set; }
            public Document RG;
            public int Age { get; set; }
            public Decimal Money { get; set; }
            public string Name { get; set; }
            public DateTime BirthDay { get; set; }
            public DateTime? DeathDay { get; set; }
            public Person Father { get; set; }
        }

        public class Document
        {
            public Document(int _) { }

            public string Name;
            public double Id { get; set; }
        }

        internal enum Color
        {
            Black,
            White,
            Yellow,
            LightBlue,
        }
```

example of translatin csv line to `Person` object

```c#
    public class GenericRecordParserTests
    {
        [Fact]
        public void Parse()
        {
            CultureInfo.CurrentCulture = CultureInfo.InvariantCulture;

            // Arrange

            Color Color = Color.Yellow;
            bool IsAlive = true;
            char Gender = 'M';
            double Id = 12.34;
            int Age = 25;
            Decimal Money = 123.345M;
            string Name = "Bob";
            DateTime BirthDay = DateTime.Today.AddYears(-Age);
            DateTime? DeathDay = null;
            string FatherName = nameof(FatherName);
            string GrandpaName = nameof(GrandpaName);
            int GrandpaId = 734;
            Color Eye = Color.LightBlue;

            var mapped = new[]
            {
                nameof(Eye),
                nameof(Color),
                nameof(IsAlive),
                nameof(Gender),
                "RG.Id",
                "RG.Name",
                nameof(Age),
                nameof(Money),
                nameof(Name),
                nameof(BirthDay),
                nameof(DeathDay),
                "Father.Name",
                "Father.Father.Name",
                "Father.Father.RG.Id",
            };

            var EyeColor = "   LIGHT    BLUE   ";
            var parser = new GenericRecordParser<Person>(mapped);

            var csvLine = $@"{EyeColor};{Color};{IsAlive};{Gender};{Id};
         {Name};{Age};{Money};{Name};
         {BirthDay};{DeathDay};{FatherName};{GrandpaName};{GrandpaId}";

            // Act

            Person person = parser.Parse(csvLine);

            // Assert

            person.Eye.Should().Be(Eye);
            person.Color.Should().Be(Color);
            person.IsAlive.Should().Be(IsAlive);
            person.Gender.Should().Be(Gender);
            person.RG.Id.Should().Be(Id);
            person.RG.Name.Should().Be(Name);
            person.Age.Should().Be(Age);
            person.Money.Should().Be(Money);
            person.Name.Should().Be(Name);
            person.BirthDay.Should().Be(BirthDay);
            person.DeathDay.Should().Be(DeathDay);

            person.Father.Name.Should().Be(FatherName);
            person.Father.Father.Name.Should().Be(GrandpaName);
            person.Father.Father.RG.Id.Should().Be(GrandpaId);
            person.Father.Father.Father.Should().BeNull();
        }
```


IDataReader maps between the input source and the destination table using the schema details provided by GetSchemaTable(). Currently in CsvDataReader all columns are defaulted to strings which causes conversion issues when using as a source for SqlBulkCopy.

To remedy this I have added an additional constructor that accepts a DataTable along with the required CsvReader, this DataTable should contain the schema of the destination table and can be generated like so.

```
public static DataTable GetDataTableSchema(string schema, string tableName)
{
	DataTable dataTable = new DataTable();

	using (SqlConnection _sqlConnection = new SqlConnection(_sqlConnectionString))
	using (SqlCommand command = new SqlCommand("select top 0 * from " + schema + "." + tableName))
	{
		command.Connection = _sqlConnection;
		_sqlConnection.Open();

		using (SqlDataReader reader = command.ExecuteReader(CommandBehavior.SchemaOnly))
		{
			dataTable = reader.GetSchemaTable();
		}

		_sqlConnection.Close();
	}

	return dataTable;
}
```

This will ensure that the correctly typed Get method will be used within the CsvDataReader.

A complete example can be seen [here](https://github.com/mattosaurus/DataTransfer/tree/master/DataTransfer.GoogleCloudStorageToSql).
Suggesting new default for `ShouldUseConstructorParameters`. Unit-tests are still passing, not sure what other ramifications this change has. I only use it for a very small and specific dataset.

```
public static bool ShouldUseConstructorParameters(Type type)
{
	return !type.HasParameterlessConstructor()
		&& type.HasConstructor()
		&& !(type.IsUserDefinedStruct() && type.HasParameterlessConstructor())
		&& !type.IsInterface
		&& Type.GetTypeCode(type) == TypeCode.Object;
}
```

Hi 

For a task I need to bring the PLC interface into a Android Tablet. For the huge amount of data with information (Name, Data type , offset , comment etc...) i'm using CsvHelper to easily save & sort the information in maps. Unfortunately I have some problems with my CSV.file (with all the information from the PLC in it). This is the error : 

![image](https://user-images.githubusercontent.com/58330185/69865386-55fe8680-12a1-11ea-8586-f4ea9053de4a.png)

I have been searching for this problem but haven't found the solution yet. Any help would be great!

Code ;

![image](https://user-images.githubusercontent.com/58330185/69865486-8e9e6000-12a1-11ea-95a8-2a0efb14bb9d.png)


I also have a second question. What CsvHelper should do is locate to a location on the server where the Csv.file is located. Is that possible to do that with CsvHelper on a wireless Android Tablet with an mobile made application? This application will be made with Xamarin on Visual Studio

Thank you for your time to read this
UniNan

i have nested class structure and want to export csv file with header name.

```cs
public class PersonalDetailsMI
{
    public CustumerDetails PrimaryCustomer { get; set; }

    public CustumerDetails SecondryCustomer { get; set; }
}

public class CustumerDetails
{ 
    public Name Name { get; set; }
}

public class Name
{ 
    public string FirstName { get; set; }
    public String LastName { get; set; }
}
```

Expected Csv Format:

```
PrimaryCustomer_FirstName, PrimaryCustomer_LastName,SecondaryCustomer_FirstName,SecondaryCustomer_Lastname
```

currently i am able to export like this.

```
Name_FirstName,Name_LastName,Name_FirstName,Name_LastName
```

can you please help me to resolve this.