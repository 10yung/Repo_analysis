matcaffe中数据的存储格式是WHCN，为什么测试源码中输入数据的格式是HWCN
没有看见论文里面提到的关键的sub-pixel Convolution layer？你这个像SRCNN呀。
https://github.com/tetrachrome/subpixel

这个tensorflow里面有这个layer。
the paper said it can reach 24fps on CPU.
but I test it on i7 with set5, only 1 fps.
怎么才能输出彩色图？
我自己进行了训练，发现出来的模型 对有些图片很好，有些图片没啥效果。
问下这个跟什么有关系，训练集么。 有木有这方面的经验
谢谢！
Hello
I am just wondering if it is at all possible to make FSRCNN to look like Waifu2x does with full denoising and still running it in real time on a high end gpu? The image scaling I want is 320x240 up to 1080p and around 30 fps. 


看你的solver 文件max 迭代次数1500w 次，学习率更新是fixed，问下你真的训练了1500w次么。
我这边loss 一直稳定在7-8的样子，用跟你相同的参数
很感谢您的分享让我能进一步了解ESRCN。其中我遇到了一个问题，希望您有时间的时候帮忙解答下。
问题如下：
请问下面论文描述的部分对应的程序哪部分？
3.2. Implementation details
For the ESPCN, we set l = 3, (f1, n1) = (5, 64), (f2, n2) = (3, 32) and f3 = 3 in our evaluations. The choice of the parameter is inspired by SRCNN’s 3 layer 9-5-5 model and the equations in Sec. 2.2. In the training phase,17r × 17r pixel sub-images are extracted from the training ground truth images IHR, where r is the upscaling factor. To synthesize the low-resolution samples ILR, we blur IHR using a Gaussian filter and sub-sample it by the upscaling factor. The sub-images are extracted from original images with a stride of (17 − Pmod (f, 2)) × r from IHR and a stride of 17 − Pmod (f, 2) from ILR. This ensures that all pixels in the original image appear once and only once as the ground truth of the training data. We choose tanh instead of relu as the activation function for the final model motivated by our experimental results.
谢谢您的浏览，期待您的回复，祝生活愉快！
What is the performance of your fsrcnn implementation in psnr?
I cannot make my network to the same performance as the paper given.
How many iteration does it need to reach the same performance of fsrcnn?

Thanks
