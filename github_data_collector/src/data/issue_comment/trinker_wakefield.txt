@trinker , amazing package. Quick question, can I have control over the mean and sd for the first variable in an r_series?  It would probably look like this:

>  r_series(normal(mean = 35, sd = 10, min = 10, max = 45), 2, 100, name = "Question", relate = list(operation = "+", mean = 5, sd = 10))

 Add more groups to gender.  http://abcnews.go.com/blogs/headlines/2014/02/heres-a-list-of-58-gender-options-for-facebook-users/

Nice! It would also be great to set percentile distribution per var group? Ex. Age - 10% 10-20 ; 20% 30-40, 70 % 50-80 & so forth

Thanks for making this useful package.

I tried to use it initially by doing:

```
wakefield::r_data_frame(id, age, n = 500)
```

This fails because, it seems, the `id` and `age`, etc, functions need to be available. It is beyond my knowledge, but perhaps you could interpret the symbols given in the wakefield namespace. Adding all those generic-sounding names to my namespace is a little worrying. I suppose I can call each function directly, using `wakefield::` but this becomes more cumbersome. Just a thought.

Currently all user errors are swallowed by try blocks in `r_list`:

```
> r_data_frame(10,
+              id = sample(NULL, 10),
+              answer())
Error in sample(NULL, 10, n = 10) (from r_list.R#71) : unused argument (n = 10)
> 
```

which is unrelated to the real problem 

```
> sample(NULL, 10)
Error in sample.int(length(x), size, replace, prob) : 
  invalid first argument
```

BTW, you can eliminate such errors and  avoid the substitution of each var_function by having a smart `n` argument that would automatically pick `n` from the calling environment:

```
> var_fun <- function(a = get(".N.", parent.frame(1))){print(a)}
> caller <- function(){ .N. <- 10; var_fun()}
> caller()
[1] 10
```

```
library(wakefield)
fun <- function(n, ..., digits = 0) round(rnorm(n=n, ...), digits)

foo <- r_data_frame(
    n = 10000,
    Income = fun(mean=54000, sd=1100),
    race,
    Age= fun(mean=35, sd=10),
    sex,
    internet_browser,
    state,
    marital
)
```

Is it possible to generate values in a multi-select environment?  This could apply to survey research (select all that apply), or graphs (edges between nodes of a certain type).  

Below is a really hacky function that demonstrates this use-case in a hard-coded way

```
## helper function:  obviously not a production-quality function
build_multi = function(ids) {
  df_data = data.frame()
  for (i in 1:length(ids)) {
    ## randomize how many choices are made
    n_obs = sample(x=1:2, size=1, prob = c(.75, .25))
    ## what are the choices available in the multi-select
    cvals = c("BIZ","ARTS","SCIENCE","HEALTH","OTHER")
    vals = sample(x = cvals,
                  replace = FALSE, 
                  prob = c(.4,.2,.15,.2, .05), 
                  size = n_obs)
    tmp_df = data.frame(id = ids[i],
                        values = vals)
    df_data = dplyr::bind_rows(df_data, tmp_df)
  }
  return(df_data)
}
```

```
## generate a set of ids
my_df = r_data_frame(id = id, n=100)
```

and generate the data 

```
## return a long dataset of multiselect options for given probabilities (which I hardcoded)
my_long = build_multi(my_df$id)
```

Above generates the dataset in a structure that I would need, but I wasn't sure if this already existed in the current package. 

I started work awhile ago on a much less ambitious project than `wakefield` to attempt to generate random data sets on the fly with a known correlation structure. You can see the seeds of that work here: https://github.com/jknowles/datasynthR

It would be cool to include the ability to generate numeric or factor data with a known correlation structure to build structural relationships into the very realistic looking data generated by `wakefield`. 
