Fixes #1998

_(Message COC002)_

As of January 1 2019, Mozilla requires that all GitHub projects include this [CODE_OF_CONDUCT.md](https://github.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md) file in the project root. The file has two parts:

1. Required Text - All text under the headings *Community Participation Guidelines and How to Report*, are required, and should not be altered.
2. Optional Text - The Project Specific Etiquette heading provides a space to speak more specifically about ways people can work effectively and inclusively together. Some examples of those can be found on the [Firefox Debugger](https://github.com/devtools-html/debugger.html/blob/master/CODE_OF_CONDUCT.md) project, and [Common Voice](https://github.com/mozilla/voice-web/blob/master/CODE_OF_CONDUCT.md). (The optional part is commented out in the [raw template file](https://raw.githubusercontent.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md), and will not be visible until you modify and uncomment that part.)

If you have any questions about this file, or Code of Conduct policies and procedures, please reach out to Mozilla-GitHub-Standards+CoC@mozilla.com.

_(Message COC001)_
conf:
`[kafkaInputTest]
type = "KafkaInput"
topic = "jie"
addrs = ["172.20.3.50:9092"]
splitter = "KafkaSplitter"
decoder = "ProtobufDecoder"

[KafkaSplitter]
type = "NullSplitter"
use_message_bytes = true
`

But error:

`2018/09/17 16:01:18 Input 'kafkaInputTest' error: kafka server: In the middle of a leadership election, there is currently no leader for this partition and hence it is unavailable for writes.
`
[ 85%] Performing build step for 'lua_sandbox'
Scanning dependencies of target lua-5_1_5
[  1%] Creating directories for 'lua-5_1_5'
[  2%] Performing download step (git clone) for 'lua-5_1_5'
Cloning into 'lua-5_1_5'...
remote: Repository not found.
fatal: repository 'https://github.com/trink/lua.git/' not found


[hekad]
maxprocs = 2
#base_dir = "./base_dir"
share_dir = "/usr/share/heka"
#log_info_filename = "logs/info.log"
#log_error_filename = "logs/error.log"
#log_file_max_size = 64
#log_file_max_backups = 7


[Sync-1_5-SlowQuery]
type = "LogstreamerInput"
log_directory = "/data/soft/"
file_match = 'mysqlslowq\.log'
parser_type = "regexp"
delimiter = "\n(# User@Host:)"
delimiter_location = "start"
decoder = "MySqlSlowQueryDecoder"

[MySqlSlowQueryDecoder]
type = "SandboxDecoder"
filename = "lua_decoders/mysql_slow_query.lua"

    [MySqlSlowQueryDecoder.config]
    truncate_sql = 64

[ESJsonEncoder]
index = "%{Type}-%{%Y.%m.%d}"
es_index_from_timestamp = true
type_name = "%{Type}"
    [ESJsonEncoder.field_mappings]
    Timestamp = "@timestamp"
    Severity = "level"

[output_file]
type = "FileOutput"
message_matcher = "TRUE"
path = "/data/mysql-output.log"
perm = "666"
flush_count = 100
flush_operator = "OR"
encoder = "ESJsonEncoder"




###
###
###
###
###
#######################################################################

[root@oskey heka]# hekad -config="mysql.toml"

2018/01/25 09:59:20 Pre-loading: [output_file]
2018/01/25 09:59:20 Pre-loading: [Sync-1_5-SlowQuery]
2018/01/25 09:59:20 Pre-loading: [MySqlSlowQueryDecoder]
2018/01/25 09:59:20 Pre-loading: [ESJsonEncoder]
2018/01/25 09:59:20 Pre-loading: [ProtobufDecoder]
2018/01/25 09:59:20 Loading: [ProtobufDecoder]
2018/01/25 09:59:20 Pre-loading: [ProtobufEncoder]
2018/01/25 09:59:20 Loading: [ProtobufEncoder]
2018/01/25 09:59:20 Pre-loading: [TokenSplitter]
2018/01/25 09:59:20 Loading: [TokenSplitter]
2018/01/25 09:59:20 Pre-loading: [HekaFramingSplitter]
2018/01/25 09:59:20 Loading: [HekaFramingSplitter]
2018/01/25 09:59:20 Pre-loading: [NullSplitter]
2018/01/25 09:59:20 Loading: [NullSplitter]
2018/01/25 09:59:20 Loading: [MySqlSlowQueryDecoder]
2018/01/25 09:59:20 Loading: [ESJsonEncoder]
2018/01/25 09:59:20 Loading: [Sync-1_5-SlowQuery]
2018/01/25 09:59:20 unknown config setting for 'Sync-1_5-SlowQuery': parser_type
2018/01/25 09:59:20 Loading: [output_file]
2018/01/25 09:59:20 Error reading config: 1 errors loading plugins

RT
need any other config items ?

follow is my part config
[hekad]
maxprocs = 16
base_dir = "/export/home/hekad"
**max_message_size = 10485760**

#attack log default
[nginx_udp_551]
type = "UdpInput"
address = "172.18.182.162:551"
decoder = "JsonDecoder"
send_decode_failures = true
log_decode_failures = true

[JsonDecoder]
type = "SandboxDecoder"
filename = "lua_decoders/json.lua"

[JsonDecoder.config]
payload_keep = false
map_fields = true
Timestamp = "time_stamp"
Type = "log_type"
#type = "ngx_log"

Hi All,
I have installed Heka 0.10 version on windows server 2012 R2 machine. I have configured heka to read a log file that is being written by an exe.
Heka is started from command line with LogOutput as the output plugin. Heka does not read any of the log lines from the log file.
But if we open the log file and manually edit the file ( just giving a space/ enter) heka then starts to read all the log lines from the file.
Could any of you throw suggest opinions like what could the issue be. If the splitter/delimiter is not correct then it will not work after I edit manually. 
I run hekad on a lot of server, but just one server show error log and shut down.
All the server is same, same system, same path, same config.
I don't know why, every time I restart hekad then the server will show me the log!

2016/11/14 10:12:33 Plugin 'o' error: StreamOutput stopped: can't get record: can't unmarshal record: proto: illegal wireType 6
2016/11/14 10:12:33 Plugin 'o' error: can't get record: can't unmarshal record: proto: illegal wireType 6
2016/11/14 10:12:33 Plugin 'o': stopped
2016/11/14 10:12:33 Plugin 'o': has stopped, shutting down.

`
[hekad]
maxprocs = 1
base_dir = "/apps/heka-0_10_0-linux-amd64/bin"
share_dir = "/apps/heka-0_10_0-linux-amd64/bin"

[ks]
type = "RegexSplitter"
delimiter = '</log>'
delimiter_eol = true

[pd]
type = "PayloadRegexDecoder"
match_regex = '(?P<msg>[\s\S]*)'

  [pd.message_fields]
  Logger = "xml_log"
  Payload = "{{pay_mpos_front_cnepay}}%msg%</log>"

[file_input]
type = "LogstreamerInput"
log_directory = "/apps/front_cnepay/log"
file_match = 'front_cnepay\.log'
splitter = "ks"
decoder = "pd"

[PayloadEncoder]
append_newlines = false

[o]
type = "TcpOutput"
address = "logs.qianbao.com:516"
message_matcher = "Logger=='xml_log'"
encoder = "PayloadEncoder"
`
Feature: add a new config directive `cluster_mode` for kafka input plugin.

If `cluster_mode` is enabled, then the kafka topic is consumed across from multiple, balanced heka instances.

The directive requires Kafka v0.9+.

Related issues: #1714, #1910.

Provides https://github.com/mozilla-services/heka/issues/1985
