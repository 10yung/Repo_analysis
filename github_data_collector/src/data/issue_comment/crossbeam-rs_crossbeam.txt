I've recently been fiddling with a multi threaded application using crossbeam channels. On threadripper I noticed that performance would degrade rapidly when the sender and receiver were on different CCX's (or in other words when cache wasn't shared between sender and receiver).

With a bit of digging I found that in the array implementation of channels does suffer from the buffer not being cach aligned.

I wrapped the buffer in a `CachePadded` and it improved significantly in [my tests](https://github.com/Licenser/trb) over 2x in some cases. that said obviously the tests only capture a tiny bit and using  a single 64 bit value in them definitely is the extreme case to trigger this edge case. Still it looks lice a  nice improvement.

I will keep this as a draft for now as while the benchmarks looks nice real world impact I measured is not as big as I hoped :tm: so I think I have a bit more digging to do.


## this
```
running 24 tests
test bounded_0::create    ... bench:          45 ns/iter (+/- 0)
test bounded_0::mpmc      ... bench:  48,288,434 ns/iter (+/- 7,449,535)
test bounded_0::mpsc      ... bench:  79,192,749 ns/iter (+/- 2,066,971)
test bounded_0::spmc      ... bench:  86,323,323 ns/iter (+/- 2,397,011)
test bounded_0::spsc      ... bench:  29,002,652 ns/iter (+/- 1,547,061)
test bounded_1::create    ... bench:         195 ns/iter (+/- 3)
test bounded_1::mpmc      ... bench:  20,014,231 ns/iter (+/- 436,181)
test bounded_1::mpsc      ... bench: 109,318,843 ns/iter (+/- 4,693,295)
test bounded_1::oneshot   ... bench:         180 ns/iter (+/- 1)
test bounded_1::spmc      ... bench:  97,771,406 ns/iter (+/- 3,625,496)
test bounded_1::spsc      ... bench:  18,986,039 ns/iter (+/- 238,972)
test bounded_n::mpmc      ... bench:   5,376,086 ns/iter (+/- 422,042)
test bounded_n::mpsc      ... bench:  11,749,680 ns/iter (+/- 560,767)
test bounded_n::par_inout ... bench:  13,453,292 ns/iter (+/- 966,845)
test bounded_n::spmc      ... bench:  89,016,467 ns/iter (+/- 3,262,106)
test bounded_n::spsc      ... bench:   4,137,098 ns/iter (+/- 375,743)
test unbounded::create    ... bench:         109 ns/iter (+/- 1)
test unbounded::inout     ... bench:          39 ns/iter (+/- 0)
test unbounded::mpmc      ... bench:   3,024,718 ns/iter (+/- 179,688)
test unbounded::mpsc      ... bench:   5,306,185 ns/iter (+/- 362,481)
test unbounded::oneshot   ... bench:         175 ns/iter (+/- 2)
test unbounded::par_inout ... bench:  10,732,447 ns/iter (+/- 542,191)
test unbounded::spmc      ... bench:  92,086,599 ns/iter (+/- 1,790,785)
test unbounded::spsc      ... bench:   1,303,073 ns/iter (+/- 16,593)
```

## master
```
running 24 tests
test bounded_0::create    ... bench:          45 ns/iter (+/- 0)
test bounded_0::mpmc      ... bench:  47,513,539 ns/iter (+/- 7,685,319)
test bounded_0::mpsc      ... bench:  79,297,255 ns/iter (+/- 1,721,529)
test bounded_0::spmc      ... bench:  86,583,535 ns/iter (+/- 2,025,047)
test bounded_0::spsc      ... bench:  29,433,918 ns/iter (+/- 3,792,133)
test bounded_1::create    ... bench:         120 ns/iter (+/- 5)
test bounded_1::mpmc      ... bench:  19,896,780 ns/iter (+/- 523,015)
test bounded_1::mpsc      ... bench: 106,761,448 ns/iter (+/- 4,330,258)
test bounded_1::oneshot   ... bench:         138 ns/iter (+/- 3)
test bounded_1::spmc      ... bench: 100,886,592 ns/iter (+/- 2,866,250)
test bounded_1::spsc      ... bench:  28,713,988 ns/iter (+/- 1,218,632)
test bounded_n::mpmc      ... bench:   6,456,962 ns/iter (+/- 516,168)
test bounded_n::mpsc      ... bench:  13,604,237 ns/iter (+/- 338,683)
test bounded_n::par_inout ... bench:  12,855,325 ns/iter (+/- 1,735,288)
test bounded_n::spmc      ... bench:  97,568,112 ns/iter (+/- 3,793,568)
test bounded_n::spsc      ... bench:   2,035,692 ns/iter (+/- 753,005)
test unbounded::create    ... bench:         112 ns/iter (+/- 2)
test unbounded::inout     ... bench:          39 ns/iter (+/- 0)
test unbounded::mpmc      ... bench:   3,014,406 ns/iter (+/- 308,277)
test unbounded::mpsc      ... bench:   5,213,754 ns/iter (+/- 159,838)
test unbounded::oneshot   ... bench:         165 ns/iter (+/- 1)
test unbounded::par_inout ... bench:  10,640,906 ns/iter (+/- 743,346)
test unbounded::spmc      ... bench:  91,300,215 ns/iter (+/- 2,178,182)
test unbounded::spsc      ... bench:   1,480,523 ns/iter (+/- 47,803)
```
I'm currently working on a project where I have custom allocators that want to perform epoch garbage collection, but with special, nonstandard allocation/deallocation behavior. To accomplish this, I intend to use crossbeam-epoch's `Guard::defer` method to indicate to these custom allocators when thread-time (here meaning intervals after which all threads have released `Guard`s) advances, allowing them to perform a local epoch garbage collection.

Unfortunately, the weak guarantees of `defer` mean that I will almost certainly not get called back right when all threads get unpinned in some circumstances, causing my allocators to lose time. This would be a non-issue if the function passed to defer received the current epoch count, as the custom allocators could see how much time they lost and use this information to potentially clean up multiple epochs-worth of stale lists at once. Would it be possible to add this feature? Or, is it already possible and I'm just not seeing a combo of calls that would make it happen?

Thanks for this project, the crossbeam-epoch system is saving me a lot of work and confusion!
Several libs in crossbeam contain unsound code (`Block::new`). This PR fixes them and requires a MSRV upgrade to 1.36.


I'm using a channel to send a message once and then using the channel again. Do I want to use a bounded or unbounded channel for this? It should probably state so in the readme.
It supersedes #209 for supporting dynamically sized types (DST) in Crossbeam.  It's much cleaner and less intrusive than the previous attempts in that it doesn't introduce another `Atomic` type.  `Atomic<T>` is still there without significant changes.

The key idea is (1) instead of requiring the condition on `T: Sized`, (2) requiring `T: Pointable` that means an object of type `T` can be pointed to by a single word.  For instance, `Atomic` becomes: `pub struct Atomic<T: ?Sized + Pointable> { ... }`.

It is breaking the backward compatibility in that it (1) increases the minimum required Rust version to 1.36 (for `MaybeUninit`) and (2) now const fn `Atomic::null()` is Nightly only.
https://github.com/crossbeam-rs/crossbeam/blob/424f926673d652f306f266d4309ed8717e931144/crossbeam-channel/src/waker.rs#L221-L231

is_empty is an AtomicBool. 
In function SyncWaker::notify()
1. load is_empty to check
2. lock and notify
3. store new value to is_empty

The struct implements Sync and notify() takes an immutable self, so it can be called in two threads.
To me, it seems that the function intends to notify only once when is_empty is not true.
However, the following sequence may happen:
Th1: 1->W->W->W->2 
Th2: W->1->2->3
Thread 1 load is_empty and check, then Thread 2 notify and change the is_empty. Thread 2 executes notify again. Now notify() is called twice.
The fix is to lift the lock before the is_empty check, or check is_empty again after the lock.



Maybe FIX #366
Hi! After a cargo update on a large project I started seeing segfaults on in test run on an android `arm64-v8a` emulator. These segfaults seems to come from `crossbeam-channel` as downgrading to `0.3.8` removes the problem.

I started poking around in order to get a reproduction test case and ended up founding that running a simple `cargo test` on crossbeam-channel on the emulator ends up in a segfault. This seems to happen both on `0.3.8` and `0.3.9` though, but only appears when running the tests on release mode, which smells a lot like a race condition somewhere (probably exacerbated by the fact that the arm64-v8a emulator is slooow). I didn't manage to reproduce it on a real device, having it happen on the emulator is problematic though as is is way easier to setup for continuous integration than a device.

The test [`select_macro::linearizable_default`](https://github.com/crossbeam-rs/crossbeam/blob/master/crossbeam-channel/tests/select_macro.rs#L732) seems to trigger the segfault most of the time when running in release.

## Steps to reproduce:
1. get the android ndk https://developer.android.com/ndk/downloads 
2. get the android sdk tools https://developer.android.com/studio#downloads (bottom of page) and use `sdkmanager` to install the packages `platform-tools` `tools` `system-images;android-24;default;arm64-v8a` (you need to add `adb` in `android-sdk/platform-tools` to you path for dinghy do work)
3. install [dinghy](https://github.com/snipsco/dinghy) with `cargo install cargo-dinghy` (cross compilation helper)
4. setup an android emulator `android-sdk/tools/bin/avdmanager create avd -n foobar -k 'system-images;android-24;default;arm64-v8a' -b arm64-v8a -c 256M -d 7 -f`
5. start the emulator `android-sdk/emulator/emulator -avd toto -prop emu.uuid=toto -partition-size 2048 -no-snapshot -no-window -wipe-data -cores 6 -memory 4096`
6. run the tests `ANDROID_NDK_HOME=/path/to/ndk cargo dinghy --platform auto-android-aarch64-api24 test -p crossbeam-channel  --test select_macro --release -- linearizable_default`





@stjepang [said](https://github.com/crossbeam-rs/crossbeam/pull/359#issuecomment-485958500):

> Just so we don't forget, in all the other places where we have atomic timestamps, we should use `AtomicU64` (I believe we can't use wide sequences like in this PR, unfortunately):
>
> - epoch representation
> - head/tail index in deque, channel, and queues
>
> But that can come later in another PR. It will also require Rust 1.34 minimum.


The original test has:

https://github.com/golang/go/blob/03bb3e9ad13ef49afbed7e422d21ef6eb00389c1/src/runtime/chan_test.go#L105-L108

Notably `done <- v == 0 && ok == false`, which in Rust ought to be `done.send(v.is_none())`.