
Hi Zehao,

I don't quite understand the usage instructions.

1. 
Place the "Train" folder into "($Caffe_Dir)/examples/", and rename "Train" to "VDSR"
What is **($Caffe_Dir)**? Is it caffe or caffe2? I am a bit confused about your directory structures in the usage section.

2. To train VDSR, run ./build/tools/caffe train --solver examples/VDSR/VDSR_solver.prototxt
What is **./build/tools/caffe**? Is **caffe** an executable? Where is this directory?

I thought by based on caffe, you mean python code written in caffe, but I didn't find any python code file.

Thanks for your clarification.
Hi Huang,thanks your sharing! But I have some question.
1.The relation of Training image data and the image I want to rebuild.I mean if i want to rebuild some low resolution images of human face. Do you think my Training data should be all the human face images? Or I should make my Training data the more types, the better?
2. The Size of the cutting image in the file "generate_train". I mean you choose the 41*41 size to cut the training data cause most paper choose the 91 or 291 images. And the training data all about 300*300 size. If my training data all about 1000*1000, should I make my cutting size larger? If I do it, larger cutting size would learn more or less features?
3.About the Multi-scale. In the paper of VDSR the writer said the"Scale augmentation during training is a key technique to equip a network with super-resolution machines of multiple scales." I could not understand that because in FSRCNN, they also used the aug. I think VDSR make the multi scale because of the files "generate_train" and "generate_test". These two files have a "for scale = 2:4". So I want to ask that which is the most important reason to achieve the multi scale rebuild?
4.The most important reason that The VDSR is better the the SRCNN. I did a lot of trying. But I still don't know the key skill of VDSR. What do you think the most important change of VDSR to make a better PSNR to the SRCNN? Maybe the reason is "sum" in the end of the net make it only learn the difference between low and high resolution images? Or the deeper net 20 layers? (I tried 50 layers but a little little better rebuild effect).
So many questions to ask you. A little ashame ^-^
Could I ask you a question?
I trained a network and then used this network to process the image sequence and the Caffe framework is adopted. When I started one task, GPU load is 65%, but when I ran two independent tasks at the same time, the GPU load is only 70%. The processing speed of each road is almost half that of the original, that is, it cost two times time to process each task. The utilization rate of CPU is not high and there is plenty of memory. And there are no other tasks taking up GPU. My GPU is not full but processing speed is down,do you know why?  
Do anyone have the test code without matconvnet. I tried using python interface and I am not able to get good results. I am able to get good results using matconvnet and the given test code. But not for python interface. Seems like I have done something wrong in the data preprocessing. It would be great if anyone has done it already.
Hi, guys! The codes of multi-scale implementation and data argumentation have been updated.
The model trained by myself yields similar performance with original paper!