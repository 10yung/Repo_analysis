Branch Master
run in Windows Power Shellï¼Œlooks like repository is missing
 
.\install_libusb_vs2013.cmd                      
git clone https://github.com/libusb/libusb.git libusb_src   || exit /b
Cloning into 'libusb_src'...
remote: Enumerating objects: 60, done.
remote: Counting objects: 100% (60/60), done.
remote: Compressing objects: 100% (45/45), done.
remote: Total 13807 (delta 26), reused 31 (delta 5), pack-reused 13747
Receiving objects: 100% (13807/13807), 3.88 MiB | 28.00 KiB/s, done.
Resolving deltas: 100% (9984/9984), done.

git remote add xlz https://github.com/xlz/libusb.git
git fetch xlz   || exit /b
remote: Repository not found.
fatal: repository 'https://github.com/xlz/libusb.git/' not found
PS E:\Github\libfreenect2-0.2.0\depends>  
Hello, I am looking at a way to extend the working distance of traditional usb 3.0, currently for my project i am running 4 kinects on one system, and using usb active extensions to extend the range of the kinects. I am having intermittent issues with the usb active extensions, particulary when i start to daisy chain, the kinects are either not recognized at all, are recognized but don't open correctly, or open and then crash shortly after. However i can run the four fairly stable if i don't daisy chain. If anyone has any ideas on making this behave better im all ears.

My team's preferred solution originally was to run the kinect's using four seperate computers, some single board computer like the new raspberry pi 4 would be nice, but as i understand, these will not meet performance standards for decent depth processing frame rate (we need 30hz +).

So the main question, is it possible to repeat the raw data of the kinects over ethernet? My first idea would be to use the DumpPacketPipeline, which constructs a Frame instance with the raw packet data, and then send this over ethernet (perhaps using ROS). This data would go into a high-end pc to perform processing on the RGB and Depth packets, how could i input this raw data into libfreenect2 to perform rgb and depth packet processing using appropriate methods (eg. Cuda depth processing) to then spit out the processed rgb and depth images?

Has anyone tried doing something similar before? Any thoughts / ideas is much appreciated.
Overview Description:
I can't get Video from Protonect, or rather i cannot display it on my Screen.
Haven't had any luck with either X11 or Wayland. (tried Deepin and Gnome Wayland / Gnome X11).
Any pointers in the right direction are greatly appreciated.

Version, Platform, and Hardware Bug Found:

1. `da68a71 (HEAD -> master, origin/master, origin/HEAD) Update TegraJPEG detection`
2. `Linux yoshio-notebook 5.3.18-1-surface #1 SMP PREEMPT Sat, 28 Dec 2019 22:53:29 +0000 x86_64 GNU/Linux`
3. 
```
Bus 02.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/6p, 5000M
    |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/3p, 5000M
        |__ Port 2: Dev 3, If 0, Class=Hub, Driver=hub/1p, 5000M
            |__ Port 1: Dev 4, If 0, Class=Vendor Specific Class, Driver=, 5000M
            |__ Port 1: Dev 4, If 1, Class=Vendor Specific Class, Driver=, 5000M
            |__ Port 1: Dev 4, If 2, Class=Audio, Driver=snd-usb-audio, 5000M
            |__ Port 1: Dev 4, If 3, Class=Audio, Driver=snd-usb-audio, 5000M

```
4. `00:14.0 USB controller [0c03]: Intel Corporation Sunrise Point-LP USB 3.0 xHCI Controller [8086:9d2f] (rev 21)`

Steps to Reproduce:

1. Build current libfreenect2 from Github
2. run /build/Protonect

Actual Results:
`$ ./Protonect`
```
Version: 0.2.0
Environment variables: LOGFILE=<protonect.log>
Usage: ./Protonect [-gpu=<id>] [gl | cl | clkde | cuda | cudakde | cpu] [<device serial>]
        [-noviewer] [-norgb | -nodepth] [-help] [-version]
        [-frames <number of frames to process>]
To pause and unpause: pkill -USR1 Protonect
[Info] [Freenect2Impl] enumerating devices...
[Info] [Freenect2Impl] 9 usb devices connected
[Info] [Freenect2Impl] found valid Kinect v2 @2:4 with serial 298089633947
[Info] [Freenect2Impl] found 1 devices
[Error] [OpenGLDepthPacketProcessorImpl] GLFW error 65544 Wayland: Failed to connect to display
[Error] [OpenGLDepthPacketProcessor] Failed to initialize GLFW.
```

Expected Results:
- Display Sensor Results

Reproducibility:
- Unknown


Additional Information:
- Kinect v2 with Official Microsoft Kinect One to Windows Adapter.
- Bought a Second Pair (unofficial [Kinect One Windows Adapter](https://www.amazon.de/dp/B07GFGBF6Q/ref=sr_1_3?keywords=Kinect+v2&qid=1578252389&sr=8-3) + Kinect v2) where i experience the same result.
- `./Protonect cpu` results in `$ GLFW error 65537 The GLFW library is not initialized` being displayed 5 times.

hi, i was tinkering with the kinect sensor with python and opencv.
Is there a way to get the distance from the sensor in millimeters? I ask because i don't find any examples or documentation of it in python, thanks

Hello,

Is it possible to use Kinect v2 as a webcam in Ubuntu to access from other applications such as Cheese? In other words, I would like to register the RGB camera of Kinect v2 as /dev/videoX.
I have tried:

https://github.com/yoshimoto/gspca-kinect2

as a driver. However, it didn't work with the test program Protonect.

Thank you in advance.
Overview Description:
I want to edit the SimpleUserTracker to meet my requirement of human follower robot. I want to publish the coordinates into a rostopic. Is that possible?
If not can I create a new sample similar to SimpleUserTracker? If so, could you explain me how to do that?
Thank you.
Overview Description:
i am getting this error:
CMakeFiles/Protonect.dir/Protonect.cpp.o: In function `MyFileLogger::log(libfreenect2::Logger::Level, std::string const&)':
/home/ixtiyor/Downloads/libfreenect2/examples/Protonect.cpp:93: undefined reference to `libfreenect2::Logger::level2str(libfreenect2::Logger::Level)'
CMakeFiles/Protonect.dir/Protonect.cpp.o: In function `main':
/home/ixtiyor/Downloads/libfreenect2/examples/Protonect.cpp:282: undefined reference to `libfreenect2::Freenect2::openDevice(std::string const&, libfreenect2::PacketPipeline const*)'
/home/ixtiyor/Downloads/libfreenect2/examples/Protonect.cpp:275: undefined reference to `libfreenect2::Freenect2::getDefaultDeviceSerialNumber()'
/home/ixtiyor/Downloads/libfreenect2/examples/Protonect.cpp:287: undefined reference to `libfreenect2::Freenect2::openDevice(std::string const&)'
collect2: error: ld returned 1 exit status
CMakeFiles/Protonect.dir/build.make:152: recipe for target 'Protonect' failed
make[2]: *** [Protonect] Error 1
CMakeFiles/Makefile2:67: recipe for target 'CMakeFiles/Protonect.dir/all' failed
make[1]: *** [CMakeFiles/Protonect.dir/all] Error 2
Makefile:83: recipe for target 'all' failed
make: *** [all] Error 2

Steps to Reproduce:

1. install pytorch using [this](https://pytorch.org/cppdocs/installing.html)
2. change the  CMakeLists.txt file as shown in the link above
3. then build with:
```
mkdir build
cd build
cmake -DCMAKE_PREFIX_PATH="/home/ixtiyor/Downloads/pytorchc++/libtorch;$HOME/freenect2/lib/cmake/freenect2" ..
cmake --build .
```

can somebody help me please ?

Hi!

I have been checking different issues on performing the offline registration but I cannot find exactly the case I am working on. I have RGB and its correspondent depth image of hands saved on memory. The problem is that they are cropped to only show the hand so the sizes of both RGB and depth images are not anymore (1920, 1080) nor (512, 424) but resized to random squared sizes dependent on the hand size. 
![color](https://user-images.githubusercontent.com/43776720/68746953-e67a6d00-05f9-11ea-8653-12c984f0e63c.png) ![depth](https://user-images.githubusercontent.com/43776720/68746954-e67a6d00-05f9-11ea-983d-01ddef941e26.png)

I dont know if once cropped the registration can be performed. What I am trying to do is adding borders to the image (both mirroring or zero padding) up to their default size and do the registration but I keep on getting completely black images both for the registered and undistorted images. If I dont add any border to the images and perform registration with their squared sizes I get the registered on the left and undistorted on the right. 
![registered](https://user-images.githubusercontent.com/43776720/68747767-7ff64e80-05fb-11ea-909d-f989784e4887.png) ![undistorted](https://user-images.githubusercontent.com/43776720/68747768-7ff64e80-05fb-11ea-98d7-8e3af36cff88.png)

Do you know if this can be fixed somehow?

My code is as follows

> libfreenect2::Registration *registration = new libfreenect2::Registration(
>       dev->getIrCameraParams(), dev->getColorCameraParams());
> color_img = cv::imread("color.png", cv::IMREAD_COLOR);
> depth_img = cv::imread("depth.png");
> cv::cvtColor(color_img, color_img, cv::COLOR_BGR2BGRA);
> 
> int rgbHorizontalMargin = std::abs((color_img.cols - 1920) / 2);
> int rgbVerticalMargin = std::abs((color_img.rows - 1080) / 2);
> int depthHorizontalMargin = std::abs((depth_img.cols - 512) / 2);
> int depthVerticalMargin = std::abs((depth_img.rows - 424) / 2);
> cv::Scalar value = cv::Scalar(0, 0, 0);
> 
> cv::copyMakeBorder(color_img, color_img, rgbVerticalMargin + 1,
>                    rgbVerticalMargin, rgbHorizontalMargin + 1,
>                    rgbHorizontalMargin, cv::BORDER_CONSTANT, value);
> cv::copyMakeBorder(depth_img, depth_img, depthVerticalMargin + 1,
>                    depthVerticalMargin, depthHorizontalMargin + 1,
>                    depthHorizontalMargin, cv::BORDER_CONSTANT, value);
> 
> libfreenect2::Frame *rgb =
>     new libfreenect2::Frame(color_img.cols, color_img.rows, 4, color_img.data);
> libfreenect2::Frame *depth =
>     new libfreenect2::Frame(depth_img.cols, depth_img.rows, 4, depth_img.data);
> 
> libfreenect2::Frame undistorted(depth->width, depth->height,
>                                 depth->bytes_per_pixel);
> libfreenect2::Frame registered(depth->width, depth->height,
>                                depth->bytes_per_pixel);
> 
> registration->apply(rgb, depth, &undistorted, &registered);
> 
> cv::Mat undistorted_img(undistorted.height, undistorted.width, CV_8UC4,
>                         undistorted.data);
> cv::Mat registered_img(registered.height, registered.width, CV_32FC1,
>                        registered.data);




After running cmake --build . --config RelWithDebInfo --target install
I get this error in Windows 10 64bit.
    Microsoft (R) Build Engine version 14.0.25420.1
    Copyright (C) Microsoft Corporation. All rights reserved.
    MSBUILD : error MSB1009: Project file does not exist.
    Switch: install.vcxproj

I tried adding SET(CMAKE_INSTALL_PREFIX < path >)
but still having the same error. 
Any suggestion?
Did all the steps as per instructions. When I do make, this is what I see:

[ 68%] Linking CXX shared library lib/libfreenect2.so
/usr/bin/ld: /usr/local/lib/libglfw3.a(context.c.o): relocation R_X86_64_32S against `.rodata' can not be used when making a shared object; recompile with -fPIC
/usr/local/lib/libglfw3.a: error adding symbols: Bad value
collect2: error: ld returned 1 exit status
CMakeFiles/freenect2.dir/build.make:658: recipe for target 'lib/libfreenect2.so.0.2.0' failed
make[2]: *** [lib/libfreenect2.so.0.2.0] Error 1
CMakeFiles/Makefile2:136: recipe for target 'CMakeFiles/freenect2.dir/all' failed
make[1]: *** [CMakeFiles/freenect2.dir/all] Error 2
Makefile:127: recipe for target 'all' failed
make: *** [all] Error 2

Tried all the suggestions mentioned by other people facing the issue. Especially all the fixes from https://github.com/BVLC/caffe/issues/2171#issuecomment-85260916 and https://github.com/OpenKinect/libfreenect2/issues/773.

Nothing helps so far. Kindly advice.