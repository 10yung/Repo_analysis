```
make -C /lib/modules/4.15.0-72-generic/build M=/home/user/Downloads/netmap-master CONFIG_NETMAP=m  \
	O_DRIVERS="e1000e" \
	 \
	NETMAP_DRIVER_SUFFIX=_netmap \
	 \
	modules_install
make[1]: Entering directory '/usr/src/linux-headers-4.15.0-72-generic'
  INSTALL /home/user/Downloads/netmap-master/netmap.ko
At main.c:160:
- SSL error:02001002:system library:fopen:No such file or directory: bss_file.c:175
- SSL error:2006D080:BIO routines:BIO_new_file:no such file: bss_file.c:178
sign-file: certs/signing_key.pem: No such file or directory
  DEPMOD  4.15.0-72-generic
make[1]: Leaving directory '/usr/src/linux-headers-4.15.0-72-generic'
make -C e1000e install INSTALL_MOD_PATH= CFLAGS_EXTRA="-fno-pie -I/home/user/Downloads/netmap-master -I/home/user/Downloads/netmap-master/LINUX -I/home/user/Downloads/netmap-master/LINUX/../sys -I/home/user/Downloads/netmap-master/LINUX/../sys/dev -DCONFIG_NETMAP -Wno-unused-but-set-variable -g -DCONFIG_NETMAP_NULL -DCONFIG_NETMAP_PTNETMAP -DCONFIG_NETMAP_GENERIC -DCONFIG_NETMAP_MONITOR -DCONFIG_NETMAP_PIPE -DCONFIG_NETMAP_VALE -DNETMAP_DRIVER_SUFFIX=_netmap" NETMAP_DRIVER_SUFFIX=_netmap KSRC=/lib/modules/4.15.0-72-generic/build
make[1]: Entering directory '/home/user/Downloads/netmap-master/e1000e-3.6.0/src'
make[2]: Entering directory '/usr/src/linux-headers-4.15.0-72-generic'
  Building modules, stage 2.
  MODPOST 1 modules
make[2]: Leaving directory '/usr/src/linux-headers-4.15.0-72-generic'
gzip: ../e1000e_netmap.7: No such file or directory
Makefile:97: recipe for target 'manfile' failed
make[1]: *** [manfile] Error 1
make[1]: Leaving directory '/home/user/Downloads/netmap-master/e1000e-3.6.0/src'
netmap.mak:89: recipe for target 'install-e1000e' failed
make: *** [install-e1000e] Error 2
```
I'm trying to run a userspace IPv6 stack on top of netmap. ICMPv6 requires the stack to listen to various multicast groups (for neighbor discovery). It looks like just bringing up the interface in netmap mode is insufficient to receive these packets. Promiscuous mode seems overkill.

How do I make netmap subscribe to various multicast groups?
Remove peer in veth_netmap_krings_delete(vna) because without that
subsequent call of veth_netmap_krings_create(vna->peer) do not create rings.
Hi!
Got on starting pkt-gen with veth. Linux version: 4.19.69
```bash
[  681.083945] BUG: unable to handle kernel NULL pointer dereference at 0000000000000000
[  681.083952] PGD 417b70067 P4D 417b70067 PUD 3cd38d067 PMD 0 
[  681.083961] Oops: 0000 [#1] SMP NOPTI
[  681.083967] CPU: 5 PID: 4513 Comm: fwd Tainted: G           OE     4.19.69 #1
[  681.083970] Hardware name: MSI MS-7693/970A-G43 (MS-7693), BIOS V10.3 03/28/2013
[  681.083992] RIP: 0010:netmap_do_regif+0x1ab/0x390 [netmap]
[  681.083996] Code: 51 28 eb 17 8b b2 e0 00 00 00 85 f6 74 05 45 85 c0 75 21 83 c0 01 41 39 c1 76 71 83 ff 01 0f 84 96 01 00 00 48 8b 51 30 89 c6 <48> 8b 14 f2 f6 42 1c 02 74 d0 b8 10 00 00 00 8b 4b 08 85 c9 0f 85
[  681.084000] RSP: 0018:ffffba8185fabaf8 EFLAGS: 00010297
[  681.084004] RAX: 0000000000000000 RBX: ffffa0a898fef000 RCX: ffffa0a898fef000
[  681.084007] RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000
[  681.084010] RBP: ffffa0a88e12cd80 R08: 0000000000000000 R09: 0000000000000001
[  681.084012] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000001
[  681.084015] R13: 0000000000000001 R14: 0000000000000000 R15: ffffa0a898fef000
[  681.084019] FS:  00007fa7e0cf6740(0000) GS:ffffa0a89eb40000(0000) knlGS:0000000000000000
[  681.084022] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[  681.084025] CR2: 0000000000000000 CR3: 00000003cd516000 CR4: 00000000000406e0
[  681.084028] Call Trace:
[  681.084049]  netmap_ioctl+0xc63/0x12a0 [netmap]
[  681.084054]  ? __wait_on_bit+0x78/0x90
[  681.084055]  ? out_of_line_wait_on_bit+0x8e/0xb0
[  681.084058]  ? __kmalloc+0x1e3/0x220
[  681.084062]  netmap_ioctl_legacy+0x15c/0x5e0 [netmap]
[  681.084069]  netmap_ioctl+0xfa/0x12a0 [netmap]
[  681.084072]  ? task_work_add+0x3e/0x50
[  681.084077]  linux_netmap_ioctl+0xb0/0x160 [netmap]
[  681.084080]  ? mem_cgroup_commit_charge+0x83/0x160
[  681.084082]  ? lru_cache_add+0x5b/0x80
[  681.084084]  ? __handle_mm_fault+0xf3f/0x16e0
[  681.084086]  ? do_filp_open+0xa5/0x100
[  681.084089]  do_vfs_ioctl+0xa9/0x620
[  681.084091]  ksys_ioctl+0x60/0x90
[  681.084093]  __x64_sys_ioctl+0x16/0x20
[  681.084095]  do_syscall_64+0x5b/0x1a0
[  681.084098]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
[  681.084100] RIP: 0033:0x7fa7df98d2b7
[  681.084101] Code: 44 00 00 48 8b 05 b9 1b 2d 00 64 c7 00 26 00 00 00 48 c7 c0 ff ff ff ff c3 66 2e 0f 1f 84 00 00 00 00 00 b8 10 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 89 1b 2d 00 f7 d8 64 89 01 48
[  681.084102] RSP: 002b:00007ffd4fa85eb8 EFLAGS: 00000246 ORIG_RAX: 0000000000000010
[  681.084103] RAX: ffffffffffffffda RBX: 0000000000000003 RCX: 00007fa7df98d2b7
[  681.084104] RDX: 000000000071204c RSI: 00000000c03c6992 RDI: 0000000000000003
[  681.084105] RBP: 00000000c03c6992 R08: 0000000000000000 R09: 0000000000000000
[  681.084106] R10: 00007ffd4fa858e0 R11: 0000000000000246 R12: 000000000071204c
[  681.084107] R13: 00007fa7e04e37c0 R14: 0000000000000009 R15: 0000000000712010
[  681.084108] Modules linked in: veth(OE) netmap(OE) fuse ip6t_rpfilter ip6t_REJECT nf_reject_ipv6 xt_conntrack ip_set nfnetlink ebtable_nat ebtable_broute bridge stp llc ip6table_nat nf_nat_ipv6 ip6table_mangle ip6table_security ip6table_raw iptable_nat nf_nat_ipv4 nf_nat nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 libcrc32c iptable_mangle iptable_security iptable_raw ebtable_filter ebtables ip6table_filter ip6_tables sunrpc ufs edac_mce_amd kvm_amd ccp snd_hda_codec_realtek kvm snd_hda_codec_hdmi snd_hda_codec_generic snd_hda_intel snd_hda_codec snd_hda_core snd_hwdep irqbypass snd_seq crct10dif_pclmul crc32_pclmul pcspkr sp5100_tco snd_seq_device snd_pcm mxm_wmi ghash_clmulni_intel snd_timer i2c_piix4 snd k10temp fam15h_power pcc_cpufreq soundcore wmi binfmt_misc acpi_cpufreq radeon i2c_algo_bit
[  681.084138]  drm_kms_helper ttm drm ixgbe crc32c_intel ata_generic serio_raw pata_acpi 8139too r8169 8139cp mdio mii ptp pata_atiixp pps_core dca
[  681.084147] CR2: 0000000000000000
[  681.084148] ---[ end trace f04fadbd27318750 ]---
[  681.084154] RIP: 0010:netmap_do_regif+0x1ab/0x390 [netmap]
[  681.084155] Code: 51 28 eb 17 8b b2 e0 00 00 00 85 f6 74 05 45 85 c0 75 21 83 c0 01 41 39 c1 76 71 83 ff 01 0f 84 96 01 00 00 48 8b 51 30 89 c6 <48> 8b 14 f2 f6 42 1c 02 74 d0 b8 10 00 00 00 8b 4b 08 85 c9 0f 85
[  681.084156] RSP: 0018:ffffba8185fabaf8 EFLAGS: 00010297
[  681.084158] RAX: 0000000000000000 RBX: ffffa0a898fef000 RCX: ffffa0a898fef000
[  681.084187] RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000
[  681.084188] RBP: ffffa0a88e12cd80 R08: 0000000000000000 R09: 0000000000000001
[  681.084189] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000001
[  681.084190] R13: 0000000000000001 R14: 0000000000000000 R15: ffffa0a898fef000
[  681.084191] FS:  00007fa7e0cf6740(0000) GS:ffffa0a89eb40000(0000) knlGS:0000000000000000
[  681.084192] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[  681.084193] CR2: 0000000000000000 CR3: 00000003cd516000 CR4: 00000000000406e0
```
I would like to get virtio building. I am building against 4.4.184.

I'm on a build of netmap from April (https://github.com/luigirizzo/netmap/commit/597f602). The virtio patch has not changed since then, so currently there is no reason to expect latest master to fix this (as far as I can tell).

It seems more likely that 4.4.184 isn't supported - this is a problem for me because because 4.4 is long-term support - it will be difficult to move to another kernel version. For that reason I would like to be _sure_ what the problem is first.

I get this error:

```
********************************** WARNING **********************************
*** There were problems building the external driver virtio_net.c.
***
*** Please note that this is not related to the netmap patches,
*** that were not applied.
***
*** Disabling virtio_net.c.
```

I have attached config.log - maybe that will help confirm the issue.

If you could give me some ideas, that'd be great. I may have to take the performance hit and stay with emulated drivers.

[config.log](https://github.com/luigirizzo/netmap/files/4003557/config.log)

Update: I tried master and it did not correct the issue.


I am using real tek NIC r8169. 
I cloned this repo and tried to build it, "./configure & make"
got the following warning:
```
********************************** WARNING **********************************
*** 'r8169.c': sources not found.  Disabling driver.
*****************************************************************************
```

Wonder how to fix it.

Thanks

Hi there! I want to use it for faster NAT perfomance (and of course reduce the CPU load)
We are using VLANs. Can i setup VLANs via
`ip link set eth6 vf 0 mac 90:e2:ba:55:aa:bb
`
and after creating new virtual eth10 interface do 
```
ip link add link eth10 name vlan100 type vlan id 100
ip link add link eth10 name vlan200 type vlan id 200
ip a add dev vlan100 10.0.0.1/16
ip a add dev vlan200 Y.Y.Y.Y/30
```
and then use simple rule
`iptables -t nat -A POSTROUTING -s 10.0.0.0/16 -o vlan200 -j SNAT --to-source Y.Y.Y.Y
`
Will it add performance?
Thank you!
Hello,

I've been having an issue with Netmap in generic/qdisc mode on Linux where it will spontaneously stop making space available on the output rings. The input rings continue receiving packets. What's peculiar about this bug is that I have 3 separate processes using 3 different rings on the same interface. All 3 encountered this issue within the same second. They work fine until throughput reaches some threshold, and then the output rings seem to stop advancing.

Before the issue starts, `nm_ring_space()` reports somewhere between 1020 and 1023 available slots. Once the issue starts, the available space quickly drops to 0 and never recovers. All 3 processes see this behavior at the same time. The processes have the `CAP_NET_ADMIN` capability set with `setcap`. There is nothing from netmap in the syslog when this occurs.

I'm not entirely sure what specifically triggers this behavior. I've so far only seen it when running an application that makes use of netmap. I've tried creating a synthetic test to reproduce it but haven't had luck yet, but my application does so fairly consistently.

Do you have any ideas on what might cause this behavior or how I could diagnose it?

Thanks!
ixgbe igb ..... disabled
Dear maintainers,

we are building a high-throughput application (build on top of [blockmon](https://github.com/sysml/blockmon)) to monitor real-time traffic from a large network. For this purpose we have servers with different hardware configurations, and after many hours of testing we came to the conclusion that the network card is 1:1 correlated to the performance (in terms of packet loss) of both our application and the reference pkt-gen. The obvious point here is the chipset of these cards - we suspect it to be responsible for the differences in performance. We tested the following ixgbe-driven Intel NICs:

- Intel X540-AT2: copper, released Q1 2012, PCIe 2.1, controller X540
- Intel X550-T2: copper, released Q1 2016, PCIe 3.0, controller X550
- Intel X520-SR2: fiber, released Q3 2009, PCIe 2.0, controller 82599 (we have tested both an Intel and HPE version of this)

The thing that brought us on track are onboard NICs in our servers, which performed much better than the PCIe cards. After suspecting the bus at first (see e.g. [#336](https://github.com/luigirizzo/netmap/issues/336)), we acquired an "external" X540-AT2 and were able to attain perfect performance with that one (setup below). This lead us to the conclusion above with the chipset being the main culprit.
Another thing to keep in mind is that all of these cards are dual port cards, even the design of the internal NICs.

Some more information about our setup, in case it is of relevance:
- 3 queues (`RSS=3,3`)
- ring size to 2048 (`ethtool -G $if rx 2048`)
- local loopback and server-spanning (meaning different servers sending and receiving) setups
- at least 20 CPU cores (*tested on different servers*)
- at least 100GB RAM (*tested on different servers*)
- KVM and bare metal
- Linux 3.10.0-957 on CentOS 7 and RHEL 7 (superficial tests done on Debian 9 indicating same results)
- ixgbe 5.5.2
- tested with `pkt-gen` with randomized source addresses and ports (`-z`); together with the drivers hash filter this leads to even distribution over all rings
- netmap commit 97f4fdf3fceaab1acfc2a9a6f20968ca0844a142 (for the sake of deployment scripts and reproducibility this is a fixed commit)
- flow control disabled due to the way our application works; this way we achieve maximum line speed (~14.8Mpps with 60 byte per packet). If we enable flow control, we maintain optimal (=0) packet loss at the cost of transmission speed.

We are wondering now if these results indicate an issue with ixgbe interfacing with certain chipsets or if we simply hit a hardware limitation; also, why the magic number of 3 rings seems to yield optimal results. Do you have any insights into this?

If you think this issue is not relevant for the netmap project, feel free to close this issue and consider it as an information for others running into similar problems. 