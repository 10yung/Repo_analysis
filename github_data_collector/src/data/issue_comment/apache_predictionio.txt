Bumps [excon](https://github.com/excon/excon) from 0.45.1 to 0.71.0.
<details>
<summary>Changelog</summary>

*Sourced from [excon's changelog](https://github.com/excon/excon/blob/master/changelog.txt).*

> 0.71.0 2019-12-12
> =================
> 
> fix for leftover data with interrupted persistent connections
> 
> 0.70.0 2019-12-02
> =================
> 
> Update bundled certificates
> 
> 
> 0.69.1 2019-11-21
> =================
> 
> Fix mistake in proxy connection error handling
> 
> 0.69.0 2019-11-21
> =================
> 
> Raise better proxy connection errors
> 
> 0.68.0 2019-10-25
> =================
> 
> Updated bundled certs
> 
> 0.67.0 2019-09-24
> =================
> 
> Properly redact user/pass info from proxy credentials
> Update bundled certs
> 
> 0.66.0 2019-08-06
> =================
> 
> Add remote_ip to datum, enabling usage in middleware
> redirect follower now raises after following too many redirects (default 10)
> fixed stub clearing in tests to avoid race conditions
> 
> 0.65.0 2019-07-22
> =================
> 
> fix yardoc formatting
> fix creating Proc without a block
> reduce/refine gem file contents
> update bundled certs
> readd bundled certs to gem file contents
> 
> 0.64.0 2019-04-15
> =================
></tr></table> ... (truncated)
</details>
<details>
<summary>Commits</summary>

- [`1149d44`](https://github.com/excon/excon/commit/1149d44d921660bcde5e21671e6a10346d177f33) v0.71.0
- [`ccb57d7`](https://github.com/excon/excon/commit/ccb57d7a422f020dc74f1de4e8fb505ab46d8a29) fix for leftover data with interrupted persistent connections
- [`f8de8cf`](https://github.com/excon/excon/commit/f8de8cf63e789ff9329a13756bfb51364abe107a) v0.70.0
- [`93f4a21`](https://github.com/excon/excon/commit/93f4a214271df3b543ac4f4d1444d80ea2d75a01) v0.69.1
- [`e89bbb7`](https://github.com/excon/excon/commit/e89bbb718bb67972e2e08109fb4c1edd09568cd5) Merge pull request [#709](https://github-redirect.dependabot.com/excon/excon/issues/709) from jasquat/fix_response_status_check
- [`5647437`](https://github.com/excon/excon/commit/56474377bea9fdda2e07f52c169f4500e8c2be36) fixed response status check when making a request with a valid proxy is set
- [`f769176`](https://github.com/excon/excon/commit/f7691760969e74b6facaedd0a80ccef01709d428) v0.69.0
- [`20c0748`](https://github.com/excon/excon/commit/20c0748f2cfdd78a5f5b23057ad538240c372344) define ProxyConnectionError
- [`f44106a`](https://github.com/excon/excon/commit/f44106afd686d6eda076c0b92182f3df60e37f34) raise on failed proxy connect
- [`d7ed5fe`](https://github.com/excon/excon/commit/d7ed5fe894fb696fddb5f28c454c949d3c1116d9) be thorough in unsubscribing to notifications in instrumentation tests
- Additional commits viewable in [compare view](https://github.com/excon/excon/compare/v0.45.1...v0.71.0)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=excon&package-manager=bundler&previous-version=0.45.1&new-version=0.71.0)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/predictionio/network/alerts).

</details>
pio-docker to identify container by image id
described in docker/docker-compose.yml
**This PR is not ready for review until related PR #516 is merged.**


before:
Spark 2.1.3

after:
Spark 2.4.3
added description of the commandline and examples

I'm considering about incorporate the official templates with main repository to reduce maintenance costs of them. My idea is:

- Check versions of PredictionIO/Scala/Spark/etc by TravisCI using a shell script and if these versions are not same among PredictionIO and templates, test will fail.
- Include the official templates and examples in the distribution which is made by `make-distribution.sh`.
- Documentations which refer these templates or examples will be fixed to be started from:
   ```
   $ cd $PIO_HOME/templates/template-scala-parallel-recommendation
   $ pio build
   ...
   ```
   instead of:
   ```
   $ git clone https://github.com/apache/predictionio-template-recommender.git
   $ cd predictionio-template-recommender
   $ pio build
   ...
   ```
Currently, for every release, we have to update versions of PredictionIO/Scala/Spark/etc, then create tag for each template repository by hand. If the official templates are in the same repository with PredictionIO itself, we will be able to finish this boring operation at once. Also, it will ensure that all official templates is synchronized with the latest PredictionIO version.

Adds missing articles and tweaks grammar.
Adds missing articles and tweaks the grammar.
I tried to leverage the already present async interface of elasticsearch and armouring the HBase and JDBC call with blocking constructs which will tell the standard scala ExecutionContext to use a separate thread for that.

Let me know what you think.

See https://issues.apache.org/jira/browse/PIO-193
and 
https://lists.apache.org/thread.html/f14e4f8f29410e4585b3d8e9f646b88293a605f4716d3c4d60771854@%3Cuser.predictionio.apache.org%3E
and also https://jira.apache.org/jira/browse/PIO-182
for more details

See also https://github.com/actionml/universal-recommender/pull/62 for corresponding UR PR
Fixes [PIO-138](https://issues.apache.org/jira/browse/PIO-138)

Switches batch query processing from Spark RDD to a Scala parallel collection. As a result, the `pio batchpredict` command changes in the following ways:

* `--query-partitions` option is no longer available; parallelism is now managed by Scala's [parallel collections](http://docs.scala-lang.org/overviews/parallel-collections/overview.html)
* `--input` option is now read as a plain, local file
* `--output` option is now written as a plain, local file
* because the input & output files are no longer parallelized through Spark, memory limits may require that large batch jobs be split into multiple command runs.

This solves the root problem that certain custom PersistentModels, such as [ALS Recommendation template](https://github.com/apache/incubator-predictionio-template-recommender), may themselves [contain RDDs](https://github.com/apache/incubator-predictionio-template-recommender/blob/develop/src/main/scala/ALSModel.scala#L27), which cannot be nested inside the batch queries RDD. (See [SPARK-5063](https://issues.apache.org/jira/browse/SPARK-5063))