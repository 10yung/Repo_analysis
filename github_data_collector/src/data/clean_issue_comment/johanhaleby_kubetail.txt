With that change and a following kube config context namespace dev name dev context namespace prod name prod all calls to kubetail below will work and yield the same result kubetail context prod kubetail n prod context prod kubetail context prod n prod Hi there Not sure if thats the intended behaviour but presently if I pass context and that context has a namespace attached to it in my kube config file I wont be able to tail anything as it wont get the specific namespace of that context it will set the namespace of the currentcontext no matter what My configuration is something like that context cluster cluster com namespace dev user usercluster com name dev context cluster cluster com namespace prod user usercluster com name prod currentcontext dev When running the following with kubetail version kubetail oauth context prod returns No pod exists that matches oauth However running kubetail oauth context prod n prod returns all the logs expected Ive looked into the script and while Im not an expert in bash I think its due to the method calculatedefaultnamespace which doesnt get passed the context option if one is given to the kubetail command thus grabbing the namespace of the currentcontext every time that function is ran Happy to help if needed If you call kubetail from a script it will kill the script when its done sh c echo shell pid kubetail k false f false s s devnull echo foo shell pid terminated sh c This forces the user to trap TERM to avoid failure during successful execution and consequently messes up signal handling in that script which wont die when sent TERM from elsewhere See we tried kubetail j pod n namespace we get backend is not defined at toplevel line as line try fromjson pod name catch line Am i calling this correctly Our logs for a particular service output as json Hi Thanks for your great product But it has some misses which seem really useful For example grep option which there is a pull request which adds this feature And another essential feature is some option that helps me to get all log of the pods not from now on I mean not applying tail option Can you add this feature too Hello I have multiple cluster and for safety reason I use a different kubeconfig file in order to avoid doing harm to my production cluster I would love to see some support for kubeconfig instead to realy on the default kubeconfig Thanks for this Search Pod in all namespaces Search Pod in all namespaces and ignore some Search Pod in defined namespaces Search Logs or Exclude Logs TODO Adding GREP options for search or exclude some logs state POC TODO export to a file TODO export to rsyslog TODO export as json Plz review and feedback A subshell now checks for matching pods every second and pipes a new list of pods if changes Pipe is being listened on by main every time a new list of pods comes through tails get remade issues new pods appearing are still in initializing state and should not be picked up by subshell pipe tmpkubetailmatchingpodspipe can be used for arbitrary code execution dont like the kill t colours of existing pods shouldnt change when the list of pods changes 