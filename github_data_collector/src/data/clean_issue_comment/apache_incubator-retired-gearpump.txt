Be sure to do all of the following to help us incorporate your contribution quickly and easily Make sure the commit message is formatted like GEARPUMPJira issue Meaningful description of pull request Make sure tests pass via sbt clean test Make sure old documentation affected by the pull request has been updated and new documentation added for new functionality Be sure to do all of the following to help us incorporate your contribution quickly and easily Make sure the commit message is formatted like GEARPUMPJira issue Meaningful description of pull request x Make sure tests pass via sbt clean test Make sure old documentation affected by the pull request has been updated and new documentation added for new functionality R huafengw This is work in process and even doesnt compile breaking RemoteMaterializerImpl The motivation is to make user application even simpler from scala val context ClientContextakkaConfig val app StreamAppname context val runningApplication contextsubmitapp contextclose to scala val app StreamAppname akkaConfig creates ClientContext val runningApplication RunningApplication apprun invokes contextsubmitapp and address the following issues I find One subtlety in the current way is StreamApp is implicitly converted to StreamApplication for contextsubmit It can be broken if a user forgets to import the conversion and user doesnt know where it is I find it difficult to explain the usage of class StreamAppname String system ActorSystem userConfig UserConfig private val graph Graph Op OpEdge Wed better make the constructor private if its not intended for users Both RunningApplication and ClientContext have a askAppMaster method to query application status How should their roles be divided RunningApplication has no ScalaDoc One downside about the new way is we cant close ClientContext and its underlying ActorSystem Is it a big problem Still implementing upstream downstream access but the flow is now working Cassandra database integration X CassandraSource X CassandraSink X CassandraStore Reuses some SparkCassandra connector files and follows how that works The intent is to allow the connector to be reused when version for other processing systems is available The Source looks up token ranges in the desired table splits to independent sets of partitions and assigns those to available number of source tasks allowing very good parallelism All fetches of data except the first one are asynchronous The Sink can be trivially parallelised by the user where different writes are assigned to different tasks The Source scans a current table snapshot and does not currently honour updates so not a continuous stream The source is not time replayable There are options how to handle both these but must be properly thought through The test coverage is poor at the moment but this first attempt will allow iteration and continuous improvement of the code and adding features GEARPUMP The time interval rotation will rolling out a new file when time interval get the limit GEARPUMP Storm has been released with a lot of changes We need to upgrade our support for Storm to x Redis redisio is a hight performance in memory storage and have widely used in a lot of project Its should support redis as DataSource and DataSink 