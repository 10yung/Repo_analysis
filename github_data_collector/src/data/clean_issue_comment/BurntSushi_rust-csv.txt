This is important to justify the use of unsafe when reading StringRecords Theoretically if there were no performance difference between doing two UTF validity checks versus doing only one then unsafe could be avoided Its quite unlikely that this difference cannot be observed but Ive been wrong before See for more discussion When reading CSV files without a special header row the line number of each record is inaccurate As a sidenote the documentation for Positionline is a bit unclear whether line numbers are counted relative to the first line in the fileinput stream or relative to the first valid record or to some other reference frame Regardless of the interpretation the reported line number is still inaccurate What version of the csv crate are you using however this problem occurs in version Rust Stable OS Windows if that information is useful Briefly describe the question bug or feature request When reading a CSV file without a special header row ie using ReaderBuilderhasheaders set to false the line number reported by Positionline of each record after the first one is off by one as if the first record failed to get counted Include a complete program demonstrating a problem mainrs rust fn main let mut rb csvReaderBuildernew hasheadersfalse frompathcsvcsv unwrap for entry in rbrecords let record entryunwrap println recordpositionunwrapline csvcsv expectline expectline expectline expectline expectline What is the observed behavior of the code above Output What is the expected or desired behavior of the code above Expected output What version of the csv crate are you using Briefly describe the question bug or feature request When writing a program that does validations on deserialized data I would like to be able to access position information after deserialization Include a complete program demonstrating a problem rust struct PositionedT pub position csvPosition pub value T implT PositionedT pub fn mapUself f impl FnOnceT U PositionedU Positioned position selfposition value fselfvalue deriveStructOpt struct Options TSV files of simple rules with one rule per line structoptname FILES parsefromosstr files VecPathBuf fn main anyhowResult let opts Options Optionsfromargs let mut rules vec for path in optsfiles let mut reader csvReaderBuildernewdelimiterb tfrompathpath let headers readerheadersclone for record in readerrecords let record record let position recordpositionexpectLost CSV positionclone let value recorddeserializeRuleSome headers rulespushPositioned value position I WOULD LIKE TO DO VALIDATIONS HERE AND SURFACE POSITIONS ON THE ERRORS let compiled rules intoiter mapv vmapruleCompiledRulefrom collectVec let mut writer csvWriterBuilderdefault hasheaderstrue fromwriterstdiostdout for rule in compiled writerserializerulevalue Ok What is the observed behavior of the code above Not relevant in this case What is the expected or desired behavior of the code above In the validation code Id like to write something that runs validations and returns a VecDiagnostic where each Diagnostic has a message and a position property A spanlike thing would also work well Other Notes I created something similar for darling here However in that case I controlled the traits so Im not sure how much of that is relevant here I also saw that dtolnay did something like this for toml but after reading his example I struggled to understand how Id apply it to CSV More sketching around I found out that once onlycomplete is there a method to get a mutable reference to the inner reader will be helpful it allows one to implement a feeder pattern demonstrated by testchunks of teststestchunksrs This will allow incremental parsing without having to scrap and rebuild Reader for every chunk With these changes incremental parsing would be if not easy at least a lot easier than before I sketched a bit with the completeonly API idea I presented here What do you think What version of the csv crate are you using name csv version Briefly describe the question bug or feature request Hi this is not a bug request but just a question about the usage patterns Im dealing with streaming IO and Ive got my CSV parsing logic in a function that is repeatedly called with new chunks of data Ive encountered the following problems Repeatedly constructing new Readers from the input slices resets the parsing all info about headers etc is lost On exhausting the end of the input slice Id rather revert parsing to last complete record and return the unparsed input to be chained as a reader with the next chunk instead of trying to parse the final record and possibly missing the end of it So my question is are the current APIs intended to accomodate for this chunked incremental use case and Im just failing to find the correct knobs and patterns or Im I trying to use the csv crate for something it wasnt originally meant for Would it be possible to add APIs or documentation that made this easier Include a complete program demonstrating a problem What is the observed behavior of the code above Parse chunk Chain t u Got record ByteRecord aaaa bbbb cccc Got record ByteRecord aaaa bbbb cc Done Unparsed Parse chunk Chain t u Done Unparsed Parse chunk Chain t u Done Unparsed Parse chunk Chain t u Done Unparsed Parse chunk Chain t u Got record ByteRecord aaaa bbbb cccc thread main panicked at called Resultunwrap on an Err value ErrorUnequalLengths pos SomePosition byte line record expectedlen len srclibcoreresultrs note run with RUSTBACKTRACE environment variable to display a backtrace What is the expected or desired behavior of the code above Parse chunk Chain t u Got record ByteRecord aaaa bbbb cccc Done Unparsed Parse chunk Chain t u Got record ByteRecord aaaa bbbb cccc Done Unparsed Parse chunk Chain t u Done Unparsed Parse chunk Chain t u Got record ByteRecord aaaa bbbb cccc Done Unparsed Parse chunk Chain t u Got record ByteRecord aaaa bbbb cccc Got record ByteRecord aaaa bbbb cccc Done Unparsed Parse chunk Chain t u Got record ByteRecord aaaa bbbb cccc Done Unparsed See title Closes My concerns Cargotoml took a beating with required features Doc comments with serde are ugly I think is fine but feels awful What version of the csv crate are you using Briefly describe your feature request I have a program that parses a CSV file with many columns only some of which are relevant to any given run of the program Here is a cutdown example CSV file the real thing has many more rows and also many more columns labeled with uppercase threecharacter codes csv addridlongitudelatitudeABWAFGAGOAIAALA On each run of the program it wants to deserialize addr longitude latitude and one of the columns labeled with a threecharacter code into this structure rust struct HostRecord addr IpAddr longitude f latitude f distance f The catch is that which of the threecharactercode columns should be deserialized into the distance field varies at runtime There doesnt seem to be any way to make Serde do that There also doesnt seem to be any way to extract a subset of the fields from a StringRecord or BytesRecord by name The best I have managed to do is scan the headers record manually for each relevant field make note of their indices and then manually extract each field by index as shown below Its tedious to write and easy to screw up Include a complete program demonstrating a problem rust struct CSVColumns addr usize longitude usize latitude usize distance usize Error type for selectcolumns deriveDebug Fail faildisplaymissing columns struct MissingColumnsErrorString fn selectcolumnsheader csvStringRecord loc str ResultCSVColumns MissingColumnsError let mut addr Optionusize None let mut longitude Optionusize None let mut latitude Optionusize None let mut distance Optionusize None let mut wanted for index field in headeriterenumerate match field addr addr Someindex wanted longitude longitude Someindex wanted latitude latitude Someindex wanted f if f loc distance Someindex wanted if wanted break if wanted OkCSVColumns addr addrunwrap longitude longitudeunwrap latitude latitudeunwrap distance distanceunwrap else let mut missing Vec str Vecwithcapacity if addrisnone missingpushaddr if longitudeisnone missingpushlongitude if latitudeisnone missingpushlatitude if distanceisnone missingpushloc ErrMissingColumnsErrormissingjoin fn loadhostsfname Path loc str ResultVecHostRecord Error use stdstrfromutf let mut fp Fileopenfname let mut rd csvReaderBuildernew hasheaderstrue trimcsvTrimAll fromreaderfp let cols selectcolumnsrdheaders loc Dont bother doing UTF validation on the columns were not interested in let mut row csvByteRecordnew let mut v VecHostRecord Vecnew while rdreadbyterecord mut row vpushHostRecord addr fromutf row colsaddr parse longitude fromutf row colslongitude parse latitude fromutf row colslatitude parse distance fromutf row colsdistance parse Okv What is the expected or desired behavior of the code above The above code does work its just that there should be a better way to write it Off the top of my head a plausible better way would be a Reader method findcolumns that tells you the indices for a set of column names allowing me to dispense with selectcolumns and write something like this instead rust fn loadhostsfname Path loc str ResultVecHostRecord Error use stdstrfromutf let mut fp Fileopenfname let mut rd csvReaderBuildernew hasheaderstrue trimcsvTrimAll fromreaderfp findcolumns fails if any columns are missing or produces a HashMap a str usize mapping column names to indices let cols rdfindcolumns addr latitude longitude loc Dont bother doing UTF validation on the columns were not interested in let mut row csvByteRecordnew let mut v VecHostRecord Vecnew while rdreadbyterecord mut row vpushHostRecord addr fromutf row cols addr parse longitude fromutf row cols longitude parse latitude fromutf row cols latitude parse distance fromutf row cols loc parse Okv A further improvement would be a way to ask the reader to return only the desired columns from each row which would both speed up parsing since only those columns would need to be copied and UTF validated and enable use of serde again rust fn loadhostsfname Path loc str ResultVecHostRecord Error use stdstrfromutf let mut fp Fileopenfname csv does its own buffering no need for a BufReader let mut rd csvReaderBuildernew hasheaderstrue trimcsvTrimAll fromreaderfp findcolumns fails if any columns are missing or produces a HashMap a str usize mapping column names to indices let cols rdfindcolumns addr latitude longitude loc let mut row csvStringRecordnew let mut v VecHostRecord Vecnew while rdreadcolumns mut row cols vpushrowdeserializeHostRecord Okv Currently the Serde deserializer in this crate hardcodes specific nullable semantics Namely only fields with an empty value are considered missing But it is fairly common in CSV formats to use other sentinels such as null even for otherwise nonString fields It should be possible to augment ReaderBuilder to permit the caller to provide a predicate that determines whether a field value is missing or not Once we have the predicate it should be as simple as plumbing it through and calling it in deserializeoption See also for motivation