In the Dockerfile there is a line which defines two volumes Without specifying a volume in the run command these volumes arent easily accessible to the end user I believe v options need to be added in the sample run command Tracking issue Previously requested with js PUT classLevelPermissions getfindcountupdatedeleteaddField true Public access set by default objectId true by id of User roleadmin true by role rolerolename requiresAuthentication true only authenticated users pointerFields fieldname fields of type PointerUser or PointerUser readUserFields fieldname same as pointerFields for getfindcount writeUserFields fieldname same as pointerFields for updatedeleteaddField Pointer permissions for create has no effect addField accounted only on updating object ignored when creating When set for an operation js classLevelPermissions operation pointerFields field default Public removed no other rules set Operation user not pointed by field user is pointed by field get Object not found ok find Limited results ok count Limited count ok create Permission denied Permission denied update Object not found ok delete Object not found ok addField Permission denied ok Is your feature request related to a problem Please describe As of now its impossible to set finegrained pointer permissions in CLP Was previously requested and Ill track progress here This involves server implementation dashboard update docs update parsecommunitydocs Previously i was using PFFacebookUtils to loginsignup in app using users Facebook but somehow PFFacebookUtils stopped working in my app due to clash with other libraries So i moved to actual Facebook login Now all working fine here when user signed uplogin using facebook SDK and then after searching in Parse server am logging the user in using username and password Now the issue is how to login the previously added user which was logged in using PFFacebookUtils through simple parse method logInWithUsername and password I cant find users password in parse User class Any help would be much appreciated Thanks The dependency mongodb was updated from to This version is not covered by your current version range If you don t accept this pull request your project will work just like it did before However you might be missing out on a bunch of new features fixes andor performance improvements from the dependency update Publisher mbroadst License Apache details summaryRelease Notes for v summary pThe MongoDB Nodejs team is pleased to announce version of the driverp h Release Highlightsh h CMAPcompliant Connection Poolh pThis release introduces a modern replacement for the drivers connection pool available only with thebr unified topology A major effort was made in early to fully specifiy connection pools for MongoDBbr drivers see a href specificationa and this release brings the Nodejs driver in line with thatbr specificationp h Traceabilityh pThe new pool supports monitoring for all aspects of its behavior This allows deep introspection intobr the operation of the connection pool as well as an ability to profile the lifetime of an operationbr when used in conjunction with command monitoringp h Streamfirst Connection Designh pThe codeConnectioncode class was completely rewritten for the new pool adopting a streamfirst mentality Allbr wire message processing and compression is handled in a duplex stream called the codeMessageStreamcode andbr that stream is connected bidirectionally to the underlaying TCP socket The result is a connection whichbr gains the general benefit of streams better performance less memory pressure backpressure support Itbr also opens the possiblity of supporting nonTCPUDP streams as a transport for the driverp h waitQueueTimeoutMSh pThe new connection pool has a concept of a wait queue which allows operation requests to buffer waitingbr for a connection to execute against There is no timeout by default but users can now specify a new valuebr codewaitQueueTimeoutMScode in their connection string or codeMongoClientcode options to proactively cancel operationsbr that have waited too longp pRemember that the new connection pool is only available for the Unified Topology so remember to passbr codeuseUnifiedTopology truecode to your codeMongoClientcode constructor to use itp h Dedicated monitoring threadh pBoth the legacy and unified SDAM implementations have until now executed monitoring checks as prioritybr messages in the legacy Pool implementation This means that monitoring codeismastercode operations werebr prioritized over other queued operations but also means that monitoring could be indefinitely blockedbr in particular during failover or blackhole scenarios The default socket timeout is codenullcode read Infinitybr so if the pool was completely saturated with operations there may be no ability to execute a monitoringbr check and determine that the connection to a server was no longer valid This version of the driverbr introduces a new codeMonitorcode class which manages its own dedicated monitoring socket to each knownbr nodep h Server selection errorsh pIn v of the driver we introduced a new codeMongoTimeoutErrorcode for all errors covered by the serverbr selection loop leading to a spike in bug reports with a title similar to codeServer selection timed out after mscodebr Even though the error type itself had an attached codereasoncode field we still feel it was easy to miss whybr the selection had failed As a result we have introduced a new type codeMongoServerSelectionErrorcode whichbr will use the originating error codereasoncode for its message better informing users what caused abr selection error while still also conveying it is an error in server selectionp h Release Notesh h New Feature h ul li a href relnofollowNODE a Implement Connection Monitoring and Pooling spec li li a href relnofollowNODE a Use a dedicated monitoring thread li ul h Bug h ul li a href relnofollowNODE a Synchronous errors are swallowed by executeOperation li li a href relnofollowNODE a Server descriptions with me mismatch from primary response should be removed li li a href relnofollowNODE a client platform not sent in metadata for CMAP connections li ul h Improvement h ul li a href relnofollowNODE a Remove wasteful empty Buffer allocations in Connection li li a href relnofollowNODE a Add connectionError as a valid reason for a ConnectionCheckOutFailedEvent when connection set up fails li li a href relnofollowNODE a Make server selection errors more informative li li a href relnofollowNODE a Integrate CMAP connection pool into unified topology li li a href relnofollowNODE a Improve traceability of CMAP events li li a href relnofollowNODE a Ignore ConnectionReadyEvent in CMAP pool creation test li ul details details summaryCommitssummary pThe new version differs by commitsp ul lia href codechorerelease codeli lia href codechore codewaitQueueTimeoutMScode is a valid connection string optioncodeli lia href coderefactor wait until server destroyed before stopping event relaycodeli lia href codedoc add basic documentation for CMAP event monitoringcodeli lia href coderefactor dont encode type name into public CMAP event typescodeli lia href codefeat relay all CMAP events to MongoClientcodeli lia href coderefactor warn on use of deprecated SDAM events in unified modecodeli lia href codetest reduce flakiness of objectid test which checks by timecodeli lia href codedoc add documentation for CMAP events and errorscodeli lia href codefeat include codeconnectionIdcode for APM with new CMAP connection poolcodeli lia href codetest ignore ismaster events in change streams spec testscodeli lia href codetest allow all test files to use custom chai mongodb spec matchercodeli lia href codefix report the correct platform in client metadatacodeli lia href codeRevert fix remove servers with me mismatch in codeupdateRsFromPrimarycodecodeli lia href codeRevert test include auth information in generated test connection stringcodeli ul pThere are commits in totalp pSee the a href diffap details details summaryFAQ and helpsummary There is a collection of frequently asked questions If those don t help you can always ask the humans behind Greenkeeper details Your Greenkeeper bot palmtree We use GitHub Issues for reporting bugs with parseserver If you have a question you should join the Parse Communitys Discourse forum If you have a vulnerability disclosure please follow our policy available here You may also search through existing issues before opening a new one Please use this template If you dont use this template your issue may be closed without comment Issue Description Describe your issue in as much detail as possible The ParseObject returned by LiveQuery events gives Date in String format instead of Date format Problem seem to specifically pertain to Update events Strangely some Date fields are returned in Date format while some are returned in String format I have tried several ParseServer versions and with the exception of version all other versions and seem to have this problem PS I am aware that special fields like updatedAt and createdAt return String values I was referring to custom Date fields created by me Note I am using Back App which is a backendasaservice built on Parse Steps to reproduce Codes in Android client ParseQueryParseObject liveQuery ParseQuerygetQueryQueueGP liveQuerywhereEqualToclinic clinicId SubscriptionHandlingParseObject subscription parseLiveQueryClientsubscribeliveQuery subscriptionhandleEventsnew SubscriptionHandlingHandleEventsCallbackParseObject Override public void onEventsParseQueryParseObject query SubscriptionHandlingEvent event ParseObject parseObject ifevent SubscriptionHandlingEventUPDATE Date registeredAt parseObjectgetDateregisteredAt Please include a detailed list of steps that reproduce the issue Include curl commands when applicable Expected Results What you expected to happen onEvent from ParseLiveQueryClient seen in verbose in my logs Socket onMessage opupdate registeredAttypeDateiso T Z Expected to see Date and iso and parseObjectgetDateregisteredAt should contain date value Actual Outcome What is happening instead No Date or iso seen registeredAt T Z In actual parseObjectgetDateregisteredAt gives null value while parseObjectgetregisteredAt gives value of String type Environment Setup Server parseserver version Be specific Dont say latest Operating System Handled by back app Hardware Handled by back app Localhost or remote server AWS Heroku Azure Digital Ocean etc Handled by back app Database MongoDB version Handled by back app Storage engine Handled by back app Hardware Handled by back app Localhost or remote server AWS mLab ObjectRocket Digital Ocean etc Handled by back app LogsTrace Include all relevant logs You can turn on additional logging by configuring VERBOSE in your environment Sourcefile Function name parseAggregateArgs The purpose of the function is to recursively traverse the pipeline and convert any Pointer or Date columns But it can only recognize existing fields defined in the collection schema If we create a new Data field in project stage it can not recognize it and the query wont work Examples any match on startTime will work but not on endTime which is generated in project stage var pipeline match puser UseruserId project puser startTime endTime add startTime multiply duration startTime can be recognized as Date type thus the query will work match startTime gt new Date endTime can not be recognized as Date type any query on endTime will fail match endTime gt new Date limit Is your feature request related to a problem Please describe Currently when saving files the only thing you can set is the data itself and the file name The ability to add additional metadata and tags specifically with S would be a great feature add Describe the solution youd like Being able to pass in a metaData andor tags key to the options object when saving a file These two values would be sent to S along with the file data Also if support for beforeSaveFile and afterSaveFile are implemented these metaData and tag values could be set there too This would make it possible for things like deleting all files a user created once their account is deleted etc Describe alternatives youve considered None Additional context I have no problem adding this along with if the community will accept the changes Is your feature request related to a problem Please describe Currently there is zero authentication or customization of files via hooks Describe the solution youd like Just like we have beforeSave afterSave etc for Objects Having the ability for beforeSaveFile afterSaveFile etc would allow for different authentication validations file name changes meta data etc when saving files This would allow the ability to implement a file tracking class that would then allow for easily deleting files from file storage when theyre no longer needed Describe alternatives youve considered building my own middleware in front of Parse Additional context I have no problem building this 