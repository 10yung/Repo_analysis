Hi Im trying to use Kamon with Prometheus reporting in my Akka application Im not seeing any akka metrics being published my pom dependency groupIdiokamongroupId artifactIdkamoncore artifactId version version dependency dependency groupIdiokamongroupId artifactIdkamonakka artifactId version version scoperuntimescope dependency dependency groupIdiokamongroupId artifactIdkamonsystemmetrics artifactId version version scoperuntimescope dependency dependency groupIdiokamongroupId artifactIdkamonprometheus artifactId version version scoperuntimescope dependency dependency groupIdiokamongroupId artifactIdkanelaagentartifactId version version scopeprovidedscope dependency dependency groupIdiokamongroupId artifactIdkamonlogback artifactId version version scoperuntimescope dependency Documentation suggests all I need to do is Kamoninit but Prometheus scrape does not include akka metrics Kamon Status page doent no anything about them either Kamon What am I missing The kamonjmx artifact seems to be no longer maintained so I cannot use it with Scala Is there any currently working JMXReporter kamonKamoncounterfoo causes a classloader leak in playframework when using the dev workflow with run Heres a minimal project with instructions to reproduce the issue My setup Linux openjdk version scala playframework sbt edit Same issue on playframework side At some point when we started Kamon we had a single repository with all the code in there It was convenient to have everything on the same place but for reasons that I really cant remember at the moment we started splitting instrumentation and reporters into dedicated repositories Funny thing is that somehow we went back to that with the kamonbundle not by joining repositories but by putting all dependencies back into a single package that people can reference with a single version number Some of the pain points coming up often are Users constantly complain about different Kamon components having different versions This got a bit better with the bundle but I still see examples of people using the same Kamon version variable for all their dependencies and missing important upgrades because versions are not aligned and they are not using the bundle As a developer every time a tiny change needs to be done on core or instrumentationcommon there is a chain publishing locally and testing changes until things finally work that makes it quite unpleasant Similarly to the above every time there is a release we need to individually publish each one of the independent projects that were affected Not a big deal but this is done manually at the moment Some pieces of instrumentation are very closely related to each other For example the Play Framework instrumentation is tied to the Akka HTTP instrumentation which in turn requires the Akka instrumentation and the Common instrumentation to work This usually means jumping and publishing different artifacts locally for troubleshooting and fixing things Rough Idea Pull all of the instrumentation repositories and the bundle into kamonioKamon an every time we make a release publish everything together even if there are no changes in some of the artifacts Keep separate repositories for all reporters Or maybe a joint repo with all reporters in there Keep a separate repository for Kanela Benefits Besides solving everything on the pain points section having a single repository can also help centralize all issues and pull requests and that can make it more manageable I constantly find myself frustrated jumping between different issues and PRs on different projects and realizing that I left things unanswered or unattended for long Im not saying that this would fix the problem but will probably help The challenges I see here Running tests on the entire thing This will definitely increase the time it takes to test stuff On the other hand we will always be testing everything together and at one which eliminates the chance of introducing crossmodule compatibility issues Automating the release process If a single release process will end up publishing all artifacts at once thats going to take quite some time and is prone to failures but I believe that with proper automation this can stop being a pain in the ass Looking forward to comments on this it might be a good Christmas project smile cc dpsoft mladens adriancole I want to use use kamon with lagom I added the kamon bundle in my application and kanelaplugin as per the documentation kanela should automatically start and instrumentation should begin but nothing happens Moreover I want to use logreporter but I am not able to find factory to provide in the config file to use kamonlogreporter module I added this plugin addSbtPluginiokamon sbtkanelarunner This is my buildsbt file val kamon iokamon kamonbundle val logReporter iokamon kamonlogreporter lazy val root project in file enablePluginsJavaAgent aggregaterootapi rootimpl settingslibraryDependencies in ThisBuild SeqmacwirekamonlogReporter settings credentials CredentialsPathuserHome sbt credentials settings javaOptions in Universal DKamonautostarttrue This is my logreporter conf kamon modules enabled true name LOG REPORTER description Logs the metrics factory dont know what to add here This is the repo link Im trying to track internal asynchronous operations duration potentially hundreds within one trace where some metric tags are collected along the way Initial approach was to create a span tagMetrics on it and finish at the end resulting in spanprocessingtime tracking duration and being properly tagged while also reporting a span for each execution Although having subspans for operations is desirable in some cases i would like to make it configurable Currently options are having simple duration tracking via spans but producing and reporting in case of a positive sampling decision of a parent operation unneccessary spans only their metrics are or manually track start times for each operation since by disabling span creation we are loosing their metrics Couple of solutions that come to mind a special type of span to be used as a metric vehicle to propagate around which is once finished and metrics recorded discarded by tracer irregardles of sampling decision KamontempSpanBuilder Additional methods to discard regular local span KamonspanBuilderoperNameIrrelevantfinishAndDiscard Make discard decision a parameter to finish spanfinishdicard true Wdyt I just realised there is support in kamon x for providing a custom Samplerimplementation just by configuring it sampler comarea CustomSampler A bit of hidden feature as it doesnt seem to be documented anywhere Anyways my issue is that the sampler trait only provides the operation name to use as decision point which is kind of pointless for akkahttp client operations as the name contains the actual HTTP operation eg GET POST A simple way to test this First a custom sampler class CustomSampler extends Sampler override def decideoperation SamplerOperation TraceSamplingDecision printlnsample operationoperationName TraceSamplingDecisionSample Then a simple akkahttp route private lazy val route Route pathPrefixhealth get completeHttpEntityContentTypestextplainUTF OK Using the akkahttp client like this HttpsingleRequestHttpRequesturi s Will render a printout like sample GET If I direct a browser towards my local app I instead get a printout like sample health So on the server side of the sampling decision I get the URL which makes it much more usable Having the custom sampler on the client side is useless as I cant make any decision based purely on the HTTP operation The use cases Im trying to solve apps periodically poll Consul for config and service updates These lookups URLs I dont want sampled at all An orchestration system periodically polls a healthURL on the apps These I dont want sampled either Yes theres the new AdaptiveSampler but I want a random sampler with a filtering capability This because I want to be able to control the sampling density in runtime just by tweaking probability setting AND have the filtering capability Could have been solved in a custom sampler provided I would get more relevant information to make the decision on Kinda obvious at this point we should already have gRPC support Heard already a few times in the last week about users missing the client instrumentation for the Mongo Driver More info in the official driver page cc jtjeferreira 