Thats kinda really important no Using jdk Maven Eclipse Mars Release LogAnalyzer application Trying to import a Maven project into eclipse Import existing Maven project Getting error CoreException Could not calculate build plan Plugin orgapachemavenpluginsmavencompilerplugin or one of its dependencies could not be resolved Failed to read artifact descriptor for orgapachemavenpluginsmavencompilerpluginjar ArtifactResolutionException Failure to transfer orgapachemavenpluginsmavencompilerpluginpom from Have tried to install this plugin whatever I tried Install New Software did not work Tried adding a couple of M E connectors also I now have m e connector for mavenremoteresourcesplugin m e connector for the Maven Dependency Plugin How to solve this Thanks While running the sample WeatherApp I get the following exception while embedded Kafka is trying to connect to the ZooKeeper instance Pls advice me to resolve this issue INFO orgapachezookeeperClientCnxn Opening socket connection to server Will not attempt to authenticate using SASL unknown error INFO orgapachezookeeperZooKeeper Session x closed INFO orgapachezookeeperClientCnxn EventThread shut down ERROR orgapachezookeeperserverNIOServerCnxnFactory Thread Thread main main died orgI IteczkclientexceptionZkTimeoutException Unable to connect to zookeeper server within timeout at orgI IteczkclientZkClientconnectZkClientjava zkclient jar at orgI IteczkclientZkClientinitZkClientjava zkclient jar at orgI IteczkclientZkClientinitZkClientjava zkclient jar at comdatastaxsparkconnectorembeddedEmbeddedKafkainitEmbeddedKafkascala sparkcassandraconnectorembedded jar at comdatastaxsparkconnectorembeddedEmbeddedKafkainitEmbeddedKafkascala sparkcassandraconnectorembedded jar at comdatastaxsparkconnectorembeddedEmbeddedKafkainitEmbeddedKafkascala sparkcassandraconnectorembedded jar at comdatabricksappsWeatherAppdelayedInitbodyapplyWeatherAppscala classesna at scalaFunction classapplymcVspFunction scala scalalibraryjarna at scalaruntimeAbstractFunction applymcVspAbstractFunction scala scalalibraryjarna at scalaAppanonfunmain applyAppscala scalalibraryjarna at scalaAppanonfunmain applyAppscala scalalibraryjarna at scalacollectionimmutableListforeachListscala scalalibraryjarna at scalacollectiongenericTraversableForwarderclassforeachTraversableForwarderscala scalalibraryjarna at scalaAppclassmainAppscala scalalibraryjarna at comdatabricksappsWeatherAppmainWeatherAppscala classesna at comdatabricksappsWeatherAppmainWeatherAppscala classesna at sunreflectNativeMethodAccessorImplinvoke Native Method na at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava na at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava na at javalangreflectMethodinvokeMethodjava na at comintellijrtexecutionapplicationAppMainmainAppMainjava ideartjarna There are examples illustrating Streaming with SQL processing I suppose in Spark the preferred way of processing streaming data with SQL queries is Spark Structured Streaming Makes sense to rework at least one example to illustrate this technique Candidates are LogAnalyzerStreamingSQL LogAnalyzerStreamingImportDirectory Guidelines to run examples force user to run Spark local master with cores master local Real number of logical cores may differ from user to user It would be better to let Spark decide how many cores it needs master local As Spark is not a breaking news anymore its time to make reference apps working with it I can see at least the following things to do Use SparkSession instead of SQLContext Use Dataset API Update JavaDStreamforeachRDD invocations to new contract returns nothing Update JavaPairDStreamupdateStateByKey to new contract uses Spark implementation of Optional Hi Guys I tried the Log Analyzer examples In particular the LogAnalyzerSql one I include in my classpath sparkcore as well as sparksql but I keep getting compilation errors cannot Access Row class if I use other jar versions etc I keep getting missing classes DataFrames etc Could any one tell me which versions of these jars should I include to run the LogAnalyzerSql examples I have google this but nobody else seems to have any similar issue thanks Aim API call from any machine that submits a Spark job to Spark EC cluster Job runs perfectly well Python file running on Localhost Apache Spark However unable to run it on Apache Spark EC API call curl X POST header ContentTypeapplicationjsoncharsetUTF data action CreateSubmissionRequest appArgs appResource wordcountpy clientSparkVersion environmentVariables SPARKENVLOADED mainClass sparkProperties sparkjars wordcountpy sparkdriversupervise true sparkappname MyJob sparkeventLogenabled true sparksubmitdeployMode cluster sparkmaster sparkec compute amazonawscom action CreateSubmissionResponse message Driver successfully submitted as driver serverSparkVersion submissionId driver success true To get the response following API returns error File not found curl action SubmissionStatusResponse driverState ERROR message Exception from the cluster njavaioFileNotFoundException wordcountpy No such file or directory n tjavaioFileInputStreamopenNative Method n tjavaioFileInputStreaminitFileInputStreamjava n torgsparkprojectguavaioFilesFileByteSourceopenStreamFilesjava n torgsparkprojectguavaioFilesFileByteSourceopenStreamFilesjava n torgsparkprojectguavaioByteSourcecopyToByteSourcejava n torgsparkprojectguavaioFilescopyFilesjava n torgapachesparkutilUtilsorgapachesparkutilUtilscopyRecursiveUtilsscala n torgapachesparkutilUtilscopyFileUtilsscala n torgapachesparkutilUtilsdoFetchFileUtilsscala n torgapachesparkutilUtilsfetchFileUtilsscala n torgapachesparkdeployworkerDriverRunnerorgapachesparkdeployworkerDriverRunnerdownloadUserJarDriverRunnerscala n torgapachesparkdeployworkerDriverRunneranon runDriverRunnerscala serverSparkVersion submissionId driver success true workerHostPort workerId worker Awaiting suggestions and improvements ps newbie in Apache Spark Update API call Set the main class appArgs appResource clientSparkVersion to updated value curl X POST action CreateSubmissionRequest appArgs wordcountpy appResource filewordcountpy clientSparkVersion environmentVariables SPARKENVLOADED mainClass orgapachesparkdeploySparkSubmit sparkProperties sparkdriversupervise false sparkappname Simple App sparkeventLogenabled true sparksubmitdeployMode cluster sparkmaster sparkec compute amazonawscom Hi I have successfully compiled the Twitter classifier sample and I am trying to run the first program to collect the tweets When I run the example I am running into this issue ERROR schedulerReceiverTracker Deregistered receiver for stream Restarting receiver with delay ms Error receiving tweets sunsecurityvalidatorValidatorException PKIX path validation failed javasecuritycertCertPathValidatorException Algorithm constraints check failed SHA withRSA Relevant discussions can be found on the Internet at or TwitterExceptionexceptionCode d b b db db dea ae db dea ae db dea ae statusCode messagenull code retryAfter rateLimitStatusnull version at twitter jinternalhttpHttpClientImplrequestHttpClientImpljava at twitter jinternalhttpHttpClientWrapperrequestHttpClientWrapperjava at twitter jinternalhttpHttpClientWrappergetHttpClientWrapperjava at twitter jTwitterStreamImplgetSampleStreamTwitterStreamImpljava at twitter jTwitterStreamImpl getStreamTwitterStreamImpljava at twitter jTwitterStreamImplTwitterStreamConsumerrunTwitterStreamImpljava Caused by javaxnetsslSSLHandshakeException sunsecurityvalidatorValidatorException PKIX path validation failed javasecuritycertCertPathValidatorException Algorithm constraints check failed SHA withRSA My java is usrjdk java openjdk b el x jrebinjava 