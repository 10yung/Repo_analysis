Hello is it possible to train the small M GPT model with GB VRAM using FP Recommended Vram is GB so with fp I could halve the memory consumption Hi there There are so many developers want to try gpt I found a lot of people confuse and suffering for deploy gpt as a web service may be this commit will help them avoid this trouble and save more time focus on the model itself Relevant tweet chain Basically youre prompting the model with endoftext a single token with BPE value or whatever but the BPE encoder encodes endoftext as end of text five separate tokens Its completely different I am working to make pb file of the checkpoint but i dont know the input and output nodes of the model so i am unable to make frozen graph of the model for prediction i tried so many ways to make pb file In one of the way i am getting error that PB file should be less than gb How to resolve this issue Thank you for your time allow listing of available models on object storage I am using GPT small model M I have trained the model on real Estate home descriptions samples So it start generating homes description I am use the GPT following generate function to generate home description samples gpt generatesesslength temperature nsamples runnamerun Well the generated description well look like this NW Dogwood St Unit H is a condo in Seattle WA This square foot condo features bedrooms and bathrooms having stories and floorsThis property was built in and last sold for Based on Redfins Seattle data we estimate the homes value is Comparable nearby homes include NW Dogwood St Unit H NW Dogwood St Unit H So my question is that how can i give the parameter like stories floors to GPT generate function and it will generating the home description samples with this feature stories floors and if i give parameter like bedrooms and bathrooms it will start generating samples with this feature bedrooms and bathrooms Can we leverage GPT pretrained model for WebNLG tasks The WebNLG challenge consists in mapping data to text similar to what is being done in I get the below errors when running gpt The model runs in the end and seems to work but is there any way to fix this Thanks E tensorflowstreamexecutorcudacudadrivercc failed to alloc bytes on host CUDAERROROUTOFMEMORY out of m emory W tensorflowcorecommonruntimegpugpuhostallocatorh could not allocate pinned host memory of size E tensorflowstreamexecutorcudacudadrivercc failed to alloc bytes on host CUDAERROROUTOFMEMORY out of m emory W tensorflowcorecommonruntimegpugpuhostallocatorh could not allocate pinned host memory of size E tensorflowstreamexecutorcudacudadrivercc failed to alloc bytes on host CUDAERROROUTOFMEMORY out of m emory W tensorflowcorecommonruntimegpugpuhostallocatorh could not allocate pinned host memory of size 