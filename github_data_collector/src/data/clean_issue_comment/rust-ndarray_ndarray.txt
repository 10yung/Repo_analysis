I asked this question on reddit but I didnt get any response over there Im currently using ndarray for a project of mine and one thing I need to quite frequently is to mutate the contents of two or more columnsrows based on each others contents It isnt always the case that both lanes need to be mutable but they usually need to be Ive figured out how to do it with ndarrayZip and iteraxismut as follows rust pub fn applytwolanesT F arr mut Array T axis Axis l usize l usize f F where F Fn mut T mut T assertnel l let mut lanes arraxisitermutaxis let lane lane if l l lanesnthl unwrap lanesnthl l unwrap else let lane lane lanesnthl unwrap lanesnthl l unwrap lane lane ndarrayZipfromlane andlane applyf However as you can see because I dont know if l or l comes first I need the additional if test I havent managed to figure out how to do the above without some manner of checking of the ordering of l and l Is there a way to accomplish the above without having to check which index is first Im using ndarray for a project that Im currently working on I required to replace NaNs in a d array and Ive recreated a similar function to pandas ffill I can share the code if this is something that might be helpful for ndarray Hi Im just trying to get a sense of the level of interest from the ndarray developers regarding adopting the Apache Arrow memory layout and padding I have been wanting to build integrations between Arrow and ndarray for some time Today it should be easy enough to build a zerocopy converter to ndarray types Arrow has a tensor type and this could be converted with the optional names for dimensions in Arrow dropped However without guarantees over the memory alignment and padding assumptions you could not go back to Arrow with zerocopy The easiest way to do this would be for ndarray to use the Arrow functions that allocate memory through the Arrow Buffer type Arrow is attempting to make integrations between crates easier I noticed this issue today This is the kind of issue we could avoid In general I think that Arrow and ndarray fit together quite nicely where Arrow could provide alot of help processing data and ndarray provides all the algorithms once data is cleaned and inmemory Im not very familiar with the ndarray codebase if this sounds like a good idea could you point me to where you allocate memory etc and any other information that might help Previously the first paragraph of the docs indicated that any contiguous array was accepted while the second paragraph indicated that only c or fcontiguous arrays were accepted The second paragraph is correct This commit fixes the description in the first paragraph to match Fixes Apparently ArrayBaseallclose has been deprecated in favor of approx crate and feature I think this new method brings unnecessary complications to the workflow ie extra crate must be included and feature must be enabled by hand in Cargotoml So my question is Is the deprecation really worth the benefits it brings Or why is it deprecated at all There are lots of extern crate numtraits use selfnumtraits Needed Same for rawpointers and numintegers This is on the master branch Are there any plans to add simple moving average to a D array or at an axis level Currently if we need to do elementwise operation on array we can create a result array and wrap it together with parameters arrays in Zip and use apply to assign the result However since Zip have the shape information can we add a helper function to allocate a result array with correct shape so that we dont need to create the result array manually As adviced by jturner in I now use asslicememoryorder in zipmutwithsameshape for sameorder arrays I also wanted to optimize zipindexed but its more complex so Ill probably do it later I modified zipmutwithsameshape more than I intended at first because there were some useless statements At that point we have sameshape arrays so they have the same length which make the slicing useless The bench I added show that cc is not slower than it was and ff is as fast as cc On windows and WSL This PR implements std and var methods see using the same method as used for varaxis stdaxis The variance is computed by flattening the array of N dimensions into a D array of the length len of the original array The return type is scalar A instead of ArrayA DSmaller An attempt was made to refactor varaxis to use var but this resulted in a performance regression so original implementation is kept and we accept some code duplication stuckouttongue rust pub fn varaxis self axis Axis ddof A ArrayA DSmaller where A Float FromPrimitive D RemoveAxis let mut sumsq ArrayA DSmallerzerosselfdimremoveaxisaxis for lane sum in selflanesaxisintoiterzipsumsqitermut sum lanevarddof sumsq Thanks LukeMathWalker for the mentoring grinning 