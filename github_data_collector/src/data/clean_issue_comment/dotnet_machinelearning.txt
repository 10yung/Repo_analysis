Fixes So some weeks ago I noticed that the documentation under docscode mention several interfaces that currently dont exist in MLNETs codebase They existed back in TLC and perhaps some of them if not all of them actually made it into MLNET before version release but the case is that they no longer exist so I just wanted to update them After looking into the TLC code I decided to make the following replacements in the docs ISchema DataViewSchema IRandom SystemRandom IRow DataViewRow IRowCursor and ICursor DataViewRowCursor Still there are some mentions to IDataReader which doesnt exist in MLNET and I wouldnt be sure how to handle that case Side notes About IRandom In TLC it seems that only SysRandom and TauswortheHybrid implemented IRandom In MLNET IRandom and SysRandom dont exist but TauswortheHybrid inherits from SystemRandom So I guess its safe to replace IRandom for SystemRandom in the docs Dear all Unless I am mistaken there is currently a single model suitable for timeseries forecasting ForecastBySsa The other models within this catalogue target anomaly detection There are various alternative methods that may be used to forecast time It would be nice to have a choice and the option to try a different method Thank you Fig System information OS versiondistro Windows NET Version eg dotnet info NET Framework Issue I would like to know how I can leverage a datatable or some similar type instead of using model classes To start with I am currently able to successfully train and predict with a model class using the multiclass classification The current model in my setup looks like this public class MultiClassInput ColumnNameStatement public string Statement get set ColumnNameLabel public string Label get set I am essentially creating a ListMultiClassInput from data in a datatable Some sample data I used to successfully train and predict vModelTrainingDataRowsClear vModelTrainingDataRowsAddI need to Reset Password ITSupport vModelTrainingDataRowsAddI want to Reset Password ITSupport vModelTrainingDataRowsAddPassword Reset ITSupport vModelTrainingDataRowsAddReset My Password ITSupport vModelTrainingDataRowsAddPass Reset ITSupport vModelTrainingDataRowsAddPay Bill Billing vModelTrainingDataRowsAddPay Invoice Billing vModelTrainingDataRowsAddBilling Problems Billing vModelTrainingDataRowsAddReview Charges Billing vModelTrainingDataRowsAddPay Charges Billing vModelTrainingDataRowsAddInvoice Problem Billing What I would like to do is figure out some way to have a user pick a column to be the label that way I can support multiple columns of data to act as input to the training process without creating multiple classes Everything I have found so far looks like it requires a known model class Any thoughts on how I can achieve this Thanks Source code logs Read documentation for loading data Hello Do you plan on adding Feature Contribution to multi class classification problem Document Details Do not edit this section It is required for docsmicrosoftcom GitHub issue linking ID fdbc efdca da d fb d Version Independent ID ad c cdf fc b ce a f e f Content FeatureContributionCalculatingEstimator Class MicrosoftMLTransforms Content Source dotnetxmlMicrosoftMLTransformsFeatureContributionCalculatingEstimatorxml Product dotnetmlapi GitHub Login natke Microsoft Alias nakersha Due to test in private agent pool these tests seems crashing test host process try to disable them Start the test process from a managed place instead directly from xunit that will give us better control logging and restart test process if crashes retry flaky test with everything reset logging when test process hangs Fixed TextLoader now checks whether the given file in path exists If the file is missing a clear exception stating that the file is missing is given instead of stating that some field is missing some unknown attribute Our F metric can currently return a NaN value when both the precision and recall are zero as F precision recall precision recall which turns into Precisionrecall being zero occurs for a trivial model which always guesses the majority class zero We should return F instead of NaN this is done in sklearn code and others note brOur F calculation code See background AutoML API code is not handing NaN values for metrics During the sweep when a model returns a NaN value for the metric being optimized AutoML crashes See background 