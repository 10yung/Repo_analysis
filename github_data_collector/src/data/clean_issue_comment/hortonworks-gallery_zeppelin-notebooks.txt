Hi Team Could you please share the helm chart for Kubernetes deployment Best regards Poshak Well actually I just wanted to report an issue and Im not sure that I got how the demo notebooks load On the official tutorial page there is a link to get all the Spark notebooks with hash CJW M I suppose that this page was created from GitHub md file However on both of this pages screenshot suggest that after download of test data data is moved from local system to tmp folder in the Hadoop like this remove existing copies of dataset from HDFS hdfs dfs rm r f tmpflightscsv put data into HDFS hdfs dfs put tmpflightscsv tmp and later spark Create a flights DataFrame from CSV file val flights sparkread optionheader true Use first line as header optioninferSchema true Infer schema csvtmpairflightsdelaysflightscsv Read data Which is not correct The error is present only at screenshots the code in the notebook seems to be ok In the original repo there is a folder with what seems to be a correct notebook with hash C C EK for this tutorial with the commands hadoop fs rm r f tmpairflightsdelays hadoop fs mkdir tmpairflightsdelays put data into HDFS hadoop fs put tmpflightscsv tmpairflightsdelays So it might be a good idea to fix either a screenshot or the code Hi guys Just wanted to let you know that weve migrated all links for to Well be making the correct redirect but would be helpful if the links and directions could be updated with the new URL only the domainexplore needs to be updated The proceeding random URL will be maintained Also if you register to you will be able to publish the notebooks directly to the desired public category Thanks ps Btw great stuff Keep analyzing and sharing Love the examples updated path to zeppelin notebook path changed in hdp sandbox Sandboxversion Sandbox information Created on for Hadoop stack version Hadoop Ambari Version Ambari Hash b e de eeff d b d a f Ambari build Release Java version OS Version CentOS release Final Commenting out redundant val sqlContext new orgapachesparksqlSQLContextsc as its already available 