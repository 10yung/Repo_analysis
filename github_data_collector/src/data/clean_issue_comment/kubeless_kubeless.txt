Is this a BUG REPORT or FEATURE REQUEST BUG REPORT What happened Ive created a new function that just print the date and created a cronjob trigger thats run each minute The pod of the the trigger cannot be created due to the following error Failed create pod sandbox rpc error code Unknown desc failed to start sandbox container for pod triggerkobycronjob z b Error response from daemon OCI runtime create failed containerlinuxgo starting container process caused processlinuxgo container init caused unknown Pod sandbox changed it will be killed and recreated What you expected to happen The job will be complted successfully How to reproduce it as minimally and precisely as possible python file import datetime def koby print cronJob NEW sdatetimedatetimenow kubeless function deploy kubeless function deploy kobycronjob runtime python handler kkoby fromfile kpy trigger creation kubeless trigger cronjob create koby function kobycronjob schedule Anything else we need to know kubectl describe pod triggerkobycronjob wmd z Name triggerkobycronjob wmd z Namespace default Priority PriorityClassName none Node aksnodepool vmss Start Time Wed Jan Labels controlleruid fadf b eab e fdc cd jobnametriggerkobycronjob Annotations kubernetesiopsp privileged Status Pending IP Controlled By Jobtriggerkobycronjob Containers trigger Container ID Image kubelessunzipsha f c cca de ed c d df cdb f b a b Image ID Port none Host Port none Args curl Lv H eventid MUNUDPwFaFpTRkk H eventtime UTC H eventtype applicationjson H eventnamespace cronjobtriggerkubelessio State Waiting Reason ContainerCreating Ready False Restart Count Limits cpu m memory Mi Requests cpu m memory Mi Environment none Mounts varrunsecretskubernetesioserviceaccount from defaulttokenfjfpg ro Conditions Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes defaulttokenfjfpg Type Secret a volume populated by a Secret SecretName defaulttokenfjfpg Optional false QoS Class Guaranteed NodeSelectors none Tolerations nodekubernetesionotreadyNoExecute for s nodekubernetesiounreachableNoExecute for s Events Type Reason Age From Message Normal Scheduled m s defaultscheduler Successfully assigned defaulttriggerkobycronjob wmd z to aksnodepool vmss Warning FailedCreatePodSandBox m s kubelet aksnodepool vmss Failed create pod sandbox rpc error code Unknown desc failed to start sandbox container for pod triggerkobycronjob wmd z Error response from daemon OCI runtime create failed runc did not terminate sucessfully unknown Warning FailedCreatePodSandBox m s x over m s kubelet aksnodepool vmss Failed create pod sandbox rpc error code Unknown desc failed to start sandbox container for pod triggerkobycronjob wmd z Error response from daemon OCI runtime create failed containerlinuxgo starting container process caused processlinuxgo container init caused read initp connection reset by peer unknown Normal SandboxChanged m s x over m s kubelet aksnodepool vmss Pod sandbox changed it will be killed and recreated Environment Kubernetes version use kubectl version Client Version versionInfoMajor Minor GitVersionv GitCommitb d ef f ca abbaa b c GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Server Version versionInfoMajor Minor GitVersionv GitCommit da ba ad e d a d e f GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Kubeless version use kubeless version Kubeless version v dirty Cloud provider or physical cluster Cloud provider Azure AKS Is this a BUG REPORT or FEATURE REQUEST FEATURE REQUEST What happened When pods are terminated active connections are closed What you expected to happen The function pod should attempt a graceful shutdown on sigterm with some configurable timeout How to reproduce it as minimally and precisely as possible Create a function that sleeps for seconds or so and returns success Trigger the function Intentionally terminate the poddocker container before the function completes Youll get a socket hang up error Anything else we need to know I might like to attempt a PR for this if you decide its an feature worth having From what I can see it looks like it could be added relatively easily to the function proxy following this example Environment Kubernetes version use kubectl version Client Version versionInfoMajor Minor GitVersionv GitCommit b f acc bed d ba dd f e cf GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Server Version versionInfoMajor Minor GitVersionv gke GitCommitd fd c a c b f b d f f b df ca GitTreeStateclean BuildDate T Z GoVersiongo b Compilergc Platformlinuxamd Kubeless version use kubeless version Kubeless version v dirty Cloud provider or physical cluster GKE Is this a BUG REPORT or FEATURE REQUEST BUG What happened NAME NAMESPACE HANDLER RUNTIME DEPENDENCIES STATUS weather kubeless testweather nodejs request NOT READY requestpromisenative Im following the example provided below but am getting a status not ready when deploying the function I also visited this comment and applied it but am still getting status not ready What you expected to happen NAME NAMESPACE HANDLER RUNTIME DEPENDENCIES STATUS weather kubeless testweather nodejs request READY requestpromisenative Im also seeing this issue with the serverlesskubeless plugin when packaging functions with dependencies How to reproduce it as minimally and precisely as possible Run the weather example Anything else we need to know Using kubeless with minikube and context virtual box Environment Kubernetes version use kubectl version Client Version versionInfoMajor Minor GitVersionv GitCommit e a eaa a ed e a c GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformdarwinamd Server Version versionInfoMajor Minor GitVersionv GitCommit b f acc bed d ba dd f e cf GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Kubeless version use kubeless version v dirty Cloud provider or physical cluster local cluster using minikube and virtualbox Is this a BUG REPORT or FEATURE REQUEST BUG REPORT What happened Im trying to expose a function deployed on a AWS EKS Cluster with httptrigger either by using kong ingress controller or nginx ingress controller I get a fatal error What you expected to happen the ingress creation for the function is created and function gets exposed How to reproduce it as minimally and precisely as possible kubeless trigger http create helloingress functionname hello gateway nginx FATA Can not create outofcluster client stat Usersandreaspoldikubeconfig no such file or directory Anything else we need to know my kubeconfig exists and it is the proper pathother kubeless commands works okay kubeless getserverconfig INFO Current Server Config INFO Supported Runtimes are ballerina dotnetcore dotnetcore go go go java java nodejs nodejs nodejs nodejs php php python python python python ruby ruby ruby ruby jvm nodejsdistroless nodejsCE vertx my kubeconfig is generated like this aws eks region region updatekubeconfig name clustername as per AWS documentation Environment Kubernetes version use kubectl version Client Version versionInfoMajor Minor GitVersionv GitCommitb d ef f ca abbaa b c GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformdarwinamd Server Version versionInfoMajor Minor GitVersionv eksc eccc GitCommitc eccca d bb b f dd d ffeb f a GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Kubeless version use kubeless version Kubeless version v dirty Cloud provider or physical cluster AWS EKS Thanks Is this a BUG REPORT or FEATURE REQUEST BUG REPORT What happened I made the kubeless setup and everything worked fine with examples Then i migrated a lambda to it and now when there is a error I am guessing there is a error btw I cant see the logs This is the very first lines of the lambda def lambdahandlerevent context printaaaaa printevent When I call with dummy data it prints as expect but when I call it with some real data and I am guerssing there is a error no output is produced with kubectl logs and after some time I see Jan POST HTTP curl If I call the lambda by cli kubeless function call xxxxxx data groupidyyyyyyyy ERRO FATA Request timeout exceeded What you expected to happen The minimum I expect is to see some logs How to reproduce it as minimally and precisely as possible Not sure here there is a lot of async on this code Anything else we need to know Environment Kubernetes version use kubectl version kubectl version Client Version versionInfoMajor Minor GitVersionv GitCommitc fe ef df d e c c e b GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Server Version versionInfoMajor Minor GitVersionv GitCommitc fe ef df d e c c e b GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Kubeless version use kubeless version kubeless version Kubeless version v dirty Cloud provider or physical cluster Digital Ocean Best of luck for the whole project team This is a great start for Is this a BUG REPORT or FEATURE REQUEST Bug What happened When I customize service port My cronjob not use right value apiVersion v kind Service metadata creationTimestamp T Z labels createdby kubeless function awscomponentmonitoring name awscomponentmonitoring namespace kubeless spec ports name httpfunctionport port protocol TCP targetPort apiVersion batchv beta kind CronJob metadata creationTimestamp T Z labels createdby kubeless function awscomponentmonitoring name triggerawscomponentmonitoring namespace kubeless spec concurrencyPolicy Allow failedJobsHistoryLimit jobTemplate Lv H eventid mAAlIu XQtXqSo H eventtime UTC H eventtype applicationjson H eventnamespace cronjobtriggerkubelessio image kubelessunzipsha de bf a dad ab ac eb c e d What you expected to happen Used customize port How to reproduce it as minimally and precisely as possible Create function when customize port and create trigger cronjob Anything else we need to know Environment Kubernetes version use kubectl version v Kubeless version use kubeless version v dirty Cloud provider or physical cluster AWS kops Im running self hosted registry with registry it is configured with basic auth Everything works with all docker clients besides kubeless Issue error triggered here Error Unable to build function Unable to check is target image exists Unable to extract auth info Unable to find the property Bearer realm in Basic realm basicrealm Looks like kubeless expect wwwauthenticate header to have the following properties Bearer realm service scope which do not exist with basic auth Any plans to support basic auth FEATURE REQUEST Im looking over the docs and it seems that the only way to specify dependencies is with a Gopkgtoml file and using dep Given the norm of dependency management in go moving to modules are there plans to support using the built in module system which would also allow using a proxy for private packages Is this a BUG REPORT or FEATURE REQUEST Bug Design Flaw What happened Kafka Controller Triggers provide no backpressure and constantly pull in data from the Kafka topics This is a recipe for disaster leading to Kubeless basically DDOSing its own functions If the function andor trigger is removed from Kubeless the controller still retains all the messages in memory and continues to try and deliver messages to the missing functions in error This also results in other queuesfunctions being starved out as the controller continues to try and delivery the defunct large queue and does not appear to attempt any roundrobin like delivery among all the functionstopics This is further confounded by the fact that the controller only has consumer per topic and therefore you can not scale out the queue throughput beyond partition What you expected to happen Kafka Controller should implement backpressure capability and provide scalability beyond consumerpartition One topicfunction getting overloaded should not impact other topics functions In addition removing the kafka trigger should clear or stop any pending messages trying to get to those functions How to reproduce it as minimally and precisely as possible Use the python target and throw thousand messages onto a Kafka topic that Kubeless listens to Then have another function that expects to here Kafka messages on another topic that Kubeless listens to Anything else we need to know While fixing the single consumerpartition problem isnt necessarily a blocker for adding some sort of backpressure capability its certainly lumped in with the overall design flows with the Kafka Controller Environment Kubernetes version use kubectl version Kubeless version use kubeless version Cloud provider or physical cluster AWS EKS 