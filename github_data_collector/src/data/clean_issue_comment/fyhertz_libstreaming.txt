I was writing a program that could pack RTP header before h aac but I was confused with RTP timestamp field If the video codec is h the timestamp could be added by fps with each frame I have no idea about the aac My aac sample rate is HZconfig and each frame is How to calculate the audio rtp timestamp libstreaming rtsp server does not support digest authenticationDo you have any plans As you knowsBasic authentication security is low I know little about RTSP and I think its similar to some CS architecture application Wish that someone tell me if the description below is right With libstreaming I can build an RTSP Server in an Android devicelets call it device A capturing video and audio Then I run an RTSP Client in another Android devicelets call it device B Device B can easily play media which provided by Device A If that is true then I am confused It seems that examples do not behave like that all devices are in the same LAN I am trying to stream Video using the rtp and should stream video simultaniously from other devices connected to same Wifi Network I used this github link to implement the above concept but i am facing an issue for how to configure the session bilder and get the video transmitted so that we can use vlc media player through sdp file to pull to display the video Im setting MediaFormatKEYIFRAMEINTERVAL value as below given code but its not generating Key frame every second but it is generating every second Im using Libstreaming library can anyone please help why is not working mMediaCodec MediaCodeccreateByCodecNamedebuggergetEncoderName MediaFormat mediaFormat MediaFormatcreateVideoFormatvideoavc mediaFormatsetIntegerMediaFormatKEYBITRATE mediaFormatsetIntegerMediaFormatKEYFRAMERATE mediaFormatsetIntegerMediaFormatKEYCOLORFORMAT debuggergetEncoderColorFormat mediaFormatsetIntegerMediaFormatKEYIFRAMEINTERVAL here mMediaCodecconfiguremediaFormat null null MediaCodecCONFIGUREFLAGENCODE mMediaCodecstart I want to use another video source and stream it using libstreaming but as I understand there is no way to change the source video and libstreaming automatically use device camera as source video to be more specific I have an external camera that I can get video as a raw ByteBuffer and I wanted to stream it over network I call this function in onCreate java private void initListener hdCameraManager HDCameraManager getUnitManagerFuncConstantHDCAMERAMANAGER LogiTAG Now in initListener start hdCameraManagersetMediaListenernew MediaStreamListener Override public void getVideoStreamint i byte bytes int i int i drawVideoSampleByteBufferwrapbytes Override public void getAudioStreamint i byte bytes its not important what is HdCameraManager and other stuff the only important thing is in getVideoStream function I get the raw video data as bytes and wrap it up in a ByteBuffer and pass it to another function java Override public void getVideoStreamint i byte bytes int i int i drawVideoSampleByteBufferwrapbytes so How can I be able to send this raw stream to external encoder like Wowza or FFmpeg using Libstreaming Should I use MediaCodec and other stuff to make it through Should I change the libstreaming source code to make it happen Thanks a lot H Packetizerjava if type sps null pps null buffer socketrequestBuffer socketmarkNextPacket socketupdateTimestampts Systemarraycopystapa buffer rtphl stapalength supersendrtphl stapalength Above code executing every seconds in my device I want to execute it every seconds I tried by adding interval manually but it not working because packets not there for pps and sps at that time So anybody please tell me how can I achieve this Thanks Brother the delay is a bit serious about to seconds this effect is too bad simply can not be used is there any solution Let me explain Im new in RTSP world All I can say is that I have a camera and it connect well Im receiving all the frames in byte format Just dont know how to finally display it I should use this library or theres a native method Hope u guys help me 