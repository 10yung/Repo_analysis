Added an example which would publish the odometry message information from openvslam Seen some issues created looking for this I needed it as well so I thought it would be good to have an example for others as well This is a very rudimentary implementation and there might even be some issues but maybe someone will improve upon it if need be and perhaps add some more features etc This branch is checked out from ros latest commit so this will hopefully pass all tests etc as soon as the main ros PR is merged edit of course all commits are here as well but I still think the other one should be a separate merge and if needed Ill just merge master into this one after that PR merge vslam I am able to build and run the sample Runvideoslamexe but after run a few frames a debug assertion warning message popup The warning message is attached with this issue Is there any plan to include nonmaximal suppression NMS algorithms to homogenously distribute detected keypoints in the image Hello How can I specify a real world measurement in order to provide a reference to resolve scale and coordinates frame Feeding a stereo frame would do the trick but Im doing monocular For example in Ucoslam one can set arucomarkerSize so that we provide an object size reference to solve the scale issue Can something like that be implemented in openvslam as it will also help fight scale drift For the coordinate position orientation reference we can always work in the frame reference of the first Keyframe but it would be great if we could specify the position and orientation of a KeyFrame and freeze it as a reference but it will probably induce some numerical instabilities to have a hard constraint To fight orientation and position drift it would be great to be able to add compass from IMU but it would be great to have some way to manually constrain some orientation of a KeyFrame and position of a KeyFrame Thanks It seems that in order to build OpenVSLAM using Visual Studio people have to keep adding pretty much these same changes over and over again see eg here and here As these minor additions should cause no harm to Linux or macOS users would suggest incorporating them in the official codebase I ran the sample tutorial with the video sequence provided in Google drive After the vocabulary mp and yaml files are loaded the program prompts a invalid node error I have tried to figure out the reason by running the program with debug option here is the output base ubuntuubuntuMacminiopenvslammasterbuild runvideoslam v orbvocaborbvocabdbow c aistentrancehall configyaml m aistentrancehall videomp frameskip mapdb aistentrancehall mapmsg debug D CONSTRUCT config I config file loaded aistentrancehall configyaml D load camera model type invalid node this may result from using a map iterator as a sequence iterator or viceversa I have checked the files and they are all right Can someone help Hi all Thanks for the repo And I wonder what are the options for the camera model I see perspective fisheye and equirectangular What should I put into the camera config file if I am using a common stereo camera Thanks in advance Duncan hi I recently read the code of openvslam well done But when i run into the trackingmoduletrackmonocularimage i have being confused by the method you used to initialize the first frame and second frame Then I give my question We run into the initializerinitialize firstly use first frame in createinitializer Secondly use second frame combine with first frame to do initilization job for mobocular tracking Where the code makes me confused is areamatchinconsistentarea called by initializertryinitializeformonocular Why we omit keypoints extracted on other scale I donnot think its reasonable I am looking forward for your answer thanks in advance kensakurada shinsumicco MikiyaShibuya Just confused The case for Perspective camera has the same code as the case for Fisheye Is fisheye meant to behave differently Is this a mistake or oversight or just convenient I am running the system for my own video I already calibrated the camera accordingly However the system has a weird behavior at the beginning it works fine when the tracking is performed in a straight line but when it turns left or right the tracking is eventually lost At other times after turning the viewer shows the current keyframe green square spinning around repeatedly although the video shows a following up straight path Has somebody an idea what is happening Can it be due to the fact that the video shows very close objects less than one meter close 