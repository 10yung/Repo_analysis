In order to product ordered message can we set the hashcode of primary key to message key How to do that Can provide examples of rabbitmq this time is very slow why can you tell me how to run mypipe my english is low I can not to run mypipe project runner runMain mypiperunnerKafkaGenericConsoleConsumer worldtestgeneric groupId project runner need to use which project and groupId is what thank you very much dont get mysql binary log file position some error output info like this INFO marConfigurableFileBasedBinaryLogPositionRepository Saving binlog position for pipe mysqlbinposition null INFO marConfigurableMySQLBasedBinaryLogPositionRepository Saving binlog position for kafkageneric Somenull INFO marConfigurableFileBasedBinaryLogPositionRepository Saving binlog position for pipe mysqlbinposition null INFO marConfigurableMySQLBasedBinaryLogPositionRepository Saving binlog position for kafkageneric Somenull INFO marConfigurableMySQLBasedBinaryLogPositionRepository Saving binlog position for kafkageneric Somenull INFO marConfigurableFileBasedBinaryLogPositionRepository Saving binlog position for pipe mysqlbinposition null INFO marConfigurableFileBasedBinaryLogPositionRepository Saving binlog position for pipe mysqlbinposition null INFO marConfigurableMySQLBasedBinaryLogPositionRepository Saving binlog position for kafkageneric Somenull this is my configure file applicationconf include applicationoverrides mypipe schemarepoclient mypipeavroschemaSchemaRepo consumers mytestmysql source testtest producers stdout class mypipekafkaproducerstdoutStdoutProducer kafkageneric class mypipekafkaproducerKafkaMutationGenericAvroProducer pipes stdout consumers mytestmysql producer stdout binlogpositionrepo class mypipeapirepoConfigurableFileBasedBinaryLogPositionRepository config fileprefix mysqlbinposition datadir datamypipeout kafkageneric enabled true consumers mytestmysql producer kafkageneric metadatabrokers binlogpositionrepo class mypipeapirepoConfigurableMySQLBasedBinaryLogPositionRepository config source testtest database mytest table binlogpos id kafkageneric Ive a MySql table with a primary key of type Int unsigned when the id is bigger than the max Int value the id becomes a negative value as expected I found what I think could be the root of the problem the query on the information schema done by the MySQLMetadataManager is using the DATATYPE column value and this value is always int even for the unsigned kind I think an idea for a possible solution is to look also at the COLUMNTYPE that is where the unsigned information is stored and cast this values to long ColumnTypescala gives us some errors on VARSTRING and STRING values Data stored in these kinds of columns seems to be typically byte Implicit conversion using columnvalueOption String getOrElse fails We now use a imperfect patched version which is attached Imperfect by means that it assumes UTF as encoding something that should be read from the database column definition in the future ColumnTypescalazip Hi I am new to Kafka and have a requirement to read binary log of MySQL and publish it to Kafka I have followed your readme file and have mdoified mycnf for MySQL My applicationconf file is as below applicationconftxt My stdout producer works fine and I am able to see the logs in the console But I am not able to see the same in kafka I can see that the topics are created I run the following command to see view the same from Kafka sbt project runner runMain mypiperunnerKafkaGenericConsoleConsumer kafkatesttestusergeneric localhost testconsumergroup I get the following output I am not sure how to proceed further I believe it has to do with my schema registry address Please kindly help me Java HotSpotTM Bit Server VM warning ignoring option MaxPermSize m sup port was removed in info Loading project definition from homekafkauserconfluent mypipeproject warn Multiple resolvers having different access mechanism configured with same name sbtpluginreleases To avoid conflict Remove duplicate project resolvers resolvers or rename publishing resolver publishTo info Set current project to mypipe in build filehomekafkauserconfluent mypipe info Set current project to runner in build filehomekafkauserconfluent mypipe warn Multiple main classes detected Run show discoveredMainClasses to see the list info Running mypiperunnerKafkaGenericConsoleConsumer kafkatesttestusergeneric localhost testconsumergroup log jWARN No appenders could be found for logger kafkautilsVerifiableProperties log jWARN Please initialize the log j system properly log jWARN See for more info INFO orgapachezookeeperZooKeeper Client environmentzookeeperversion built on GMT INFO orgapachezookeeperZooKeeper Client environmenthostnameBIPROSHADOOP INFO orgapachezookeeperZooKeeper Client environmentjavaversion INFO orgapachezookeeperZooKeeper Client environmentjavavendorOracle Corporation INFO orgapachezookeeperZooKeeper Client environmentjavahomeoptjdk jre INFO orgapachezookeeperZooKeeper Client environmentjavaclasspathhomekafkausersbtlaunchers sbtlaunchjar INFO orgapachezookeeperZooKeeper Client environmentjavalibrarypathusrjavapackageslibamd usrlib lib libusrlib INFO orgapachezookeeperZooKeeper Client environmentjavaiotmpdirtmp INFO orgapachezookeeperZooKeeper Client environmentjavacompilerNA INFO orgapachezookeeperZooKeeper Client environmentosnameLinux INFO orgapachezookeeperZooKeeper Client environmentosarchamd INFO orgapachezookeeperZooKeeper Client environmentosversion el x INFO orgapachezookeeperZooKeeper Client environmentusernamekafkauser INFO orgapachezookeeperZooKeeper Client environmentuserhomehomekafkauser INFO orgapachezookeeperZooKeeper Client environmentuserdirhomekafkauserconfluent mypipe INFO orgapachezookeeperZooKeeper Initiating client connection connectStringlocalhost sessionTimeout watcherorgI IteczkclientZkClient e INFO orgapachezookeeperClientCnxn Opening socket connection to server localhost Will not attempt to authenticate using SASL unknown error INFO orgapachezookeeperClientCnxn Socket connection established to localhost initiating session INFO orgapachezookeeperClientCnxn Session establishment complete on server localhost sessionid x daae negotiated timeout WARNING Avro Invalid default for field txid null not a nulltypefixednameGuidnamespacemypipeavrosize WARNING Avro Invalid default for field txid null not a nulltypefixednameGuidnamespacemypipeavrosize WARNING Avro Invalid default for field txid null not a nulltypefixednameGuidnamespacemypipeavrosize Hi is it possible to publish to maven for easier use at least mypipeapi Thanks i have a mysql server on my remote server with row binlog enabledthen i want to implement a data collection bus using kafkawhether source is mysql or other format log file we use these bus to store them and provide other service then i want to consume these topics in kafka to get the exact same mysql database for others to use does this make sensehow to realize this 