Problem comcodahalemetricshttpclientHttpClientMetricNameStrategies should also provide PATHANDMETHOD because most of the time we are interested only in path information Currently to get path metrics we use QUERYLESSURLANDMETHOD This is not a good practice because endpoints change frequently Suppose if we have dashboards alerting system or other dependents in place we need to change all of them with new metric names each time endpoint changes it will be really painful Solution we need something like this public static final HttpClientMetricNameStrategy PATHANDMETHOD name request final URIBuilder url new URIBuilderrequestURIrequest return nameHttpClientclass name urlgetPath methodNameStringrequest Bumps junit from to details summaryRelease notessummary pemSourced from a href releasesaemp blockquote h JUnit h pPlease refer to the a href notesa for detailsp h JUnit RC h pPlease refer to the a href notesa for detailsp h JUnit RC h pPlease refer to the a href notesa for detailsp h JUnit Beta h pPlease refer to the a href notesa for detailsp h JUnit Beta h pPlease refer to the a href notesa for detailsp h JUnit Beta h pPlease refer to the a href notesa for detailsp blockquote details details summaryCommitssummary ul lia href mavenreleaseplugin prepare release r li lia href mavenreleaseplugin prepare for next development iterationli lia href mavenreleaseplugin prepare release r rc li lia href mavenreleaseplugin prepare for next development iterationli lia href mavenreleaseplugin prepare release r rc li lia href Ensure classes annotated with a href do not have a href lia href Never reorder classes annotated with a href lia href Remove reference to obsolete mailing listli lia href Delete outdated docsli lia href mavenreleaseplugin prepare for next development iterationli liAdditional commits viewable in a href viewali ul details br Dependabot compatibility score Dependabot will resolve any conflicts with this PR as long as you dont alter it yourself You can also trigger a rebase manually by commenting dependabot rebase dependabotautomergestart dependabotautomergeend details summaryDependabot commands and optionssummary br You can trigger Dependabot actions by commenting on this PR dependabot rebase will rebase this PR dependabot recreate will recreate this PR overwriting any edits that have been made to it dependabot merge will merge this PR after your CI passes on it dependabot squash and merge will squash and merge this PR after your CI passes on it dependabot cancel merge will cancel a previously requested merge and block automerging dependabot reopen will reopen this PR if it is closed dependabot close will close this PR and stop Dependabot recreating it You can achieve the same result by closing it manually dependabot ignore this major version will close this PR and stop Dependabot creating any more for this major version unless you reopen the PR or upgrade to it yourself dependabot ignore this minor version will close this PR and stop Dependabot creating any more for this minor version unless you reopen the PR or upgrade to it yourself dependabot ignore this dependency will close this PR and stop Dependabot creating any more for this dependency unless you reopen the PR or upgrade to it yourself dependabot use these labels will set the current labels as the default for future PRs for this repo and language dependabot use these reviewers will set the current reviewers as the default for future PRs for this repo and language dependabot use these assignees will set the current assignees as the default for future PRs for this repo and language dependabot use this milestone will set the current milestone as the default for future PRs for this repo and language dependabot badge me will comment on this PR with code to add a Dependabot enabled badge to your readme Additionally you can set the following in your Dependabot dashboard Update frequency including time of day and day of week Pull request limits per update run andor open at any time Automerge options neverpatchminor and devruntime dependencies Outofrange updates receive only lockfile updates if desired Security updates receive only security updates if desired details Currently interface Reservoir has a method void updatelong value migrating to double value would extend the use Reservoir for stats purposes with real numbers with no significative loss Problem Statement The current implementation of ScheduledReporter relies on a ScheduledExecutorService scheduled at fixed rate thisscheduledFuture executorscheduleAtFixedRaterunnable initialDelay period unit Every period a thread will report except when one of the Gauge implementations getValue is slower than that period for example network latency In that case threads will start to accumulate When the latency is resolved there will be a spike of report requests Reproducible Scenario To reproduce have a gauge that sleeps seconds the first three times then the upcoming times before returning a value a ScheduledReporter with a delay of seconds that prints all gauges You will get reports at and Possible solution I suggest to replace executorscheduleAtFixedRate with executorscheduleWithFixedDelay so that the next call to report is separated by period with respect to the previous call instead of having an absolute period We got NoClassDefFoundError on loading comsunmanagementUnixOperatingSystemMXBean when accessing FileDescriptorRatioGauge on OpenJDK OpenJ build suspected using SunOracle internal class which should only works on Oracle HotSpot JDK Suggest to check class accessibility before type casting Stacktrace javalangNoClassDefFoundError comsunmanagementUnixOperatingSystemMXBean at comcodahalemetricsjvmFileDescriptorRatioGaugegetRatioFileDescriptorRatioGaugejava at comcodahalemetricsRatioGaugegetValueRatioGaugejava at comcodahalemetricsRatioGaugegetValueRatioGaugejava at comcodahalemetricsjsonMetricsModuleGaugeSerializerserializeMetricsModulejava at comcodahalemetricsjsonMetricsModuleGaugeSerializerserializeMetricsModulejava at comfasterxmljacksondatabindserstdMapSerializerserializeFieldsMapSerializerjava at comfasterxmljacksondatabindserstdMapSerializerserializeMapSerializerjava at comfasterxmljacksondatabindserstdMapSerializerserializeMapSerializerjava at comfasterxmljacksondatabindserDefaultSerializerProviderserializeDefaultSerializerProviderjava at comfasterxmljacksondatabindserDefaultSerializerProviderserializeValueDefaultSerializerProviderjava at comfasterxmljacksondatabindObjectMapperwriteValueObjectMapperjava at comfasterxmljacksoncorebaseGeneratorBasewriteObjectGeneratorBasejava at comfasterxmljacksoncoreJsonGeneratorwriteObjectFieldJsonGeneratorjava at comcodahalemetricsjsonMetricsModuleMetricRegistrySerializerserializeMetricsModulejava at comcodahalemetricsjsonMetricsModuleMetricRegistrySerializerserializeMetricsModulejava at comfasterxmljacksondatabindserDefaultSerializerProviderserializeDefaultSerializerProviderjava at comfasterxmljacksondatabindserDefaultSerializerProviderserializeValueDefaultSerializerProviderjava at comfasterxmljacksondatabindObjectWriterPrefetchserializeObjectWriterjava at comfasterxmljacksondatabindObjectWriterconfigAndWriteValueObjectWriterjava at comfasterxmljacksondatabindObjectWriterwriteValueObjectWriterjava at comcodahalemetricsservletsMetricsServletdoGetMetricsServletjava During a heap dump analysis for a long running process I noticed the comcodahalemetricsWeightedSnapshotWeightedSample class being in the top of my histogram for number of items currently A heap analysis tool determined that of these instances are garbage While this doesnt take up a large amount of memory it appears that they arent getting gcd I am wondering under what circumstances might this occur and if upgrading from our current use of would help this issue at all There is a warning here that says We don t recommend that you try to gather metrics from your production environment JMX s RPC API is fragile and bonkers For development purposes and browsing though it can be very useful Is this implying the JmxReporter isnt ready for production use or its the opinion of the metrics team that JMX itself or metrics in general shouldnt be used in production Add unit tests for InstrumentedExecutorServiceinvokeAll methods I am getting this exception write failed I am checking for isConnected before and then doing send and flush javanetSocketException Connection timed out Write failed at javanetSocketOutputStreamsocketWrite Native Method at javanetSocketOutputStreamsocketWriteSocketOutputStreamjava at javanetSocketOutputStreamwriteSocketOutputStreamjava at sunniocsStreamEncoderwriteBytesStreamEncoderjava at sunniocsStreamEncoderimplFlushBufferStreamEncoderjava at sunniocsStreamEncoderimplFlushStreamEncoderjava at sunniocsStreamEncoderflushStreamEncoderjava at javaioOutputStreamWriterflushOutputStreamWriterjava at javaioBufferedWriterflushBufferedWriterjava at comcodahalemetricsgraphiteGraphiteflushGraphitejava at comwalmartrumpoolsGraphiteConnectionflushGraphiteConnectionscala Adding a new function removeAll inverse to registerAll to remove all the metrics in the metrics set