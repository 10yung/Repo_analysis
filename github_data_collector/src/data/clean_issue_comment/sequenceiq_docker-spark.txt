 This is great can we have support for Support for spark Hi guys Someone can help me It my first time to install and use Spark Actually im installing spark binhadoop in Windows I encountered many issues but now when i write this command sparkshell in the CMD i received the message like this bellow WARN NativeCodeLoader Unable to load nativehadoop library for your platform using builtinjava classes where applicable Setting default log level to WARN To adjust logging level use scsetLogLevelnewLevel For SparkR use setLogLevelnewLevel Spark context Web UI available at Spark context available as sc master local app id local Spark session available as spark Welcome to version Using Scala version Java HotSpotTM Bit Server VM Java Type in expressions to have them evaluated Type help for more information What can i do exactly and what that mean do I need to install another library If yes which Thanks in advance for your help hi i get the following error it seems randomly sometimes it works any idea why docker run it p p p h sandbox sequenceiqspark bash Starting sshd OK Starting namenodes on sandbox sandbox starting namenode logging to usrlocalhadooplogshadooprootnamenodesandboxout localhost starting datanode logging to usrlocalhadooplogshadooprootdatanodesandboxout Starting secondary namenodes starting secondarynamenode logging to usrlocalhadooplogshadooprootsecondarynamenodesandboxout starting yarn daemons starting resourcemanager logging to usrlocalhadooplogsyarnresourcemanagersandboxout localhost starting nodemanager logging to usrlocalhadooplogsyarnrootnodemanagersandboxout chown missing operand after usrlocalhadooplogs Try chown help for more information starting historyserver logging to usrlocalhadooplogsmapredhistoryserversandboxout bash bash bash sparksubmit class orgapachesparkexamplesSparkPi master yarn drivermemory g executormemory g executorcores SPARKHOMEexamplesjarssparkexamplesjar INFO sparkSparkContext Running Spark version WARN sparkSparkContext Support for Java is deprecated as of Spark WARN utilNativeCodeLoader Unable to load nativehadoop library for your platform using builtinjava classes where applicable INFO sparkSecurityManager Changing view acls to root INFO sparkSecurityManager Changing modify acls to root INFO sparkSecurityManager Changing view acls groups to INFO sparkSecurityManager Changing modify acls groups to INFO sparkSecurityManager SecurityManager authentication disabled ui acls disabled users with view permissions Setroot groups with view permissions Set users with modify permissions Setroot groups with modify permissions Set INFO utilUtils Successfully started service sparkDriver on port INFO sparkSparkEnv Registering MapOutputTracker INFO sparkSparkEnv Registering BlockManagerMaster INFO storageBlockManagerMasterEndpoint Using orgapachesparkstorageDefaultTopologyMapper for getting topology information INFO storageBlockManagerMasterEndpoint BlockManagerMasterEndpoint up INFO storageDiskBlockManager Created local directory at tmpblockmgr ef bf adf b f b d INFO memoryMemoryStore MemoryStore started with capacity MB INFO sparkSparkEnv Registering OutputCommitCoordinator INFO utillog Logging initialized ms INFO serverServer jetty zSNAPSHOT INFO handlerContextHandler Started osjsServletContextHandler f jobsnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler b e ejobsjsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler a d jobsjobnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler ddcc jobsjobjsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler fb caa stagesnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler d e stagesjsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler eaa dstagesstagenullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandlerb de fstagesstagejsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler f b a stagespoolnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler bb d stagespooljsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler d c storagenullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler c c storagejsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler e storagerddnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler f storagerddjsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler c denvironmentnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler fa e environmentjsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler eexecutorsnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler b df executorsjsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler faf executorsthreadDumpnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler ba c executorsthreadDumpjsonnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler c b c staticnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler nullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler dapinullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler b jobsjobkillnullAVAILABLE INFO handlerContextHandler Started osjsServletContextHandler daff bstagesstagekillnullAVAILABLE INFO serverServerConnector Started ServerConnector c HTTP INFO serverServer Started ms INFO utilUtils Successfully started service SparkUI on port INFO uiSparkUI Bound SparkUI to and started at INFO sparkSparkContext Added JAR fileusrlocalsparkexamplesjarssparkexamples jar at spark jarssparkexamples jar with timestamp INFO clientRMProxy Connecting to ResourceManager at INFO yarnClient Requesting a new application from cluster with NodeManagers INFO yarnClient Verifying our application has not requested more than the maximum memory capability of the cluster MB per container INFO yarnClient Will allocate AM container with MB memory including MB overhead INFO yarnClient Setting up container launch context for our AM INFO yarnClient Setting up the launch environment for our AM container INFO yarnClient Preparing resources for our AM container WARN yarnClient Failed to cleanup staging dir hdfssandbox userrootsparkStagingapplication orgapachehadoopipcRemoteExceptionorgapachehadoophdfsservernamenodeSafeModeException Cannot delete userrootsparkStagingapplication Name node is in safe mode The reported blocks has reached the threshold of total blocks The number of live datanodes has reached the minimum number In safe mode extension Safe mode will be turned off automatically in seconds at orgapachehadoophdfsservernamenodeFSNamesystemcheckNameNodeSafeModeFSNamesystemjava at orgapachehadoophdfsservernamenodeFSNamesystemdeleteFSNamesystemjava at orgapachehadoophdfsservernamenodeNameNodeRpcServerdeleteNameNodeRpcServerjava at orgapachehadoophdfsprotocolPBClientNamenodeProtocolServerSideTranslatorPBdeleteClientNamenodeProtocolServerSideTranslatorPBjava at orgapachehadoophdfsprotocolprotoClientNamenodeProtocolProtosClientNamenodeProtocol callBlockingMethodClientNamenodeProtocolProtosjava at orgapachehadoopipcProtobufRpcEngineServerProtoBufRpcInvokercallProtobufRpcEnginejava at orgapachehadoopipcRPCServercallRPCjava at orgapachehadoopipcServerHandler runServerjava at orgapachehadoopipcServerHandler runServerjava at javasecurityAccessControllerdoPrivilegedNative Method at javaxsecurityauthSubjectdoAsSubjectjava at orgapachehadoopsecurityUserGroupInformationdoAsUserGroupInformationjava at orgapachehadoopipcServerHandlerrunServerjava at orgapachehadoopipcClientcallClientjava at orgapachehadoopipcClientcallClientjava at orgapachehadoopipcProtobufRpcEngineInvokerinvokeProtobufRpcEnginejava at comsunproxyProxy deleteUnknown Source at orgapachehadoophdfsprotocolPBClientNamenodeProtocolTranslatorPBdeleteClientNamenodeProtocolTranslatorPBjava at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachehadoopioretryRetryInvocationHandlerinvokeMethodRetryInvocationHandlerjava at orgapachehadoopioretryRetryInvocationHandlerinvokeRetryInvocationHandlerjava at comsunproxyProxy deleteUnknown Source at orgapachehadoophdfsDFSClientdeleteDFSClientjava at orgapachehadoophdfsDistributedFileSystem doCallDistributedFileSystemjava at orgapachehadoophdfsDistributedFileSystem doCallDistributedFileSystemjava at orgapachehadoopfsFileSystemLinkResolverresolveFileSystemLinkResolverjava at orgapachehadoophdfsDistributedFileSystemdeleteDistributedFileSystemjava at orgapachesparkdeployyarnClientcleanupStagingDirClientscala at orgapachesparkdeployyarnClientsubmitApplicationClientscala at orgapachesparkschedulerclusterYarnClientSchedulerBackendstartYarnClientSchedulerBackendscala at orgapachesparkschedulerTaskSchedulerImplstartTaskSchedulerImplscala at orgapachesparkSparkContextinitSparkContextscala at orgapachesparkSparkContextgetOrCreateSparkContextscala at orgapachesparksqlSparkSessionBuilderanonfun applySparkSessionscala at orgapachesparksqlSparkSessionBuilderanonfun applySparkSessionscala at scalaOptiongetOrElseOptionscala at orgapachesparksqlSparkSessionBuildergetOrCreateSparkSessionscala at orgapachesparkexamplesSparkPimainSparkPiscala at orgapachesparkexamplesSparkPimainSparkPiscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachesparkdeploySparkSubmitorgapachesparkdeploySparkSubmitrunMainSparkSubmitscala at orgapachesparkdeploySparkSubmitdoRunMain SparkSubmitscala at orgapachesparkdeploySparkSubmitsubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala ERROR sparkSparkContext Error initializing SparkContext orgapachehadoopipcRemoteExceptionorgapachehadoophdfsservernamenodeSafeModeException Cannot create directory userrootsparkStagingapplication Name node is in safe mode The reported blocks has reached the threshold of total blocks The number of live datanodes has reached the minimum number In safe mode extension Safe mode will be turned off automatically in seconds at orgapachehadoophdfsservernamenodeFSNamesystemcheckNameNodeSafeModeFSNamesystemjava at orgapachehadoophdfsservernamenodeFSNamesystemmkdirsFSNamesystemjava at orgapachehadoophdfsservernamenodeNameNodeRpcServermkdirsNameNodeRpcServerjava at orgapachehadoophdfsprotocolPBClientNamenodeProtocolServerSideTranslatorPBmkdirsClientNamenodeProtocolServerSideTranslatorPBjava at orgapachehadoophdfsprotocolprotoClientNamenodeProtocolProtosClientNamenodeProtocol callBlockingMethodClientNamenodeProtocolProtosjava at orgapachehadoopipcProtobufRpcEngineServerProtoBufRpcInvokercallProtobufRpcEnginejava at orgapachehadoopipcRPCServercallRPCjava at orgapachehadoopipcServerHandler runServerjava at orgapachehadoopipcServerHandler runServerjava at javasecurityAccessControllerdoPrivilegedNative Method at javaxsecurityauthSubjectdoAsSubjectjava at orgapachehadoopsecurityUserGroupInformationdoAsUserGroupInformationjava at orgapachehadoopipcServerHandlerrunServerjava at orgapachehadoopipcClientcallClientjava at orgapachehadoopipcClientcallClientjava at orgapachehadoopipcProtobufRpcEngineInvokerinvokeProtobufRpcEnginejava at comsunproxyProxy mkdirsUnknown Source at orgapachehadoophdfsprotocolPBClientNamenodeProtocolTranslatorPBmkdirsClientNamenodeProtocolTranslatorPBjava at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachehadoopioretryRetryInvocationHandlerinvokeMethodRetryInvocationHandlerjava at orgapachehadoopioretryRetryInvocationHandlerinvokeRetryInvocationHandlerjava at comsunproxyProxy mkdirsUnknown Source at orgapachehadoophdfsDFSClientprimitiveMkdirDFSClientjava at orgapachehadoophdfsDFSClientmkdirsDFSClientjava at orgapachehadoophdfsDistributedFileSystem doCallDistributedFileSystemjava at orgapachehadoophdfsDistributedFileSystem doCallDistributedFileSystemjava at orgapachehadoopfsFileSystemLinkResolverresolveFileSystemLinkResolverjava at orgapachehadoophdfsDistributedFileSystemmkdirsInternalDistributedFileSystemjava at orgapachehadoophdfsDistributedFileSystemmkdirsDistributedFileSystemjava at orgapachehadoopfsFileSystemmkdirsFileSystemjava at orgapachehadoopfsFileSystemmkdirsFileSystemjava at orgapachesparkdeployyarnClientprepareLocalResourcesClientscala at orgapachesparkdeployyarnClientcreateContainerLaunchContextClientscala at orgapachesparkdeployyarnClientsubmitApplicationClientscala at orgapachesparkschedulerclusterYarnClientSchedulerBackendstartYarnClientSchedulerBackendscala at orgapachesparkschedulerTaskSchedulerImplstartTaskSchedulerImplscala at orgapachesparkSparkContextinitSparkContextscala at orgapachesparkSparkContextgetOrCreateSparkContextscala at orgapachesparksqlSparkSessionBuilderanonfun applySparkSessionscala at orgapachesparksqlSparkSessionBuilderanonfun applySparkSessionscala at scalaOptiongetOrElseOptionscala at orgapachesparksqlSparkSessionBuildergetOrCreateSparkSessionscala at orgapachesparkexamplesSparkPimainSparkPiscala at orgapachesparkexamplesSparkPimainSparkPiscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachesparkdeploySparkSubmitorgapachesparkdeploySparkSubmitrunMainSparkSubmitscala at orgapachesparkdeploySparkSubmitdoRunMain SparkSubmitscala at orgapachesparkdeploySparkSubmitsubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala INFO serverServerConnector Stopped ServerConnector c HTTP INFO handlerContextHandler Stopped osjsServletContextHandler daff bstagesstagekillnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler b jobsjobkillnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler dapinullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler nullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler c b c staticnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler ba c executorsthreadDumpjsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler faf executorsthreadDumpnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler b df executorsjsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler eexecutorsnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler fa e environmentjsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler c denvironmentnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler f storagerddjsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler e storagerddnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler c c storagejsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler d c storagenullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler bb d stagespooljsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler f b a stagespoolnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandlerb de fstagesstagejsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler eaa dstagesstagenullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler d e stagesjsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler fb caa stagesnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler ddcc jobsjobjsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler a d jobsjobnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler b e ejobsjsonnullUNAVAILABLE INFO handlerContextHandler Stopped osjsServletContextHandler f jobsnullUNAVAILABLE INFO uiSparkUI Stopped Spark web UI at WARN clusterYarnSchedulerBackendYarnSchedulerEndpoint Attempted to request executors before the AM has registered INFO clusterYarnClientSchedulerBackend Stopped INFO sparkMapOutputTrackerMasterEndpoint MapOutputTrackerMasterEndpoint stopped INFO memoryMemoryStore MemoryStore cleared INFO storageBlockManager BlockManager stopped INFO storageBlockManagerMaster BlockManagerMaster stopped WARN metricsMetricsSystem Stopping a MetricsSystem that is not running INFO schedulerOutputCommitCoordinatorOutputCommitCoordinatorEndpoint OutputCommitCoordinator stopped INFO sparkSparkContext Successfully stopped SparkContext Exception in thread main orgapachehadoopipcRemoteExceptionorgapachehadoophdfsservernamenodeSafeModeException Cannot create directory userrootsparkStagingapplication Name node is in safe mode The reported blocks has reached the threshold of total blocks The number of live datanodes has reached the minimum number In safe mode extension Safe mode will be turned off automatically in seconds at orgapachehadoophdfsservernamenodeFSNamesystemcheckNameNodeSafeModeFSNamesystemjava at orgapachehadoophdfsservernamenodeFSNamesystemmkdirsFSNamesystemjava at orgapachehadoophdfsservernamenodeNameNodeRpcServermkdirsNameNodeRpcServerjava at orgapachehadoophdfsprotocolPBClientNamenodeProtocolServerSideTranslatorPBmkdirsClientNamenodeProtocolServerSideTranslatorPBjava at orgapachehadoophdfsprotocolprotoClientNamenodeProtocolProtosClientNamenodeProtocol callBlockingMethodClientNamenodeProtocolProtosjava at orgapachehadoopipcProtobufRpcEngineServerProtoBufRpcInvokercallProtobufRpcEnginejava at orgapachehadoopipcRPCServercallRPCjava at orgapachehadoopipcServerHandler runServerjava at orgapachehadoopipcServerHandler runServerjava at javasecurityAccessControllerdoPrivilegedNative Method at javaxsecurityauthSubjectdoAsSubjectjava at orgapachehadoopsecurityUserGroupInformationdoAsUserGroupInformationjava at orgapachehadoopipcServerHandlerrunServerjava at orgapachehadoopipcClientcallClientjava at orgapachehadoopipcClientcallClientjava at orgapachehadoopipcProtobufRpcEngineInvokerinvokeProtobufRpcEnginejava at comsunproxyProxy mkdirsUnknown Source at orgapachehadoophdfsprotocolPBClientNamenodeProtocolTranslatorPBmkdirsClientNamenodeProtocolTranslatorPBjava at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachehadoopioretryRetryInvocationHandlerinvokeMethodRetryInvocationHandlerjava at orgapachehadoopioretryRetryInvocationHandlerinvokeRetryInvocationHandlerjava at comsunproxyProxy mkdirsUnknown Source at orgapachehadoophdfsDFSClientprimitiveMkdirDFSClientjava at orgapachehadoophdfsDFSClientmkdirsDFSClientjava at orgapachehadoophdfsDistributedFileSystem doCallDistributedFileSystemjava at orgapachehadoophdfsDistributedFileSystem doCallDistributedFileSystemjava at orgapachehadoopfsFileSystemLinkResolverresolveFileSystemLinkResolverjava at orgapachehadoophdfsDistributedFileSystemmkdirsInternalDistributedFileSystemjava at orgapachehadoophdfsDistributedFileSystemmkdirsDistributedFileSystemjava at orgapachehadoopfsFileSystemmkdirsFileSystemjava at orgapachehadoopfsFileSystemmkdirsFileSystemjava at orgapachesparkdeployyarnClientprepareLocalResourcesClientscala at orgapachesparkdeployyarnClientcreateContainerLaunchContextClientscala at orgapachesparkdeployyarnClientsubmitApplicationClientscala at orgapachesparkschedulerclusterYarnClientSchedulerBackendstartYarnClientSchedulerBackendscala at orgapachesparkschedulerTaskSchedulerImplstartTaskSchedulerImplscala at orgapachesparkSparkContextinitSparkContextscala at orgapachesparkSparkContextgetOrCreateSparkContextscala at orgapachesparksqlSparkSessionBuilderanonfun applySparkSessionscala at orgapachesparksqlSparkSessionBuilderanonfun applySparkSessionscala at scalaOptiongetOrElseOptionscala at orgapachesparksqlSparkSessionBuildergetOrCreateSparkSessionscala at orgapachesparkexamplesSparkPimainSparkPiscala at orgapachesparkexamplesSparkPimainSparkPiscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachesparkdeploySparkSubmitorgapachesparkdeploySparkSubmitrunMainSparkSubmitscala at orgapachesparkdeploySparkSubmitdoRunMain SparkSubmitscala at orgapachesparkdeploySparkSubmitsubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala INFO utilShutdownHookManager Shutdown hook called INFO utilShutdownHookManager Deleting directory tmpsparkcb c ec a aaad fa cbee b You and try with docker pull bananacodingsparkhadoop sparkshell screenshot sparksubmit screenshot I tried doing a wget on my docker container from sequenceip and I keep getting the following error My command in the Dockerfile RUN yum update yum install wget y note also tried with just yum install without the update first Output The command binsh c yum update yum install wget y returned a nonzero code Full trace of related output Step RUN yum install wget y Running in bc a c fae a Loaded plugins fastestmirror keys protectpackages protectbase Determining fastest mirrors base mirrorlugudeledu epel mirrorusleasewebnet extras mirrorcogentcocom updates mirrorlinuxdukeedu packages excluded due to repository protections Setting up Install Process Resolving Dependencies Running transaction check Package wgetx el will be installed Finished Dependency Resolution Dependencies Resolved Package Arch Version Repository Size Installing wget x el base k Transaction Summary Install Packages Total download size k Installed size M Downloading Packages Running rpmcheckdebug Running Transaction Test Transaction Test Succeeded Running Transaction Installing wget el x Rpmdb checksum is invalid dCDPTpkg checksums wgetx el u The command binsh c yum install wget y returned a nonzero code I havent done a lot of testing but this updates the Dockerfile to support Spark Ive also pushed this image as michaelmiorspark for anyone who wants to do a quick test 