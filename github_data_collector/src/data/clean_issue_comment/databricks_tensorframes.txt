Py JJavaError An error occurred while calling o analyze orgapachesparkSparkException Job aborted due to stage failure Task in stage failed times most recent failure Lost task in stage TID executor javalangNoClassDefFoundError Could not initialize class orgtensorframesimplSupportedOperations at orgtensorframesExtraOperationsanalyzeDataExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionIndexedSeqOptimizedclassforeachIndexedSeqOptimizedscala at scalacollectionmutableWrappedArrayforeachWrappedArrayscala at scalacollectionTraversableLikeclassmapTraversableLikescala at scalacollectionAbstractTraversablemapTraversablescala at orgtensorframesExtraOperationsanalyzeDataExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun anonfun anonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun anonfun anonfun applyExperimentalOperationsscala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionimmutableRangeforeachRangescala at scalacollectionTraversableLikeclassmapTraversableLikescala at scalacollectionAbstractTraversablemapTraversablescala at orgtensorframesExtraOperationsanonfun anonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun anonfun applyExperimentalOperationsscala at scalacollectionIteratoranon nextIteratorscala at scalacollectionIteratorclassforeachIteratorscala at scalacollectionAbstractIteratorforeachIteratorscala at scalacollectionTraversableOnceclassreduceLeftTraversableOncescala at scalacollectionAbstractIteratorreduceLeftIteratorscala at scalacollectionTraversableOnceclassreduceLeftOptionTraversableOncescala at scalacollectionAbstractIteratorreduceLeftOptionIteratorscala at scalacollectionTraversableOnceclassreduceOptionTraversableOncescala at scalacollectionAbstractIteratorreduceOptionIteratorscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at orgapachesparkrddRDDanonfunmapPartitions anonfunapply applyRDDscala at orgapachesparkrddRDDanonfunmapPartitions anonfunapply applyRDDscala at orgapachesparkrddMapPartitionsRDDcomputeMapPartitionsRDDscala at orgapachesparkrddRDDcomputeOrReadCheckpointRDDscala at orgapachesparkrddRDDiteratorRDDscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunneranonfun applyExecutorscala at orgapachesparkutilUtilstryWithSafeFinallyUtilsscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Driver stacktrace at orgapachesparkschedulerDAGSchedulerorgapachesparkschedulerDAGSchedulerfailJobAndIndependentStagesDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at scalacollectionmutableResizableArrayclassforeachResizableArrayscala at scalacollectionmutableArrayBufferforeachArrayBufferscala at orgapachesparkschedulerDAGSchedulerabortStageDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at scalaOptionforeachOptionscala at orgapachesparkschedulerDAGSchedulerhandleTaskSetFailedDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLoopdoOnReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkutilEventLoopanon runEventLoopscala at orgapachesparkschedulerDAGSchedulerrunJobDAGSchedulerscala at orgapachesparkSparkContextrunJobSparkContextscala at orgapachesparkSparkContextrunJobSparkContextscala at orgapachesparkSparkContextrunJobSparkContextscala at orgapachesparkSparkContextrunJobSparkContextscala at orgapachesparkrddRDDanonfuncollect applyRDDscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparkrddRDDwithScopeRDDscala at orgapachesparkrddRDDcollectRDDscala at orgtensorframesExtraOperationsdeepAnalyzeDataFrameExperimentalOperationsscala at orgtensorframesExperimentalOperationsclassanalyzeExperimentalOperationsscala at orgtensorframesimplDebugRowOpsanalyzeDebugRowOpsscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at py jreflectionMethodInvokerinvokeMethodInvokerjava at py jreflectionReflectionEngineinvokeReflectionEnginejava at py jGatewayinvokeGatewayjava at py jcommandsAbstractCommandinvokeMethodAbstractCommandjava at py jcommandsCallCommandexecuteCallCommandjava at py jGatewayConnectionrunGatewayConnectionjava at javalangThreadrunThreadjava Caused by javalangNoClassDefFoundError Could not initialize class orgtensorframesimplSupportedOperations at orgtensorframesExtraOperationsanalyzeDataExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionIndexedSeqOptimizedclassforeachIndexedSeqOptimizedscala at scalacollectionmutableWrappedArrayforeachWrappedArrayscala at scalacollectionTraversableLikeclassmapTraversableLikescala at scalacollectionAbstractTraversablemapTraversablescala at orgtensorframesExtraOperationsanalyzeDataExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun anonfun anonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun anonfun anonfun applyExperimentalOperationsscala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionimmutableRangeforeachRangescala at scalacollectionTraversableLikeclassmapTraversableLikescala at scalacollectionAbstractTraversablemapTraversablescala at orgtensorframesExtraOperationsanonfun anonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun anonfun applyExperimentalOperationsscala at scalacollectionIteratoranon nextIteratorscala at scalacollectionIteratorclassforeachIteratorscala at scalacollectionAbstractIteratorforeachIteratorscala at scalacollectionTraversableOnceclassreduceLeftTraversableOncescala at scalacollectionAbstractIteratorreduceLeftIteratorscala at scalacollectionTraversableOnceclassreduceLeftOptionTraversableOncescala at scalacollectionAbstractIteratorreduceLeftOptionIteratorscala at scalacollectionTraversableOnceclassreduceOptionTraversableOncescala at scalacollectionAbstractIteratorreduceOptionIteratorscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at orgtensorframesExtraOperationsanonfun applyExperimentalOperationsscala at orgapachesparkrddRDDanonfunmapPartitions anonfunapply applyRDDscala at orgapachesparkrddRDDanonfunmapPartitions anonfunapply applyRDDscala at orgapachesparkrddMapPartitionsRDDcomputeMapPartitionsRDDscala at orgapachesparkrddRDDcomputeOrReadCheckpointRDDscala at orgapachesparkrddRDDiteratorRDDscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunneranonfun applyExecutorscala at orgapachesparkutilUtilstryWithSafeFinallyUtilsscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava more Change to use bintray instead of local After having followed the documentation to connect Databricks to Pycharm I am not able to run the sample example in car I get an error Notice that the connection seem to work car at the beginning is checking the cluster status and is executing it after that the error occurs on the spark command execution WARN NativeCodeLoader Unable to load nativehadoop library for your platform using builtinjava classes where applicable Using Sparks default log j profile orgapachesparklog jdefaultsproperties Setting default log level to WARN To adjust logging level use scsetLogLevelnewLevel For SparkR use setLogLevelnewLevel WARN MetricsSystem Using default name SparkStatusTracker for source because neither sparkmetricsnamespace nor sparkappid is set Testing simple count WARN HTTPClient Setting proxy configuration for HTTP client based on env var HTTPSPROXY WARN SparkClientManager Cluster xxx in state PENDING waiting for it to start running WARN SparkClientManager Cluster xxx in state PENDING waiting for it to start running WARN SparkClientManager Cluster xxx in state PENDING waiting for it to start running Traceback most recent call last File CUsersmynamePycharmProjectsDatabricksmainpy line in module printsparkrange count File C Users myname AppData Local Continuum anaconda envs dbconnect lib sitepackages pyspark sql sessionpy line in range jdf selfjsparkSessionrange intstart intstep intnumPartitions File C Users myname AppData Local Continuum anaconda envs dbconnect lib sitepackages py j javagatewaypy line in call answer selfgatewayclient selftargetid selfname File C Users myname AppData Local Continuum anaconda envs dbconnect lib sitepackages pyspark sql utilspy line in deco return fa kw File C Users myname AppData Local Continuum anaconda envs dbconnect lib sitepackages py j protocolpy line in getreturnvalue formattargetid name value py jprotocolPy JJavaError An error occurred while calling o range javalangNoClassDefFoundError comtrueaccordscalapbGeneratedMessage at javalangClassLoaderdefineClass Native Method at javalangClassLoaderdefineClassUnknown Source at javasecuritySecureClassLoaderdefineClassUnknown Source at javanetURLClassLoaderdefineClassUnknown Source at javanetURLClassLoaderaccess Unknown Source at javanetURLClassLoader runUnknown Source at javanetURLClassLoader runUnknown Source at javasecurityAccessControllerdoPrivilegedNative Method at javanetURLClassLoaderfindClassUnknown Source at javalangClassLoaderloadClassUnknown Source at sunmiscLauncherAppClassLoaderloadClassUnknown Source at javalangClassLoaderloadClassUnknown Source at comdatabricksserviceSparkServiceRPCClientStubcomdatabricksserviceSparkServiceRPCClientStubbuildRpcSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollStatuses applySparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollStatuses applySparkServiceRPCClientStubscala at comdatabrickssparkutilLog jUsageLoggerrecordOperationUsageLoggerscala at comdatabrickssparkutilUsageLoggingclassrecordOperationUsageLoggerscala at comdatabricksserviceSparkServiceRPCClientStubrecordOperationSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubpollStatusesSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubcomdatabricksserviceSparkServiceRPCClientStubpollAndUpdateStatuses SparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollAndUpdateStatuses anonfunapplymcVsp applymcVspSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollAndUpdateStatuses anonfunapplymcVsp applySparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollAndUpdateStatuses anonfunapplymcVsp applySparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubcomdatabricksserviceSparkServiceRPCClientStubwithPollLockSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollAndUpdateStatuses applymcVspSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollAndUpdateStatuses applySparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfunpollAndUpdateStatuses applySparkServiceRPCClientStubscala at comdatabrickssparkutilLog jUsageLoggerrecordOperationUsageLoggerscala at comdatabrickssparkutilUsageLoggingclassrecordOperationUsageLoggerscala at comdatabricksserviceSparkServiceRPCClientStubrecordOperationSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubpollAndUpdateStatusesSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfungetServerHadoopConf applySparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubanonfungetServerHadoopConf applySparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubcomdatabricksserviceSparkServiceRPCClientStubwithPollLockSparkServiceRPCClientStubscala at comdatabricksserviceSparkServiceRPCClientStubgetServerHadoopConfSparkServiceRPCClientStubscala at comdatabricksserviceSparkClientgetServerHadoopConfSparkClientscala at comdatabrickssparkutilSparkClientContextgetServerHadoopConfSparkClientContextscala at orgapachesparkSparkContextanonfunhadoopConfiguration applySparkContextscala at orgapachesparkSparkContextanonfunhadoopConfiguration applySparkContextscala at scalautilDynamicVariablewithValueDynamicVariablescala at orgapachesparkSparkContexthadoopConfigurationSparkContextscala at orgapachesparksqlinternalSharedStateinitSharedStatescala at orgapachesparksqlSparkSessionanonfunsharedState applySparkSessionscala at orgapachesparksqlSparkSessionanonfunsharedState applySparkSessionscala at scalaOptiongetOrElseOptionscala at orgapachesparksqlSparkSessionsharedStatelzycomputeSparkSessionscala at orgapachesparksqlSparkSessionsharedStateSparkSessionscala at orgapachesparksqlinternalBaseSessionStateBuilderbuildBaseSessionStateBuilderscala at orgapachesparksqlSparkSessionorgapachesparksqlSparkSessioninstantiateSessionStateSparkSessionscala at orgapachesparksqlSparkSessionanonfunsessionState applySparkSessionscala at orgapachesparksqlSparkSessionanonfunsessionState applySparkSessionscala at scalaOptiongetOrElseOptionscala at orgapachesparksqlSparkSessionsessionStatelzycomputeSparkSessionscala at orgapachesparksqlSparkSessionsessionStateSparkSessionscala at orgapachesparksqlDatasetinitDatasetscala at orgapachesparksqlSparkSessionrangeSparkSessionscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeUnknown Source at sunreflectDelegatingMethodAccessorImplinvokeUnknown Source at javalangreflectMethodinvokeUnknown Source at py jreflectionMethodInvokerinvokeMethodInvokerjava at py jreflectionReflectionEngineinvokeReflectionEnginejava at py jGatewayinvokeGatewayjava at py jcommandsAbstractCommandinvokeMethodAbstractCommandjava at py jcommandsCallCommandexecuteCallCommandjava at py jGatewayConnectionrunGatewayConnectionjava at javalangThreadrunUnknown Source Caused by javalangClassNotFoundException comtrueaccordscalapbGeneratedMessage at javanetURLClassLoaderfindClassUnknown Source at javalangClassLoaderloadClassUnknown Source at sunmiscLauncherAppClassLoaderloadClassUnknown Source at javalangClassLoaderloadClassUnknown Source more Process finished with exit code I have latest version of Protobuf after the error tried with thinking older stable version may solve the issue but issue still persists remotefusedgraphexecuteinfoproto is not getting compiled tensorframesmastersrcmainprotobuftensorflowcoreframeworkremotefusedgraphexecuteinfoproto javalangRuntimeException error occurred while compiling protobuf files Cannot run program protoc error No such file or directory at sbtprotobufScopedProtobufPluginexecuteProtocProtobufPluginscala at sbtprotobufScopedProtobufPluginsbtprotobufScopedProtobufPlugincompileProtobufPluginscala at sbtprotobufScopedProtobufPluginanonfunsourceGeneratorTask anonfun applyProtobufPluginscala at sbtprotobufScopedProtobufPluginanonfunsourceGeneratorTask anonfun applyProtobufPluginscala at sbtFileFunctionanonfuncached applyTrackedscala at sbtFileFunctionanonfuncached applyTrackedscala at sbtFileFunctionanonfuncached anonfunapply anonfunapply applyTrackedscala at sbtFileFunctionanonfuncached anonfunapply anonfunapply applyTrackedscala In import numpy as np In from sklearnmetrics import pairwisedistances In a nprandomrandn In b nprandomrandn In npallclosenpsqrtnplinalgnorma axis keepdimsTrue npmatmula bT nplinalgnormb axis keepdimsTrueT pairwisedistancesa b Out True In switches to sbtrelease to update version numbers We should make it manage the entire release so we can save some manual effort so string datatype is not acceptable to tensorframes tensor and also binary cant work with mapblocks only with maprows so if the user want to use contrib models they need to manually load the so files in java land lets find a easier way to enable that i have a columnplaceholder x with shape None and i want to obtain the mean which ill have to sum over all the vectors and i also want to obtain the mean of outer product which ill have to sum over all the outer product for each vector sumi xi otimes xi which will have shape it seems right now the reduceblock have some constraints on one input one output exactly mapping is there any reason 