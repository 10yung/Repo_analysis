I want to alter the contents of an automerge table by using Tablesetid UUID value T But Im having an issue that the connection callback sendMsg is not being fired after applying changes to a document The following part is properly working where I add a new object by using Tableadditem T Removing via Tableremoveid UUID is also working What could cause this issue This DOES work let document DocTodoDoc AutomergeinitTodoDoc let docset thisdocSetsetDocdocsetid thisdocument let connection ConnectionTodoDoc constructor thisconnection new ConnectionTodoDocthisdocSet thissendMessagebindthis thisconnectionopen const changedDoc Automergechangethisdocument Create todo doc DocTodoDoc const newTodo Todo id todoid title todotitle complete todocomplete createdAt todocreatedAt updatedAt new DatetoISOString doctodosaddnewTodo const currentChanges Change AutomergegetChangesthisdocument changedDoc thisdocSetapplyChangesdocsetid currentChanges This DOES NOT work const changedDoc Automergechangethisdocument Update todo doc DocTodoDoc const currentTodoById thisdocumenttodosbyIdtodoid currentTodoByIdtitle Updated Title currentTodoByIdcomplete true currentTodoByIdupdatedAt new DatetoISOString doctodossettodoid currentTodoById const currentChanges Change AutomergegetChangesthisdocument changedDoc thisdocSetapplyChangesdocsetid currentChanges After initializing a document with Automergefrom this patch changes the behaviour such that the initialization cannot be undone as suggested in Hi folks Ive been following the JSON CRDT awesomeness for a few years now From it sounds like performance for textordered lists gets rough for substantial documents possibly because of the underlying algorithm tradeoff of tombstones and fast insertremove So first question what is the current strategy for TextOrdered Lists OT RGA This code for example Follow up question Ive been using the LSEQ CRDT in collaborative frontend experiments for a few years like Google Docs Its a proper CRDT with some amazing performance properties especially for large documents keeping memory usage lower than W TLogoot or tombstone strategies but with Ologn for insertionremoval The implementation Ive been using supports the same insertAtremoveAt operations so Im thinking it might be straightforward to experiment with an alternative merge strategy What are your thoughts Any caveats or recommendations on how I could take this for a spin I am trying to utilize the libraries undo functionality however AutomergecanUndo is returning true when called immediately after the initialization of my document thisactionDoc Automergefrom clips initialClips AutomergecanUndothisactionDoc Displaying the history of the document immediately after initialization only shows the Initialization action Yet canUndo still returns true My question is why it makes sense to be able to undo the populating of the initial state Is there anyway to change the undo threshold Steps to reproduce Insert some characters into a Text in document Sync the changes to document Delete the characters in document Undo the insert in document Undo the delete in document Merge the changes Expected result Since the edit that inserted the characters was undone you would expect the inserted characters to be missing from the end result Actual result The characters are still present in the end result Example code js Setup var base Automergeinit base Automergechangebase Base text doc doctext new AutomergeText doctextinsertAt B A S E var doc Automergeinit doc Automergemergedoc base var doc Automergeinit doc Automergemergedoc base Insert some characters into a Text in document doc Automergechangedoc Insert doc doctextinsertAt i n s e r t Sync the changes to document doc Automergemergedoc doc Delete the characters in document doc Automergechangedoc Delete doc doctextdeleteAt Undo the insert in document doc Automergeundodoc Undo insert Undo the delete in document doc Automergeundodoc Undo delete Merge the changes var final Automergemergedoc doc Expected BASE Actual BAinsertSE consolelogfinaltexttoString Theres AutomergegetConflictsdoc key but this means I already need to know the conflicting key It would be nice to have for example AutomergegetConflictsdoc which returns x or even x actor so one can detect those conflicts and surface them to the user Moves all initialization tests to an initialization describe block directly under Automerge Adds tests for passing different types of values to Automergefrom an array a string a number and a boolean While looking through previous issues and pull requests I ve noticed a few mentions of a desire to move from vector clocks towards hash chaining for encoding the dependency graph After reading through these issues and pull requests there are a number of questions that come to mind Is this still something that is desired If not then the rest of the questions below become irrelevant Would it be okay if I started working towards adding this functionality It seems like adding hashbased integrity checking would be a good place to start with full hash chaining to follow Does this make sense Are there any backwardscompatibility concerns that would need to be kept in mind What are the expected benefits of using hash chaining over vector clocks A few potential benefits that jump to mind Dependency encoding becomes a fixed size for each change rather than the O of peers size that comes with vector clocks though that s only observed in the worst case given the recent change to remove transitive dependencies from changes I think we wouldn t need to store the states object any more instead we would only need to store a collection of each hash and its parents I think we wouldn t need to store clock or deps objects any more instead we would only need to store a set of the most recently observed concurrent hashes Any more What are the expected drawbacks of using hash chaining over vector clocks One of the issues mentions that we would need to use a multiround protocol to determine the latest common ancestor between peers Any others This is related to where I encounter a need for splitting text segments without making delete insert route As I was trying to find a solution I came across to RGASplit paper that happens to be foundation for xi editor atoms collaborative editing feature and their next generation code editor I think copyonwrite CRDT approach not only has promising performance improvements but also might offer some good solution for Rich Text modeling due to introduced split operation I imagine text blocks could be extended with additional metadata where formatting information could be stored and with that it would be possible to represent Rich Text without resorting to marker tokens as described in This is related to as I attempt to model rich text as series of tokens of characters and markers js formatitalictrueHello formatboldtrue italictruebeautifulformatnull world n As I was trying to figure out a best approach to this I noticed that AutomergeText would happily insert objects eg textinsertAt bold true which than would appear as objectIds inside the text related thread on slack Its also worth mentioning that AutomergegetObjectByIddoc objectId would actually return inserted object Im not sure what is the intended behavior here but I suspect that textjoin including objectId is highly unlikely It seemed like a convenient accident for my use case but Im suspicious there might be deeper consequences so I chose to use list or should I say array of tokens instead Either way I would like to propose To document how AutomergeText outperforms arrays as suggested by the readme Either throw if nontext is being inserted or omit objectIds in join and document non textual inserts bit more