Currently all implementations of a component type inputs processors outputs etc have documentation residing in a single long document These documents consist of a config example containing all fields and some text the text may describe the purpose of particular fields but most are undocumented It would be nice to expand the documentation of a component such that we see a config snippet a general description of the behaviour and purpose of the component followed by a break down of each field with further details where applicable In order to do that we certainly need to break out the docs for each component into their own page otherwise well end up bloating the docs We should therefore solve the following Doc pages per component implementation and a READMEmd that lists them in sections and provides componentwide advice a Should we also redirect docsinputsREADMEmdfoo to docsinputsfoomd Per field documentation Distinction between optional vs mandatory and common vs advanced fields a Should we limit the config example to only common fields Apache Pulsar is a distributed pubsub messaging system similar to Apache Kafka but significantly more flexible and arguably performs better It would be very useful to have inputoutput support for Pulsar in Benthos There is an officially supported golang client which wraps their official C client The kafka and kinesis inputs do not support batching at the output level This is currently covered in documentation but theres nothing stopping a user from missing it and falling into this hole Before the next major release where output batching is more prominent and obvious I need a solution Two currently off the top of my head Allow output level batching by tracking offsets Inputs that dont support output batching can add context to each message the output batcher then detects this and refuses to batch it with intermittent warning logs Tracking offsets would mean recording all offsets consumed and acked and allowing them to be processed out of sync Its not impossible but its a headache to ensure messages arent duplicated during restarts if a single message fails to propagate during shutdown then we reprocess any number of backlogged offsets This adds support for Saramas SASL access token providers to the Kafka inputs and outputs Since access token providers are callbacks a custom build of Benthos that registers the access token provider under a given name must be used that name is then used in the config to specify which access token provider to use For example we have a library that generates auth tokens based on our cloud providers IAM infrastructure the maingo against this branch looks something like this go package main import os githubcomJeffailbenthosv libinputreader githubcomJeffailbenthosv libservice examplecomiamauth func main provider iamauthNewJWTTokenProvider readerKafkaRegisterAccessTokenProvideriam provider serviceRun This has a corresponding input configuration along the lines of yaml input type kafka kafka addresses localhost sasl enabled true tokenprovider iam startfromoldest false topic example tls enabled true A static access token can also be specified via accesstoken this is useful for testing or for general purpose use if your tokens are longlived and you can get away without worrying about refreshes and dont want to build your own Benthos binary Benthos is useful thank you It would be cool if Benthos was able to reload configurations without a restart Initially this would simply involve stopping and starting the entire pipeline but eventually we might be able to optimise it to avoid downtime entirely We should investigate the feasibility of using SIGHUP as a signal to reload config We can also potentially add a REST endpoint Theres also the possibility of watching the config file for changes and reloading automatically or based on a configured interval Jeffail We have created our own custom processor which can use a redis cluster for rate limiting purposes and would like to contribute the code as new functionality in benthos Before getting started though I am wondering where and how it should be added in terms of structure I see a number of different approaches Create a new cache or redis rate limits resource effectively duplicating the existing cache resource and define new args for this functionality under the existing ratelimit processor Allow the ratelimit processor to use cache resources and define new args for this functionality Create a new ratelimitcache or ratelimitredis processor and disregard the ratelimits and cache resource types Any preferences between these or other ways of structuring this new functionality Im pushing my Benthos instances quite hard and Ive noticed that the application stals and becomes very slow when the memory buffer becomes large order of gigabytes Im under the impression that Benthos needs to do a lot of computation before being able to pop work of the memory buffer The outputs are working very slow at this point If Im restarting Benthos the outputs have higher throughput curl localhost metrics json benthos buffer ack error backlog latency latencyreadable m s read count error send error success write count error goroutines input batch received connection failed lost up count latency latencyreadable m s processor batch sent count error sent batch sent count error sent batch sent count error sent batch sent count error sent received running output batch bytes latency latencyreadable s sent broker outputs batch bytes latency latencyreadable s sent connection failed lost up count retry count endofretries parts send success running send error success sent connection failed lost up count retry count endofretries parts send success running send error success sent pipeline processor batch sent condition count false true count dropped oncondition oncount onperiod onsize sent batch sent count error sent success batch sent count error sent uptime h m s shell pmap usrlocalbinbenthos c etcbenthosconfyaml K rx benthos d K r benthos d K rw benthos daf K rw anon dcf K rw anon c K rw anon f da K rw anon f da f K anon f da K rw anon f da d K anon f dac K rw anon f daffd K anon f db K rw anon f db f e K anon f db K rw anon f db ff K anon f db K rw anon f dbbf b K anon f dbc K rw anon f dbffdf K anon f dc K rw anon f dc f K anon f dc K rw anon f dc fae K anon f dc K rw anon f dcbff K anon f dcc K rw anon f dcffe K anon f dd K rw anon f dd fd K anon f dd K rw anon f dd fb K anon f dd K rw anon f ddbf K anon f ddc K rw anon f ddfffb K anon f de K rw anon f de f K anon f de K rw anon f de f K anon f de K rw anon f debf K anon f dec K rw anon f deff f K anon f df d K rw anon f df a K rw anon f df K rw anon f df K anon f dfc K rw anon f dfc K anon f e K rw anon f e K anon f e b K rw anon f e K rw anon f e ffa K anon f e ffb K rw anon f e fb K anon f e fc K rw anon f e ffc K anon f e ffd K rw anon f e fd K anon f e fe K rw anon f e ffe K anon f e fff K rw anon f e ff K anon f e K rw anon f e K rw anon f e bfed K anon f e c K rw anon f e c K anon f e K rw anon f e K anon f e K rw anon f e K anon f e K rw anon f e K anon f e c K rw anon f e c f K anon f e c f K rw anon f e c f K anon f e c f K rw anon f e d f K anon f e d fa K rw anon f e d fa K anon f e d fb K rw anon f e e fb K rx libnssfiles so f e e K libnssfiles so f e e K r libnssfiles so f e e K rw libnssfiles so f e e K rw anon f e e d K rw anon f e e d K anon f e e e K rw anon f e ec e K anon f e ec f K rw anon f e f f K anon f e f K rw anon f e fc K anon f e fc K rw anon f e K anon f e K rw anon f e c K anon f e c K rw anon f e K anon f e K rw anon f e e K rx libresolv so f e e K libresolv so f e K r libresolv so f e K rw libresolv so f e a K rw anon f e c K rx libkeyutilsso f e f K libkeyutilsso f e e K r libkeyutilsso f e f K rw libkeyutilsso f e a K rx libkrb supportso f e ab K libkrb supportso f e aa K r libkrb supportso f e ab K rw libkrb supportso f e ac K rx libcomerrso f e af K libcomerrso f e ae K r libcomerrso f e af K rw libcomerrso f e b K rx libk cryptoso f e df K libk cryptoso f e df K r libk cryptoso f e e K rw libk cryptoso f e e K rw anon f e e K rx libkrb so f e ac K libkrb so f e bac K r libkrb so f e bba K rw libkrb so f e bbd K rx liblzmaso f e be K liblzmaso f e de K r liblzmaso f e de K rw liblzmaso f e de K rx libgccsso f e df K libgccsso f e ff K r libgccsso f e ff K rw libgccsso f e ffa K rx libm so f e fd K libm so f e fc K r libm so f e fd K rw libm so f e fe K rx libstdcso f e K libstdcso f e K r libstdcso f e a K rw libstdcso f e c K rw anon f e K rx librt so f e K librt so f e K r librt so f e K rw librt so f e K rx libdl so f e b K libdl so f e a a K r libdl so f e a b K rw libdl so f e a c K rx libgssapikrb so f e ad K libgssapikrb so f e cd K r libgssapikrb so f e cd K rw libgssapikrb so f e cd K rx libnormso f e d K libnormso f e f K r libnormso f e f c K rw libnormso f e f d K rw anon f e d K rx libpgm so f e K libpgm so f e K r libpgm so f e K rw libpgm so f e K rw anon f e a K rx libsodiumso f e be K libsodiumso f e be K r libsodiumso f e bf K rw libsodiumso f e c K rx libunwindso f e cc K libunwindso f e cb K rw libunwindso f e cc K rw anon f e db K rx libc so f e K libc so f e a K r libc so f e a K rw libc so f e a K rw anon f e a a K rx libzmqso f e b K libzmqso f e d K r libzmqso f e d K rw libzmqso f e d K rx libpthread so f e d K libpthread so f e f K r libpthread so f e f K rw libpthread so f e f a K rw anon f e f e K rx ld so f e f K rw anon f e K rw anon f e K r ld so f e K rw ld so f e K rw anon fff K rw stack fff f K r anon fff K rx anon ffffffffff K rx anon total K Currently our process has been running smoothly using Benthos but a new requirement has been added and we need support for TLS NSQ as input The current configuration for NSQ as an input does not give us the flexibility to pass in TLS options Having support for this will increase security measurements and allow us to pass vulnerability tests The current NSQ config could be updated and there could be a flag that if enabled could add on tlsv and the tlsconfig properties that way we can pass the require parameters and TLS can be enabled For example our current need would look like this if cEnableTLS nsqConfigSettlsv true nsqConfigSettlsconfig tlsConfig InsecureSkipVerify true Thank you Benthos has a huge amount of flexibility with processors such as processfield and processmap However most of the time users just want to perform a relatively simple and common operation on a field eg increment a value yaml processfield codec metadata path foo resulttype int processors number operator add value For that purpose we could use awk yaml pipeline processors awk program metadatasetfoo metadatagetfoo But theres a performance hit and it seems a little heavy handed for something so simple Perhaps we could add a more general solution for these common operators that doesnt require a full scripting engine