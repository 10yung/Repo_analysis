Bumps lodash from to details summaryCommitssummary ddfd b Bump to v b fce Rebuild lodash and docs be d Bump to v a fe b Rebuild lodash and docs e Bump to v e Rebuild lodash and docs fd a Bump to v e d Rebuild lodash and docs d Update OpenJS references eac Fix minified build Additional commits viewable in compare view details br Dependabot compatibility score Dependabot will resolve any conflicts with this PR as long as you dont alter it yourself You can also trigger a rebase manually by commenting dependabot rebase dependabotautomergestart dependabotautomergeend details summaryDependabot commands and optionssummary br You can trigger Dependabot actions by commenting on this PR dependabot rebase will rebase this PR dependabot recreate will recreate this PR overwriting any edits that have been made to it dependabot merge will merge this PR after your CI passes on it dependabot squash and merge will squash and merge this PR after your CI passes on it dependabot cancel merge will cancel a previously requested merge and block automerging dependabot reopen will reopen this PR if it is closed dependabot ignore this patchminormajor version will close this PR and stop Dependabot creating any more for this minormajor version unless you reopen the PR or upgrade to it yourself dependabot ignore this dependency will close this PR and stop Dependabot creating any more for this dependency unless you reopen the PR or upgrade to it yourself dependabot use these labels will set the current labels as the default for future PRs for this repo and language dependabot use these reviewers will set the current reviewers as the default for future PRs for this repo and language dependabot use these assignees will set the current assignees as the default for future PRs for this repo and language dependabot use this milestone will set the current milestone as the default for future PRs for this repo and language You can disable automated security fix PRs for this repo from the Security Alerts page details This switches to using Fun and fun in function types and values respectively mirroring the syntax of record types and values This avoides the following ambiguous syntax x A B This could either be parsed as a dependent function type a nondependent function with the input type annotated I was attempting to get around this in rustnbeformltt either by using parser combinators with ordered choice or a handrolled recursive descent parser but discovered that this would still require a significant amount of lookahead to resolve I m still open to discussing this further though The new syntax has the downside of being less succinct and I still find capitalised keywords a tad odd Closes Removing patterns from the core language in preparation for NbE Closes Our autobinding library Moniker is currently not pulling its weight in terms of making it easy to understand the internals of Pikelet and will make supporting a high performance compiler heading into the future In the words of kleimkuhler I know the times I ve explored enough into the codebase to get an idea of how you have implemented something I usually end up at a point where a binding occurs and I lose track a little Also from conversations on Gitter boomshroom and others have struggled with grasping Moniker so its not an isolated issue jonsterling has also noted on Twitter that he is not really a fan of using ABTs Abstract binding trees in implementations What I found is that unfortunately it is difficult to see the right way to code a specific thing unless I have handcoded the syntax Some kind of ABT thing that abstracted over bindingsensitive traversals would be nice but I concluded that the main point of ABTs which was to abstract over binding itself providing some interface with names and automatically freshening etc providing substitution is actually harmful for implementations Its not only this moniker is also standing in the way of using visitors in the compiler and will cause us performance problems down the line as Pikelet codebases get larger It also could make salsaadapton style incrementalism harder Requirements for name binding The problems we will have to tackle when moving to a new variable binding scheme is sound semantics captureavoiding substitution xe ex should not result in xx alpha equivalence xx should be equivalent to yy reduce the chance of messing up variable binding when adding new features support existing and upcoming features produce nice stable pretty names when pretty printing recursive bindings support reflection like in Idris Agda F Lean performance optimizations allow for stable names across incremental compilations see adapton and salsa reduce unnecessary tree traversals and variable shifts allow for vistorbased fusion resulting in reduced allocations and as closeto singlepass compilation as we can get Possible solutions We have a number of options open to us Nominal binding Use nominal binding like in David Christiansens NBE tutorial could be compatible with visitorbased futsion which might amortize some of the performance penalties pythonesque has expressed some concern over going down this route though especially when it comes to recursive bindings Graph libraries Use petgraph like in Program Synthesis is Possible in Rust Not sure how well this would support alpha equivalence though This feels similar to the Scope Graph stuff from A Theory of Name Resolution Im not sure if this has ever been applied to dependently typed languages though and it is offthe beaten track in terms of the mainline of research Locally Nameless Continue to use a locally nameless approach as with moniker but bring it into Pikelet This might result in lots of traversals though Lean has workarounds though Also not compatible with visitors Explicit substitutions with a fully representation Apparently locally nameless has not been proven stable under substitution for delayed substitutions so wed have to go with a fully nameless representation here like in autosubst This is well understood but might be harder to get to work with visitors The advantage would be that it would be quite close to what we would be doing in a theorem prover if we ever wanted to do a soundness proof of Pikelet Use semantic type checking This is what jonsterling has advocated to me on Twitter I base my stuff on an algorithm that I think comes from Thierry Coquand called semantic type checking The main idea is as follows Have a syntax based on De Bruijn indices You dont even need to implement any operations on the syntax This syntax will serve as the unchecked inputs to your judgments Like the M in G M A Have a semantic domain based on De Bruijn levels Interpret binders as closures environments are sequences of values In your bidirectional type checker you have judgments like G M A and G M A in both cases G and A are coming from the semantic domain whereas M is syntax In the modeshift rule you will check either definitional equivalence or subtyping depending on the language and this will be done structurally in the semantic domain this part has the structure of quotation from NbE but let me observe that you actually dont ever need to quote anything The algorithm has the same structure though Now let me point out the epic Power Move that we executed so far What was important was the yoga of having indices in the syntax and levels in the semantics It means that the parts of your judgment that have wellformedness presuppositions which we already agreed to draw from the semantic domain can be implicitly weakened so there is never any need anywhere in the algorithm to unleash a De Bruijn shift or any kind of operation on syntax The only thing you ever do to syntax is check the head constructor and evaluate it into the domain afterward I will have to think about this more in order to get my head around it Here is an example type checker that uses the technique Improve Monikers performance and documentation I feel like it still would be handy to have a nice way of doing binding but perhaps this would require more experimentation using other techniques first Im not sure though Itd be neat to have a toplevel tests directory with a bunch of Pikelet test files in there and a custom test harness to check them Closes TODO x Initialise docusaurus site x Move book documentation over to new site x Copy monthly Reddit updates to the blog Get KaTeX equations to render properly Styling cleanups Make homepage nice It would be neat to have a way to define Pikelet packages Im also thinking it would also be neat to be able to define packages using Pikelet records record name prelude version copyright Apache dependencies Having custom literals or something perhaps like in relit might make this nicer TODO List add a pikeletpackage crate My brain is running round in circles trying to design this in a vacuum so I thought Id sketch out some high level thoughts on this stuff There are a bunch of interlocking concerns which makes it a little hard to figure out how to make any headway on it Currently our loaderdriver API lives in the pikeletdriver but it leaves a lot to be desired Ultimately we want a Rust API that maintains some incrementally accumulated state and has an API with functions that give a nice way to parse source code type check ASTs evaluate expressions compile stuff load primitive functions query the current state type at cursor position jump to definition complete at cursor find all references find all implementations editor actions rename symbol autoformat case split move hole into binding search for hole substitutions inline definition extract definition The Pikelet loader API would probably be consumed by the following clients Pikelet CLI tools the compiler the REPL the language server the package manager an application that embeds Pikelet as a scripting language a rust application eg a game via web assembly eg sordinapigraph via a C ffi exotic editorcode visualisation tools structured editing for example bidirectional editors Import paths may be relative to the current file global from a builtin eg primitive functions from a package dependency or the standard library from a dynamically loadedcompiled script Paths need to be followed in topological order forming a DAG We will want to be able to listen to the file system for updates and incrementally update as needed We probably want to avoid baking in a heavy compiler backend like LLVM at this level although I also wouldnt rule out including a JIT like CraneLift for evaluating expressions at compile time Core languages like PiSigma and MiniTT have simple constructs for pattern matching allowing for easier verification of type checking Im not sure where this should be done however MLton seems to do it during its defunctorise pass We can do it in a naive way for now but there is an interesting paper showing how to do it well Compiling Pattern Matching to Good Decision Trees Do note that we have the added complication of perhaps wanting to add dependent patterns etc Compiling nondependent pattern matching to case trees is described in chapter of The Implementation of Functional Programming Languages This is what Sixten currently uses with some dependent pattern matching hacked in Compiling dependent pattern matching to case trees has been described by Jesper Cockx in Dependent pattern matching and proofrelevant unification Elaborating dependent copattern matching 