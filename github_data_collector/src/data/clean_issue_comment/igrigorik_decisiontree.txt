There is already one similar open issue Consider a training set as myself myname friend friendname family membername other othername If all methodsmyname friendname etc return same name decision tree is breaking In your file the first line is AgeEducationIncomeMarital Status You should change it to AgeEducationIncomeMaritalStatus Add MIT license notice you forgot to made a word adverb and suggested a better word than look at Im try run examplessimplerb in master but throw this error entropy undefined method sum for Array NoMethodError Try gem version and work find maybe it introduced in pull request I am using the graphr Ruby gem and GraphViz on Ubuntu and all I get is discrete Btw why didn t you put the graphr gem in the dependencies I need the train data out of the box so added an attributes accessor to access the train data in RuleSet Class So that I can get the accuracy directly For better understanding I can show u the code snippet ruby class Simple def initializeattributesnil trainingnil attributes attributes Temperature training training healthy sick sick healthy sick really sick end def tree dectree DecisionTreeID Treenewattributes training sick continuous dectreetrain ruleset dectreeruleset result rulesetruleseach r raccuracyrulesettraindata resultcollect r ap rconclusion raccuracy end end Thank you Ilya for your great job I work with nicomahler and we look forward contributing to this project As I worked on I remarked that the last line of the code snippet below extracted from ID Treeid continuous line in id treerb seems to have no effect at all ruby gain thresholdscollect threshold dataclassificationentropy possp classificationentropy negsp classificationentropy threshold max ab a b return if gainsize gainsize is never so this line of code has no effect but will raise exception if gain is nil gain is a result of Enumerablemax method applied on an array of elements arrays Its value is either nil if the array is empty case where thresholds is empty I dont know if it can happen we never met that case or a elements array It can never be an empty array So gainsize is never On a real production dataset with explanatory variables and lines I received a SystemStackError stack level too deep when calling DecisionTreeID Treetrain Trying to figure out what was happening I built the following simple dataset which allows to reveal the bug ruby attributes X X X X data a a a a datatype X discrete X continuous X continuous X continuous tree DecisionTreeID Treenewattributes data datatype treetrain SystemStackError is raised here The reason of this bug seems to lie in the specific output of DecisionTreeID Treeid continuous in the case if valuessize see this line Returning instead of in the cases if valuessize and if gainsize in the method id continuous solves the problem It would also be relevant to stop the recursion in the case where the selection of each variable leads to a zero gain That can be done adding in id train the following line ruby return datafirstlast if performanceall a b a after this line ruby performance attributescollect attribute fitnessforattributecalldata attributes attribute What do you think Do you want me to make a pull request with these changes Ive encountered a problem where if you have a training set like ruby Where the attributes do not vary only the target feature does I get an error undefined method toa for String I encounter the same issue if the attributes vary but the target feature does not 