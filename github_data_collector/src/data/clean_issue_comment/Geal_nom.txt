Inline attribute is ignored for prototypes so this change removes it See This PR just upgrades jemalloc and criterion to the latest supported versions It does not require any code change and tests seem to pass It updates the two missing dependencies after and or get merged The API does not change so this can be released as a minor version As you know better than anyone with nom we seem to be moving from macros toward methods There are a set of macros for parsing numbers that take endianness as a parameter For example u nomnumberEndiannessBig is roughly equivalent to nomnumbercompletebeu This pull request adds a set of equivalent methods such as nomnumbercompleteu that take endianness as a parameter and delegate to u be or u le as appropriate This allows for easy migration of older projects that use the macro u syntax by instead calling the method u In a separate commit I also marked nomnumbercompletebeu and leu as deprecated It doesnt seem to make sense to have endianspecific methods for handling onebyte integers since there is no byte swapping involved Feedback and edits are welcome Thank you for considering this pull request I am trying to parse utf encoded text with nonascii alphabetical characters I was using alpha before but it only accepts ascii characters Then I tried to parse the strings char by char however I am getting an error IncompleteSize from this test rust extern crate nom derivePartialEq Debug Eq Clone Hash Ord PartialOrd pub struct Word chars String impl From str for Word fn froms str Self Self chars sinto use nom impl Word named parse str Self map takewhile nomAsCharisalpha s Self chars sinto test fn parseword asserteqWordparseerf llenunwrap Wordfromerf llen fn main printlnHello world Why does this happen Signedoffby koushiro koushirocqxgmailcom What have you changed Fix the alloc feature in stable version Fix warnings Patches And a few upstream issues Hi and thanks for all the hard work on Nom Prerequisites Nom uses a dependency I maintain lexicalcore which used to define a CAPI and Rust API within a single crate Due to symbol issues and to remove unnecessary functionality from lexicalcore the CAPI was separated into a new crate Other bug fixes have since been implemented for example in ensuring full standard compliance in parsing weird edgecases like among others Issues Other uses have reported issues with older versions of lexical Undefined Symbols when building on Windows Symbol Issues when used in a proc macro Undefined Symbols when building on Windows Incorrect result with parsing Versions To support Rustc versions as Nom currently does please use lexicalcore in Cargotoml which supports any version of Rustc F Complete The patch for the complete f parser would be rust cfgfeature lexical pub fn doubleT EParseErrorTinput T IResultT f E where T cratetraitsAsBytes InputLength SliceRangeFromusize match lexicalcoreparsepartialinputasbytes Okvalue processed Okinputsliceprocessed value Err ErrErrErrorEfromerrorkindinput ErrorKindFloat F Streaming The patch for the streaming f parser would be rust cfgfeature lexical pub fn doubleT EParseErrorTinput T IResultT f E where T cratetraitsAsBytes InputLength SliceRangeFromusize match lexicalcoreparsepartialinputasbytes Okvalue processed if processed inputinputlen ErrErrIncompleteNeededUnknown else Okinputsliceprocessed value Err ErrErrErrorEfromerrorkindinput ErrorKindFloat This PR fixes a minor grammatical error and a minor typo in the docs in srclibrs the diff is tiny and should be easy to check for correctness purpose purposes then them There is the separatedpair macro but I have already found it useful to parse multiple values separated by the same separator into a tuple map separatedtuple tag tagab tagxy tag c c c println c c c abxy ab xy A use case was discussed here I think there s no obvious reason why tag should only work on bytes as opposed to any kind of slice or vector However it currently requires the InputTake trait on the type of the input which allows the input to be sliced InputTake s inputtake method specifies that it returns a slice with a specified length in bytes and is only implemented for strings and slices of bytes I think it could be generalized to arbitrary slices in which case the length of the returned slice would not necessarily be measured in bytes Compare should work in a similar way which would allow generalization of tag