Hey I implemented a simple kernel just kopies each pixel of an image and issues in the lower part of the image grafik The black stripes at the bottom of the image are different on each call but always get larger from top to bottom Therefore I assume that streamsynchronise has an issue for multidimensional kernel launches like this launchmoduleconv d stream note the image size is x pixels How can the synchronisation issue be solved Should I restrict my kernels to Dimensional block and thread dimensions launchmoduleconv d stream elimininates the issue Deriving generates code like implT Trait Trait for DevicePointerT But pointer primitives in std do not constraint like that It seems to me that the reexports in are outdated I tried to use DeviceBox which is in rustacudamemory together with DeviceBuffer but I couldnt I had to include pub use rustacudamemory Moreover when replacing use rustacudaprelude by pub use cratecontextContext pub use cratecontextContextFlags pub use cratedeviceDevice pub use cratemoduleModule pub use cratestreamStream pub use cratestreamStreamFlags pub use crateCudaFlags I could not use DeviceBuffer any longer Thanks and cheers Can we please get examples for benchmarking timing kernels via RustaCUDA Im not familiar with how to benchmark CUDA code and would love to learn from examples Make sure that everything compiles in Rust mode then convert the code and all examplesrustdoc commentstestsetc to that mode Forgot to do this when I was setting up CI initially Could maybe try adding a Mac OS build too but I have no idea if they support CUDA at all Right now RustaCUDA only supports very basic usage of Unified Memory but CUDA provides a complex API for prefetching data to a particular device advising the driver about which device will use a range of data and so on RustaCUDA should expose this section of the API Unified Addressing Im not entirely sure how these two are related but RustaCUDA should support them Texture Reference Management Texture Object Management Surface Reference Management Surface Object Management CUDA supports complex strided multidimensional arrays when performing memory transfers Im not really sure what theyre used for or how they work but RustaCUDA should support them It may also be nice to support copying tofrom ndarray if thats feasible See the Memory module for more CUDA provides the ability to link together different modules at runtime Its pretty niche but it is there so we should expose it through RustaCUDA See the Module module 