Can we suggest Are the other imports really necessary too Originally posted by krlmlr in You are likely already aware of this but I just discovered the hard and painful way that due to the recent change in ropenscilabstravis the private SSH key is now stored in the TRAVISDEPLOYKEYendpoint environment variable It seems that many of the steps in tic in particular stepsetupssh and dopkgdown assume that the name of the env var is idrsa IIUC you can manually run stepsetupssh and specify the name outside dopkgdown getstagebeforedeploy addstepstepsetupsshTRAVISDEPLOYKEYCOM dopkgdown But dopkgdown doesnt expose the name parameter which could be one solution to this mismatch In the end I for the time being created the key with r travisusetravisdeploykeynameprivate idrsa The error messages in the logs when this fails are misleading First the stepsetupssh is skipped but its hard to tell why ticbeforedeploy Loading tic stage configuration from ticR Skipping beforedeploy stepsetupssh function if privateinstallsshkeyscheck returnFALSE if privateaddtoknownhostscheck returnFALSE if privatetestsshcheck returnFALSE TRUE environment x fada c bc Then the push deploy step will fail due to the privatekey not being set Initializing Git repo at docs Staging Checking changed files Committing to Userstravisbuildownerrepodocsgit No upstream branch found Pushing to remote git push force ticremote HEAD remote Invalid username or password fatal Authentication failed for Im reading the getting started vignette and have a few questions Why We recommend the following setup Appveyor Windows Circle CI Linux Travis CI macOS Could there be some footnote about the reason for that Why would someone want to deploy from several CI do you have a practical example In The deployment setup functionality comes I wonder where the Appveyor functionality comes from At the beginning of the vignette your link resources about CI in general but mostly Travis do you know of some comparisons of all CIs for R packages or so Maybe I should also read the peerreview thread to see whether there are answers there wink This might be a silly question to automate querying of available macros Solves manual editing of parts in our articles and might be useful for users see This is a complex task Below is sketch how this could work Every template comes with an ID so that we know which tic template we should look up Every template has a part TEMPLATE startend which will be strictly replaced with the upstream template Then we enforce users to put local modifications to the templates in a section which is encapsulated by USER CHANGES During the update process we look for this part and simply append it to the upstream template part We check for possible duplicates and delete the duplicated parts from the TEMPLATE part since the user changes have higher preference We tell the user which part we deleted from the TEMPLATE part due to the local changes which are stored in his YAML Most often changes will be made for installing additional system libs In this case there will be no conflict at all because we do not define this part in the tic templates Other changes I see are mods to the env vars This is a case that we should be able to catch in a descriptive way using the approach outlined above If users follow the principle to install any R deps only via ticR I am positive that this approach could work In the end the user would only need to call ticupdateyaml and everything will just work are very unintuitive Example r librarytic getstagedeploy addstepsteppushdeploy path path Creating a blank tic stage configuration Error Error evaluating the step argument of addstep expected an object of class TicStep Original error Cannot orphan the branch that has been used for the CI run supCreated on by the reprex package v sup Can we print a short version of the expression that this step tried to evaluate Is it obvious from the documentation that ticR should never include code that has side effects or performs actual computation only in a step I somehow dislike the mass of explicit tic forwarding calls in the YAML files Maybe we should outsource them to a script residing in the GH repo which is only called in one stage This script then does all the forwarding calls to ticR Downside Another layer in between that might confuse users Also the initial build stages are not visually present anymore Upside A tidy YAML file