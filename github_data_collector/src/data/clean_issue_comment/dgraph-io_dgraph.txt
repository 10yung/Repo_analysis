 Experience Report What you wanted to do I want to perform a mutation in an upsert block using userprovided data safely What you actually did upsert name string query varfunc eqxid Type as uid varfunc eq Robin Wright Person as uid mutation set uidPerson xid uidPerson uidType uidPerson name uidPerson dgraphtype Person Why that wasnt great with examples GraphQL variables are not supported in mutations so its impossible to safely mutate userprovided data without errorprone validation Any external references to support your case None at the moment Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Currently the tests for multiposting lists are only including UIDs Postings should be added to the list so that we can verify they are correctly handled Also use the errors library instead of fmt Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend This PR reenalbles splits so it should only be merged once is merged Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Experience Report Currently I am building a unified graph that converges data compute and machine learning On the data side I use Postgres a graph database Still working on making DGraph work but thats a very different story On the compute machine learning side everything integrates through webservices On the integration layer all data and web services get queried accessed and mutated through a master GraphQL layer It works but when I recently integrated another machine learning use case I ended up sending a bunch of data forward and backward and that made me think of a better way What you wanted to do I had a similar situation a few times before which means I move data around that isnt exactly great because processing cannot be done where the data is or the data arent where the processing is happening Either way this is stupid and Hadoop really isnt the answer either What you actually did Eventually I did what everyone else would have done Load the data send it to the ML service processes it and store the results back to the datastore Simple Why that wasnt great with examples There are so many problems No data compute locality Unnecessary traffic Lousy latency Realtime is getting harder due to another network hop Processing larger datasets well isnt fun precisely because of the implied data loading What is the main idea One of the most intriguing properties of a DGraph comes in the form of context locality that naturally follows from predicate sharding When predicates P Pn resides on nodeX then all queries against predicates on that nodeX are by definition independent from all other predicates on all other nodes and thus can be executed in parallel Ok we all know that However it also follows that any algorithm operating on predicates can be parallelized by default and because of that moved to the node where the data are located traverse through the corresponding subgraph and compute stuff That is data parallelism in its purest form What would be a truly great way of doing this The greatest possible way I can think of would be processing data where they are stored by adding a third kind of node to Dgraph that hosts data ML algorithms Due to the distributed nature I think aggregated realtime result streams might be possible It requires a third kind of node to prevent adding more load to the rest of the system so that normal queries remain unaffected performancewise The alpha nodes just dispatch queries and mutations to zero nodes and sends ML workload to ML nodes Plus the ML instance might get pinned to a highspec or GPU machine With the current work on the GraphQL endpoint the ML algorithm can be then exposed and parametrized through a custom resolver More details considerations This idea is based on my current practice of integrating ML services into the unified graph by only taking a start stop ID as a parameter to let the custom resolver query all data required before passing them to the ML server It does work in practice but comes at the caveat that there are some limits of how much data you can query and send over the network before something slows down Obviously this makes a lot of sense when the subgraph remains reasonably small but it doesnt work anymore on a large graph At some point the network isnt your friend anymore The number of usable algorithms that are suitable for a large graph is relatively low but these solve really important problems among other things community predictions graph structure classification and predicting shifts in structural imbalance Specifically the algorithms in DGL are a terrific contender for these tasks because they can manage arbitrary graph size through either batch loading or message passing and DGL already supports multiprocessing and distributed training out of the box Obviously loading a large graph out of a distributed DGraph cluster shuffle the data to a DGL cluster just to distribute them again for processing sounds as stupid as it actually is And in many ways that is how its done in practice I do not believe that kind of datashuffling between distributed data storage and data processing is going to be sustainable And the leading DB vendors already know that for some time Oracle absolutely nailed its indatabase machine learning precisely because at some point it is actually easier to move the headquarter than moving data out of the data warehouse Even the guys at neo j got this simple message and started adding some ML capabilities You simply cannot load and transfer humongous data anymore so you have to process them where they are and that is exactly why indatabase machine learning will only grow in importance Doing so however remains a prevalent painpoint with no truly great solution for graph data Any external references to support your case This will help to get stats of graphql query adoption Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend There were some bugs in how hasInverse and interfaces work The hasInverse wasnt in all the right places so with a schema like type Author questions Question hasInversefield author interface Post author Author type Question implements Post wed incorrectly copy the hasInverse to the Question but when doing mutation rewriting look for it on the post and thus not link up questions and authors correctly Although this error really came from both schema generation and runtime problems I dont think that this needs rewriting or e e tests at this point Really the rewriting and e e tests show that if there is a has inverse directive then the reverse references get setup properly So now we have a set of schema tests that show that the hasInverse gets set up properly Would be good to rearrange the e e tests to show this but thats a bigger bit of work Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend What version of Dgraph are you using Have you tried reproducing the issue with the latest release Im working on that now I havent seen it in g e d a yet but its been difficult to reproduce so its hard to tell What is the hardware spec RAM OS node LXC Jepsen cluster GB ECC RAM way Xeon Steps to reproduce the issue commandconfig used to run Dgraph With Jepsen ce dc a e fd b b d d try lein run test workload uidset timelimit concurrency n testcount Expected behaviour and actual result In the UIDset test Jepsen creates a schema like value int and inserts a whole bunch of unique triples each with the same UID same predicate and unique values At the end of the test it tries to read those triples back by querying for every value associated with the chosen UID In this test run we inserted distinct values However when we tried to read those values at the end of the test we observed clj q uid x value rather than the expected clj q uid x value more elements was the most recent successfully inserted value It appears as if Dgraph has perhaps lost the schema for the value predicate entirely or somehow overwritten every previous record with a single one danielmai suggests this could be due to a bug in posting lists which may have been fixed in 