This is a proposal to begin addressing with the most minimal API necessary Background The most seemingly accurate and thorough research I could come across on this topic is Ross Bencinas excellent paper PortAudio and Media Synchronisation Its All in the Timing It contains an overview of the media synchronisation problem with example scenarios visual diagrams etc that make it more intuitive The first few sections of the paper describe some hypothetical scenarios and different techniques for synchronising audio with some other kind of media A MIDI clock is the primary example used in the paper but the same techniques apply to presenting frames of graphics and other forms of media sync Section describes the minimal set of information necessary in order to make these synchronisation techniques possible Sample rate We already have this Buffer start times We do not yet provide this This refers to the most accurate form of monotonic clock time available on the system It is also essential that users have access to the same source of time that provides this value in order to timestamp their media events This means describing the exact source for each host in the docs and possibly providing a function for easily retrieving this value portaudio do so via a GetStreamTimeStream s function PortAudio decided to provide this monotonic time in seconds using a doubleprecision floatingpoint data type The double data type was chosen after considerable deliberation because it provides sufficient resolution to represent time with highprecision may be manipulated using numerical operators and is a standard part of the C and C languages Section also describes implementation issues They can be roughly summed up as follows Sample rates Subtle variations between the nominal sample rate and the observed sample rate occur between sound card chipsets resulting in subtle inaccuracies occurring within the aforementioned synchronisation techniques PortAudio provides an actual sample rate via its stream info parameters Calculating this requires a highresolution system clock though this isnt always available One Shared Timebase The time source of timestamps provided via audio callbacks sometimes differ from the source used to provide timestamps for other media events eg Windows MIDI API This is why PortAudio found it necessary to provide a function for easy access to the correct source GetStreamTime Buffer playback times Exact buffer playback times are often unprovided or inaccurate PortAudio takes on the initiative of trying to calculate this for the user in the case that it isnt provided by the platform ASIO buffer timestamps have a bestcase resolution of ms significantly worse than necessary for samplelevel synchronisation Proposal I propose that we add the following A StreamInstant struct representing a monotonic time instance retrieved from either the streams underlying audio data callback or the same time source used to generate time stamps for a streams underlying audio data callback No guarantees are made about the duration that the value represents only that it is monotonic and begins either before or equal to the moment the stream was started Internally we could represent the instant in a similar manner to stdtimeDuration providing methods for easy access to more accessible representations eg assecsf etc The following timestamp structs InputStreamTimestamp OutputStreamTimestamp Both structs contain two fields of type StreamInstant callback indicating the instant at which the data callback was called bufferadc and bufferdac representing the instance of capture and playback from the audio device for the input and output streams respectively An instance of these structs would be provided to the respective users data callback A fn now self StreamInstant method for the Stream handle type allowing users to produce an instant in time via the same source used to generate timestamps for the data callback useful for media sync It will be important to document exactly what system API is used for each host and to list any notable limitations eg the ms bestcase resolution on ASIO Ive been doing some research into the way that timing information is provided by each of the different hosts supported by CPAL Ill add a followup comment soon with the relevant info for some more context for those interested and for myself to refer back to during implementation The transport API discussed within has been intentionally omitted in the hope that it can be implemented on top of the proposed timestamp API In the case that it cannot this is likely best left to be addressed in a future PR either way This is an implementation of the planned changes described in For a quick overview of how the API has changed check out the updated examples TODO x Update API x Update examples Remove datatype field from Format See here x Update docs Update backends x null x ALSA x ASIO x WASAPI x CoreAudio x Emscripten Closes Closes When I cross compile the enumerate CPAL example and run it on the target device I get this list Supported hosts Alsa Available hosts Alsa ALSA Default Input Device Somedefault Default Output Device Somedefault Devices defaultCARDI S sysdefaultCARDI S defaultCARDUAC sysdefaultCARDUAC If I do the same but then using the devices rustportaudio example I get this list Number of devices Default input device OkDeviceIndex Default output device OkDeviceIndex All devices DeviceIndex DeviceInfo structversion name MTK APSoC I S hw hostapi DeviceIndex DeviceInfo structversion name ReSpeaker MicArray UAC USB Audio hw hostapi DeviceIndex DeviceInfo structversion name sysdefault hostapi DeviceIndex DeviceInfo structversion name default hostapi DeviceIndex DeviceInfo structversion name dmix hostapi Stripped some output to make the lists easier to read As you can see I get one device less using CPAL vs and I get strange and partly duplicate names instead of the much nicer and clearer names rustportaudio returns Is this something that is expected andor can I tweak something to improvefix this Thanks I tried running examplesbeeprs but it seems to fail with the following messages Cannot connect to server socket err No such file or directory Cannot connect to server request channel jack server is not running or cannot be started JackShmReadWritePtrJackShmReadWritePtr Init not done for skipping unlock JackShmReadWritePtrJackShmReadWritePtr Init not done for skipping unlock Error The requested device is no longer available For example it has been unplugged This is a tracking issue for supporting duplex streams Duplex streams are streams that have devicesynchronised input and output an essential requirement for many realtime and proaudio applications This is a followup to but focused specifically on duplex support As far as I can tell cpal relies on no way on the COM mode being COINITMULTITHREADED So lets survive even if COM was already initialized in apartmentthreaded mode there is no such thing as singlethreaded mode I m investigating the use of cpal in nostd environment I don t have a particular goal ie embedded device in mind but it would be cool to do something with audio in a bare metal environment Is there a way cpal could help me here Has nostd support been looked into before Hi Im the maintainer of the alsa crate and Im wondering if it would make sense for CPAL to depend on the alsa crate rather than the alsasys crate Im not familiar with CPAL but from a quick glance at the code in the hostsalsa directory a lot of that code is just simple wrappers around alsalib object which is exactly what the alsa crate already has so probably the alsa backend in CPAL could be very much simplified if it were to use the alsa crate instead That said I probably wont have time nor sufficient knowledge of CPAL to make that code myself but I still wanted to raise the issue Is it time to switch to edition A significant amount time has passed since the edition was introduced All input samples are on this mbp inch Mid running macOS Using this code only zero samples come out of the input stream Other audio stuff works like recording with quicktime The same cpalinputdemo outputs nonzero samples on two other machines One newer mbp inch also running macOS and one laptop running Ubuntu On the problem machine cd cpalinputdemo cargo run release Finished release optimized targets in s Running targetreleasecpalinputdemo Default input device Builtin Microphone Default input format Format channels samplerate SampleRate datatype F buffer f len buffer f len buffer f len buffer f len buffer f len buffer f len etc With no nonzero sample in sight cargo run release example enumerate Compiling cpal v Usersmilescodevendorcpal Finished release optimized targets in s Running targetreleaseexamplesenumerate Supported hosts CoreAudio Available hosts CoreAudio CoreAudio Default Input Device SomeBuiltin Microphone Default Output Device SomeBuiltin Output Devices Builtin Microphone Default input stream format Format channels samplerate SampleRate datatype F All supported input stream formats SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F Builtin Output Default output stream format Format channels samplerate SampleRate datatype F All supported output stream formats SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F SupportedFormat channels minsamplerate SampleRate maxsamplerate SampleRate datatype F img width altimage src What can I do to get nonzero samples from the mic