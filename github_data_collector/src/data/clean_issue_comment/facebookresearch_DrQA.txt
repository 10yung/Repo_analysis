Can you please tell how doc score is calculated If it is tfidf approach cosine similarity falls between range of to why does doc score is very high How can I have threshold in such cases for better retrieval of docs When running interactive with numpy I encountered the following error It seems the npz file must be loaded with numpy version When I installed numpy the problem is gone Please update requirementstxt or update the datawikipediadocstfidfngram hash tokenizersimplenpz file python scriptspipelineinteractivepy PM CUDA enabled GPU PM Initializing pipeline PM Initializing document ranker PM Loading homeqibinDrQAdatawikipediadocstfidfngram hash tokenizer simplenpz Traceback most recent call last File scriptspipelineinteractivepy line in module tokenizerargstokenizer File homeqibinDrQAdrqapipelinedrqapy line in init selfranker rankerclassrankeropts File homeqibinDrQAdrqaretrievertfidfdocrankerpy line in init matrix metadata utilsloadsparsecsrtfidfpath File homeqibinDrQAdrqaretrieverutilspy line in loadsparsecsr return matrix loader metadata item if metadata in loader else None File dataqibinanaconda envsalchemylibpython collectionsabcpy line in contains self key File dataqibinanaconda envsalchemylibpython sitepackagesnumpylibnpyiopy line in g etitem picklekwargsselfpicklekwargs File dataqibinanaconda envsalchemylibpython sitepackagesnumpylibformatpy line in re adarray raise ValueErrorObject arrays cannot be loaded when ValueError Object arrays cannot be loaded when allowpickleFalse Running python setuppy develop on Windows gives the following error Traceback most recent call last File setuppy line in module readme fread File E WPy python amd lib encodings cp py line in decode return codecscharmapdecodeinputselferrorsdecodingtable UnicodeDecodeError charmap codec cant decode byte x d in position character maps to undefined I also did the following before running it set LANGUAGEenUSUTF set LCALLenUSUTF set LANGenUSUTF set LCTYPEenUSUTF sysgetdefaultencoding and sysstdoutencoding both gives utf I am on WinPython v ec c a Oct MSC v bit AMD on win Windows bit Hello Im trying to run builddbpy on the nested directory of files returned by running WikiExtractorpy on the English wiki dump however I keep gettting this error UnicodeDecodeError utf codec cant decode byte x in position invalid start byte Could you please let me know if you know how to fix this Thanks WHEN I RUN THE COMMAND python scirptspipelineinteractionpy I GET THE FOLLOWING ERROR AM CUDA enabled GPU AM Initializing pipeline AM Initializing document ranker AM Loading homezlabsnlpraviDrQAdatawikipediadocstfidfngram hash tokenizersimplenpz Traceback most recent call last File scriptspipelineinteractivepy line in module tokenizerargstokenizer File homezlabsnlpraviDrQAdrqapipelinedrqapy line in init selfranker rankerclassrankeropts File homezlabsnlpraviDrQAdrqaretrievertfidfdocrankerpy line in init matrix metadata utilsloadsparsecsrtfidfpath File homezlabsnlpraviDrQAdrqaretrieverutilspy line in loadsparsecsr return matrix loader metadata item if metadata in loader else None File homezlabsnlpminiconda envsdrqalibpython collectionsabcpy line in contains self key File homezlabsnlpminiconda envsdrqalibpython sitepackagesnumpylibnpyiopy line in getitem picklekwargsselfpicklekwargs File homezlabsnlpminiconda envsdrqalibpython sitepackagesnumpylibformatpy line in readarray raise ValueErrorObject arrays cannot be loaded when ValueError Object arrays cannot be loaded when allowpickleFalse CAN ANYONE HELP ME WHAT THE ERROR IS THANKS IN ADVANCE scriptsretrieverinteractivepy and scriptsreaderinteractivepy all works well But when I try to run scriptspipelineinteractivepy It shows python scriptspipelineinteractivepy PM CUDA enabled GPU PM Initializing pipeline PM Initializing document ranker PM Loading homexuelifDocumentsNLPDrQAdatawikipediadocstfidfngram hash tokenizersimplenpz PM Initializing document reader PM Loading model homexuelifDocumentsNLPDrQAdatareadermultitaskmdl PM Initializing tokenizers and document retrievers Traceback most recent call last File scriptspipelineinteractivepy line in module tokenizerargstokenizer File homexuelifDocumentsNLPDrQAdrqapipelinedrqapy line in init initargstokclass tokopts dbclass dbopts fixedcandidates File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingcontextpy line in Pool contextselfgetcontext File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingpoolpy line in init selfrepopulatepool File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingpoolpy line in repopulatepool selfwrapexception File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingpoolpy line in repopulatepoolstatic wstart File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingprocesspy line in start selfpopen selfPopenself File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingcontextpy line in Popen return Popenprocessobj File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingpopenforkpy line in init selflaunchprocessobj File homexuelifDocumentsanaconda envsautopaperlibpython multiprocessingpopenforkpy line in launch selfpid osfork OSError Errno Cannot allocate memory PS I have downloaded the latest CoreNLPTokenizer from Stanford Without the lastest corenlp running scriptsreaderinteractivepy will return TIMEOUT error python scriptsreaderinteractivepy PM CUDA enabled GPU PM Initializing model PM Loading model homexuelifDocumentsNLPDrQAdatareadersinglemdl PM Initializing tokenizer Traceback most recent call last File homexuelifDocumentsanaconda envsautopaperlibpython sitepackagespexpectexpectpy line in expectloop incoming spawnreadnonblockingspawnmaxread timeout File homexuelifDocumentsanaconda envsautopaperlibpython sitepackagespexpectptyspawnpy line in readnonblocking raise TIMEOUTTimeout exceeded pexpectexceptionsTIMEOUT Timeout exceeded During handling of the above exception another exception occurred Traceback most recent call last File scriptsreaderinteractivepy line in module normalizenot argsnonormalize File homexuelifDocumentsNLPDrQAdrqareaderpredictorpy line in init selftokenizer tokenizerclassannotatorsannotators File homexuelifDocumentsNLPDrQAdrqatokenizerscorenlptokenizerpy line in init selflaunch File homexuelifDocumentsNLPDrQAdrqatokenizerscorenlptokenizerpy line in launch selfcorenlpexpectexactNLP searchwindowsize File homexuelifDocumentsanaconda envsautopaperlibpython sitepackagespexpectspawnbasepy line in expectexact return expexpectlooptimeout File homexuelifDocumentsanaconda envsautopaperlibpython sitepackagespexpectexpectpy line in expectloop return selftimeoute File homexuelifDocumentsanaconda envsautopaperlibpython sitepackagespexpectexpectpy line in timeout raise TIMEOUTmsg pexpectexceptionsTIMEOUT Timeout exceeded pexpectptyspawnspawn object at x fac a command binbash args binbash buffer last chars bcumentsNLPDrQA x x b mxuelifxuelifHPZ G Workstation x b m x b mDocumentsNLPDrQA x b m before last chars bcumentsNLPDrQA x x b mxuelifxuelifHPZ G Workstation x b m x b mDocumentsNLPDrQA x b m after class pexpectexceptionsTIMEOUT match None matchindex None exitstatus None flageof False pid childfd closed False timeout delimiter class pexpectexceptionsEOF logfile None logfileread None logfilesend None maxread ignorecase False searchwindowsize None delaybeforesend delayafterclose delayafterterminate searcher searcherstring bNLP when i try to run the code im getting this error my cuda version is and my pytorch version is a some one help me paperspacepsochxboaDRQA sudo python scriptspipelineinteractivepy PM CUDA enabled GPU PM Initializing pipeline PM Initializing document ranker PM Loading homepaperspaceDRQAdatawikipediadocstfidfngram hash tokenizersimplenpz PM Initializing document reader PM Loading model homepaperspaceDRQAdatareadermultitaskmdl Traceback most recent call last File scriptspipelineinteractivepy line in module tokenizerargstokenizer File homepaperspaceDRQAdrqapipelinedrqapy line in init selfreadercuda File homepaperspaceDRQAdrqareadermodelpy line in cuda selfnetwork selfnetworkcuda File usrlocallibpython distpackagestorchnnmodulesmodulepy line in cuda return selfapplylambda t tcudadevice File usrlocallibpython distpackagestorchnnmodulesmodulepy line in apply moduleapplyfn File usrlocallibpython distpackagestorchnnmodulesmodulepy line in apply moduleapplyfn File usrlocallibpython distpackagestorchnnmodulesmodulepy line in apply moduleapplyfn File usrlocallibpython distpackagestorchnnmodulesrnnpy line in apply selfflattenparameters File usrlocallibpython distpackagestorchnnmodulesrnnpy line in flattenparameters if not anyparamiscuda or not torchbackendscudnnisacceptableanyparam File usrlocallibpython distpackagestorchbackendscudnninitpy line in isacceptable if libcudnn is None File usrlocallibpython distpackagestorchbackendscudnninitpy line in libcudnn but linked against formatcompileversion cudnnversion RuntimeError cuDNN version mismatch PyTorch was compiled against but linked against thank you While running python scriptsreadertrainpy embeddingfile glove B dtxt tunepartial gpu I am getting error WARN fixembeddings set to False as tunepartial PM COMMAND scriptsreadertrainpy embeddir homeatulDrQAdataembeddings tunepartial gpu PM PM Load data files PM Num train examples PM Num dev examples PM PM Training model from scratch PM PM Generate features PM Num features PM posJJR posPOS posNN pos posWP posRB posVBN posRBS posUH inquestion posVBD posCC posJJS pos posRP posVBZ nerORGANIZATION posWRB pos posWDT nerMONEY nerLOCATION tf posVBG pos posNNP posLS posNNPS nerPERSON nerORDINAL nerMISC posEX nerTIME nerDATE nerDURATION posNNS posFW posTO posCD posPRP nerO inquestionuncased pos nerSET pos posPDT nerNUMBER posWP posVB posVBP posJJ nerPERCENT posSYM pos posPRP posDT inquestionlemma posLRB posIN posRRB posRBR posMD PM PM Build dictionary PM Restricting to words in homeatulDrQAdataembeddingsglove B dtxt PM Num words in set PM Num words PM Loading pretrained embeddings for words from homeatulDrQAdataembeddingsglove B dtxt PM WARN Duplicate embedding found for Kr s n a PM WARN Duplicate embedding found for PM WARN Duplicate embedding found for PM WARN Duplicate embedding found for a PM WARN Duplicate embedding found for Jose Traceback most recent call last File scriptsreadertrainpy line in module mainargs File scriptsreadertrainpy line in main model initfromscratchargs trainexs devexs File scriptsreadertrainpy line in initfromscratch modelloadembeddingsworddicttokens argsembeddingfile File homeatulDrQAdrqareadermodelpy line in loadembeddings assertlenparsed embeddingsize AssertionError How to resolve this Thanks Is there anyway to run this model on low requirement machineOr on google colaboratoryIf anyone tried this or any alternative models similar to this which runs on low requirement machines python scriptspipelineinteractivepy AM Running on CPU only AM Initializing pipeline AM Initializing document ranker AM Loading scratchnikitaDrQAdatawikipediadocstfidfngram hash tokenizersimplenpz AM Initializing document reader AM Loading model scratchnikitaDrQAdatareadermultitaskmdl AM Initializing tokenizers and document retrievers Interactive DrQA processquestion candidatesNone topn ndocs usage salloc Exceeded job memory limit getting memory error using cpu gb