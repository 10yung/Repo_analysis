I am implementing a custom recurrent class that inherits tflayersLayer when using the Bidirectional wrapper I get the error KeyError Traceback most recent call last ipythoninput bd b in module a TimeDistributedBidirectionalcharrecurrentcell optanaconda envstensorflowp libpython sitepackagestensorflowcorepythonkeraslayerswrapperspy in initself layer mergemode weights backwardlayer kwargs if backwardlayer is None selfbackwardlayer selfrecreatelayerfromconfig layer gobackwardsTrue else selfbackwardlayer backwardlayer optanaconda envstensorflowp libpython sitepackagestensorflowcorepythonkeraslayerswrapperspy in recreatelayerfromconfigself layer gobackwards config layergetconfig if gobackwards config gobackwards not config gobackwards if customobjects in tfinspectgetfullargspec layerclassfromconfigargs KeyError gobackwards This is the code for the layer itself class RecurrentConfigBaseLayer Basic configurable recurrent layer def initself args kwargs superinitargs kwargs selflayers List layersLayer stacklayersselfparams selfnumlayers selflayername def callself inputs npndarray layersLayer This function is a sequentialfunctional call to this layers logic Args inputs Array to be processed within this layer Returns inputs processed through this layer processed inputs for layer in selflayers processed layerprocessed return processed staticmethod def defaultparams Dict Any Any return units recurrentinitializer glorotuniform dropout recurrentdropout activation None returnsequences True I have attempted to add the gobackwards to the config that is retrieved when getconfig is called but this results in another error TypeError Traceback most recent call last ipythoninput bd b in module a TimeDistributedBidirectionalcharrecurrentcell optanaconda envstensorflowp libpython sitepackagestensorflowcorepythonkeraslayerswrapperspy in initself layer mergemode weights backwardlayer kwargs Recreate the forward layer from the original layer config so that it will not carry over any state from the layer selfforwardlayer selfrecreatelayerfromconfiglayer if backwardlayer is None optanaconda envstensorflowp libpython sitepackagestensorflowcorepythonkeraslayerswrapperspy in recreatelayerfromconfigself layer gobackwards return layerclassfromconfigconfig customobjectscustomobjects else return layerclassfromconfigconfig tfutilsshapetypeconversion optanaconda envstensorflowp libpython sitepackagestensorflowcorepythonkerasenginebaselayerpy in fromconfigcls config A layer instance return clsconfig def computeoutputshapeself inputshape nlpv generalnlplibsrcmainpythonmosaixpymosaixlearnlayersrecurrentlayerspy in initself args kwargs Basic configurable recurrent layer def initself args kwargs superinitargs kwargs selflayers List layersLayer stacklayersselfparams selfnumlayers nlpv generalnlplibsrcmainpythonmosaixpymosaixlearnlayersbaselayerpy in initself params mode layername numlayers custname kwargs custname str kwargs superinitparams mode kwargs selflayername layername selfcustname custname nlpv generalnlplibsrcmainpythonmosaixpymosaixlearnconfigurablepy in initself params mode kwargs def initself params Dict AnyStr Any mode ModeKeys kwargs superinitkwargs type ignore selfparams parseparamsparams selfdefaultparams selfmode mode optanaconda envstensorflowp libpython sitepackagestensorflowcorepythontrainingtrackingbasepy in methodwrapperself args kwargs selfselfsetattrtracking False pylint disableprotectedaccess try result methodself args kwargs finally selfselfsetattrtracking previousvalue pylint disableprotectedaccess optanaconda envstensorflowp libpython sitepackagestensorflowcorepythonkerasenginebaselayerpy in initself trainable name dtype dynamic kwargs Validate optional keyword arguments genericutilsvalidatekwargskwargs allowedkwargs Mutable properties optanaconda envstensorflowp libpython sitepackagestensorflowcorepythonkerasutilsgenericutilspy in validatekwargskwargs allowedkwargs errormessage for kwarg in kwargs if kwarg not in allowedkwargs raise TypeErrorerrormessage kwarg TypeError Keyword argument not understood gobackwards Version info is tfversion dev gitversion v gf f ea fa The kerasapplications module has been splitted from the main Keras repository Please submit your issue using this link Thank you emTraining a model that have a lot of outputs causes my keras to freeze using usemultiprocessingTrue in fit it become freezes lessprobably but still freezes i believe there is a problem in keras i train it on data of size for epoch for multiple times reinforcement learning it freezes randomly it freezes after few times of training but sometimes it takes thousands em System information Have I written custom code as opposed to using example directory yes OS Platform and Distribution eg Linux Ubuntu Windows TensorFlow backend yes no yes TensorFlow version Keras version Python version CUDAcuDNN version CUDA cuDNN tested also with CUDA GPU model and memory GTX gb memory Describe the current behavior My model freeze randomly during training when i use a model with alot of multiple layers in my case Describe the expected behavior it dont freeze Code to reproduce the issue dims inputlayer Inputshapedims hidden Densedims activationreluinputlayer hidden Densedims activationreluhidden hidden Densedims activationreluhidden policy for i in rangedims hiddenl Densedims activationreluhidden policyappend Densenatomsactivationsoftmaxhiddenl rmodel Modelinputsinputlayer outputspolicy rmodelcompileloss categoricalcrossentropy optimizerAdamlrlrdecaydecay return rmodel Other info logs cant provide any other infos python dont display any errors emPlease make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template If your issue is an implementation question please ask your question on StackOverflow or on the Keras Slack channel instead of opening a GitHub issueem System information Have I written custom code as opposed to using example directory yes OS Platform and Distribution eg Linux Ubuntu google colab TensorFlow backend yes no yes TensorFlow version rc Keras version Python version CUDAcuDNN version GPU model and memory You can obtain the TensorFlow version with python c import tensorflow as tf printtfGITVERSION tfVERSION You can obtain the Keras version with python c import keras as k printkversion Describe the current behavior The code modellayerspop doesnt pop the input layer as expected it still shows the input layer in summary Model inceptionv Layer type Output Shape Param Connected to input InputLayer None Describe the expected behavior This issue is not present in Tensorflow x with keras that works as expected Code to reproduce the issue Provide a reproducible test case that is the bare minimum necessary to generate the problem tensorflowversion x from tensorflowkerasapplicationsinceptionv import InceptionV basemodel InceptionV weights imagenet includetopFalse inputshape basemodellayerspop basemodelsummary Other info logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Some lines in the code block of the keras docs is too long the result of which is there will be a horizonal scroll bar at the bottom of the code block That is hard to read The long lines should be rearranged to multiple short lines to improve readibility Example The docs for the SimpleRNN class The initializer of SimpleRNN has many arguments but the docs put them in just a single long line That makes it very hard to read docs line too long The single long line should be rearranged to multiple short lines just like what was did in the source code for the init function of SimpleRNN short lines Im trying to pass the output of a CNN model as an input to LSTM Im currently working with videos The array of each frame of the video is passed to a CNN model and the output is a vector array I want to divide the output of CNN into a sequence of size and pass it as an input to LSTM I cant seem to figure it out how to divide the output of CNN into a sequence of size I tried to use reshape but it didnt work Heres my current cnn model inp Inputshape norminp BatchNormalizationinp img Convolution D kernelsize activationactivationsrelunorminp img MaxPooling Dpoolsize img img Dropoutrate img img Convolution D kernelsize activationactivationsreluimg img MaxPooling Dpoolsize img img Dropoutrate img img Convolution D kernelsize activationactivationsreluimg img MaxPooling Dpoolsize img img Dropoutrate img img Flattenimg dense BatchNormalizationDense activationactivationsreluimg dense Dense activationsoftmaxdense cnn modelsModelinputsinp outputsdense cnn summary I want the input to input to LSTM to be of shape Can someone help me with this please Summary Hi Optuna optunaorg is a new hyperparameter optimization library and we ve written an integration module for Keras to make it easy to use Optuna to search for good hyperparameter settings and prune unpromising trials We re looking for ways to let Keras users know this is available and thought a badge to show Optuna integration is available would be helpful Here s our example of using the pruning integration with Keras If there are other ways you would recommend reaching out to Keras users to let them know about Optuna please let us know Thanks Related Issues None PR Overview n This PR requires new unit tests yn make sure tests are included n This PR requires to update the documentation yn make sure the docs are uptodate n This PR is backwards compatible yn n This PR changes the current API yn all API changes need to be approved by fchollet emPlease make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template If your issue is an implementation question please ask your question on StackOverflow or on the Keras Slack channel instead of opening a GitHub issueem System information Have I written custom code as opposed to using example directory Yes I have Written Custom code OS Platform and Distribution windows TensorFlow backend yes no yes TensorFlow version Keras version Python version CUDAcuDNN version GPU model and memory geforce gtx gb You can obtain the TensorFlow version with python c import tensorflow as tf printtfGITVERSION tfVERSION You can obtain the Keras version with python c import keras as k printkversion Describe the current behavior I am trying to write a code to classify dicom Head CT images as Hemorrhage and normal I have copied a code using theano backend and turned it into a tensorflow code but when i try to run the code it returns AttributeError ProgbarLogger object has no attribute logvalues I searched the internet and github it seems the problem is because of batch size being bigger than the validation sample size So i changed batch size from to and and the same issue came out I increased my validation positive and negative sample size from to in total and nothing happened Also note that the network trained on theano backend but i wanted to use GPU so i had to change it to tensorflow So here are the codes The traceback code Reading validation images Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldPoz Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from VldNeg Reading image IMG dcm from EgtPoz Reading image IMG dcm from EgtNeg Reading image IMG dcm from EgtPoz Reading image IMG dcm from EgtNeg Train on samples validate on samples AttributeError Traceback most recent call last Anaconda envs tfgpu lib sitepackages tensorflowcore python keras engine trainingv py in onepochself epoch mode try yield epochlogs finally Anaconda envs tfgpu lib sitepackages tensorflowcore python keras engine trainingv py in fitself model x y batchsize epochs verbose callbacks validationsplit validationdata shuffle classweight sampleweight initialepoch stepsperepoch validationsteps validationfreq kwargs trainingcontexttrainingcontext totalepochsepochs cbksmakelogsmodel epochlogs trainingresult ModeKeysTRAIN Anaconda envs tfgpu lib sitepackages tensorflowcore python keras engine trainingv py in runoneepochmodel iterator executionfunction datasetsize batchsize strategy stepsperepoch numsamples mode trainingcontext totalepochs with trainingcontextonbatch stepstep modemode sizecurrentbatchsize as batchlogs try Anaconda envs tfgpu lib contextlibpy in enterself try return nextselfgen except StopIteration Anaconda envs tfgpu lib sitepackages tensorflowcore python keras engine trainingv py in onbatchself step mode size selfcallbackscallbatchhook mode begin step batchlogs selfprogbaronbatchbeginstep batchlogs Anaconda envs tfgpu lib sitepackages tensorflowcore python keras callbackspy in callbatchhookself mode hook batch logs for callback in selfcallbacks batchhook getattrcallback hookname batchhookbatch logs AttributeError CSVLogger object has no attribute ontrainbatchbegin During handling of the above exception another exception occurred AttributeError Traceback most recent call last ipythoninput dda fbeae in module y labels epochs validationdata valImagesreshape valLabels callbacks ayirgaclog Anaconda envs tfgpu lib sitepackages tensorflowcore python keras engine trainingpy in fitself x y batchsize epochs verbose callbacks validationsplit validationdata shuffle classweight sampleweight initialepoch stepsperepoch validationsteps validationfreq maxqueuesize workers usemultiprocessing kwargs maxqueuesizemaxqueuesize workersworkers usemultiprocessingusemultiprocessing def evaluateself Anaconda envs tfgpu lib sitepackages tensorflowcore python keras engine trainingv py in fitself model x y batchsize epochs verbose callbacks validationsplit validationdata shuffle classweight sampleweight initialepoch stepsperepoch validationsteps validationfreq kwargs totalepochs cbksmakelogsmodel epochlogs evalresult ModeKeysTEST prefixval return modelhistory Anaconda envs tfgpu lib contextlibpy in exitself type value traceback value type try selfgenthrowtype value traceback except StopIteration as exc Suppress StopIteration unless its the same exception that Anaconda envs tfgpu lib sitepackages tensorflowcore python keras engine trainingv py in onepochself epoch mode Epochs only apply to fit selfcallbacksonepochendepoch epochlogs selfprogbaronepochendepoch epochlogs tfcontextlibcontextmanager Anaconda envs tfgpu lib sitepackages tensorflowcore python keras callbackspy in onepochendself epoch logs selflogvaluesappendk logs k if selfverbose selfprogbarupdateselfseen selflogvalues AttributeError ProgbarLogger object has no attribute logvalues This one is where i store my functions to read and store train validation and test images the batchSize is defined in this code from skimage import exposure import os import pydicom import math import random import numpy import matplotlibpyplot as plt import time def imageCountdirName for root dir files in oswalkF HeadCTKanamaSeries dirName scans file for file in files if file desktopini return lenscans printdirName is not a valid directory exit def readScanscanNum dirName for root dir files in oswalkF HeadCTKanamaSeries dirName scans file for file in files if file desktopini printReading image scans scanNum from dirName data pydicomdcmreadF HeadCTKanamaSeries dirName scans scanNum data datapixelarray pltimshowdata cmappltcmbinary pltshow data exposureequalizeadapthistdata pltimshowdata pltshow return data printdirName is not a valid directory exit def readValidationImages labels patientData for i in range imageCountVldPoz data readScani VldPoz labelsappend patientDataappenddata for i in range imageCountVldNeg data readScani VldNeg labelsappend patientDataappenddata patientData numpystackpatientDataastypefloat return patientData numpystacklabels def readBatchbatchSize labels patientData posLen imageCountEgtPoz deneme amac yla kanamapoz ilerde egitimPoz ile degistirilecek negLen imageCountEgtNeg deneme amac yla kanamaneg ilerde egitimNeg ile degistirilecek posStart randomrandint posLen batchSize negStart randomrandint negLen batchSize for i in rangebatchSize data readScanposStart i EgtPoz labelsappend patientDataappenddata data readScannegStart i EgtNeg labelsappend patientDataappenddata patientData numpystackpatientDataastypefloat return patientData numpystacklabels def normReadAll labels patientData posLen imageCountEgtPoz egtpoz olarak de i ecek negLen imageCountEgtNeg egtneg olarak de i ecek for i in rangeposLen data readScani EgtPoz labelsappend data exposureequalizeadapthistdata patientDataappenddata for i in rangenegLen data readScani EgtNeg labelsappend data exposureequalizeadapthistdata patientDataappenddata patientData numpystackpatientDataastypefloat return patientData numpystacklabels def readTest labels patientData posLen imageCountTestPoztestpoz olarak de i ecek negLen imageCountTestNegtestpoz olarak de i ecek for i in rangeposLen data readScani TestPoz labelsappend data exposureequalizeadapthistdata patientDataappenddata for i in rangenegLen data readScani TestNeg labelsappend data exposureequalizeadapthistdata patientDataappenddata patientData numpystackpatientDataastypefloat return patientData numpystacklabels And here i define and train the model import tensorflow as tf import matplotlibpyplot as plt import argparse import math import random import keras import sys import numpy from CTdataloader import imageCount readScan readValidationImages readBatch readTest from tensorflowkerasmodels import Sequential from tensorflowkeraslayers import Dense Conv D Activation Flatten MaxPooling D from tensorflowkeras import optimizers from tensorflowkeraslayers import BatchNormalization from tensorflowkeras import backend model Sequential modeladdConv D inputshape modeladdMaxPooling Dpoolsize modeladdConv D modeladdActivationtanh modeladdBatchNormalization modeladdConv D modeladdActivationtanh modeladdBatchNormalization modeladdMaxPooling Dpoolsize modeladdConv D modeladdActivationtanh modeladdBatchNormalization modeladdMaxPooling Dpoolsize modeladdFlatten modeladdDense modeladdActivationtanh modeladdBatchNormalization modeladdDense modeladdActivationtanh modelcompilelossmeansquarederror optimizeroptimizersSGDlr metrics accuracy ayirgaclog kerascallbacksCSVLoggerKerasLogcsv append True printReading validation images batchSize valImages valLabels readValidationImages bestLoss floatinf for i in range batch labels readBatchbatchSize history modelfitx batchreshapebatchSize y labels epochs validationdata valImagesreshape valLabels callbacks ayirgaclog Other info logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached System information Have I written custom code as opposed to using example directory Yes OS Platform and Distribution eg Linux Ubuntu Arch Linux TensorFlow backend yes no Yes TensorFlow version also with tf Keras version also with tf keras Python version CUDAcuDNN version GPU model and memory Describe the current behavior Output for original model and its loaded from h file copy differ Describe the expected behavior Output of both models expected to be the same MWE from kerasmodels import Model from keraslayers import Input Lambda from kerasmodels import loadmodel import numpy as np def buildmodelsz inputx Inputshapesz slicedx Lambdalambda x x j inputx for j in rangesz model Modelinputsinputx outputsslicedx return model m buildmodel msavemh mcopy loadmodelmh data nparray printmpredictdata printmcopypredictdata Outputs differ from each other array dtypefloat array dtypefloat array dtypefloat array dtypefloat The problem goes away if slicedx is redefined in the following way slicedx Lambdalambda xi x i argumentsijinputx for j in rangesz However original definition seems to be more natural I do believe this issue is somehow related to python lambdafunction closures System information Have I written custom code as opposed to using example directory No OS Platform and Distribution eg Linux Ubuntu CentOS TensorFlow backend yes no yes TensorFlow version Keras version Python version CUDAcuDNN version CUDA GPU model and memory Not a problem modelA and modelB are two models with same structure modelA input shape None dim dim None modelB input shape None dim dim None the last dim is timestep so we can set it to None To merge this two models into one Id like to run the following code python modelA loadmodelmodelApath modelB loadmodelmodelBpath newinput Inputdim dim I want a fixed timestep now say reset layer names to avoid name conflicts for layer in modelAlayers layername A layername for layer in modelBlayers layername Blayername modelAname A mdoelBname B out modelAnewinput out modelBnewinput newmodel Model newinput out out res newmodelpredictfeat will print correct result newmodelsavenewmodelh save to local Looks perfect But if I want to save the model to disk and reuse it Ill get an error python model loadmodelnewmodelh raise exception modelsummary Whole traceback traceback Traceback most recent call last File generatenewmodelpy line in module modelnew loadmodelnewmodelh File data moyanzittoanaconda libpython sitepackageskerasenginesavingpy line in loadwrapper return loadfunctionargs kwargs File data moyanzittoanaconda libpython sitepackageskerasenginesavingpy line in loadmodel model deserializemodelh dict customobjects compile File data moyanzittoanaconda libpython sitepackageskerasenginesavingpy line in deserializemodel model modelfromconfigmodelconfig customobjectscustomobjects File data moyanzittoanaconda libpython sitepackageskerasenginesavingpy line in modelfromconfig return deserializeconfig customobjectscustomobjects File data moyanzittoanaconda libpython sitepackageskeraslayersinitpy line in deserialize printablemodulenamelayer File data moyanzittoanaconda libpython sitepackageskerasutilsgenericutilspy line in deserializekerasobject listcustomobjectsitems File data moyanzittoanaconda libpython sitepackageskerasenginenetworkpy line in fromconfig processnodelayer nodedata File data moyanzittoanaconda libpython sitepackageskerasenginenetworkpy line in processnode layerunpacksingletoninputtensors kwargs File data moyanzittoanaconda libpython sitepackageskerasenginebaselayerpy line in call outputshape selfcomputeoutputshapeinputshape File data moyanzittoanaconda libpython sitepackageskerasenginenetworkpy line in computeoutputshape strlenselfinputlayers tensor inputs ValueError Invalid inputshape argument None model has tensor inputs I think its a bug 