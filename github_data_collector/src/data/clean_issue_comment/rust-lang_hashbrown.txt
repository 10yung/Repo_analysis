Adding reprC isnt expected to change anything since the RawTable consists purely of pointers and pointersized integers It will however make it possible to pass hashmaps across the FFI boundary which would be useful to Geckointegrated Rust projects such as wgpu cc Gankra This might seem impertinent but since this is the HashMap of the Rust standard library and std is x when can this crate become x itself Obviously that wouldnt halt development any more than the standard library doesnt develop but it would mark to direct users of the crate as the Readme suggests a person might want to do that they can rely on the direct crate usage not breaking out from under them just as much as they can rely on using this through std wont break out from under them This change would make the RawTable usable with things like arena allocation RawTable has a new type parameter A Alloc Clone When the nightly flag is passed Alloc will be the trait in allocAlloc On stable a minimal shim implementation is provided along with an implementation for the global allocator No public APIs changed For HashMap everything is monomorphized to the global allocator and there should be no performance or size overhead Hi Im interested in whether hashbrown can be used for implementing Lua tables for Luster Note Im not the owner just someone interested in the project The unusual requirements for Luas tables are Luas nexttable item function returns the next item in the table given another Iteration using next has to be stable when removing items during the iteration Ive had a look and think that hashbrown can support this with not much modification and prototyped it here a few months ago so I havent yet caught up on recent changes this was before it was moved to rustlang I added a fn nextafter self key Option K Option K V which simply steps through hash buckets via a RawIterRange constructed to point part way through to implement and happens for free by using tombstones when removing which relies on there not being a resize when shrinking too far Im not confident I havent missed any cases I would be interested to know if functionality like this would be considered for hashbrown itself I could understand not I can certainly see not wanting to guarantee no resize on removal or if not whether Ive missed any obvious issues if I or someone else were to maintain a fork with these changes Thanks Ive certainly enjoyed looking through and having a play either way For my use case I have a worker thread that periodically updates a thread local HashMap and then copies it to another thread For most iterations no entries are added or removed only the values change I would like to efficiently synchronize the two HashMaps by copying the arrays of control bytes and elements directly to the already allocated arrays of the other HashMap Basically it would be the same thing thats done in RawTables clone function without the extra allocations I saw that the RawTable was recently exposed in but unless I missed something it is not enough to copy the contents from one map into another Do you think it would be a good idea to implement clonefrom on RawTable which reuses the arrays if possible With the switch to Hashbrow stdmemsizeofstdcollectionsHashMap on bit platforms grew from bytes to to bytes with BuildHasherDefault In Servo s DOM implementation we have types whose sizeof is several hundreds of bytes Because some notsounusual pages can have very many DOM nodes this size can add up to significant memory usage We have unit tests for sizeof to ensure it does not accidentally grow which fail in today s Rust Nightly because several types grew by bytes because they contain a HashMap Hashbrown s HashMap contains a RawTable which has five pointersized fields Some of them seem potentially redundant but I m not sure For example there are two pointers that seem to be in the same allocation How expensive would it be to recompute the second pointer every time it is needed Are bucketmask growthleft and len related such that one of them could be computed from the others When growing a table hashbrown will start with a table of size which can hold element due to load factor and then double every time the load factor is reached Table size Capacity Memory usage sizeofT Memory usage sizeofT Memory usage sizeofT empty rounded up to for allocator alignment In comparison the current std HashMap starts off empty but then immediately grows to a table size of capacity as soon as the first element is added We want to try to balance memory usage for small tables with the allocation overhead when growing tables up to their final size The current code base only has the doctests from the standard library HashMap We should add a proper testsuite Possible sources of inspiration The benchmarks should really be using criterion It would be interesting to benchmark it against bytellhashmap which I did rust implementation for Havent optimised it that much and should really make it usable library