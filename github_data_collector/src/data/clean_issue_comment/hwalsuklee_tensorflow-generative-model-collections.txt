Thank you for sharing your codes I found that there is no weight clipping in the paper Least Squares Generative Adversarial Networks The weight clipping is used in the paper LossSensitive Generative Adversarial Networks on Lipschitz Densities Obviously your code is the former I tried both situations and the performance is better without weight clipping I changed the network structure and adjusted the superparameters to apply to data cifar I thought maybe someone needed it so I left the url of my code Thanks again Thanks for your code I found that Discriminator los sfunction of wgan is the same as Discriminator los sfunction of gan in your codebut actually not Pleace check it at line in WGANGP I recommend changing the code alpha tfrandomuniformshapeselfinputsgetshape minval maxval to alpha tfrandomuniformshape BATCHSIZE minval maxval Because It must be created one alpha value for each batch Hey hwalsuklee Thanks for sharing your code which helps me a lot I have a question about the linear function in opspy I would be appreciated if you can explain what you are doing in the this function def linearinput outputsize scopeNone stddev biasstart withwFalse shape inputgetshapeaslist with tfvariablescopescope or Linear matrix tfgetvariableMatrix shape outputsize tffloat tfrandomnormalinitializerstddevstddev bias tfgetvariablebias outputsize initializertfconstantinitializerbiasstart if withw return tfmatmulinput matrix bias matrix bias else return tfmatmulinput matrix bias Also It would be great if you add some comments when you are implementing to be much easier for others to understand Thanks Ive noticed an inefficiency in the CGAN code When we append the onehot encoded labels to the image they influence the training gradients a lot Instead Ive noticed that scaling the onehot encoded labels down by a factor of or even helps the CGAN converge around twice as fast That would mean changing optspys convcondconcat function My hack was to change return concat x ytfones xshapes xshapes xshapes yshapes to return concat x ytfones xshapes xshapes xshapes yshapes and that worked well for me Im not too sure about in general though perhaps try adding batch norm Make sure it works in win Thanks for your contribution A problem occurs when I am training ACGAN without tuning any parameters which is shown as follows As the training process goes on the loss of D is declining but the loss of G is increasing on the contraryand the gap between two of them is pretty large I do not know how to solve it thanks you code when i read the code the discriminator use sigmoid output but you also return Dreallogits and when caluate the loss real or fake you use Dreallogits or Dfakelogits before sigmoid output why you dont use the Dreal or Dfake the sigmoid ouput get loss for discriminator dlossreal tfreducemeanDreallogits dlossfake tfreducemeanDfakelogits thank can you help me Thanks for the nicely orgnized code I learned a lot from it But I have question about the CVAEs input you just append ys hot code to the last dimension of x so it makes the original data up to times larger the image shape becomes But why not just append y in the middle of the encoding process say when we get a flat vector after several conv d transformation then we could append y to this flat vector This is a great collection of generative models for TensorFlow all nicely wrapped in a common class interface Id like to use this as a basis for ongoing work Im migrating to TensorFlow Im interested in using this code not only to test MNIST models but also as a way of generating a series of reference models using several other datasets which can be reused and shared So as a first proposed change Id like to separate the batchsize from the model definition to instead be a runtime variable by using a placeholder This allows a trained model can be later opened without knowing the batchsize used at training time the encoderdecoder can be called on xz of variable length a trained model can be later refined via transfer learning at a different batchsize Ive done a quick version of this for the VAE model and verified that this still works on that model at least on the latest TensorFlow and enables and above If you are open to the spirit of this change Im happy to rework the implementation if youd like this cleaned up further