 The Schlick Fresnel approximation is R R R cos theta where R is the reflectance at normal indicence inline Float SchlickWeightFloat cosTheta Float m Clamp cosTheta return m m m m m inline Float FrSchlickFloat R Float cosTheta return LerpSchlickWeightcosTheta R inline Spectrum FrSchlickconst Spectrum R Float cosTheta return LerpSchlickWeightcosTheta R Spectrum Lerp here is SchlickWeightcosTheta R SchlickWeightcosTheta not R R SchlickWeightcosTheta Hi I am learning the bssrdf code of PBRT and possibly found a problem The problem occurs when I was trying to render a sqare with BSSRDF material The original scene file is from the material test ball scene from Tungsten rendering resource page And I remove the all of objects except a floor The strange thing is when I set subsurface material to the floor the rendering result is totaly black The original material for the floor is a lambert which of course show something in the result Then I tried to look into the shape of the floor the floor actually has a normal facing downwards ie the normal is The rendering result looks OK when material is Lamber and floor facing downwards which means pbrt works with two sided shading right But it seems that bssdf has a problem here bssrdf works if I revert the floors normal manually ie make the normal I guess the reason for this black floor is as following The bssrdf has a bsdf to sample reflection or transmission at the boudary at po ie bssrdf will only happen when a transmission is sampled The reason for being black is that transmission actually can NOT be sampled at boundary I guess there might be an inconsistency regarding the direction defined for wo in the following code Spectrum FresnelSpecularSamplef const Vector f wo Vector f const Point f u Float BxDFType sampledType const Float F FrDielectricCosThetawo etaA etaB here F is always if u F when the floor is facing downwards wo here has z value that is less than zero but here FrDielectric use the sign of woz to judge if the ray is entering or exiting the boundary The black floor is due to that for the case woz and the program thought the ray is exiting the boudary and then total reflection happens here F and no transmission sampled for bssrdf so the image is all black the following the scene file that trigger this problem uncomment the mesh to see the problem scene file Integrator path integer maxdepth Transform Sampler random integer pixelsamples PixelFilter triangle float xwidth float ywidth Film image integer xresolution integer yresolution string filename sssproblemexr Camera perspective float fov WorldBegin MakeNamedMaterial sss string type subsurface float g float eta string name Skin float scale rgb Kr MakeNamedMaterial sss string type subsurface float g float eta string name Skin float scale LightSource point point from rgb I NamedMaterial sss bssrdf does NOT works Shape trianglemesh integer indices point P e e normal N float uv bssrdf works if I revert the floors normal manually Shape trianglemesh integer indices point P e e normal N float uv WorldEnd One of the GitHub features Im not comfortable with is embedding external dependencies It can be convenient for quickly trying out a project you download everything recursively build everything together and there you go but when you finish your first glance and you move into seriously using a project then you need to install it and you realize that you are duplicating code because you are using the external dependencies for more than one project and each of them embeds and builds its own copy although quite often the install target is broken in that workflow I want to use pbrt tightly integrated in another application so the first thing is to get a tidy and clean source tree and build workflow where dependencies are parallel to pbrt at the same hierarchy level in the source tree and not inside it Is it currently possible to invoke Cmake in some way to achieve this Of course I could fork pbrt and tune it to my needs but I prefer to avoid doing that because when you do your custom modified fork applying commits from the official fork becomes harder and harder with time So if I could achieve this with the official source unmodified it would be great volpath is not included in the list of available integrators in According to the formula dpdu is not a normalized vector but sishadingdpdu is normalized Compute bumpmapped differential geometry Vector f dpdu sishadingdpdu uDisplace displace du Vector fsishadingn displace Vector fsishadingdndu Vector f dpdv sishadingdpdv vDisplace displace dv Vector fsishadingn displace Vector fsishadingdndv This is a part of code in TriangleIntersect ts and ss are normalized the values are assigned to shadingdpdu and shadingdpdv Vector f ts Crossss ns if tsLengthSquared f ts Normalizets ss Crossts ns else CoordinateSystemVector fns ss ts isectSetShadingGeometryss ts dndu dndv true Is the code wrong FourierBSDFTables fields dont get deleted when the struct is being destroyed in file srcshapessphereh line to line since z r costheta according to the book Theta is in pi Obviously z is a monotone decreasing function to theta in pi Is it should be thetaMinstdacosClampstdmaxzMin zMax radius thetaMaxstdacosClampstdminzMin zMax radius since if zMax equals lets say its a unit sphere the theta should be which is the minimum value in its range I know it wont make such a difference but shouldnt you stop recursion when the number of primitives in current node is equal or bellow maxPrimsInNode In the current version end start then the for loop is useless I suppose you wanted the if condition to be if nPrimitives maxPrimsInNode So I was using my own scene and rendering it from different view points by tweaking the lookat values in the pbrt file I have the D coordinates of the model that I am rendering so I would like to do a D to D projection to find out where some specific point lies on a rendered image I am using the openCV projectPoints function however it requires to know the camera intrinsics and extrinsics I know the extrinsics using the lookat matrix however i dont know the focal length focal distance for the default camera in PBRT As far as I am concerned the default camera in PBRT uses a Pinhole model where by default the focal length is But using a value of in the camera matrix does not make sense and also the values that I am getting for the D points are very close to the principal point The principal point is halfwidth halfheight of my rendered images So basically I am looking for a value for my focal lenght Can anyone help me with this Or am I missing something Thanks for reading any sort of help will be appreciated I build the pbrtv on Linux Windows MacOS Every rendering on these OS is normal and can be generate the exr results for a CG scene by myself But I encounter an issue that the linux rendering exr result is Decode error when trying to open it while the result of same behavior on Windows and MacOS is normal What is wrong about the Linux version pbrt rendering result And how to solve this issue Looking forward to get some reply and thanks in advance