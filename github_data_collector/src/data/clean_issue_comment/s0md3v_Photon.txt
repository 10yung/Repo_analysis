Hi First things first thank you for creating and sharing so many awesome tools You It looks findsubdomainscom no longer exists and is redirected to Spyse and hence photon is not exporting any subdomains to a text file when using the flag dns Can you please review Thanks again for an awesome project The issue was being cause by a nevercatcheable regex dnsdumpster HTML attributes use double quotes whereas this regex was catching only the expression with simple ones and thus creating an empty regex object None Type I found at least one example where the links are not being extracted in any of the datasets html DOCTYPE html html head titleTesttitle script srcjavascriptfilejsscript script src head body Body content body html In this case should be left in at least one dataset I tried to locate the appropriate point in the code to modify the logic but I got kind of lost P Hi as shown in the following full dependency graph of Photon Photon requires urllib the latest version while the installed version of requests requires urllib According to Pips first found wins installation strategy urllib is the actually installed version Although the first found package version urllib just satisfies the later dependency constraint urllib it will lead to a build failure once developers release a newer version of urllib in the near future which is greater than Dependency tree Photonversion range requestsversion range chardetversion range idnaversion range urllib version range certifiversion range tldversion range urllib version range Thanks for your attention Best Neolith I have an issue where Photon gets stuck when using the keys option Example python photonpy u publicsectormgmtpcom v keys v URLs retrieved from robotstxt URLs retrieved from sitemapxml Level URLs Progress And then it just stays there forever However not using keys works great python photonpy u publicsectormgmtpcom v onlyurls wayback v Fetching URLs from archiveorg Retrieved URLs from archiveorg URLs retrieved from robotstxt URLs retrieved from sitemapxml Level URLs Progress Level URLs Progress Files Robots Internal External Total requests made Total time taken minutes seconds Requests per second Results saved in publicsectormgmtpcom directory Note that this does not happen on every domain but only on some Also does wayback work I always get URLs from archiveorg Hi mate awesome project Thank you Would be possible to collect js files from wayback and see if they are live If so we add it to the scriptstxt list and look for api keys inside js files too Cheers I try to use photon as a crawler and save its request to burpsuite History tab Because Photon failed to verify SSL certificate Any option to skip this The encode method was used incorrectly as a result the files were not written and caused the handles to hang The clone function only clones the seed URL and not all pages crawled as described in the Photon Wiki Saved the logic of autodetection schemes all wrapped in an error handler