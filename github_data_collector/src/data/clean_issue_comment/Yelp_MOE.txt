After building from source in a virutal environment i get the following error when running the following example code Sample points for i in range Use MOE to determine what is the point with highest Expected Improvement to use next nextpointtosample gpnextpointsexp By default we only ask for one point Sample the point from our objective function we can replace this with any function valueofnextpoint functiontominimizenextpointtosample print Sampled f s Eformatstrnextpointtosample valueofnextpoint Add the information about the point to the experiment historical data to inform the GP exphistoricaldataappendsamplepoints SamplePointnextpointtosample valueofnextpoint We can add some noise ERROR File sdpy line in module nextpointtosample gpnextpointsexp By default we only ask for one point File homehallabmoeeMOEmoeeasyinterfacesimpleendpointpy line in gpnextpoints jsonresponse callendpointwithpayloadresthost restport endpoint jsonpayload testapp File homehallabmoeeMOEmoeeasyinterfacesimpleendpointpy line in callendpointwithpayload with contextlibclosingurllib urlopenrequest as f File usrlibpython urllib py line in urlopen return openeropenurl data timeout File usrlibpython urllib py line in open response selfopenreq data File usrlibpython urllib py line in open open req File usrlibpython urllib py line in callchain result funcargs File usrlibpython urllib py line in httpopen return selfdoopenhttplibHTTPConnection req File usrlibpython urllib py line in doopen raise URLErrorerr urllib URLError urlopen error Errno Connection refused My collaborator added some covariance functions using polynomial exponential and matern kernels to the gppcovariancecpp and gppcovariancehpp and the python wrapper covariancepy and also in domainpy however when attempting to build moe with these changes cmake succeeds meaning the C code seems good but I dont understand how the python code gets compiled and placed in the appropriate place Therefore I dont know how to build moe so that I can use these new covariance functions through the python interface Could some detail be added to the documentation regarding adding custom functions via C with wrappers Hey I noticed there havent been any commits since January I was just curious if this project was essentially abandoned by the developers Or was it deemed sufficient for use Or was the project brought internally back to Yelp The algorithm looks a lot similar to spearmint which also use GP EI Just curious if there is any comparison or is it simply a commericial version of spearmint I found a MiB moelog file which contains logs since till MiB git repo DSStore files vim temp files end with etc in the final docker image All of them are useless for a productionready docker image Besides once built building tools are no longer useful so I suggest you use twosteps build that copy the generated binary files into another image Hi there I have been trying to run a project which is built upon the MOE there is an error showing that import moebuildGPP as CGP ImportError No module named buildGPP I am under MOEmoeoptimallearningpythoncppwrappersgaussianprocesspy I check the file and there is no build file under moe What should I do This is a collection of minor fixes that resolve A compilation error Dramatically reduce the amount of warnings generated by GCC x I am assuming that MOE doesnt support userdefined prior mean functions and that the only way to incorporate prior knowledge into MOE is by carefully adding fake points with a large error on them First of all I am really amazed by the wonderful neat interface of MOE I appreciate it I dont understand why there are noisevariance attribute in SamplePoint In other words why does every datapoint have their own noise value I dont think it is about multifidelity setting If so it would be truly amazing though So what does noisevariance assigned to each data point mean and what value should I plug in to it