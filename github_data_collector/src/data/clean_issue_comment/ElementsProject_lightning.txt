 Issue and Steps to Reproduce Describe your issue and tell us how to reproduce it include any useful information The documentation could benefit a lot from examples for the RPC commands For example from the synopsis sendpay route paymenthash label msatoshi bolt partid the following might not be immediately clear judging from own experience route and paymenthash are mandatory others are optional specifying argument names for mandatory arguments route is not required route should be in the form nodeid nodeid nodeid without quotes paymenthash must be in the form not sure see if any optional arguments are provided all of them must be provided optional arguments must be provided as a JSON objects add rules on escaping quotes etc Some of the points above are commandspecific some are related to the API as a whole but I havent been able to find these points written down explicitly For the commandspecific issues most of the uncertainties can probably be resolved by adding a simple example getinfo output Issue and Steps to Reproduce Describe your issue and tell us how to reproduce it include any useful information Its not clear from the documentation how this command should be used sendpay route paymenthash label msatoshi bolt partid I send a payment to a neighboring node b with the hash value of ones and get an error lightningcli sendpay b cddd beb f fbdce cde ba f c ddf c d e b code message Expected array or object for params How should I use sendpay getinfo output id d ac f cbdb f afee db becd d e b c cee f f alias clightningM color d numpeers numpendingchannels numactivechannels numinactivechannels address binding type ipv address port version v g f de blockheight network regtest msatoshifeescollected feescollectedmsat msat lightningdir homesergeilightningregtest Dual Funding This PR updates the channel establishment aka openingds responsiblity to allow for both the originating and the reciprocating peer to contribute UTXOs to the funding transaction The protocol for this has been laid out in in the lightningrfcs but for ease of review Ill include it here as well along with some explanation for the decisions Note that this PR does not encompass the RBF flows illustrated those will be covered in a future update openchannel acceptchannel a fundingaddinput b fundingaddinput c fundingaddinput d fundingaddoutput e fundingaddoutput a fundingaddcomplete b fundingaddcomplete A B commitmentsigned commitmentsigned fundingsigned a initrbf b ackrbf fundinglocked fundinglocked There are a few notable changes First the funding inputs and outputs are exchanged via rounds where either peer may submit almost any number of fundingaddinput or fundingaddoutput messages The round is finished when both peers have sent a fundingaddcomplete message with a tally of all the inputs and outputs that they sent The peers construct the funding transaction from the set of inputs and outputs that have been sent and received and update the messages channelid accordingly such that commitmentsigned now includes both the correct funding transaction id and a valid commitment signature for that transaction Finally the reciprocating peer also known as the accepter sends the originating peer opener the signatures for their inputs in the funding transaction Why Rounds of InputsOutputs Originally the dual funding protocol called for both peers to exchange signatures for their inputs However weve softened this to just the accepter side sending their signatures The reason for this has to do with why we introduced the rounds of fundingadd in the first place The goal is to enable the accepter and the opener to both solicit and then include funding transaction outputs from other peers simultaneously Heres a quick example of how the Accepter of a channel open might include a second open in the same transaction OPENERA ACCEPTERAOPENERB ACCEPTERB openchannel acceptchannel fundingaddinput openchannel fundingaddinput acceptchannel fundingaddoutput fundingaddinput fundingaddoutput fundingaddoutput fundingaddcomplete fundingaddinput fundingaddinput fundingaddoutput fundingaddoutput fundingaddcomplete fundingaddcomplete fundingaddcomplete commitmentsigned commitmentsigned commtmentsigned commitmentsigned fundingsigned fundingsigned In this scenario OPENERA will be the peer that broadcasts the funding transaction as theyre the only peer who knows the signatures to their funding transaction inputs Note that the commitmentsigned message is broken out from the fundingsigned message Originally I had these as the same message but that would delay the communication of the commitments in the case where the the first accepter ACCEPTERA needs to get the funding signatures from ACCEPTERB before sending their signatures to OPENERA Note that this construction allows a small ambiguity into the origination of any input that an opener receives for a funding transaction One downside to this is that the opener as a result of their receiving all of the inputs and having control over the broadcast of the transaction pays all of the fees This makes opens more brittle as more peers are required to be online and participate in order to RBF an open transaction It has no effect on the operation of channels opened in this manner How to Dual Fund a Channel To dual fund a channel we make use of the openchannel plugin hook Weve expanded the openchannel payload to include a few new fields First we now provide a version number of the channel open protocol that this openchannel request is using Second we rename fundingsatoshis to openersatoshis as this amount is the satoshi value that the opener is contributing to the channel not the total funding amount Finally we also include an availablefunds value which tells the plugin the total amount of funds that the internal wallet currently has available to fund this channel To contribute funds to an openchannel request the hook must respond with a continue JSON object that also includes a fundingsats member indicating the total value of satoshi that we should add to this channel See testspluginsfunderpy as a very simple example of this Channel Open Tracking With the first version of channel establishment the publishing node was the one that owned all of the outputs as well as the funding transaction Any failure of the channel to open was within your own purview forgetting a failed channel open as an accepting peer had no consequences v however changes these assumptions We now need to know if a channel open gets voided via the spend of any of its inputs Until the channel funding transaction or an input to it is seen on chain we must keep track and not forget any data about the channel open To this end this PR also includes a series of commits which add a new table to the database called outputtracking This is where we keep data of every input which pertains to a channel If we detect a spend of an input for a channels funding transaction and not in that funding transaction we move a channel to a temporary state called BORKED It persists in the BORKED state until the offending transaction that contains the input spend reaches a depth of At this point the channel is forgotten and a new open may be attempted with this peer We also track these across reorgs and restarts If you restart a node with a rescan value of less than theres a good chance youll break this and your channel will get stuck in BORKED mode forever Errata Because of how fundchannelstart and fundchannelcomplete are used under the hood to make fundchannel work we do a few hacky things to work around the fact that txpreparetxsend hold the transaction for this channel Dualfunded transactions expect a zerovalue output from the opener that will be usedfilled in with the feerate in order to accommodate this txprepare has an option zerooutchange which will supply a transaction with a change output of value zero Likewise hsmd has been adjusted to make sure that we never actually sign a transaction with any output of value zero so these are unspendable as is Completing a funding open fundchannelcomplete will return the updated txid for the funding transaction This updated txid is what must be passed into txsend in order to send the transaction as the v channel open pathways modify the underlying prepared transaction in clightnings wallet This is admittedly suboptimal Ive got some sketches done of how to transition this to PSBT Ongoing Work The python tests are currently not passing failed error on my machine x The commits for this PR are missing CHANGELOG entries Protocol tests need to be fixed up for the new SIGS and message updates Protocol tests for the opener side need to be completed Future Work RBF Using PBST to handle the inputsoutputs for fundchannelstartfundchannelcomplete Issue and Steps to Reproduce See unilateral close and INFO here The node id is ad fb d dc e bcedefadf f a ae dc f c b c c f b a b so what is that extra doing in INFO ad fb d dc getinfo output id c ab f c de e b c c f b alias Bitkoinsnl color d numpeers numpendingchannels numactivechannels numinactivechannels address type ipv address port type torv address tjeuwxa rr iprsonion port type torv address bh psr dinasuz d jm o ebkmlnotqqptoesikzvsyqxwmaneyiadonion port binding type ipv address port version v gb b b blockheight network bitcoin msatoshifeescollected feescollectedmsat msat lightningdir homeuserlightningbitcoin Issue and Steps to Reproduce I was trying to check the availability of nodes to make better routing decisions While doing that I tried to connect to every node on the network and discovered the error from the title several times You can reuse the code from I get several errors as expected because there is just a timeout of the connection However I get several errors with a crypotgraphic handshake error for example this one could not connect to da ffa a fe a f e b dfd d e e RPC call failed method connect payload id da ffa a fe a f e b dfd d e e error code message Cryptographic handshake Connection reset by peer I even reproduced it with loglevelio and a new clear node lightningd lightningdirtmpln networkbitcoin bindaddr loglevelio lightningcli lightningdirtmpln connect da ffa a fe a f e b dfd d e e which produces the following log output T Z jsonrpc IN b a f e a e c d f a f e e c a c e e d c T Z jsonrpc IN d c d a b T Z jsonrpc IN c e e e c d d T Z DEBUG da ffa a fe a f e b dfd d e e connectd Connected out starting crypto T Z DEBUG lightningd feerate estimate for normal hit floor T Z DEBUG lightningd feerate estimate for slow hit floor T Z DEBUG gossipd seeker no peers waiting T Z DEBUG lightningd feerate estimate for normal hit floor T Z DEBUG lightningd feerate estimate for slow hit floor T Z jsonrpc OUT b a f e a e c a c e e d c d c f a b f a d c d a e e e a a f e b a f e e f e e d d a a T Z DEBUG da ffa a fe a f e b dfd d e e connectd Failed connected out Cryptographic handshake Connection reset by peer getinfo output id a d aa cec aa d cf d bed a aef d d f alias ANGRYSUCKER color a d numpeers numpendingchannels numactivechannels numinactivechannels address type ipv address XXXXXXXX port type ipv address XXXXXXXXX port binding type ipv address port type ipv address port version v blockheight network bitcoin msatoshifeescollected feescollectedmsat msat lightningdir homerpickhardtlightningbitcoin While studying the existing fundchannel in preparation for fully implementing I noticed that the current fundchannel does this connect to peer txprepare a dryrun fundchannel using a dummy funding address Extract the funding output amount in the returned transaction presumably this is how we determine the actual amount when given all fundchannelstart to peer using the extracted amount receiving a target funding address txdiscard the previous dryrun transaction txprepare this time with the nowfilledin funding address fundchannelcomplete with the transaction ID txsend the transaction What I want to point is that in theory it would be possible for a sufficiently heavilyused server to have some other withdraw fundchannel or txprepare execute between the txdiscard of the dryrun transaction and the subsequent txprepare as a multithreaded race condition As locking of the RPC is not implemented and would be dangerous as well consider that a plugin can easily deadlock itself with an incorrect lock behavior we might instead want to have an atomic operation that combines a txdiscard with a txprepare that uses the exact same inputs and outputs just redirects the address of an output So let me propose txmodifypayee txid modifications Where modifications is an array containing objects with fields outnum address LXPWUpTGKmeatx NpyQ A TZr GCXkK u The address would have to take up the same amount of space as the current address at that outnum The command succeeds or fails atomically If it succeeds then the old txid is no longer passable to txdiscard or txsend If it fails then the old txid can still be passed to txdiscard or txsend Thoughts niftynei cdecker rustyrussell Issue and Steps to Reproduce Describe your issue and tell us how to reproduce it include any useful information Ive set up a regtest LN on a local machine with one clightning instance and two Eclair instances clightning Eclair Eclair The problem is that clightning doesnt know on the channel between Eclair and Eclair and cant route payments to Eclair Connecting clightning to Eclair meaning P P connection not a channel doesnt help the channel isnt added to clightnings view of the graph Is there a way to manually add a channels to clightnings view Another solution may be to force Eclair to send a channel update but that is not a clightning issue Asked about it on Eclairs Gitter getinfo output id d ac f cbdb f afee db becd d e b c cee f f alias clightningM color d numpeers numpendingchannels numactivechannels numinactivechannels address binding type ipv address port version v g f de blockheight network regtest msatoshifeescollected feescollectedmsat msat lightningdir homesergeilightningregtest As a challenge I with some help from others built to explore how the createonion sendonion and generally the TLV stuff can be used for building apps Also maybe help spread awareness of the associated concepts out there The full code is all at First thanks to all of you in the CLightning project for building this stuff exposing it to be used from the outside and performing the handful of public talks to explain it Very cool stuff that I am excited to follow the future of Here are some of my thoughts and feedback about some of the bumpy parts I encountered in my arc of building A lot of it is along the lines of other app developers will likely have need for the same stuff I wrote so shared pluginplatform code that makes these operations easier would be a benefit This type of thing also might be premature to action on without additional feedback from others trying to build apps I hope this account is useful info to help refine going forward I apologize in advance for verbosity The documentation for createonion refers to BOLT for how to encode a payload That was a rabbit hole for me to go down and I ended up having to implement the stuff in BOLT in Python in order to build the TLV payloads myself This library is somewhat generalized such that it could be used by a different Python app and has four main modules bigsizepy tlvpy namespacepy and hoppayloadpy which build on each other in that order For my appspecific extension TLVs I extend a generated hop payload with my extension module When writing this I was thinking about how CLightning has the invoice and decodepay commands which in a way go together as a pair for creating and decoding a BOLT invoice also is able to prevent the creation of an incorrect BOLT with the benefit of context The net effect is that the application developer doesnt have to think much about the details of BOLT encodings so maybe that is similarly achievable for the BOLT payload encodings SUGGESTION It might be good to provide an on rails payload creator that can to all the TLV encodingdecoding according to spec with the main codebase such that encodersdecoders dont have to be written in N different languages Also it is imaginably straightforward to include optional parameters for extension TLVs to be appended after Since a there is the hard cap of bytes for the payload HMAC data in the onion packet and b the data is all variablylength encoded for compactness and c The quantity of hops to get to the destination and back can also be fluid it makes it difficult to determine how much data is ultimately available in the packet for application extension data My solution for Onion Studio is a fudgy estimate starting point and a couple iteration of finding hops and attempting an encoding and reducing the amount of payload pixels I encode until it fits under the byte limit Also when playing with this stuff I hit the two crashing bugs which were additional pain for trying to use the createonion command before I had a proper clue about what I was doing Overall this was kind of gnarly to get done but I now have some solution logic written that might be helpful to others SUGGESTION a Aside from fixing the crashes and giving nice error messages when you give wrong input it might be good to provide a fullerfeatured onion packet creator functionality that is more aware of the content and give you less rope to hang yourself with Applicationside fudgy estimates like mine are doomed to be less accurate and maintained than the internal code for creating onions doing validation so it seems to make sense to provide a better service SUGGESTION b Perhaps in conjunction with SUGGESTION the workflow for such an onion creator tool might have two phases First a phase for creating the routing instructions as desired since that is the most important thing Second the first phase might tell you how many spare bytes are left for nonroutingextension concerns and then lets you fill them in Onion Studios client sends the pixel data via a circular route and pays for the pixels by overpaying the routing fee at that hop The route creation uses getroute with a fuzzpercent setting of It uses the fromid to compute the reverse route in the same way which is can be identical to the outgoing route It has to be deterministic simply because the algorithm need to hold the route relatively constant as it iterates on the onion construction to fit the pixel payload and appropriate payment using the rest of the space and changing the payment amount also can influence the chosen route changing the available space changing the number of pixels in the payload changing the payment etc This implementation trickiness resulted in me abandoning the desire to construct a good circular route that would prefer the outgoing and returning route to be fuzzy and avoid node overlaps The result is an implementation that is perhaps subpar for the purpose of passing a maximallydiscreet message The chosen circular scheme is also convenient for sending data without some outofband negotiation between the source in the destination An alternative for a similar app might be the Key Send scheme to make it a unidirectional send of a payment extension data However choosing between the two schemes for a particular style of app is a complex discussion that I dont have a clear formed opinion on However I observe that the circular scheme might be useful for obscuring the real destination of a TLV RPC call among the set of participants in the circular route Also I observe that if there are schemes designed I expect this to be inevitable if not already happened for TLV RPC calls where there is a call out with a payload to a node and a call back with a payload to the source this might look exactly like a circular operation even though it might be two different unidirectional suboperations in implementation Having both schemes around and supported might be a good platform for privacy for the variety of possible operations SUGGESTION A get circular route operation might be a good plugincommand to provide as a common utility Also given that the real payment might be in the form of a forwarding fee somewhere along the route it would be a nice feature if that amount could be optionally be selected as a criteria A noted fact of the extension TLVs is that they are delivered to their intended recipient before the preimage is revealed to trigger the associated payment Onion Studios design is such that the pixels dont draw until the payment is received On the application side it has to catch the payload field upon a call from the htlcaccepted hook notification and hold on to the data it until getting a forwardevent notification Also the application needs to have a scheduled pruning step to cull the stored payload data from forwarding HTLCs that never get paid SUGGESTION a Possibly consider a design for notifications to the plugin to give notification of the extension TLVs specifically along their lifecycle such that the application can get a notification upon HTLC accepted HTLC fulfilled or HTLC expired This way the extension TLV might not need to be held separately by the application SUGGESTION b One perhaps halfbaked thought is that there might be value in the protocol supporting encrypted extended TLVs that can only be decrypted with knowledge of the preimage This would be such that the recipient doesnt know what the requested extension operation is until the payment is received This would give sender the option to avoid revealing the content of request until the sender has definitively decided to go ahead with the paymentoperation With Onion Studio typically only encoded pixels fit in the onion packet Unless they are tiny png images they have to be split up into many separate payments For example a x pixel image will require approximately payments of satoshis each totalling satoshis to transmit all the pixels There is a challenge in estimating channel capacity for this kind of payment because it isnt quite I wish to route k sats to the destination it is I wish to route many small payments totaling k sats to the destination which can go via different routes Ideally we would want to determine for the user whether it looks like that can realistically be done to completion before deciding to proceed Right now the approach of Onion Studio is to allow failure if there is a capacity exhaustion event midway but gives the user the option to manually resume the transmission from the point it left off later However this might be frustrating user experience to have to babysit the operation and restart I imagine this is a similar problem for other datapublishing apps where it doesnt really deliver full value to only get a partial set of payments through to their destination SUGGESTION This probably needs a chunk of science done to figure out good algorithms for this but I can perhaps spot a similarity between this and the routing considerations needed for AMP In this specific concern we want the full message transmission to be the concern for atomicity It might make sense to include this problem for consideration in that discussion FIN Currently libplugin inherently assumes that every pluginlevel command will have a single thread of operations For example pay might do something like getroute sendpay waitsendpay While designing a C plugin for multifundchannel for however I think it is best if we can support sending multiple commands in parallel eg connect fundchannelstart connect txprepare fundchannelstart dryrun connect fundchannelstart Currently sendoutreq is designed to just send commands one at a time with processing of the plugin command suspended while the lowerlevel command is executed This is undesirable for multifundchannel since we would end up waiting for one peer to finish some step then move to the next peer when in principle since those are presumably separate peers then we should be able to at least start the phase in parallel with all of them That way the time of a phase is only the slowest peer instead of the sum of all the times of all peers What I would like to have is something in libpluginh that is very much like struct pluginspark struct pluginsparkcompletion Perform some commands in the background struct pluginspark pluginsparkstruct command cmd struct commandresult sparkcbstruct command cmd struct pluginsparkcompletion complete void arg void arg Called within the sparkcb struct commandresult plugincompletesparkstruct command cmd struct pluginsparkcompletion complete Called by the caller of pluginspark Wait for one or more sparks to call plugincompletespark then invoke the callback when all of them have completed struct commandresult pluginwaitsparksstruct command cmd Allows us to staticalloc a fixed array of sparks instead of always requiring a tallocated array unsigned int numsparks struct pluginspark sparks struct commandresult cbstruct command cmd void arg void arg To some extent the current plugintimer has a lot of similarities to this and with some modification to plugintimer specifically allow creating a timer that has an argument and a struct command and access to the struct commandresult pending complete it might be possible to build the above sparks system on top of the plugin timers by using timers with timerel as the spark construct a spark object that serves as coordinator between the timer and the main thread etc Then for the multifundchannel case during the connect phase we would start sparks for each peer listed saving the spark for each then wait for all the sparks to complete and check the results for the connect commands Of course concurrency is much harder sigh Thoughts rustyrussell niftynei cdecker Rationale described here Summary We may be going to rely on pluginexposed RPC methods for crucial operations such as Bitcoin backend a versioning is useful to avoid nasty corner cases Open questions should we allow to register multiple RPC methods with the same name but different versions 