Hithanks for your work Did you ever try to put it together I think put it together shouldnt make it worse But when I use it to train lenetdatasetmnist it actually get worse result Hi I found that the model trained with AMS may get higher similarity bettem a pair of abnormal enroll and probe images the probe is low qulaity wrong aligned or even not a face the enroll is not a good id photo The similarity may be around or even higher while the ones trained with softmax may be just around So have you ever met the same problems Is it because that the margin push the feature space much compact than softmax Thanks Dear happynear first of all thanks for your work and uploaded results I would like to ask about alignment step is it really important to get good performance I have not tried your code will do it this week but tried ResNet with VGG without alignment step SoftMax and CenterLoss gave about both CenterLoss also provided much better localization but surprisingly ArcFace result was only I will try CosFace this week but I expect more or less the same Did you try to train something without alignment Thank you I will post my result with CosFace I set an image to AMSoftmax which net prototxt is facedeploymirrornormalizeprototxt and weight is your pretrained weights after loading weights I put an image to net input and run forward method on it Then I wanted to explore how the flip layer works but after plot the output of flipdata blobs I see something goes wrong the flip layer has flipped data verticallyI mean up down is it Okay result of code selection The code is something like below netcaffeNet facedeploymirrornormalizeprototxt facetraintestiter caffemodel caffeTEST def returnlayernamelayernamei outputnetblobs layername data i outputnpswapaxesoutput return output imgcaffeioloadimageAnthonyHopkins jpg imgcaffeioresizeimg imgnpexpanddimsimg imgnpswapaxesimg netblobs data data img netforward outputnetblobs norm data out returnlayernamedatainput split out returnlayernameflipdata fig pltfigurefigsize pltsubplot pltimshowout pltsubplot pltimshowout I train my model Webface in parms of s m The Result in lfw is I try to change parms but it get worse result Is the parms is the best in your tests Can data strength help me improve the effect thanks for your advice Hi thanks for your great job I wonder how I can debug the value of margin and scale to get better resultI use the default settingm scale on my face recognition dataset the final training loss is about and it cant decrease So I come here to ask the quesion thank you