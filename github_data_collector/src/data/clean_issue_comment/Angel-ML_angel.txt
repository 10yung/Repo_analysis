 Could not complete tmphadoopyarnangelstagingapplication libjarsall pom retrying property nameangeljoblibjarsname valueANGELHOMElibangelmath jarANGELHOMElibangelformat jarANGELHOMElibangelmlcore jarANGELHOMElibjniloader jarANGELHOMElibnativesystemjava jarANGELHOMElibarpackcombinedall jarANGELHOMEliball pomANGELHOMElibcore jarANGELHOMElibnetlibnativereflinuxarmhf nativesjarANGELHOMElibnetlibnativereflinuxi nativesjarANGELHOMElibnetlibnativereflinuxx nativesjarANGELHOMElibnetlibnativesystemlinuxarmhf nativesjarANGELHOMElibnetlibnativesystemlinuxi nativesjarANGELHOMElibnetlibnativesystemlinuxx nativesjarANGELHOMElibjacksonannotations jarANGELHOMElibjacksoncore jarANGELHOMElibjacksoncoreasl jarANGELHOMElibjacksondatabind jarANGELHOMElibjacksonjaxrs jarANGELHOMElibjacksonmapperasl jarANGELHOMElibjacksonmoduleparanamer jarANGELHOMElibjacksonmodulescala jarANGELHOMElibjacksonxc jarANGELHOMElibjson sast jarANGELHOMElibjson score jarANGELHOMElibjson sjackson jarANGELHOMElibnettyall FinaljarANGELHOMElibangelpsmllibANGELVERSIONjarANGELHOMElibangelpstoolsANGELVERSIONjarANGELHOMElibscalareflect jarANGELHOMElibmemory jarANGELHOMElibsketchescore jarANGELHOMElibcommonspool jarANGELHOMElibkryoshaded jarANGELHOMElibkryoserializers jarANGELHOMElibscalalibrary jarANGELHOMElibangelpscoreANGELVERSIONjarANGELHOMElibangelpspsfANGELVERSIONjarANGELHOMElibfastutil jarANGELHOMElibsizeof jarANGELHOMElibminlog jarANGELHOMElibbreeze jarANGELHOMElibangelformat jarANGELHOMElibangelmath jarANGELHOMElibangelmlcore jarANGELHOMElibcommonsmath jarvalue property sona angel If my train data has not number of features will have error below error log ERROR MatrixTransportClient serialize request PutPartitionUpdateRequest taskIndex rowsSplit size updateClockfalse toStringPartitionRequestclock partKeyPartitionKeymatrixId partitionId startRow startCol endRow endCol indexNum comeFromPsfalse comtencentangelpsserverdatarequestUpdateRequest failed javalangArrayIndexOutOfBoundsException at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeIntDoubleRowRowsViewUpdateItemjava at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeRowRowsViewUpdateItemjava at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeRowsViewUpdateItemjava at comtencentangelpsserverdatarequestUpdateRequestserializeUpdateRequestjava at comtencentangelpsagentmatrixtransportMatrixTransportClientserializeRequestMatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientaccess MatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientRequestersendRequestMatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientRequesterrunMatrixTransportClientjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava ERROR MatrixTransportClient serialize request PutPartitionUpdateRequest taskIndex rowsSplit size updateClockfalse toStringPartitionRequestclock partKeyPartitionKeymatrixId partitionId startRow startCol endRow endCol indexNum comeFromPsfalse comtencentangelpsserverdatarequestUpdateRequest failed javalangArrayIndexOutOfBoundsException at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeIntDoubleRowRowsViewUpdateItemjava at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeRowRowsViewUpdateItemjava at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeRowsViewUpdateItemjava at comtencentangelpsserverdatarequestUpdateRequestserializeUpdateRequestjava at comtencentangelpsagentmatrixtransportMatrixTransportClientserializeRequestMatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientaccess MatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientRequestersendRequestMatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientRequesterrunMatrixTransportClientjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava ERROR MatrixTransportClient serialize request PutPartitionUpdateRequest taskIndex rowsSplit size updateClockfalse toStringPartitionRequestclock partKeyPartitionKeymatrixId partitionId startRow startCol endRow endCol indexNum comeFromPsfalse comtencentangelpsserverdatarequestUpdateRequest failed javalangArrayIndexOutOfBoundsException at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeIntDoubleRowRowsViewUpdateItemjava at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeRowRowsViewUpdateItemjava at comtencentangelpsagentmatrixtransportadapterRowsViewUpdateItemserializeRowsViewUpdateItemjava at comtencentangelpsserverdatarequestUpdateRequestserializeUpdateRequestjava at comtencentangelpsagentmatrixtransportMatrixTransportClientserializeRequestMatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientaccess MatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientRequestersendRequestMatrixTransportClientjava at comtencentangelpsagentmatrixtransportMatrixTransportClientRequesterrunMatrixTransportClientjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava my dawjson data format libsvm indexrange numfield validateratio model modeltype TDOUBLESPARSELONGKEY modelsize train epoch numupdateperepoch lr decay defaultoptimizer type momentum momentum reg layers name wide type simpleinputlayer outputdim transfunc identity name embedding type embedding numfactors outputdim name fclayer type FCLayer inputlayer embedding outputdims transfuncs relu relu identity name sumPooling type SumPooling outputdim inputlayers wide fclayer name simplelosslayer type simplelosslayer lossfunc logloss inputlayer sumPooling my train data like sona Angel error log WARN TaskSetManager Lost task in stage TID bj pgryaigraphspark pswpscn executor javalangArrayIndexOutOfBoundsException at comtencentangelmlcorenetworklayersLayeranonfungatherGradInput anonfunapply anonfunapplymcVIsp applyLayerscala at comtencentangelmlcorenetworklayersLayeranonfungatherGradInput anonfunapply anonfunapplymcVIsp applyLayerscala at scalacollectionimmutableRangeforeachRangescala at comtencentangelmlcorenetworklayersLayeranonfungatherGradInput anonfunapply applymcVIspLayerscala at scalacollectionimmutableRangeforeachmVcspRangescala at comtencentangelmlcorenetworklayersLayeranonfungatherGradInput applyLayerscala at comtencentangelmlcorenetworklayersLayeranonfungatherGradInput applyLayerscala at scalacollectionimmutableListforeachListscala at comtencentangelmlcorenetworklayersLayergatherGradInputLayerscala at comtencentangelmlcorenetworklayersInputLayerbackwardInputLayerscala at comtencentangelmlcorenetworkGraphanonfuncalBackward applyGraphscala at comtencentangelmlcorenetworkGraphanonfuncalBackward applyGraphscala at scalacollectionimmutableListforeachListscala at scalacollectiongenericTraversableForwarderclassforeachTraversableForwarderscala at scalacollectionmutableListBufferforeachListBufferscala at comtencentangelmlcorenetworkGraphcalBackwardGraphscala at comtencentangelsonamlcommonTrainertrainOneBatchTrainerscala at comtencentangelsonamlclassificationAngelClassifieranonfuntrain anonfunapplymcVIsp anonfun applyAngelClassifierscala at comtencentangelsonamlclassificationAngelClassifieranonfuntrain anonfunapplymcVIsp anonfun applyAngelClassifierscala at scalacollectionIteratoranon nextIteratorscala at scalacollectionIteratorclassforeachIteratorscala at scalacollectionAbstractIteratorforeachIteratorscala at scalacollectionTraversableOnceclassreduceLeftTraversableOncescala at scalacollectionAbstractIteratorreduceLeftIteratorscala at orgapachesparkrddRDDanonfunreduce anonfun applyRDDscala at orgapachesparkrddRDDanonfunreduce anonfun applyRDDscala at orgapachesparkSparkContextanonfun applySparkContextscala at orgapachesparkSparkContextanonfun applySparkContextscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava deepfmjson data format libsvm indexrange numfield validateratio sampleratio model modeltype TDOUBLESPARSELONGKEY modelsize train epoch numupdateperepoch lr decayclass StandardDecay decayalpha defaultoptimizer Momentum layers name wide type simpleinputlayer outputdim transfunc identity name embedding type embedding numfactors outputdim optimizer type momentum momentum reg name fclayer type FCLayer outputdims transfuncs relu relu identity inputlayer embedding name biinnersumcross type BiInnerSumCross inputlayer embedding outputdim name sumPooling type SumPooling outputdim inputlayers wide biinnersumcross fclayer name simplelosslayer type simplelosslayer lossfunc logloss inputlayer sumPooling train data eg how to define java when submit application use sparksubmit name Bug reportFeature requestQuestion about Create a report to help us improve title label bugenhancementquestion assignees Environment Java version Scala version Spark version PyTorch and Python version OS and version Checklist Did you check if your bugfeaturequestion is answered in the FQA Did you search issues to find if somebody discuss your bugfeaturequestion before If your bugquestion is about install did you read this doc docsdeploysourcecompileenmd If your bugquestion is about parameter setting did you read this doc docsdeployconfigdetailsenmd Your BugFeature requestQuestion Please describe bugenhancementquestion in detail For bugs please post the submit commands error report logs and related code snippet For feature requests please describe whats you scenario and why you need this feature if you required feature is big please connect us email list Angel DeepFM demo INFO main comtencentangelworkerWorker angelclusterlocaldir for child data yarnlocalusercachedeepthoughtappcacheapplication data yarnlocalusercachedeepthoughtappcacheapplication data yarnlocalusercachedeepthoughtappcacheapplication data yarnlocalusercachedeepthoughtappcacheapplication data yarnlocalusercachedeepthoughtappcacheapplication data yarnlocalusercachedeepthoughtappcacheapplication data yarnlocalusercachedeepthoughtappcacheapplication data yarnlocalusercachedeepthoughtappcacheapplication INFO main comtencentangelworkerWorker actual workergroup number INFO main comtencentangelworkerWorker actual task number INFO main comtencentangelworkerWorker Init and start worker INFO main comtencentangelworkerWorker Init and start psagent for worker INFO main comtencentangelpsagentPSAgent PSAgent get matrices from master INFO main comtencentangelpsagentmatrixtransportMatrixTransportClient Use nio channel INFO main comtencentangelpsagentmatrixtransportMatrixTransportClient ByteOrdernativeOrderLITTLEENDIAN INFO main comtencentangelworkerWorker Init data block manager INFO main comtencentangelworkerWorker Init and start worker rpc server WARN main ionettybootstrapServerBootstrap Unknown channel option TCPNODELAY for channel id xd fcd WARN main ionettybootstrapServerBootstrap Unknown channel option SOKEEPALIVE for channel id xd fcd INFO main comtencentangelworkerWorkerService Starting workerserver service at INFO main comtencentangelworkerWorker Init counter updater INFO main comtencentangelpsagentCounterUpdater Using ResourceCalculatorProcessTree INFO main comtencentangelworkerWorker Register to master and start the heartbeat thread INFO main comtencentangelworkerWorker Get data splits from master INFO Worker Heartbeat comtencentangelworkerWorker Register to master INFO Worker Heartbeat comtencentangelworkerWorker worker register finished INFO main comtencentangelworkerWorker Init and start task manager and all task INFO main comtencentangelworkertaskTaskManager start all tasks INFO main comtencentangelworkertaskTaskManager start task task with contextTaskContext taskIdtask taskIdPrototaskIndex contextcomtencentangelpsagenttaskTaskContext adb db TaskContext index matrix clocks INFO pool thread comtencentangelworkertaskTask task task is running INFO pool thread comtencentangelworkertaskTask userTaskClass class comtencentangelmlcoregraphsubmitGraphTrainTask task index name Thread WARN pool thread orgapachehadooputilNativeCodeLoader Unable to load nativehadoop library for your platform using builtinjava classes where applicable WARN pool thread orgapachehadoophdfsshortcircuitDomainSocketFactory The shortcircuit local reads feature cannot be used because libhadoop cannot be loaded WARN pool thread orgapachehadoopsecurityUserGroupInformation PriviledgedActionException asdeepthought authKERBEROS causeorgapachehadoopipcRemoteExceptionorgapachehadoopipcStandbyException Operation category READ is not supported in state standby Visit WARN pool thread orgapachehadoopipcClient Exception encountered while connecting to the server orgapachehadoopipcRemoteExceptionorgapachehadoopipcStandbyException Operation category READ is not supported in state standby Visit WARN pool thread orgapachehadoopsecurityUserGroupInformation PriviledgedActionException asdeepthought authKERBEROS causeorgapachehadoopipcRemoteExceptionorgapachehadoopipcStandbyException Operation category READ is not supported in state standby Visit INFO pool thread comhadoopcompressionlzoGPLNativeCodeLoader Loaded native gpl library INFO pool thread comhadoopcompressionlzoLzoCodec Successfully loaded initialized nativelzo library hadooplzo rev null INFO pool thread comtencentangelmlcoregraphsubmitGraphTrainTask Task preprocessed samples for train for validation processing time is INFO pool thread comtencentangelmlcoregraphsubmitGraphLearner Task Starting to train INFO pool thread comtencentangelmlcoregraphsubmitGraphLearner Task epoch initLearnRate INFO pool thread comtencentangelmlcoregraphsubmitGraphLearner Task epoch start WARN pool thread comtencentangelmlmath MatrixExecutors angelmathmatrixopparallelworkernum is not set just use default worker number ERROR pool thread comtencentangelworkertaskTask task runner error javalangError javalangError at sunreflectNativeConstructorAccessorImplnewInstance Native Method at sunreflectNativeConstructorAccessorImplnewInstanceNativeConstructorAccessorImpljava at sunreflectDelegatingConstructorAccessorImplnewInstanceDelegatingConstructorAccessorImpljava at javalangreflectConstructornewInstanceConstructorjava at javautilconcurrentForkJoinTaskgetThrowableExceptionForkJoinTaskjava at javautilconcurrentForkJoinTaskreportExceptionForkJoinTaskjava at javautilconcurrentForkJoinTaskjoinForkJoinTaskjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorapplyParallelDotMatrixExecutorjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorapplyDotMatrixExecutorjava at comtencentangelmlmath ufuncsUfuncsdotUfuncsjava at comtencentangelmlcorenetworklayersunaryFCLayerdoForwardFCLayerscala at comtencentangelmlcorenetworklayersLinearLayerforwardLinearLayerscala at comtencentangelmlcorenetworklayersLinearLayerforwardLinearLayerscala at comtencentangelmlcorenetworklayersLinearLayerforwardLinearLayerscala at comtencentangelmlcorenetworklayersJoinLayeranonfun applyJoinLayerscala at comtencentangelmlcorenetworklayersJoinLayeranonfun applyJoinLayerscala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionIndexedSeqOptimizedclassforeachIndexedSeqOptimizedscala at scalacollectionmutableArrayOpsofRefforeachArrayOpsscala at scalacollectionTraversableLikeclassmapTraversableLikescala at scalacollectionmutableArrayOpsofRefmapArrayOpsscala at comtencentangelmlcorenetworklayersJoinLayerforwardJoinLayerscala at comtencentangelmlcorenetworklayersLossLayerforwardLossLayerscala at comtencentangelmlcorenetworklayersLossLayercalLossLossLayerscala at comtencentangelmlcorenetworkGraphcalForwardGraphscala at comtencentangelmlcoregraphsubmitGraphLearnertrainOneEpochGraphLearnerscala at comtencentangelmlcoregraphsubmitGraphLearnertrainGraphLearnerscala at comtencentangelmlcoregraphsubmitGraphLearnertrainGraphLearnerscala at comtencentangelmlcoregraphsubmitGraphTrainTasktrainGraphTrainTaskscala at comtencentangelmlcoreTrainTaskrunTrainTaskscala at comtencentangelworkertaskTaskrunUserTaskjava at comtencentangelworkertaskTaskrunTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangError at orgjpaineformatterFormatParserinitFormatParserjava at orgjpaineformatterFormatParserinitFormatParserjava at orgjpaineformatterParsersinitFormatterjava at orgjpaineformatterParserstheParsersFormatterjava at orgjpaineformatterFormatinitFormatterjava at orgjpaineformatterFormatterinitFormatterjava at orgnetlibutilUtilf writeUtiljava at orgnetliberrXerblaxerblaerrf at orgnetlibblasDgemmdgemmblasf at comgithubfommilnetlibF jBLASdgemmF jBLASjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorapplyDotMatrixExecutorjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutoraccess DotMatrixExecutorjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorDotForkJoinOpcomputeDotMatrixExecutorjava at javautilconcurrentRecursiveActionexecRecursiveActionjava at javautilconcurrentForkJoinTaskdoExecForkJoinTaskjava at javautilconcurrentForkJoinTaskdoInvokeForkJoinTaskjava at javautilconcurrentForkJoinTaskinvokeAllForkJoinTaskjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorDotForkJoinOpcomputeDotMatrixExecutorjava at javautilconcurrentRecursiveActionexecRecursiveActionjava at javautilconcurrentForkJoinTaskdoExecForkJoinTaskjava at javautilconcurrentForkJoinTaskdoInvokeForkJoinTaskjava at javautilconcurrentForkJoinTaskinvokeAllForkJoinTaskjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorDotForkJoinOpcomputeDotMatrixExecutorjava at javautilconcurrentRecursiveActionexecRecursiveActionjava at javautilconcurrentForkJoinTaskdoExecForkJoinTaskjava at javautilconcurrentForkJoinPoolWorkQueuerunTaskForkJoinPooljava at javautilconcurrentForkJoinPoolrunWorkerForkJoinPooljava at javautilconcurrentForkJoinWorkerThreadrunForkJoinWorkerThreadjava INFO pool thread comtencentangelworkerWorker worker failed message taskidtask stateFAILED diagnostics task runner error javalangError javalangError at sunreflectNativeConstructorAccessorImplnewInstance Native Method at sunreflectNativeConstructorAccessorImplnewInstanceNativeConstructorAccessorImpljava at sunreflectDelegatingConstructorAccessorImplnewInstanceDelegatingConstructorAccessorImpljava at javalangreflectConstructornewInstanceConstructorjava at javautilconcurrentForkJoinTaskgetThrowableExceptionForkJoinTaskjava at javautilconcurrentForkJoinTaskreportExceptionForkJoinTaskjava at javautilconcurrentForkJoinTaskjoinForkJoinTaskjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorapplyParallelDotMatrixExecutorjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorapplyDotMatrixExecutorjava at comtencentangelmlmath ufuncsUfuncsdotUfuncsjava at comtencentangelmlcorenetworklayersunaryFCLayerdoForwardFCLayerscala at comtencentangelmlcorenetworklayersLinearLayerforwardLinearLayerscala at comtencentangelmlcorenetworklayersLinearLayerforwardLinearLayerscala at comtencentangelmlcorenetworklayersLinearLayerforwardLinearLayerscala at comtencentangelmlcorenetworklayersJoinLayeranonfun applyJoinLayerscala at comtencentangelmlcorenetworklayersJoinLayeranonfun applyJoinLayerscala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionIndexedSeqOptimizedclassforeachIndexedSeqOptimizedscala at scalacollectionmutableArrayOpsofRefforeachArrayOpsscala at scalacollectionTraversableLikeclassmapTraversableLikescala at scalacollectionmutableArrayOpsofRefmapArrayOpsscala at comtencentangelmlcorenetworklayersJoinLayerforwardJoinLayerscala at comtencentangelmlcorenetworklayersLossLayerforwardLossLayerscala at comtencentangelmlcorenetworklayersLossLayercalLossLossLayerscala at comtencentangelmlcorenetworkGraphcalForwardGraphscala at comtencentangelmlcoregraphsubmitGraphLearnertrainOneEpochGraphLearnerscala at comtencentangelmlcoregraphsubmitGraphLearnertrainGraphLearnerscala at comtencentangelmlcoregraphsubmitGraphLearnertrainGraphLearnerscala at comtencentangelmlcoregraphsubmitGraphTrainTasktrainGraphTrainTaskscala at comtencentangelmlcoreTrainTaskrunTrainTaskscala at comtencentangelworkertaskTaskrunUserTaskjava at comtencentangelworkertaskTaskrunTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangError at orgjpaineformatterFormatParserinitFormatParserjava at orgjpaineformatterFormatParserinitFormatParserjava at orgjpaineformatterParsersinitFormatterjava at orgjpaineformatterParserstheParsersFormatterjava at orgjpaineformatterFormatinitFormatterjava at orgjpaineformatterFormatterinitFormatterjava at orgnetlibutilUtilf writeUtiljava at orgnetliberrXerblaxerblaerrf at orgnetlibblasDgemmdgemmblasf at comgithubfommilnetlibF jBLASdgemmF jBLASjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorapplyDotMatrixExecutorjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutoraccess DotMatrixExecutorjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorDotForkJoinOpcomputeDotMatrixExecutorjava at javautilconcurrentRecursiveActionexecRecursiveActionjava at javautilconcurrentForkJoinTaskdoExecForkJoinTaskjava at javautilconcurrentForkJoinTaskdoInvokeForkJoinTaskjava at javautilconcurrentForkJoinTaskinvokeAllForkJoinTaskjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorDotForkJoinOpcomputeDotMatrixExecutorjava at javautilconcurrentRecursiveActionexecRecursiveActionjava at javautilconcurrentForkJoinTaskdoExecForkJoinTaskjava at javautilconcurrentForkJoinTaskdoInvokeForkJoinTaskjava at javautilconcurrentForkJoinTaskinvokeAllForkJoinTaskjava at comtencentangelmlmath ufuncsexecutormatrixDotMatrixExecutorDotForkJoinOpcomputeDotMatrixExecutorjava at javautilconcurrentRecursiveActionexecRecursiveActionjava at javautilconcurrentForkJoinTaskdoExecForkJoinTaskjava at javautilconcurrentForkJoinPoolWorkQueuerunTaskForkJoinPooljava at javautilconcurrentForkJoinPoolrunWorkerForkJoinPooljava at javautilconcurrentForkJoinWorkerThreadrunForkJoinWorkerThreadjava send it to appmaster success INFO pool thread comtencentangelworkerWorker start to close all modules in worker INFO pool thread comtencentangelworkerWorker stop workerService INFO pool thread comtencentangelworkerWorkerService stop rpc server INFO pool thread comtencentangelipcNettyServer Stopping server on INFO pool thread comtencentangelworkerWorker stop psagent INFO pool thread comtencentangelpsagentPSAgent stop heartbeat thread INFO pool thread comtencentangelpsagentPSAgent stop op log merger WARN oplogmergedispatcher comtencentangelpsagentmatrixoplogcacheMatrixOpLogCache oplogmergedispatcher interrupted INFO pool thread comtencentangelpsagentPSAgent stop clock cache INFO pool thread comtencentangelpsagentPSAgent stop matrix cache INFO clocksyncer comtencentangelpsagentclockClockCache sync thread is interrupted INFO pool thread comtencentangelpsagentPSAgent stop user request adapater INFO pool thread comtencentangelpsagentPSAgent stop rpc dispacher INFO pool thread comtencentangelcommontransportChannelManager Channel manager stop INFO pool thread comtencentangelworkerWorker stop heartbeat thread INFO pool thread comtencentangelworkerWorker stop taskmanager INFO pool thread comtencentangelworkerWorker stop data block manager json data format dummy indexrange numfield useshuffle true validateratio model modeltype TDOUBLESPARSELONGKEY modelsize train epoch numupdateperepoch lr decayclass ConstantLearningRate defaultoptimizer Momentum layers name wide type simpleinputlayer outputdim transfunc identity name embedding type embedding numfactors outputdim optimizer type momentum momentum reg name fclayer type FCLayer outputdims transfuncs relu relu identity inputlayer embedding name biinnersumcross type BiInnerSumCross inputlayer embedding outputdim name sumPooling type SumPooling outputdim inputlayers wide biinnersumcross fclayer name simplelosslayer type simplelosslayer lossfunc logloss inputlayer sumPooling It is Move the scala code into scala fold under the psf sub module Angel training data w cols w lines G sh dataangelangel binangelsubmit DangelappsubmitclasscomtencentangelmlGBDTGBDTRunner Dangeltraindatapathviewfshadoopbduserdeepthoughttempdeepthoughttest datapart DangellogpathviewfshadoopbduserdeepthoughttestmodelmPSgbdt log DangelsavemodelpathviewfshadoopbduserdeepthoughttestmodelmPSgbdt model Dactiontypetrain Dmldatatypedummy Dmlfeatureindexrange DmlmodeltypeTFLOATDENSE Dmllearnrate Dmlgbdttasktypeclassification Dmlgbdtclassnum Dmlgbdttreenum Dmlgbdttreedepth Dmlgbdtsplitnum Dmlgbdtsampleratio Dmlgbdtminchildweight Dmlgbdtregalpha Dmlgbdtreglambda Dmlgbdtbatchsize Dmlgbdtserversplittrue Dmlgbdtcatefeatnone Dmldatavalidateratio DmldatalabeltransclassPosNegTrans Dmldatalabeltransthreshold Dmldataposnegratio Dangelcompressbytes DangeljobnamePSgbdt Dangelworkergroupnumber Dangelworkermemorygb Dangelworkercpuvcores Dangelworkertasknumber Dangelpsnumber Dangelpsmemorygb Dangelpscpuvcores Dangeltaskdatastoragelevelmemory Dangelamcpuvcores Dangelammemorygb Dangeloutputpathdeleteonexisttrue yarn syslog sysloglog stdoutlog 