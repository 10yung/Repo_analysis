I am training the pythia vqa model on multiple datasets Say I have datasets for the vqa task say vqa and some new vqax I noticed that while training a dataset is chosen at random based on its length at the beginning and the model is trained with just that dataset and never on the other dataset Is this the expected behaviour See the changedataset function is called at the time of initialization and never later preventing the dataset that is not chosen at first from being used Could you please let me know if I am missing something Merge the M C model for TextVQA into Pythia Summary of changes Adding READMEmd under projectsM C Adding new models M C under pythiamodelsm cpy Adding new dataset classes m ctextvqa m cstvqa and m cocrvqa under pythiadatasetsvqa Adding new config files under configsvqa Adding new processors metrics and losses for M C training and evaluation Adding other utilities such as PHOC feature extraction Introducing new dependencies added to requirementstxt pytorchtransformers editdistance M C for the TextVQA Task R Hu A Singh T Darrell M Rohrbach Iterative Answer Prediction with PointerAugmented Multimodal Transformers for TextVQA arXiv preprint arXiv PDF articlehu iterative titleIterative Answer Prediction with PointerAugmented Multimodal Transformers for TextVQA authorHu Ronghang and Singh Amanpreet and Darrell Trevor and Rohrbach Marcus journalarXiv preprint arXiv year Vocabs ImDBs and Features Datasets M C Vocabs M C ImDBs Object Faster RCNN Features OCR Faster RCNN Features TextVQA All Vocabs TextVQA ImDB OpenImages TextVQA Rosettaen OCRs TextVQA Rosettaml OCRs STVQA All Vocabs STVQA ImDB STVQA Objects STVQA Rosettaen OCRs OCRVQA All Vocabs OCRVQA ImDB OCRVQA Objects OCRVQA Rosettaen OCRs Pretrained models Datasets Configs under configsvqa Pretrained Models Metrics Notes TextVQA m ctextvqa m ctextvqam cwithstvqayml download val accuracy test accuracy Rosettaen OCRs STVQA as additional data TextVQA m ctextvqa m ctextvqam cyml download val accuracy test accuracy Rosettaen OCRs TextVQA m ctextvqa m ctextvqam cocrmlyml download val accuracy Rosettaml OCRs STVQA m cstvqa m cstvqam cyml download val ANLS accuracy test ANLS Rosettaen OCRs OCRVQA m cocrvqa m cocrvqam cyml download val accuracy test accuracy Rosettaen OCRs Questions and Help I have RTX s on my ubuntu machine and Im running the pythia vqa demo on images Right now it takes around seconds for it to process image its running on gpu Is there a way to accelerate the running time or even run it on multiple gpus simultaneously Edit Here is the nvidiasmi output when running pythia GeForce RTX Off Off NA C P W W MiB MiB Default GeForce RTX Off A Off NA C P W W MiB MiB Default GeForce RTX Off Off NA C P W W MiB MiB Default Bug Without the evalaiinference argument AttributeError dict object has no attribute datasettype This error occurs You can run the script with python toolsrunpy tasks vqa datasets vqa model pythia config configsvqavqa pythiatrainandvalyml resumefile datamodelspythiatrainvalpth runtype val Additional context It seems that in the batch it should refer datasettype as a dictionary key not an attribute Either in pythiacommontaskloaderpy the preparebatch function should change to batchdatasettype to batch datasettype or add datasettype as an attribute to the dictionary Feature Based on we definitely need to move to Detectron as soon as possible for feature extraction This would also allow faster e e training Motivation Detectron is going to maintained in future rather than maskrcnnbenchmark and detectron and thus we need to move to it We need to implement similar features in our fork of detectron like we did for vqamaskrcnnbenchmark Pitch Look into the changes that were made to original maskrcnnbenchmark to create vqamaskrcnnbenchmark See the diff Fork detectron First read the breaking changes in detectron compared to detectronmaskrcnnbenchmark at this link Make changes according to the diff above to your fork and try training a model Questions and Help Hi while trying to reproduce LoRRA model on Text VQA my computer freezes indefinitely while loading fasttext model from vectorcachewikienbin I have GB of RAM and I followed the instructions on the README homepage of Pythia Running the following command python toolsrunpy tasks vqa datasets textvqa model lorra config configsvqatextvqalorrayml runtype inference evalaiinference resumefile datamodelslorrabestpth any suggestions if i can make it work on my computer or is GB memory insufficient to run LoRRA Questions and Help Hi I have a custom dataset of annotated images So far I have managed to generate the detectron features for the images the vocabulary for the captions and set up the config files correctly When I try to train on using a butd model I encounter an error AttributeError Key answers not found in the SampleList Valid choices are text captionlen imageid imagefeature datasettype datasetname which I think is because my dataset only contains captions and there are no questionanswer segments associated with it My question is that can Pythia be setup for an image captioning image retrieval task What would be the steps required to train it on this custom dataset Thanks Questions and Help I tried to reproduce the validation result of LoRRA on TextVQA After finishing training I evaluated the LoRRA model offline by setting the batchsize and using the command python toolsrunpy tasks vqa datasets textvqa model lorra config configsvqatextvqalorrayml runtype val resumefile lorrabestpth and I got a result of When I generated the json file by using the command python toolsrunpy tasks vqa datasets textvqa model lorra config configsvqatextvqalorrayml runtype val evalaiinference resumefile lorrabestpth and evaluated it via EvalAI I got a result of Could you please explain the difference Questions and Help Hello ask a question What is the role of textprocessor and answerprocessor in vqa yml and the corresponding vocabfile vocabsvocabulary ktxt and vocabfile vocabsanswersvqatxt What is the use Questions and Help I met an error when training after the max iterations T INFO textvqa full val valtotalloss vallogitbce valvqaaccuracy validation time m s ms best iteration best valvqaaccuracy T INFO Restoring checkpoint T ERROR CUDA out of memory Tried to allocate MiB GPU GiB total capacity GiB already allocated MiB free MiB cached Traceback most recent call last File toolsrunpy line in module run File toolsrunpy line in run trainertrain File homeBgcycodepythiamasterpythiatrainersbasetrainerpy line in train selffinalize File homeBgcycodepythiamasterpythiatrainersbasetrainerpy line in finalize selfcheckpointrestore File homeBgcycodepythiamasterpythiautilscheckpointpy line in restore selftraineroptimizerloadstatedictckpt optimizer File homegcyanaconda envsyelibpython sitepackagestorchoptimoptimizerpy line in loadstatedict statedict deepcopystatedict File homegcyanaconda envsyelibpython copypy line in deepcopy y copierx memo File homegcyanaconda envsyelibpython copypy line in deepcopydict y deepcopykey memo deepcopyvalue memo File homegcyanaconda envsyelibpython copypy line in deepcopy y copierx memo File homegcyanaconda envsyelibpython copypy line in deepcopydict y deepcopykey memo deepcopyvalue memo File homegcyanaconda envsyelibpython copypy line in deepcopy y copierx memo File homegcyanaconda envsyelibpython copypy line in deepcopydict y deepcopykey memo deepcopyvalue memo File homegcyanaconda envsyelibpython copypy line in deepcopy y copiermemo File homegcyanaconda envsyelibpython sitepackagestorchtensorpy line in deepcopy newstorage selfstoragedeepcopymemo File homegcyanaconda envsyelibpython sitepackagestorchstoragepy line in deepcopy newstorage selfclone File homegcyanaconda envsyelibpython sitepackagestorchstoragepy line in clone return typeselfselfsizecopyself RuntimeError CUDA out of memory Tried to allocate MiB GPU GiB total capacity GiB already allocated MiB free MiB cached How can I do with this error without setting my batchsize smaller