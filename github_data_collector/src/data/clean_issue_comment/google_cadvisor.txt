I am trying to run cadvisor globally on every node in my swarm To visualize data properly in Prometheus I need a hostname to be along with metrics Stack config services cadvisor image googlecadvisor command logtostderr dockeronly hostname NodeHostname volumes varrundockersockvarrundockersockro rootfsro varrunvarrun syssysro varlibdockervarlibdockerro ports networks prometheusnet deploy mode global resources limits memory M reservations memory M prometheus In this stack theres a Prometheus instance running that uses service discovery to get all nodes where cadvisor is running and get all metrics from them jobname cadvisor dnssdconfigs names taskscadvisor type A port Later on if we inspect cadvisorversioninfo metrics that should contain hostname we can see that there are no labels with hostname formatted a bit so not to be in one line cadvisorversioninfo cadvisorRevision c cadvisorVersionv dockerVersion instance jobcadvisor kernelVersion el x osVersionAlpine Linux v No matter what I do I still cannot get a proper hostname to be somewhere within any metric collected from cadvisor Please help I havent found any documentation how to make it properly Thank you TCP retransmits might indicate a network issue see the discussion on this issue prometheusnodeexporter but currently it only reported by nodeexporter on node level Is it possible for cadvisor to collect it also so we can have those metrics per container As a newcomer it is very much essential to bootstrap the local setup as quickly as possible If someone is inexperienced and encounter some errors it consumes a lot of time and makes them hesitant to further continue to explore the project I am proposing to create make commands in already present makefile to onboard developers much more quickly with necessary checks for version and dependencies in place I use overlay xfs as storage driver for docker it work ok but cannot get fs stats per container rootxxg merged cat etcdockerdaemonjson registrymirrors dataroot varlibdocker storagedriver overlay storageopts overlay size G logopts maxfile maxsize m df h look work ok tmpfs G K G varlibkubeletpods db fd f eaac c bf dvolumeskubernetesiosecretdefaulttokengj mr overlay G K G varlibdockeroverlay c b c bc a fcab c a f daa b b cf b d c merged shm M M varlibdockercontainersd fb b ef ca ccd e f af fc b faa cbe c d mountsshm overlay G K G but cannot get containerfslimitbytes per container which set overlay size G it only the entire disk containerfslimitbytescontainertestnew sitwildfly containernametestnew sitwildfly devicedevmapperdockerthinpoolidkubepodsburstablepoda d f ea d c bf a cea b b e d e a aff dc f fdd b d c a cimagesha ec c eccac b eb f ba de adc fe af dfanamek stestnew sitwildfly testnew sitwildfly d blz s testnew a d f ea d c bf a namespacetestnew podtestnew sitwildfly d blz s podnametestnew sitwildfly d blz s e When I start cAdvisor v in docker the startup fails and the log prompts managergo Registration of the raw container factory failed inotifyinit too many open files cadvisorgo Failed to start container manager inotifyinit too many open files But openfiles has been configured to and it still fails to start until I adjust the openfiles to million I dont know how many openfiles it needs or does it mistakenly think that the file handle is abnormal or I need adjust the other system parameter Thanks for answer Actually we are trying to test the cadvisor based disk io metrics collection via prometheus for different file system esp on block and nfs We creating statefulset of sample application to collect those metrics We tested by deploying the statefulset application using block storage and it works fine means we could able collect the disk io related metrics By checking the cadvisor metrics code we found that the supported file system of cadvisor to collect is btrfs overlay tmpfs xfs zfs So when we create a statefulset based on NFS storage we will not be able to see any disk io related metrics via cadvisor Is this correct If yes how do we collect the container based disk io metrics in which the container is using a NFS storage as a backend Please clarify Is all the network related metrics are reported per POD interface or on the host interface How cadvisor collects the container network related metrics Is there any correlation between metrics named containernetworkreceivetransmitpacketsdroppedtotal and containernetworkreceivetransmiterrorstotal for ease I made receivetransmit together Because in our lab we observed there are packet drops for few kubesystem pods whereas there is no errors reported and the respective error related metrics is always Attached the graphs for reference graph receivepacketsdropped graph receiveerrors Ideally when there is a packet drop it means there could be a transmission format errors and so theoretically speaking both the metric should be populated right It would be great if the above metrics could be described in more detail Again the metric type for network and disk io related metrics are of Counter In general is it because GAUGE is only for values that have all the points until process lives ex memory Is this understanding correct A simple patch to allow the reading of a db password from a file as opposed to having to type the password on the command line when starting cadvisor This can be useful with eg docker secrets where you can specify storagedriverpasswordfilerunsecretscadvisorinfluxdbpassword InfluxDB looks to be the only storage engine with authentication so its only valid for that at the moment but would be trivial to extend to other storage engines if they gain authentication functionality eg This should address Tested with Docker against InfluxDB graph m Did a small study to report the CPU usage in terms of MHZ To get the POD s cpu usage sum of the CPU usage of each container belonging to the pod the below query is used that will give the number of cores that are being used by each pod sum by podname rate containercpuusagesecondstotalnamespacedefault namecpustress m Attached the sample graph for reference CPU simulation is done by deploying a sample deployment that uses stress tool to stress the CPU As in the above query the final output per pod will be in terms of cores To convert the cores into MHZ there is no out of the box solution from Prometheus through cAdvisor even with queries as I understood As per the study there would be a manual intervention required to convert the cores into MHZ because the meaning of CPU differs in various platform Challenge here is to understand whether one CPU in Kubernetes is one physical core or one Hyperthread and what is the corresponding clock speed It varies based on the infrastructure that is being used to run Kubernetes One CPU in Kubernetes is equivalent to AWS vCPU Each vCPU is a thread of a CPU core except for T instances For T instances vCPU physical core For all others vCPU logical core Reference GCP Core A vCPU is implemented as a single hardware Hyperthread on one of the available CPU platforms Reference Azure vCore vCore hyperthread except for Gen hardware generation Reference Hyperthread on a baremetal Intel processor with Hyperthreading Let us take the baremetal case as an example Hyperthread enabled CPU sockets with cores each physical cores yielding Hyperthreads Clockspeed of each core GHZ or MHZ So the clockspeed of single hyperthread would be MHZ threads MHZ If in case POD has used m core then the it can be converted as below to show in MHZ MHZ MHZ Any other solution in my scenario please Also I feel that this could be facilitated by cadvisor itself to have a metrics for CPU in MHZ Do you agree Lets take we want to measure CPU usage in containers cadvisor provides a metric named containercpuusagesecondstotal which is of a metric type Counter As the counter is an accumulator we need to apply a function over it to see the type of values we need I saw in most of the articles rate function is applied As we know the rate function calculates the persecond average rate of increase of the time series in the range vector Actually the output of rate function query gives us a value that is an average value measure over the period of time Example rate containercpuusagesecondstotalnamespacedefault m gives the average CPU usage in the last mins That means for each instant t in the provided instant vector the rate function uses the values from t m to t to calculate its average value So for example the value at describes the average number of containercpuusagesecondstotal per second that were used between and the value at describes the average number of containercpuusagesecondstotal per second that were created between and and so on Considering such values to identify the peak CPU usage at instant as it is an average we might miss the peak spot The question here is Is it not possible to measure the absolute value of containercpuusagesecondstotal Ex What is the absolute current CPU usage at this instance of time Like memory metric defined as Gauge containermemoryusagebytes why containercpuusagesecondstotal could not be gauge metric type In this case we would get the absolute current value of CPU usage Isnt Correct my understanding if I am wrong In general to dimension an application is it suggested to take the output of rate function