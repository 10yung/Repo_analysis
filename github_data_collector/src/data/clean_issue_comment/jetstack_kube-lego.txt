Reenables the e e test now that Lets Encrypt Staging is working Changes user email domain now that Lets Encrypt no longer allows users with the domain examplecom current version of kubernetes on CGP refuses to create or configure a loadbalancer without a secret because of that wellknow route is not created if you create a loadbalancer without ssl and try to set it after if you try to create a ingress with ssl from the beginning gce will not create the loadbalancer no loadbalancer no ip not reachable managed to create a cert using by configuring the GCE loadbalancer manually using a previous created one by kubelego with old version of kubernetes The kubelego container tends to climb in memory usage Definitely has the appearance of a memory leak Ive had to kill the deployed pod and let it get rescheduled because it has repeatedly gotten itself over GB Im running v Reverts jetstackkubelego It seems kube lego cant get the certificates here whats in the log levelerror msgworker error processing item requeuing after rate limit Get dial tcp lookup acmev apiletsencryptorg on read udp gt io timeout contextkubelego Does anyone have an idea what could be misconfigured here All my pods are running correctly I see problem Warning BackOff m x over h kubelet server Backoff restarting failed container kubectl describe pods n kubelego Name kubelego f bc c dk v Namespace kubelego Node server Start Time Sat May Labels appkubelego podtemplatehash Annotations none Status Running IP Controlled By ReplicaSetkubelego f bc c Containers kubelego Container ID docker c f efc dc f d db d a ea e d b b ae faee a Image jetstackkubelego Image ID dockerpullablejetstackkubelegosha ffcc c f d c f a fa ffd c f ab ff bdf Port TCP Host Port TCP State Waiting Reason CrashLoopBackOff Last State Terminated Reason Error Exit Code Started Sun May Finished Sun May Ready False Restart Count Readiness httpget delay s timeout s period s success failure Environment LEGOEMAIL set to the key legoemail of config map kubelego Optional false LEGOURL set to the key legourl of config map kubelego Optional false LEGONAMESPACE kubelego v metadatanamespace LEGOPODIP v statuspodIP Mounts varrunsecretskubernetesioserviceaccount from defaulttokenv wsw ro Conditions Type Status Initialized True Ready False PodScheduled True Volumes defaulttokenv wsw Type Secret a volume populated by a Secret SecretName defaulttokenv wsw Optional false QoS Class BestEffort NodeSelectors none Tolerations nodekubernetesionotreadyNoExecute for s nodekubernetesiounreachableNoExecute for s Events Type Reason Age From Message Normal Started h x over h kubelet server Started container Normal Pulling h x over h kubelet server pulling image jetstackkubelego Warning BackOff m x over h kubelet server Backoff restarting failed container Normal SuccessfulMountVolume m kubelet server MountVolumeSetUp succeeded for volume defaulttokenv wsw Warning FailedCreatePodSandBox m kubelet server Failed create pod sandbox rpc error code Unknown desc NetworkPlugin cni failed to set up pod kubelego f bc c dk vkubelego network open runflannelsubnetenv no such file or directory Normal SandboxChanged m x over m kubelet server Pod sandbox changed it will be killed and recreated Warning Unhealthy m kubelet server Readiness probe failed Get dial tcp getsockopt connection refused Normal Pulled m x over m kubelet server Successfully pulled image jetstackkubelego Normal Created m x over m kubelet server Created container Normal Started m x over m kubelet server Started container Normal Pulling m x over m kubelet server pulling image jetstackkubelego Warning BackOff m x over m kubelet server Backoff restarting failed container Normal SuccessfulMountVolume m kubelet server MountVolumeSetUp succeeded for volume defaulttokenv wsw Warning FailedCreatePodSandBox m kubelet server Failed create pod sandbox rpc error code Unknown desc NetworkPlugin cni failed to set up pod kubelego f bc c dk vkubelego network open runflannelsubnetenv no such file or directory Normal SandboxChanged m x over m kubelet server Pod sandbox changed it will be killed and recreated Warning Failed m kubelet server Failed to pull image jetstackkubelego rpc error code Unknown desc Error response from daemon Get nethttp request canceled while waiting for connection ClientTimeout exceeded while awaiting headers Warning Failed m kubelet server Error ErrImagePull Normal BackOff m kubelet server Backoff pulling image jetstackkubelego Warning Failed m kubelet server Error ImagePullBackOff Normal Pulling m x over m kubelet server pulling image jetstackkubelego Normal Pulled m x over m kubelet server Successfully pulled image jetstackkubelego Normal Created m x over m kubelet server Created container Normal Started m x over m kubelet server Started container Warning BackOff m x over m kubelet server Backoff restarting failed container kubectl get pods kubelego f bc c dk v n kubelego o yaml apiVersion v kind Pod metadata creationTimestamp T Z generateName kubelego f bc c labels app kubelego podtemplatehash name kubelego f bc c dk v namespace kubelego ownerReferences apiVersion extensionsv beta blockOwnerDeletion true controller true kind ReplicaSet name kubelego f bc c uid e a ec f e ccc a fcc resourceVersion selfLink apiv namespaceskubelegopodskubelego f bc c dk v uid e c e f e ccc a fcc spec containers env name LEGOEMAIL valueFrom configMapKeyRef key legoemail name kubelego name LEGOURL valueFrom configMapKeyRef key legourl name kubelego name LEGONAMESPACE valueFrom fieldRef apiVersion v fieldPath metadatanamespace name LEGOPODIP valueFrom fieldRef apiVersion v fieldPath statuspodIP image jetstackkubelego imagePullPolicy Always name kubelego ports containerPort protocol TCP readinessProbe failureThreshold httpGet path healthz port scheme HTTP initialDelaySeconds periodSeconds successThreshold timeoutSeconds resources terminationMessagePath devterminationlog terminationMessagePolicy File volumeMounts mountPath varrunsecretskubernetesioserviceaccount name defaulttokenv wsw readOnly true dnsPolicy ClusterFirst nodeName server restartPolicy Always schedulerName defaultscheduler securityContext serviceAccount default serviceAccountName default terminationGracePeriodSeconds tolerations effect NoExecute key nodekubernetesionotready operator Exists tolerationSeconds effect NoExecute key nodekubernetesiounreachable operator Exists tolerationSeconds volumes name defaulttokenv wsw secret defaultMode secretName defaulttokenv wsw status conditions lastProbeTime null lastTransitionTime T Z status True type Initialized lastProbeTime null lastTransitionTime T Z message containers with unready status kubelego reason ContainersNotReady status False type Ready lastProbeTime null lastTransitionTime T Z status True type PodScheduled containerStatuses containerID dockerdba b e bad db d f ad e fff bcdf e e ff dc image jetstackkubelego imageID dockerpullablejetstackkubelegosha ffcc c f d c f a fa ffd c f ab ff bdf lastState terminated containerID dockerdba b e bad db d f ad e fff bcdf e e ff dc exitCode finishedAt T Z reason Error startedAt T Z name kubelego ready false restartCount state waiting message Backoff m s restarting failed containerkubelego podkubelego f bc c dk vkubelegoe c e f e ccc a fcc reason CrashLoopBackOff hostIP phase Running podIP qosClass BestEffort startTime T Z sysctl netipv confallforwarding netipv confallforwarding kubectl get nodes NAME STATUS ROLES AGE VERSION ivanworkstation Ready none d v server Ready none d v server Ready master d v I had a power outage on Saturday which kicked off an issue I still cant fully explain The hostAliases I defined in my kubelego deployment which was working before suddenly was ignored and as a result one of the domains in an ingress wasnt reachable ourdomaincom while the other domain in the ingress did resolve to the correct IP See footnote for more info As a result of failing the reachability test kubelego proceeded to get a certificate for just the wwwourdomaincom domain Because the certificate wasnt for all of the domains in the ingress kubelego proceeded to repeatedly request a new one which latherrinserepeated couldnt reach the fake acme challenge at ourdomaincom requested a new one for just wwwourdomaincom etc I got rate limited and then IP blocked before I was even awoken by the alert emails that tell me when the site goes down While I try to figure out how to get it to actually resolve to the correct IP I would also like to learn how to prevent it from causing that kind of loop in the future Hopefully I dont have to bug Lets Encrypt admins more than once even if I do run into a DNS thing again It doesnt make sense to me that kubelego would ever try to request a certificate if it couldnt do the reachability test to all domains in the certificate unless Im missing something such a situation indicates the ingress was configured for the wrong domain a DNS resolution issue like in my case or something else similarly fatal If Im wrong and there is a good reason for it to go ahead and get a certificate even if it cant reach all of them then at the very least it shouldnt ever try to reobtain the certificate at least until all domains pass the reachability test Im opening this under the assumption that what causes this to happen is different at least in some part than the retry issue that was addressed in if I am incorrect in that assumption then please accept my apology as I await eagerly for the next release sub I dont know much about Windows networks but for some reason the nameserver on the inside of the LAN has to point ourdomaincom to a different IP than the one I want my cluster to point to for the purposes of reachabilityreadinessliveness tests of that site To the outside world both ourdomaincom and wwwourdomaincom point to the same IP which gets forwarded to this nginx ingress To get kubelego to work I had originally set it up with a hostAliases entry that mapped ourdomaincom to the correct IP This worked until a power outage reboot on Saturday I dont know why it doesnt work now Im trying a few other things like setting up dnsmasq on the host nodes with an appropriate etchosts entrysub Image version is updated already Should fix 