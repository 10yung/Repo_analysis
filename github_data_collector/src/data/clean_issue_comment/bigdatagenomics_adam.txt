 Hi I try to install this package and use it but Im constantly failing What I did so far set up Anaconda with PySpark pip install bdgenomicsadam pyadam optanacondaenvsadambin optanacondaenvsadamlibpython sitepackagesbdgenomicsadam optanacondaenvsadambin optanacondaenvsadamlibpython sitepackagesbdgenomicsadam ls cannot access optanacondaenvsadamlibpython sitepackagesbdgenomicsadamadampythondist No such file or directory Failed to find ADAM egg in optanacondaenvsadamlibpython sitepackagesbdgenomicsadamadampythondist You need to build ADAM before running this program When I try to use the Python API I get the following result python from pysparksql import SparkSession spark SparkSessionbuilderappNameabcgetOrCreate from bdgenomicsadamadamContext import ADAMContext ac ADAMContextspark Traceback most recent call last File optanacondaenvsadamlibpython sitepackagesIPythoncoreinteractiveshellpy line in runcode execcodeobj selfuserglobalns selfuserns File ipythoninput ade e ddf line in module ac ADAMContextspark File optanacondaenvsadamlibpython sitepackagesbdgenomicsadamadamContextpy line in init c selfjvmorgbdgenomicsadamrddADAMContextADAMContextFromSessionssjsparkSession TypeError JavaPackage object is not callable Python will not be maintained past Many modules already have dropped support adamsubmit transformAlignments sortbyreferencepositionandindex NA alignedHg duplicateMarkedbaseRealignedbam NA alignedHg duplicateMarkedbaseRealignedalignmentsadam INPUTNA alignedHg duplicateMarkedbaseRealignedalignmentsadam OUTPUTNA alignedHg duplicateMarkedbaseRealignedoutcram adamshell i convertparquetalignmentsadamdatasetscala javalangIllegalArgumentException requirement failed To save as CRAM input must be sorted at scalaPredefrequirePredefscala at orgbdgenomicsadamrddreadAlignmentRecordDatasetanonfunsaveAsSam applyAlignmentRecordDatasetscala at scalaOptionfoldOptionscala at orgapachesparkrddTimertimeTimerscala at orgbdgenomicsadamrddreadAlignmentRecordDatasetsaveAsSamAlignmentRecordDatasetscala at orgbdgenomicsadamrddreadAlignmentRecordDatasetanonfunsaveAsSam applymcVspAlignmentRecordDatasetscala at orgbdgenomicsadamrddreadAlignmentRecordDatasetanonfunsaveAsSam applyAlignmentRecordDatasetscala at orgbdgenomicsadamrddreadAlignmentRecordDatasetanonfunsaveAsSam applyAlignmentRecordDatasetscala at scalaOptionfoldOptionscala at orgapachesparkrddTimertimeTimerscala at orgbdgenomicsadamrddreadAlignmentRecordDatasetsaveAsSamAlignmentRecordDatasetscala elided See convertparquetalignmentsadamdatasetscala Abstract classes scala trait GenomicDataset T U Product V GenomicDataset T U V extends Logging def saveAsParquetargs SaveArgs Unit def saveAsParquet pathName String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false Unit def saveAsPartitionedParquetpathName String compressCodec CompressionCodecName CompressionCodecNameGZIP partitionSize Int abstract class AvroGenomicDataset T IndexedRecord Manifest U Product V AvroGenomicDataset T U V extends GenomicDataset T U V protected def saveRddAsParquetargs SaveArgs Unit protected def saveRddAsParquet pathName String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false optSchema Option Schema None Unit SaveAsADAMtime def saveAsParquet pathName String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false def saveAsParquet pathName javalangString blockSize javalangInteger pageSize javalangInteger compressCodec CompressionCodecName disableDictionaryEncoding javalangBoolean def saveAsParquetpathName javalangString Concrete classes scala abstract class CoverageDataset def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false def savefilePath javalangString asSingleFile javalangBoolean disableFastConcat javalangBoolean case class DatasetBoundFeatureDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class FeatureDataset def savefilePath javalangString asSingleFile javalangBoolean disableFastConcat javalangBoolean def saveAsGtffileName String asSingleFile Boolean false disableFastConcat Boolean false def saveAsGff fileName String asSingleFile Boolean false disableFastConcat Boolean false def saveAsUcscBedfileName String asSingleFile Boolean false disableFastConcat Boolean false minimumScore Double maximumScore Double missingValue Int def saveAsBedfileName String asSingleFile Boolean false disableFastConcat Boolean false def saveAsIntervalListfileName String asSingleFile Boolean false disableFastConcat Boolean false def saveAsNarrowPeakfileName String asSingleFile Boolean false disableFastConcat Boolean false case class DatasetBoundFragmentDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class FragmentDataset def savefilePath javalangString case class DatasetBoundAlignmentDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class AlignmentDataset def saveargs ADAMSaveAnyArgs isSorted Boolean false Boolean def savefilePath javalangString isSorted javalangBoolean javalangBoolean def saveAsSamString String def saveAsSam filePath String asType Option SAMFormat None asSingleFile Boolean false isSorted Boolean false deferMerging Boolean false disableFastConcat Boolean false Unit SAMSavetime def saveAsSam filePath String asType Option SAMFormat asSingleFile Boolean sortOrder SAMFileHeaderSortOrder deferMerging Boolean disableFastConcat Boolean Unit SAMSavetime def saveAsSam filePath javalangString asType SAMFormat asSingleFile javalangBoolean isSorted javalangBoolean def saveAsPairedFastq fileName String fileName String writeOriginalQualityScores javalangBoolean asSingleFile javalangBoolean disableFastConcat javalangBoolean validationStringency ValidationStringency persistLevel StorageLevel def saveAsPairedFastq fileName String fileName String writeOriginalQualityScores Boolean false asSingleFile Boolean false disableFastConcat Boolean false validationStringency ValidationStringency ValidationStringencyLENIENT persistLevel Option StorageLevel None def saveAsFastq fileName String writeOriginalQualityScores javalangBoolean sort javalangBoolean asSingleFile javalangBoolean disableFastConcat javalangBoolean validationStringency ValidationStringency def saveAsFastq fileName String fileName Opt Option String None writeOriginalQualityScores Boolean false sort Boolean false asSingleFile Boolean false disableFastConcat Boolean false validationStringency ValidationStringency ValidationStringencyLENIENT persistLevel Option StorageLevel None case class DatasetBoundReadDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class ReadDataset def savefilePath javalangString asSingleFile javalangBoolean def saveAsFastqfilePath String asSingleFile Boolean false disableFastConcat Boolean false case class DatasetBoundSequenceDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class SequenceDataset def save filePath javalangString asSingleFile javalangBoolean disableFastConcat javalangBoolean def saveAsFastafilePath String asSingleFile Boolean false disableFastConcat Boolean false lineWidth Int case class DatasetBoundSliceDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class SliceDataset def save filePath javalangString asSingleFile javalangBoolean disableFastConcat javalangBoolean def saveAsFastafilePath String asSingleFile Boolean false disableFastConcat Boolean false lineWidth Int case class DatasetBoundGenotypeDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class GenotypeDataset def saveVcfHeadersfilePath String Unit sealed abstract class VariantContextDataset def saveVcfHeadersfilePath String Unit def saveAsParquetpathName String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false def saveAsVcfargs ADAMSaveAnyArgs stringency ValidationStringency ValidationStringencyLENIENT Unit def saveAsVcffilePath String Unit def saveAsVcffilePath String asSingleFile Boolean deferMerging Boolean disableFastConcat Boolean stringency ValidationStringency Unit SaveAsVcftime case class DatasetBoundVariantDataset override def saveAsParquetfilePath String blockSize Int pageSize Int compressCodec CompressionCodecName CompressionCodecNameGZIP disableDictionaryEncoding Boolean false sealed abstract class VariantDataset def saveVcfHeadersfilePath String Unit Expected to fail CI comesotericsoftwarekryoKryoException javalangIllegalArgumentException Class is not registered orgapachesparksqlexecutiondatasourcesInMemoryFileIndexSerializableFileStatus Note To register this class use kryoregisterorgapachesparksqlexecutiondatasourcesInMemoryFileIndexSerializableFileStatusclass Serialization trace array scalacollectionmutableArrayBuffer at comesotericsoftwarekryoserializersObjectFieldwriteObjectFieldjava at comesotericsoftwarekryoserializersFieldSerializerwriteFieldSerializerjava at comesotericsoftwarekryoKryowriteClassAndObjectKryojava at comtwitterchillTuple SerializerwriteTupleSerializersscala at comtwitterchillTuple SerializerwriteTupleSerializersscala at comesotericsoftwarekryoKryowriteClassAndObjectKryojava at comesotericsoftwarekryoserializersDefaultArraySerializersObjectArraySerializerwriteDefaultArraySerializersjava at comesotericsoftwarekryoserializersDefaultArraySerializersObjectArraySerializerwriteDefaultArraySerializersjava at comesotericsoftwarekryoKryowriteClassAndObjectKryojava at orgapachesparkserializerKryoSerializerInstanceserializeKryoSerializerscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava See scala classForName is expensive in case the class is not found so we filter the list of SQL ML MLlib classes once and then reuse that filtered list in newInstance calls private lazy val loadableSparkClasses Seq Class Seq orgapachesparksqlcatalystexpressionsUnsafeRow orgapachesparksqlcatalystexpressionsUnsafeArrayData orgapachesparksqlcatalystexpressionsUnsafeMapData orgapachesparkmlattributeAttribute orgapachesparkmlattributeAttributeGroup orgapachesparkmlattributeBinaryAttribute orgapachesparkmlattributeNominalAttribute orgapachesparkmlattributeNumericAttribute orgapachesparkmlfeatureInstance orgapachesparkmlfeatureLabeledPoint orgapachesparkmlfeatureOffsetInstance orgapachesparkmllinalgDenseMatrix orgapachesparkmllinalgDenseVector orgapachesparkmllinalgMatrix orgapachesparkmllinalgSparseMatrix orgapachesparkmllinalgSparseVector orgapachesparkmllinalgVector orgapachesparkmlstatdistributionMultivariateGaussian orgapachesparkmltreeimplTreePoint orgapachesparkmllibclusteringVectorWithNorm orgapachesparkmlliblinalgDenseMatrix orgapachesparkmlliblinalgDenseVector orgapachesparkmlliblinalgMatrix orgapachesparkmlliblinalgSparseMatrix orgapachesparkmlliblinalgSparseVector orgapachesparkmlliblinalgVector orgapachesparkmllibregressionLabeledPoint orgapachesparkmllibstatdistributionMultivariateGaussian flatMap name try Some Class UtilsclassForNamename catch case NonFatal None do nothing case NoClassDefFoundError if UtilsisTesting None See SPARK 