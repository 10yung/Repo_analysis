It would be nice to add a tor proxy to the results Weboproxy for example gives the option TOR proxy Canada Proxy regards Py is no longer supported officially Do you want to discontinue the support of py compatibility in searx Please vote with to abandon and to keep it Often we hear that searx results of public instances are pure it is common that this mainly due to two aspects a bot blocker up to date instance To give users a chance to detect if a searx instance is maintained we should more often increase the version set a vtag By this can warn about a unmaintained old version of searx For me this is also related to This is my first attempt to partial address WIP I will add more patches in the next days remarks are welcome A preview of the docs is here dont bookmark In the result parsing engines parse the HTML using lxml most of the time If an XPath request doesnt return at least one result it may be fine or trigger an error later In the later case it is difficult to know exactly what is going on without looking at the downloaded HTML This issue suggests to add new exception classes to add two optional parameters to evalxpath function to check the result count It may help to know when an engine starts to be broken if the engine codes says which XPath request should not fail Im not sure if it is useful and or a privacy problem if searx makes statistics about broken XPath Class hierarchy SearxException SearxParameterException SearxEngineException SearxEngineCaptchaException instead of RuntimeWarning in googlepy SearxEngineXPathException evalxpath python def evalxpathelement xpathstr eqNone gteNone xpath getxpathxpathstr result xpathelement new code check result count now if eq is not None and lenresult eq raise SearxEngineXPathExceptionxpath eqeq if gte is not None and lenresult gte raise SearxEngineXPathExceptionxpath gtegte return result usage examples extracturl python def extracturlxpathresults searchurl if xpathresults raise ExceptionEmpty url resultset Make the check before calling extracturl bing engine python for result in evalxpathdom div classsacc link evalxpathresult h a eq for result in evalxpathdom li classbalgo link evalxpathresult h a eq google engine python title extracttextevalxpathresult titlexpath eq url parseurlextracturlevalxpathresult urlxpath eq googleurl googlehostname The huge trycatch to ignore all the parsing errors would be able to display the XPath in the logs Another way without trycatch and without modification to the evalxpath function python titlexpr evalxpathresult titlexpath urlxpr evalxpathresult urlxpath if lentitlexpr and lenurlxpr title extracttexttitlexpr url parseurlextracturlurlxpr googleurl googlehostname The eq and gte parameters cant help much for the result count Using eq python try resultsnum intevalxpathdom div idresultStats text eq split replace resultsappendnumberofresults resultsnum except pass Without eq with more checking python resultsnumxpath evalxpathdom div idresultStats text if lenresultsnumxpath resultsnumtext resultsnumxpath resultsnumtextfirst resultsnumtextsplit replace try resultsnum intresultsnumtextfirst resultsappendnumberofresults resultsnum except ValueError pass We should stop C P the license text into every file We have one in the root folder and the source files should be tagged with a SPDX License Identifier SPDXLicenseIdentifier AGPL orlater SPDX reduces redundant work by providing a common format for companies and communities to share important data about software licenses copyrights and security references thereby streamlining and improving compliance Similar to Installation current master commit How to reproduce Search for kek on and click on Images ERRORflaskappException on POST Traceback most recent call last File usrlocalsearxsearxvelocallibpython sitepackagesflaskapppy line in wsgiapp response selffulldispatchrequest File usrlocalsearxsearxvelocallibpython sitepackagesflaskapppy line in fulldispatchrequest rv selfhandleuserexceptione File usrlocalsearxsearxvelocallibpython sitepackagesflaskapppy line in handleuserexception reraiseexctype excvalue tb File usrlocalsearxsearxvelocallibpython sitepackagesflaskapppy line in fulldispatchrequest rv selfdispatchrequest File usrlocalsearxsearxvelocallibpython sitepackagesflaskapppy line in dispatchrequest return selfviewfunctions ruleendpoint reqviewargs File usrlocalsearxsearxwebapppy line in index result title highlightcontentescaperesult title or u searchqueryquery File usrlocalsearxsearxutilspy line in highlightcontent if contentlowerfindquerylower UnicodeDecodeError ascii codec cant decode byte xc in position ordinal not in range Here is a way to install searx in minutes and wanted to post this somewhere This is not a bug this is a guide Requirements You have docker running already You have several websites already being served by Apache we will be using a subdomain Apache version You are using certbot for ssl certs Need to use TLS TLS not implemented until Apache Updated for dalf comment below Add ability not to log anything recommended reverse proxy setup I used docker repo wonderfallsearx as that was stated in the install here but is out of date so updated to searxsearx Removed old CSP sha as it was not needed for updated docker image Added more default requirements Removed FilesMatch cgishtmlphtmlphp and Directory usrlibcgibin as they are not needed for using docker Guide Grab the docker code sudo docker pull searxsearx Start searx docker image listening on port note you can change this to whatever you want sudo docker run i t d restartalways p searxsearx Open up a browser and navigate to If you see the searx logo you may continue If not check to see if anything is running on port with sudo netstat peanut grep Create a new apache config file called searxconf with the following content Note if you are not using port change it in the apache conf file apache DEFINE searxurl DEFINE searxport DEFINE publicurl searxsubdomain DEFINE email webadminsearxsubdomain ServerTokens Prod SSLStaplingCache shmcbAPACHELOGDIRstaplingcache SSLSessionCache shmcbAPACHELOGDIRsslscache SSLSessionCacheTimeout If you have Googles Mod PageSpeed disable it ModPagespeed Off VirtualHost ServerName publicurl DocumentRoot varwwwoffline ServerAdmin email ErrorLog APACHELOGDIRweberrorlog CustomLog APACHELOGDIRwebaccesslog combined If you dont want logs ErrorLog devnull CustomLog devnull combined RewriteEngine On RewriteCond SERVERNAMEpublicurl RewriteCond HTTPS off RewriteRule ENDNERpermanent VirtualHost VirtualHost ServerName publicurl DocumentRoot varwwwoffline ServerAdmin email ErrorLog APACHELOGDIRweberrorlog CustomLog APACHELOGDIRwebaccesslog combined If you dont want logs ErrorLog devnull CustomLog devnull combined SSLEngine On SSLCertificateFile etcletsencryptlivepublicurlfullchainpem SSLCertificateKeyFile etcletsencryptlivepublicurlprivkeypem Include etcletsencryptoptionssslapacheconf Forbid the http protocol Protocols h http Timeout ProxyRequests Off ProxyPreserveHost On ProxyTimeout ProxyReceiveBufferSize SSLProxyEngine On RequestHeader set FrontEndHttps On ServerSignature Off SSLCompression Off SSLUseStapling On SSLStaplingResponderTimeout SSLStaplingReturnResponderErrors Off SSLSessionTickets Off RequestHeader set XForwardedProto https envHTTPS Header always set StrictTransportSecurity maxage preload Header always set XContentTypeOptions nosniff Header always set XRobotsTag none Header always set XXSSProtection modeblock Header always set XFrameOptions SAMEORIGIN Header always set ReferrerPolicy strictoriginwhencrossorigin Header always set ContentSecurityPolicy defaultsrc self https fontsrc self data searxurl publicurl mediasrc self blob data https searxurl publicurl scriptsrc self searxurl publicurl imgsrc self data https blob searxurl publicurl Header always set FeaturePolicy geolocation self midi self syncxhr self microphone self camera self magnetometer self gyroscope self speaker self fullscreen self payment self SSLHonorCipherOrder Off Use next two for very secure connections SSLCipherSuite EECDHAESGCMEDHAESGCMAES EECDHAES EDHaNULLeNULLEXPORTDESMD PSKRC SSLProtocol All SSLv SSLv TLSv TLSv Use next two for secure connections and supports more endpoints SSLCipherSuite EECDHAESGCMEDHAESGCMAES EECDHAES EDHECDHERSAAES GCMSHA ECDHERSAAES GCMSHA ECDHERSAAES GCMSHA DHERSAAES GCMSHA DHERSAAES GCMSHA DHERSAAES GCMSHA ECDHERSAAES SHA ECDHERSAAES SHA ECDHERSAAES SHAECDHERSAAES SHADHERSAAES SHA DHERSAAES SHA DHERSAAES SHADHERSAAES SHAECDHERSADESCBC SHAEDHRSADESCBC SHAAES GCMSHA AES GCMSHA AES SHA AES SHA AES SHAAES SHADESCBC SHAHIGHaNULLeNULLEXPORTDESMD PSKRC SSLProtocol All SSLv SSLv TLSv TLSv Actually proxy the traffic and really the only important part ProxyPass ProxyPassReverse Additional suggestions BrowserMatch MSIE nokeepalive ssluncleanshutdown downgrade forceresponse BrowserMatch MSIE ssluncleanshutdown VirtualHost Enable the new site sudo a ensite searxconf Reload and restart apache service sudo service apache reload sudo service apache restart Congrats Wasnt that easy Comments Questions Complaints Grievances Go ahead and leave a comment below Type Feature Request This enhancement proposal is a continuation of dalfs feedback on PR to track proposal Description After accepting PR along with Info box Suggestion and Link box moved to top of page in low width devices so replacing Link box with dropdown button has following advantages Cleaner UI No issue with infinite scrolling Currently the documentation even if it requires a huge update describes how to setup reverse proxy uwsgi searx I think this should be removed to avoid unsafe installations because it is vulnerable to bots or at least put aside with a warning Filtron should be a first citizen not an optional layer The documentation should explain how to setup step by step reverse proxy filtron uwsgi searx EDIT Here I have pick filtron as bot shield but there is also antibotproxy Also the comments of 