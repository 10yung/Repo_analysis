Updates orgscalasbtsbt from to Release NotesChangelog Ill automatically update this PR to resolve conflicts as long as you dont change it yourself If youd like to skip this version you can just close this PR If you have any feedback just mention me in the comments below Have a fantastic day writing Scala details summaryIgnore future updatessummary Add this to your scalastewardconf file to ignore future updates of this dependency updatesignore groupId orgscalasbt artifactId sbt details labels libraryupdate semverpatch I was just migrating to scala and realised that the only collections related migration I had to do was with JsObject I was using this two fields The fields of this JsObject in the order passed to the constructor lazy val fields collectionSeq String JsValue underlyingtoSeq The value of this JsObject as an immutable map lazy val value Map String JsValue underlying match case m immutableMap String JsValue m case m mtoMap What I found interesting is that even the second comment says immutable map and underlyingtoSeq is returning an immutableSeq the return values are collectionMapand collectionSeq This seems odd to me Especially because immutable collections should be considered the default since it is what is defined in predef now Are there any good reasons to not change this to immutable The build in TravisCI doesnt exercise the docsbuildsbt or forces the sbtversion to use for that build That is was merged without addressing Implicit conversions between JValue JsValue Instances for Play typeclasses Reads and Writes based on implicit instances of JSON S Reader and Writer Instances for JSON typeclass Reader and Writer based on implicit instances of Play Reads and Writes Ive a compile error with PlayJson macro and catsdataNewtype More details and a reproducible failing snippet here If would we awesome if sbt release process will have additional step with modifying README with latest version before commiting version changes As an example we can take Pull Request Checklist x Have you read through the contributor guidelines Have you signed the Typesafe CLA Have you squashed your commits Have you added copyright headers to new files Have you updated the documentation x Have you added tests for any changed functionality Fixes Doesnt have a ticket Purpose Often I have or use java enums in my projects and have to serialize or deserialize them in json context So i wrote a generic solution for doing this and want give it back to the comunity Background Context Because i got sick of duplicating code References Are there any relevant issues PRs mailing lists discussions Play JSON Version x etc API Scala Java Neither Both Scala Operating System Ubuntu MacOS Windows macOS JDK Oracle OpenJDK x Azul Zing java version JavaTM SE Runtime Environment build b Java HotSpotTM Bit Server VM build b mixed mode Library Dependencies NA Expected Behavior scala paste Entering paste mode ctrlD to finish import playapilibsjson val js Jsonparse a b c stripMargin val removeAAndB ajsonprune andThen bjsonprune val removeAAndBPickD removeAAndB andThen djsonpick Exiting paste mode now interpreting import playapilibsjson js playapilibsjsonJsValue a b c removeAAndB playapilibsjsonReads playapilibsjsonJsObject playapilibsjsonReadsanon d fc removeAAndBPickD playapilibsjsonReads playapilibsjsonJsValue playapilibsjsonReadsanon ed bd scala removeAAndBreadsjs res playapilibsjsonJsResult playapilibsjsonJsObject JsSuccessc ab scala removeAAndBPickDreadsjs res playapilibsjsonJsResult playapilibsjsonJsValue JsErrorListabdListJsonValidationErrorListerrorpathmissingWrappedArray Should evaluate to JsErrorListdListJsonValidationErrorListerrorpathmissingWrappedArray Actual Behavior It evaluates to JsErrorListabdListJsonValidationErrorListerrorpathmissingWrappedArray The issue is that prune is effectively repathing the result and so it does not compose properly with subsequent Reads It makes sense to use the path in the error cases but not success Reproducible Test Case See above Issue If a JavaScala Long value is converted to JSON then naturally I expect that it will be represented as JSON number But counterintuitively the Long value can be too large for javascript and therefore it isnt good idea to represent as JSON number For an example you can take LongMaxValue and try it out with browsers console In my case the last four digits fail var longVal count longVal Object count Actual Behavior Playjson represents Long as JSON number Scala println playjson JsontoJsonLongMaxValue playjson Expected Behavior As Pickle the Long value should be represented as JSON string Scala println upickle writeLongMaxValue upickle Tested Version playjson upickle firefox 