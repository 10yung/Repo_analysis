This PR addresses issue I have made the following changes Added show hyperparameter to manifold Updated test for the quick method Updated documentation Sample Code and Plot from yellowbrickfeaturesManifold import manifoldembedding from yellowbrickdatasets import loadconcrete Load the regression dataset X y loadconcrete Instantiate the visualizer manifoldembeddingX y manifoldisomap nneighbors CHECKLIST Heres a handy checklist to go through before submitting a PR note that you can check a checkbox in Markdown by changing to x or you can create the PR and check the box manually x Is the commit message formatted correctly Have you noted the new functionalitybugfix in the release notes of the next release If youve changed any code x Included a sample plot to visually illustrate your changes x Do all of your functions and methods have docstrings x Have you addedupdated unit tests where appropriate x Have you updated the baseline images if necessary x Have you run the unit tests using pytest x Is your code style correct are you using PEP pyflakes x Have you documented your new featurefunctionality in the docs FutureWarning The sklearnmetricsclassification module is deprecated in version and will be removed in version The corresponding classes functions should instead be imported from sklearnmetrics Anything that cannot be imported from sklearnmetrics is now part of the private API This PR refers to issue It adds effect plots to yellowbrickregressors It has the following features Auto identification of discrete and continuous columns Hyperparams for custom plots Sample Code and Plot python from yellowbrickregressoreffect import EffectPlot from yellowbrickdatasets import loadbikeshare from sklearnlinearmodel import LinearRegression X y loadbikeshare viz EffectPlotLinearRegression colormapcool vizfitX y vizpoofoutpath Effectpng Effect TODOs and questions If this is a workinprogress WIP list the changes you still need to make andor questions or the Yellowbrick team You can also mention extensions to your work that might be added as an issue to work on after the PR Still to do Provide parameter which allows users to define discrete and continuous features Add testeffectpy Add Documentation Questions for the DistrictDataLabsteamozmaintainers CHECKLIST Heres a handy checklist to go through before submitting a PR note that you can check a checkbox in Markdown by changing to x or you can create the PR and check the box manually Is the commit message formatted correctly Have you noted the new functionalitybugfix in the release notes of the next release If youve changed any code Included a sample plot to visually illustrate your changes Do all of your functions and methods have docstrings Have you addedupdated unit tests where appropriate Have you updated the baseline images if necessary Have you run the unit tests using pytest Is your code style correct are you using PEP pyflakes Have you documented your new featurefunctionality in the docs If youve added to the docs Have you built the docs using make html Addressing issue I have made the following changes Added show kwarg to Postag Added test for the quick method Updated documentation Sample Code python import nltk from yellowbricktextpostag import postag from yellowbrickdatasets import loadhobbies docs loadhobbiesdata taggedstanzas nltkpostagnltkwordtokenizesent for sent in docs tag taggedstanzas viz postagtag CHECKLIST Heres a handy checklist to go through before submitting a PR note that you can check a checkbox in Markdown by changing to x or you can create the PR and check the box manually Is the commit message formatted correctly Have you noted the new functionalitybugfix in the release notes of the next release If youve changed any code Included a sample plot to visually illustrate your changes Do all of your functions and methods have docstrings Have you addedupdated unit tests where appropriate Have you updated the baseline images if necessary Have you run the unit tests using pytest Is your code style correct are you using PEP pyflakes Have you documented your new featurefunctionality in the docs If youve added to the docs Have you built the docs using make html I have made the following changes Rearrange quick method function parameters to match docstring Reformat docstring Add show kwarg to quick method Remove unnecessary args randomstate legend from test Update docs with link example of quick method and add to automodule Questions for the DistrictDataLabsteamozmaintainers x Im not a data science expert so the example I created for the kelbow quickmethod may be nonsense Can someone please review the example x I did basically nothing regarding the test since the quick method uses xfail due to some nondeterminism in the output graph Other tests seem to have have the same problem and fix Is this fine In the docs I included what I expect to be the hyperlink to the quick method kelbowvisualizer though I believe I have no way to test this until it actually gets merged and hosted Is there a correct way to handle this After the visualizer audit we believe that the quick methods are ready to be made prime time Quick methods must Have a function signature identical to the Visualizer constructor with additional data for fitscore Call finalize and not poofshow Return the fitted visualizer instance Some visualizers must also insure that they call transformfittransformscore For each visualizer found in the list below we must x refactor the quick method to the new API document the quick method ensure there is an associated test or tests for the quick method See for more details on this issue classpredictionerror classificationreport confusionmatrix precisionrecallcurve x rocauc discriminationthreshold alphas cooksdistance predictionerror residualsplot kelbowvisualizer interclusterdistance x silhouettevisualizer balancedbinningreference classbalance featurecorrelation x cvscores learningcurve validationcurve explainedvariancevisualizer featureimportances rank d rank d x rfecv jointplot mainfoldembedding x pcadecomposition x parallelcoordinates x radviz dispersion freqdist x postag x tsne umap gridsearchcolorplot This PR fixes and adds support for Pipelines in most ScoreVisualizers It also adds some automatic checking extending functionality described in I have made the following changes Added an ispipeline type check Added functionality to ModelVisualizer to access the final estimator in a pipeline TODOs and questions If this is a workinprogress WIP list the changes you still need to make andor questions or the Yellowbrick team You can also mention extensions to your work that might be added as an issue to work on after the PR Still to do modify visualizers to use new code create tests for pipelines with model visualizers document pipelines in visualizers CHECKLIST Heres a handy checklist to go through before submitting a PR note that you can check a checkbox in Markdown by changing to x or you can create the PR and check the box manually Is the commit message formatted correctly Have you noted the new functionalitybugfix in the release notes of the next release If youve changed any code Included a sample plot to visually illustrate your changes Do all of your functions and methods have docstrings Have you addedupdated unit tests where appropriate Have you updated the baseline images if necessary Have you run the unit tests using pytest Is your code style correct are you using PEP pyflakes Have you documented your new featurefunctionality in the docs If youve added to the docs Have you built the docs using make html Welcome Contributor Thank you for contributing to Yellowbrick please follow the instructions below to get your PR started off on the right foot First Steps Are you merging from a feature branch into develop If not please create a feature branch and change your PR to merge from that branch into the Yellowbrick develop branch Does your PR have a title Please ensure your PR has a short informative title eg Enhances ParallelCoordinates with new andrewscurve parameter or Corrects bug in WhiskerPlot that causes index error Summarize your PR HINT See CHECKLISTTEMPLATE below This PR fixes I added the following features Added a parameter for showing cumulative explained variance Added a parameter which takes percentage of variance needed in the components and shows corresponding principal components Sample Code and Plot python from yellowbrickfeaturesdecomposition import ExplainedVariance from sklearndatasets import loaddigits digits loaddigits X digitsdata viz ExplainedVariancecumulativeTrue cutoff vizfitX viztransformX vizpoofVaraincepng abc Still to do Add more features Add tests Add documentation More Todos x Is the commit message formatted correctly Have you noted the new functionalitybugfix in the release notes of the next release If youve changed any code x Included a sample plot to visually illustrate your changes Do all of your functions and methods have docstrings Have you addedupdated unit tests where appropriate Have you updated the baseline images if necessary Have you run the unit tests using pytest Is your code style correct are you using PEP pyflakes Have you documented your new featurefunctionality in the docs If youve added to the docs Have you built the docs using make html I am suggesting trying migrating Miniconda builds to Travis I have determined how to resolve the issue on Windows CI that resulted in but Travis would offer better overall build times for each successful TravisAppveyor build than continuing with Miniconda on Appveyor Why Appveyor total build times are longer than on Travis Jobs sequential Also seems to be additional time needed between jobs in each build Sample times from recent commits are below Having the ability to use either Appveyor or Travis for Windows in general should remain to remain resilient to issues on either CI service but the discrepancy in total build times between them can be adjusted Impact of migrating Miniconda greater per job than regular Python Each Miniconda job taking longer by up to min s Impact on successful build times Potential minute reduction in successful build times depending on whether both and considered Sample Appveyor time now minutes with Miniconda with Miniconda and Expected Appveyor times after migration minutes without Miniconda Expected Travis time after migration unknown precisely Potential small uptick in failed build times but improvement likely overall Given a reduction in successful Appveyor build times of about minutes and a possible but not known increase in failing Travis build time of minutes there would need to be about times as many failing builds as successful builds in order to avoid at least testing this migration Passing builds Appveyor Job Time elapsed Result Python PASS Python PASS Miniconda PASS Setup and all jobs PASS Note that the sum of the job times was just under minutes but the total time was about minutes longer Travis Job Time elapsed Result Python PASS Python PASS Miniconda PASS Miniconda PASS All jobs PASS Failing builds Appveyor Job Time elapsed Result Python FAIL Total time FAIL In the case of this failed build the total time equals the time for this single job Based on this and the total time for the successful build there seems to be additional time between jobs in a build that are not included in the Appveyor job times but impact the overall time Travis Job Time elapsed Result Python FAIL Python FAIL Miniconda FAIL Miniconda FAIL Total time FAIL This line alerts the Yellowbrick maintainers feel free to use this address to alert us directly in follow up comments DistrictDataLabsteamozmaintainers I would be glad to work on a PR so the impact can be validated and realized Weve recently been having some issues ensuring that all of our dependencies are passing tests since our CI only tests the latest version Currently our tests have good coverage but do take a while to run which is slowing down the PR process Instead of updating our tests with a larger test matrix we are proposing an advanced matrix that only runs if the version has been bumped eg on a release This matrix would include all major versions of our dependencies and potentially could expand the number of python versions and implementations eg miniconda reducing these from our daytoday test requirements Also for discussion jklymak suggests that we test matplotlib from master so that we can better catch changes in matplotlib dependencies before a release requires a hotfix 