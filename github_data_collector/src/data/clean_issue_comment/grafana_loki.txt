Describe the bug Loki promtail daemons crash eventually To Reproduce Steps to reproduce the behavior Started Loki SHA or version Started Promtail SHA or version I have a very basic setup everything is stored on localhost When I look at the logs of loki I see lots of messages about out of order events I believe this happens as I currently have persistence configured for journald to varlogjournal and whenever it starts up it tries to ingest the entire directory not just the most recentcurrent journal Another thing I noticed is that eventually the ingester is gone But I havent been able to track as to why this happened Maybe the amount of journal is the problem Its roughly MB the VM has plenty of RAM GiB and vCPUs Promtail crashes eventually as well after I think too many errors from loki which I guess is related but also undesired behaviour Should I make another ticket for that Expected behavior I expect them to be running and working Environment Infrastructure VM on baremetal HV Deployment tool Ansible OS CentOS CentOS Linux release Core kernel Screenshots Promtail config or terminal output Loki config authenabled True server httplistenaddress httplistenport grpclistenaddress loglevel debug ingester lifecycler address ring kvstore store inmemory replicationfactor finalsleep s chunkidleperiod m chunkretainperiod s schemaconfig configs from store boltdb objectstore filesystem schema v index prefix lokiindex period h storageconfig boltdb directory tmplokiindex filesystem directory tmplokichunks limitsconfig enforcemetricname false rejectoldsamples true rejectoldsamplesmaxage h chunkstoreconfig maxlookbackperiod h tablemanager chunktablesprovisioning inactivereadthroughput inactivewritethroughput provisionedreadthroughput provisionedwritethroughput indextablesprovisioning inactivereadthroughput inactivewritethroughput provisionedreadthroughput provisionedwritethroughput retentiondeletesenabled true retentionperiod h Promtail config server httplistenadress httplistenport grpclistenaddress grpclistenport loglevel debug Positions positions filename tmppositionsyaml Loki Server URL clients url tenantid till externallabels node fullyqualifieddomainname customer till scrapeconfigs jobname journal journal path varlogjournal labels job journal relabelconfigs sourcelabels journalsystemdunit targetlabel unit Id love to use Loki in a distributed system easier and without being forced relatively high cardinality labels based on something like process ID This goes double for systems like AWS Lambda This main obstacle to this for me is being unable to submit out of order log lines it would be great if loki could have a feature that would enable this At one point I found an old issue relating to this request but it was closed with not something we need before releasing Perhaps it is time to revisit this Cheers A common way to match multiple simple words in either label matching or log text is to use a regex filter firsttermsecondterm for example This is expensive to compute as the regex engine can be slow Specifically for this case where the regex is a simple string contains another string break the query into n queries where n is the number of terms provided using the faster bytecontains method to match then combine the results This would be as if the user searched first on firstterm and then on secondterm and then manually combined the results but automatically converted and computed when executing the original firsttermsecondterm If Promtail happens to crash when it has a batch of logs queued to send to Loki the logs will be lost While the file and journal targets have their last read positions saved in the positions file this file is updated before Promtail guarantees the batch was sent One potential implementation to solve this problem is a WAL Promtail is unable to install using helm charts I am getting the error below in logs of all pods Not ready Unable to find any logs to tail Please verify permissions volumes scrapeconfig etc n ws false AcceptEncoding gzip Connection close UserAgent kubeprobe I was trying to install it on rancher kubernetes its creating the pod but not initializing it img width altCapture src Getting a warning message on kubernetes dashboard like Search Line limits were exceeded some search paths have been omitted the applied search line isdefaultsvcclusterlocal svcclusterlocal clusterlocal rancherinternal Readiness probe failed HTTP probe failed with statuscode Is your feature request related to a problem Please describe I want to use the Loki Docker driver to get my logs from Amazon ECS into Loki but there isnt an easy way to do so Describe the solution youd like The Loki Docker driver is easily usable with Amazon ECS Describe alternatives youve considered The solution suggested by Amazon in the LogConfiguration documentation is to fork the ECS agent and run a custom build You can also work around it by setting the Loki driver as the default Docker logging driver docs on your EC instance then providing no logging configuration in your ECS task Additional context This isnt really a problem that can be fixed within Loki but this issue provides a reference point for people who are interested in using Loki with ECS or attempting to find more information It may make sense for a Loki maintainer to open a PR to add support to the ECS agent This issue would also be resolved by the completion of which allows the usage of arbitrary custom log drivers with ECS The documentation added in should also be updated once a better solution is available Make Promtails Helm chart support passing extra env variables bump charts versions Thanks for sending a pull request Before submitting Read our CONTRIBUTINGmd guide Name your PR as Feature Area Describe your change Rebase your PR if it gets out of sync with master If changing the Helm chart please ensure the chart version is increased per semantic versioning What this PR does why we need it This PR enables developers to pass environment variables to the promtail containers via helm similarly to how its done for loki Which issues this PR fixes Fixes issue number Special notes for your reviewer Checklist Documentation added Tests updated Describe the bug I see a lot of statuscodes in s metrics cortexs requestdurationsecondsbucket Strange thing is that we do not see those requests on the storage backend I see that timeout for s is not configurable but I think there is some default which reports as in this metric Expected behavior I would like to be able to set storage timeout Environment K S Rados Gateway Ceph Describe the bug Got error below when running tk apply environmentsloki The content of tk show shows that there is no selector in promtail daemonset part shell tk apply environmentsloki The DaemonSet promtail is invalid spectemplatemetadatalabels Invalid value map string stringnamepromtail selector does not match template labels Warning There are no differences Your apply may not do anything at all Applying to namespace loki of cluster clusterlocal at using context kubernetesadminclusterlocal Please type yes to confirm no aborted by user Describe the bug When turning on AutoKubernetesLabels fluentbit log returns panic as follow Expected behavior Successfully see all logs in Loki Environment Infrastructure minikube v Deployment tool kustomize Screenshots Promtail config or terminal output kubectl logs output info filterkube https hostkubernetesdefaultsvc port info filterkube local POD info OK info filterkube testing connectivity with API server info filterkube API server connectivity OK info sp stream processor started panic interface conversion interface is map string interface not map interface interface fluentbitconf SERVICE Flush Daemon Off LogLevel info ParsersFile parsersconf INPUT Name tail Path varlogcontainerslog Parser docker Tag kube RefreshInterval MemBufLimit MB SkipLongLines On DB runfluentbitflbkubedb INPUT Name systemd Tag host SystemdFilter SYSTEMDUNITdockerservice SystemdFilter SYSTEMDUNITkubeletservice SystemdFilter SYSTEMDUNITnodeproblemdetectorservice MaxEntries ReadFromTail true StripUnderscores false FILTER Name kubernetes Match kube KubeTagPrefix kubevarlogcontainers KubeURL KubeCAFile varrunsecretskubernetesioserviceaccountcacrt KubeTokenFile varrunsecretskubernetesioserviceaccounttoken MergeLog On K SLoggingParser Off OUTPUT Name loki Match kube Url Labels jobfluentbit RemoveKeys kubernetesstream AutoKubernetesLabels true LabelMapPath fluentbitetclabelmapjson LineFormat json LogLevel warn parsersconf PARSER Name docker Format json TimeKey time TimeFormat YmdTHMSL 