To facilitate TumblThrees development within a larger community TumblThree is moving to its new home at a github organization For new releases issues and communitydeveloper chat at gitter check out its new home TumblThreeApp Exception info from Event Application TumblThreeexe Framework Version v Description The process was terminated due to an unhandled exception Exception Info SystemNullReferenceException at TumblThreeApplicationsCrawlerAbstractCrawlerHandleUnauthorizedWebExceptionSystemNetWebException at TumblThreeApplicationsCrawlerTumblrBlogCrawlerIsBlogOnlineAsyncd MoveNext at SystemRuntimeExceptionServicesExceptionDispatchInfoThrow at SystemRuntimeCompilerServicesTaskAwaiterHandleNonSuccessAndDebuggerNotificationSystemThreadingTasksTask at TumblThreeApplicationsControllersManagerControllerCheckStatusOfBlogsAsyncd MoveNext at SystemRuntimeExceptionServicesExceptionDispatchInfoThrow at SystemRuntimeCompilerServicesTaskAwaiterHandleNonSuccessAndDebuggerNotificationSystemThreadingTasksTask at TumblThreeApplicationsControllersManagerControllercDisplayClass ThrottledCheckStatusOfBlogsAsyncb dMoveNext at SystemRuntimeExceptionServicesExceptionDispatchInfoThrow at SystemRuntimeCompilerServicesTaskAwaiterHandleNonSuccessAndDebuggerNotificationSystemThreadingTasksTask at TumblThreeApplicationsControllersManagerControllerThrottledCheckStatusOfBlogsAsyncd MoveNext at SystemRuntimeExceptionServicesExceptionDispatchInfoThrow at SystemRuntimeCompilerServicesTaskAwaiterHandleNonSuccessAndDebuggerNotificationSystemThreadingTasksTask at TumblThreeApplicationsControllersManagerControllerCheckStatusAsyncd MoveNext at SystemRuntimeExceptionServicesExceptionDispatchInfoThrow at SystemRuntimeCompilerServicesTaskAwaiterHandleNonSuccessAndDebuggerNotificationSystemThreadingTasksTask at SystemWafApplicationsAsyncDelegateCommandExecuted MoveNext at SystemRuntimeExceptionServicesExceptionDispatchInfoThrow at SystemWindowsThreadingExceptionWrapperInternalRealCallSystemDelegate SystemObject Int at SystemWindowsThreadingExceptionWrapperTryCatchWhenSystemObject SystemDelegate SystemObject Int SystemDelegate at SystemWindowsThreadingDispatcherOperationInvokeImpl at MSInternalCulturePreservingExecutionContextCallbackWrapperSystemObject at SystemThreadingExecutionContextRunInternalSystemThreadingExecutionContext SystemThreadingContextCallback SystemObject Boolean at SystemThreadingExecutionContextRunSystemThreadingExecutionContext SystemThreadingContextCallback SystemObject Boolean at SystemThreadingExecutionContextRunSystemThreadingExecutionContext SystemThreadingContextCallback SystemObject at MSInternalCulturePreservingExecutionContextRunMSInternalCulturePreservingExecutionContext SystemThreadingContextCallback SystemObject at SystemWindowsThreadingDispatcherOperationInvoke at SystemWindowsThreadingDispatcherProcessQueue at SystemWindowsThreadingDispatcherWndProcHookIntPtr Int IntPtr IntPtr Boolean ByRef at MSWin HwndWrapperWndProcIntPtr Int IntPtr IntPtr Boolean ByRef at MSWin HwndSubclassDispatcherCallbackOperationSystemObject at SystemWindowsThreadingExceptionWrapperInternalRealCallSystemDelegate SystemObject Int at SystemWindowsThreadingExceptionWrapperTryCatchWhenSystemObject SystemDelegate SystemObject Int SystemDelegate at SystemWindowsThreadingDispatcherLegacyInvokeImplSystemWindowsThreadingDispatcherPriority SystemTimeSpan SystemDelegate SystemObject Int at MSWin HwndSubclassSubclassWndProcIntPtr Int IntPtr IntPtr at MSWin UnsafeNativeMethodsDispatchMessageSystemWindowsInteropMSG ByRef at SystemWindowsThreadingDispatcherPushFrameImplSystemWindowsThreadingDispatcherFrame at SystemWindowsApplicationRunDispatcherSystemObject at SystemWindowsApplicationRunInternalSystemWindowsWindow at TumblThreePresentationAppMain No idea which blog causes it This is very useful for recognizing the blogs that are dead and no longer post content so they can be safely removed If the scan is limited and no new content within the limited span days pages show No New Content instead Right now theres no way to get that information TumblThree is wonderful Im having good luck with it except when it simply stops crawling Ive simplified my configuration all the way down to crawling only one blog at a time and it is often successful even when downloading tens of thousands of files Occasionally however it just stops and the message in the queue is sometimes that it was Downloading and sometimes that it was Skipping a file My settings are Concurrent Connections Concurrent Video Concurrent blogs Timeout Scan connections Limiting API to connections per seconds In the Settings file MaxNumberOfRetries Im downloading everything saving metadata as JSON posts per page Downloading specified size x even if it isnt offered and Dumping crawler data My internet access is speedy and reliable I have RAM to spare and Im saving to an SMB share for what its worth When TumblThree stops crawling the application hasnt frozen if I click Stop it stops and cleans up duplicates Any thoughts on how I can troubleshoot this Or a settings change that might help Edit Also it may be the case that this only happens near or at the completion of a blog the last three times I ran into this the Downloaded Files value was at least of the of Number of Downloads Edit I just saw it happen at the mark so that goes against my previous edit Also Ill mention that clicking Pause and then Resume has no effect My installation of latest TumblThree version doesnt save its settings or changes I make to Settings I have to manually edit the Settingsjson file which is no big deal However how can I save my account and password inside it can I use direct strings or do I need to convert my password to some encrypted format and add it that way Please help me Thanks in advance Since january rd TumblThree is no longer able to find any data from flagged as explicit posts it looks like these posts dont exist anymore The total number of posts appearing in number of downloads column before crawling is correct but these posts are missing no infos neither in images imagesurl or texts files after backup Please do you know a solution Thank you for your help Migrate issues and development focus over to organisation Im not sure what tooling exists for this and keeping any discussions and stuff in place but that could be advantageous Example URL Also it prevents crawler from being stopped and application wont exit UI is destroyed but rest of process is still running Hello I am trying to download copies of my likes posts on the page there is and the application shows only 