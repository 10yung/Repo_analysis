Hi I have a question in BytesQueue part Why reset qhead leftMarginIndex qtail qrightMargin in function allocateAdditionalMemory Will it cause some entries live longer than lifeWindow during cache cleanUp when additional memory allocated EntryStatus back to the caller Expired cannot be differentiated Fixing this by default to and incremental RemoveReasons comment was missing for GetWithInfo api so updated that test ran all unit test cases Currently there is no automation for release noteschangelog see latest and It will be good to have some automation for this so changelog will be created automatically its fine to paste it manually but the text should be done automatically PLEASE if youre going to start working on this issue comment below to discuss the solution thanks in advance Hi I try load to BigCache millions pair keyvalue but unfortunately my golang script took up all the memory gb and was killed by the OS My bigcache config config bigcacheConfig Shards LifeWindow timeMinute MaxEntrySize HardMaxCacheSize Please tell me what am I doing wrong maybe I did the wrong config Or can you tell me another solution for this problem My golang script Hi I have a requirement that when an entry is marked for eviction LifeWindow I want to call a callback function before it gets evicted essentially CleanWindow Was looking at the config object and found out that callbacks are only supported for evictions Can you please share details on whether this can be supported or not I have a problem cache bigcacheNewBigCachebigcacheDefaultConfig timeMinute cacheSetmyuniquekey bytevalue entry cacheGetmyuniquekey fmtPrintlnstringentry cacheSetmyuniquekey bytevalues entry cacheGetmyuniquekey fmtPrintlnstringentry set the same key twice with different valuebigcache can get the newer value but I dont find any code to delete old valueDid the older value is still in memorybut never couldnt get by useror delete it already but I didnt seek out func NewBytesQueueinitialCapacity int maxCapacity int verbose bool BytesQueue return BytesQueue array make byte initialCapacity capacity initialCapacity maxCapacity maxCapacity headerBuffer make byte headerEntrySize tail leftMarginIndex head leftMarginIndex rightMargin leftMarginIndex verbose verbose initialCapacity initialCapacity array and headerBuffer use make to initalize but the second param of make is len if initialCapacity means capactiy it shoud be use as third parammake byte initialCapacity Hi there I want to use bigcache for an index for my own memory database My records have various fields and are indexed by a uint primary key I now want to add secondary indices for columns pointing to primary keys The data structure would look like the following bigcache columnvalue uint uint uint So for example my record has a column city and I want to an index on this column bigcachecityindex newyork pk pk pk From my point of view this cannot be done today because I will have a race condition between get and set calls Right now I am thinking about the following Implement new AppendUint key id Look up shard by key Lock shard Get value Add new id uint to value binaryPutUvarint Set value Unlock shard What are your thoughts about this Thank you Stefan Something like diff diff git abigcachego bbigcachego index b db abigcachego bbigcachego func c BigCache Iterator EntryInfoIterator func c BigCache onEvictoldestEntry byte currentTimestamp uint evict funcreason RemoveReason error bool oldestTimestamp readTimestampFromEntryoldestEntry if currentTimestampoldestTimestamp clifeWindow if intclifeWindow currentTimestampoldestTimestamp clifeWindow evictExpired return true diff git aconfiggo bconfiggo index cc f aconfiggo bconfiggo type Config struct Number of cache shards value must be a power of two Shards int Time after which entry can be evicted No eviction if LifeWindow LifeWindow timeDuration Interval between removing expired entries clean up If set to then no action is performed Setting to second is counterproductive bigcache has a one second resolution diff git ashardgo bshardgo index a f e a ashardgo bshardgo func s cacheShard delkey string hashedKey uint error func s cacheShard onEvictoldestEntry byte currentTimestamp uint evict funcreason RemoveReason error bool oldestTimestamp readTimestampFromEntryoldestEntry if currentTimestampoldestTimestamp slifeWindow if intslifeWindow currentTimestampoldestTimestamp slifeWindow evictExpired return true It appears there is a bounds check before the blockSize but then there is an assumption that adding block size is not out of bounds 