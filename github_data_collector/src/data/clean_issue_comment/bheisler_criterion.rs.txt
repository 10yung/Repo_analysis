I discovered and fixed a panic caused by someone reducing nresamples to a very small number After fixing the panic I added a warning about reducing nresamples to such a low value That warning should become an error in a future breaking change release Alternately should the user even be allowed to configure nresamples I cant think of a use case for it it doesnt meaningfully affect the benchmark time It might speed up analysis on underpowered machines I guess but in that situation the benchmark itself is still likely to dominate One downside of leaving the nresamples function is that it can confuse people who are looking for the samplesize function I wanted to write a benchmark function generic over the measurement such that I can easily benchmark once using cycles and once using time see However there was no way to generically perform the measurements which is why I added this function The clone might not necessarily be required but otherwise lifetime foo would become complicated and usually its a unitstruct anyway See the example in the doccomment for an example usecase Adds a new application argument loadbaseline name This restores raw data from the implementation defined raw dumps and subsequently treats it as if it had just been sampled The dumps are created for all runs early after the sampling and analysis process Note that this requires all benchmarks that are analyzed to have the named baseline previously saved with savebaseline except the last run which can be loaded under the name new The expose command line option requires a comparison baseline to be specified as the option otherwise offers little advantage over the already available csv exporter Open to discussion of the approach and alternatives Also the error behaviour could be adjusted it does not feel correct yet A mechanism to actually importexport sample dumps can be discussed in future issues and PRs or implemented by external tools as filesystem operations Closes currently benchmarks within the same benchmark group may use different time units for displaying this makes it a bit harder to compare at a glance for example one may use nanoseconds and one microseconds they should instead use one unit for the whole group Now that cargo install automatically updates the version if there is a new one available see rustlangcargopull we no longer need to force the installation of mdbook in the documentation CI build Remove that once that change lands in a stable release Motivation Criterions elaborate statistical analysis can only be run on a current newly performed benchmark against some previously established baseline measurement It would also be useful to be able to do a comparison without having to do a new expensive benchmark run and instead utilize two saved measurementsbaselines Use cases Two main use cases come to mind Compare one state of a program against multiple other previous runs such as against the integration branch against master and against the last release But this may also apply to experimentation where several competing ideas should be compared against each other instead of the linear fashion that baseline suggests Allow the analysis to occur on a separate virtual machine than the performance measurement For example when running the performance capture in a separate machine to ensure the better control of the hardware and the runtime environment But the output is persisted into the target directory which is typically wiped in CI and the comparison analysis is not saved at all A current workaround is to capture a the full analysis run but this restricts it to comparing the exact chosen baseline against that CI run Currently Ive only found ways to perform a single measurement at the same time However Id like to measure both the cpu cycles rdtscp and time CLOCKTHREADCPUTIMEID at the same time I could have two benchmarks one with cycles and one with time but I dont want to run the benchmarks twice as they already take in the range of minutes I tried implementing a custom Measurement which uses a tuple of cycles time as Value However it appears that the measurement value will be converted to an f for internal analysis and is pass to the ValueFormatter as an f as well I could think of the following two solutions Let the formatter format the output by passing the original MeasurementValue types Add a function Criterionwithmeasurements dyn Measurement which allows performing multiple measurements during a single run I have a cargo workspace project with a child project that contains benchmarks When I run cargo nightly bench it performs the benchmarking and generates an indexhtml file and various json and csv files However there are no plots or tables or links in the indexhtml report and no other files in that report directory I have gnuplot installed and can run it from the commandline Ive copypasted the fib benchmarks and most of their cargo body div classbody h Criterionrs Benchmark Indexh See individual benchmark pages below for more details ul liFibonacciCustomli liFibonacciCustomcopyli liFibonacciSimpleli liFibonacciSimplecopyli ul div div idfooter pThis report was generated by a href a statisticsdriven benchmarking library in Rustp div body Hi I am using latest rayon from git By adding the criterion to my dependencies cargo is not building the project Here is the error DESKTOP DESKTOP cargo test Updating cratesio index error multiple packages link to native library rayoncore but a native library can be linked only once package rayoncore v homedineshphdrustingrayonrayoncore which is depended on by rayon v homedineshphdrustingrayon which is depended on by continuousdem v homedineshphdpaperstpbsandstonesrccontinuousdem links to native library rayoncore package rayoncore v which is depended on by rayon v which is depended on by criterion v which is depended on by continuousdem v homedineshphdpaperstpbsandstonesrccontinuousdem also links to native library rayoncore I tried to benching a system that has several threads communicating by channels And after I started iterbatched the Criterion givens me some info Benchmarking RawNodecluster Warming up for ms Warning Unable to complete samples in s You may wish to increase target time to s or reduce sample count to Benchmarking RawNodecluster Collecting samples in estimated s iterations 