Im using the suckerpunch ActiveJob queue adapter in a Rails app Ive created a job that bulkfetches pricing data from an API and loads it into postgres via ActiveRecord models Im also abusing the job within a rake task so I can run several of them in parallel since it takes awhile Id say about half the time this works flawlessly and the other half the rake task hangs with the last thing in the log being Enqueued GetPricesJob Job ID a a b a a d e d de f to SuckerPunchdefault with arguments If I hit CtrlC in the rake task two times then the rake task gets an Interrupt and the jobs start to run and finish successfully However the main rake task db transaction gets rolled back due to the Interrupt My rake task looks like this Ive tried with and without the transaction and withconnection wrapper blocks ruby task import environment do SuckerPunchshutdowntimeout ActiveRecordBaseconnectionpoolwithconnection do Importtransaction do do some database work ImportPricesJobperformlatersomeids end end end Is this something that should be possible Or am I breaking suckerpunch in an unsupported way Thanks In Readme it is written ach job acts as its own queue But when using Sucker Punch with Active Job All jobs are executed in one queue Cause I think that this is because the performasync method of the JobWrapper class is called in the SuckerPunchAdapter rb JobWrapperperformasync jobserialize SuckerPunch retrieves job information from job class properties rb SuckerPunchQueuefindorcreateselftos numworkers numjobsmax Hypothesis If this will be fixed like the following it seems possible to run the job in a different queue rb jobclassperformasync jobarguments However this fix makes AcitveJob log incomplete Job start log like the following will be lost ActiveJob SearchJob d d a a c f Performing SearchJob Job ID d d a a c f from SuckerPunchSearchJob with arguments b f e e c dc ea f If you execute the job using ActiveJob Baseexecute as follows the start log is output rb Baseexecute jobserialize If you can separately specify the class calling performasync and the block to be executed you should be able to accomplish both to run the job in a different queue and to log ActiveJob rb jobclassperformasync Baseexecute jobserialize Solution I think that the following modifications are necessary SuckerPunchJobperformasync executes the block when called with block When there is no block it instantiates its own class and perform it rb def performasyncargs block return unless SuckerPunchRUNNINGtrue queue SuckerPunchQueuefindorcreateselftos numworkers numjobsmax if block queuepostargs jobargs runperform block else queuepostargs jobargs runperform selfnewperformjobargs end end And the runperform method executes the received block rb def runperform block SuckerPunchCounterBusynewselftosincrement result blockcall SuckerPunchCounterProcessednewselftosincrement result rescue ex SuckerPunchCounterFailednewselftosincrement SuckerPunchexceptionhandlercallex self args ensure SuckerPunchCounterBusynewselftosdecrement end Conclusions I think this is a good idea Once you agree we will make a pull request Please let me know if you need anything such as tests 