 It would be interesting to see performance of Intel TBB with your microbenchmark I ran into an issue when I tried to get stack to generate prof files with the RTS flags It seems like the stackghc on windows swallows the RTS flags meant for the application This bug means the windows code never even got the N flag and wasnt even parallelized One workaround is to run the benchmarks against the executable directly without calling stack somewhere in stackwork install xxxxxxx bin until this is resolved Project Orleans is the actor framework for net With Rust installed by Linuxbrew on Linux Mint Rosa x based on Trusty when running cargo build release homefabiocargoregistrysrcgithubcom ac ac a afs srcunixrs error mismatched types expected i found u E homefabiocargoregistrysrcgithubcom ac ac a afs srcunixrs let ret unsafe libcposixfallocatefileasrawfd len as offt Sorry not knowledgeable enough in Rust to open a PR but wanted to give it a try nevertheless clojurecoreasync lein run Elapsed time msecs Haskell went from being one of the slowest on Macbook to the fastest in the Linux test case Any indication of whats causing this relative slowdown MemoryCPU Perhaps even OS There is rphmeierskynetjobsteal implementation of this kata which is much better and faster than my own faster on my laptop It would be very cool to see those results in the repos readme I looked at the code found it a bit weird and went on to debug it It seems we have one task running parallel to the Main task and doing if I understand it correctly only an asynchronous reduce aggregate over all synchronous and recursive results Can anyone help me understand this Ive created a stackoverflow question hoping for more attention Out of interest I have included my own implementation in Prolog This is written in my own Prolog which implements Erlangstyle processes and messagepassing It is quite slow as I havent done too much optimisation in this area in fact I just got it working wellenough to run the test at all moduleskynet export start startSizeDiv spawnskynet SizeDiv recvTot writeln Tot skynetNum Div sendNum skynetNumSizeDiv NewSize is Size div Div between DivIdx NewNum is NumIdx NewSize spawnskynetNewNumNewSizeDiv fail skynetNumSizeDiv processsum Div processsumTot sendparentTot processsumTotIdx recvN NewTot is TotN NewIdx is Idx processsumNewTotNewIdx It would be trivially easy to distribute the skynet processes over multiple nodes as sendrecv work transparently over networks as well 