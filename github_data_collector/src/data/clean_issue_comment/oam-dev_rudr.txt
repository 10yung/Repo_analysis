 Thanks for filing an issue Before hitting the button please answer these questions Its helpful to search the existing GitHub issues first Its likely that another user has already reported the issue youre facing or its a known issue that were already aware of Describe in detail the featurebehaviorchange youd like to see Be ready for followup questions and please respond in a timely manner If we cant reproduce a bug or think a feature already exists we might close your issue If were wrong PLEASE feel free to reopen it and explain why The fastest and best way to solve feature request issue is to give a Pull Request yourself OAM Spec Info Rudr will always follow OAM spec if this feature is related with spec definition please make sure they are consistent Is your feature request related to a problem Please describe Id like to scale workloads on other metrics than CPUMemory with the Autoscaler trait Describe the solution youd like Autoscale based on Service Bus queue size Additional context Im translating my KEDA sample to OAM to give an example of what OAM leverages KEDA is already mentioned in the Autoscaler trait but doesnt seem to be supported is that correct Scenario yaml apiVersion coreoamdevv alpha kind ComponentSchematic metadata name orderworkercomponent spec workloadType coreoamdevv alpha Server containers name orderworkercontainer image tomkerkhovekedasampledotnetworkerservicebusqueue env name KEDASERVICEBUSQUEUECONNECTIONSTRING fromParam ServiceBusQueueConnectionstring name PORT fromParam port ports protocol TCP containerPort name http parameters name ServiceBusQueueConnectionstring description Connection string for the Azure Service Bus queue type string required true apiVersion coreoamdevv alpha kind ApplicationConfiguration metadata name orderworkerconfig spec components componentName orderworkercomponent instanceName orderworkercomponent parameterValues name ServiceBusQueueConnectionstring value redacted traits name autoscalercoreoamdevv alpha properties maximum minimim It would be great to add DNS domain and SSL cert via Letsencrypt when a frontend app is deployed via Rudr Currently once we installed Rudr and OAM apps we can only view them via kubectl It would be great if we can have a UI dashboard to list the apps and their traits what capabilities WorkloadTraitScope the platform provides Heres an example how CodeFresh displays helm releases Currently the resources field in the container which describes minimal computing resource to the runtime is optional But as per OAM spec it is mandatory OAM have spec which defines how to run an Application while we also need a standard way to know whether the Application is running well and cooperate with another Application In k s we usually use status of an object to do this kind of work So I think we need some standard way to define the status of OAM object The health scope should have APIs that I can query after a deployment fails and assuming the YAML was valid that will describe to me what went wrong with the deployment For example if I deploy an ApplicationConfiguration and there is an error the Health Scope should be queryable and return information on which components failed to come up and some deeper information as to why kubectl describe healthscope name and it returns a description of the scope and the problems within that scope Create error codes and message formats for those error codes so that errors can be consumedreinterpreted by various clientsRPs Rather than just having details of the error as the string we can also add standardized error code so that any clients using them can reinterpret and inform its client in a better way Add more diagnostics logs to figure out issues sooner The installation of admission controller should be part of rudr installation So that could help rudr to mutate and validate spec applied to rudr Now we have resource minimum in Component definition the operator may want to define resource limit So we need resource limit as a Trait