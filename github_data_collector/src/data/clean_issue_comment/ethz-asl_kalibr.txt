I am trying to calibrate a tof camera TI TINTIN the problem is that for every dataset I always receive the error FATAL No corners could be extracted for the image below Hi I am trying to generate a Depth image using a RGB camera and a point cloud from Ddepth sensor camera In this case it is quite essential to have correct extrinsic information between two cameras to registeroverlay the data from both cameras accurately I am using Kalibr multicamera calibration tool to generate that extrinsic information where I feed gray scale image from RGB camera and IR images from from Ddepth sensor However I see that Kalibr also generates the intrinsic information for all the cameras and I assume that it might be using this information to generate the extrinsic transformation between them In my case I already have the intrinsic information for both of these sensors which are factory calibrated and hence accurate I wanted to know if there is any way where we can give the intrinsic value to the Kalibr multicamera calibration tool as an input so that it can use that information to compute the extrinsic between the camera Secondly the IR images from the Ddepth sensor are x in resolution and RGB camera has x resolution Would the difference in resolution affect the accuracy of the result from multicamera calibration tool Also what should be a good reprojection error for cameras with such resolution I notice that the number of threads is set according to cpu core here however when I really calibrate cameraimu only one thread is been used as I make sure that with system monitor Hi recently I have been reading the codes of kalibrcalibrateimucamera When I read addCameraChainErrorTerms which the function is to add the reprojection error terms for all cameras in the IccSensorspy I have felt uncertainty Here are the codes add the reprojection error terms for all cameras in the chain def addCameraChainErrorTermsself problem poseSplineDv blakeZissermanDf timeOffsetPadding add the induviduak error terms for all cameras for camNr cam in enumerateselfcamList add error terms for the first chain element if camNr initialize the chain with first camerea imu to cam Tchain camTcbDvtoExpression else Tchain camTcbDvtoExpression Tchain from imu coords to camerea N coords as DVs TcNb Tchain add the error terms camaddCameraErrorTerms problem poseSplineDv TcNb blakeZissermanDf timeOffsetPadding I have a question about TcNb In its notes TcNb is from imu coordinate systems b to the Nth camera coordinate systemscN There we assume only two cameras and one imu When the camera number is the first camera Tchain Tc b Then the camNr and Tc b Tc b Tchain where Tchain is Tc b I have no idea about the equation Tchain camTcbDvtoExpression Tchain In my case above the matrix T from imu to second camera is equal to Tc b Tc b In my opinion the Tc b should be Tc c Thank you Mostly involves adding in boost and eigen includes to the various CMakeListstxt Perhaps there is a better way to do this using catkinsimple It still builds fine in Ubuntu eyeCamera L eyeCamera R I try to use Kalibr to calibrate two pointgrey Camera These images almost have no distortion The distance of two cameras is x cm Y Close to Z Close to but the result is wrong Cam resolution Cam model pinholefov I dont know what problem cause the result wrong i had attached my result belowbaseline my camera mm its give correctly but compare with imu distance between cam to imu is mm and imu to camera is but kalibr result are incorrect any idea for this results Transformation cam Tci imu to cam Tic cam to imu timeshift cam to imu s timu tcam shift Transformation cam Tci imu to cam Tic cam to imu timeshift cam to imu s timu tcam shift Baselines Baseline cam to cam baseline norm m Gravity vector in target coords ms In the file BSplinePosecpp there is a word The box times is the linearized transformation way of inverting the jacobian But I dont know how to get this conclusion Could anyone show me which paper refer to Hello after I used kalibrcalibrateimucamera with scalemisalignment option I got following result imu Tib accelerometernoisedensity accelerometerrandomwalk accelerometers M gyroscopenoisedensity gyroscoperandomwalk gyroscopes A e Cgyroi M model scalemisalignment rostopic taraxlimudataraw timeoffset updaterate And i had use this formal cMRB to convert the raw to correct data mmissaliment data Rraw data from camerauncalibrated data B randomwalk i got work result like instants of its this right way to calculate the results or use any other formulas are avalible 