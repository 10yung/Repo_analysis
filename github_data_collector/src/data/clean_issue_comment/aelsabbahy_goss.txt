Describe the feature The default tests include a check on the root filesystem verifying it is mounted with usage under This is not always the case in real life Describe the solution youd like Change the test to be so that tests can be expected to pass on most systems Describe alternatives youve considered Ive changed it temporarily for now so I can work but it is a small change that would make contributing easier Thank you for your pull request Please provide a description above and review the requirements below Bug fixes and new features should include tests and possibly benchmarks Contributors guide CONTRIBUTINGmd Please make sure to review and check all of these items Checklist Remove items that do not apply For completed items change to x x make testall UNIX passes CI will also test this x unit andor integration tests are included if applicable x documentation is changed or added if applicable NOTE these things are not required to open a PR and can be done afterward while the PR is open Description of change Please provide a description of the change here Be sure to use issue references when applicable Add varsinline to dynamically pass variables which can overwrite variables sourced from vars but with no deep merging Closes Thank you for your pull request Please provide a description above and review the requirements below Bug fixes and new features should include tests and possibly benchmarks Contributors guide CONTRIBUTINGmd Please make sure to review and check all of these items Checklist Remove items that do not apply For completed items change to x x make testall UNIX passes CI will also test this x documentation is changed or added update CCTESTREPORTERID with Goss token maintainer task NOTE these things are not required to open a PR and can be done afterward while the PR is open Description of change Please describe the change here Be sure to use issue references when applicable Add Code Coverage support to perform Static Code Analysis as discussed on This is just the initial setup When everyone has visibility into the code problems within Goss the contributors can see how their changes affect the overall quality and the maintainers can make informed decisions The Code Climate PR actions will only be active on PRs that are created after Code Climate is configured and this PR is merged Closes Setup Code Climate Sign up for free to Code Climate for OSS via GitHub Add the Goss Repository on the OSS Dashboard Install Code Climate GitHub App Locate the Repo Settings menu on the Code Climate Repo Page Locate the GitHub menu on the Repo Settings page Enable Summary comments and Delete outdated comments and post a new one Disable Inline issue comments Activate Pull request status updates Install the Webhook on GitHub Locate the Test coverage menu on the Repo Settings page Disable Enforce Diff Coverage and Enforce Total Coverage then save Generate a new TEST REPORTER ID and copy it Replace the CCTESTREPORTERID in this PRs travisyml with the previous Id Verify the Code Climate Webhook is installed on GitHub Describe the bug new semver version match if match is format it fails but if format is passes How To Reproduce package mypkgmasked installed true versions and havelen containelement semverconstraint kernel installed true versions and havelen containelement semverconstraint mypkg info bash rpm qa mypkgmasked info Name mypkgmasked Version Release lrh Expected Behavior expect package to pass Actual Behavior bash usrlocalbingoss g packageversionyaml validate f tap ok Package mypkgmasked installed matches expectation true not ok mypkgmasked version Error Expected a valid semver constraint Got string ok Package kernel installed matches expectation true ok Package kernel version matches expectation Environment v RHEL Some things to note prior to opening a Goss feature request Goss is intended to be quick and easy to learn Goss is focused on the of the rule In other words Goss focuses on the of features that cover the core aspects of OS testing and benefit of users Goss provides a generic command runner to allow users to cover more nuanced test cases If after reading the above you believe your feature is valid within the project scope please submit this feature request Once a feature is submitted it will be reviewed Upon approval the issue can be worked on and PRs can be submitted that implement this new feature Describe the feature A clear and concise description of what the featureproblem Golint should find problems or fail the CI build Describe the solution youd like A clear and concise description of what you want to happen Please provide examples of how you would like this feature to work While its nonfunctional its worrying that golint finds a high quantity of problems during builds Since most problems seem to be documentation it will double as a method to lower the entry barrier to understand Goss internals Describe alternatives youve considered A clear and concise description of any alternative solutions or features youve considered if applicable Some actions can be taken to minimize the issue Increasing golint problem confidence Ignoring certain types of golint problems Simply removing golint Go vet should also be enabled as part of the build Describe the feature Updating the READMEmd Installation section with the proper links to the latest release would improve the usability a lot The described solution can also improve the install script and avoid copypaste confusion Describe the solution youd like Update the links to VERSION according to ownernamereleaseslatestdownloadassetnamezip Describe alternatives youve considered Alternatively you can link to the latest release version v atm Hi I am trying to use a command validation to run a database migration as part of controlling container startstop in a docker compose environment The process is working well so far but I notice that all I get in the output is the result of the tests artisan FailuresSkipped artisan artisan Command dbmigrate exitstatus artisan Expected artisan int artisan to equal artisan int artisan artisan Total Duration s artisan Count Failed Skipped artisan Retrying in s elapsedtimeout time s s Id like to know how to get the stderr from the command to show up after the tests run I noticed there was stdout stderr optional parameters in the guide but I dont quite understand how to use those Thanks This is a great tool Describe the feature Currently DNS checks specify the hostname to resolve as a key The server name to use for resolving is an attribute However if you want to test the same item resolving on multiple DNS servers you cannot do it as the resolving hostname is a unique key in the heira Describe the solution youd like As previously done with the exec resource I would like to add a new attribute resolve which optionally holds the hostname to resolve overriding the key This will allow structures such as dns primaryserver resolve myhostcompanycom server ns companycom resolveable yes secondaryserver resolve myhostcompanycom server ns companycom resolveable yes which will allow you to check correct name resolution from multiple DNS hosts which is not currently possible I also believe that keeping the keys as symbolic only is a better way to work with all the test definition held in the attributes as this allows better control when merging Describe alternatives youve considered It would be possible to use different resolution targets on different DNS servers but this seems untidy and may cause automation or scaling problems Hi I am using podman for some time now and am starting to use goss as validator verifier for ansible and my containers For docker you have the dgoss dcgoss wrapper which is already working fine I request to either extend the existing wrapper to support podman via cli switch add pgos and bgoss for podman and buildah provide cgoss which is a general containergoss wrapper with support for docker podman etc After a confirmation of one of the above I can help to develop this wrapper in the way you prefer Currently all tests are run in parallel which is faster and efficient However some tests may not be able to run in parallel with others or may need to test output created by previous tests Can we add optional scheduling attributes before and after to indicate when a test should not be started until the successful completion of another test This might be a bit of a canoworms as it then requires checks for circular dependencies and a method to start a new thread once its requirements are completed