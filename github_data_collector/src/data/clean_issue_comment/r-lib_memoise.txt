This adds a new cache cachefixedsize which wraps another cache by default cachememory and which drops a keyvalue pair when the size limit is exceeded I think this is useful in long running programs such as shiny apps where you want to limit memory usage By default the cache evicts keys according to a firstin firstout FIFO strategy with a leastrecentlyused LRU eviction strategy also available Eviction strategies follow an API so a user could implement their own Its not here but I guess one could make a similar cache that has a maximum memory size rather than a maximum number of items In that case the same eviction strategies could be used Happy to mess with the nomenclature if desired for instance by calling an eviction strategy a cache replacement policy instead Is this fixed size cache of interest as an addition to this package This could alternatively be moved to an extensions package if its considered too niche My personal view is that limiting the cache size is good programming practice to avoid memory leaks so I think its a good candidate for this package See Having srcrefs in a function causes weird behaviour when it is memoised in the source to a package The hash seems to come out different every time so memoisation doesnt work Yes the docs recommend against that but why not be resilient The qs package is much faster at serialising R objects to file therefore adding as an optional addition selectable via the compress argument x Create cachesetfs and cachegetfs to be shared by cachefilesystem cachegcs and caches x Added tests for all compression options including these new ones X Update documentation internally should simplify the caching logic a lot I am using memoise to perform long and painful scraping so I put the task into the job Heres content of my job r mysum functionx catAdding pastex collapse and result is sumx memsum memoisememoisemysum cachememoisecachefilesystemrcache xlist lapplyxmemsum If I run the job two cache files are produced as expected If I rerun the same job no new caches are created as expected Now I remembered that I have one more address to scrape I come into my job script and modify it r everything above is unchanged xlist lapplyxmemsum Three new files are created Wait a second memoise disregarded the previously created cache because the environment has changed I realize Ive done something wrong I come in and restore things as they were hoping memoise would pick old cache objects r everything above is unchanged xlist lapplyxmemsum Alas memoise creates yet another two objects disregarding everything that happened above Now I have at least three duplicate calls to the same function with same arguments Funny part is that my local environment of course is completely unaware of any of that and theres no way to get to those cached versions r memoisehascachememsum FALSE Not only that but theres also no way to forget or clean those caches now as far as I understand since the Jobs environment is impossible to reproduce Questions Do we have to memoise with the environment signature given that we have an assumption that the function is pure ref How do I recover caches that are related to the same function but created in a different environment Shouldnt there be a way to decrypt the content of cache from my GlobEnv even though the cache has been created in the job Maybe this is for memoisetools by coolbutuseless Hi guys would you be interested in a PR that implements a cacheazure function Basically the Azure storage equivalent to S and GCS Change cachememory function to allow for relative paths in the cache location When returning a datatable from a memoised function the stored memoised result is also modified by datatable operations such as that subassign values by reference While this datatable attribute of modificationbyreference is somewhat common knowledge with datatable users I wouldnt have expected this behavior for datatables returned by memoise perhaps naively assuming that the results stored via memoise would be compartmentalized from any resulting operations Copying the function output fixes the issue as does using the filesystem instead of memory cache see below for an example However I worry that new users may not realize that the memoized results if they output datatables or other objects that can be modified by reference can modify the actual memoized results after they have already been produced Additionally this causes a discrepancy between results depending on the caching method used memory vs filesystem Is there any way to tweak the memoise function or the inmemory environment for cachememory to allow memoise to keep datatable results fixed rather than subject to accidental modification by reference later on in a script librarydatatable librarymemoise basefunction function returndatatablex y Base memoise that returns modified datatable rather than function output memoisedfunction memoisememoisebasefunction data memoisedfunction printdata data z data memoisedfunction Using copy to avoid inplace modification issues forgetmemoisedfunction data copymemoisedfunction data z data memoisedfunction Filesystem cache returns different result than inmemory cache memoisedfilesystem memoisememoisebasefunction cache cachefilesystemtempdir data memoisedfilesystem data z data memoisedfilesystem printdata x y z printdata x y printdata x y Addendum I did notice this closed issue but that issue related to using a memoised function within a datatable while this one is referring to behavior when memoise returns a datatable when the function has multiple default arguments or the default argument is not defined at the end of formal list whether the default values are passed explicitly by call or implicitly by default mechanism may matter fn functionx y fm memoisefn fmx fmy the last call are essentially same but would have called fn twice that is because default values are attached to args ignoring their order in formals sort them in original order would solve this each default arguments not called is assigned to a dedicated environment as promise just like how R initialize evaluation frame of function call and the enclosure of the environment is set to the enclosure of the function then values of default arguments are retrieved from the environment would fix 