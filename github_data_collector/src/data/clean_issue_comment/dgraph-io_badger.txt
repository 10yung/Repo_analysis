The test TestL Stall and TestL Stall would never fail because of error in the manifest file This PR fixes it Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Please answer these questions before submitting your issue Thanks What version of Go are you using go version pre go version go pre What version of Badger are you using Does this issue reproduce with the latest master probably What are the hardware specifications of the machine RAM OS Disk GB ram TB nvme What did you do used badger probably ran out of disk space If possible provide a recipe for reproducing the error A complete runnable program is good What did you expect to see no crashes What did you see instead unexpected fault address x f a d bb fatal error fault signal SIGBUS bus error code x addr x f a d bb pc x e b goroutine running runtimethrow x c dc x usrlibgosrcruntimepanicgo x fp xc c sp xc c pc x ca runtimesigpanic usrlibgosrcruntimesignalunixgo x fp xc c sp xc c pc x runtimememmove xc faf x f a d a b x ce usrlibgosrcruntimememmoveamd s x c fp xc c sp xc c pc x e b githubcomdgraphiobadgerv ySafeCopy homewhygopkgmodgithubcomdgraphiobadgerv v yygo githubcomdgraphiobadgerv ItemValueCopy xc a x x x x x x x x homewhygopkgmodgithubcomdgraphiobadgerv v iteratorgo x fp xc ca sp xc c pc xd d githubcomipfsgodsbadger txnget xc cb xc c x c xc c xc c xc cb x x homewhygopkgmodgithubcomipfsgodsbadger v f e b datastorego xe fp xc cac sp xc ca pc xd a githubcomipfsgodsbadger DatastoreGet xc fa xc c x c x x x x x homewhygopkgmodgithubcomipfsgodsbadger v f e b datastorego x fp xc cba sp xc cac pc xd ac githubcomipfsgodatastorekeytransformDatastoreGet xc d xc bd x xc bd x x d x e xc ea homewhygopkgmodgithubcomipfsgodatastorev keytransformkeytransformgo x fp xc cbf sp xc cba pc x e githubcomipfsgodatastorekeytransformDatastoreGet xc d xc ea x e xc ea x e x x x a homewhygopkgmodgithubcomipfsgodatastorev keytransformkeytransformgo x fp xc cc sp xc cbf pc x e githubcomipfsgoipfsblockstoreblockstoreGet xc d e xc fa x x x x x homewhygopkgmodgithubcomipfsgoipfsblockstorev blockstorego xaf fp xc cd sp xc cc pc x e d f githubcomipfsgoipfsblockstoreidstoreGet xc f fef xc fa x xc a xc f b x xc db homewhygopkgmodgithubcomipfsgoipfsblockstorev idstorego xd fp xc cd sp xc cd pc x e githubcomipfsgoipfsblockstoregcBlockstoreGet xc a xc fa x x f f xc b x x autogenerated x fp xc cda sp xc cd pc x e d githubcomipfsgobitswapdecisionEnginenextEnvelope xc fa c x f eca xc fa e x x x homewhygopkgmodgithubcomipfsgobitswapv decisionenginego x c fp xc cee sp xc cda pc xe githubcomipfsgobitswapdecisionEnginetaskWorker xc fa c x f eca xc fa e homewhygopkgmodgithubcomipfsgobitswapv decisionenginego x bd fp xc cfc sp xc cee pc xe d runtimegoexit usrlibgosrcruntimeasmamd s x fp xc cfd sp xc cfc pc x cc created by githubcomipfsgobitswapdecisionNewEngine homewhygopkgmodgithubcomipfsgobitswapv decisionenginego x bb The rest of the software does a good job of handling the case where the system runs out of disk space but badger seems to not deal with it that well If we could get errors returned instead of faulting like this that would be fine In the current implementation if you happen to always have at least one write transaction open the memory usage of the transaction oracle is unbounded It is actually relatively easy to hit when batch importing data If you have more than one WriteBatch active during the import the transaction oracle will never be cleaned up This is a RFC on an approach to fix this The core idea is to Avoid increasing contention on purely read transactions so only clean up the transaction oracle when write transactions are committed even if technically we could free memory sooner Split the big oraclecommit map into one map per previously committed transaction this allows Go to release memory sooner than when performing deletes on a single map Take advantage of the fact that we have acquired the oracle lock in oraclenewCommitTs to do the cleanup I am assuming here that the number of committedbutstilltracked transactions is small which makes an implementation based on a simple slice reasonable If thats not the case we will need some form of a sorted datastructure ie a btree here Comments welcome Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Travis build randomly fails with RUN TestPagebufferReader FAIL TestPagebufferReader s ytestgo Error Trace ytestgo Error Received unexpected error EOF Test TestPagebufferReader Messages unable to read error RUN TestPagebufferReader PASS TestPagebufferReader s RUN TestPagebufferReader PASS TestPagebufferReader s FAIL coverage of statements FAIL githubcomdgraphiobadgery s see Ive seen the test fail multiple times on various PRs Coverallio integration fails frequently which leads to a failed build We should remove it See example build Please answer these questions before submitting your issue Thanks What version of Go are you using go version pre go version go pre What version of Badger are you using Does this issue reproduce with the latest master yes What do you expect to see Hi we are evaluating to migrate from embedded SQLCipher to Badger As I understand Badger can enable AES encryption using OptionsEncrpytionKey Is it envisaged to add modern encryption algorithms as an option like XChaCha Poly According to cryptographers its far better than AES for multiple reasons the number one being its simplicity Badger uses eventLog to keep track of longrunning background operations These eventLogs are expensive as seen in All the traceeventlog calls should be replaced with loggerDebugf statements Level is very slow for any practical use of badger This PR reduces the compression level from to is the fastest level nocompression nsop MBs zstdcompressionlevel nsop MBs zstdcompressionlevel nsop MBs zstdcompressionlevel nsop MBs Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Please answer these questions before submitting your issue Thanks What version of Go are you using go version What version of Badger are you using What are the hardware specifications of the machine RAM OS Disk CoreOS Stable gb ram for this service gb ram total RAID tb samsung SSDs The issue The disk writes are normal and consistent when writing data to the DB However the disk reads spike dramatically I believe this is due to running the compactions GC All of our data has a hr TTL My question Is there anything we can do to cut down on the disk reads It is negatively impacting other services which are running on this machine We are currently running GC every min Would changing the max levels or anything else relieve this pressure Even if it takes up more space on disk Thanks Move all access to valueLogmaxFid under valueLogfilesLock while all mutations happen either with writes stopped or sequentially under valueLogwrite Fixes a concurrency issue in valueLogRead where the maxFid variable and the writableLogOffset variable could point to two different log files Fixes as a side effect Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend 