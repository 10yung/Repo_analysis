This change fixes compiler misjudgement on whether small functions should be inlined into LZ compressgeneric Since LZ compressgeneric is a big function and it is force inlined the compiler heuristics prevent inlining of small functions which results in excessive code size For example LZ getIndexOnHash is compiled by MSVC as FF A A mov eaxecx FF A A mov eaxdword ptr rdxrax FF A A ret With the following call site in LZ compressgeneric pass tableType even though it is unused FF A A mov r d store h on stack as it is later used in the function but may be changed during the call FF A A mov dword ptr rsp F h ecx FF A B call tracyLZ getIndexOnHash FF A A h With the proposed changes the entire LZ getIndexOnHash call is compiled as FF F mov ecxdword ptr r rdx This has the following effect on compression speed Ryzen X GHz turbo disabled dickens Compression functions LZ compressdefault MBs MBs LZ compressdefaultsmall dst MBs MBs LZ compressdestSize MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfastextState MBs MBs LZ compressfastcontinue MBs MBs LZ compressHC MBs MBs LZ compressHCextStateHC MBs MBs LZ compressHCcontinue MBs MBs LZ compressforceDict MBs MBs ooffice Compression functions LZ compressdefault MBs MBs LZ compressdefaultsmall dst MBs MBs LZ compressdestSize MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfastextState MBs MBs LZ compressfastcontinue MBs MBs LZ compressHC MBs MBs LZ compressHCextStateHC MBs MBs LZ compressHCcontinue MBs MBs LZ compressforceDict MBs MBs Odroid C ARM ooffice Compression functions LZ compressdefault MBs MBs LZ compressdefaultsmall dst MBs MBs LZ compressdestSize MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfast MBs MBs LZ compressfastextState MBs MBs LZ compressfastcontinue MBs MBs LZ compressHC MBs MBs LZ compressHCextStateHC MBs MBs LZ compressHCcontinue MBs MBs LZ compressforceDict MBs MBs Yesterday when I uploaded app binary in Apple AppStore Connect I received the following error message ITMS Nonpublic API usage The app references nonpublic symbols in MYAPPNAME LZ decompresssafe If method names in your source code match the private Apple APIs listed above altering your method names will help prevent this app from being flagged in future submissions Can someone advise a way to solve the problem This PR allows testing on multiple architectures via TravisCI function LZ resetStreamfast is added in LZ attachdictionary at commit f ae c f in order to make sure that changes will not be erased by subsequent calls to LZ resetStreamfast in case stream was marked as having dirty context eg requiring full reset Correspondingly when LZ compressgeneric goto failure cctxdirtyContext is set to However now LZ compressgeneric goto failure no cctxdirty would be set So if cctxdirty in function LZ resetStreamfast makes no sense No body will set this variable to Subject Can we introduce GitHubs issue templates to this project Recently actually recent months Ive observed that therere many vague issues here GitHub issues of LZ project And also I can say that therere many users and potential contributors who are struggling to express their issueproblemconcernimpressions I think GitHubs issue templates helps them a lot Because it has been designed to help normalordinal people who doesnt have technicalbaremetal computing background Especially for this project there must be many people who doesnt have experience with baremetal computer language such as CC but also has interest high performance computing and compression For example electron project has their own template and their typical issue looks like this one EDIT I removed direct link to electron projects issue to avoid auto issue linking Im sorry if someone from the team is looking this issue Imagine a protocol that disallows the compressor to inflate the packet size and we want to use LZ Frame streaming compression Whenever we compress a packet and it gets larger we must send it uncompressed because of the protocol restrictions We now need to reset the compressor and decompressor since the decompressor will never receive the uncompressed block and the compressor has already processed it we just threw out the result We will still send the uncompressed data to the decompressor It would be nice to have a function like LZ FinjectUncompressedBlockLZ Fdctx dctx void const src sizet srcSize That way we dont have to reset the stream Alternatively the user could prepend a fake LZ F block header to the uncompressed data and pass that to the normal decompression function This works with the current LZ version Hello Im looking to compress on an embedded arm platform for decompression on a pc or mobile platform Im using the same format in the examples bit length data bit length data Ive verified through crc that the data on the embedded matches the pc side The code to compress is identical although the code driving the compress has some minor differences that shouldnt affect things Im seeing differences in the compressed data starting about halfway through the first compressed block Source size of output size of bytes arm x This is single threaded at the moment Increased stack to k in case it was a stack overflow Compared byte input block to confirm it matches between ARMx by printing out each byte and a column sum in byte chunks Decompressing the ARM compressed block yields the same data for the first byte chunk I dont have the means to compare the full buffer Is it expected that the algorithm could produce different compressed output between the two platforms but that I should be able to decompress the ARM compressed data on a pcmobile platform The spec doclz Blockformatmd says that a byte means to add that to an accumulator and read another byte It does not specify overflow behavior what to do if eg decoding million consecutive xFF bytes is around billion which is more than Of course a reasonable encoder shouldnt do that but not every encoder is reasonable and a malicious actor passing around a MB file is very feasible It would be great if the spec and various implementations whether C Java JavaScript Python etc which all have different integer semantics could all agree on how to treat this eg is it an error or should it always be uint t modular arithmetic It is possibly a security issue if two different programs disagree on the decoding of some LZ compressed data especially if the first program verifies some sort of safety property before passing it on to the second If I understand the canonical implementation correctly readvariablelength in lz c uses an unsigned The function does have comments that say overflow detection but this checks overflowing the input buffer not overflowing the accumulator Technically sizeofunsigned int depends on the platform A mere copies of an xFF byte could overflow on a bit platform where sizeofint As of v I dont see any stable frame API lz frameh for compressing with a dictionary The LZ FframeInfot struct does have an unsigned dictID field but thats just an ID not the const void dictBuffer sizet dictSize There is a Bulk processing dictionary API but it is guarded by LZ FSTATICLINKINGONLY and my Go program does not staticlink lz The block API lz h does have LZ loadDict in its stable API eg used by examplesdictionaryRandomAccessc I guess I could roll my own format to wrap the block format or roll my own implementation of the frame format and stick to stable LZ API but the existing LZ framing format and its existing unstable API does exactly what I want I know that just bless the existing unstable API as stable can be easier said than done I just want a LZ theproject issue to point people to if Im asked why my program doesnt support LZ theformat dictionaries yet Through release lz releases for Windows included prebuilt shared libraries eg dllliblz so dll Starting with the X line prebuilt dlls are no longer present and instead only a static liblz dlla file is shipped in the dll folder It seems an unconventional change to provide a GCCstyle static file here especially when similar libraries eg zstd stick with the normal convention of shipping a prebuilt Windows dll in the dll folder Prebuilt shared libraries are incredibly convenient for Windows devs thank you to whomever built these in the past A quick scan of lz s X release notes doesnt explain why this changed so I just wanted to see if this was an intentional or accidental change tldr are there plans to include prebuilt Windows DLLs in future lz releases Similarly is there a reason they are no longer provided hopefully no known problems with building lz this way using the provided VS solutions Thank you