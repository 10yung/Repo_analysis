This replaces the waterfall workflow with dumping a serialized DDSketch instead Its not meant to be integrated into rpcperf proper but instead shows how rpcperf can be used to generate latency graphs The graph generation parts within this PR are specialized to my endofinternship presentation so they probably wont generalize to anything beyond comparing two latency distributions However it should be enough to show how to draw these graphs Hello I was looking at testing more complex commands for redis such as mget mset eval evalsha which were supported in the previous version but not in the recent rewrite Ive tried to prototype how I think it could be possible to support commands that have additional options such as the number of keys a script script arguments and so on Ive prototyped for mget and mset and was wondering if my approach was correct here If so Ill continue to add more commands since we are looking at heavily benchmarking different workloads for redis Thanks On client systems that have multiple NICsIP addresses it would be useful to be able to specify which local interface either ip address or interface name eg eth to use for the connection to the server An exampleI have a Gb NIC and a Gb NIC on my client system It is not clear which will be used by rpcperf the current warmup behavior is to spin endlessly on the warmup workloads until the target hit rate is attained however there is the possibility that the target hit rate will never be reached and we should detect this condition by monitoring the hit rate to see if it levels off over some number of windows A few engineers on our team reported that without specifying the request connect timeout setting reconnect on timeout has the old behavior without exponential back off We should make exponential back off the default since it is the most sensible reconnect policy My current use case of rpcperf with explicitly sized dataset involves first configuring rpcperf to send write heavy traffic to warm up the cache then restarting rpcperf with the workload being tested It would be nice if we had a warm up option that would systematically write all keys then automatically transition to the configured workload connect is a fairly expensive operation for the cache server at large volume it can easily overwhelm the server thread accepting new connections temporarily leading to test instabilities Since its currently impossible to coordinate different rpcperf instances at a fine granularity I think we should introduce a few features into the connect behavior to reduce the chance of reconnect storms allow connect to be ratelimited and the rate can be set in the config allow timeouts to be retried with an exponential backoff with a max cap that can be configured Lets add integration tests Initial thought is to have a mock server for each protocol Open to other ideas on this 