 Description Remove usage of GORPOXY let go decide the defaults Motivation and Context custom envs are not needed How to test this PR nothing special to test Types of changes x Bug fix nonbreaking change which fixes an issue New feature nonbreaking change which adds functionality Breaking change fix or feature that would cause existing functionality to change Checklist Fixes a regression If yes please add commitid or PR here Documentation needed Unit tests needed Functional tests needed If yes add mint PR here Provide a general summary of the issue in the Title above Expected Behavior If youre describing a bug tell us what should happen If youre suggesting a changeimprovement tell us how it should work Prometeus monitoring stats of disk usage stats show optdata disk usage not diskstorageuseddiskoptdata e root du hs optdata K optdata Current Behavior If describing a bug tell us what happens instead of the expected behavior If suggesting a changeimprovement explain the difference from current behavior Wrong monitoring stats of disk usage Prometeus monitoring stats show disk usage diskstorageuseddiskoptdata e root df h C devtmpfs M M dev tmpfs M M devshm tmpfs M M M run tmpfs M M sysfscgroup devmappercentosroot G G G devsda M M M boot tmpfs M M runuser Possible Solution Not obligatory but suggest a fixreason for the bug or ideas how to implement the addition or change Change code to display stats shown in paramert diskstorageuseddiskoptdata e not Steps to Reproduce for bugs Provide a link to a live example or an unambiguous set of steps to reproduce this bug Include code to reproduce if relevant Run minio distributed server via reverse proxy nginx install docs Take a look df h and du hs optdata Take a look prometeus stats diskstorageuseddiskoptdata e Context How has this issue affected you What are you trying to accomplish Providing context helps us come up with a solution that is most useful in the real world Regression Is this issue a regression Yes No If Yes optionally please include minio version or commit id or PR that caused this regression if you have these details Your Environment Include as many relevant details about the environment you experienced the bug in Version used minio version RELEASE T Z Environment name and version eg nginx nginx version openresty Server type and version VM Centos Operating System and version uname a el x Link to your project Description For snapshot type profiles record a before profile that can be used as go tool pprof basebefore to compare before and after Before profiles are included in the zipped package runtimeMemProfileRate should not be updated while the application is running so we set it at startup Adds threadcreate as threads profiling as well Motivation and Context Reliable benchmarking tools How to test this PR warp mixed objrandsize serverprofmemcpublockmutex duration m warp Profile data successfully downloaded as warpmixed HCA profileszip unzip warpmixed HCA profileszip Archive warpmixed HCA profileszip extracting profiling mutexbeforepprof extracting profiling mempprof extracting profiling membeforepprof extracting profiling blockpprof extracting profiling blockbeforepprof extracting profiling cpupprof extracting profiling mutexpprof go tool pprof baseprofiling mutexbeforepprof profiling mutexpprof Type delay Time Jan at pm CET Entering interactive mode type help for commands o for options pprof web Types of changes x New feature nonbreaking change which adds functionality Description fix close and drain the response body always Motivation and Context Fix close and drain of response body across the codebase How to test this PR Allows for proper keepalive behavior in nethttp clients observed with liveness checks hitting gateway backends Types of changes x Bug fix nonbreaking change which fixes an issue New feature nonbreaking change which adds functionality Breaking change fix or feature that would cause existing functionality to change Checklist Fixes a regression If yes please add commitid or PR here Documentation needed Unit tests needed Functional tests needed If yes add mint PR here Im running minio in server mode on an edge server for local object storage Every h when disk usage is crawled this results in a peak of CPUmemory usage Since there are quite a few other things running on this edge node this breaks my use case It was working fine with version RELEASE T Z Related documentation about this rss increase Expected Behavior If youre describing a bug tell us what should happen If youre suggesting a changeimprovement tell us how it should work Disk usage calculation does NOT create high peaks in CPUmemory usage Current Behavior If describing a bug tell us what happens instead of the expected behavior If suggesting a changeimprovement explain the difference from current behavior Disk usage calculation creates high peaks in CPUmemory usage Possible Solution Not obligatory but suggest a fixreason for the bug or ideas how to implement the addition or change Disk usage calculation should either run nonaggressively in the background probably preferred or an option provided to turn this feature off Steps to Reproduce for bugs Provide a link to a live example or an unambiguous set of steps to reproduce this bug Include code to reproduce if relevant run minio server observe the high CPUmemory usage every h Context How has this issue affected you What are you trying to accomplish Providing context helps us come up with a solution that is most useful in the real world This prevents me from using minio for local object storage on our edge nodes as these high peaks degrade the performance of the other processes running on the same edge node too much Regression Is this issue a regression Yes No If Yes optionally please include minio version or commit id or PR that caused this regression if you have these details For my usecase this is a clear regression Your Environment Include as many relevant details about the environment you experienced the bug in Version used minio version RELEASE T Z Environment name and version eg nginx Server type and version various smaller x edge nodes Operating System and version uname a Linux Link to your project If i remove a user from a group the user is not removed at all nodes in the cluster i remove the user with the command mc admin group remove from a windows client the server runs under ubuntu command to remove mc admin group remove minio mygroup myuser command to check mc admin user info minio myuser Here an example out put D MinIomc admin user info exanic developer AccessKey developer Status enabled PolicyName MemberOf heidakdevwritenewhomebuildwritenewhomedevwritenewhomeintegrationwrite D MinIomc admin user info exanic developer AccessKey developer Status enabled PolicyName MemberOf heidakdevwritenewhomebuildwritenewhomedevwrite D MinIomc admin user info exanic developer AccessKey developer Status enabled PolicyName MemberOf heidakdevwritenewhomebuildwritenewhomedevwritenewhomeintegrationwrite D MinIomc admin user info exanic developer AccessKey developer Status enabled PolicyName MemberOf heidakdevwritenewhomebuildwritenewhomedevwritenewhomeintegrationwrite D MinIomc admin user info exanic developer AccessKey developer Status enabled PolicyName MemberOf heidakdevwritenewhomedevwritenewhomeintegrationwritenewhomestagingwrite D MinIomc admin user info exanic developer AccessKey developer Status enabled PolicyName MemberOf heidakdevwritenewhomebuildwritenewhomedevwritenewhomeintegrationwritenewhomestagingwrite The commands were carried out one after the other EDIT The Cluster is behind a loadbalancer So you can see many different nodes Expected Behavior the user should removed from the group at all nodes inside the cluster Current Behavior it looks like that the user is only remove at the node it the command executed In the logs at the server i cant found any exception Steps to Reproduce for bugs Create a user and a group Add the user to the group Remove the user from the group Check if the user is removed Your Environment Include as many relevant details about the environment you experienced the bug in Version used minio version T Z Environment name and version eg nginx Server type and version ubuntu lts Operating System and version uname a Linux vstorage generic Ubuntu SMP Wed Sep UTC x x x GNULinux For the building my Minio cluster Minio version RELEASE T Z I used servers server and server Debian stretch On each server I have instances of Mino in the docker containers Docker version every instance has one HDD disk RPM devsdc and devsdd xfs fielsystem ie server instance mounted to homedata instance mounted to homedata server instance mounted to homedata instance mounted to homedata I had a fat directory GB with millions of files inside which I decided to delete from the Minio Web interface After deleting I looked at the graphics and found that disks utilization was on both servers server server So I decided to turn off my cluster each node but after turning back turn on my cluster I saw that my disks operations didnt normalize Then I decided to turn off one of my instances server instance for minimizing disks operations and CPU WA and it a little bit helped I waited for a while and when I look that IO operations for working instance come to normal working I tuned on my second instance and I got the same behavior as in the beginning both disks were eaten Now I turn off my server instance and enable server instance just for test and what I saw the disk was eaten on the graphics you can see two disks blue and purple and how the load is growing when one or another instance is turning on or off I illustrate the graphics of one of the server server disksoperations cpuusage For the debugging I dug strace output for each instance I found the name of the biggest directory that I deleted before the directory with millions of files it has the name prru Then I count for every process openat files from the trace command The strace worked seconds for every instance I disabled one of the instances for the comparing server instance DISABLED for the test server instance strace f p grep openat grep prru tmppr txt cat tmppr txt wc l server instance strace f p grep openat grep prru tmppr txt cat tmppr txt wc l server instance strace f p grep openat grep prru tmppr txt cat tmppr txt wc l The questions are Is it normal behavior for the Minio cluster Why did it happen just after deleting but before it works perfectly some kind of indexing But why for all instances and so aggressive Can I minimize the IO operations Expected Behavior When I use following YAMLs in our OpenShift cluster I would expect that I get a working minio cluster Current Behavior On start I get following error ERROR Invalid command line arguments path data can not be served by different port on same address HINT For more information please refer to Steps to Reproduce for bugs Use the yamls mentioned above on OpenShift v Your Environment Created my own minio Dockerimage based on rhel Description This PR introduces a form of caching for b listbuckets calls clearing the cache and retrying once on any errors thrown removing the need for this to happen on every request In the event that the cached bucket information is invalid the next request will throw an error which can be caught silently the bucket cache updated and the request repeated once This is an nonbreaking change and should not affect users in any way other than saving costs and increasing performance Resolves and Motivation and Context The constant bucket listing calls slow down B integration and cost users Largely eliminating these requests is anticipated to save significant amounts of money and time for users making many requests How to test this PR Use the gateway and monitor the number of b listbuckets calls during testing and benchmark the performance Use a number of random requests against random objects to encourage invalid bucket errors and ensure the expected silent recovery takes place Types of changes x Bug fix nonbreaking change which fixes an issue New feature nonbreaking change which adds functionality Breaking change fix or feature that would cause existing functionality to change Checklist Fixes a regression If yes please add commitid or PR here Documentation needed Unit tests needed Functional tests needed If yes add mint PR here Im trying to develop an app that needs to have an object store and am using minio inside minikube to help me develop it Uploading files to minio seems to work with portforward but the upload gets stuck after transferring of the files when using an ingress Expected Behavior After starting minikube creating a pod for minio and creating an ingress logging in through a browser creating a bucket and adding a file to that bucket will work Current Behavior When adding a file the transfer seems to succeed and reaches However the blue uploading message remains closing it will create a warning that this will abort the upload and aborting it shows that no objects are created Steps to Reproduce for bugs Install minikube Run minikube start After that finished create the following YAML file and apply it with kubectl apply f yaml apiVersion appsv kind StatefulSet metadata name minio spec replicas selector matchLabels app minio serviceName minio template metadata labels app minio spec containers name minio image miniominio ports containerPort name minio args server data env name MINIOACCESSKEY value minio name MINIOSECRETKEY value foobar apiVersion v kind Service metadata name minio labels app minio spec ports port name minio clusterIP None selector app minio apiVersion networkingk siov beta kind Ingress metadata name minio spec rules host minioexamplecom http paths path backend serviceName minio servicePort Create a etchosts entry for minioexamplecom that points to whatever minikube ip points to Open web browser and enter minioexamplecom as URL Log in add a bucket Try to upload a file to that bucket fails Run kubectl portforward svcminio Go back to browser enter localhost as URL Log in add a file to the bucket created in step succeeds note yaml file does not create any volumes for brevity but it fails with a volume too Your Environment Version used minio version T Z runtime Version go CPUs Environment name and version eg nginx docker file inside kubernetes 