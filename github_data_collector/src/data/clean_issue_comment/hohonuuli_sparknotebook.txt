Dear friends I am a beginner of sparkBecause I think the sparkshell is inconvenience to use so I want to use sparkshellscala with jupyter ipython notebook But my scala version is and my spark version is what do you think about it if I git your jupyter scala for the spark work can you give me some advice on the IDE with sparkshellscala Thanks in advance Hong Cheng emailkwchenghonggmailcom Has auto completion been implemented eg ctrlspace There is a binary package of jupyterscala for so I tried to run your code var lines sctextFilesotu BOtxt val wordCountBO lines flatMapsplit maptoLowerCasetrim mapclean mapword word reduceByKey wordCountBOcount and got javaioNotSerializableException orgapachesparkSparkContext This is probably because one of the closures references sc Do you know why I cant load spark from the repo This is what Im getting when I execute loadivyorgapachespark sparkassembly module not found orgapachesparksparkassembly Any idea what is the problem Sorry if this qustione seems to be mundane I am new to the JVM world 