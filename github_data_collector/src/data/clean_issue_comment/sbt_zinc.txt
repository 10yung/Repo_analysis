We might need to support new API to call javac and javadoc programmatically This is but targeting x Closes DiagnosticsReporter was eagerly turning URIs into Files without checking whether or not the URI is indeed a file This adds a check to make sure that the scheme is defined isAbsolute before doing the conversion and calling getAbsolutePath eed si n this targets develop and has as the target version is there any way to get this on x I will gladly do the work to backport if needed Moved over from steps sbt version using run clientcompile add a new line at the end of eg clientsrcmainscalacomolegychscastieclientcomponentsScaladexSearchscala problem unrelated files are recompiled even though no code has actually changed here is a sample debug log expectation only the modified file is recompiled notes this is a scalajs project but ive been assured that this is inconsequential minimizing the problem turned out to be very hard because sometimes the problem goes away only to reappear after clean compile sbt works fine so it appears that some change in caused the regression Currently input and output files are specified in the API in terms of javaioFile The underlying Scala compiler however does not require interaction with the filesystem If inputs and outputs could be handled through inmemory data structures it could open the door for some optimizations in some cases in this case in the project Im aware this is a large issue but figured Id open it to signal support steps sbt version and but sbt works as expected scala problem Files with nested types whose combined names are longer than a certain limit are seen as always needing recompilation by sbt invalidated For me Xmaxclassfilename gives a limit of characters at or beyond that my test file always gets recompiled package foo object ABCD class ABCD object Test val new ABCD ABCD characters long expectation When unchanged the file should not be recompiled no matter how long the type names inside This was the behaviour under sbt notes Transcript MB LengthLimit peterrobinson cat projectbuildproperties sbtversion MB LengthLimit peterrobinson cat LengthTestscala package foo object ABCD class ABCD object Test val new ABCD ABCD characters long MB LengthLimit peterrobinson cat buildsbt scalaVersion scalacOptions SeqXmaxclassfilename MB LengthLimit peterrobinson sbt info Loading settings for project globalplugins from ideasbt info Loading global plugins from Userspeterrobinsonsbt plugins info Loading project definition from privatetmpLengthLimitproject info Loading settings for project lengthlimit from buildsbt info Set current project to lengthlimit in build fileprivatetmpLengthLimit info sbt server started at localUserspeterrobinsonsbt serverb c df d e bb sock sbtlengthlimit compile info Compiling Scala source to privatetmpLengthLimittargetscala classes success Total time s completed Dec sbtlengthlimit compile info Compiling Scala source to privatetmpLengthLimittargetscala classes success Total time s completed Dec sbtlengthlimit The Dependency file was a source of allocations of Tuple objects Given that resolveNonLocalClass is a completely private method does not seem to be used anywhere else and that the second value always flows to a local field assignment we can do that assignment in the procedure and avoid creating the tuple This uses rootPaths to encode VirtualFileRef id As a relatively simple method of abstracting out absolute paths VirtualFileUtilmapSources takes a list of root paths and substitutes them with positional index like Ref Currently Analysis file contains the absolute path of the classes directory As a first step towards reducing machinedependence this replaces it with a dummy value tmpdummy There shouldnt be any downstream effect to build tools Current data structure depends too much on the notion of javaioFile For Zinc I propose we get rid of this notion and abstract it as a virtual file There are various benefits Reduced file size and memory footprint of Analysis data structure Currently its full of absolute path that we have to pass around Repeatable build Cached compilation There has been multiple efforts around build caching and the technique we have been using is mapping the Analysis Pants hoarder etc We could skip this process if Analysis was machineindependent to begin with 