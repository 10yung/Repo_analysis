I need to download and upload to S a really large file GB I need to run this on a serverless environment so I may not necessarily have access to a local disk How can I do this with mechanize Thanks I just tried the following code and this code is still running for last minutes ruby agentpluggableparserdefault MechanizeDownload agentgeturlbody FIxes save and load of MechanizeCookieJar accept as a file path It leads to OS Command Injection How to reproduce PoC of save is the following ruby require mechanize url agent Mechanizenew page agentgeturl loginform pageforms loginformfieldwithname emailvalue xxx loginformfieldwithname passwordvalue zzz page loginformsubmit agentcookiejarsave touch tmpeviltxt Then tmpeviltxt will be created load is the same Environments Mechanize master branch Ruby MRI ruby p revision x darwin From RFC Appendix A The realm parameter is no longer always required on challenges consequently the ABNF allows challenges without any auth parameters This patch makes the realm parameter optional for Basic auth Having said that Im not too sure whether this would be in conflict with RFC section where it says the following about Basic auth The authentication parameter realm is REQUIRED RFC Section Feel free to reject this PR if wed rather keep to the words of RFC andor I have misinterpreted RFC Otherwise comments and suggestions welcome if improvements needed Possibly relevant SO link This PR updates the CI matrix to use latest JRuby JRuby release blog post This does not solve any of the three Zlib Gzip test failures This does not introduce any new failures details Error TestMechanizetestgetgzip IOError footer is not found orgjrubyextzlibJZlibRubyGzipReaderjava in eof orgjrubyextzlibJZlibRubyGzipReaderjava in eof hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in autoio hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in contentencodinggunzip hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in responsecontentencoding hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in fetch hometravisbuildsparklemotionmechanizelibmechanizerb in get hometravisbuildsparklemotionmechanizetesttestmechanizerb in testgetgzip Error TestMechanizetestcontentencodinghooksbodyio ZlibGzipFileNoFooter footer is not found orgjrubyextzlibJZlibRubyGzipReaderjava in read hometravisbuildsparklemotionmechanizetesttestmechanizerb in externalcmd hometravisbuildsparklemotionmechanizetesttestmechanizerb in block in testcontentencodinghooksbodyio hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in block in hookcontentencoding orgjrubyRubyArrayjava in each hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in hookcontentencoding hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in fetch hometravisbuildsparklemotionmechanizelibmechanizerb in get hometravisbuildsparklemotionmechanizetesttestmechanizerb in testcontentencodinghooksbodyio Error TestMechanizetestcontentencodinghooksheader IOError footer is not found orgjrubyextzlibJZlibRubyGzipReaderjava in eof orgjrubyextzlibJZlibRubyGzipReaderjava in eof hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in autoio hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in contentencodinggunzip hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in responsecontentencoding hometravisbuildsparklemotionmechanizelibmechanizehttpagentrb in fetch hometravisbuildsparklemotionmechanizelibmechanizerb in get hometravisbuildsparklemotionmechanizetesttestmechanizerb in testcontentencodinghooksheader details Credential headers Authorization and Cookie are now forwarded to crosssite when redirection Should be cleared these headers before redirection to protect leaking credential info mechanize v socksify patch no working mechanize v working require socksify require socksifyhttp Socksifydebug true class MechanizeHTTPAgent public def setsocks addr port sethttp unless http class http attraccessor socksaddr socksport def httpclass NetHTTPSOCKSProxysocksaddr socksport end end httpsocksaddr addr httpsocksport port end end It seems to be require kconv Kanji converter in the standard Ruby libraries is not used anywhere at all This found in truffleruby which hasnt been kconv yet in this issue This thing was introduced in this commit I saw the other issue about a memory leak in nethttppersistent but even after rolling back to I still see this behaviour require mechanize def meminfo pid size ps ax o pidrss grep E space stripsplitmap toi return size end mech Mechanizenew x while mechget m meminfo if m x then x m p x end end Simply loading a page seems to endlessly consume RAM Surely this isnt expected behaviour