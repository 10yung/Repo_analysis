Before you open an issue please make sure you have tried the following steps Make sure your environment is the same with Have you ever read the document for your usage Check if your issue appears in HOWTODEBUG or FAQ The form below must be filled System information OS Platform and Distribution eg Linux Ubuntu Ubuntu NDK versioneg c b GCC versionif compiling for host eg MACE version Use the command git describe long tags rc Python version Bazel version eg Model deploy file yml yaml The name of library libraryname model targetabis arm v a modelgraphformat file modeldataformat file models sp model tag which will be used in model loading and must be specific platform caffe path to your tensorflow models pb file Support local path http and https modelfilepath modelsspmodelnofcprototxt weightfilepath modelsspmodelnofccaffemodel sha checksum of your models pb file use this command to get the sha checksum sha sum pathtoyourpbfile modelsha checksum f ec f bfcc cb f c e d f f cc fffe b weightsha checksum e be e d a f b f b d a b ecb efc bcdbc ea f a subgraphs inputtensors data inputshapes inputdataformats NCHW outputtensors prefc outputshapes outputdataformats NCHW obfuscate quantize quantizerangefile maceoverallrange runtime cpu cpu gpu or cpugpu or dsp winograd Describe the problem Segmentation fault happens when running quantized depthwise conv d To Reproduce Steps to reproduce the problem bash cd pathtomace python toolsconverterpy convert configfilepathtoyourmodeldeploymentfile python toolsconverterpy run configfilepathtoyourmodeldeploymentfile Error information logs Please include the full log andor traceback here Additional context Models runs fine wo quantization Before you open an issue please make sure you have tried the following steps Make sure your environment is the same with Have you ever read the document for your usage Check if your issue appears in HOWTODEBUG or FAQ The form below must be filled System information OS Platform and Distribution eg Linux Ubuntu NDK versioneg c GCC versionif compiling for host eg MACE version Use the command git describe long tags Python version Bazel version eg Model deploy file yml yaml Describe the problem A clear and concise description of what the bug is To Reproduce Steps to reproduce the problem bash cd pathtomace python toolsconverterpy convert configfilepathtoyourmodeldeploymentfile Error information logs Please include the full log andor traceback here bash LOGs Additional context Add any other context about the problem here eg what you have modified about the code Before you open an issue please make sure you have tried the following steps Make sure your environment is the same with Have you ever read the document for your usage Check if your issue appears in HOWTODEBUG or FAQ The form below must be filled System information OS Platform and Distribution eg Linux Ubuntu NDK versioneg c GCC versionif compiling for host eg MACE version Use the command git describe long tags Python version Bazel version eg Model deploy file yml yaml Describe the problem A clear and concise description of what the bug is To Reproduce Steps to reproduce the problem bash cd pathtomace python toolsconverterpy convert configfilepathtoyourmodeldeploymentfile Error information logs Please include the full log andor traceback here bash LOGs Additional context Add any other context about the problem here eg what you have modified about the code I apologies for posting my question as an issue Im trying to run QualcommHexagonSDK exampleshexagonnntutorials on Xiaomi Mi phone SM SDM Example nopc using libshexagonnn I added pragma weak remotesessioncontrol and hexnncontrollerrequestunsignedpd to nopc Tutorial execution in exampleshexagonnntutorials shows python tutorialswalkthroughpy T sm N Run Examples on cDSP Runing nop adb waitfordevice push root libshexagonnn hexagonDebugdynamictoolv v shiplibhexagonnnskelso datalocaltmpvendorlibrfsaadsp root libshexagonnn hexagonDebugdynamictoolv v shiplibhexagonnnskelso file pushed MBs bytes in s adb waitfordevice push root exampleshexagonnntutorialsandroidDebugaarch ship nop datalocaltmpvendorbin root exampleshexagonnntutorialsandroidDebugaarch ship nop file pushed MBs bytes in s adb waitfordevice shell chmod datalocaltmpvendorbin nop adb waitfordevice shell ADSPLIBRARYPATHdatalocaltmpvendorlibrfsaadsp datalocaltmpvendorbin nop remotesessioncontrol is TRUE remotesessioncontrol returned fastrpcsetup Done Trying to hexagonnnconfig hexagonnnconfig Done hexagonnninit Done hexagonnnappendnode Done hexagonnnprepare Done Trying hexagonnnexecute Whoops run failed Test Failed err logcat shows that remotehandleopen for libhexagonnnskelso was successfull but remotehandleinvoke failed V datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrcfastrpcappsuserc Successfully opened fastrpcshellunsigned V datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrcfastrpcappsuserc Successfully created user PD on domain attrs x V datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrcfastrpcappsuserc remotehandleopen Successfully opened handle xed for hexagonnn on domain D datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrcfastrpcappsuserc Error xffffffff remotehandleinvoke failed for handle xed method on domain sc xc D datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrcfastrpcappsuserc Error xffffffff remotehandleinvoke failed for handle x method on domain sc x E datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrclistenerandroidc listener protocol failure ffffffff D datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrcfastrpcappsuserc Error x remotehandleinvoke failed for handle xed method on domain sc xd D datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrcfastrpcappsuserc Error x remotehandleinvoke failed for handle x method on domain sc x E datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrclistenerandroidc error nErr QAICHEADERadsplistenernext ctx nErr ctx handle sc inBufs inBufsLen inBufsLenReq E datalocaltmpvendorbin nop vendorqcomproprietarycommonsysintfadsprpcsrclistenerandroidc Error x listener thread exited Full example code nopc include remoteh pragma weak remotesessioncontrol hexagonnnh includes most of the things youll need to create and run graphs Its most important includes are nngraphh which includes nngraphifh Together these provide the datatypes for inputoutput tensors and the API youll use for initializing building preparing and running your graphs NOTE hexagonnnh redefines malloc alloc etc so they become a compileerror OOPS MALLOC This is because you should use rpcmemalloc instead include hexagonnnh hexagonnnopsh defines the various graph operations eg MatMul NOP and Relu which you can do Internally it just expands interfaceopsdef into a usable format opsdef contains the list of all implemented ops include hexagonnnopsh For printf etc include stdioh If youre already familiar with SDK programming for the DSP youve probably used fastRPC Theres already lots of examples documenting its use and the purpose of this tutorial is to expose the hexagonnn API so well ignore the fastRPC details For these tutorials we create a couple functions fastrpcsetup and fastrpcteardown and some required includes FastRPC allows our code running on the ARM to call functions located on the DSP quite seamlessly To enable this ARMDSP communication we need to open a channel Well also need to be careful later how we call functions that cross the ARMDSP partition eg sending pointers to ensure the ARM and DSP see the same data include sdkfastrpch The structure of our NOP network looks like this Its really just a NOP floating in space with no inputs or outputs NOP nothing id x nothing int hexnncontrollerrequestunsignedpd int ret if remotesessioncontrol printf remotesessioncontrol is TRUE n struct remoterpccontrolunsignedmodule data dataenable datadomain CDSPDOMAINID ret remotesessioncontrolDSPRPCCONTROLUNSIGNEDMODULE void data sizeofdata printf remotesessioncontrol returned d n ret else printf remotesessioncontrol is FALSE n return ret int mainint argc char argv int err hexnncontrollerrequestunsignedpd Start the ARMDSP communications channel so we can call library functions that execute on the dsp if fastrpcsetup return printffastrpcsetup Done n The nnlib API consists of functions that begin hexagonnn This prefix indicates that the function will actually run on the DSP To run a neural network well use this basic API hexagonnnconfig Start nnlib preparing globals hexagonnninit Initialize a new graph hexagonnnsetdebuglevel Enable debug hexagonnnappendnode Add nodes to the graph hexagonnnappendconstnode Add constants pure data not ops we wont need any for now hexagonnnprepare Allocate memory strategize and optimize the graph for speed hexagonnnexecute Run an inference hexagonnnteardown Destroy the graph free resources Ensures that nnlib is ready to start working printfTrying to hexagonnnconfig n hexagonnnconfig printfhexagonnnconfig Done n Initialize a fresh empty graph Return a graphhandle by reference hexagonnnnnid graphid if hexagonnninit graphid printfWhoops Cannot init n return printfhexagonnninit Done n Set power level to maxturbo if err hexagonnnsetpowersavelevel printfWhoops Cannot set power level d n err goto TEARDOWN Select our debug level none max When creating new graphs its nice to have max debug even if you dont think you need it hexagonnnsetdebuglevelgraphid Append a node to the graph We need to provide a uniqueid so other nodes can connect The operation can be any of the ops found in interfaceopsdef prefixed with OP eg OPMatMulf OPReluf OPMaxPoolf Our NOP node doesnt need any padding because it wont do anything Our inputoutput lists will be NULL in this example but for real graphs well need to connect nodes using these lists hexagonnnappendnode graphid Graph handle were appending into x Node identifier any unique uint OPNop Operation of this node eg Concat Relu NNPADNA Padding type for this node NULL The list of inputs to this node How many elements in input list NULL The list of outputs from this node How many elements in output list printfhexagonnnappendnode Done n Prepare the graph for execution by optimizing it allocating storage connecting all the inputoutput pointers between nodes and doing some basic checks like number of inputoutput tensors and sizing for each node if hexagonnnpreparegraphid printfWhoops Cannot prepare n printfhexagonnnprepare Done n Execute an inference on our input data Real graphs require input and output buffers but well just use zerosize NULL pointers for this NOP example uint t outbatches outheight outwidth outdepth outdatasize printfTrying hexagonnnexecute n if err hexagonnnexecute graphid Our input has dimension NULL Pointer to input data How many total bytes of input unsigned int outbatches unsigned int outheight unsigned int outwidth unsigned int outdepth uint t NULL Pointer to output buffer Max size of output buffer unsigned int outdatasize Actual size used for output printfWhoops run failed d nerr TEARDOWN Free the memory especially if we want to build subsequent graphs hexagonnnteardowngraphid Stop fastRPC fastrpcteardown if err printfTest Passed n else printf Test Failed errd n err return err Before you open an issue please make sure you have tried the following steps Make sure your environment is the same with Have you ever read the document for your usage Check if your issue appears in HOWTODEBUG or FAQ The form below must be filled System information OS Platform and Distribution eg Linux Ubuntu NDK versioneg c GCC versionif compiling for host eg MACE version Use the command git describe long tags Python version Bazel version eg Model deploy file yml yaml libraryname shufflenetv targetabis arm v a modelgraphformat code modeldataformat code models shufflenetv platform onnx modelfilepath modelslmlshufflenetv ssdchangev optonnx modelfilepath modelslmlshufflenetv ssdchangev optonnx modelsha checksum b fcb ff d a b cc e f e cc ac e fa a e cebf modelsha checksum f fc ac c eae d d b d f c dd e fa d datatypes fp fp subgraphs inputtensors inputshapes outputtensors outputshapes onnx backend framwork for validation Suppport pytorchcaffetensorflow Default is tensorflow backend pytorch cpu gpu or cpugpu runtime cpugpu obfuscate winograd Describe the problem A clear and concise description of what the bug is shufflenetv onnx slice end mace build To Reproduce Steps to reproduce the problem bash cd pathtomace python toolsconverterpy convert configfilepathtoyourmodeldeploymentfile Error information logs Please include the full log andor traceback here bash LOGs Additional context Add any other context about the problem here eg what you have modified about the code Before you open an issue please make sure you have tried the following steps Make sure your environment is the same with Have you ever read the document for your usage Check if your issue appears in HOWTODEBUG or FAQ The form below must be filled System information OS Platform and Distribution eg Linux Ubuntu NDK versioneg c GCC versionif compiling for host eg MACE version Use the command git describe long tags Python version Bazel version eg Model deploy file yml yaml Describe the problem A clear and concise description of what the bug is To Reproduce Steps to reproduce the problem bash cd pathtomace python toolsconverterpy convert configfilepathtoyourmodeldeploymentfile Error information logs Please include the full log andor traceback here bash LOGs Additional context Add any other context about the problem here eg what you have modified about the code Hi I have kaldi model and I want to deploy asr on iphone and android phone I successfully deploy the Mobilenet example on my phone but I still dont know how to do with the kaldi model Could you give me an example of speech recognition Thanks a lot Before you open an issue please make sure you have tried the following steps Make sure your environment is the same with Have you ever read the document for your usage Check if your issue appears in HOWTODEBUG or FAQ The form below must be filled System information OS Platform and Distribution eg Linux Ubuntu Ubuntu NDK versioneg c b GCC versionif compiling for host eg MACE version Use the command git describe long tags rc Python version Bazel version eg Model deploy file yml yaml The name of library libraryname FD targetabis arm v a targetsocs rk modelgraphformat file modeldataformat file models RF model tag which will be used in model loading and must be specific platform caffe path to your tensorflow models pb file Support local path http and https modelfilepath modelsmodelprototxt weightfilepath modelsmodelcaffemodel sha checksum of your models pb file use this command to get the sha checksum sha sum pathtoyourpbfile modelsha checksum c e da e da eff d d e ae dcb d e dbd e ad weightsha checksum beffe bc f f b fa f bb f ae eb c a ae c b subgraphs inputtensors data inputshapes inputdataformats NCHW outputtensors facerpnclsprobstride facerpnbboxpredstride facerpnlandmarkpredstride facerpnclsprobstride facerpnbboxpredstride facerpnlandmarkpredstride facerpnclsprobstride facerpnbboxpredstride facerpnlandmarkpredstride facerpnclsprobstride facerpnbboxpredstride facerpnlandmarkpredstride facerpnclsprobstride facerpnbboxpredstride facerpnlandmarkpredstride facerpnclsprobstride facerpnbboxpredstride facerpnlandmarkpredstride outputshapes outputdataformats NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW NCHW obfuscate runtime cpugpu cpu gpu or cpugpu or dsp winograd Describe the problem Inference time on MALI GPUs is very slow compared to other frameworks and a lot slower than the same model running on Adreno GPUs To Reproduce Steps to reproduce the problem bash cd pathtomace python toolsconverterpy convert configfilepathtoyourmodeldeploymentfile python toolsconverterpy benchmark configfilepathtoyourmodeldeploymentfile Error information logs Please include the full log andor traceback here bash LOGs Additional context For example the model running with the above yml file takes ms on a MALI T ms on Adreno ms on MALI T using AlibabaMNN Before you open an issue please make sure you have tried the following steps Make sure your environment is the same with Have you ever read the document for your usage Check if your issue appears in HOWTODEBUG or FAQ The form below must be filled System information OS Platform and Distribution eg Linux Ubuntu Linux ubuntu generic NDK versioneg c r c GCC versionif compiling for host eg MACE version Use the command git describe long tags v rc g d b Python version Bazel version eg Model deploy file yml yaml Describe the problem A clear and concise description of what the bug is When I converted a pretrained kaldionnx model to MACE format model I got an error like Exception Unexpected fc input ndim A dimension of shapea selfgraphshapesdict nodeinputs for GEMM at convertgemmonnxconverterpy is while the program assumes its dimension as Thank you To Reproduce Steps to reproduce the problem bash cd pathtomace python toolsconverterpy convert configfile Error information logs Please include the full log andor traceback here bash Transform model to one that can better run on device onnx model IR version constains ops domain aikaldidnn version Traceback most recent call last File softwaremacebazelbinmacepythontoolsconverterrunfilesmacemacepythontoolsconverterpy line in module mainunusedargs sysargv unparsed File softwaremacebazelbinmacepythontoolsconverterrunfilesmacemacepythontoolsconverterpy line in main outputgraphdef converterrun File softwaremacebazelbinmacepythontoolsconverterrunfilesmacemacepythontoolsconvertertoolonnxconverterpy line in run selfconvertopsgraphdef File softwaremacebazelbinmacepythontoolsconverterrunfilesmacemacepythontoolsconvertertoolonnxconverterpy line in convertops selfopconverters nodeoptype node File softwaremacebazelbinmacepythontoolsconverterrunfilesmacemacepythontoolsconvertertoolonnxconverterpy line in convertgemm Unexpected fc input ndim File softwaremacebazelbinmacepythontoolsconverterrunfilesmacemacepythontoolsconvertutilpy line in macecheck raise Exceptionmsg Exception Unexpected fc input ndim toolsconverterpy YAMLLoadWarning calling yamlload without Loader is deprecated as the default Loader is unsafe Please read for full details configs yamlloadf m Common Configuration key value libraryname callhome targetabis armeabiv a arm v a targetsocs modelgraphformat file modeldataformat file m m Convert callhome model m mLoading m A K mLoading m packages loaded A K mINFO mAnalysed target macepythontoolsconverter packages loaded mBuilding m no action A K mINFO mFound target mBuilding m no action A K m m BazelWorkspaceStatusAction stablestatustxt A KTarget macepythontoolsconverter uptodate m m no action A K bazelbinmacepythontoolsconverter m m no action A K mINFO mElapsed time s Critical Path s m m no action A K mINFO m processes m m no action A K mINFO m Build completed successfully total action m Traceback most recent call last File toolsconverterpy line in module flagsfuncflags File toolsconverterpy line in convertfunc convertmodelconfigs flagsclmemtype File toolsconverterpy line in convertmodel joinmodelconfiggetYAMLKeywordgraphoptimizeoptions File softwaremacetoolsshcommandspy line in genmodelcode fgTrue File locallibpython sitepackagesshpy line in call raise exc shErrorReturnCode RAN anaconda envspy binpython bazelbinmacepythontoolsconverter u platformonnx modelfilebuildsdownloads d e a a ec cbd a pb weightfile modelchecksum f f f ffd b e e e b a e c c c fc c a weightchecksum inputnodeinput inputdatatypesfloat inputdataformatsNONE outputnodeoutputlogsoftmax outputdatatypesfloat outputdataformatsNONE checknode runtimecpu templatemacepythontools modeltagcallhome inputshape inputrange outputshape checkshape dspmode embedmodeldataFalse winograd quantize quantizerangefile changeconcatranges obfuscate outputdirmacecodegenmodelscallhome modelgraphformatfile datatypefp fp graphoptimizeoptions clmemtypeimage STDOUT STDERR Additional context Add any other context about the problem here eg what you have modified about the code Additional context It would help performance if we could directly pass OpenGL textures to MACE for GPU inference without first downloading those to CPU Currently we spend about of our inference time in downloading opengl textures to CPU and preprocessing which can be saved upon if MACE adds support for openclopengl interop 