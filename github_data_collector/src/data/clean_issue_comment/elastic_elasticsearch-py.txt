 queryparams source sourceexcludes sourceincludes fields pipeline refresh routing timeout waitforactiveshards def bulkself body doctypeNone indexNone paramsNone Posted from the source code Can I know the reason of why query parameters dont support version or versiontype field If dont support the version all the es document will not encounter version conflict error and keep updating the document which bothers me a lot Or if I missing something that each bulk item can actually specify version or versiontype value Thanks for your help This PR adds tests as required in Description Since there is no maxretry configuration on helpersparallelbulk the default case seems to retry forever and never stop This is a very strange default behavior and caused my batch processing script to run out of memory This situation is caused by having the elasticsearch database run out of storage space which I easily achieved by filling a default elasticsearch docker container with documents until my partition was filled That lead to the following error with basic curl insertion curl X POST localhost testdocpretty H ContentType applicationjson d key key value Long wait here until I recieved any result error rootcause type clusterblockexception reason blocked by SERVICEUNAVAILABLE no master suppressed type masternotdiscoveredexception reason null type clusterblockexception reason blocked by SERVICEUNAVAILABLE no master suppressed type masternotdiscoveredexception reason null status Since the parallelbulk method retries on responses and it retires an infinite amount of times this becomes a major issue In my case I need to ingest a large amount of small documents into ES on periodic schedule To do this quickly I increased the queuesize and chunksize of the parallelbulk call according to the Elasticsearch documentation In my case an optimal configuration looked like this python for success info in elasticsearchhelpersparallelbulk elastic documents maxretries queuesize chunksize raiseonexceptionTrue raiseonerrorTrue if not success Log any exception or database errors selfloggererrorFailed to insert document s info Despite having raiseonexception and raiseonerror set to true this call continues to consume my iterator and fill up my memory despite every single insertion attempt being stuck on infinite retries I did especially not expect the iterator to continue to be consumed in such a situation Environment Linux Debian Stretch Python with pip install elasticsearch Elasticsearch database running with docker run rm p elasticsearch Expected outcome That the default configuration would be to retry a limited amount of times and that the iterator stops being consumed until the insertion is either aborted or starts working again I would also very much appreciate getting fixed so that we have control over the amount of retires Added bytes param for nodes function The formatted documentation on readthedocsio is not showing recent updates and still refers to as a development version When passing basic auth headers the client calls b encodebbasicauthdecodeutf via the urllib request package Here b is defined as def bs return sencodelatin This causes any non latin to be encoded incorrectly and prevents auth Currently gzip compression and httpcompress parameter handling is only implemented for Urllib HttpConnection so when using alternative RequestsHttpConnection the parameter is ignored and the requests are not compressed which might be unexpected for the users The PR adds gzip compression support to RequestsHttpConnection class Compression is enabled by setting httpcompress constructor parameter to True exactly as in the Urllib HttpConnection elasticsearchpy has support here for simplejson if its installed but does not currently include this dependency as an optional extra in the setup file After running the bulk function to update objects I noticed that the connections are not being reused and are on CLOSEWAIT state Also the garbage collector is not flushing out the connections I have closed the connection pool manually which resulted in flushing out of all CLOSEWAIT connections I am wondering why the library is not able to close connection and why am i having so many CLOSEWAIT connections I have read in few issue reported earlier that the library depends on the gc to collect the connections But in my case it is not able to collect the connections i am wondering why this is happening 