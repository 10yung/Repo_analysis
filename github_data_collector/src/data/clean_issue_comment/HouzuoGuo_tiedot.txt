In from how I can interpret it added json config feature to set how much space tiedot shall use when creating the database yet theres barely any hint of where the documentation is nor any examplesguidelines on how to use it beyond godocs It works well when I check it yesterday it has stores GB data today it grows up to GB it return nothing by http api also by golang script when I use Scrub to fix panic as below panic runtime error makeslice len out of range goroutine running githubcomHouzuoGuotiedotdataCollectionRead xc e x c abd x x x rootgosrcgithubcomHouzuoGuotiedotdatacollectiongo x f githubcomHouzuoGuotiedotdataPartitionForEachDoc xc x x a xc de x rootgosrcgithubcomHouzuoGuotiedotdatapartitiongo xf githubcomHouzuoGuotiedotdbColforEachDoc xc c xc de x d rootgosrcgithubcomHouzuoGuotiedotdbcolgo x githubcomHouzuoGuotiedotdbDBScrub xc d x dff xd x x rootgosrcgithubcomHouzuoGuotiedotdbdbgo x mainmain rootgosrcexamplesmaindbtestgo x e Hi Seems variable numPartsAssumed is unused and it can return error early Please review it Looks like there is a mistake inside recovers inside that file If r is nil it cant match sprintf result so there is something wrong here I would guess that should be changed to but r fmtSprintf also look incorrect Anyway I dont have any context it looks like it tries to test that panic is caught and that the value returned by recover match the expected one Code inside tests doesnt do that in a clear way right now Hello I was playing with Tiedot and came across an interesting scenario I took the example code and modified it to simulate some concurrency Here is my code package main import fmt os time githubcomHouzuoGuotiedotdb githubcomHouzuoGuotiedotdberr func main myDBDir MyDatabase osRemoveAllmyDBDir defer osRemoveAllmyDBDir Create if not exist open a database myDB err dbOpenDBmyDBDir if err nil panicerr Create collections Feeds if err myDBCreateFeeds err nil panicerr Document Management Start using a collection the reference is valid until DB schema changes or Scrub is carried out feeds myDBUseFeeds go func myDB err dbOpenDBmyDBDir if err nil panicerr feeds myDBUseFeeds for Insert document afterwards the docID uniquely identifies the document and will never change docID err feedsInsertmap string interface doc fmtSprintfGo is released d timeNowUnixNano if err nil panicerr Read document readBack err feedsReaddocID if err nil panicerr fmtPrintlnInserting Document docID is readBack if err myDBScrubFeeds err nil panicerr timeSleeptimeMillisecond timeSleeptimeSecond go func myDB err dbOpenDBmyDBDir if err nil panicerr feeds myDBUseFeeds for fmtPrintlnRead looping Process all documents note that document order is undetermined feedsForEachDocfuncid int byte willMoveOn bool fmtPrintlnRead Document id id data err feedsReadid if err nil panicerr fmtPrintlnRead Document read data err feedsDeleteid if dberrTypeerr dberrErrorNoDoc fmtPrintlnRead The document was already deleted else panicerr return true move on to the next document timeSleeptimeMillisecond fmtPrintlnOut of the loops var str string fmtScanln str Gracefully close database if err myDBClose err nil panicerr I tried this on a mac and a linux box and the behavior was exactly the same Looks like foreach locks up after the first read if the first argument to pass type type MapClaims map string interface example how here go if sliceContainsStrtokenClaims JWTENDPOINTSATTR url httpErrorw httpStatusUnauthorized return It switch possibleSlicetype will return interface accordingly the function will never return true go func sliceContainsStrpossibleSlice interface str string bool switch possibleSlicetype case string for elem range possibleSlice string if elem str return true return false I suggest so go func sliceContainsStrpossibleSlice interface str string bool if possibleSlice exist possibleSlice string exist for elem range possibleSlice if elem str return true return false Hi i get the message Bad hash table repair ASAP homexxxgobinonionscandbrelationshipsOnion after scanning an onion site with onionscan my system uname a Linux user generic Ubuntu SMP Thu Jul UTC x x x GNULinux lsbrelease a No LSB modules are available Distributor ID Ubuntu Description Ubuntu LTS Release Codename xenial any ideas Im experiencing strange behaviour when trying to query more complex JSON documents in embedded mode When the document that is inserted inserted to tiedot is created from a string via jsonUnmarshal it can be queried successfully In case it is created from a directly initialized object it can not be queried Example object is taken from the example in documentation Name PenName Joshua PenName John David Consider the following code snippet err collInsertjsonDoc query map string interface eq John in interfaceName PenName queryResult makemap int struct if err dbEvalQueryquery coll queryResult err nil panicerr Query returns any data only in a case when jsonDoc is created as s Name PenName Joshua PenName John David var jsonDoc map string interface jsonUnmarshal bytes jsonDoc but does not work when created as jsonDoc map string interface Name interface map string interface PenName Joshua map string interface PenName stringJohn David From my understanding these two methods of creating jsonDoc are equivalent What Im missing Hey Im starting to use Tiedot now in almost production environment of my project and the randomness of getting the data is starting to get to me Also Im a little concerned about the lack of limits At some point itll suck if someone tries to access some data collection and the query pulls back rows in there right unless there isnt a performance hit for grabbing the documents anyway I read in another issue about the hassle performance hit with ordering data I know that tiedot is similar to MongoDB but I was wondering if there was a way to add createdat or updatedat fields This way you could pull the content based on some created order and then you could have a limiter if needed I dont know much about db development and I know that this doesnt really follow the nosql mongo pattern but I thought it may be a useful solution 