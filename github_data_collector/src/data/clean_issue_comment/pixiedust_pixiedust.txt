As a developer using python I want the Continue execution until the current function returns button to eventually end the debugging session so that I can debug Premise I am on python Tested the code both with a normal kernel and with the pixiedust kernel the debugger should work even outside of the pixiedustspark kernel When running the debugger on the simple example python pixiedebugger import random def findmax values max for val in values if val max max val return max findmaxrandomsamplerange if I click Continue execution until the current function returns until the end of the snippet the debugger gets to python finally Reset our crash handler in place sysexcepthook oldexcepthook in the coroutine python asynciocoroutine def runcodeself codeobj resultNone asyncFalse then it goes through all the internals of asyncio and finally it hangs at python finally selfrestoreinput in the coroutine python gencoroutine def doexecuteself code silent storehistoryTrue userexpressionsNone allowstdinFalse from this moment onwards the button Continue execution until the current function returns is idempotently leaving me on the same line None of the debugger buttons can get me unstack from here As a user type I want to task so that goal make this the title Expected behavior It should show the spark job monitor Actual behavior it shows a error Spark Job Progress Monitoring cannot be started on DSX Steps to reproduce the behavior As a USER I want to user pixiedust in jupyter of windows so that I got the exception in thread main javaioIOException No FileSystem for scheme C Expected behavior jupyter kernel pythonwithpixiedustspark should be able handle path Cspark binhadoop pythonpysparkshellpy Actual behavior Exception in thread main javaioIOException No FileSystem for scheme C at orgapachehadoopfsFileSystemgetFileSystemClassFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemFileSystemjava at orgapachehadoopfsFileSystemaccess FileSystemjava at orgapachehadoopfsFileSystemCachegetInternalFileSystemjava at orgapachehadoopfsFileSystemCachegetFileSystemjava IPKernelApp WARNING Unknown error in handling PYTHONSTARTUP file Cspark binhadoop pythonpysparkshellpy Steps to reproduce the behavior start from command line jupyter lab create a new ipynb page input following from pyspark import SparkContext sc SparkContextlocal First App run them You may see the exception printed in the console of jupyter switch to original kernel Python these two lines can be run without error environment Windows only one hard disk C Anaconda python spark with prebuilt hadoop winutilexe included scala tried but not working set windows enviornment variable SPARKHOMECspark binhadoop change line of createKernelpy as PYTHONSTARTUP file pythonpysparkshellpyformatselfsparkhome As a user type I want to task so that goal make this the title Expected behavior Actual behavior Steps to reproduce the behavior As a user type I want to task so that goal make this the title Expected behavior Expected to get the interactive viewer Actual behavior display nothing Steps to reproduce the behavior read in csv with pdreadcsv displaymydataframe I have tired convert my dataframe to pysparksqldataframeDataFrame But still got nothing As a data analyst I want to create charts with secondary axis such that for primary secondary axis I can have different chart types I have referred to the issue raised in and the only thing that I need is to have one as a bar chart and the other as a line chart rather than bar chart Expected behavior Currently we can only display chart types of the same nature Actual behavior Ability to choose different chart types Steps to reproduce the behavior Option to change chart type of axis is not available currently Regards Ganesh Bhat I cant set break point in a file which the function is not shown in the jupyter note book How can I do it Downloading Total population by country from SSLCertVerificationError Traceback most recent call last miniconda libpython urllibrequestpy in doopenself httpclass req httpconnargs hrequestreqgetmethod reqselector reqdata headers encodechunkedreqhasheaderTransferencoding except OSError as err timeout error miniconda libpython httpclientpy in requestself method url body headers encodechunked Send a complete request to the server selfsendrequestmethod url body headers encodechunked miniconda libpython httpclientpy in sendrequestself method url body headers encodechunked body encodebody body selfendheadersbody encodechunkedencodechunked miniconda libpython httpclientpy in endheadersself messagebody encodechunked raise CannotSendHeader selfsendoutputmessagebody encodechunkedencodechunked miniconda libpython httpclientpy in sendoutputself messagebody encodechunked del selfbuffer selfsendmsg miniconda libpython httpclientpy in sendself data if selfautoopen selfconnect else miniconda libpython httpclientpy in connectself selfsock selfcontextwrapsocketselfsock serverhostnameserverhostname miniconda libpython sslpy in wrapsocketself sock serverside dohandshakeonconnect suppressraggedeofs serverhostname session contextself sessionsession miniconda libpython sslpy in createcls sock serverside dohandshakeonconnect suppressraggedeofs serverhostname context session raise ValueErrordohandshakeonconnect should not be specified for nonblocking sockets selfdohandshake except OSError ValueError miniconda libpython sslpy in dohandshakeself block selfsettimeoutNone selfsslobjdohandshake finally SSLCertVerificationError SSL CERTIFICATEVERIFYFAILED certificate verify failed certificate has expired sslc During handling of the above exception another exception occurred URLError Traceback most recent call last ipythoninput b cd in module popdf pixiedustsampleData miniconda libpython sitepackagespixiedustutilsenvironmentpy in wrapperargs kwargs elif versionstartswith return except Exception as exc raise ExceptionUnable to read spark Version please check your install formatexc return None miniconda libpython sitepackagespixiedustutilssampleDatapy in sampleDatadataId type forcePandas def sampleDatadataIdNone typecsv forcePandasFalse delimiter global dataDefs return SampleDatadataDefs forcePandas delimitersampleDatadataId type class SampleDataobject miniconda libpython sitepackagespixiedustutilssampleDatapy in sampleDataself dataId type if dataId is None selfprintSampleDataList elif strdataId in dataDefs return selfloadSparkDataFrameFromSampleDatadataDefs strdataId elif in strdataId or in strdataId or file in strdataId miniconda libpython sitepackagespixiedustutilssampleDatapy in loadSparkDataFrameFromSampleDataself dataDef df jsonnormalizedata return df def loadSparkDataFrameFromSampleDataself dataDef return DownloaderdataDef selfforcePandasdownloadselfdataLoader miniconda libpython sitepackagespixiedustutilssampleDatapy in downloadself dataLoader req Requesturl None selfheaders printDownloading from formatdisplayName url tdir homesparkshared if EnvironmenthasSpark and not selfforcePandas and ospathexistshomesparkshared else tempfilegettempdir with tempfileNamedTemporaryFiledeleteFalse dirtdir as f bytesDownloaded selfwriteurlopenreq f miniconda libpython urllibrequestpy in urlopenurl data timeout cafile capath cadefault context else opener opener return openeropenurl data timeout def installopeneropener miniconda libpython urllibrequestpy in openself fullurl data timeout req methreq response selfopenreq data postprocess response miniconda libpython urllibrequestpy in openself req data protocol reqtype result selfcallchainselfhandleopen protocol protocol open req if result return result miniconda libpython urllibrequestpy in callchainself chain kind methname args for handler in handlers func getattrhandler methname result funcargs if result is not None return result miniconda libpython urllibrequestpy in httpsopenself req def httpsopenself req return selfdoopenhttpclientHTTPSConnection req contextselfcontext checkhostnameselfcheckhostname httpsrequest AbstractHTTPHandlerdorequest miniconda libpython urllibrequestpy in doopenself httpclass req httpconnargs encodechunkedreqhasheaderTransferencoding except OSError as err timeout error raise URLErrorerr r hgetresponse except URLError urlopen error SSL CERTIFICATEVERIFYFAILED certificate verify failed certificate has expired sslc So Ive been trying to run this file for quite some time I have gotten a ton of help but none seem to work When i drag the openmepy file into a command prompt file and enter it says no module named colorama After tryiny to install colorama with various commands unistalling it reinstalling it all multiple times nothing has worked Even weirder when i try to use the command pip install colorama it says i have it but when i run the file after it says i dont have it Any help would be appreciated Im a total newbie on this so its probably user error but I have a Jupyter Notebook that runs without errors Ive installed pixiedust and am trying to use pixiedebugger as an IDE in a particular cell Running the same cell without the debugger no errors With the debugger and with no breakpoints set if I click continue to next breakpoint yellow play icon I get a name error referring to a variable that is set in the global context I would expect the code to execute the same way with or without the pixiedebugger line of code Any help would be appreciated Thanks 