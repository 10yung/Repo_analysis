I get NPE periodically but it always happens while trying to read when a large number of entries are being written Attached the stacktrace below Details MapDB version MapDB type transaction enabled fileDB Is it Reproducing Always Hi I am getting an NPE in HTreeMapget the stack trace is below The map is created using this code mapdb DBMakerfileDBfilePathtoFile allocateStartSizeALLOCATESTARTSIZE allocateIncrementALLOCATEINCREMENT closeOnJvmShutdown transactionEnable fileMmapEnableIfSupported make metricsMap mapdb hashMapmetrics SerializerSTRING new JacksonSerializerMetricDefinitionclass createOrOpen The key supplied to get is non null and it doesnt exist in the map This is during load tests and there are many concurrent calls to mapgetString key mapputkey value mapvaluesstream mapsize The stack trace javalangNullPointerException null at orgmapdbvolumeByteBufferVolgetSliceByteBufferVoljava at orgmapdbvolumeByteBufferVolgetLongByteBufferVoljava at orgmapdbvolumeReadOnlyVolumegetLongReadOnlyVolumejava at orgmapdbStoreWALgetIndexValStoreWALkt at orgmapdbStoreWALgetStoreWALkt at orgmapdbIndexTreeListJavatreeGetNonBinaryIndexTreeListJavajava at orgmapdbIndexTreeListJavatreeGetIndexTreeListJavajava at orgmapdbIndexTreeLongLongMapgetIndexTreeLongLongMapkt at orgmapdbHTreeMapgetprotectedHTreeMapkt at orgmapdbHTreeMapgetHTreeMapkt Use createOrOpen instead of deprecated make method Ive noticed even using regular value serializer SerializerArray would cause multiple copies of underlying raw bytes Ideally Id like to get only copy for thread safety Whats the simplest way to get byte ByteBuffer for key with minimum number memory copy operations from DirectStore Ive done some code checks and looks like its doable by creating custom deserializer Is it safe to assume what DataInput internalByteBuffer will have copy already ready if its retrieved from DirectStore or there are more copies of memory one should be aware of Thanks Cannot compile on Android This is the error I get Error Method name verifymapdb in class orgmapdbDBMaker cannot be represented in dex format Any idea because I am using coroutines in my project I get error when I try to depend on mapdb ErrorKotlin Supertypes of the following classes cannot be resolved Please make sure you have the required dependencies in the classpath class kotlinxcoroutinesCoroutineExceptionHandlerKey unresolved supertypes kotlincoroutinesCoroutineContextKey Can you please upgrade mapdb to use Please add updte batch future as in RocksDB I need WriteBatchWithIndex Similar to link orgrocksdbWriteBatch but with a binary searchable index built for all the keys inserted Calling put merge remove or putLogData calls the same function as with link orgrocksdbWriteBatch whilst also building an index A user can call link orgrocksdbWriteBatchWithIndexnewIterator to create an iterator over the write batch or link orgrocksdbWriteBatchWithIndexnewIteratorWithBaseorgrocksdbRocksIterator to get an iterator for the database with ReadYourOwnWrites like capability public class WriteBatchWithIndex extends AbstractWriteBatch with methods getFromBatchAndDB newIteratorWithBase containsBatchAndDB dbwritewriteBatch Release example as dbfork here see with Patent Copyright c present Facebook Inc All rights reserved This source code is licensed under both the GPLv found in the COPYING file in the root directory and Apache License found in the LICENSEApache file in the root directory package orgrocksdb Similar to link orgrocksdbWriteBatch but with a binary searchable index built for all the keys inserted Calling put merge remove or putLogData calls the same function as with link orgrocksdbWriteBatch whilst also building an index A user can call link orgrocksdbWriteBatchWithIndexnewIterator to create an iterator over the write batch or link orgrocksdbWriteBatchWithIndexnewIteratorWithBaseorgrocksdbRocksIterator to get an iterator for the database with ReadYourOwnWrites like capability public class WriteBatchWithIndex extends AbstractWriteBatch Creates a WriteBatchWithIndex where no bytes are reserved upfront bytewise comparison is used for fallback key comparisons and duplicate keys operations are retained public WriteBatchWithIndex supernewWriteBatchWithIndex Creates a WriteBatchWithIndex where no bytes are reserved upfront bytewise comparison is used for fallback key comparisons and duplicate key assignment is determined by the constructor argument param overwriteKey if true overwrite the key in the index when inserting a duplicate key in this way an iterator will never show two entries with the same key public WriteBatchWithIndexfinal boolean overwriteKey supernewWriteBatchWithIndexoverwriteKey Creates a WriteBatchWithIndex param fallbackIndexComparator We fallback to this comparator to compare keys within a column family if we cannot determine the column family and so look up its comparator param reservedBytes reserved bytes in underlying WriteBatch param overwriteKey if true overwrite the key in the index when inserting a duplicate key in this way an iterator will never show two entries with the same key public WriteBatchWithIndex final AbstractComparator extends AbstractSlice fallbackIndexComparator final int reservedBytes final boolean overwriteKey supernewWriteBatchWithIndexfallbackIndexComparatornativeHandle fallbackIndexComparatorgetComparatorTypegetValue reservedBytes overwriteKey pPrivate WriteBatchWithIndex constructor which is used to construct WriteBatchWithIndex instances from C side As the reference to this object is also managed from C side the handle will be disownedp param nativeHandle address of native instance WriteBatchWithIndexfinal long nativeHandle supernativeHandle disOwnNativeHandle Create an iterator of a column family User can call link orgrocksdbRocksIteratorInterfaceseekbyte to search to the next entry of or after a key Keys will be iterated in the order given by indexcomparator For multiple updates on the same key each update will be returned as a separate entry in the order of update time param columnFamilyHandle The column family to iterate over return An iterator for the Write Batch contents restricted to the column family public WBWIRocksIterator newIterator final ColumnFamilyHandle columnFamilyHandle return new WBWIRocksIteratorthis iterator nativeHandle columnFamilyHandlenativeHandle Create an iterator of the default column family User can call link orgrocksdbRocksIteratorInterfaceseekbyte to search to the next entry of or after a key Keys will be iterated in the order given by indexcomparator For multiple updates on the same key each update will be returned as a separate entry in the order of update time return An iterator for the Write Batch contents public WBWIRocksIterator newIterator return new WBWIRocksIteratorthis iterator nativeHandle Provides ReadYourOwnWrites like functionality by creating a new Iterator that will use link orgrocksdbWBWIRocksIterator as a delta and baseIterator as a base Updating write batch with the current key of the iterator is not safe We strongly recommand users not to do it It will invalidate the current key and value of the iterator This invalidation happens even before the write batch update finishes The state may recover after Next is called param columnFamilyHandle The column family to iterate over param baseIterator The base iterator eg link orgrocksdbRocksDBnewIterator return An iterator which shows a view comprised of both the database pointintime from baseIterator and modifications made in this write batch public RocksIterator newIteratorWithBase final ColumnFamilyHandle columnFamilyHandle final RocksIterator baseIterator RocksIterator iterator new RocksIteratorbaseIteratorparent iteratorWithBase nativeHandle columnFamilyHandlenativeHandle baseIteratornativeHandle when the iterator is deleted it will also delete the baseIterator baseIteratordisOwnNativeHandle return iterator Provides ReadYourOwnWrites like functionality by creating a new Iterator that will use link orgrocksdbWBWIRocksIterator as a delta and baseIterator as a base Operates on the default column family param baseIterator The base iterator eg link orgrocksdbRocksDBnewIterator return An iterator which shows a view comprised of both the database pointintimefrom baseIterator and modifications made in this write batch public RocksIterator newIteratorWithBasefinal RocksIterator baseIterator return newIteratorWithBasebaseIteratorparentgetDefaultColumnFamily baseIterator Similar to link RocksDBgetColumnFamilyHandle byte but will only read the key from this batch param columnFamilyHandle The column family to retrieve the value from param options The database options to use param key The key to read the value for return a byte array storing the value associated with the input key if any null if it does not find the specified key throws RocksDBException if the batch does not have enough data to resolve Merge operations MergeInProgress status may be returned public byte getFromBatchfinal ColumnFamilyHandle columnFamilyHandle final DBOptions options final byte key throws RocksDBException return getFromBatchnativeHandle optionsnativeHandle key keylength columnFamilyHandlenativeHandle Similar to link RocksDBgetbyte but will only read the key from this batch param options The database options to use param key The key to read the value for return a byte array storing the value associated with the input key if any null if it does not find the specified key throws RocksDBException if the batch does not have enough data to resolve Merge operations MergeInProgress status may be returned public byte getFromBatchfinal DBOptions options final byte key throws RocksDBException return getFromBatchnativeHandle optionsnativeHandle key keylength Similar to link RocksDBgetColumnFamilyHandle byte but will also read writes from this batch This function will query both this batch and the DB and then merge the results using the DBs merge operator if the batch contains any merge requests Setting link ReadOptionssetSnapshotlong long will affect what is read from the DB but will NOT change which keys are read from the batch the keys in this batch do not yet belong to any snapshot and will be fetched regardless param db The Rocks database param columnFamilyHandle The column family to retrieve the value from param options The read options to use param key The key to read the value for return a byte array storing the value associated with the input key if any null if it does not find the specified key throws RocksDBException if the value for the key cannot be read public byte getFromBatchAndDBfinal RocksDB db final ColumnFamilyHandle columnFamilyHandle final ReadOptions options final byte key throws RocksDBException return getFromBatchAndDBnativeHandle dbnativeHandle optionsnativeHandle key keylength columnFamilyHandlenativeHandle Similar to link RocksDBgetbyte but will also read writes from this batch This function will query both this batch and the DB and then merge the results using the DBs merge operator if the batch contains any merge requests Setting link ReadOptionssetSnapshotlong long will affect what is read from the DB but will NOT change which keys are read from the batch the keys in this batch do not yet belong to any snapshot and will be fetched regardless param db The Rocks database param options The read options to use param key The key to read the value for return a byte array storing the value associated with the input key if any null if it does not find the specified key throws RocksDBException if the value for the key cannot be read public byte getFromBatchAndDBfinal RocksDB db final ReadOptions options final byte key throws RocksDBException return getFromBatchAndDBnativeHandle dbnativeHandle optionsnativeHandle key keylength Override protected final native void disposeInternalfinal long handle Override final native int count final long handle Override final native void putfinal long handle final byte key final int keyLen final byte value final int valueLen Override final native void putfinal long handle final byte key final int keyLen final byte value final int valueLen final long cfHandle Override final native void mergefinal long handle final byte key final int keyLen final byte value final int valueLen Override final native void mergefinal long handle final byte key final int keyLen final byte value final int valueLen final long cfHandle Override final native void deletefinal long handle final byte key final int keyLen throws RocksDBException Override final native void deletefinal long handle final byte key final int keyLen final long cfHandle throws RocksDBException Override final native void singleDeletefinal long handle final byte key final int keyLen throws RocksDBException Override final native void singleDeletefinal long handle final byte key final int keyLen final long cfHandle throws RocksDBException Override final native void deleteRangefinal long handle final byte beginKey final int beginKeyLen final byte endKey final int endKeyLen Override final native void deleteRangefinal long handle final byte beginKey final int beginKeyLen final byte endKey final int endKeyLen final long cfHandle Override final native void putLogDatafinal long handle final byte blob final int blobLen throws RocksDBException Override final native void clear final long handle Override final native void setSavePoint final long handle Override final native void rollbackToSavePoint final long handle Override final native void popSavePointfinal long handle throws RocksDBException Override final native void setMaxBytesfinal long nativeHandle final long maxBytes Override final native WriteBatch getWriteBatchfinal long handle private native static long newWriteBatchWithIndex private native static long newWriteBatchWithIndexfinal boolean overwriteKey private native static long newWriteBatchWithIndex final long fallbackIndexComparatorHandle final byte comparatorType final int reservedBytes final boolean overwriteKey private native long iterator final long handle private native long iterator final long handle final long cfHandle private native long iteratorWithBase final long handle final long baseIteratorHandle final long cfHandle private native byte getFromBatchfinal long handle final long optHandle final byte key final int keyLen private native byte getFromBatchfinal long handle final long optHandle final byte key final int keyLen final long cfHandle private native byte getFromBatchAndDBfinal long handle final long dbHandle final long readOptHandle final byte key final int keyLen private native byte getFromBatchAndDBfinal long handle final long dbHandle final long readOptHandle final byte key final int keyLen final long cfHandle The secondary title of Mapdb states MapDB provides concurrent Maps Sets and Queues But I cant find any way to create a queue When I searched I found in the tests here a QueueMaker but I cant use it in my code maybe it doesnt exist in v XX I am using latest stable v How can I create a simple queue Ive analysed your codebase and noticed that orgmapdbioDataIO is not fully tested Ive written some tests for the methods in this class with the help of Diffblue Cover Hopefully these tests will help you detect any regressions caused by future code changes If you would find it useful to have additional tests written for this repository I would be more than happy to look at other classes that you consider important in a subsequent PR Including MapDB dependency triggers sonatype repository scanning from time to time Downloading from sonatypenexussnapshots Downloading from central Downloaded from central kB at Bs And as far as I can tell MapDB depends on both the snapshot and released versions of eclipsecollections