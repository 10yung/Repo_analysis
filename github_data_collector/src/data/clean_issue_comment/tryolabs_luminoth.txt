Bumps tensorflow from to details summaryRelease notessummary Sourced from tensorflows releases TensorFlow Release This is the last x release for TensorFlow We do not expect to update the x branch with features although we will issue patch releases to fix vulnerabilities for at least one year Major Features and Improvements As announced tensorflow pip package will by default include GPU support same as tensorflowgpu now for the platforms we currently have GPU support Linux and Windows It will work on machines with and without Nvidia GPUs tensorflowgpu will still be available and CPUonly packages can be downloaded at tensorflowcpu for users who are concerned about package size TensorFlow contains a complete implementation of the API in its compatv module It contains a copy of the main module without contrib in the compatv module TensorFlow is able to emulate behavior using the enablev behavior function This enables writing forward compatible code by explicitly importing either tensorflowcompatv or tensorflowcompatv you can ensure that your code works without modifications against an installation of or EagerTensor now supports numpy buffer interface for tensors Add toggles tfenablecontrolflowv and tfdisablecontrolflowv for enablingdisabling v control flow Enable v control flow as part of tfenablev behavior and TF BEHAVIOR AutoGraph translates Python control flow into TensorFlow expressions allowing users to write regular Python inside tffunctiondecorated functions AutoGraph is also applied in functions used with tfdata tfdistribute and tfkeras APIS Adds enabletensorequality which switches the behavior such that Tensors are no longer hashable Tensors can be compared with and yielding a Boolean Tensor with elementwise comparison results This will be the default behavior in Auto MixedPrecision graph optimizer simplifies converting models to float for acceleration on Volta and Turing Tensor Cores This feature can be enabled by wrapping an optimizer class with tftrainexperimentalenablemixedprecisiongraphrewrite Add environment variable TFCUDNNDETERMINISTIC Setting to true or forces the selection of deterministic cuDNN convolution and maxpooling algorithms When this is enabled the algorithm selection procedure itself is also deterministic TensorRT Migrate TensorRT conversion sources from contrib to compiler directory in preparation for TF Add additional user friendly TrtGraphConverter API for TensorRT conversion Expand support for TensorFlow operators in TensorRT conversion eg Gather Slice Pack Unpack ArgMin ArgMaxDepthSpaceShuffle Support TensorFlow operator CombinedNonMaxSuppression in TensorRT conversion which significantly accelerates object detection models Breaking Changes Tensorflow code now produces different pip packages tensorflowcore containing all the code in the future it will contain only the private implementation and tensorflow which is a virtual pip package doing forwarding to tensorflowcore and in the future will contain only the public API of tensorflow We dont expect this to be breaking unless you were importing directly from the implementation TensorFlow is built using devtoolset GCC on Ubuntu This may lead to ABI incompatibilities with extensions built against earlier versions of TensorFlow Deprecated the use of constraint and constraint with ResourceVariable tfkeras OMPNUMTHREADS is no longer used by the default Keras config To configure the number of threads use tfconfigthreading APIs tfkerasmodelsavemodel and modelsave now defaults to saving a TensorFlow SavedModel kerasbackendresizeimages and consequently keraslayersUpsampling D behavior has changed a bug in the resizing implementation was fixed Layers now default to float and automatically cast their inputs to the layers dtype If you had a model that used float it will probably silently use float in TensorFlow and a warning will be issued that starts with Layer layername is casting an input tensor from dtype float to the layers dtype of float To fix either set the default dtype to float with tfkerasbackendsetfloatxfloat or pass dtypefloat to each of the Layer constructors See tfkeraslayersLayer for more information Some tfassert methods now raise assertions at operation creation time ie when this Python line executes if the input tensors values are known at that time not during the sessionrun When this happens a noop is returned and the input tensors are marked nonfeedable In other words if they are used as keys in feeddict argument to sessionrun an error will be raised Also because some assert ops dont make it into the graph the graph structure changes A different graph can result in different perop random seeds when they are not given explicitly most often Bug Fixes and Other Changes tfestimator tfkerasestimatormodeltoestimator now supports exporting to tftrainCheckpoint format which allows the saved checkpoints to be compatible with modelloadweights Fix tests in canned estimators Expose Head as public API Fixes critical bugs that help with DenseFeatures usability in TF tfdata Promoting unbatch from experimental to core API Adding support for datasets as inputs to fromtensors and fromtensorslices and batching and unbatching of nested datasets tfkeras tfkerasestimatormodeltoestimator now supports exporting to tftrainCheckpoint format which allows the saved checkpoints to be compatible with modelloadweights Saving a Keras Model using tfsavedmodelsave now saves the list of variables trainable variables regularization losses and the call function Deprecated tfkerasexperimentalexportsavedmodel and tfkerasexperimentalfunction Please use tfkerasmodelssavemodel saveformattf and tfkerasmodelsloadmodel instead Add an implementation mode for tfkeraslayersLocallyConnected D and tfkeraslayersLocallyConnected D layers using tfSparseTensor to store weights allowing a dramatic speedup for large sparse models trtable truncated details details summaryChangelogsummary Sourced from tensorflows changelog Release This is the last x release for TensorFlow We do not expect to update the x branch with features although we will issue patch releases to fix vulnerabilities for at least one year Major Features and Improvements As announced tensorflow pip package will by default include GPU support same as tensorflowgpu now for the platforms we currently have GPU support Linux and Windows It will work on machines with and without Nvidia GPUs tensorflowgpu will still be available and CPUonly packages can be downloaded at tensorflowcpu for users who are concerned about package size TensorFlow contains a complete implementation of the API in its compatv module It contains a copy of the main module without contrib in the compatv module TensorFlow is able to emulate behavior using the enablev behavior function This enables writing forward compatible code by explicitly importing either tensorflowcompatv or tensorflowcompatv you can ensure that your code works without modifications against an installation of or EagerTensor now supports numpy buffer interface for tensors Add toggles tfenablecontrolflowv and tfdisablecontrolflowv for enablingdisabling v control flow Enable v control flow as part of tfenablev behavior and TF BEHAVIOR AutoGraph translates Python control flow into TensorFlow expressions allowing users to write regular Python inside tffunctiondecorated functions AutoGraph is also applied in functions used with tfdata tfdistribute and tfkeras APIS Adds enabletensorequality which switches the behavior such that Tensors are no longer hashable Tensors can be compared with and yielding a Boolean Tensor with elementwise comparison results This will be the default behavior in Breaking Changes Tensorflow code now produces different pip packages tensorflowcore containing all the code in the future it will contain only the private implementation and tensorflow which is a virtual pip package doing forwarding to tensorflowcore and in the future will contain only the public API of tensorflow We dont expect this to be breaking unless you were importing directly from the implementation TensorFlow is built using devtoolset GCC on Ubuntu This may lead to ABI incompatibilities with extensions built against earlier versions of TensorFlow Deprecated the use of constraint and constraint with ResourceVariable tfkeras OMPNUMTHREADS is no longer used by the default Keras config To configure the number of threads use tfconfigthreading APIs tfkerasmodelsavemodel and modelsave now defaults to saving a TensorFlow SavedModel kerasbackendresizeimages and consequently keraslayersUpsampling D behavior has changed a bug in the resizing implementation was fixed Layers now default to float and automatically cast their inputs to the layers dtype If you had a model that used float it will probably silently use float in TensorFlow and a warning will be issued that starts with Layer layername is casting an input tensor from dtype float to the layers dtype of float To fix either set the default dtype to float with tfkerasbackendsetfloatxfloat or pass dtypefloat to each of the Layer constructors See tfkeraslayersLayer for more information Some tfassert methods now raise assertions at operation creation time ie when this Python line executes if the input tensors values are known at that time not during the sessionrun When this happens a noop is returned and the input tensors are marked nonfeedable In other words if they are used as keys in feeddict argument to sessionrun an error will be raised Also because some assert ops dont make it into the graph the graph structure changes A different graph can result in different perop random seeds when they are not given explicitly most often Bug Fixes and Other Changes tfestimator tfkerasestimatormodeltoestimator now supports exporting to tftrainCheckpoint format which allows the saved checkpoints to be compatible with modelloadweights Fix tests in canned estimators Expose Head as public API Fixes critical bugs that help with DenseFeatures usability in TF tfdata Promoting unbatch from experimental to core API Adding support for datasets as inputs to fromtensors and fromtensorslices and batching and unbatching of nested datasets tfkeras tfkerasestimatormodeltoestimator now supports exporting to tftrainCheckpoint format which allows the saved checkpoints to be compatible with modelloadweights Saving a Keras Model using tfsavedmodelsave now saves the list of variables trainable variables regularization losses and the call function Deprecated tfkerasexperimentalexportsavedmodel and tfkerasexperimentalfunction Please use tfkerasmodelssavemodel saveformattf and tfkerasmodelsloadmodel instead Add an implementation mode for tfkeraslayersLocallyConnected D and tfkeraslayersLocallyConnected D layers using tfSparseTensor to store weights allowing a dramatic speedup for large sparse models Enable the Keras compile API experimentalruntffunction flag by default This flag enables single trainingevalpredict execution path With this All input types are converted to Dataset When distribution strategy is not specified this goes through the noop distribution strategy path Execution is wrapped in tffunction unless runeagerlyTrue is set in compile Raise error if batchsize argument is used when input is datasetgeneratorkeras sequence tflite Add GATHER support to NN API delegate tflite object detection script has a debug mode Add delegate support for QUANTIZE Added evaluation script for COCO minival Add delegate support for QUANTIZED BITLSTM Converts hardswish subgraphs into atomic ops Add support for defaulting the value of cyclelength argument of tfdataDatasetinterleave to the number of schedulable CPU cores trtable truncated details details summaryCommitssummary d ee Merge pull request from tensorflowjenkinsrelnotes rc b ac Update RELEASEmd bf Merge pull request from Inteltensorflowmkldnn f ff Merge pull request from tensorflowggadde cp c e Merge pull request from tensorflowggadde finalversion a adeb Update TensorFlow version to in preparation for final relase d a Add saving of loadedtrained compatibility models in test and fix a compatibi c aff Intel Mkl Upgrading MKLDNN to to fix SGEMM regression ea bb Merge pull request from tensorflowperf a ef f Automated rollback of commit db e d c c f e e a bb a Additional commits viewable in compare view details br Dependabot compatibility score Dependabot will resolve any conflicts with this PR as long as you dont alter it yourself You can also trigger a rebase manually by commenting dependabot rebase dependabotautomergestart dependabotautomergeend details summaryDependabot commands and optionssummary br You can trigger Dependabot actions by commenting on this PR dependabot rebase will rebase this PR dependabot recreate will recreate this PR overwriting any edits that have been made to it dependabot merge will merge this PR after your CI passes on it dependabot squash and merge will squash and merge this PR after your CI passes on it dependabot cancel merge will cancel a previously requested merge and block automerging dependabot reopen will reopen this PR if it is closed dependabot ignore this patchminormajor version will close this PR and stop Dependabot creating any more for this minormajor version unless you reopen the PR or upgrade to it yourself dependabot ignore this dependency will close this PR and stop Dependabot creating any more for this dependency unless you reopen the PR or upgrade to it yourself dependabot use these labels will set the current labels as the default for future PRs for this repo and language dependabot use these reviewers will set the current reviewers as the default for future PRs for this repo and language dependabot use these assignees will set the current assignees as the default for future PRs for this repo and language dependabot use this milestone will set the current milestone as the default for future PRs for this repo and language You can disable automated security fix PRs for this repo from the Security Alerts page details I can predict in a dataset on top level of a folder its a great feature of Luminoth but can I predict over all subfolders in a recursively way I imagine something like lumi predict r Maybe its not de purpose of this tool then is there a way to do this in bash I want to modify the VGG layers by changing some of them to atrous convolution and am wondering if this library supports that If so what is the best way on how to do that I already have an idea but am curious if you guys who know the code know the best way After modifying the layers Im also going to use the feature map from an earlier one but I know this is already supported because I read the code Thank you very much people for beautiful clean library I read the article on how frcnn works and ever since then I never forget I made a model using Luminoth and it works well But now I have to use the model In local i used a python script detector DetectorcheckpointGoogleModel result detectorpredictimage All work well But now I have to use it on a webpage so I used WampServer to make it in local A php file call the python script but I have the error Checkpoint not found Check remote repository yN I think its because all my checkpoints are in local but i dont know how use them online I tought download Luminoth on the WampServer and import the checkpoint but I dont know how do that Thank you for your help The onlyclasses option is not filtering out the classes I desire Currently I have the following lumi dataset transform type pascal datadir datasetspascal VOCdevkitVOC outputdir datasetspascaltf split train onlyclassescar However all classes are being read according to what is being outputted to my screen I objectdetectionwriterpy Saved records to datasetspascaltf traintfrecords I transformpy Composition per class train I transformpy person I transformpy car I transformpy chair I transformpy bottle I transformpy pottedplant I transformpy bird I transformpy dog I transformpy sofa I transformpy boat I transformpy horse I transformpy bicycle I transformpy motorbike I transformpy cat I transformpy tvmonitor I transformpy sheep I transformpy cow I transformpy train I transformpy aeroplane I transformpy diningtable I transformpy bus lumi checkpoint info id or alias config displays the config info The baseconfigyml includes these options under model basenetwork From which file to load the weights weights Should we download weights if not available download True As far as I can tell these are not used in the code What is the intended use of these settings Is there any way to specify the location of the base network checkpoint besides changing the LUMIHOME environment variable to set a different default path I have trained a Faster RCNN model including the final RCNN module Now the final output contains bounding boxes and class probabilities But I want to know the classindependent bounding boxes and their objectness scores which is what the RPN module gives from the same model Can anyone help me how to get them in Luminoth Any help is much appreciated We have a special dataset about extreme weather The dataset has channels and the size of the image is px which is totally different from the ImageNet We want to implement end to end training based on this dataset The FasterRCNN is composed of three parts base network RPN RCNN The base network usually is a pretrained CNNeg ResNet VGG for extracting features but only ImageNetbased pretrained model can be found because our dataset is not common So the question is can we implement end to end training without a pretrained base network Or does the endtoend training of FasterRCNN include the parameters in the base network I have seen many works about endtoend training but they all use the pretrained model as their base network and seems only train the RPN and RCNN Hey Firstly this is cool project I read that youve plans to implement Retinanet and MaskRCNN If anyone is working on this id like to collaborate on it If not then I can try implementing these I need a green signal from the maintainers to get started Thanks Christie 