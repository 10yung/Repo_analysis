Looking at how the theta property is computed in the abstract base class Kernel in sklearngaussianprocesskernelpy Python property def thetaself theta params selfgetparams for hyperparameter in selfhyperparameters if not hyperparameterfixed thetaappendparams hyperparametername if lentheta return nplognphstacktheta else return nparray then it is apparent that the names of the hyperparameters are obtained from the hyperparameters property while the values are looked up using the names from params as returned from getparams However it looks like each Hyperparameter instance already contains a value field As such I wonder why this field is not used leading to something like Python property def thetaself theta for hyperparameter in selfhyperparameters if not hyperparameterfixed thetaappendhyperparametervalue if lentheta return nplognphstacktheta else return nparray Could someone help me understand this jmetzen jnothman While using the bostonhousing data set a data set hosted by the Scikitlearn package and used to demo models on house price prediction I came across a feature titled B This struck me as odd because all other features had been given descriptive names such as AGE or TAX It turns out that B Bk where Bk is the proportion of blacks by town I naively assumed as this data was being hosted by a prestigious package that these data were in the data set because they offer significant explanatory value which would point to a strongly pervasive racist mentality in the population at the time However after reading the blog post attached below it appears as though the data in the B feature of the Boston housing data set were manufactured in an attempt to encourage segregation of the races If true this would be strong evidence of systemic institutional racism and by continuing to use this fraudulent data we would be perpetuating the effect desired by the author I hope you will agree that we would be doing the scientific literature a service by investigating this issue further and ultimately consigning this data to historic reference archives and not encouraging its use in modern research by hosting it I look forward to your response Jamie R Sykes Reference IssuesPRs What does this implementfix Explain your changes Use checksampleweight to validate sampleweight in KernelRidge I realised after and also a lecture that I gave that we dont add TrueFalse YesNo above the arrow in plottree Therefore we know the criterion for the decision and the further splits but we dont have any idea what path a sample will take or at least it makes it more difficult to infer it I think that we should annotate the arrow depending if the comparison in the node is TrueFalse amueller NicolasHug thomasjpfan WDYT Describe the bug When I try and run agglomerative clustering with a precomputed distance matrix I get a ValueError as follows ValueError Precomputed metric requires shape nqueries nindexed Got for indexed I looked up similar past bugs and they said it was because the distance matrix was not square However I checked the shape and it is indeed square I even ran the scikit learn checkpairwisearrays function on it with precomputed set to True and confirmed that the matrix returned was the same The code is attached below in a zip file agglomerativetestzip any help would be appreciated StepsCode to Reproduce import numpy as np import sklearncluster from sklearnmetricspairwise import checkpairwisearrays connectivitymatrix nploadconnectivitymatrix npy remappedaffinitymatrix nploadremappedaffinitymatrix npy P D remappeddistancethreshold updatedconnectivitymatrix checkpairwisearraysconnectivitymatrix connectivitymatrix precomputedTrue updatedremappedaffinitymatrix checkpairwisearraysremappedaffinitymatrix remappedaffinitymatrix precomputedTrue printconnectivity is same npallnpequalupdatedconnectivitymatrix connectivitymatrix printremapped is same npallnpequalremappedaffinitymatrix updatedremappedaffinitymatrix clusterer sklearnclusterAgglomerativeClusteringnclustersNone computefulltreeTrue affinityprecomputed connectivityconnectivitymatrix linkagecomplete distancethresholdremappeddistancethreshold printremapped affinity matrix size remappedaffinitymatrixshape printconnectivity matrix size connectivitymatrixshape printremapped affinity is symetric npallnpequalremappedaffinitymatrix remappedaffinitymatrixT printconnectivity is symetric npallnpequalconnectivitymatrix connectivitymatrixT clustererfitremappedaffinitymatrix The actual data is in the zip file attached Expected Results connectivity is same True remapped is same True remapped affinity matrix size connectivity matrix size remapped affinity is symetric True connectivity is symetric True and then the code would run without error Actual Results connectivity is same True remapped is same True remapped affinity matrix size connectivity matrix size remapped affinity is symetric True connectivity is symetric True UsershumzaiqbalLibraryPython libpythonsitepackagessklearnclusteragglomerativepy UserWarning the number of connected components of the connectivity matrix is Completing it to avoid stopping the tree early affinityaffinity Traceback most recent call last File agglomerativetestpy line in module clustererfitremappedaffinitymatrix File UsershumzaiqbalLibraryPython libpythonsitepackagessklearnclusteragglomerativepy line in fit kwargs File usrlocallibpython sitepackagesjoblibmemorypy line in call return selffuncargs kwargs File UsershumzaiqbalLibraryPython libpythonsitepackagessklearnclusteragglomerativepy line in completelinkage return linkagetreeargs kwargs File UsershumzaiqbalLibraryPython libpythonsitepackagessklearnclusteragglomerativepy line in linkagetree affinityaffinity File UsershumzaiqbalLibraryPython libpythonsitepackagessklearnclusteragglomerativepy line in fixconnectivity D pairwisedistancesXi Xj metricaffinity File UsershumzaiqbalLibraryPython libpythonsitepackagessklearnmetricspairwisepy line in pairwisedistances forceallfiniteforceallfinite File UsershumzaiqbalLibraryPython libpythonsitepackagessklearnmetricspairwisepy line in checkpairwisearrays Xshape Xshape Yshape ValueError Precomputed metric requires shape nqueries nindexed Got for indexed Versions System python default Jul Clang clang executable usrlocaloptpythonbinpython machine Darwin x i bit Python dependencies pip setuptools sklearn numpy scipy Cython pandas matplotlib joblib Thanks for contributing Reference IssuesPRs In relation to this request What does this implementfix Explain your changes Format of values plotted in confusion matrix Attempting to reduce memory footprint of Birchpredict Please see solution description at issue Benchmark script to be added soon Its really nice that transformers such as sklearnpreprocessingOneHotEncoder and sklearnpreprocessingStandardScaler can operate on multiple data columns simultaneously sklearnfeatureextractiontextTfidfVectorizer on the other hand can only process one column at a time so you need to make a new transformer for each text column in your dataset This can get a little tedious and in particular makes pipelines more verbose Itd be nice if TfidfVectorizer could also operate on multiple text columns using the same settings for each column perhaps with an option to make one vocabulary per column or use a shared vocabulary across all the columns It might be easiest to implement this as a new class that wraps TfidfVectorizer sagemakerscikitlearnextension takes this approach If this seems like a good idea Id be happy to make a PR Within the RANSAC algorithm a residual threshold is calculated residualthreshold npmediannpabsy npmediany If more than half of the values of y are equal to the median of y this returns a residual threshold of In that case the line inliermasksubset residualssubset residualthreshold always returns zero inliers causing a value error since inliermaskbest is always None The current cross validation procedure adopted in the CalibratedClassifierCV does not follow the cross validation procedure described in the original Platt paper Platt Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods J Platt I checked also the other papers cited in the references for the CalibratedClassifierCV class and none of them describes the cross validation process it implements CalibratedClassifierCV currently fits and calibrates an estimator for each fold calibration is performed on the test part of the fold All the estimators fit at each fold are kept in a list At prediction time every estimator makes a prediction and the average of the returned values is the final prediction The estimator produced by CalibratedClassifierCV is thus an ensemble and not a single estimator calibrated on the whole training set via CV When using cross validation the original baseestimator is not used to make the prediction Platt describes a cross validation procedure that fits an estimator on each fold and the predictions for the test fold are saved Then the predictions from all the folds are concatenated in a single list and calibration parameters for the baseestimator are determined using such list Cross validation should be only a mean to calibrate the baseestimator on the same data it has been fit not to fit a different estimator The procedure described in Platt is what one would expect from a proper application of a cross validation procedure as the cross validation only determines the parameters of the calibration and does not fit the estimator It is also more efficient as is does not store the estimators for each fold and requires a single predict at prediction time 