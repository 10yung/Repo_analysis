I added a section on readme to inform users about the state of the project Druid docs say that it is not the recommended way to ingest data See here and here We should let people now that when they stumble upon this repository that there might be a better way to ingest data tranquility druid run bintranquility server configFile confserverjson DdruidextensionsloadList druiddatasketches Ddruidextensionsdirectoryusrlocaldruid extensions in serverjson i add metricsSpec name count type count namesketchuid typethetaSketch fieldNameuid isInputThetaSketchfalse size output main INFO idinitializationInitialization Loading extension druiddatasketches for class iodruidinitializationDruidModule main INFO idinitializationInitialization added URL fileusrlocaldruid extensionsdruiddatasketchescommonsmath jar main INFO idinitializationInitialization added URL fileusrlocaldruid extensionsdruiddatasketchesdruiddatasketches incubatingjar main INFO idinitializationInitialization added URL fileusrlocaldruid extensionsdruiddatasketchesmemory jar main INFO idinitializationInitialization added URL fileusrlocaldruid extensionsdruiddatasketchessketchescore jar main INFO idinitializationInitialization added URL fileusrlocaldruid extensionsdruiddatasketchesslf japi jar main INFO cmetamxemittercoreLoggingEmitter Start started true main WARN iodruidsegmentindexingDataSchema No metricsSpec has been specified Are you sure this is what you want main WARN iodruidsegmentindexingDataSchema No metricsSpec has been specified Are you sure this is what you want main INFO cmetamxemittercoreLoggingEmitter Start started true main WARN iodruidsegmentindexingDataSchema No metricsSpec has been specified Are you sure this is what you want javalangIllegalArgumentException Could not resolve type id thetaSketch into a subtype of simple type class iodruidqueryaggregationAggregatorFactory at Source NA line column through reference chain Object at comfasterxmljacksondatabindObjectMapperconvertObjectMapperjava at comfasterxmljacksondatabindObjectMapperconvertValueObjectMapperjava at commetamxtranquilitydruidDruidBeamsmakeFireDepartmentDruidBeamsscala at commetamxtranquilitydruidDruidBeamsfromConfigInternalDruidBeamsscala at commetamxtranquilitydruidDruidBeamsfromConfigDruidBeamsscala at commetamxtranquilityserverhttpServerMainanonfun applyServerMainscala at commetamxtranquilityserverhttpServerMainanonfun applyServerMainscala at commetamxcommonscalacollectionpackageMapLikeOpsanonfunstrictMapValues applypackagescala at commetamxcommonscalacollectionpackageMapLikeOpsanonfunstrictMapValues applypackagescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionTraversableLikeanonfunmap applyTraversableLikescala at scalacollectionimmutableMapMap foreachMapscala at scalacollectionTraversableLikeclassmapTraversableLikescala at scalacollectionAbstractTraversablemapTraversablescala at commetamxcommonscalacollectionpackageMapLikeOpsstrictMapValuespackagescala at commetamxtranquilityserverhttpServerMaincreateServletServerMainscala at commetamxtranquilityserverhttpServerMainmainServerMainscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at comtwitterappAppanonfunnonExitingMain applyAppscala at comtwitterappAppanonfunnonExitingMain applyAppscala at scalaOptionforeachOptionscala at comtwitterappAppclassnonExitingMainAppscala at commetamxtranquilityserverhttpServerMainnonExitingMainServerMainscala at comtwitterappAppclassmainAppscala at commetamxtranquilityserverhttpServerMainmainServerMainscala at commetamxtranquilitydistributionDistributionMainmainDistributionMainscala at commetamxtranquilitydistributionDistributionMainmainDistributionMainscala Caused by comfasterxmljacksondatabindJsonMappingException Could not resolve type id thetaSketch into a subtype of simple type class iodruidqueryaggregationAggregatorFactory at Source NA line column through reference chain Object at comfasterxmljacksondatabindJsonMappingExceptionfromJsonMappingExceptionjava at comfasterxmljacksondatabindDeserializationContextunknownTypeExceptionDeserializationContextjava format json at comfasterxmljacksondatabindjsontypeimplTypeDeserializerBasefindDeserializerTypeDeserializerBasejava at comfasterxmljacksondatabindjsontypeimplAsPropertyTypeDeserializerdeserializeTypedForIdAsPropertyTypeDeserializerjava at comfasterxmljacksondatabindjsontypeimplAsPropertyTypeDeserializerdeserializeTypedFromObjectAsPropertyTypeDeserializerjava at comfasterxmljacksondatabinddeserAbstractDeserializerdeserializeWithTypeAbstractDeserializerjava at comfasterxmljacksondatabinddeserstdObjectArrayDeserializerdeserializeObjectArrayDeserializerjava at comfasterxmljacksondatabinddeserstdObjectArrayDeserializerdeserializeObjectArrayDeserializerjava at comfasterxmljacksondatabinddeserSettableBeanPropertydeserializeSettableBeanPropertyjava at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeUsingPropertyBasedBeanDeserializerjava at comfasterxmljacksondatabinddeserBeanDeserializerBasedeserializeFromObjectUsingNonDefaultBeanDeserializerBasejava at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeFromObjectBeanDeserializerjava at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeBeanDeserializerjava at comfasterxmljacksondatabinddeserSettableBeanPropertydeserializeSettableBeanPropertyjava at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeUsingPropertyBasedBeanDeserializerjava at comfasterxmljacksondatabinddeserBeanDeserializerBasedeserializeFromObjectUsingNonDefaultBeanDeserializerBasejava at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeFromObjectBeanDeserializerjava at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeBeanDeserializerjava at comfasterxmljacksondatabindObjectMapperconvertObjectMapperjava I use the version sql query eq select auuid from db a where auuid not in select buuid from db b where bstatus it always return LIMIT orgapachedruidjavautilcommonISE but use in that okAm I using the error thanks Could anyone point me in the right direction to use tranquility with BeamRDD in JAVA Basically I would like to see a basic working example with default values just as in But in java My error is like follows It seems caused by I have too many process want to write the same druid datasource But why it need zookeeper lock when write to druid javalangIllegalStateException Failed to create merged beam druidoverlorddwarchadlocalabtestlit at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at comtwitterutilPromiseTransformerliftedTree Promisescala at comtwitterutilPromiseTransformerkPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseanon runPromisescala at comtwitterconcurrentLocalSchedulerActivationrunSchedulerscala at comtwitterconcurrentLocalSchedulerActivationsubmitSchedulerscala at comtwitterconcurrentLocalSchedulersubmitSchedulerscala at comtwitterconcurrentSchedulersubmitSchedulerscala at comtwitterutilPromiserunqPromisescala at comtwitterutilPromiseupdateIfEmptyPromisescala at comtwitterutilExecutorServiceFuturePoolanon runFuturePoolscala at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangIllegalStateException Failed to save new beam for identifier druidoverlorddwarchadlocalabtestlit timestamp T Z at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at comtwitterutilFutureanonfunrescue applyFuturescala at comtwitterutilFutureanonfunrescue applyFuturescala more Caused by javalangIllegalStateException instance must be started before calling this method at orgapachecuratorshadedcomgooglecommonbasePreconditionscheckStatePreconditionsjava at orgapachecuratorframeworkimpsCuratorFrameworkImplcreateCuratorFrameworkImpljava at orgapachecuratorframeworkrecipeslocksStandardLockInternalsDrivercreatesTheLockStandardLockInternalsDriverjava at orgapachecuratorframeworkrecipeslocksLockInternalsattemptLockLockInternalsjava at orgapachecuratorframeworkrecipeslocksInterProcessMutexinternalLockInterProcessMutexjava at orgapachecuratorframeworkrecipeslocksInterProcessMutexacquireInterProcessMutexjava at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreV internalAcquire LeaseInterProcessSemaphoreV java at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreV acquireInterProcessSemaphoreV java at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreV acquireInterProcessSemaphoreV java at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreMutexacquireInterProcessSemaphoreMutexjava at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at comtwitterutilTryapplyTryscala more javalangIllegalStateException Failed to create merged beam druidoverlorddwarchadlocalabtestlit at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at comtwitterutilPromiseTransformerliftedTree Promisescala at comtwitterutilPromiseTransformerkPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseanon runPromisescala at comtwitterconcurrentLocalSchedulerActivationrunSchedulerscala at comtwitterconcurrentLocalSchedulerActivationsubmitSchedulerscala at comtwitterconcurrentLocalSchedulersubmitSchedulerscala at comtwitterconcurrentSchedulersubmitSchedulerscala at comtwitterutilPromiserunqPromisescala at comtwitterutilPromiseupdateIfEmptyPromisescala at comtwitterutilExecutorServiceFuturePoolanon runFuturePoolscala at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangIllegalStateException Failed to save new beam for identifier druidoverlorddwarchadlocalabtestlit timestamp T Z at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at comtwitterutilFutureanonfunrescue applyFuturescala at comtwitterutilFutureanonfunrescue applyFuturescala more Caused by javalangNullPointerException at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreV acquireInterProcessSemaphoreV java at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreMutexacquireInterProcessSemaphoreMutexjava at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at comtwitterutilTryapplyTryscala more javalangIllegalStateException Failed to create merged beam druidoverlorddwarchadlocalabtestlit at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at comtwitterutilPromiseTransformerliftedTree Promisescala at comtwitterutilPromiseTransformerkPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseanon runPromisescala at comtwitterconcurrentLocalSchedulerActivationrunSchedulerscala at comtwitterconcurrentLocalSchedulerActivationsubmitSchedulerscala at comtwitterconcurrentLocalSchedulersubmitSchedulerscala at comtwitterconcurrentSchedulersubmitSchedulerscala at comtwitterutilPromiserunqPromisescala at comtwitterutilPromiseupdateIfEmptyPromisescala at comtwitterutilExecutorServiceFuturePoolanon runFuturePoolscala at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangIllegalStateException Failed to save new beam for identifier druidoverlorddwarchadlocalabtestlit timestamp T Z at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at comtwitterutilFutureanonfunrescue applyFuturescala at comtwitterutilFutureanonfunrescue applyFuturescala more Caused by javalangNullPointerException at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreV acquireInterProcessSemaphoreV java at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreMutexacquireInterProcessSemaphoreMutexjava at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at comtwitterutilTryapplyTryscala more javalangIllegalStateException Failed to create merged beam druidoverlorddwarchadlocalabtestlit at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at comtwitterutilPromiseTransformerliftedTree Promisescala at comtwitterutilPromiseTransformerkPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseanon runPromisescala at comtwitterconcurrentLocalSchedulerActivationrunSchedulerscala at comtwitterconcurrentLocalSchedulerActivationsubmitSchedulerscala at comtwitterconcurrentLocalSchedulersubmitSchedulerscala at comtwitterconcurrentSchedulersubmitSchedulerscala at comtwitterutilPromiserunqPromisescala at comtwitterutilPromiseupdateIfEmptyPromisescala at comtwitterutilExecutorServiceFuturePoolanon runFuturePoolscala at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangIllegalStateException Failed to save new beam for identifier druidoverlorddwarchadlocalabtestlit timestamp T Z at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at comtwitterutilFutureanonfunrescue applyFuturescala at comtwitterutilFutureanonfunrescue applyFuturescala more Caused by javalangNullPointerException at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreV acquireInterProcessSemaphoreV java at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreMutexacquireInterProcessSemaphoreMutexjava at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at comtwitterutilTryapplyTryscala more javalangIllegalStateException Failed to create merged beam druidoverlorddwarchadlocalabtestlit at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfunsendAll anonfun applyClusteredBeamscala at comtwitterutilPromiseTransformerliftedTree Promisescala at comtwitterutilPromiseTransformerkPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseTransformerapplyPromisescala at comtwitterutilPromiseanon runPromisescala at comtwitterconcurrentLocalSchedulerActivationrunSchedulerscala at comtwitterconcurrentLocalSchedulerActivationsubmitSchedulerscala at comtwitterconcurrentLocalSchedulersubmitSchedulerscala at comtwitterconcurrentSchedulersubmitSchedulerscala at comtwitterutilPromiserunqPromisescala at comtwitterutilPromiseupdateIfEmptyPromisescala at comtwitterutilExecutorServiceFuturePoolanon runFuturePoolscala at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangIllegalStateException Failed to save new beam for identifier druidoverlorddwarchadlocalabtestlit timestamp T Z at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanonfun applyOrElseClusteredBeamscala at comtwitterutilFutureanonfunrescue applyFuturescala at comtwitterutilFutureanonfunrescue applyFuturescala more Caused by javalangNullPointerException at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreV acquireInterProcessSemaphoreV java at orgapachecuratorframeworkrecipeslocksInterProcessSemaphoreMutexacquireInterProcessSemaphoreMutexjava at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at commetamxtranquilitybeamClusteredBeamanon anonfunmodify applyClusteredBeamscala at comtwitterutilTryapplyTryscala more I need select avglatencyMsminlatencyMssumlatencyMs from mytable so make config I can only do that metricsSpec name views type count name latencyMs type doubleSum fieldName latencyMs or I should do this metricsSpec name views type count name latencyMs type doubleSum fieldName latencyMs name latencyMs type doubleMin fieldName latencyMs and what about avg Exception in thread main orgapacheflinkapicommonInvalidProgramException The implementation of the RichSinkFunction is not serializable The object probably contains or references non serializable fields at orgapacheflinkapijavaClosureCleanercleanClosureCleanerjava at orgapacheflinkstreamingapienvironmentStreamExecutionEnvironmentcleanStreamExecutionEnvironmentjava at orgapacheflinkstreamingapidatastreamDataStreamcleanDataStreamjava at orgapacheflinkstreamingapidatastreamDataStreamaddSinkDataStreamjava at comkebigdatadtarchflinkdruidsinkDruidSinkemitDataStreamDruidSinkjava at orgapacheflinktableapiStreamTableEnvironmentwriteToSinkStreamTableEnvironmentscala at orgapacheflinktableapiTableEnvironmentinsertIntoTableEnvironmentscala at orgapacheflinktableapiTableEnvironmentsqlUpdateTableEnvironmentscala at orgapacheflinktableapiTableEnvironmentsqlUpdateTableEnvironmentscala at comkebigdatadtarchflinkMainexecuteSqlMainjava at comkebigdatadtarchflinkMainmainMainjava Caused by javaioNotSerializableException iodruidqueryaggregationCountAggregatorFactory at javaioObjectOutputStreamwriteObject ObjectOutputStreamjava at javaioObjectOutputStreamwriteArrayObjectOutputStreamjava at javaioObjectOutputStreamwriteObject ObjectOutputStreamjava at javaioObjectOutputStreamdefaultWriteFieldsObjectOutputStreamjava at javaioObjectOutputStreamwriteSerialDataObjectOutputStreamjava at javaioObjectOutputStreamwriteOrdinaryObjectObjectOutputStreamjava at javaioObjectOutputStreamwriteObject ObjectOutputStreamjava at javaioObjectOutputStreamdefaultWriteFieldsObjectOutputStreamjava at javaioObjectOutputStreamwriteSerialDataObjectOutputStreamjava at javaioObjectOutputStreamwriteOrdinaryObjectObjectOutputStreamjava at javaioObjectOutputStreamwriteObject ObjectOutputStreamjava at javaioObjectOutputStreamdefaultWriteFieldsObjectOutputStreamjava at javaioObjectOutputStreamwriteSerialDataObjectOutputStreamjava at javaioObjectOutputStreamwriteOrdinaryObjectObjectOutputStreamjava at javaioObjectOutputStreamwriteObject ObjectOutputStreamjava at javaioObjectOutputStreamwriteObjectObjectOutputStreamjava at orgapacheflinkutilInstantiationUtilserializeObjectInstantiationUtiljava at orgapacheflinkapijavaClosureCleanercleanClosureCleanerjava more Every time a new connection is established in IndexService there is a DruidTaskResolver submitting a runnable to a new thread poll thread bind to the connection and periodically check the task running status but when the beam is closed the poll runnable cannot be notified and cancled properly This caused a thread leakage in a longlast running jvm After upgrading all plugins to newer versions and changing certain dependencies diff diff git abuildsbt bbuildsbt index f c eae abuildsbt bbuildsbt scalaVersion in ThisBuild scalaVersion in ThisBuild Disable parallel execution the various Druid oriented tests need to claim ports parallelExecution in ThisBuild false concurrentRestrictions in Global TagslimitAll val jacksonOneVersion See before upgrading Jackson val jacksonTwoVersion val jacksonTwoModuleScalaVersion val jacksonTwoModuleScalaVersion val druidVersion val curatorVersion val guiceVersion def dependOnDruidartifact String val coreDependencies Seq commetamx scalautil commetamx scalautil excludelog j log j excludemysql mysqlconnectorjava Not needed unwanted GPLv license force commetamx javautil excludelog j log j force commetamx javautil excludelog j log j force ionetty netty Final force orgapachecurator curatorclient curatorVersion force orgapachecurator curatorframework curatorVersion force val kafkaDependencies Seq loggingDependencies val coreTestDependencies Seq orgscalatest scalatest test orgscalatest scalatest test dependOnDruiddruidservices test orgapachecurator curatortest curatorVersion test excludelog j log j force comsunjersey jerseyservlet test force lazy val commonSettings Seq Target Java scalacOptions targetjvm javacOptions in compile Seqsource target javacOptions in compile Seqsource target resolvetermconflictobject since stormcore has a package and object with the same name scalacOptions Seqfeature deprecation Yresolvetermconflictobject lazy val commonSettings Seq lazy val root projectinfile settingscommonSettings settingspublishArtifact false aggregatecore flink storm samza spark server kafka aggregatecore lazy val core projectinfilecore settingscommonSettings lazy val core projectinfilecore settingspublishArtifact inTest packageBin true settingslibraryDependencies coreDependencies coreTestDependencies lazy val flink projectinfileflink settingscommonSettings settingsname tranquilityflink settingslibraryDependencies flinkDependencies flinkTestDependencies dependsOncore testtestcompilecompile lazy val spark projectinfilespark settingscommonSettings settingsname tranquilityspark settingslibraryDependencies sparkDependencies dependsOncore testtestcompilecompile lazy val storm projectinfilestorm settingscommonSettings settingsname tranquilitystorm settingsresolvers clojars at settingslibraryDependencies stormDependencies dependsOncore testtestcompilecompile lazy val samza projectinfilesamza settingscommonSettings settingsname tranquilitysamza settingslibraryDependencies samzaDependencies samzaTestDependencies settingspublishArtifact in Test false dependsOncore testtestcompilecompile lazy val server projectinfileserver settingscommonSettings settingsname tranquilityserver settingslibraryDependencies serverDependencies serverTestDependencies settingspublishArtifact in Test false dependsOncore testtestcompilecompile lazy val kafka projectinfilekafka settingscommonSettings settingsname tranquilitykafka settingslibraryDependencies kafkaDependencies kafkaTestDependencies settingspublishArtifact in Test false dependsOncore testtestcompilecompile lazy val distribution projectinfiledistribution settingscommonSettings settingsname tranquilitydistribution settingspublishArtifact in Test false settingsmainClass in Compile SomecommetamxtranquilitydistributionDistributionMain settingsexecutableScriptName tranquility settingsbashScriptExtraDefines addJava DlogbackconfigurationFileapphomeconflogbackxml enablePluginsJavaAppPackaging dependsOnkafka server lazy val flink projectinfileflink settingscommonSettings settingsname tranquilityflink settingslibraryDependencies flinkDependencies flinkTestDependencies dependsOncore testtestcompilecompile lazy val spark projectinfilespark settingscommonSettings settingsname tranquilityspark settingslibraryDependencies sparkDependencies dependsOncore testtestcompilecompile lazy val storm projectinfilestorm settingscommonSettings settingsname tranquilitystorm settingsresolvers clojars at settingslibraryDependencies stormDependencies dependsOncore testtestcompilecompile lazy val samza projectinfilesamza settingscommonSettings settingsname tranquilitysamza settingslibraryDependencies samzaDependencies samzaTestDependencies settingspublishArtifact in Test false dependsOncore testtestcompilecompile lazy val server projectinfileserver settingscommonSettings settingsname tranquilityserver settingslibraryDependencies serverDependencies serverTestDependencies settingspublishArtifact in Test false dependsOncore testtestcompilecompile lazy val kafka projectinfilekafka settingscommonSettings settingsname tranquilitykafka settingslibraryDependencies kafkaDependencies kafkaTestDependencies settingspublishArtifact in Test false dependsOncore testtestcompilecompile lazy val distribution projectinfiledistribution settingscommonSettings settingsname tranquilitydistribution settingspublishArtifact in Test false settingsmainClass in Compile SomecommetamxtranquilitydistributionDistributionMain settingsexecutableScriptName tranquility settingsbashScriptExtraDefines addJava DlogbackconfigurationFileapphomeconflogbackxml enablePluginsJavaAppPackaging dependsOnkafka server diff git aprojectbuildproperties bprojectbuildproperties index cc deae aprojectbuildproperties bprojectbuildproperties sbtversion sbtversion diff git aprojectpluginssbt bprojectpluginssbt index b af e aprojectpluginssbt bprojectpluginssbt resolvers Seq Central at addSbtPluginnetvirtualvoid sbtdependencygraph addSbtPluginnetvirtualvoid sbtdependencygraph addSbtPlugincomgithubgseitz sbtrelease addSbtPlugincomgithubgseitz sbtrelease addSbtPlugincomjsuereth sbtpgp addSbtPlugincomjsuereth sbtpgp M addSbtPlugincomtypesafesbt sbtnativepackager addSbtPlugincomtypesafesbt sbtnativepackager logs info Loading settings for project tranquilitybuild from pluginssbt info Loading project definition from homesuryanshworkspacesonartesttranquilityproject info Loading settings for project root from buildsbtversionsbt info Set current project to root in build filehomesuryanshworkspacesonartesttranquility info Setting Scala version to on projects info Reapplying settings info Set current project to root in build filehomesuryanshworkspacesonartesttranquility info Compiling Scala sources to homesuryanshworkspacesonartesttranquilitycoretargetscala classes warn homesuryanshworkspacesonartesttranquilitycoresrcmainscalacommetamxtranquilitydruidDruidBeamsscala nonvariable type argument javanioByteBuffer in type iodruiddatainputimplInputRowParser javanioByteBuffer is unchecked since it is eliminated by erasure warn trialParserisInstanceOf InputRowParser ByteBuffer warn warn homesuryanshworkspacesonartesttranquilitycoresrcmainscalacommetamxtranquilitydruidDruidBeamsscala nonvariable type argument javanioByteBuffer in type iodruiddatainputimplInputRowParser javanioByteBuffer is unchecked since it is eliminated by erasure warn trialParserisInstanceOf InputRowParser ByteBuffer warn error homesuryanshworkspacesonartesttranquilitycoresrcmainscalacommetamxtranquilitydruidDruidGuicerscala ambiguous reference to overloaded definition error both method putAll in class Properties of type x javautilMap Unit error and method putAll in class Hashtable of type x javautilMap Object Object Unit error match argument types javautilProperties error thePropsputAllprops error error homesuryanshworkspacesonartesttranquilitycoresrcmainscalacommetamxtranquilitydruidDruidGuicerscala ambiguous reference to overloaded definition error both method putAll in class Properties of type x javautilMap Unit error and method putAll in class Hashtable of type x javautilMap Object Object Unit error match argument types javautilProperties error thePropsputAllSystemgetProperties error warn two warnings found error two errors found error core Compile compileIncremental Compilation failed error Total time s completed Jun PM From this report there are high severity CVEs and medium severity CVEs in tranquility dependencies Most of these are related to Jackson and Jetty It would be great to see these upgraded for a new release