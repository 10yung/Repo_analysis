 Welcome to ingressnginx For a smooth issue process try to answer the following questions Dont worry if theyre not all applicable just try to include what you can If you need to include code snippets or logs please put them in fenced code blocks If theyre superlong please use the details tag like detailssummarysuperlong logsummary lots of stuff details IMPORTANT Please complete the next sections or the issue will be closed This questions are the first thing we need to know to understand the context NGINX Ingress controller version I only tested these versions Environment ingressnginx cmd line nginxingresscontroller defaultbackendservicekubesystemdefaulthttpbackend ingressclasskubesystemingress configmapkubesystemproxynginxconfig tcpservicesconfigmapkubesystemproxynginxtcp udpservicesconfigmapkubesystemproxynginxudp healthcheckpathhealthz healthzport statusport annotationsprefixingresskubernetesio enablesslpassthrough v ingressnginx configmap apiVersion v data enablestickysessions true enablevtsstatus true forcesslredirect false proxybodysize G proxybuffersize k proxybuffersnumber proxyreadtimeout servertokens false skipaccesslogurls nginxstatusformatjson sslredirect false kind ConfigMap metadata loadbalancecaicloudiocreatedby kubesystemingress loadbalancecaicloudioproxy nginx name proxynginxconfig namespace kubesystem ingress example apiVersion extensionsv beta kind Ingress metadata annotations ingresskubernetesioaffinity true ingresskubernetesioenablecors true ingresskubernetesioforcesslredirect true ingresskubernetesiolimitconnections ingresskubernetesiolimitrps ingresskubernetesioloadbalance roundrobin ingresskubernetesiosslpassthrough false kubernetesioingressclass kubesystemingress labels loadbalancecaicloudiocreatedby kubesystemingress name i namespace pp spec rules host testnetingresscom http paths backend serviceName ingressapp servicePort path tls hosts testnetingresscom secretName aaanetingressv What happened For https rule nginx gets a wrong src ip or real ip nginx log Jan GET HTTP curl pphhlaa c d e bb a e e e please include exact error messages if you can It works fine for http rule What you expected to happen nginx recognizes correct src ip for https rule What do you think went wrong How to reproduce it As minimally and precisely as possible Keep in mind we do not have access to your cluster or application Help up us if possible reproducing the issue using minikube or kind Install minikubekind Minikube Kind Install the ingress controller kubectl apply f kubectl apply f Install an application that will act as default backend is just an echo app kubectl apply f Create an ingress please add any additional annotation required echo apiVersion networkingk siov beta kind Ingress metadata name foobar spec rules host foobar http paths backend serviceName httpsvc servicePort path kubectl apply f make a request PODNAMEk get pods n ingressnginx l appkubernetesionameingressnginx o NAME kubectl exec it n ingressnginx PODNAME curl H Host foobar localhost Anything else we need to know If this is actually about documentation add kind documentation below kind bug I have to build this image to publish it for internal Microsoft consumption and for some reason it was failing to build due to the following error RUN apk add U nocache diffutils libcap binsh apk not found ERROR executor failed running binsh c apk add U nocache diffutils libcap runc did not terminate sucessfully It appears that it was attempting to use a base image that was for the release and it was refusing to download the new base image even though the sha had been updated Im not sure if this is an issue with buildx not fetching the base image correctly or something else but figured I would open an issue in case other people run into this same problem kind bug Welcome to ingressnginx For a smooth issue process try to answer the following questions Dont worry if theyre not all applicable just try to include what you can If you need to include code snippets or logs please put them in fenced code blocks If theyre superlong please use the details tag like detailssummarysuperlong logsummary lots of stuff details IMPORTANT Please complete the next sections or the issue will be closed This questions are the first thing we need to know to understand the context NGINX Ingress controller version Kubernetes version use kubectl version v gke Environment Cloud provider or hardware configuration GKE OS eg from etcosrelease Kernel eg uname a Install tools Others What happened Changing an nginxingresskubernetesioenableopentracing ingress annotation from true to false or vice versa is not reflected in the tracing headers sent to the app until ingressnginx is restarted What you expected to happen The headers to reflect the annotation without needing to restart ingressnginx What do you think went wrong How to reproduce it Enable opentracing and configure a zipkincollector this may apply to the other types of collector but we dont have them configured in our cluster apply nginxingresskubernetesioenableopentracing true to an ingress You should see the app receives tracing headers eg using an echoserver workload xb traceid xb spanid xb parentspanid xb sampled xb flags Update the ingress annotation to false and the app continues receiving the same headers and values particularly xb sampled Restart the ingresses The app now sees xb sampled and no longer gets xb flags the other id headers still get sent this is expected behaviour The same happens again if you now switch it back to true As minimally and precisely as possible Keep in mind we do not have access to your cluster or application Help up us if possible reproducing the issue using minikube or kind Install minikubekind Minikube Kind Install the ingress controller kubectl apply f kubectl apply f Install an application that will act as default backend is just an echo app kubectl apply f Create an ingress please add any additional annotation required echo apiVersion networkingk siov beta kind Ingress metadata name foobar spec rules host foobar http paths backend serviceName httpsvc servicePort path kubectl apply f make a request PODNAMEk get pods n ingressnginx l appkubernetesionameingressnginx o NAME kubectl exec it n ingressnginx PODNAME curl H Host foobar localhost Anything else we need to know If this is actually about documentation add kind documentation below kind bug Provide a general summary of your changes in the Title above Please dont mention people in PR or commit messages do so in an additional comment What this PR does why we need it Why is this change required What problem does it solve If it fixes an open issue please link to the issue here Types of changes What types of changes does your code introduce Put an x in all the boxes that apply Bug fix nonbreaking change which fixes an issue New feature nonbreaking change which adds functionality Breaking change fix or feature that would cause existing functionality to change Which issues this PR fixes optional in fixes issue number format will close that issue when PR gets merged fixes How Has This Been Tested Please describe in detail how you tested your changes Include details of your testing environment and the tests you ran to see how your change affects other areas of the code etc Checklist Go over all the following points and put an x in all the boxes that apply If youre unsure about any of these dont hesitate to ask Were here to help My change requires a change to the documentation I have updated the documentation accordingly Ive read the CONTRIBUTION guide I have added tests to cover my changes All new and existing tests passed should shutdown after waiting seconds for pending connections to be closed It should shutdown after waiting seconds for pending connections to be closed It should delete Ingress updated to catchall It uses custom default backend It Welcome to ingressnginx For a smooth issue process try to answer the following questions Dont worry if theyre not all applicable just try to include what you can If you need to include code snippets or logs please put them in fenced code blocks If theyre superlong please use the details tag like detailssummarysuperlong logsummary lots of stuff details IMPORTANT Please complete the next sections or the issue will be closed This questions are the first thing we need to know to understand the context NGINX Ingress controller version What happened When the oldest Ingress that specifies a TLS host does not reference a secret the default certificate is always served even if another Ingress references a valid secret What you expected to happen If multiple Ingress specify a TLS host but only one references a valid secret the certificate from that secret should be used not the default certificate How to reproduce it create a tls secret mysecret with a valid certificate for foobarcom create Ingress without secret reference echo apiVersion extensionsv beta kind Ingress metadata name defaultcert spec rules host foobarcom http paths path foo backend serviceName foobar servicePort tls hosts foobarcom kubectl apply f create Ingress with secret reference echo apiVersion extensionsv beta kind Ingress metadata name customcert spec rules host foobarcom http paths path bar backend serviceName foobar servicePort tls hosts foobarcom secretName mysecret kubectl apply f check certificate returned openssl sclient connect INGRESSADDR servername foobarcom Anything else we need to know Applying steps and in reverse order will serve the correct certificate Restart the controller after removing Ingresses when testing because certificates may linger See and which asked for this behaviour I suspect this was broken by kind bug I would like to start a discussion about the possibility to extend the current configuration of external Auth providers in order to support Lua plugin based solutions too The current ingressnginx implementation provides a way to involve such OIDC client implementations that run as external processes and ingressnginx has to contact them via a HTTP subrequest Such an external process can be provided for example by oauth proxy or by vouchproxy etc In this situation some parts of the OIDC flow are executed inside ingressnginx while other parts are executed by the external solutions and consequently there are configuration options in ingressnginx to control the internal part With the possibility to use an OIDC Lua plugin all parts of the client side OIDC flow are processed in ingressnginx ie there should be a way to configure all the necessary parameters in the ingressnginx configuration This issue is a request to discuss and agree on the details of that configuration if the community thinks that it is a valuable extension to ingressnginx If we consider the needs of an OIDC client the requestor s proposal is that the user should be able to configure the necessary parameters in a ConfigMap and a Secret The ConfigMap and Secret names should be configured on the corresponding Ingress resources in annotations similarly to the current practice of the external authentication related auth annotations On this way we would have a plugin agnostic way to provide the configuration to the plugin at runtime Also it would be more dynamic if eg the OIDC client ID and the corresponding client secret could be provided via a K s Secret resource instead of the usual environment variables kind feature When using Helm to install its very hard to figure out how to get the ConfigMap working Proposing a little bit of help Provide a general summary of your changes in the Title above Please dont mention people in PR or commit messages do so in an additional comment What this PR does why we need it Why is this change required What problem does it solve If it fixes an open issue please link to the issue here Types of changes What types of changes does your code introduce Put an x in all the boxes that apply Bug fix nonbreaking change which fixes an issue New feature nonbreaking change which adds functionality Breaking change fix or feature that would cause existing functionality to change Which issues this PR fixes optional in fixes issue number format will close that issue when PR gets merged fixes How Has This Been Tested Please describe in detail how you tested your changes Include details of your testing environment and the tests you ran to see how your change affects other areas of the code etc Checklist Go over all the following points and put an x in all the boxes that apply If youre unsure about any of these dont hesitate to ask Were here to help My change requires a change to the documentation x I have updated the documentation accordingly Ive read the CONTRIBUTION guide I have added tests to cover my changes All new and existing tests passed Welcome to ingressnginx For a smooth issue process try to answer the following questions Dont worry if theyre not all applicable just try to include what you can If you need to include code snippets or logs please put them in fenced code blocks If theyre superlong please use the details tag like detailssummarysuperlong logsummary lots of stuff details IMPORTANT Please complete the next sections or the issue will be closed This questions are the first thing we need to know to understand the context NGINX Ingress controller version Kubernetes version use kubectl version v What happened The Ingress annotations included authtlspasscertificatetoupstream true but nginxconf was rendered without the line proxysetheader sslclientcert sslclientescapedcert What you expected to happen Consider multiple Ingress resources on a single hostname With other TLSrelated annotations like authtlsverifyclient adding them to one Ingress will cause cause them to be enabled for all Ingresses on that hostname However with authtlspasscertificatetoupstream the certificate is not passed passed to the upstream unless authtlspasscertificatetoupstream true is set on all ingresses for that hostname Since this annotation simply controls a boolean in the location section of the template I would expect to be able to enable it on a peringress basis When reading the template it is clear what the problem is PassCertToUpstream is scoped under server not location so the value may actually be populated by a different ingress resource What do you think went wrong How to reproduce it yaml apiVersion networkingk siov beta kind Ingress metadata name foo annotations kubernetesioingressclass nginx nginxingresskubernetesioauthtlssecret defaultcacert nginxingresskubernetesioauthtlsverifyclient optional spec rules host examplecom http paths backend serviceName httpsvc servicePort path foo apiVersion networkingk siov beta kind Ingress metadata name bar annotations kubernetesioingressclass nginx nginxingresskubernetesioauthtlspasscertificatetoupstream true nginxingresskubernetesioauthtlssecret defaultcacert nginxingresskubernetesioauthtlsverifyclient optional spec rules host examplecom http paths backend serviceName httpsvc servicePort path bar As minimally and precisely as possible Keep in mind we do not have access to your cluster or application Help up us if possible reproducing the issue using minikube or kind Install minikubekind Minikube Kind Install the ingress controller kubectl apply f kubectl apply f Install an application that will act as default backend is just an echo app kubectl apply f Create an ingress please add any additional annotation required echo apiVersion networkingk siov beta kind Ingress metadata name foobar spec rules host foobar http paths backend serviceName httpsvc servicePort path kubectl apply f make a request PODNAMEk get pods n ingressnginx l appkubernetesionameingressnginx o NAME kubectl exec it n ingressnginx PODNAME curl H Host foobar localhost Anything else we need to know I suspect this patch to the e e tests will reproduce the issue but I dont have a system to run the e e tests on at the moment to try it diff diff git ateste eannotationsauthtlsgo bteste eannotationsauthtlsgo index e a abbea a ateste eannotationsauthtlsgo bteste eannotationsauthtlsgo var frameworkIngressNginxDescribeAnnotations AuthTLS func ExpecterrToNotHaveOccurred annotations map string string nginxingresskubernetesioauthtlssecret nameSpace host nginxingresskubernetesioauthtlserrorpage fGetURLframeworkHTTP errorPath nginxingresskubernetesioauthtlspasscertificatetoupstream true nginxingresskubernetesioauthtlssecret nameSpace host nginxingresskubernetesioauthtlserrorpage fGetURLframeworkHTTP errorPath fEnsureIngressframeworkNewSingleIngressWithTLShost foo host stringhost nameSpace frameworkEchoService annotations annotations nginxingresskubernetesioauthtlspasscertificatetoupstream true fEnsureIngressframeworkNewSingleIngressWithTLShost host stringhost nameSpace frameworkEchoService annotations assertSslClientCertificateConfigf host on If this is actually about documentation add kind documentation below kind bug Welcome to ingressnginx For a smooth issue process try to answer the following questions Dont worry if theyre not all applicable just try to include what you can If you need to include code snippets or logs please put them in fenced code blocks If theyre superlong please use the details tag like detailssummarysuperlong logsummary lots of stuff details IMPORTANT Please complete the next sections or the issue will be closed This questions are the first thing we need to know to understand the context NGINX Ingress controller version unable to verify Kubernetes version use kubectl version Environment Cloud provider or hardware configuration On premise underlying hypervisor is VMware OS eg from etcosrelease Debian Kernel eg uname a Debian deb u x GNULinux Install tools NA Others NA What happened Nginx istances not using the tls specified in the ingresses but sticking to the default certificate in local etckubernetesssl folder please include exact error messages if you can What you expected to happen Nginx istances should use certificates specified by ingresses instead of the default ones What do you think went wrong Local nginx did not receive the configuration specified in the ingress text How to reproduce it Implement an ingress like the following one apiVersion extensionsv beta kind Ingress metadata annotations nginxingresskubernetesioproxybodysize m nginxingresskubernetesioproxyconnecttimeout nginxingresskubernetesioproxysendtimeout nginxingresskubernetesioproxyreadtimeout nginxingresskubernetesioproxynextupstream error nginxingresskubernetesioproxynextupstreamtries nginxingresskubernetesioproxyrequestbuffering on nginxingresskubernetesiosslredirect False nginxingresskubernetesiorewritetarget nginxingresskubernetesiouseregex true nginxingresskubernetesioconfigurationsnippet if requestmethod GETOPTIONSHEAD return set vpn yes if notvpnip set vpn no if ingressname set service assetsapps set subenv ourapps set serviceid appsmycompanyassetsapps set realingress true moresetheaders XcompanynameUuid tid moreclearheaders xcompanyappname moreclearheaders xpoweredby moreclearheaders xourorchestrator moreclearinputheaders xourwebsitecacheid moresetheaders OurServiceName service moresetheaders OurServiceSubenv subenv moresetheaders OurServiceId serviceid moresetheaders OurServiceIngress ingressname moresetheaders stricttransportsecurity strictheader proxysetheader XCompanyHeaderUUID tid set cors false set corsdone false name mywebsiteapps namespace appsourcompany spec tls hosts mywebsite secretName mywebsitecerts rules host mywebsite http paths path Apps backend serviceName appsourcompanyassetsappsdefaultservice servicePort Verify if the NGINX Configuration appears as this server servername appsourwebsiteit listen proxyprotocol set proxyupstreamname set passaccessscheme scheme set passserverport serverport set besthttphost httphost set passport passserverport listen proxyprotocol ssl http PEM sha c cb aced d bef c ef fbf sslcertificate etcingresscontrollerssldefaultfakecertificatepem sslcertificatekey etcingresscontrollerssldefaultfakecertificatepem sslcertificatebyluablock certificatecall location set namespace ourstore set ingressname appsourwebsiteitourstore set servicename ourstoreassetsourstoredefaultservice set serviceport set locationpath rewritebyluablock luaingressrewrite forcesslredirect true useportinredirects false balancerrewrite pluginsrun headerfilterbyluablock pluginsrun bodyfilterbyluablock logbyluablock balancerlog monitorcall pluginsrun if scheme https moresetheaders StrictTransportSecurity maxage includeSubDomains portinredirect off set proxyupstreamname ourstoreourstoreassetsourstoredefaultservice set proxyhost proxyupstreamname clientmaxbodysize m proxysetheader Host besthttphost Pass the extracted client certificate to the backend Allow websocket connections proxysetheader Upgrade httpupgrade proxysetheader Connection connectionupgrade proxysetheader XRequestID reqid proxysetheader XRealIP therealip proxysetheader XForwardedFor therealip proxysetheader XForwardedHost besthttphost proxysetheader XForwardedPort passport proxysetheader XForwardedProto passaccessscheme proxysetheader XOriginalURI requesturi proxysetheader XScheme passaccessscheme Pass the original XForwardedFor proxysetheader XOriginalForwardedFor httpxforwardedfor mitigate HTTPoxy Vulnerability proxysetheader Proxy Custom headers to proxied server proxyconnecttimeout s proxysendtimeout s proxyreadtimeout s proxybuffering off proxybuffersize k proxybuffers k proxyrequestbuffering on proxyhttpversion proxycookiedomain off proxycookiepath off In case of errors try the next upstream server before returning an error proxynextupstream error proxynextupstreamtries if requestmethod GETPOSTOPTIONSDELETEPUTHEAD return set vpn yes if notvpnip set vpn no if ingressname set service assetsourstore set subenv ourstore set serviceid ourstoreassetsourstore set realingress true moresetheaders XOurUUID tid moreclearheaders xourapp moreclearheaders xpoweredby moreclearheaders xourorchestrator moreclearinputheaders xourcacheid moresetheaders XOurServiceName service moresetheaders XOurServiceSubenv subenv moresetheaders XOurServiceId serviceid moresetheaders XOurServiceIngress ingressname moresetheaders stricttransportsecurity strictheader proxysetheader XOurUUID tid set cors false set corsdone false proxypass proxyredirect off More specifically I dont expect nginx to use the local default SSL certificate as specified in the following line sslcertificate etcingresscontrollerssldefaultfakecertificatepem 