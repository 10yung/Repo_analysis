I want to get the last offset for each partition in a topic That requires me to dial every single partition which is extremely slow For example before parallelizing it it takes over seconds for a partition topic in my setup It should be possible to use a connection to a broker to get the last offset for every partition that it leads Here is an extract from my program of the current code Im using go import golangorgxsyncerrgroup var Dialer kafkaDialer Brokers string func LastOffsetsctx contextContext topic string int error conn err dialctx Dialer Brokers if err nil return nil err defer connClose partitions err connReadPartitionstopic if err nil return nil err var lastOffsets make int lenpartitions var group ctx errgroupWithContextctx for i partition range partitions p partition groupGofunc error conn err DialerDialPartitionctx tcp p if err nil return err defer connClose lastOffsets i err connReadLastOffset if err nil return err groupWait return lastOffsets nil dial connects to a Kafka broker func dialctx contextContext dialer kafkaDialer brokers string kafkaConn error var conn kafkaConn errs error for broker range brokers var err error conn err dialerDialContextctx tcp broker if err nil errs multierrAppenderrs xerrorsErrorfdialing q w broker err continue return conn nil return nil errs The address parameter is ignored in DialerDialPartition since the address is provided in the Partition struct I think it is confusing and should be removed Followup on stale with full use of the streaming API from klauspost Decompression is slower while the default compression ratio went down from to name old timeop new timeop delta Compressionzstdcompress ms ms p n Compressionzstddecompress s s p n name old speed new speed delta Compressionzstdcompress MBs MBs p n Compressionzstddecompress GBs GBs p n Hi Currently the default RetentionTime for ConsumerGroup is hours By taking a look at Sarama you can see this to I think its a better way if it would be In my case I set offsetsretentionminutes on the brokers so all offsets are kept for a long period But didnt know the kafkago could override this behavior Some of my consumers got crazy by restarting from the beginning and made some mess in my data Maybe Im wrong it would be the better default case any thought welcome Thank you Describe the bug A clear and concise description of what the bug is ReadMessage in group modelthe speed blow ws Kafka Version What versions of Kafka are you testing against kafka To Reproduce Steps to reproduce the behavior Bonus points for a code sample consumer code consumer kafkaNewReaderkafkaReaderConfig Brokers stringsSplithosts GroupID topic Topic topic QueueCapacity queueCap MinBytes e MaxBytes e fmtPrintlnBegin to consume topic start timeNow for i iconsumeNumi err consumerReadMessagecontextBackground if err nil fmtPrintfconsume falied err is s n err break fmtPrintfmessage at offset d s s nmOffset stringmKey stringmValue coast timeNowSubstart fmtPrintfread d msgscoast s fw qpss nconsumeNumcoastStringfloat consumeNumcoastSecond Expected behavior A clear and concise description of what you expected to happen Additional context Add any other context about the problem here Describe the bug A clear and concise description of what the bug is when i produce msgs to an unknow hostti dont report any error Kafka Version What versions of Kafka are you testing against To Reproduce Steps to reproduce the behavior Bonus points for a code sample go brokers stringsSplithosts producer kafkaNewWriterkafkaWriterConfig Brokers brokers Topic topic QueueCapacity queueCap BatchBytes batchBytes BatchSize batchSize BatchTimeout timeDurationbatchTimeouttimeMillisecond Async true RequiredAcks CompressionCodec lz CompressionCodec Balancer kafkaMurmur Balancer producedMsg kafkaMessage Value msg fmtPrintlnstart to produce msgs start timeNow for i i produceNum i err producerWriteMessagescontextBackground producedMsg if err nil fmtPrintfProduce d msg faliedi Expected behavior A clear and concise description of what you expected to happen Additional context Add any other context about the problem here Hi I am using kafkago for reading binary messages and writing to a remote endpoint I was looking at function and it seems that the commitLoop is started in a goroutine func r Reader runcg ConsumerGroup genStartfuncctx contextContext rcommitLoopctx gen When close is called by the reader it does wait for rdone to be closed but that it seems will be done by the third goroutine and it wont wait for commitLoop to endthis is what I am unsure of I wanted to know if I can assume if close returns it will flush all pending commit messages First of all I would like to thank you for sharing this library Im writing a service that uses this library to connect to kafka Now I want to expose a url to check the readiness and liveness of the service In order to check the liveness I have to check the status of the connections to the infrastructure services used by the service instance The question is how to check the connection status to ensure its alive This PR revolves around giving the Reader capabilities to read from wildcard topics There is a singleton routine called the topic scanner that gets triggered by the first reader that wants to use a wildcard topic evaluation Those readers that want to use the wildcard topics will subscribe to the topic scanner and receive periodic updates from the scanner that keeps track of them and their wildcard pattern The scanner also allows readers to unsubscribe when they close The scanner will run each subscribers regex against the list of all the topics in that broker to send it only matching topics regex matching is based off of the golang regexMatchString The scanner will cache the list of topics for a broker while its updating each subscriber to reduce the amount of calls made to kafka One decision I made was that if the reader is not associated with a consumer group and has wildcards enabled it will ignore the partition field as there is no guarantee youll find a specific partition across several topics though that can be changed based on your input Describe the bug I know we should set number of consumers partitions This happens when I am doing some testing with number of consumers partitions So I am not sure its a bug or not A reader with group id consumes from a topic with multiple partitions After Kafka Server restart FetchMessage is not getting any new messages Kafka Version To Reproduce version v partitions each with replica consumers Additional context partition offset After Kafka Server restart Kafka reader keeps seeking to the latest offset etc without sending data to consumers no messages received from kafka within the allocated time for partition of history at offset no messages received from kafka within the allocated time for partition of history at offset failed to read from current broker for partition of history at offset not the leader initializing kafka reader for partition of history starting at offset failed to read from current broker for partition of history at offset not the leader initializing kafka reader for partition of history starting at offset error initializing the kafka reader for partition of history Not Leader For Partition the client attempted to send messages to a replica that is not the leader for some partition the clients metadata are likely out of date error initializing the kafka reader for partition of history Not Leader For Partition the client attempted to send messages to a replica that is not the leader for some partition the clients metadata are likely out of date initializing kafka reader for partition of history starting at offset initializing kafka reader for partition of history starting at offset error initializing the kafka reader for partition of history write tcp use of closed network connection error initializing the kafka reader for partition of history write tcp use of closed network connection initializing kafka reader for partition of history starting at offset initializing kafka reader for partition of history starting at offset stopped heartbeat for group history stopped heartbeat for group history stopped commit for group history stopped commit for group history Unable to establish connection to consumer group coordinator for group history dial tcp connect connection refused Leaving group history member mainlocalhost githubcomsegmentiokafkagocba c e e a b cecd dd Unable to establish connection to consumer group coordinator for group history dial tcp connect connection refused Leaving group history member mainlocalhost githubcomsegmentiokafkago bdf cd f d f bf a e bf dial tcp connect connection refused dial tcp connect connection refused stopped heartbeat for group history stopped commit for group history Unable to establish connection to consumer group coordinator for group history dial tcp connect connection refused Leaving group history member mainlocalhost githubcomsegmentiokafkago dcdbd c e bda f cd dial tcp connect connection refused Unable to establish connection to consumer group coordinator for group history dial tcp connect connection refused Unable to establish connection to consumer group coordinator for group history dial tcp connect connection refused dial tcp connect connection refused Unable to establish connection to consumer group coordinator for group history dial tcp connect connection refused dial tcp connect connection refused Unable to establish connection to consumer group coordinator for group history Group Coordinator Not Available the broker returns this error code for group coordinator requests offset commits and most group management requests if the offsets topic has not yet been created or if the group coordinator is not active Unable to establish connection to consumer group coordinator for group history Group Coordinator Not Available the broker returns this error code for group coordinator requests offset commits and most group management requests if the offsets topic has not yet been created or if the group coordinator is not active Group Coordinator Not Available the broker returns this error code for group coordinator requests offset commits and most group management requests if the offsets topic has not yet been created or if the group coordinator is not active Group Coordinator Not Available the broker returns this error code for group coordinator requests offset commits and most group management requests if the offsets topic has not yet been created or if the group coordinator is not active Unable to establish connection to consumer group coordinator for group history Group Coordinator Not Available the broker returns this error code for group coordinator requests offset commits and most group management requests if the offsets topic has not yet been created or if the group coordinator is not active Group Coordinator Not Available the broker returns this error code for group coordinator requests offset commits and most group management requests if the offsets topic has not yet been created or if the group coordinator is not active joined group history as member mainlocalhost githubcomsegmentiokafkagodf a f ddfafafecaff c da in generation joinGroup succeeded for response history generationID memberIDmainlocalhost githubcomsegmentiokafkagodf a f ddfafafecaff c da Joined group history as member mainlocalhost githubcomsegmentiokafkagodf a f ddfafafecaff c da in generation joined group history as member mainlocalhost githubcomsegmentiokafkago ea fd b bba cb d in generation selected as leader for group history joined group history as member mainlocalhost githubcomsegmentiokafkagoa cc bef e baf a cfc in generation joinGroup succeeded for response history generationID memberIDmainlocalhost githubcomsegmentiokafkagoa cc bef e baf a cfc Joined group history as member mainlocalhost githubcomsegmentiokafkagoa cc bef e baf a cfc in generation using range balancer to assign group history found member mainlocalhost githubcomsegmentiokafkago ea fd b bba cb d bytenil found member mainlocalhost githubcomsegmentiokafkagodf a f ddfafafecaff c da bytenil found member mainlocalhost githubcomsegmentiokafkagoa cc bef e baf a cfc bytenil found topicpartition history found topicpartition history assigned membertopicpartitions mainlocalhost githubcomsegmentiokafkagoa cc bef e baf a cfchistory assigned membertopicpartitions mainlocalhost githubcomsegmentiokafkagodf a f ddfafafecaff c da history joinGroup succeeded for response history generationID memberIDmainlocalhost githubcomsegmentiokafkago ea fd b bba cb d Joined group history as member mainlocalhost githubcomsegmentiokafkago ea fd b bba cb d in generation Syncing assignments for generation as member mainlocalhost githubcomsegmentiokafkago ea fd b bba cb d received empty assignments for group history as member mainlocalhost githubcomsegmentiokafkago ea fd b bba cb d for generation sync group finished for group history sync group finished for group history sync group finished for group history subscribed to partitions map started commit for group history subscribed to partitions map initializing kafka reader for partition of history starting at offset started heartbeat for group history s started commit for group history started heartbeat for group history s subscribed to partitions map started commit for group history started heartbeat for group history s initializing kafka reader for partition of history starting at offset the kafka reader for partition of history is seeking to offset the kafka reader for partition of history is seeking to offset no messages received from kafka within the allocated time for partition of history at offset no messages received from kafka within the allocated time for partition of history at offset no messages received from kafka within the allocated time for partition of history at offset no messages received from kafka within the allocated time for partition of history at offset initializing kafka reader for partition of history starting at offset the kafka reader for partition of history is seeking to offset initializing kafka reader for partition of history starting at offset the kafka reader for partition of history is seeking to offset 