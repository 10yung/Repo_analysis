Important notices Before you add a new report we ask you kindly to acknowledge the following yes I have read the contributing guide lines at yes I have searched the existing issues and Im convinced that mine is new Is your feature request related to a problem Please describe I have a pf states inconsistence from time to time on a PBX behind an OPNSense firewall My PBX loses conectivity with a trunk provider and I cant figure out why At first this happend when my ISP changed the public IP but it hasnt changed for a long while and the problem persists Describe the solution youd like Id like to automate the steps I found to be the work around to this issue Actually I go to Firewall Diagnostics State Dump and filter the states related to the VOIP trunk provider IP address The state table shows two states and then after the filter is applied I press the kill button and when the PBX registers again it generates new states and the problem is gone I would like a new option in the Command combo box of the Edit Job menu at System Settings Cron The new command would be named Kill states and the filter would be set in the Parameter box below the Command combo The parameter could accept IPs or Aliases I could execute this command every hour and in the worst case the VOIP service would fail for that time Describe alternatives youve considered I have tested pfctl command with the k command using the IP address of the trunk provider and it worked The alternative is to add the cron job manually from a commnad shell but it will not survive system updates Additional context imagen I have the following error message in my logs config Model OPNsense Diagnostics Netflow cant be saved skip Phalcon Validation Exception OPNsense Diagnostics Netflowcaptureinterfaces WAN interfaces missing in listening interfaces wan in usrlocalopnsensemvcappmodelsOPNsenseBaseBaseModelphp Stack trace usrlocalopnsensemvcappmodelsOPNsenseBaseBaseModelphp OPNsense Base BaseModelserializeToConfig usrlocalopnsensemvcscriptrunmigrationsphp OPNsense Base BaseModelrunMigrations main I have had this happen for at least the last few releases but cannot remember when I started to get this GOT REQUEST TO UPGRADE all Updating OPNsense repository catalogue OPNsense repository is up to date All repositories are up to date Updating OPNsense repository catalogue OPNsense repository is up to date All repositories are up to date Checking for upgrades candidates done Processing candidates candidates done The following packages will be affected of checked Installed packages to be UPGRADED opnsense Number of packages to be upgraded MiB to be downloaded Fetching opnsense txz done Checking integrity done conflicting Upgrading opnsense from to Extracting opnsense done Stopping configddone Resetting root shell Updating etcshells Unhooking from etcrc Unhooking from etcrcshutdown Updating etcshells Registering root shell Hooking into etcrc Hooking into etcrcshutdown Starting configd Keep version OPNsense Monit Monit Keep version OPNsense Firewall Alias Keep version OPNsense OpenVPN Export Keep version OPNsense CaptivePortal CaptivePortal Keep version OPNsense Cron Cron Keep version OPNsense Backup NextcloudSettings Keep version OPNsense TrafficShaper TrafficShaper Keep version OPNsense IDS IDS Keep version OPNsense Proxy Proxy OPNsense Diagnostics Netflow Migration failed check log for details Keep version OPNsense Routes Route Keep version OPNsense AcmeClient AcmeClient Keep version OPNsense Dnscryptproxy Forward Keep version OPNsense Dnscryptproxy General Keep version OPNsense Dnscryptproxy Whitelist Keep version OPNsense Dnscryptproxy Server Keep version OPNsense Dnscryptproxy Dnsbl Keep version OPNsense Dnscryptproxy Cloak Keep version OPNsense Syslog Syslog Keep version OPNsense Wireguard General Keep version OPNsense Wireguard Server Keep version OPNsense Wireguard Client Keep version OPNsense IPsec IPsec Writing firmware settingdone Writing trust filesdone Configuring login behaviourdone Configuring system loggingdone Message from opnsense Roar Checking integrity done conflicting Nothing to do The following package files will be deleted varcachepkgopnsense d c ea edtxz varcachepkgopnsense txz The cleanup will free MiB Deleting files done All done Starting web GUIdone Generating RRD graphsdone DONE Not sure why this started happening as I have not touched the netflow stuff at all x I have read the contributing guide lines at x I have searched the existing issues and Im convinced that mine is new Is your feature request related to a problem Please describe When working with ip aliases VIPs etc there may exist several addresses within the same subnet This will cause warning when using squid k check squidconf acl localnet src Possible internal network interfaces v acl localnet src db b Possible internal network interfaces v acl localnet src Possible internal network aliases acl localnet src db b Possible internal network aliases acl localnet src Possible internal network interfaces v acl localnet src Possible internal network aliases acl localnet src Possible internal network aliases acl localnet src Possible internal network aliases acl localnet src Possible internal network aliases squid k check WARNING A is a subnetwork of B WARNING because of this is ignored to keep splay tree searching predictable WARNING You should probably remove from the ACL named localnet aclIpParseIpData WARNING Netmask masks away part of the specified IP in db b WARNING B db b is a subnetwork of A db b WARNING because of this c b is ignored to keep splay tree searching predictable WARNING You should probably remove c b from the ACL named localnet WARNING A is a subnetwork of B WARNING because of this is ignored to keep splay tree searching predictable WARNING You should probably remove from the ACL named localnet WARNING A is a subnetwork of B WARNING because of this is ignored to keep splay tree searching predictable WARNING You should probably remove from the ACL named localnet WARNING A is a subnetwork of B WARNING because of this is ignored to keep splay tree searching predictable WARNING You should probably remove from the ACL named localnet WARNING A is a subnetwork of B WARNING because of this is ignored to keep splay tree searching predictable WARNING You should probably remove from the ACL named localnet WARNING A is a subnetwork of B WARNING because of this is ignored to keep splay tree searching predictable WARNING You should probably remove from the ACL named localnet Describe the solution youd like Run the src ips through aggregate Unforunatelly I am not familar with Jinja and howwhether you can filter via external commands One must build one list from coresrcopnsenseservicetemplatesOPNsenseProxysquidconf lines interface addr and VIPs pipe it through aggregate and then build the acls I think aggregate will just handle ipv Describe alternatives youve considered If template engine cannot call external filters I fear so at least without additional python code you could use php when save button is pressed to aggregate the IPs and write result as config entry to configxml for localnets which can be used directly by template engine Describe the bug The MAC address database used to get eg the hardware vendor from a mac address in the DHCP Leases page is pretty outdated According to this forum post OPNsense uses the netaddr Python lib which hasnt been updated since January and has no selfupdate mechanism built in From the issues in their Github project this has been mentioned multiple times but it seems to be rather dead To Reproduce Go to Services DHCPv Leases statusdhcpleasesphp Have any recent device on your network See vendor names only for older hardware Expected behavior Show vendor names for all MAC addresses Additional context Maybe using the macvendorlookup Python library is a valid replacement Add ipv addresses to listening interfaces Also add ipv transparent mode listeners Either VIPs if using CARP Or interface address if not using CARP All you need to do is adding a forwarding rule to local interface ip address for transparent mode eg int lan src lan dst any proto inet dstport target lanipv address ToDo Add transparentv proxy template in Describe the bug Hi the failover based on latency are buggy when latency is high the gateway are removed from group gateways many times and when the latency is normal again the gateway returns to group only one time and the connections dont go through it and I need apply firewall rules again Expected behavior If latency is already high and the gateway was removed from group gateways it not should removed again and again Relevant log files Jan monit gatewayalert status succeeded no output Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Jan monit gatewayalert status failed MONITOR FLINGW has high latency removing from routing group ESSSFLNGW Environment OPNsense amd OpenSSL Important notices Before you add a new report we ask you kindly to acknowledge the following x I have read the contributing guide lines at x I have searched the existing issues and Im convinced that mine is new Is your feature request related to a problem Please describe no Describe the solution youd like add some VPN Tunnel states Tunnel Phase into the API for monitoring purposes API should contain the status of the VPN Tunnel as shown in the OpnSense Dashboard see screenshot API should contain the status of the Phase Entries as shown in VPN IPSec Status Overview Describe alternatives youve considered parsing the vpn status of the dashboard will run into issues upon updates of opnsense not a valuable solution Additional context At present visibility of enduser identity is lost within OPNsense when accessing the Administration frontend through reverse proxy Proposed here is native lighttpd support for capturing these data which might serve as a baseline for expanded configuration scenarios moving forward Shown here is the result I have also tested the direct nonproxied access of OPNsense via the configured lighttpd port rather than nginx port which results in the expected logging of enduser IP modextforward exists in the current version of lighttpd distributed with OPNsense so no additional components are required beyond this revision to lightywebConfiguratorconf Of note Im not certain that the inclusion of modextforward at line is the expected behavior of core developers Please confirm that this does not belong at line noting that this module must be loaded after both modopenssl and modaccesslog to function properly The configuration proposed here supports proxied connections from localhost which will not meet the needs of all deployments Although the mod does support extforwardforwarder all trust this is clearly a bad pathforward so consideration may be given to adding a Support Proxied Connections option at System Settings Administration wherein the user can select a checkbox and add a list of proxy IPs to allow The intention of this functionality should be further clarified via help text to avoid user perception of this setting effectively enabling a reverse proxy vs only supporting connections from them modextforward also supports connections from HAProxy but enabling this configuration is beyond the scope of this pull request Ive acknowledged this observation in the contents of the code Important notices Before you add a new report we ask you kindly to acknowledge the following x I have read the contributing guide lines at x I have searched the existing issues and Im convinced that mine is new Bug decscription Walking through the Wizard configuring a static IPv WAN still gateways get configured The IPv WANGW corresponding to your static WAN configuration It will show as offline in System Gateways Single The IPv WANDHCP from the default DHCP setting for IPv of the interface It will be online in System Gateways Single and cannot be removed there of course comes from interface configuration Note Getting state online happens even when no IPv configuration DHCP is present To Reproduce Reset to defaults Wizard Configure static IPv WAN have no DHCP on WAN side Test ping to some WAN address fails with ping sendto No route to host Expected behavior Disable IPv DHCP Allow IPv setting eg IPv Configuration Type None in Wizard Workaround After running through the wizard go to Interfaces WAN and set IPv Configuration Type None Edit the IPv GW changing nothing save The IPv GW will now change to state online ping works now Additional context related to Environment Important notices Before you add a new report we ask you kindly to acknowledge the following x I have read the contributing guide lines at x I have searched the existing issues and Im convinced that mine is new Use case Be able to reconfigure the system right after a configuration reset and reboot without need to manually power on eg firewall being remote having separate connection to the first LAN port getting configured to default Current behaviour Shut down after changes are complete Proposed solution Remove the yes button instead show buttons Load defaults and poweroff Load defaults and reboot As an extra add a confirmation dialog before performing the config reset 