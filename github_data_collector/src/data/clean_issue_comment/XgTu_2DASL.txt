There is no visualizerar file for google drive Could you please upload it once more Could you please publicize the training code We are not sure about the training details such as how to get the mean and std of parameters and how to set the super parameters about the net Thanks a lot Hi XgTu Thanks for sharing the code I am able to successfully run the project however the obtained objs are just white meshes The material file for each obj is not getting generated In the writeobjm function i am guessing options argument has to be called properly Should we write texture jpg to the mtl file ie any connection between optionsnmfile is texture jpg but in this project we are not writing generating any texture file Can you please tell me if i am wrong and how to create mtl files Thank you Hellothanks for your open source code Im getting start to follow the work of PRN but I cannot really reimplement their work yet Ive read your paper on arxiv and noticed that you compared DASL with PRN in experiment part So I hope you can help me with some problems about the NME metrics Do reimplement PRN and get the results or you just evaluate their model How do you calculate D NME and do you have any idea about how do PRN calculate D NME I evaluated the model provided in their github on AFLW D The D NME is alright But I come up with some problem when calculating D NME I use exactly the same normalization factor bounding box size and calculate the mean L distance between ground truth and predicted results But the kpt D NME I got is around which is much higher than PRN papers and similar to in your paper Ive tried to refer to the evaluation code of DDFA but it seems that they didnt evaluate D coordinates Hi Tu Thanks for your code I have obtained vertices from DMM but I do not which pixels are the D visible landmarks of AFLWLFPA Could you please tell me the relationship between them Thanks Hi i recently read your paper but i have a little confusion about the backward pass In your paper you show that you backward pass your predicted d landmarks to output x d do you means that you replace x d with x d to generate d FLMs and keep the input image unchanged and restart forward training If i am understanding it in a wrong way could you please describe the backward pass with more details Hello I am very happy to see your work I want to achieve a dense alignment of the face like the following But I didnt see how to implement this step in your code and your code is based on Matlab not Python Can you provide a Python implementation This will help understand the meaning of each step thank you Hi I am kind of new to pytorch did anyone know which script should I run in order to predict D or D landmarks for a given facial image or should I write a new testing code and use the model such as DASLcheckpointepochallParamsstage pthtar for this task Thanks a lot ddfa testvertex dasl testvertex ddfa dasl Where the code to apply Face swapping 