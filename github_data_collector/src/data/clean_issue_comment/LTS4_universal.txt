This is my Pytorch code These days I implement your idea by pytorch But I find that when I use the same dataset my code can only fool images in Validation set but your code can fool I checked it many times but still couldnt find the problem Could you help me thank you Hi Please be aware that imreadimresize under scipymisc has been removed from Thank you for the work My concept of targeted attack means we want to set specific target class to let the attacker to make such adversarial image Can universal perturbation do that and how The perturbation file is saved for every pass on the dataset so we wont need to start fooling rate from zero but from the file saved in universalpartialnpy This is similar to saving model after every epoch while training Similarly the perturbation will be saved after every pass in universalpartialnpy and when starting the universalpertpy each time it will look at universalpartialnpy and will load the perturbations from there and start fooling from that particular foolingrate When finding the perturbation for MNIST dataset using samples for each pass the FOOLINGRATE doesnt increase beyond even after passes The fooling rate is not increasing rather oscillating between and I have used conv layers with batch norm one max pool and fc layers The UAP calculated after passes with fooling rate of has a mean of as most of absolute value is Please I need some help as I cant understand what is wrong in my implementation Looking forward to your reply Dear Mr I am a student now I have just studied your codes for about one weeks I am very interested in your finished paper I think this paper is of great value to me in the process of studying universal adversarial perturbationsBut I have some questionsI will appreciate it if you can explain these problems Question v v dr in universalpertpyLine the v is the perturbation vectors and dr is the minimal perturbation that fools the classifier According your codes the dr have the dimensions with the input image which has three dimensions and v is the perturbation vectors but your setting is v which means a real value why can they be added I wonder the dimensions of v and dr Question driter deepfoolcurimg v f grads numclassesnumclasses overshootovershoot maxitermaxiterdf in universalpertpyLine in which the function deepfool is in deepfoolpy w npzerosinputshape Line which means the dimensions of w is same with that of inputshape which is wk gradients k gradients in deepfoolpyLine which means the dimensions of wk is w wk why can wk be assigned to w Thank you for taking time out of your busy schedule and look forward to hearing from you soon Yours faithfully Thank you very much for the code Learned a lot from it The issue i am facing is that the value of v after being computed is coming out to be NaN I am implementing this in Matlab I have changed the value of optsdelta and optsp random changes but in all the cases it outputs value NaN The new fooling rate comes around Kindly advice PS To be more specific the output dr projectboundarypolyhedronddfffidxQ is turning out to be zero Hi Thanks for your code I learn a lot from it When I run the python code with inception h model it works very well and I can reproduce perturbation maps However when I try the code with VGG or ResNet models I always get GPU memory full errors I used the tensorflow SLIM pretrained models and freeze them into pb file just like the format of inception h model in your example Do you have any idea to work around this issue I use a K C G Mem GPU Thanks In demoinceptionpy pathtrainimagenet datasets ILSVRC train is passed into createimagenetnpy This path doesnt exist so the rest of the function doesnt run What is the best way to get the data so the universal perturbation vector can be created