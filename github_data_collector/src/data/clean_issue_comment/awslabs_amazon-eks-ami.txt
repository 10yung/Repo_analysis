Is it possible to retrieve the cluster name on the EKS nodepod without having to pass this as an environment variable to the configuration Issue Description of changes See CIS Benchmark By submitting this pull request I confirm that you can use modify copy and redistribute this contribution under the terms of your choice If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security Issue Description of changes See CIS Benchmark By submitting this pull request I confirm that you can use modify copy and redistribute this contribution under the terms of your choice If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security Issue Description of changes See CIS Benchmark By submitting this pull request I confirm that you can use modify copy and redistribute this contribution under the terms of your choice If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security Description of changes Update Makefile to reflect the correct kubernetesversion and kubernetesbuilddate values used to generate the official AWS AMIs By submitting this pull request I confirm that you can use modify copy and redistribute this contribution under the terms of your choice If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security Were in eucentral using EKS with t xlarge worker nodes After updating to AMI v the allocatable memory went down from Ki to Ki Also the allocatable CPU went down to m which is less important Wondering whats going on here Please use this template while reporting a bug and provide as much info as possible Please also search for existing open and closed issues that may answer your question Thanks What happened upgraded EKS cluster from to Cloudformation stack consits of EKS cluster and associated ASG with UpdatePolicy set to AutoScalingRollingUpdate I updated ami version in launch config and rolling update was initiated by the time EKS was updating kubernetes software version fast fails due to set o options after min I took more than min for my cluster to update What you expected to happen bootstrap waits until EKS is ready How to reproduce it as minimally and precisely as possible Upgrade EKS from to Fleet already running bootstrapsh and waiting for the cluster to be available Anything else we need to know Environment AWS Region all Instance Types all EKS Platform version use aws eks describecluster name name query clusterplatformVersion eks Kubernetes version use aws eks describecluster name name query clusterversion AMI Version amazoneksnode v ami a f b a Kernel eg uname a all Release information run cat etceksrelease on a node Put release info in the triple backticks below If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security Issue if available Description of changes IPVS is a relatively common feature request for EKS users Their primary use case is generally to gain access to more advanced load balancing algorithms like leastconnections than what is provided by IPTables and for the performance benefit when running large numbers of Services and Pods IPVS is better at handling large numbers of rulelookups than IPTables We can see this item is on the GitHub Containers Roadmap with thumbsups but it hasnt yet been implemented Currently we dont provide IPVS as an option in the EKS AMIs since upstream Kubernetes has not set this as the default yet However Kubernetes has flagged IPVS has generally available as of hence users are interested in testing it out There are some issues with IPVS which are being ironed out which explains why it hasnt yet become the default for upstream Kubernetes However since we have interest from users already I think its worthwhile to provide this as an option for users to at least test out for themselves We can emphasize that the feature is beta but still make it easy enough for eager users to begin testing in anticipation for it becoming a future Kubernetes default This also benefits upstream Kubernetes since EKS users can funnel their feedback upstream if they encounter any issues with IPVS during testing Im opening a Pull Request which implements this feature with the following implementation Define an Environment Variable in the eksworkeral json file where users can define the netfiltermodule The options are iptables which Ive set as the default and ipvs Modify installworkersh to install the ipvsadm package and relevant kernel modules only when the netfiltermodule env var is set to ipvs We do not remove the IPTables setup section of installworkersh because IPTables is still necessary for the AWS CNI to function The AWS CNI uses IPTables for creating an SNAT rule for Pod traffic leaving the VPC Therefore IPTables needs to be setup to ensure Pods can connect to endpoints outside the VPC Modify the EKS Logs Collector script to gather IPVS rules by default This is inside a try block so even if IPVS isnt installed because the user selected IPTables it wont affect the script Additionally I have not added the ipvsadm command to the REQUIREDUTILS section since we dont need to fail when this command isnt installed Testing Ive tested the default IPTables setup by just running make in the repo without selecting IPVS Ive launched a Node Group from the resulting AMI and confirmed that k s Services are operating normally using IPTables and ipvsadm is not installed as expected So the existing functionality is still working as expected Then Ive modified the netfiltermodule env var to ipvs and run make again Ive modified the kubeproxyconfig ConfigMap to switch the mode from iptables to ipvs Ive launched a new Node Group from the resulting AMIs and cordoned all existing Nodes to force my Pods to schedule to the new Node After creating a Deployment and exposing it as a ClusterIP Service running ipvsadm l n on the Node confirmed the expected rules were created successfully Connecting to the Service endpoint worked correctly Ive recreated the above test with a NodePort Service successfully as well Connecting from the Pod to the internet also works correctly indicating the SNAT rules created by the CNI for traffic leaving the VPC is still working as expected Running the new logs collector script correctly bundles the IPVS rules into the networkingipvsrulestxt file If you have any questions about the above please let me know By submitting this pull request I confirm that you can use modify copy and redistribute this contribution under the terms of your choice If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security Please use this template while reporting a bug and provide as much info as possible Please also search for existing open and closed issues that may answer your question Thanks What happened We were using the CloudFormation template to create the stack which contains several ASGs as work node in the EKS cluster However when we tried to add a second stack using the same template PODs in the second stack cannot resolve any domain but can ping Heres a minimal reproducible example Its very easy to follow Weve also add unique name to all the resources created by the template so that the second cluster has no conflicts with the first one Could someone from AWS give it a look I believe this might lead to discovery of a bug Environment AWS Region uswest Instance Types c xlarge EKS Platform version use aws eks describecluster name name query clusterplatformVersion eks eks Kubernetes version use aws eks describecluster name name query clusterversion AMI Version Most recent Put release info in the triple backticks below If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security In order to support randomfully we need at least iptables The latest Amazon Linux supports We need to update to that version and configure legacy mode in order for things to work well with Kubernetes Environment AWS Region Instance Types EKS Platform version use aws eks describecluster name name query clusterplatformVersion Kubernetes version use aws eks describecluster name name query clusterversion AMI Version Kernel eg uname a Release information run cat etceksrelease on a node Put release info in the triple backticks below If this is a security issue please do not discuss on GitHub Please report any suspected or confirmed security issues to AWS Security 