See The container image has the systemd el x package installed which contains a few dozen files in usrlibsystemd but that directory is missing The end result is that the udevadm command fails ceph rootgnit udevadm udevadm error while loading shared libraries libsystemdshared so cannot open shared object file No such file or directory After a reboot the encrypted partitions arent opened so the cephvolume simple scan command wont find the block partition not mapped broken symlink and the simple activate will fail console cephvolume simple scan devsdb force broken symlink found tmptmpept ox jblock devmapper d feaa a f console cephvolumelog cephvolumeutilsystem INFO devsdb was not found as mounted cephvolumeutilencryption WARNING failed to detect device mapper information cephvolumeutilencryption WARNING failed to detect device mapper information cephvolumedevicessimplescan WARNING broken symlink found tmptmpept ox jblock devmapper d feaa a f cephvolumedevicessimplescan ERROR skipping due to IOError on file tmptmpept ox jblock Traceback most recent call last File usrlibpython sitepackagescephvolumedevicessimplescanpy line in scandirectory if systemisbinaryfilepath File usrlibpython sitepackagescephvolumeutilsystempy line in isbinary with openpath rb as fp FileNotFoundError Errno No such file or directory tmptmpept ox jblock cephvolumeutilencryption WARNING failed to detect device mapper information cephvolumedevicessimplescan INFO skipping binary file tmptmpept ox jblockdmcrypt If the OSD has already been scanned then we shouldnt update the associated json file on each start Closes Signedoffby Dimitri Savineau dsavinearedhatcom The Sree interface wasnt compatible with python Thoses changes allow to run sree on both python and This was breaking ceph nano cn with the CentOS based ceph container images like masteroctopus Remove pycurlStringIO requirements and switch to requests Change the exception syntax in xmlparsepy Try to import urlparse py then urllibparse py CORSConfiguration encodedecode for md content Signedoffby Dimitri Savineau dsavinearedhatcom Is this a bug report or feature request Bug Report Bug Report What happened When specified BASEOSTAG build image failed make FLAVORSluminous centos RELEASE TAGREGISTRYregistryicpcom libraryceph BASEOSREGISTRYregistryicpcom libraryos BASEOSREPOinspurcentos BASEOSTAG DAEMONTAGceph IMAGESTOBUILDdaemon DAEMONBASETAGcephbase build can not get correct cephiscsirepo cause that wrong url What you expected to happen Url should be How to reproduce it minimal and precise Specify BASEOSTAG Environment OS eg from etcosrelease cat etcosrelease NAMECentOS Linux VERSION Core IDcentos IDLIKErhel fedora VERSIONID PRETTYNAMECentOS Linux Core ANSICOLOR CPENAMEcpeocentoscentos HOMEURL BUGREPORTURL CENTOSMANTISBTPROJECTCentOS CENTOSMANTISBTPROJECTVERSION REDHATSUPPORTPRODUCTcentos REDHATSUPPORTPRODUCTVERSION Kernel eg uname a Linux xiettnovalocal el x SMP Thu Nov UTC x x x GNULinux Docker version eg docker version Docker version build d d Ceph version eg ceph v In a container theres no need to install documentation Pass the relevant option for yum to skip documentation installation Signedoffby Yaniv Kaul ykaulredhatcom Hi all As we know we can easily run any components of ceph cluster with one docker imagecephdaemonlatestluminous eg docker run d nethost namexxx v etclocaltimeetclocaltime v etccephetcceph v varlibcephvarlibceph e MONIPxxxxxxxxxxxx e CEPHPUBLICNETWORKxxxxxxxxxxxx cephdaemonlatestluminous monosdmds And we are able to check logs by command docker logs f xxx But as time flies month for example sizes of these stdout may take to much under directory varlibdockercontainersCONTAINER IDCONTAINER IDjsonlog may reach G It is not so easy to control the size of them I know there is one ENTRYPOINT in Dockerfile optcephcontainerbinentrypointsh and when running docker we can add CMD like monosdmgr etc To setup different componets and check log So are there any waysbring in new Env parameter or bring in new option following behind the scripts entrypointsh to define one switch which controls or restrains stdout log and redirect the stdout log to one directory inside the container so that we can mount the directory outside to the host directory and handle the logs easily BR We need to build development containers from git with branch names like master nautilus fix etc since not all branches begin with wip Right now the labels as reported by podman inspect look like Labels CEPHPOINTRELEASE GITBRANCH HEAD GITCLEAN True GITCOMMIT e c ab cce afd c ac a b GITREPO gitgithubcomcephcephcontainergit RELEASE wipcddf a maintainer Dimitri Savineau u cdsavinearedhatcom u e orglabelschemabuilddate orglabelschemalicense GPLv orglabelschemaname CentOS Base Image orglabelschemaschemaversion orglabelschemavendor CentOS For a ceph v of ceph version gf b a d dc e f afa cf bb df octopus dev Id like to add labels like the following CEPHVERSION gf b a CEPHRELEASE octopus CEPHRELEASETYPE dev or rc or stable Currently cephdaemon is executing ceph v inside the container to get this information but simply extracting it from the container image metadata would be much faster Are you in the right place For issues or feature requests please create an issue in this repository Did you already search the existing open issues for anything similar Is this a bug report or feature request Feature Request Connecting the ceph project and cephcontainer projects together so that we can build and package from ceph source code to container images Currently Im able to use the ceph project to compile all the source code and package them into a dozen of RPMs How can I use these local RPMs as an input to the cephcontainer project in order to further package them into container images Feature Request Are there any similar features already existing What should the feature do What would be solved through this feature Does this have an impact on existing features Environment OS eg from etcosrelease Kernel eg uname a Docker version eg docker version Ceph version eg ceph v Hello folks I dont understand this moment can u help me plz Where Do i need to put ipaddress This only works if you have skyDNS resolveable from the kubernetes node Otherwise you must manually put in one or more mon pod ips