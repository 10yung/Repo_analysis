Hi guys Im trying to build a DeepLearning network which contains a subtraction operation between two layers and I cant find a way to do that while MATLAB has just an addition operation additionLayer for more clarification the equation below discribes the step that I should do C X AvgPoolingX any suggestions guys the rbm gets initialized by a weight matrix of X and bias matrices also get initialized similarly Could u let me know where they get initialized so that I can change the dimensions for my dataset mlcnnm has a method named updateParams Unfortunately in this version it does not update the output layers weights so the whole network is like a car with a working engine but without a mechanism to transfer engines power to the tires I have a suggestion to make it work to do so I have changed the body of updateParams method to function self updateParamsself net updateParams Update network parameters based on states of netowrk gradient perform regularization such as weight decay and weight rescaling wPenalty for lL selfnLayers Changed from for lL selfnLayers by Masih Azad switch selflayerslLtype CURRENTLY ONLY UPDATE FILTERS AND FM BIASES PERHAPS IN THE FUTURE WELL BE FANCY AND DO FANCY UPDATES case conv Changed from case convoutput by Masih Azad lRate selflayerslLlRate for jM selflayerslLnFM UPDATE FEATURE BIASES selflayerslLbjM selflayerslLbjM lRateselflayerslLdbjM UPDATE FILTERS for iM selflayerslL nFM if selfwPenalty L REGULARIZATION wPenalty selflayerslLfilteriMjMselfwPenalty elseif selfwPenalty L REGULARIZATION SUB GRADIENTS wPenalty signselflayerslLfilteriMjMabsselfwPenalty end selflayerslLfilteriMjM selflayerslLfilteriMjM lRateselflayerslLdFilteriMjMwPenalty end end Added by Masih Azad case output lRate selflayerslLlRate selflayerslLb selflayerslLb lRateselflayerslLdb if selfwPenalty L REGULARIZATION wPenalty selflayerslLWselfwPenalty elseif selfwPenalty L REGULARIZATION SUB GRADIENTS wPenalty signselflayerslLWabsselfwPenalty end selflayerslLW selflayerslLW lRateselflayerslLdWwPenalty end end end Why the values of property mlcnnnetOut does not match with values of testLablels After executiong demoMLCNNm Even elements of mlcnnnetOut are between and but not exactly and Hi I was curious if dbn can call crbm instead of rbm to build a convolutional dbn as in ICML paper of Lee 