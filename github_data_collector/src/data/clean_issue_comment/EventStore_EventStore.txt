Some GRPC test cases are seeing intermittent internal failure when running on the CI build on various platforms Root cause on this is currently not clear and will need more research if it continues impacted tests across various platforms X EventStoreClientStreamswritestreammetasecuritywritingmetawithnotexistingcredentialsisnotauthenticated Expected typeofEventStoreClientAccessDeniedException Actual typeofGrpcCoreRpcException StatusStatusCodeCancelled Detail GrpcCoreRpcException StatusStatusCodeCancelled Detail X EventStoreClientStreamsappendtostreamlimitsfailswhensizeexceedsmaxappendsize Expected typeofEventStoreClientMaximumAppendSizeExceededException Actual typeofGrpcCoreRpcException StatusStatusCodeCancelled Detail GrpcCoreRpcException StatusStatusCodeCancelled Detail X EventStoreClientStreamswritestreamsecuritywritingwithnotexistingcredentialsisnotauthenticated ms Error Message AssertThrows Failure Expected typeofEventStoreClientAccessDeniedException Actual typeofGrpcCoreRpcException StatusStatusCodeCancelled Detail GrpcCoreRpcException StatusStatusCodeCancelled Detail Stack Trace at GrpcNetClientInternalHttpContentClientStreamWriter WriteAsyncCoreTRequest message at EventStoreClientEventStoreClientAppendToStreamInternalAppendReq header IEnumerable eventData UserCredentials userCredentials CancellationToken cancellationToken in homevstswork ssrcEventStoreClientEventStoreGrpcClientAppendcsline Inner Stack Trace at GrpcNetClientInternalHttpContentClientStreamWriter WriteAsyncCoreTRequest message at EventStoreClientEventStoreClientAppendToStreamInternalAppendReq header IEnumerable eventData UserCredentials userCredentials CancellationToken cancellationToken in homevstswork ssrcEventStoreClientEventStoreGrpcClientAppendcsline X EventStoreClientStreamswritestreammetasecuritywritingmetatonoaclstreamisnotauthenticatedwhennotexistingcredentialsarepassed ms Error Message AssertThrows Failure Expected typeofEventStoreClientAccessDeniedException Actual typeofGrpcCoreRpcException StatusStatusCodeCancelled Detail GrpcCoreRpcException StatusStatusCodeCancelled Detail Stack Trace at GrpcNetClientInternalHttpContentClientStreamWriter WriteAsyncCoreTRequest message at EventStoreClientEventStoreClientAppendToStreamInternalAppendReq header IEnumerable eventData UserCredentials userCredentials CancellationToken cancellationToken in homevstswork ssrcEventStoreClientEventStoreGrpcClientAppendcsline Inner Stack Trace at GrpcNetClientInternalHttpContentClientStreamWriter WriteAsyncCoreTRequest message at EventStoreClientEventStoreClientAppendToStreamInternalAppendReq header IEnumerable eventData UserCredentials userCredentials CancellationToken cancellationToken in homevstswork ssrcEventStoreClientEventStoreGrpcClientAppendcsline In the projections system when TransactionFileEventReader reaches the end of the TF file it subscribes to the Awake to be notified of further events The Awake service does not have any history an will only notify if new events are received If in the gap between the completion of the read operation and the activation of the subscription the awake service handles a message on the stream the projection will not get notified This race condition is somewhat self healing in that any further write past the last known position will trigger the notification But in the cases where the cluster is idle the update make take an indeterminate length of time to resolve and where the event is a delete further writes may happen on the stream This is seen in intermittent test case failures in the whenrunningandeventsareindexedbutastreamandtombstonepostponed tests Projection subsystem test changes per Replication Tracking Test instability fixed via adding deterministic checking on published status Read request tests fixed by adding deterministic IndexCheckpoint evaluation on replica nodes before attempting to read Fixing Instability due to projections race conditions is out of scope for this PR workarounds added Instability due to GRPC issues is also out of scope The test whenprojectionsubsystemrestartedtwice is unstable in the CI builds While a useful developer test rapid and repeated restarts of the Projection subsystem is not a system feature or goal The test has been marked Explicit as a work around to avoid false negatives in the CI test runs in Requested resolution is any one of Confirm the Explicit designation Fix the test to be stable in CI Remove the test as unwarranted I actually wanted to continue the discussion on this issue here while the findings were that the initial request was quite slow seconds which should still be unacceptable the resulting performance on subsequent appends is still unacceptable I was testing the same thing as this other user and determined that on avg a single append to EventStore takes ms which is extremely slow in a append only design Im trying to determine where this is coming from and its a long shot from the proposed k the documents suggest you can achieve over TCP Are there benchmarks anywhere showing what raw through put should be considered in a single node setup with single thread vs multiple threads Is there a way to determine what could possibly be taking ms to append bytes to a stream PC specs are fairly high end but running eventstore locally with no options passed Just work with ExpectedVersion producer There is a possibility whereby a multimaster scenario will arise due to nodes using out of date information from gossip during elections to propose or accept a node as a master candidate The gossip carries with it the Epoch Number which is used to determine whether a master candidate is a legitimate master candidate In the following example a master proposal with a higher epoch number could result in a node accepting a new master candidate even if its current master is still alive The above means that if a node gets a master proposal before it received a gossip from its master after an election the master proposal is accepted Example node cluster Node through to Node Node is elected master An election is started because Node is restarted Node is the leader of the elections Node proposes Node as the master as according to it its the best master candidate it might have not received a gossip from the current master node Node accepts its proposal Node rejects the proposal as its the master and it has the most up to date information about itself Epoch Number included and its still alive Node accepts the proposal because even though it has a previously elected master it hasnt received a gossip from the master Node with the updated Epoch Number whereas the proposal has a higher Epoch Number than the current master Node at this point Node rejects the proposal as it received a gossip from the current master Node Node accepts the proposal because it also hasnt received a gossip from the current master Node The above results in multiple masters existing in the same cluster without a network partition having occurred Once this happens a series of elections will take place Hi I have a question regarding backup order of chk files themselves If I understand various bits of info from documentation Github issues and Google Groups content of chaserchk is pointer to position in chunk files continuum reached by chaser process while writerchk is pointer to position reached by writer process Chaser process should always be behind the writer or at the same point never ahead of it Does it make sense to copy chaserchk before writerchk when performing backup The docs only say that all chk files should be copied before all other files index and data chunks but does not specify ordering between various chk files From what I understand if writerchk is copied before chaserchk it might be possible that copied chaserchk contains pointer that is after larger than value in copied writerchk which might be a problem not sure if EventStore can recover from this during startup Also another unclear point what is the purpose of epochchk and its relation to writerchk and chaserchk Does it matter if it is copied before or after writerchaser chk files Info on epochchk is particularly hard to find online As for truncatechk it will be overwritten by chaserchk during restore so it really doesnt matter when it gets copied or if at all To sum it up in one question what should the order of copying chk files during backup be so that backup consistency is ensured Explicit ordered list would be really helpful and reassuring It would be ideal if backup page in docs elaborated on this a bit Note that Im mostly interested in singlenode setup We need to find a suitable replacement for the syscpu System CPU cross platform Once is merged the syscpu will only be available via Windows as it still uses Performance Counters there Is your feature request related to a problem Please describe Scavenging Ptables can take a considerable amount of time as a database grows bigger In some cases multiple days Describe the solution youd like To add a flag to explicitly specify if scavenging of ptables needs to be skipped Describe alternatives youve considered At the moment it is possible send a stop scavenge request to stop scavenging when scavenging of Ptables has started However this needs to be done after chunks have been scavenged and it is highly likely that scavenging of at least one Ptable has already started in the meantime 