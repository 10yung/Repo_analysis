Im trying to switch to ABBA from optimizely cause i dont mind writing jquery test code on my own Still the main problem is that id like to define experiments on server side not in js code snippet Current solution lacks flexibility because i have to change the code every time i want to change my test Its an issue when you work with several clients and dont controll website code I could manage this in Google Tag Manager but AB test scripts should load ASAP and in GTM you cannot controll the order of firing scripts and all AB test vendors say that GTM is not the right tool if you want to change page contents So the solution would be to add a parameter to javascript request and concatenate test code or request it from standard js Youd also have to add possibility to create experiments on the backend but if now theyre created on first request it should be easy to simply make this request on the backend do you think its possible Is there a reason why you didnt specify any versions for the gems in Gemfile Im asking because it can lead to unexpected behaviour if you always retrieve the latest versions of the gems Is there a stable gemset with defined versions that you would suggest Odd that this happens only when running ABBA as a rack app under NGINXPassenger but when I do I get this error message Error compiling CSS asset EncodingInvalidByteSequenceError xE on USASCII in varcodeabbaappassetsstylesheetsexperimentcssstyl varcodeabbavendorbundleruby gemsexecjs libexecjsexternalruntimerb in read I understand that issue may be more appropriately answered in the ExecJS or the Stylus project maybe even Passenger Im not sure exactly which of these projects this is best addressed in This doesnt happen when running under thin However by adding this line at the top of the configru file the issue is solved for me given my preferred deployment setup Encodingdefaultexternal UTF Thought Id open this issue in part to see if others have this problem This works with the latest Cedar stack on Heroku Thanks In my head I expected this framework to report unique visitors not total So if the same user refreshes the page multiple times Im seeing a visit for each page load whereas I expect to see visit Im still pretty new to AB testing philosophy am I doing it wrong to expect unique visits If not would you accept a patch for that Thanks Bob I was getting an error while deploying to Heroku ruby symbol lookup error appvendorbundleruby gemseventmachine librubyeventmachineso undefined symbol rbenableinterrupt Given the fact that Ruby is not explicitly specified it was using Got it to work by specifying ruby in Gemfile Please update to Ruby Hi Im trying to extend your chart by a line showing the visitorsconverstions over time in order to have a better feeling for the shown values The data is already selected but I have very serious problems to get the data into the chart Im new to d and maybe I oversee the point where you put the elements into the chart Could you please elaborate a little bit how the chart works Thanks Add a callback to Abbacomplete that fires when tracking image has loaded Use case you want to record a completion when user clicks something In many cases eg signup or purchase button this links to a different page but you dont want to navigate away until the completion was recorded Full disclosure I authored the original ABBA library This looks like a great library for people who want to run AB tests themselves I havent seen any other package that takes care of the whole stack and makes it this easy However Im wary of the statistics here for a few reasons The package appears to give onetailed pvalues This is debatable but I believe that doesnt line up with how most people interpret their AB tests and thus leads to an excess of false positives The package supports multiple comparisons but includes no correction or warning for it Granted very few AB testing packages address this but it can also lead to a potentially serious excess of false positives The package computes a table of four normal tail probabilities itself using a fairly crude method a normdist step x normdist x a Mathsqrt MathPI MathE x ZTOPROBABILITY map pct normdistfind xa a pct first pct reverse resulting in zvalue computed tail prob actual tail prob For the largest zvalue the computed tail probability is low by a factor of which can be substantial for people trying to run highconfidence tests again its overestimating confidence which can again lead to excess false positives Itd be simpler and more accurate to hardcode a lookup table tables of these values are readily available One could also make use of a statistical library or directly code a numerical approximation to the standard normal CDF The package uses the nonpooled Ztest for two proportions in case where I believe the pooled test is more appropriate because the null hypothesis is that the control and the variation have the same conversion rate This tends to overestimate Zvalues and thus again confidences The Ztest can be inaccurate for small samples though this doesnt actually contribute much error since the package requires that the total number of conversions is at least which keeps us in pretty safe territory With highly uneven sampling weights we could get into smallsample trouble but its definitely less of an issue As an example of the potential for numerical accuracy issues consider an experiment with conversions in baseline and conversions in one variation The package reports confidence or a onetailed pvalue Fishers Exact Test gives a onetailed pvalue of The original ABBA gives a twotailed pvalue of corresponding to a onetailed pvalue of roughly So were underestimating the onetailed pvalue by a factor of and the twotailed pvalue which is probably more appropriate by a factor of This is pretty substantial our longrun falsepositive rate will be x higher than we expect ignoring multiple testing issues I think this would be a really awesome contribution to the world of AB testing with some more robust statistics Id suggest using the original ABBA JS library or perhaps a port of the Python version to Ruby which also gets you some nice confidence intervals on proportions and improvements Together the two would make a pretty sweet solution to doityourself AB testing Looks like you are using a tailed test to calculate the probability Is that correct I see both ways used in different AB testing tools Optimzely use a tailed test I believe Curious as to the thinking behind the choice 