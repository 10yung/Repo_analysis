Hello again Were using your work around for getting the assets for the S file but now were encountering Stack level too deep errors when running certain jobs Is there a way to keep the gem from running in our jobs layer but keep it running in our rails layer Im not seeing a config option for that but I may be missing it This is ironically the opposite as the problem we were discussing last week load time coverage is being reported as runtime The readme mentions that COVERBANDDISABLEAUTOSTART can be used to prevent require coverband from automatically starting coverage This is our usecase we want to use a feature flag to enable coverband In the Gemfile I have require coverband Start rails console with COVERBANDDISABLEAUTOSTARTtrue Inside configintitializerscoverbandrb call Coverbandstart Observe on the web interface that all coverage is being reported as runtime Before runs benchmarks on reporting large sets of files to redis Warming up storereportsall i ms Calculating storereportsall is in s Warming up storereportssubset i ms Calculating storereportssubset is k in After Warming up storereportsall i ms Calculating storereportsall is in s Warming up storereportssubset i ms Calculating storereportssubset is k in s Using msgpack gives around a speed increase along with a moderate decrease in memory usage CPU utilization does go up but that seems to correlate to more commands per second Warning coverage data from Coverage exceeds line count in Userskarlbaumworkspacefooappworkersbarworkerrb When not tracking gems coverband should use the gem paths to ignore any nonstandard gem paths that happen to be located within the project directory See for more context We have one particular controller file that is not showing up in our coverband reports and were trying to figure out why Ive looked at this but it doesnt offer any clues irb Coverbandconfigurationignore erb slim tmp vendorruby The controller in question is appcontrollersusersregistrationscontrollerrb and coverage data for it IS generated locally but not in production And we know that its used in production and handling traffic We also have a file at appcontrollersregistrationscontrollerrb Yeah I know dont ask Is it possible that theres a name collision of some sort Any suggestions for how to debug this since its only happening in prod In deployments with numerous ruby processes coverband may be reporting to redis from multiple projects at the same time When the HashRedisStore is used this may cause contention on the redis instance since it is single threaded Perhaps each coverband ruby instance should vary on reporting interval by a random number of seconds Might also be able to leverage a redis incr so that the reporting interval is not so random for each process Were trying to use a custom config to set the store to a different redis URL but coverband is picking up ENV REDISURL instead It seems like coverband goes for the ENV var when its first loaded which seems to happen before our config file is fired And then it seems like calling configstore has no effect Our config looks like this coverbandredisurl ENVfetchENVfetchCOVERBANDREDISPROVIDER Coverbandconfigure do config configstore CoverbandAdaptersRedisStorenewRedisnewurl coverbandredisurl end Hey Wanted to follow up We fixed our issue from a while ago We also added some metrics to determine the impact of Coverband I wanted to bring up our findings as they seem significantly worse than the blog post benchmarks I know that post is a year old exactly actually and Coverband is on v now but it seems to be the latest benchmark figures so its what I was hoping to see What we found was that the th percentile for No Coverband vs Coverband is about what the blogpost mentions but the tail latency is quite sizeable As you go up in the percentiles of each you see progressively worse relative performance See below To help you parse that the group is on the right Notice its pairs of coverbandfalse and coverband true The first pair represent falsetrue of th percentile The next pair is falsetrue of th percentile and finally th percentile The numbers are total request time in ms for all requests coming through the middleware and we log it in a requestend middleware These stats were gleaned over a hour period with min rollup on Datadog Thats about reqmin during the hr period hitting Coverband and far far more hitting as noncoverband The choosing of Coverband processes is totally random Due to the tail latency were hesitant to roll out Coverband beyond our very very small percentage of processes that we currently have We have no custom configuration on the coverband save for setting the background sleep time to be s instead of We also have no special anything on Coverband We removed all that after the previous discussion and went with a require false use a random number threshold to gate doing the require inside applicationrb as our way of turning on Coverband Curious what your thoughts are Is this expected Any way to decrease the tail latency PS It would be cool if you had a built in mechanism for doing process or thread based activation thresholds Eg roll out to of your processes or threads 