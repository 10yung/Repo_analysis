fcnTestm makes error berkeleyVoc Segmentstargz ERROR vocSetupAdditionalSegmentations line untararchivePath tempDir ERROR fcnTest line imdb vocSetupAdditionalSegmentations Any body know how to fix this SCRIPT vlimreadjpeg C Users Administrator Desktop matconvnetfcnmaster matconvnet matlab vlimreadjpegm getBatch line rgb vlimreadjpegrgbPath fcnTrainimdbbatchgetBatchimdbbatchoptsprefetchnargout line fn imdbbatch getBatchimdbbatchoptsprefetchnargout cnntraindagprocessepoch line inputs stategetBatchstateimdb batch cnntraindag line statstrainepoch processepochnet state opts train fcnTrain line info cnntraindagnet imdb getBatchWrapperbopts Anyone Kindly help me or give some code to solve this issue Waiting for your positive response thank you Below is the code of fcntestm I have trained the model using deep vgg And i am using the trained model from epoch to test images for segmantation Everyhting runs smooth but the predicted image is not displayed Need Help function info fcnTestvarargin experiment and data paths optsexpDir datafcn svoc optsdataDir datavoc optsmodelPath datafcn svoc netepoch mat optsmodelFamily matconvnet opts varargin vlargparseopts varargin experiment setup optsimdbPath fullfileoptsexpDir imdbmat optsvocEdition optsvocAdditionalSegmentations true optsvocAdditionalSegmentationsMergeMode optsgpus opts vlargparseopts varargin resPath fullfileoptsexpDir resultsmat if existresPath info loadresPath return end if isemptyoptsgpus gpuDeviceoptsgpus end Setup data Get PASCAL VOC segmentation dataset plus Berkeleys additional segmentations if existoptsimdbPath imdb loadoptsimdbPath else imdb vocSetupdataDir optsdataDir edition optsvocEdition includeTest false includeSegmentation true includeDetection false if optsvocAdditionalSegmentations imdb vocSetupAdditionalSegmentations imdb dataDir optsdataDir mergeMode optsvocAdditionalSegmentationsMergeMode end mkdiroptsexpDir saveoptsimdbPath struct imdb end Get validation subset val findimdbimagesset imdbimagessegmentation Compare the validation set to the one used in the FCN paper valNames sortimdbimagesnameval valNames textreaddataseg validtxt s valNames textreaddataseg validtvgtxt s assertisequalvalNames valNames Setup model switch optsmodelFamily case matconvnet net loadoptsmodelPath net dagnnDagNNloadobjnetnet makes a DagNN object from netnet netmode test for name objective accuracy netremoveLayername end netmetanormalizationaverageImage reshapenetmetanormalizationrgbMean predVar netgetVarIndexprediction inputVar input imageNeedsToBeMultiple true case ModelZoo net dagnnDagNNloadobjloadoptsmodelPath netmode test predVar netgetVarIndexupscore inputVar data imageNeedsToBeMultiple false case TVG net dagnnDagNNloadobjloadoptsmodelPath netmode test predVar netgetVarIndexcoarse inputVar data imageNeedsToBeMultiple false end if isemptyoptsgpus gpuDeviceoptsgpus netmovegpu end netmode test Train numGpus confusion zeros for i numelval imId vali name imdbimagesnameimId rgbPath sprintfimdbpathsimage name labelsPath sprintfimdbpathsclassSegmentation name Load an image and gt segmentation rgb vlimreadjpegrgbPath rgb rgb anno imreadlabelsPath lb singleanno lb modlb ignore bkg Subtract the mean color i think its normaliation method im bsxfunminus singlergb netmetanormalizationaverageImage Some networks requires the image to be a multiple of pixels if imageNeedsToBeMultiple sz sizeim sizeim sz roundsz im imresizeim sz else im im end if isemptyoptsgpus im gpuArrayim end netevalinputVar im scores gathernetvarspredVarvalue pred maxscores if imageNeedsToBeMultiple pred imresizepred sz method nearest else pred pred end Accumulate errors ok lb ok becomes a logical array confusion confusion accumarray lbokpredok Plots if modi i numelval clear info infoiu infomiu infopacc infomacc getAccuraciesconfusion fprintfIU fprintf f infoiu fprintf n meanIU f pixelAcc f meanAcc f n infomiu infopacc infomacc figure clf imagescnormalizeConfusionconfusion axis image setgcaydirnormal colormapjet drawnow Print segmentation figure clf displayImagergb lb pred drawnow Save segmentation imPath fullfileoptsexpDir name png imwritepredlabelColorsimPathpng end end Save results saveresPath struct info function nconfusion normalizeConfusionconfusion normalize confusion by row each row contains a gt label nconfusion bsxfunrdivide doubleconfusion doublesumconfusion function IU meanIU pixelAccuracy meanAccuracy getAccuraciesconfusion pos sumconfusion res sumconfusion tp diagconfusion IU tp max pos res tp meanIU meanIU pixelAccuracy sumtp max sumconfusion meanAccuracy meantp max pos function displayImageim lb pred subplot imageim axis image titlesource image subplot imageuint lb imageuint lb axis image titleground truth cmap labelColors subplot imagepred imageuint pred axis image titlepredicted colormapcmap function cmap labelColors N cmap zerosN for i N id i r g b for j r bitorr bitshiftbitgetid j g bitorg bitshiftbitgetid j b bitorb bitshiftbitgetid j id bitshiftid bitshiftid end cmapi r cmapi g cmapi b end cmap cmap Hi all Ive met a similar problem and do not know what to do with it The error info is as follows train epoch Error using dagnnDagNNeval line No variable of name input could be found in the DAG Error in cnntraindagprocessepoch line netevalinputs optsderOutputs Error in cnntraindag line statstrainepochprof processepochnet state opts train Error in cnnfour line net info trainFnnet imdb getBatchFnopts netmeta I use the pretrained model imagenetmatconvnetalexmat and found that when calling eval the nets lacking of some fields results the error netor obj in def of eval lacking fields like varNames numPendingVarRefs Does any body know how to fix it Thanks and Regards I want to convert AlexNet googleNet network to FCN semantic segmentation network similar to the way fcnInitialize function convert VGG to FCN Is there any initialization function for this networks Hi I got error when using vlnnloss function line there is repeated index generated in ci variable I try to fine tune FCN network with batchSize numSubbatch when i change one of this values i pass the error So what happen when i choose this parameters and How can i finetune the net with this parameters Thanks Hello everyone I want to finetune vgg by using my own datasetIt has classes but I faced with some error train epoch im imdbimagesdatabatch Error using dagnnDagNNeval line No variable of name label could be found in the DAG Error in cnntraindagprocessEpoch line netevalinputs paramsderOutputs holdOn s paramsnumSubBatches Error in cnntraindag line net state processEpochnet state params train Error in finetest line info cnntraindagnet imdb ib getBatchboptsib optstrain val findimdbimagesset and this my code finetune vgg for cifar dataset function net info vggtrainimdb expDir Demonstrated MatConNet on CIFAR using DAG runfullfilefilepartsmfilenamefullpath matlab vlsetupnnm run matlabvlsetupnn imdbloadimdbsmat imdb imdbloadimdbcifar mat loadimdbsmat imdb some common options optstrainbatchSize optstrainnumEpochs optstraincontinue true optstraingpus optstrainlearningRate e ones e ones optstrainweightDecay e optstrainmomentum optstrainexpDir expDir boptsuseGpu numeloptstraingpus Usually keep at seems to only work with D data optstrainnumSubBatches getBatch options boptsuseGpu numeloptstraingpus network definition MATLAB handle passed by reference net dagnnDagNN vgg artitectur netaddLayerconv dagnnConvsize hasBias true stride pad inputconv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerlrn dagnnLRNparam relu lrn netaddLayerpool dagnnPoolingmethod max poolSize stride pad relu pool netaddLayerconv dagnnConvsize hasBias true stride pad pool conv conv f conv b netaddLayerrelu dagnnReLU conv relu layer netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerlrn dagnnLRNparam relu lrn change padding in layer netaddLayerpool dagnnPoolingmethod max poolSize stride pad relu pool netaddLayerconv dagnnConvsize hasBias true stride pad pool conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu layer ok netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerlrn dagnnLRNparam relu lrn change in padding in layer netaddLayerpool dagnnPoolingmethod max poolSize stride pad relu pool netaddLayerconv dagnnConvsize hasBias true stride pad pool conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerlrn dagnnLRNparam relu lrn layer change in padding netaddLayerpool dagnnPoolingmethod max poolSize stride pad relu pool netaddLayerconv dagnnConvsize hasBias true stride pad pool conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu layer netaddLayerconv dagnnConvsize hasBias true stride pad relu conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerpool dagnnPoolingmethod max poolSize stride pad relu pool netaddLayerconv dagnnConvsize hasBias true stride pad pool conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerdrop dagnnDropOutrate relu drop netaddLayerconv dagnnConvsize hasBias true stride pad drop conv conv f conv b netaddLayerrelu dagnnReLU conv relu netaddLayerdrop dagnnDropOutrate relu drop chane in class number netaddLayerclassifier dagnnConvsize hasBias true stride pad drop classifier conv f conv b netaddLayerprob dagnnSoftMax classifier prob netaddLayerobjective dagnnLossloss log prob label objective netaddLayererror dagnnLossloss classerror problabel error initialization of the weights CRITICAL ifnumelvarargin initNetFineTuningnet netPre else initNetHenet end train iinitNetnet do the training info cnntraindagnet imdb ib getBatchboptsib optstrain val findimdbimagesset end function initNetnet f netinitParams find netlayers paramIndexes bind netlayers paramIndexes netparamsfindvalue frandnsizenetparamsfindvalue single netparamsfindlearningRate netparamsfindweightDecay for l lengthnetlayers is a convolution layer ifstrcmpclassnetlayerslblock dagnnConv find netlayerslparamIndexes bind netlayerslparamIndexes hwinout sizenetparamsfindvalue netparamsfindvalue frandnsizenetparamsfindvalue single netparamsfindlearningRate netparamsfindweightDecay netparamsbindvalue frandnsizenetparamsbindvalue single netparamsbindlearningRate netparamsbindweightDecay end end end getBatch for IMDBs that are too big to be in RAM function inputs getBatchopts imdb batch images imdbimagesdatabatch labels imdbimageslabels batch labelslabels im imdbimagesdatabatch im im ssizeim imageszeross s s single images im images im images im if optsuseGpu images gpuArrayimages end inputs input images label labels end I observe with my image set class background that I achieve much better segmentation accuracy for the validation val images during training pixelAcc then during testing pixelAcc By default fcnTrainm and fcnTestm are setup to use the same val images My understanding is that testing should actually be done on a fully independent rd set of images but when running the default setup I would expect the same accuracy from fcnTrain and fcnTest for a given epoch I confirmed by outputting images from predictions in SegmentationAccuracym that the segmentations for the val images look better during fcnTrain then fcnTest hi i got this error when run fcnTrain Error using Transpose on ND array is not defined Use PERMUTE instead Error in vlargparse line values struct cellargsai Error in cnntraindag line opts vlargparseopts varargin Error in fcnTrain line info cnntraindagnet imdb getBatchWrapperbopts Hi Thanks for every one I am a newer to FCN and I want to use FCN to train my dataset The dataset contains original images which are they are gray figure and labeled images which are Because the original images and labeled images are different images but they have nonlinear relationship and in labeled images I want to identify classes that the interestlabeled as and backgroundlabeled as so I want to use FCN to learn the nonlinear algorithm and identify two parts in labeled images I have some trouble in how can I do to solve this problem I think I should convert my data to imdbmat to feed fcntrain firstly but I didnt achieve it Then I think I should run fcnInitializeModel to initialize the net and modify some parameters in the codeWhat I think is rightI hope someone can help me and I am grateful if you can share your code to me Best Regards Emailyfs hiteducn