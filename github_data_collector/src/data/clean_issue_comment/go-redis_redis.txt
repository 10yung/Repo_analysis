Hi Weve been seeing new connection spikes after applying the fix for handling Remove for SingleConnPool Please correct me if Im wrong I think the client will issue one READONLY command per connection if ReadOnly option is set to true but this command might become a bottleneck when server is under heavy load and many requests time out causing lots of new connections to be created Im not sure what would be the best way to fix this but Do we really need to issue READONLY command given that we always slot slave node if ReadOnly option is enabled and its a ReadOnly command Is it possible to change the READONLY setting to just be set once instead of per connection Eg issue a CONFIG SET command when init the ClusterClient Thank you and I look forward to your advice For newcomers would be nice to have some guide about the differences between the versions of this library If they are related to their redis version counterpart or the features each version has than the previous one had not if it follows semVer etc Hi Is there a way to turn off the healthchecks that remove hosts from the ring Each host in my ring has its own highavailability setup GCP Memorystore and Im using them together as a consistent database so I dont want the keyhost membership changing at all Alternatively the readme hints that ClusterClient can use a bunch of nonCluster Redis hosts Is this true It seems like the code depends on MOVED etc messages coming from clustermode hosts Thanks The read timeout seems to be globally used in most of the commands However some commands require more time than others such as FlushAll BgSave FlushDB In the mean time we dont want to increase the general read timeout to make all processes hang for a long time when redis is in a dead status It would be better if it could set read timeout dynamically eg go clientWithTimeout timeSecondFlushAll maybe KeepAlive param is minutes close connect operate is not doing well I need to calculate the total cost of time of get requeset And I found that if I set the value bigger than MB it will timeout Im using WrapProcess to add logging instrumentation in goredis v and noticed that commands run within Watch arent intercepted This is because ClientnewTx creates a new baseClient with default process functions So Im forced to use the following workaround whenever I create a watch transaction go err rdsWatchfunctx redisTx error workaround process wrappers not automatically applied to watch transactions if log txWrapProcess Im not fluent with this library but I assume theres a good reason to create a new baseClient internally So I guess the only way to support this would be to store the wrapper functions internally and reapply them when watch transactions are created something like ignoring pipeline for brevity go type baseClient struct wrappers funcuncCmder error funcCmder error func c baseClient WrapProcess fn funcoldProcess funccmd Cmder error funccmd Cmder error cprocess fncprocess cwrappers appendcwrappers fn func c Client newTx Tx txbaseClientinit txstatefulCmdablesetProcessortxProcess for fn range cwrappers txWrapProcessfn return tx Happy to send a PR This scenario looks even trickier in v with the switch to instrumentation hooks because not only are they not passed to watch transactions but they cant be added manually What are my options for reliable command logging in v Looks like Tx should inherit the hooks from the original Client Again happy to provide a simple PR that passes this unit test go func ExampleWatchinstrumentation rdb redisNewClient redisOptions Addr rdbAddHookredisHook rdbWatchfunctx redisTx error txPing txPing return nil foo Output starting processing watch foo finished processing watch foo OK starting processing ping finished processing ping PONG starting processing ping finished processing ping PONG starting processing unwatch finished processing unwatch OK I want to customize whether the current command should be retried some commands i do not want to try like not idempotent likes LPOP or which uses too many redis servers resources likes hgetall command With V sdk i can use WrapProcess like this clientWrapProcessRetryWrapperhaOptions func RetryWrapperhaOpt haOptions funcoldProcess funccmd redisCmder error funcredisCmder error host osHostname ip GetIP return funcfn funccmd redisCmder error funcredisCmder error return funccmd redisCmder error var err error for attempt attempt haOptMaxRetries attempt if attempt if attempt timeSleepretryBackoffattempt haOptMinRetryBackoff haOptMaxRetryBackoff err fncmd if err nil requestTotalFailWithLabelValueshost ipInc if err nil isRetryableErrorerr isRetryableCmdcmd return err requestTotalRetryWithLabelValueshost ipInc return err But V uses Hook Instead of WrapProcesshow can i implement the feature in V or can I pr the feature uses isRetryableCmd func Hi this is not really an issue It is more a request of help I am trying to do this redis calls in one transaction func getHostkey host score error numberOfHosts err rdbZCardkeyResult if err nil return nil err host err rdbZRangeByScoreWithScoreskey redisZRangeBy Min Max strconvItoamaxScore Offset numberOfHosts Count Result if err nil return nil err score host Score member err jsonMarshalhost Member if err nil return nil err if intscore maxCapacity rdbZIncrBykey score stringmember host err rdbGetHoststringmember if err nil return nil err return host intscore nil I found this in the doc and I am trying to do something with it but it is a bit difficult at the moment Is anybody already done this and provide advice 