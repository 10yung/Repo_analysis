Resolves the error AttributeError module tornadoweb has no attribute asynchronous which is breaking the Travis build Users can have the nice blue bar with multiple spark applications with the following code change This is currently very crude and requires the user to manually know their spark ui port eg by running sparkconfgetsparkdriverappUIAddress and then hitting the url But it does work and opens up some nice new possibilities for cluster sharing Tornado appears to have removed the tornadowebasynchronous method which handlerspy relies on W NotebookApp Error loading server extension jupyterspark Traceback most recent call last File usrlibpython sitepackagesnotebooknotebookapppy line in initserverextensions funcself File usrlibpython sitepackagesjupytersparkinitpy line in loadjupyterserverextension from handlers import SparkHandler File usrlibpython sitepackagesjupytersparkhandlerspy line in module class SparkHandlerIPythonHandler File usrlibpython sitepackagesjupytersparkhandlerspy line in SparkHandler tornadowebasynchronous AttributeError module tornadoweb has no attribute asynchronous This has been noted in jupyternotebook which may have a path to a fix pip freeze of the environment this was run on under Python atomicwrites attrs backcall beautifulsoup bleach certifi chardet decorator defusedxml docutils entrypoints idna ipykernel ipython ipythongenutils ipywidgets jedi Jinja jsonschema jupyter jupyterclient jupyterconsole jupytercore jupyterspark MarkupSafe mistune moreitertools nbconvert nbformat notebook pandocfilters parso pexpect pickleshare pkginfo pluggy prometheusclient prompttoolkit ptyprocess py Pygments pyrsistent pyspark pytest pythondateutil pyzmq qtconsole readmerenderer requests requeststoolbelt Send Trash six soupsieve terminado testpath tornado tqdm traitlets twine urllib wcwidth webencodings widgetsnbextension Would be great to support Livy connections too through sparkmagic extension Thanks See releases has but does not Hi your tools looks really promising currently i get error SPARKNOTRUNNING running spark in my setup How can i configure the extension to work in an environment like this pyspark deploymode client master yarn Could you give me a hint how to configure the setting in this case jupyter notebook Sparkurl Thank you I have a case where my whole job seems to have jobs running in parallel The progress bar at the cell level shows me only jobs progress bar it shows the last job not even the job where progress is going on right now Love this extension btw Fix This adds a Spark status window to the side pane in Jupyter Lab I played with making a modal dialog like the old extension but it feels like the side pane is more in keeping with the JupyterLab way It looks like teonbrooks jezdez Proposal for Issue In the Jupyter notebook a Jupyter Comm target gets opened to listen for messages from a python kernel A new Jupyter Magic uses this comm target to forward the Spark API URL to the notebook sparkprogress spark where spark is the variable holding the Spark Session so the magic can use globals spark sparkContextuiWebUrl to get the actual Spark API Url Each call from the javascript notebook then forwards the Spark API Url as a query parameter sparkurl to the backend handler which uses it to create the backendurl This allows for multiple SparkContexts in different tabs and even for sparkuiport setting ATMO now has support for jupyter lab Is there a way to enable the progress bar within jupyter lab