The kubelet fails to start if a machines hostname is not set If networkd doesnt set it in time the kubelet service fails to start Addionally this adds retries to container pulls to ensure that any temporary network failures dont cause fatal errors if we cant pull images This implements osctl cluster destroy for Firecracker adds new utility command osctl cluser show Firecracker mode now has control process for firecracker VMs allowing clean reboots and background operations Lots of small fixes to Firecracker mode clean CNI shutdown cleaning up netns etc If we dont block there is the potential for multiple shutdown reboot and upgrade requests to be processed Documentation on talosdev and documentation in osctl state that you must supply a load balancer IP or DNS name for when you run osctl config generate but does not specify that a port is required If a port is not specified bootkube fails This should probably be corrected by both having a default of and updating documentation to inform the user of what were actually specifying and why osctl has references like id that are unclear For example Usage osctl logs id flags Flags are well described but id is never clarified either in the docs or in the cli help Add preflight checks for CNI modules required devkvm accessibility etc This should make it easier for firsttime users to successfully complete osctl cluster create provisionerfirecracker The clientCreds struct was not used very often and made using the clientNewClient function impossible to use in combination with the RemoteRenewingFileCertificateProvider This modifies clientNewClient to accept a tlsConfig instead of clientCreds allowing for the use of RemoteRenewingFileCertificateProvider with clientNewClient What occurs I installed a cluster with master nodes rootmatchbox kubectl get nodes NAME STATUS ROLES AGE VERSION mal Ready master m v wash Ready master m s v zoe Ready master m v rootmatchbox kubectl get pods n kubesystem NAME READY STATUS RESTARTS AGE calicokubecontrollers f b sp Running m caliconode bfdx Running m caliconodenxwwx Running m caliconodes lkd Running m coredns bcc f bdzsjkw Running m kubeapiservercljr Running m kubeapiserverx hsd Running m kubeapiserverzqsdc Running m kubecontrollermanager b b f m Running m kubecontrollermanager b b fskbcd Running m kubeproxy vgdm Running m kubeproxy k lx Running m kubeproxycmjqz Running m kubescheduler db bfb bcdpmw Running m kubescheduler db bfb bcqtmzk Running m podcheckpointer h s Running m podcheckpointer h s zoe Running m podcheckpointerlflph Running m podcheckpointerlflphwash Running m s podcheckpointerpgxml Running m podcheckpointerpgxmlmal Running m rootmatchbox osctl service etcd e NODE ID etcd STATE Running HEALTH OK EVENTS Running Health check successful m s ago Running Started task etcd PID for container etcd m s ago Preparing Creating service runner m s ago Preparing Running pre state m s ago Waiting Waiting for service containerd to be up m s ago rootmatchbox osctl service etcd e NODE ID etcd STATE Running HEALTH OK EVENTS Running Health check successful m s ago Running Started task etcd PID for container etcd m s ago Preparing Creating service runner m s ago Preparing Running pre state m s ago Waiting Waiting for service containerd to be up m s ago rootmatchbox osctl service etcd e NODE ID etcd STATE Running HEALTH OK EVENTS Running Health check successful m s ago Running Started task etcd PID for container etcd m s ago Preparing Creating service runner m s ago Preparing Running pre state m s ago Waiting Waiting for service containerd to be up m s ago I issued the command osctl upgrade i dockerioandrewrynhardinstalleracpi n To get the latest ACPI fixes by Andrew The output of dmesg user warning T Z talos phase cordon and drain node user warning T Z talos skipping DaemonSet pod caliconode bfdx user warning T Z talos skipping DaemonSet pod kubeproxy k lx user warning T Z talos skipping DaemonSet pod podcheckpointerpgxml user warning T Z talos skipping DaemonSet pod kubeapiserverx hsd user warning T Z talos leaving etcd cluster user warning T Z talos service etcd Stopping Sending SIGTERM to task etcd PID container etcd user warning T Z talos service etcd Finished Service finished successfully user warning T Z talos WARNING failed to evict pod failed to evict pod kubesystemkubecontrollermanager b b fskbcd etcdserver request timed out user warning T Z talos WARNING failed to evict pod failed waiting on pod kubesystemkubecontrollermanager b b f m to be deleted errors occurred x a x pod is still running on the node x a x failed to get pod kubesystemkubecontrollermanager b b f m etcdserver request timed out user warning T Z talos WARNING failed to evict pod failed waiting on pod kubesystemkubescheduler db bfb bcdpmw to be deleted errors occurred x a x pod is still running on the node x a x failed to get pod kubesystemkubescheduler db bfb bcdpmw etcdserver request timed out user warning T Z talos WARNING failed to evict pod failed waiting on pod kubesystemcoredns bcc f bdzsjkw to be deleted errors occurred x a x pod is still running on the node x a x failed to get pod kubesystemcoredns bcc f bdzsjkw etcdserver request timed out user warning T Z talos WARNING failed to evict pod failed waiting on pod kubesystemcalicokubecontrollers f b sp to be deleted errors occurred x a x pod is still running on the node x a x failed to get pod kubesystemcalicokubecontrollers f b sp etcdserver request timed out user warning T Z talos WARNING failed to evict pod failed to evict pod kubesystempodcheckpointerpgxmlmal etcdserver request timed out It doesnt finish upgrading nor does it reboot In one instance I saw a could not drain node failure and upgrade failed although I couldnt reproduce that on the latest attempt When I got the upgraded failed and reboot I get a partitioned cluster The st node comes up and I believe reinitializes as a node etcd cluster Whatever the case I know if I issue kubectl get pods n kubesystem three times and given that the haproxy config in my environment is round robin rd of the time I get no pods in the namespace and rds of the time I get the listing of pods I expect What I expected The upgrade to succeed Details about my environment v beta PXE booted to a laptop haproxy load balancer in front of the API server calico manifests for a custom CNI What occurs I installed a node with an init configuration I issued the command osctl upgrade i dockerioandrewrynhardinstalleracpi n To get the latest ACPI fixed by Andrew The output of dmesg user warning T Z talos phase cordon and drain node user warning T Z talos skipping DaemonSet pod kubeproxygcc user warning T Z talos skipping DaemonSet pod caliconodeh kvx user warning T Z talos skipping DaemonSet pod kubeapiserverfnq user warning T Z talos skipping DaemonSet pod podcheckpointervpgnl user warning T Z talos leaving etcd cluster user warning T Z talos phase cordon and drain node error running task etcdserver reconfiguration failed due to not enough started members It doesnt reboot When an osctl reboot is issued dmesg logs a message but fails user warning T Z talos reboot via API received What I expected The upgrade to succeed Details about my environment v beta PXE booted to a laptop haproxy load balancer in front of the API server calico manifests for a custom CNI The automated certificate renewal code seems to fail if the init nodes trustd service is not running The client should try all known trustd endpoints