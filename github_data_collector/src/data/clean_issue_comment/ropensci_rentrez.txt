 While it is stated that When I wrote this that was a little over SNPs I have got the following messages snpsearch entrezsearchdbsnp termY CHR AND Homo ORGN NOT CPOS snpsearch Entrez search result with hits object contains IDs and no webhistory object Search term as translated Y CHR AND Homo All Fields NOT CHRPOS Attached are my R code and log file Rcodetxt logtxt Hi rentrez developers I have a situation where i want to search for a taxa and specific gene and only download a random subsample of these search results searchresults entrezsearchdb nuccore term Drosophila ORGN AND COI usehistory TRUE lengthsearchresultsids subsample idssubsample samplesearchresultsids subsample As a subsample of ids is too large to feed directly into entrezfetch the only way i see to handle this is to then use entrezpost to upload the subsampled ids in chunks and entrezfetch to then download the chunks ids samplesearchresultsids subsample chunksize idschunked splitids ceilingseqalongidschunksize for l in lengthidschunked upload entrezpostdbnuccore ididschunked l dl entrezfetchdb nuccore webhistory upload rettype fasta retmax catdl fileoutfa appendTRUE However this is quite slow Instead the documentation for entrezpost seems to suggest that i should be able to append the ids to an existing webhistory object and then the entire webhistory object could be downloaded a single entrez fetch call I tried this with the below code however in this case entrezfetch only downloads the last chunk of ids i uploaded create new webhistory object upload entrezpostdbnuccore ididschunked Add to web history object for l in lengthidschunked upload entrezpostdbnuccore ididschunked l webhistoryupload dl entrezfetchdb nuccore webhistory upload rettype fasta retmax catdl fileoutfa appendFALSE Do you have any input on what i am doing wrong here or suggestions on better ways to do this ie can i somehow subset the webhistory object directly on the NCBI server without having to post the ids again Cheers Alex Hello I am new to R and also to NCBI database I am trying out some simple searches to understand the package I started with a simple search based on a name taxonsearch entrezsearchdbtaxonomy termSpirometra erinaceieuropaei taxonsearchids So far so good Now I want to use this taxon id to see all the links in the database I am not sure if this is the right query Why do I get only one link allthelinks entrezlinkdbfromgene id dball allthelinkslinks elink result with information from databases genegeneh k me If I start with a gene id I get more links allthelinks entrezlinkdbfromgene id dball allthelinkslinks elink result with information from databases genegenome genebioproject genecdd genegeneh k me genegeneneighbors genegenome genenuccore genenuccorepos genenucleotide genenucleotidepos genepmcnucleotide geneprotein geneproteinrefseq geneproteinclusters genepubmedpmcnucleotide genesparcle genetaxonomy And from there I can find the taxon id allthelinkslinksgenetaxonomy How do I find a link to from the taxon search thanks sharif I am trying to analyze around PubMed case reports and tried to get the data using entrezfetch as shown below fori in seq info entrezfetchdbpubmed webhistorypubmedsearchwebhistory rettypexml retmax retstarti parsed TRUE catsaveXMLinfo n filesamplexml appendTRUE cati sequences downloaded r This code snippet is very similar to the one found in the documentation However after a few thousand files an error occurs and I discovered its because the database wont allow me to download it I think its because it might be more than requests per second Does anyone know a workaround for this Im trying to access a really large number of records to be exact and used the tutorial to try and attain this So I run the following code first to save web history pubmedsearch entrezsearchdb pubmed term Case Reports Filter AND cardiovascular disease AND English lang AND PDat retmax usehistory TRUE Then I try to download first files for seqstart in seq recs entrezsummarydbpubmed webhistorypubmedsearchwebhistory retmax retstartseqstart catseqstart sequences downloaded r lengthrecs But I only get files not Can someone help with this Im quite confused here as to how to use the web history feature This is required to be autodetected by GitHub When apikey is not provided Entrez allows requests per second thus sleeptime should be at least second Rounding error caused it to wait for less than resulting in API rate limit exceeded error Fix it into Hi I was wondering if anyone might have a suggestion to return the DOI for a given pubmed id in a robust manner I tried to use the id converter but for a number of my ids the converter says the pubmed id is invalid For example this id is a valid pubmed id but the converter thinks it is invalid The closest that I have gotten is to use entrezfetch and parse out the ELocationID which if it exists will contain the DOI but it might also contain other identifiers which I am not clear on how to exclude from the XML parsing see example code below I have I believe come across pubmed ids with DOIs that dont have the ELocationID xml tag Any pointerstips would be greatly appreciated Iain example parsing from libraryrentrez libraryXML returndoifunctionpubmedid entrezxml entrezfetchdbpubmed idpubmedid rettypexml parsedxmlXMLxmlParseentrezxml elocationidXMLxpathSApplyparsedxml ELocationID XMLxmlValue returnelocationid returndoi should be nchembio nchembio returndoi should be jdrudis S jdrudis curious how to show PubMed IDs per year for a specific search ex PubmID PubmID PubmID PubmID PubmID PubmID PubmID PubmID Im able to plot papers by year but what i really need is a list of pubmed IDs per year thoughts These queries throw an error Q idlist rentrezentrezsearchdbclinvar termhuman Organism retmax retstart Q idlist rentrezentrezsearchdbclinvar termhuman Organism retmax retstart Error in ans subscript out of bounds But these queries dont idlist rentrezentrezsearchdbclinvar termhuman Organism retmax retstart idlist rentrezentrezsearchdbclinvar termhuman Organism retmax retstart The first query attempts to retrieve the first records and the second one records starting from the position I tried with retstart and thowrs the same error but everything works fine with 