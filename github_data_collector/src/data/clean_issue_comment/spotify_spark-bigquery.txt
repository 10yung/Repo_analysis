Hi This pull request includes a minor bug fix to correctly create staging dataset In comspotifysparkbigqueryBigQueryClient currently STAGINGDATASETID config includes STAGINGDATASETLOCATION string by default but if the location includes hypheneg asianortheast then the datasetid cant satisfy its naming rule and dataset creation fails So could you please add the conversion of hyphen into underscore before setting STAGINGDATASETID Thanks I would like to fix the logic to generate datasetId in BigQueryClient stagingTable val datasetId prefix locationtoLowerCase Is the following modification possible The notation is java String datasetId prefix locationtoLowerCase ReplaceAll az Explain the situation I am considering using connectors to transfer data from BigQuery to the application on dataproc The data location we use is asianortheast This is a string containing As a result it seems that table creation fails when creating a temporary table like the following log loglevel INFO time appname jobexecutor function comspotifysparkbigqueryBigQueryClient stagingDataset message Creating staging dataset repxdevjpfiotmgr sparkbigquerystagingasianortheast javautilconcurrentExecutionException comgoogleapiclientgoogleapisjsonGoogleJsonResponseException Bad Request code errors domain global message Invalid dataset ID sparkbigquerystagingasianortheast Dataset IDs must be alphanumeric plus underscores and must be at most characters long reason invalid message Invalid dataset ID sparkbigquerystagingasianortheast Dataset IDs must be alphanumeric plus underscores and must be at most characters long status INVALIDARGUMENT at comgooglecommonutilconcurrentAbstractFuturegetDoneValue AbstractFuturejava at comgooglecommonutilconcurrentAbstractFutureget AbstractFuturejava at comgooglecommonutilconcurrentAbstractFuture TrustedFutureget AbstractFuturejava at comgooglecommonutilconcurrentUninterruptiblesgetUninterruptibly Uninterruptiblesjava at comgooglecommoncacheLocalCache SegmentgetAndRecordStats LocalCachejava at comgooglecommoncacheLocalCache SegmentloadSync LocalCachejava at comgooglecommoncacheLocalCache SegmentlockedGetOrLoad LocalCachejava at comgooglecommoncacheLocalCache Segmentget LocalCachejava at comgooglecommoncacheLocalCacheget LocalCachejava at comgooglecommoncacheLocalCachegetOrLoad LocalCachejava at comgooglecommoncacheLocalCache LocalLoadingCacheget LocalCachejava at comspotifysparkbigqueryBigQueryClientquery BigQueryClientscala at comspotifysparkbigqueryBigQuerySQLContextbigQuerySelect BigQuerySQLContextscala Hi everybody LMK if you need more info but effectively I just made changes to There were a lot of library conflicts with the latest versions of the libraries since then so Ive reverted those changes back In this PR Revert libraries to version and scala back down to as wont be supported until Spark Fixed GoogleCredential for bigQuerySelect to use credentials file in Json provided by setGcpJsonKeyFile instead of GoogleCredentialgetApplicationDefault Added flag for standard sql while not breaking API for legacy SQL Documentation changes removed reference to Dataproc since I believe google provides an up to date connector that works on Dataproc Lorenz Is there a way to set a timeout Which would throw an exception if exceed I am running my sparkshell with Scala on version sparkshell packages comspotifysparkbigquery scala sqlContextsetGcpJsonKeyFilefilepath scala sqlContextsetBigQueryProjectIdproj scala sqlContextsetBigQueryGcsBucketdummybucket scala sqlContextsetBigQueryDatasetLocationUS I am trying to load some data in BigQuery which returns an error as shown below scala val df Seq toDFABC scala dfshow A B C scala dfsaveAsBigQueryTableprojdatasetnametablename javalangNoSuchMethodError comgooglecommonbaseSplittersplitToListLjavalangCharSequenceLjavautilList at comgooglecloudhadoopfsgcsGoogleHadoopFileSystemBaseParentTimestampUpdateIncludePredicatecreateGoogleHadoopFileSystemBasejava at comgooglecloudhadoopfsgcsGoogleHadoopFileSystemBasecreateOptionsBuilderFromConfigGoogleHadoopFileSystemBasejava at comgooglecloudhadoopfsgcsGoogleHadoopFileSystemBaseconfigureGoogleHadoopFileSystemBasejava at comgooglecloudhadoopfsgcsGoogleHadoopFileSystemBaseinitializeGoogleHadoopFileSystemBasejava at comgooglecloudhadoopfsgcsGoogleHadoopFileSystemBaseinitializeGoogleHadoopFileSystemBasejava at orgapachehadoopfsFileSystemcreateFileSystemFileSystemjava at orgapachehadoopfsFileSystemaccess FileSystemjava at orgapachehadoopfsFileSystemCachegetInternalFileSystemjava at orgapachehadoopfsFileSystemCachegetFileSystemjava at orgapachehadoopfsFileSystemgetFileSystemjava at orgapachehadoopfsPathgetFileSystemPathjava at orgapachesparksqlexecutiondatasourcesDataSourcewriteInFileFormatDataSourcescala at orgapachesparksqlexecutiondatasourcesDataSourcewriteDataSourcescala at orgapachesparksqlexecutiondatasourcesSaveIntoDataSourceCommandrunSaveIntoDataSourceCommandscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultlzycomputecommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultcommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecdoExecutecommandsscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecuteQuery applySparkPlanscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparksqlexecutionSparkPlanexecuteQuerySparkPlanscala at orgapachesparksqlexecutionSparkPlanexecuteSparkPlanscala at orgapachesparksqlexecutionQueryExecutiontoRddlzycomputeQueryExecutionscala at orgapachesparksqlexecutionQueryExecutiontoRddQueryExecutionscala at orgapachesparksqlDataFrameWriterrunCommandDataFrameWriterscala at orgapachesparksqlDataFrameWritersaveDataFrameWriterscala at orgapachesparksqlDataFrameWritersaveDataFrameWriterscala at comdatabrickssparkavropackageAvroDataFrameWriteranonfunavro applypackagescala at comdatabrickssparkavropackageAvroDataFrameWriteranonfunavro applypackagescala at comspotifysparkbigquerypackageBigQueryDataFramesaveAsBigQueryTablepackagescala at comspotifysparkbigquerypackageBigQueryDataFramesaveAsBigQueryTablepackagescala elided Kindly help I am a newbie in Spark Scala I ran this package in local SBT and everything worked fine But now I am trying to do the connection in Google cloud dataproc and executed the command sparkshell packages comspotifysparkbigquery But after that when I am trying to run the following command at scala prompt val table sqlContextbigQueryTablebigquerypublicdatasamplesshakespeare It cant recognize sqlContext command Am I missing something Spark version Spotifysparkbigquery version Hi I am trying to use the saveAsBigQuery table function to write a schema that has an array of struct as a field However I am getting the following error The Apache Avro library failed to parse the header with the follwing error Invalid namespace topicscores The offending field is type items namespace topicscores type record name topicscores fields type int name index type float name score null type array null name topicscores You can see that the namespace field begins with a dot My guess is that the issue stems from I cant find a way to configure the recordNamespace value According to avro documentation You can specify the record name and namespace like this import comdatabrickssparkavro import orgapachesparksqlSparkSession val spark SparkSessionbuildermasterlocalgetOrCreate val df sparkreadavrosrctestresourcesepisodesavro val name AvroTest val namespace comdatabrickssparkavro val parameters MaprecordName name recordNamespace namespace dfwriteoptionsparametersavrotmpoutput I think this is the line that reads that option and sets the value to an empty string if not provided These options are not parameterized anywhere in the Spotify library Has anyone seen this issue or have a workaround Thanks Hi everyone I encountered a weird issue while trying your library When saving the temp file to gcs it called the storage api with a weird address I tried debugging through the code to find what was causing the problem and I did not find it however I solved the issue accidentally I wanted to test creating a directory with the security account to see if it was a permission problem so I added googlecloudstorage in my dependencies because I couldnt import import comgooglecloudstorageStorageOptions and this solved the issue Is there a way to make this error more explicit Is it a problem that is global to google and not this library Here is the buildsbt to reproduce the error sbt comtypesafescalalogging scalalogging orgapachespark sparkcore orgapachespark sparksql comgooglecloud googlecloudbigquery beta comgooglecloudbigdataoss gcsconnector hadoop comspotify sparkbigquery orgapacheparquet parquetavro And the code scala object Main extends App implicit val spark SparkSession builder appNameName masterlocal configgooglecloudauthserviceaccountjsonkeyfile path configfsgsprojectid projectid getOrCreate bqSqlContextbigQuerySelectsSELECT FROM tableName LIMIT And here is the exception Exception in thread main comgoogleapiclienthttpHttpResponseException Not Found Not Found at comgoogleapiclienthttpHttpRequestexecuteHttpRequestjava at comgoogleapiclientgoogleapisbatchBatchRequestexecuteBatchRequestjava at comgooglecloudhadoopgcsioBatchHelperflushIfPossibleBatchHelperjava at comgooglecloudhadoopgcsioBatchHelperflushBatchHelperjava at comgooglecloudhadoopgcsioGoogleCloudStorageImplgetItemInfosGoogleCloudStorageImpljava at comgooglecloudhadoopgcsioForwardingGoogleCloudStoragegetItemInfosForwardingGoogleCloudStoragejava at comgooglecloudhadoopgcsioGoogleCloudStorageFileSystemgetFileInfosGoogleCloudStorageFileSystemjava at comgooglecloudhadoopgcsioGoogleCloudStorageFileSystemmkdirsGoogleCloudStorageFileSystemjava at comgooglecloudhadoopfsgcsGoogleHadoopFileSystemBasemkdirsGoogleHadoopFileSystemBasejava at orgapachehadoopfsFileSystemmkdirsFileSystemjava at comgooglecloudhadoopiobigqueryAbstractExportToCloudStorageprepareAbstractExportToCloudStoragejava at comgooglecloudhadoopiobigqueryAbstractBigQueryInputFormatgetSplitsAbstractBigQueryInputFormatjava at orgapachesparkrddNewHadoopRDDgetPartitionsNewHadoopRDDscala at orgapachesparkrddRDDanonfunpartitions applyRDDscala at orgapachesparkrddRDDanonfunpartitions applyRDDscala at scalaOptiongetOrElseOptionscala at orgapachesparkrddRDDpartitionsRDDscala at orgapachesparkrddMapPartitionsRDDgetPartitionsMapPartitionsRDDscala at orgapachesparkrddRDDanonfunpartitions applyRDDscala at orgapachesparkrddRDDanonfunpartitions applyRDDscala at scalaOptiongetOrElseOptionscala at orgapachesparkrddRDDpartitionsRDDscala at orgapachesparkrddMapPartitionsRDDgetPartitionsMapPartitionsRDDscala at orgapachesparkrddRDDanonfunpartitions applyRDDscala at orgapachesparkrddRDDanonfunpartitions applyRDDscala at scalaOptiongetOrElseOptionscala at orgapachesparkrddRDDpartitionsRDDscala at orgapachesparkrddRDDanonfuntake applyRDDscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparkrddRDDwithScopeRDDscala at orgapachesparkrddRDDtakeRDDscala at orgapachesparkrddRDDanonfunfirst applyRDDscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparkrddRDDwithScopeRDDscala at orgapachesparkrddRDDfirstRDDscala at comspotifysparkbigqueryBigQuerySQLContextbigQueryTableBigQuerySQLContextscala at comspotifysparkbigqueryBigQuerySQLContextbigQuerySelectBigQuerySQLContextscala at compowerspacebigqueryBigQueryExporterreadBigQueryExporterscala Cheers For some reason I get an IOException when I use bigQuerySelect However starting with bigQueryTable and doing the equivalent select works fine I tried multiple tables Using s ERROR ApplicationMaster User class threw exception javautilconcurrentExecutionException javaioIOException Encountered at line column Was expecting EOF javautilconcurrentExecutionException javaioIOException Encountered at line column Was expecting EOF at shadedguavazutilconcurrentAbstractFuturegetDoneValueAbstractFuturejava at shadedguavazutilconcurrentAbstractFuturegetAbstractFuturejava at shadedguavazutilconcurrentAbstractFutureTrustedFuturegetAbstractFuturejava at shadedguavazutilconcurrentUninterruptiblesgetUninterruptiblyUninterruptiblesjava at shadedguavazcacheLocalCacheSegmentgetAndRecordStatsLocalCachejava at shadedguavazcacheLocalCacheSegmentloadSyncLocalCachejava at shadedguavazcacheLocalCacheSegmentlockedGetOrLoadLocalCachejava at shadedguavazcacheLocalCacheSegmentgetLocalCachejava at shadedguavazcacheLocalCachegetLocalCachejava at shadedguavazcacheLocalCachegetOrLoadLocalCachejava at shadedguavazcacheLocalCacheLocalLoadingCachegetLocalCachejava at comspotifysparkbigqueryBigQueryClientqueryBigQueryClientscala at comspotifysparkbigqueryBigQuerySQLContextbigQuerySelectBigQuerySQLContextscala at comzulilyutilsdataBqTestfooBqTestscala at comzulilyutilsdataBqTestmainBqTestscala at comzulilyutilsdataBqTestmainBqTestscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachesparkdeployyarnApplicationMasteranon runApplicationMasterscala Caused by javaioIOException Encountered at line column Was expecting EOF at comgooglecloudhadoopiobigqueryBigQueryUtilswaitForJobCompletionBigQueryUtilsjava at comspotifysparkbigqueryBigQueryClientcomspotifysparkbigqueryBigQueryClientwaitForJobBigQueryClientscala at comspotifysparkbigqueryBigQueryClientanon loadBigQueryClientscala at comspotifysparkbigqueryBigQueryClientanon loadBigQueryClientscala at shadedguavazcacheLocalCacheLoadingValueReferenceloadFutureLocalCachejava at shadedguavazcacheLocalCacheSegmentloadSyncLocalCachejava more Hi folks Im trying to save a DF on BigQuery but Im getting this error My current environment is Spark running on a Google DataProc cluster It seems that an abstract method is getting called Any help will be appreciated Thanks in advance scala dfsaveAsBigQueryTableDATASETNEWTABLE Stage WARN orgapachesparkschedulerTaskSetManager Lost task in stage TID dotzdataprocmcdotzclouddatalabsdevinternal executor orgapachesparkSparkException Task failed while writing rows at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangAbstractMethodError orgapachesparksqlexecutiondatasourcesOutputWriterFactorygetFileExtensionLorgapachehadoopmapreduceTaskAttemptContextLjavalangString at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTasknewOutputWriterFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTaskexecuteFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparkutilUtilstryWithSafeFinallyAndFailureCallbacksUtilsscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala more Stage ERROR orgapachesparkschedulerTaskSetManager Task in stage failed times aborting job ERROR orgapachesparksqlexecutiondatasourcesFileFormatWriter Aborting job null orgapachesparkSparkException Job aborted due to stage failure Task in stage failed times most recent failure Lost task in stage TID dotzdataprocmcdotzclouddatalabsdevinternal executor orgapachesparkSparkException Task failed while writing rows at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangAbstractMethodError orgapachesparksqlexecutiondatasourcesOutputWriterFactorygetFileExtensionLorgapachehadoopmapreduceTaskAttemptContextLjavalangString at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTasknewOutputWriterFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTaskexecuteFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparkutilUtilstryWithSafeFinallyAndFailureCallbacksUtilsscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala more Driver stacktrace at orgapachesparkschedulerDAGSchedulerorgapachesparkschedulerDAGSchedulerfailJobAndIndependentStagesDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at scalacollectionmutableResizableArrayclassforeachResizableArrayscala at scalacollectionmutableArrayBufferforeachArrayBufferscala at orgapachesparkschedulerDAGSchedulerabortStageDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at scalaOptionforeachOptionscala at orgapachesparkschedulerDAGSchedulerhandleTaskSetFailedDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLoopdoOnReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkutilEventLoopanon runEventLoopscala at orgapachesparkschedulerDAGSchedulerrunJobDAGSchedulerscala at orgapachesparkSparkContextrunJobSparkContextscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite applymcVspFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite applyFileFormatWriterscala at orgapachesparksqlexecutionSQLExecutionwithNewExecutionIdSQLExecutionscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterwriteFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesInsertIntoHadoopFsRelationCommandrunInsertIntoHadoopFsRelationCommandscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultlzycomputecommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultcommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecdoExecutecommandsscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecuteQuery applySparkPlanscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparksqlexecutionSparkPlanexecuteQuerySparkPlanscala at orgapachesparksqlexecutionSparkPlanexecuteSparkPlanscala at orgapachesparksqlexecutionQueryExecutiontoRddlzycomputeQueryExecutionscala at orgapachesparksqlexecutionQueryExecutiontoRddQueryExecutionscala at orgapachesparksqlexecutiondatasourcesDataSourcewriteInFileFormatDataSourcescala at orgapachesparksqlexecutiondatasourcesDataSourcewriteDataSourcescala at orgapachesparksqlexecutiondatasourcesSaveIntoDataSourceCommandrunSaveIntoDataSourceCommandscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultlzycomputecommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultcommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecdoExecutecommandsscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecuteQuery applySparkPlanscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparksqlexecutionSparkPlanexecuteQuerySparkPlanscala at orgapachesparksqlexecutionSparkPlanexecuteSparkPlanscala at orgapachesparksqlexecutionQueryExecutiontoRddlzycomputeQueryExecutionscala at orgapachesparksqlexecutionQueryExecutiontoRddQueryExecutionscala at orgapachesparksqlDataFrameWriterrunCommandDataFrameWriterscala at orgapachesparksqlDataFrameWritersaveDataFrameWriterscala at orgapachesparksqlDataFrameWritersaveDataFrameWriterscala at comdatabrickssparkavropackageAvroDataFrameWriteranonfunavro applypackagescala at comdatabrickssparkavropackageAvroDataFrameWriteranonfunavro applypackagescala at comspotifysparkbigquerypackageBigQueryDataFramesaveAsBigQueryTablepackagescala at comspotifysparkbigquerypackageBigQueryDataFramesaveAsBigQueryTablepackagescala at line readiwiwiwiwiwiwiwiwiwiwinitconsole at line readiwiwiwiwiwiwiwiwiwinitconsole at line readiwiwiwiwiwiwiwiwinitconsole at line readiwiwiwiwiwiwiwinitconsole at line readiwiwiwiwiwiwinitconsole at line readiwiwiwiwiwinitconsole at line readiwiwiwiwinitconsole at line readiwiwiwinitconsole at line readiwiwinitconsole at line readiwinitconsole at line readinitconsole at line readinitconsole at line readclinitconsole at line evalprintlzycomputeconsole at line evalprintconsole at line evalprintconsole at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at scalatoolsnscinterpreterIMainReadEvalPrintcallIMainscala at scalatoolsnscinterpreterIMainRequestloadAndRunIMainscala at scalatoolsnscinterpreterIMainWrappedRequestanonfunloadAndRunReq applyIMainscala at scalatoolsnscinterpreterIMainWrappedRequestanonfunloadAndRunReq applyIMainscala at scalareflectinternalutilScalaClassLoaderclassasContextScalaClassLoaderscala at scalareflectinternalutilAbstractFileClassLoaderasContextAbstractFileClassLoaderscala at scalatoolsnscinterpreterIMainWrappedRequestloadAndRunReqIMainscala at scalatoolsnscinterpreterIMaininterpretIMainscala at scalatoolsnscinterpreterIMaininterpretIMainscala at scalatoolsnscinterpreterILoopinterpretStartingWithILoopscala at scalatoolsnscinterpreterILoopcommandILoopscala at scalatoolsnscinterpreterILoopprocessLineILoopscala at scalatoolsnscinterpreterILooploopILoopscala at scalatoolsnscinterpreterILoopanonfunprocess applymcZspILoopscala at scalatoolsnscinterpreterILoopanonfunprocess applyILoopscala at scalatoolsnscinterpreterILoopanonfunprocess applyILoopscala at scalareflectinternalutilScalaClassLoadersavingContextLoaderScalaClassLoaderscala at scalatoolsnscinterpreterILoopprocessILoopscala at orgapachesparkreplMaindoMainMainscala at orgapachesparkreplMainmainMainscala at orgapachesparkreplMainmainMainscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at orgapachesparkdeploySparkSubmitorgapachesparkdeploySparkSubmitrunMainSparkSubmitscala at orgapachesparkdeploySparkSubmitdoRunMain SparkSubmitscala at orgapachesparkdeploySparkSubmitsubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala Caused by orgapachesparkSparkException Task failed while writing rows at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangAbstractMethodError orgapachesparksqlexecutiondatasourcesOutputWriterFactorygetFileExtensionLorgapachehadoopmapreduceTaskAttemptContextLjavalangString at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTasknewOutputWriterFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTaskexecuteFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparkutilUtilstryWithSafeFinallyAndFailureCallbacksUtilsscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala more WARN orgapachesparkExecutorAllocationManager No stages are running but numRunningTasks orgapachesparkSparkException Job aborted at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite applymcVspFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite applyFileFormatWriterscala at orgapachesparksqlexecutionSQLExecutionwithNewExecutionIdSQLExecutionscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterwriteFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesInsertIntoHadoopFsRelationCommandrunInsertIntoHadoopFsRelationCommandscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultlzycomputecommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultcommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecdoExecutecommandsscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecuteQuery applySparkPlanscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparksqlexecutionSparkPlanexecuteQuerySparkPlanscala at orgapachesparksqlexecutionSparkPlanexecuteSparkPlanscala at orgapachesparksqlexecutionQueryExecutiontoRddlzycomputeQueryExecutionscala at orgapachesparksqlexecutionQueryExecutiontoRddQueryExecutionscala at orgapachesparksqlexecutiondatasourcesDataSourcewriteInFileFormatDataSourcescala at orgapachesparksqlexecutiondatasourcesDataSourcewriteDataSourcescala at orgapachesparksqlexecutiondatasourcesSaveIntoDataSourceCommandrunSaveIntoDataSourceCommandscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultlzycomputecommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecsideEffectResultcommandsscala at orgapachesparksqlexecutioncommandExecutedCommandExecdoExecutecommandsscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecute applySparkPlanscala at orgapachesparksqlexecutionSparkPlananonfunexecuteQuery applySparkPlanscala at orgapachesparkrddRDDOperationScopewithScopeRDDOperationScopescala at orgapachesparksqlexecutionSparkPlanexecuteQuerySparkPlanscala at orgapachesparksqlexecutionSparkPlanexecuteSparkPlanscala at orgapachesparksqlexecutionQueryExecutiontoRddlzycomputeQueryExecutionscala at orgapachesparksqlexecutionQueryExecutiontoRddQueryExecutionscala at orgapachesparksqlDataFrameWriterrunCommandDataFrameWriterscala at orgapachesparksqlDataFrameWritersaveDataFrameWriterscala at orgapachesparksqlDataFrameWritersaveDataFrameWriterscala at comdatabrickssparkavropackageAvroDataFrameWriteranonfunavro applypackagescala at comdatabrickssparkavropackageAvroDataFrameWriteranonfunavro applypackagescala at comspotifysparkbigquerypackageBigQueryDataFramesaveAsBigQueryTablepackagescala at comspotifysparkbigquerypackageBigQueryDataFramesaveAsBigQueryTablepackagescala elided Caused by orgapachesparkSparkException Job aborted due to stage failure Task in stage failed times most recent failure Lost task in stage TID dotzdataprocmcdotzclouddatalabsdevinternal executor orgapachesparkSparkException Task failed while writing rows at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangAbstractMethodError orgapachesparksqlexecutiondatasourcesOutputWriterFactorygetFileExtensionLorgapachehadoopmapreduceTaskAttemptContextLjavalangString at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTasknewOutputWriterFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTaskexecuteFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparkutilUtilstryWithSafeFinallyAndFailureCallbacksUtilsscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala more Driver stacktrace at orgapachesparkschedulerDAGSchedulerorgapachesparkschedulerDAGSchedulerfailJobAndIndependentStagesDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at scalacollectionmutableResizableArrayclassforeachResizableArrayscala at scalacollectionmutableArrayBufferforeachArrayBufferscala at orgapachesparkschedulerDAGSchedulerabortStageDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at scalaOptionforeachOptionscala at orgapachesparkschedulerDAGSchedulerhandleTaskSetFailedDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLoopdoOnReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkutilEventLoopanon runEventLoopscala at orgapachesparkschedulerDAGSchedulerrunJobDAGSchedulerscala at orgapachesparkSparkContextrunJobSparkContextscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite applymcVspFileFormatWriterscala more Caused by orgapachesparkSparkException Task failed while writing rows at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunwrite anonfunapplymcVsp applyFileFormatWriterscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Caused by javalangAbstractMethodError orgapachesparksqlexecutiondatasourcesOutputWriterFactorygetFileExtensionLorgapachehadoopmapreduceTaskAttemptContextLjavalangString at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTasknewOutputWriterFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterSingleDirectoryWriteTaskexecuteFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparksqlexecutiondatasourcesFileFormatWriteranonfunorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTask applyFileFormatWriterscala at orgapachesparkutilUtilstryWithSafeFinallyAndFailureCallbacksUtilsscala at orgapachesparksqlexecutiondatasourcesFileFormatWriterorgapachesparksqlexecutiondatasourcesFileFormatWriterexecuteTaskFileFormatWriterscala more 