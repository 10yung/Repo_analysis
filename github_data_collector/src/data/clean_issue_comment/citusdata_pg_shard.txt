Someone posted an issue in the repo for pgpartman about not being able to read data from the parent table when used in combination with pgshard Havent been able to reproduce this at this time but wondered if anyone here might be able to help them or if there are any known issues when using table inheritance with sharding Now that weve addressed this in CitusDB we want to get it into pgshard as well We know how to do prepared statements for queries but pgshard must support modifications as well Adding this support will remove a ton of friction from database adapters such as Psycopg in Python pg in Ruby or the JDBC adapters in Java Im sure some bugs could shake out of but for now all the tests are passing and pgshard appears usable under PostgreSQL alpha With this in mind can we figure out how to get the new UPSERTstyle feature of working in pgshard Many uses of this feature will be idempotent and commutable Can we detect which is huge from a distributed systems standpoint Making a query against a table that has been marked as distributed either by CREATE TABLE DISTRIBUTE BY or using mastercreatedistributedtable which does not yet have any shards created using either stage or mastercreateworkershards results in different behavior depending upon whether the active planner is CitusDBs or pgshards Under CitusDB the query returns zero rows pgshard raises an error directing the user to call mastercreateworkershards The latter is obviously helpful under pgshard especially for users who have missed this step but is confusing under CitusDB Now that integration is tighter we need to figure out what the best approach is pgshard keeps a cache of shard interval metadata within each session which is never refreshed Within pgshard this is fine since all shards are created up front caching forever isnt wrong But now that Citus integration is more fullfledged were noticing that things like appending new shards or rebalancing existing ones results in pgshard operating using stale metadata We need to come up with some sort of contract to let other pieces of software tell pgshard about changes in the shard intervals of a distributed table We may be able to reuse some existing pieces of invalidation logic within PostgreSQL but that requires some reading to determine Any query using the RETURNING clause produces the following error NotSupportedError cannot perform distributed planning for the given query DETAIL RETURNING clauses are not supported in distributed queries Can you add support for RETURNING clauses Could mastercreateworkershards be extended in order to optionally create UNLOGGED shard placements It seems to work when I change them manually but this is tedious smile But it makes a big difference in write speed Since there are replicas the risk of UNLOGGED seems to be lower than in a single node database Im experimenting with using HyperLogLog HLL data types in some columns One problem with these is that they take up quite a lot more space than a BIGINT pgshard potentially allays a lot of those issues The extension that provides the HLL datatype is this one by aggregateknowledge These two extensions seem complimentary for warehousing purposes Surprisingly these data types work with sharded tables for most types of reads but not for writes see below When I attempt an update like so sql update testhllshard set users usershllhashtextfoobar where date date I get ERROR cannot plan sharded modification containing values which are not constants or constant expressions I can sort of work around this by setting the literal bytes in this field Which works fine but adding HLL values requires a read and a write Since pgshard understandably doesnt allow for more than a single statement transaction this leaves my usecase vulnerable to race conditions in multiwriter environments Since this function is available on the workers and is deterministic based on the value of the existing row and the new HLL value to be added there shouldnt be any issue with dispatching this expression through to the workers Is there a hard limitation preventing pgshard from dispatching modifications for nonconstant expressions The bug happens when pgshard fails to INSERT to shard placement and postgres is shut down or psql connection is closed before shard placement status is updated This is not easy to reproduce bug But if a sleep function call is added to this line reproducing becomes easy Assuming that sleep is added the bug can be reproduced with following steps Create a cluster with master workers Distribute table and create worker shards with replication factor Stop one of the worker nodes Connect to psql and get its pid select pgbackendpid Issue an INSERT on that psql session During the INSERT since we added a sleep it takes at least the sleep seconds execute shell command kill pidofpsql Restart both master and the stopped worker node Connect to worker nodes and observe that one of the shards is divergent But shard placements on metadata has all STATEFINALIZED status The main problem here is that we do not execute remote commands and state status changes in an atomic way A possible Solution that we can try is to check whether HOLDINTERRUPTSRESUMEINTERRUPTS works Also check if these function call pair has any drawbacks Ive got a rubygem call Apartment that does database multitenancy for ActiveRecord using postgresql schemas Effectively our whole table structure is mirrored on a perschema basis for each customer that we add to the system Itd be nice if we could shard based on the postgresql schema such that the app itself wouldnt need to know about physical shards under the hood and queries containing a particular schema in the search path would automatically be routed to the correct physical machine The basic setup is that public schema stores excluded models which are non tenanted models Then for each tenant we create a new schema and create all the tables etc in that schema I guess this would involve triggers on things like CREATE SCHEMA x to actually create it on the correct shard and then of course on queries themselves to route to that schema As discussed at PgConf Im not well versed on the internals of pgshard itself but Im quite happy to get the discussion going around the Apartment design and using schemas from a sharding concern 