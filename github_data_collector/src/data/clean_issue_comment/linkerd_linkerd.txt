 Filing a Linkerd issue Issue Type Bug report What happened Request had been retrying for hours whilst request budget totalTimeoutMs was set on amount s What you expected to happen Request is failed when budget is exceeded How to reproduce it as minimally and precisely as possible Sorry I cant provide steps to reproduce But I provide config causing the issue and config eliminating it Environment linkerd version Linux node generic Ubuntu SMP Wed Mar UTC x x x GNULinux Config causing issue admin ip port usage enabled false telemetry kind iol dprometheus prefix cms namers kind iol dconsul host port includeTag true useHealthCheck true token linkerdtoken setHost true consistencyMode stale preferServiceAddress true routers protocol http label cmstoapi identifier kind iol dstatic path japi dtab svcjapi iol dconsulqajapijavaapi service totalTimeoutMs responseClassifier kind iol dhttpretryableRead XX retries budget minRetriesPerSec percentCanRetry ttlSecs backoff kind jittered minMs maxMs servers port ip addForwardedHeader by kind ipport for kind ip client failureAccrual kind iol dsuccessRate successRate requests backoff kind jittered minMs maxMs loadBalancer kind ewma httpAccessLog accesslog httpAccessLogRollPolicy daily httpAccessLogAppend true httpAccessLogRotateCount tracePropagator kind iol dzipkin Config fixing issue only parameters differ on service level backoff kind jittered minMs maxMs on client level requeueBudget percentCanRetry When maxMs set on was reached request was retrying again and again for hours each seconds causing an exception in linkerd trace is below On the same time application successfully responded to linkerd but linkerd continued retrying request It was happening up to times per day whilst application send k rpm to linkerd meaning that its not critical but unpleasant thing to experience D UTC THREAD TraceId a ac af a b Failed midstream Terminating stream closing connection comtwitterfinagleChannelClosedException ChannelException at remote address Remote Info Not Available at comtwitterfinaglenetty transportChannelTransportanon channelInactiveChannelTransportscala at ionettychannelAbstractChannelHandlerContextinvokeChannelInactiveAbstractChannelHandlerContextjava at ionettychannelAbstractChannelHandlerContextinvokeChannelInactiveAbstractChannelHandlerContextjava at ionettychannelAbstractChannelHandlerContextfireChannelInactiveAbstractChannelHandlerContextjava at ionettychannelChannelInboundHandlerAdapterchannelInactiveChannelInboundHandlerAdapterjava at ionettychannelAbstractChannelHandlerContextinvokeChannelInactiveAbstractChannelHandlerContextjava at ionettychannelAbstractChannelHandlerContextinvokeChannelInactiveAbstractChannelHandlerContextjava at ionettychannelAbstractChannelHandlerContextfireChannelInactiveAbstractChannelHandlerContextjava at ionettychannelChannelInboundHandlerAdapterchannelInactiveChannelInboundHandlerAdapterjava Is it an expected behavior if jittered backoff maxMs has higher value than request budget I believe it shouldnt be a such case Please correct me if I wrong Many thanks Linkerd follows the CNCF Code of Conduct Signedoffby Nguyen Hai Truong truongnhfujitsucom Issue Type Bug report x Feature request What happened Current gRPC runtime implementation by Buoyant doesnt validate contenttype header in incoming requests A generic http gRPC client making a request to any gRPC endpoints exposed by linkerdnamerd will fail to interpret the response and the error will not tell whats wrong To avoid such issues gRPC over HTTP spec suggests setting on client and validating on server following headers ServiceName proto package name service name MessageType fully qualified proto message name ContentType applicationgrpcproto ContentType validation is the most desirable one and its also the easiest to implement What you expected to happen Server should return corresponding status codes if values of the headers do not match expected values How to reproduce it as minimally and precisely as possible Assuming a gRPC endpoint for example mesh interface is exposed on port curl v http priorknowledge localhost Trying TCPNODELAY set Connected to localhost port Using HTTP server supports multiuse Connection state changed HTTP confirmed Copying HTTP data in stream buffer to connection buffer after upgrade len Using Stream ID easy handle x af c f GET HTTP Host localhost UserAgent curl Accept Connection state changed MAXCONCURRENTSTREAMS REFUSEDSTREAM retrying a fresh connect Connection died retrying a fresh connect Closing connection Issue another request to this URL Hostname localhost was found in DNS cache Trying TCPNODELAY set Connected to localhost port Using HTTP server supports multiuse Connection state changed HTTP confirmed Copying HTTP data in stream buffer to connection buffer after upgrade len Using Stream ID easy handle x af c f GET localhost HTTP Host localhost UserAgent curl Accept Connection state changed MAXCONCURRENTSTREAMS HTTP te trailers via h linkerd Connection to host localhost left intact Environment linkerdnamerd version This is related to Thanks for your help improving the project Getting Help Github issues are for bug reports and feature requests For questions about Linkerd how to use it or debugging assistance start by asking a question in the forums or join us on Slack Full details at CONTRIBUTINGmd Filing a Linkerd issue Issue Type x Bug report Feature request What happened After some time linkerd stops routing traffic to external DNS names with E UTC THREAD TraceIdb af cbd ae service failure comtwitterfinaglenamingbuoyantDynBoundTimeoutException Exceeded seconds binding timeout while resolving name svcgooglecom and I UTC THREAD Reaping svcgooglecom Routing to internal services works fine Additional symptom Delegator webpage starts to load without DTAB form and with message The request to namerd has timed out Please ensure your config is correct and try again Restart of linkerd restores functioning of routing to external services and Delegator webpage What you expected to happen linkerd shouldnt require restart to route traffic to external services How to reproduce it as minimally and precisely as possible Anything else we need to know linkerd and affected services are deployed in k s cluster router configuration protocol http label httpoutgoing maxRequestKB maxResponseKB httpAccessLog varloglinkerdl dhttpoutgoingaccesslog client failureAccrual kind none interpreter kind iol dk sconfigMap experimental true name l ddtabsconfig filename httpoutgoing namespace servicemesh servers port ip bindingTimeoutMs bindingCache paths trees bounds clients idleTtlSecs DTAB used httpoutgoing ph iobuoyantrinet ph googlecom iobuoyantrinet googlecom svc ph svcgooglecom ph googlecom svc iobuoyantporthostPfxph svcgooglecom ph googlecom k s iol dk s k sdefaulthttpfoo iol dk shttpdefaulthttpfoo portNsSvc portNsSvcToK s portNsSvchttpdefaultfoo k sdefaulthttpfoo host portNsSvchttpdefault hostfoo portNsSvchttpdefaultfoo host portNsSvchttp hostdefaultfoo portNsSvchttpdefaultfoo svc iobuoyanthttpdomainToPathPfxhost svcfoodefault hostdefaultfoo Environment linkerdnamerd version config files linkerd namerd is not used Platform version and config files Kubernetes DCOS etc Kops created k s cluster in AWS Cloud provider or hardware configuration AWS Linkerds H protocol uses the SingletonPool for connection pooling This means that all requests for an address multiplex on the same connection This works great until maxStreamsPerConnection is reached at which point additional requests will fail until an existing stream completes While this backpressure behavior is desirable it can also be limiting especially when talking to a server with a low value for maxStreamConnection We should create a connection pooling module that allows additional connections to be established and pooled when the number of concurrent requests exceeds the maximum number of streams a single connection can support Related to Thanks for your help improving the project Filing a Linkerd issue Issue Type X Bug report Feature request What happened We had an incident where out of linkerds were affected they didn t get watch update for the affected service from namerd We inspected following things during the incident All of linkerds were on http mesh and the underlying connection was healthy as well to make sure this bug is different from when underlying http connection goes stale because of the missing http ping feat We also verified that all namerds were up to date We validated that linkerds were routing traffic to the service but to wrong destination We did a rolling restarts of namerd hoping linkerds will connect back again and will get up to date w namerds But linkerds didn t recover Few other things we observed during the incident linkerds that were running v thriftmux interpreter didnt have this problem but that could just be a coincidence too After we restart namerds some linkerd watches for other services did get up to date lastUpdated in mesh interpreter state from inspect endpoint had the same time when the namerd restart occurred All of the above leads us to the hypothesis that there is a bug in http mesh interpreter client What you expected to happen Linkerds should route traffic to expected destinations How to reproduce it as minimally and precisely as possible Unfortunately we dont know the exact steps yet Anything else we need to know Please ask for the gist because im too lazy to redact it that contains namerds bind snapshots to validate all namerds were up to date and linkerd mesh interpreter snapshots before and after namerd restarts to validate some watches did up date Environment linkerdnamerd version config files linkerd and namerd v interpreter http mesh Platform version and config files Kubernetes DCOS etc k s Cloud provider or hardware configuration GCP Thanks for your help improving the project Getting Help Github issues are for bug reports and feature requests For questions about Linkerd how to use it or debugging assistance start by asking a question in the forums or join us on Slack Full details at CONTRIBUTINGmd Filing a Linkerd issue Issue Type Bug report X Feature request What happened We are seeing numerous cases where namerd state diverge from k s apiserver dtabs and endpoint linkerd state diverge from namerd eg linkerd thinks only pods are available but namerd sees We suspect events are getting dropped in namerd and linkerd To figure out where things are going wrong linkerd and namerd should trace all inbound and outbound watch or relevant events What you expected to happen Namerd and linkerd should log all inbound and outbound events Eg Namerd received X event from apiserver Namerd making X API call to apiserver Namerd sending event X to linkerd Y along with successfailure Namerd received an open stream from Linkerd X Linkerd making X api call to namerd Linkerd received X api call to namerd If we can also log on namerd that linkerd with hostname is connected to namerd that would be really helpful too IPs are NATed So we lose the observability what linkerd is connected to what namerd How to reproduce it as minimally and precisely as possible NA Anything else we need to know Let me know if you know more information Environment linkerdnamerd version config files linkerd namerd http mesh thriftmux Platform version and config files Kubernetes DCOS etc Cloud provider or hardware configuration not relevant Issue Type Bug report X Feature request This is motivated by the same use case describedin Ill copypaste that use case here Use case We are trying to use Linkerds dtab feature to build very large dynamic routing tables The goal to use Linkerd instead of eg Consul to control which versions of which applications get routed to when a a request for a particular service is received This requires us to dynamically build most of our dtab and requires that the dtab have an explicit dentry for every service in our eco system Eg svccoolthing taggedver coolthing svclamething taggedver lamething taggedver lamething This means that our dtab will get very large The example Im working with at the moment is lines long and kb Problem Were using Consul as the KV store Consul enforces a kb limit on the base encoded values While my example dtab at kb is close to what our current worst case would be were concerned that this will not scale with time Proposed solution Wed like to have the ability to readwrite gzipped or otherwise compressed dtabs from Consul or any other datastore The dynamic dtabs compress extremely well my current example is only k The compression gains are only slightly lost with base encoding that Consul demands my final encoded gzipped dtab was k Issue Type Bug report X Feature request Problem We are trying to use Linkerds dtab feature to build very large dynamic routing tables The goal to use Linkerd instead of eg Consul to control which versions of which applications get routed to when a a request for a particular service is received This requires us to dynamically build most of our dtab and requires that the dtab have an explicit dentry for every service in our eco system Eg svccoolthing taggedver coolthing svclamething taggedver lamething taggedver lamething This means that our dtab will get very large The example Im working with at the moment is lines long and kb When linkerd errors in some way say when a requested service is not found it currently s and sends back an error message that contains among other things the entire dtab in both the body and a response header Fortunately Linkerd appears to truncate the response header field instead of blowing up But I think it would be useful to be able to suppress this verbose response by default exposing it only if the client provided a debug header Possible solution Provide a configuration option to suppress verbose error responses by default Add support for a debug header that results in the verbose error response Thanks for your help improving the project Getting Help Github issues are for bug reports and feature requests For questions about Linkerd how to use it or debugging assistance start by asking a question in the forums or join us on Slack Full details at CONTRIBUTINGmd Filing a Linkerd issue Issue Type x Bug report Feature request What happened GRPC calls made from the browser are preceeded with a preflight request These requests are made via http which causes the h protocol to fail What you expected to happen Preflight check to be accepted by the h protocol and the request being normally routed How to reproduce it as minimally and precisely as possible Make calls from a web browser using Anything else we need to know Environment linkerdnamerd version config files v Platform version and config files Kubernetes DCOS etc windows server Cloud provider or hardware configuration