Excuse me I want to ask how to implement the pooling layer or other functions defined by ourselves foolwood I meet the same problem with the same environment After I change the default setting to nonrecursive the problem still exists Although the hint change the problem seems unchanged Error Message below Error using vlargparse line Expected either a paramvalue pair or a structure Error in runDCFNetDCFNetinitialize line state vlargparsestate param nonrecursive Error in runDCFNet line state DCFNetinitializeim initrect param Error in demoDCFNet line res runDCFNetsubS param It seems like the param must be a structure If not the function will be in loop But I do not allow it to loop the function have to stop because of the lack of structured parameter Can you help me Thanks a lot Originally posted by tzjtatata in In your tracking process the output feature size is before the DCF layer However in your training code the networkType is set to and the output size after two convolutional laysers is smaller than the input image size by featurezainputsize I wonder why the saved netork mat file after training can generate different feature size Look for your early reply And thank you very much What is the function of LRN layer I notice that some siamese trackers use BatchNorm layer Thanks for your work and code When i use the VID as training data it will generate pairs traning data even the batchsize is set to be it still have more than calculations in one epoch How to solve this problem when you are training the network Thanks Dear Qiang Wang can you explain how imgcropmultiscalem work I cannot grasp your thought though DCFNet indeed achieve a better results all best heng Thanks for good work as usual Take type and type network for example I find that the padding of the conv layers is all when traininginput size output size But when tracking the padding is set to input size output size while using the same conv parameters Can you explain why you do like this It is a theoretical settingbetter in theory or just a experimental result better performance in experiments why is it very slow to load when I want to run demo In one of the issues you mentioned that the resolution map is an important factor why DCFNet has better performance than CFNet Could you elaborate more information about this How much AUC would loss if the resolution of the feature map is smaller such as as mentioned Hi I noticed that while training the CNN output before DCF is not mult with cos window or hann in contradiction to tracking pipeline that mult the CNN output Why