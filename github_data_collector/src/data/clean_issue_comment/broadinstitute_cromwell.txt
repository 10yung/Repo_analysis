 Hi Im trying to enable call caching using a local file database and I cant seem to get it to work Everything that I try does not seem to make a difference and each run always starts from the first task Im running cromwell in run mode from the command line and I am testing on both cromwell and cromwell I also have writetocache and readfromcache set to true in my optionsjson although I understand that is the default behaviour I am unable to use a mySQL or postgres database at this current time Is there something that Im missing Is there any additional information that is needed to help diagnose this My cromwellconf is as follows backend default LSF providers LSF actorfactory cromwellbackendimplsfsconfigConfigBackendLifecycleActorFactory config exitcodetimeoutseconds runtimeattributes Int cpus Float memorymb String lsfqueue String lsfproject submit bsub q lsfqueue P lsfproject J jobname cwd cwd o out e err n cpus R rusage memmemorymb usrbinenv bash script jobidregex Job d kill bkill jobid checkalive bjobs jobid filesystems local localization softlink copy hardlink caching duplicationstrategy softlink copy hardlink hashingstrategy path callcaching enabled true invalidatebadcacheresults true database profile slickjdbcHsqldbProfile db driver orghsqldbjdbcDriver url jdbchsqldbfilecromwellexecutionscromwelldbcromwelldb shutdownfalse hsqldbdefaulttabletypecachedhsqldbtxmvcc hsqldbresultmaxmemoryrows hsqldblargedatatrue hsqldbapplog hsqldblobcompressedtrue hsqldbscriptformat connectionTimeout numThreads I am following up on a report by someone else filed over a year ago Now I have a slightly different need that is the task will take the optional input input opt for its required input So the following is what I want to achieve version workflow myworkflow input File input File input opt call task input input input if definedinput opt call task input input input opt output File output task output File output task output task task input File input command echo Hello world hellotxt output File output hellotxt task task input File input command cat input goodbyetxt output File output goodbyetxt Running womtool validate on this gives Failed to process workflow definition myworkflow reason of Failed to process call task reason of Failed to supply input input input opt reason of Cannot coerce expression of type File to File But like in the original post if I take out the version specification and the input braces in the workflow and tasks womtool thinks the WDL is OK Can you please explain what is the cause And is there a solution on my end Thanks The Jira interface is way too overwhelming IMPORTANT Please file new issues over in our Jira issue tracker You may need to create an account before you can viewcreate issues This PR adds a workflow specific option similar to monitoringscript that will spin up an SSH server in a container on Google Genomics workers It essentially uses the approach discussed here in an earlier GitHub issue adding an additional Action that creates a Docker container with Google Genomics Toolssshserver entrypoint See here for Googles implementation I also updated the documentation to include the new parameter and have tested it in our GCP environment with the attached files There is a corresponding JIRA issue here Happy to add or fix up anything on here just let me know Thanks Adam workflowcwl usrbinenv cwlrunner cwlVersion v class CommandLineTool baseCommand sleep requirements class DockerRequirement dockerPull debianstretch inputs time type int inputBinding position outputs workflowinputsyml time optionsjson enableremoteaccess true I have a simple workflow with the following input cache structure json String sampleName B BE D FBA A E B E File reference f b b dff c f d fbc c ac File referencebwt f b b dff c f d fbc c ac File reads fa ef d abd c e ff c df b af eb ebe c When I rerun the workflow I purely get a cacheMiss but the metadata comparison between two of the inputs gives the following error status error message Failed to calculate diff for call A and call B nFailed to extract relevant metadata for call A f a bfe a f c bca a BwaAlignerbwamem reason of Cannot extract hashes for File reads Expected JsString or JsObject but got JsArray ec ed c d d ad c e ce cf ff b c feb b nFailed to extract relevant metadata for call B e f c d c e bb c BwaAlignerbwamem reason of Cannot extract hashes for File reads Expected JsString or JsObject but got JsArray fa ef d abd c e ff c df b af eb ebe c errors JsArray elements JsString value Failed to extract relevant metadata for call A f a bfe a f c bca a BwaAlignerbwamem reason of Cannot extract hashes for File reads Expected JsString or JsObject but got JsArray ec ed c d d ad c e ce cf ff b c feb b JsString value Failed to extract relevant metadata for call B e f c d c e bb c BwaAlignerbwamem reason of Cannot extract hashes for File reads Expected JsString or JsObject but got JsArray fa ef d abd c e ff c df b af eb ebe c I presume this means that processField CallCacheDiffActorscalaL L is missing a case key subObject JsArray I confirmed this by adding the case I dont know scala nor inner workings of Cromwell except enough to know this probably isnt a good way to do it but just wanted to see if my suspicion was correct scala case key subObject JsArray MapkeyPrefix key subObjectelementsmkStringvalidNel Which fixed the error Hi Ill manually synchronise this issue with Jira Ive raised it here as I think it has better exposure might be useful as a reference and Im going to reference it from a different issue Im trying to get callcaching working for my workflows and having some trouble identifying a config that will work for the following requirements Using containers both Singularity and Docker Initial localisation strategy hardlink cachedcopy Local SFS environment My input files can be fairly large GB per Bam with up to Bams If I can get this working Ill happily document and update the CallCaching documentation page with what Ive found Background information Version Cromwell Documentation Cache duplication strategies hardlink softlink This strategy is not applicable for tasks which specify a Docker image and will be ignored copy cachedcopy This is noncache duplication strategy Cache hashing strategies file default computes an md hash of the file content Code tryWithResource filenewInputStream DigestUtilsmd Hex path computes an md hash of the file path This strategy will only be effective if the duplicationstrategy above is set to softlink pathmodtime compute an md hash of the file path and the last modified time The same conditions as for path apply here Code md HexfiletoAbsolutePathpathAsString filelastModifiedTimetoString Other caching options systemfilehashcache Prevent repeatedly requesting the hashes of the same files multiple times backendprovidersLocalcachingchecksiblingmd will check if a sibling file with the same name and the md extension exists and if it does use the content of this file as a hash My takeaway I cant use a softlink cache duplication strategy as its not allowed for containers If I select the pathmodtime hashing strategy only the first task in a workflow will succeed as the hardlink duplication strategy will cause the path absolute be different causing a hash differential Questions What defines a cache hit or exactly which information is used to the call hash Ill answer this one myself by looking at the metadata returned from apiworkflowsversionidmetadata within the callsyourstepnamecallCaching the hashes field has the following attributes output count runtime attribute output expression input count backend name command template input When does the command section get hashed before or after replacements The template gets cached What other elements go into the building the cache output count runtime attribute output expression input count backend name command template input What are the downsides with checksiblingmd can it be used in conjunction with systemfilehashcache Is the only way to use callcaching with containers without fully hashing the file Possible resolutions I was thinking the following might be potential solutions for my problem but I dont know how good bad they are and theyd require changes to Cromwell Potential for a cheaper and potentially dirtier hash for files When cromwell links from a cached result store a map of newpath original link to use or call caching so when the hashDifferential is calculated it uses the hash of the original cached result This would mean we could use the pathmodtime strategy Current attempt I realised I may have run into another error here This is my current configuration it will successfully pull cache for the FIRST step in a workflow but then fail afterwards detailssummaryClick to show configurationsummaryp hocon include requiredclasspathapplication system jobshell binsh cromwellid cromwellfdcce cromwellidrandomsuffix false database db driver commysqlcjjdbcDriver url jdbcmysqllocalhostcromwellrewriteBatchedStatementstrue useSSLfalse serverTimezoneUTC user root connectionTimeout profile slickjdbcMySQLProfile backend default Local providers Local actorfactory cromwellbackendimplsfsconfigConfigBackendLifecycleActorFactory config root Usersfranklinmichaeljaniscachetest f ee janisexecution filesystems local caching hashingstrategy pathmodtime callcaching enabled true pdetails Thanks in advance for your help