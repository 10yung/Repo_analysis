Upgrade VS to work with the newest release of Hail Upgrade Hail Integration to work with Hail The Biallelic option in the current version allows for two different representations of variants in the output file CHRPOS CHRPOSREFALT I was wondering if this option is extended to allow the user to choose which columns to be used as a variable name in the output file For example ID column that contains rsID in most VCF files Or a custom combination of columns like bcftools query f command for example CHRPOSID Ultimately it would be great if VariantSpark can output a VCF file where the importance score is annotated in the information field of the VCF file For example VSIS and VSISNA for those variants which are not selected in the tree This annotation facilitates using VariantSpark in different pipelines dependency groupIdorgjson sgroupId artifactIdjson sextscalabinaryversionartifactId version version dependency This dependancy is there twice Affecting the maven build Some ideas to consider for improved performance splits coming form a singel variable are likely to be very sparse as such it may not make sense to return them in a dense array and then merge the array may even be empty At least at the local level some sparse representation may be better or some kind of accumulator This is noticeable by comparing runtime on sparse vs dense synthetic regression datasets The sparse ones run much slower although intuitively they should run faster The procedure of selecting split variables in case of equal reduction in impurity is slightly biased towards variables with larger indexes In the previous nonreproducible approach it was casused by the increased probablilly of selecting later variables In the current one it is probably cause by not enough randomness in using XOR as hashing function The solution is to use a better hashing function to generate a surrogate order and to vary it on only per batch and partition but also for every split Mumur hashing seem to be a good candiate Here is the code snippet MurmurSnippettxt Make is somehow possible to group tests based on the spark context then need Currently only one context is possible for all tests while three different context are needed a basic local context for most of the tests a hail configured local contex for hail test a mulithreaded local context for ReproducibilyTest When using VariantSpark Interface for Hail a large batch size could lead to a crash in the process For example for the following setup a batch size of result in failure tested several times while the batch size of works well setup Hail note book running on AWS EMR with r xlarge master node sparkdrivermemory G dataset SNPs and k samples the Failure error Py JJavaErrorTraceback most recent call last ipythoninput b aa b in module JialiBD ipythoninput e b dfbf f in Jialiprefix vds vdsannotatesamplestablesets rootsaset saktvakt LRVSvds vds vdsannotatesamplestablesakt rootsasetall vds vdsannotatevariantstablevakt rootvasetall ipythoninput e b dfbf f in LRVSvds printMAF xvdscount via xvdsimportanceanalysissalabel ntrees mtryfraction oob False seed L batchsize vskt viaimportantvariants orderbydescimportanceindexedrankrename vvsisvsrank homehadoopminiconda envsjupyterlibpython sitepackagestypedecoratorinitpyc in wrapperargs kwargs doesnt match signature s k reprv constrainttostringtypes k return fnargs kwargs wrappername fnname homehadoopminiconda envsjupyterlibpython sitepackagesvarsparkhailextendpyc in importanceanalysisself yexpr ntrees mtryfraction oob seed batchsize selfvshfcacheimportanceAnalysisyexpr ntrees joptionmtryfraction oob joptionlongseed if seed is not None else None batchsize paramsselfobject operationnamestr usrlibsparkpythonlibpy j srczippy jjavagatewaypy in callself args answer selfgatewayclientsendcommandcommand returnvalue getreturnvalue answer selfgatewayclient selftargetid selfname for temparg in tempargs usrlibsparkpythonlibpysparkzippysparksqlutilspy in decoa kw def decoa kw try return fa kw except py jprotocolPy JJavaError as e s ejavaexceptiontoString usrlibsparkpythonlibpy j srczippy jprotocolpy in getreturnvalueanswer gatewayclient targetid name raise Py JJavaError An error occurred while calling n formattargetid name value else raise Py JError Py JJavaError An error occurred while calling o importanceAnalysis orgapachesparkSparkException Exception thrown in awaitResult at orgapachesparkutilThreadUtilsawaitResultThreadUtilsscala at orgapachesparkrpcRpcTimeoutawaitResultRpcTimeoutscala at orgapachesparkstorageBlockManagerMasterremoveBroadcastBlockManagerMasterscala at orgapachesparkbroadcastTorrentBroadcastunpersistTorrentBroadcastscala at orgapachesparkbroadcastTorrentBroadcastdoDestroyTorrentBroadcastscala at orgapachesparkbroadcastBroadcastdestroyBroadcastscala at orgapachesparkbroadcastBroadcastdestroyBroadcastscala at aucsiropbdavassparklesparkSparkUtilswithBroadcastSparkUtilsscala at aucsirovariantsparkalgoDecisionTreeanonfunsplitSubsets applyDecisionTreescala at aucsirovariantsparkalgoDecisionTreeanonfunsplitSubsets applyDecisionTreescala at aucsiropbdavassparklecommonutilsProfclassprofItProfscala at aucsirovariantsparkalgoDecisionTreeprofItDecisionTreescala at aucsirovariantsparkalgoDecisionTreesplitSubsetsDecisionTreescala at aucsirovariantsparkalgoDecisionTreeanonfunfindBestSplitsAndSubsets anonfunapply applyDecisionTreescala at aucsirovariantsparkalgoDecisionTreeanonfunfindBestSplitsAndSubsets anonfunapply applyDecisionTreescala at aucsiropbdavassparklesparkSparkUtilswithBroadcastSparkUtilsscala at aucsirovariantsparkalgoDecisionTreeanonfunfindBestSplitsAndSubsets applyDecisionTreescala at aucsirovariantsparkalgoDecisionTreeanonfunfindBestSplitsAndSubsets applyDecisionTreescala at aucsiropbdavassparklecommonutilsProfclassprofItProfscala at aucsirovariantsparkalgoDecisionTreeprofItDecisionTreescala at aucsirovariantsparkalgoDecisionTreefindBestSplitsAndSubsetsDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreebuildSplitDecisionTreescala at aucsirovariantsparkalgoDecisionTreeanonfun applyDecisionTreescala at aucsirovariantsparkalgoDecisionTreeanonfun applyDecisionTreescala at aucsiropbdavassparklesparkSparkUtilswithBroadcastSparkUtilsscala at aucsirovariantsparkalgoDecisionTreebatchTrainDecisionTreescala at aucsirovariantsparkalgoRandomForestanon batchTrainRandomForestscala at aucsirovariantsparkalgoRandomForestanonfun anonfunapply applyRandomForestscala at aucsirovariantsparkalgoRandomForestanonfun anonfunapply applyRandomForestscala at aucsiropbdavassparklecommonutilsTimedtimeTimedscala at aucsirovariantsparkalgoRandomForestanonfun applyRandomForestscala at aucsirovariantsparkalgoRandomForestanonfun applyRandomForestscala at scalacollectionIteratoranon nextCurIteratorscala at scalacollectionIteratoranon hasNextIteratorscala at scalacollectionIteratorclassforeachIteratorscala at scalacollectionAbstractIteratorforeachIteratorscala at scalacollectiongenericGrowableclasspluspluseqGrowablescala at scalacollectionmutableListBufferpluspluseqListBufferscala at scalacollectionmutableListBufferpluspluseqListBufferscala at scalacollectionTraversableOnceclasstoTraversableOncescala at scalacollectionAbstractIteratortoIteratorscala at scalacollectionTraversableOnceclasstoListTraversableOncescala at scalacollectionAbstractIteratortoListIteratorscala at aucsirovariantsparkalgoRandomForestbatchTrainRandomForestscala at aucsirovariantsparkapiImportanceAnalysisrfModellzycomputeImportanceAnalysisscala at aucsirovariantsparkapiImportanceAnalysisrfModelImportanceAnalysisscala at aucsirovariantsparkapiImportanceAnalysisinitImportanceAnalysisscala at aucsirovariantsparkapiImportanceAnalysisfromParamsImportanceAnalysisscala at aucsirovariantsparkhailmethodsRfImportanceAnalysisapplyRfImportanceAnalysisscala at aucsirovariantsparkhailVSHailFunctionsimportanceAnalysisextensionVSHailFunctionsscala at aucsirovariantsparkhailVSHailFunctionsimportanceAnalysisVSHailFunctionsscala at sunreflectNativeMethodAccessorImplinvoke Native Method at sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava at sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava at javalangreflectMethodinvokeMethodjava at py jreflectionMethodInvokerinvokeMethodInvokerjava at py jreflectionReflectionEngineinvokeReflectionEnginejava at py jGatewayinvokeGatewayjava at py jcommandsAbstractCommandinvokeMethodAbstractCommandjava at py jcommandsCallCommandexecuteCallCommandjava at py jGatewayConnectionrunGatewayConnectionjava at javalangThreadrunThreadjava Caused by javaioIOException Connection reset by peer at sunniochFileDispatcherImplread Native Method at sunniochSocketDispatcherreadSocketDispatcherjava at sunniochIOUtilreadIntoNativeBufferIOUtiljava at sunniochIOUtilreadIOUtiljava at sunniochSocketChannelImplreadSocketChannelImpljava at ionettybufferPooledUnsafeDirectByteBufsetBytesPooledUnsafeDirectByteBufjava at ionettybufferAbstractByteBufwriteBytesAbstractByteBufjava at ionettychannelsocketnioNioSocketChanneldoReadBytesNioSocketChanneljava at ionettychannelnioAbstractNioByteChannelNioByteUnsafereadAbstractNioByteChanneljava at ionettychannelnioNioEventLoopprocessSelectedKeyNioEventLoopjava at ionettychannelnioNioEventLoopprocessSelectedKeysOptimizedNioEventLoopjava at ionettychannelnioNioEventLoopprocessSelectedKeysNioEventLoopjava at ionettychannelnioNioEventLooprunNioEventLoopjava at ionettyutilconcurrentSingleThreadEventExecutor runSingleThreadEventExecutorjava at ionettyutilconcurrentDefaultThreadFactoryDefaultRunnableDecoratorrunDefaultThreadFactoryjava more When using VariantSpark interface for Hail to run important analysis VariantSpark expect to have exactly one allele in REF and ALT field If there was any issue some dataset have in the ALT field the process fails but it does not report which variant causing the error So it is difficult for user to Understand and fix the problem I suggest to report the offending line when loading data fails to complete 