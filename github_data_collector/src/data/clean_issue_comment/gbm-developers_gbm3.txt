Hi Just been trying this package as gbm lacks support for tweedie distribution Have been suffering a lack of predictive power for the distributions gamma tweedie and gaussian I cant share the data but ive gone from a gini of on gbm using a lognormal distribution to negative for the three listed above using gbm Its the same dataset and the code has been modified to have the same parameters any ideas what could be driving this thanks Felix As described in official documentation at the part of basehazgbm Arguments cumulative If TRUE the cumulative survival function will be computed Details The proportional hazard model assumes htxlambdatexpfx gbm can estimate the fx component via partial likelihood After estimating fx basehazgbm can compute the a nonparametric estimate Is the cumulative survival function will be computed correct Is there terminology error Since the concept of cumulative survival function and cumulative hazard function is different I read the code implemented in gbmbaselinehazardr and run an example for this function with setting tevalc but I got three values in ascending order which is not consistent to the properties of survival function so I opened this issue and same doubts has also been proposed at stackoverflow If this issue is actually existing I think it would be a wrong guide to someone like me who read the documentation and the correct version should be cumulative If TRUE the cumulative baseline hazard function will be computed thx This is not possible in the old gbm but I recently wrote a function to calculate it It can yield very different results for the most important variables for different classes See this question and my answer for the code Hopefully you would just need to translate this from my dplyrpurrr version to base to implement it If it doesnt make sense to do this this way please let me know Hi team quick question Is the GBMFit object supported by pmml Couldnt find any topic on the internet on this Posted this question in SO as well Thanks Recent advances in interpretability have produced SHAP values for assigning score contributions to features in a consistent manner Calculating perfeature score contributions was added to XGBoost and LightGBM It would be great to have it in gbm as well I tried to switch from gbm to gbm for quantile regression but I saw some wrong quantile prediction results from gbm See the example below using the attached toy data Xzip R librarydatatable gettree functiong t if classg gbm gbmprettygbmtreeg else gbm prettygbmtreeg tNode asintegerrownamest mis tMissingNode t t mis tMissingNode NULL tRealPrediction tPrediction ginitF t X readRDSXrds strX params listy dataX distribution listnamequantile alpha ntrees interactiondepth nminobsinnode shrinkage bagfraction g docallgbmgbm params g docallgbm gbm params gettreeg gettreeg overall quantile quantileXy type true quantiles inside the splits X quantiley type s a s a b Check the empirical CDFs in the th node for g and g X a b ecdfyc The output of it is gettreeg SplitVar SplitCodePred LeftNode RightNode ErrorReduction Weight Prediction Node RealPrediction gettreeg SplitVar SplitCodePred LeftNode RightNode ErrorReduction Weight Prediction Node RealPrediction overall quantile quantileXy type true quantiles inside the splits X quantiley type s a s a b s s V FALSE FALSE FALSE TRUE TRUE FALSE Check the empirical CDFs in the th node for g and g X a b ecdfyc While the true quantiles inside the splits match the leaves from g spot on the node leaf in g is wrong and it corresponds to a empirical quantile Referencing issue This PR allows the user to predict a sparse matrix representing all of the nodes an observation passes through throughout the entire ensemble Add option when predicting a GBM model to output a sparse matrix of decision tree rules Essentially output nTrees x nInternal nTerminal nodes matrix of s and s where s indicate the current record passed through that node This would allow users to apply LASSO regression to the sparse node matrix and create simple weighted rules ensembles as described here Can attempt this myself but wondering if gbmpred is the function to use I wonder if anybody can point out how ErrorReduction is calculated in prettygbmtreer I am trying to calculate it by hand and I cannot find a piece of code which would calculates it for gbm object Thanks No way I can share the data so not necessarily reproducible Data is k x k binomial response fold CV Gets to end then reports Error in dataframedata flag modelvariablesvarnames drop FALSE undefined columns selected The columns have had makenames run on them so its not weird colnames Also its sucked up all my RAM and isnt letting go killing the RStudio session did cause it to let go gbm R Ubuntu 