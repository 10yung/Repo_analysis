I used the complete example not from GitHub but from It doesnt work in recent Keras and only makes confusion better fix it or remove the website Hi first of all thank you for your work Im trying to use your framework to optimize hiperparameters in my Convolutional Neural Network in order to implement an image classifier Im obtaining the following error ValueError Error when checking input expected conv d input to have shape but got array with shape I have checked my data construction function and the training data returned have the right shape but for some reason the model receive an input with shape I really dont know what to do here is my code def dataAdv dfAll pdreadcsvfilePath labels pdreadcsvfilePath df pdreadcsvfilePath this function returns a list of all the images imageList createImageListdf dfAll imageTmp imageList this function is used to get the list of labels labelslist clearAdvancingLabellabels labelTmp labelslist this function divide the data into train validation and test set xtrain ytrain xvalid yvalid xtest ytest splitTrainValidationTestimageTmp labelTmp ytrain ytrainravel yvalid yvalidravel ytest ytestravel return xtrain ytrain xtest ytest xvalid yvalid def createmodelAdvancingxtrain ytrain xtest ytest xvalid yvalid model Sequential modeladdConv Dchoice inputshape modeladdActivationchoice relu tanh modeladdMaxPooling Dpoolsize numlayers choice one two three four if numlayers two modeladdConv Dchoice modeladdActivationchoice relu tanh modeladdMaxPooling Dpoolsize elif numlayers three modeladdConv Dchoice modeladdActivationchoice relu tanh modeladdMaxPooling Dpoolsize modeladdConv Dchoice modeladdActivationchoice relu tanh modeladdMaxPooling Dpoolsize elif numlayers four modeladdConv Dchoice modeladdActivationchoice relu tanh modeladdMaxPooling Dpoolsize modeladdConv Dchoice modeladdActivationchoice relu tanh modeladdMaxPooling Dpoolsize modeladdConv Dchoice modeladdActivationchoice relu tanh modeladdMaxPooling Dpoolsize modeladdFlatten modeladdDensechoice modeladdActivationchoice relu tanh modeladdDropoutuniform modeladdDense modeladdActivationchoice softmax sigmoid chooseOptimizer choice adam sgd rmsprop modelcompilelossbinarycrossentropy optimizerchooseOptimizer metrics accuracy modelfitxtrain ytrain batchsizechoice epochschoice verbose validationdataxvalid yvalid score acc modelevaluatextest ytest verbose printTest accuracy acc return loss acc status STATUSOK model modeltoyaml Create Spark context conf SparkConfsetAppNameElephasHyperparameterOptimizationsetMasterlocal sc SparkContextconfconf Define hyperparameter model and run optimization hyperparammodel HyperParamModelsc hyperparammodelminimizemodelcreatemodelAdvancing datadataAdv maxevals Thank you in advance for your help First of all thank you very much for your work Im trying to use your framework to optimize hiperparameters in my LSTM network in order to implement a sentiment analysis classifier I used some snippet you posted but I cannot make it work I think the main issue is how to calculate embeddingmatrix Im using word embedings to train the network I trained separately tokenize to get weights file Im getting the following error Hyperas search space def getspace return Dropout hpuniformDropout optimizer hpchoiceoptimizer rmsprop adam sgd Traceback most recent call last File optimkeraspy line in module bestrun optimminimizemodelkerasmodeldatagetdataalgotpesuggestmaxevals trialsTrials File usrbinanaconda libpython sitepackageshyperasoptimpy line in minimize keeptempkeeptemp File usrbinanaconda libpython sitepackageshyperasoptimpy line in baseminimizer modelstr gethyperoptmodelstringmodel data functions notebookname verbose stack File usrbinanaconda libpython sitepackageshyperasoptimpy line in gethyperoptmodelstring datastring retrievedatastringdata verbose File usrbinanaconda libpython sitepackageshyperasoptimpy line in retrievedatastring datastring inspectgetsourcedata File usrbinanaconda libpython inspectpy line in getsource lines lnum getsourcelinesobject File usrbinanaconda libpython inspectpy line in getsourcelines lines lnum findsourceobject File usrbinanaconda libpython inspectpy line in findsource file getsourcefileobject File usrbinanaconda libpython inspectpy line in getsourcefile filename getfileobject File usrbinanaconda libpython inspectpy line in getfile typeobjectname TypeError module class method function traceback frame or code object was expected got tuple Thank you in advance for your help Heres my code from hyperopt import Trials STATUSOK tpe from hyperas import optim from hyperasdistributions import choice uniform def getdata import pickle from keraspreprocessing import sequence from kerasmodels import Sequential from keraslayerscore import Dense Dropout Activation from keraslayersembeddings import Embedding from keraslayersrecurrent import LSTM from kerasdatasets import imdb from kerascallbacks import EarlyStopping ModelCheckpoint from keraspreprocessingsequence import padsequences from kerasutils import tocategorical from sklearnmodelselection import traintestsplit StratifiedShuffleSplit import classesfiltros as NT import classesdataprocessing as DP import classesembeddings as EB import classesmodel as M import classestoken as T import classesparameters as Params import pandas as pd import numpy as np import sys import time Carga de datos printLoading data instanciamos objetos necesarios textarray NTNormalizeText dataprocessing DPDataProcessing wordembedding EBProcessEmbeddings w v wordembeddinggetword vecParamsW VFILE dataset dataprocessingloaddata Separacion de los valores para tener un training set equilibrado neutros row for row in dataset if row positiv row for row in dataset if row negativ row for row in dataset if row dfneutros pdDataFramefromrecordsneutros dfpositiv pdDataFramefromrecordspositiv dfnegativ pdDataFramefromrecordsnegativ minimo npmin lendfneutroslendfpositivlendfnegativ dffinal pdconcat dfneutros minimo dfpositiv minimo dfnegativ minimo ignoreindexTrue Cargamos el tokenizer aprendido tokenpath modelsTokenizerpkl tm TTokenizerModel with opentokenpath rb as f tmt pickleloadf Procesado del texto y generaci n del token list filtered pdDataFramecolumns textos for row in dffinalitertuples textofilt wordembeddingcleantextrow filteredloc rowIndex textofilt encodeddocs tmttextstosequencesfiltered textos Codificamos los Documentos de entrada X padsequencesencodeddocs maxlenParamsMAXSEQUENCELENGTH paddingpost y dffinal Separamos en train y test sss StratifiedShuffleSplitnsplits testsize for trainindex testindex in ssssplitX y Xtrain Xtest X trainindex X testindex Ytrain Ytest y trainindex y testindex Debemos cambiar a categorical las etiquetas dada la funci n de p rdida que usamos en el entrenamiento ytrainbin tocategoricalYtrain numclasses dtypeint ytestbin tocategoricalYtest numclasses dtypeint return XtrainytrainbinXtestytestbin def kerasmodelXtrainytrainbinXtestytestbin import pickle Definici n del modelo y entrenamiento wordembedding EBProcessEmbeddings w v wordembeddinggetword vecParamsW VFILE textarray NTNormalizeText Cargamos el tokenizer aprendido tokenpath modelsTokenizerpkl tm TTokenizerModel with opentokenpath rb as f tmt pickleloadf Generaci n de la embedding matrix vocabsize t w v textarray embeddingmatrix wordembeddingGenerateMatrixParamsMAXNBWORDS tmt w vtextarray printBuild model Modelo LSTM model Sequential modeladdEmbeddingParamsMAXNBWORDS outputdimParamsEMBEDDINGDIM inputlengthParamsMAXSEQUENCELENGTH weights embeddingmatrix trainableFalse modeladdBidirectionalLSTMParamsLSTMUNITS ST returnsequencesFalse modeladdDropoutuniform modeladdDense activationsoftmax modelcompileoptimizerchoice rmsprop adam sgd losscategoricalcrossentropy metrics categoricalaccuracy modeltrainXtrain ytrainbin Xtest ytestbin earlystopping EarlyStoppingmonitorvalloss patience checkpointer ModelCheckpointfilepathkerasweightshdf verbose savebestonlyTrue hist modelfitXtrain ytrainbin nbepoch validationsplit showaccuracyTrue callbacks earlystopping checkpointer score acc modelevaluateXtest ytestbin showaccuracyTrue verbose printTest accuracy acc return loss acc status STATUSOK if name main bestrun optimminimizemodelkerasmodeldatagetdataalgotpesuggestmaxevals trialsTrials printbestrun Is it possible in a multiple GPU scenario to have each available GPU doing a separate trial So far it seems that using multigpumodel is not accelerating our computer vision deep learning model Unet Mask RCNN so having each trial running on a separate GPU could provide us with great speedups but Ive found no information on the matter Thank you Before filing an issue please make sure to tick the following boxes x Make sure your issue hasnt been filed already Use GitHub search or manually check the existing issues also the closed ones Also make sure to check the FAQ section of our readme x Install latest hyperas from GitHub pip install gitgitgithubcommaxpumperlahyperasgit x Install latest hyperopt from GitHub pip install gitgitgithubcomhyperopthyperoptgit x We have continuous integration running with Travis and make sure the build stays green If after installing test utilities with pip install pytest pytestcov pep pytestpep you cant successfully run python m pytest theres very likely a problem on your side that should be addressed before creating an issue x Create a gist containing your complete script or a minimal version of it that can be used to reproduce your issue Also add your full stack trace to that gist In many cases your error message is enough to at least give some guidance According to issue the number of layers could be tuned by a forloop model numlayers result of randint for in rangenumlayers modeladdDensechoice nppower nppower nppower modeladdActivationchoice tanhrelu sigmoid modeladdDropoutuniform But the layers added in the forloop are missing when you look in the space object This is because hyperparameternamesmodelstring is not able to find the string parts in modestring Aim is to optimize hyperparameters for a Keras LSTM via Hyperas While implying the structure of the example like this def LSTMHyperasData Xtrainaugment pdreadexcelEscapeKanjiXxlsx ytrainaugment pdreadexcelEscapeKanjiyxlsx Xtrainaugment XtrainaugmentdropcolumnsDel ytrainaugment ytrainaugmentdropcolumnsDel Augmentor TrainNum XtrainaugmentRnparrayXtrainaugmentreshapeAugmentor TrainNum ytrainaugmentRnparrayytrainaugmentreshapeAugmentor TrainNum XtrainHyperas XtestHyperas ytrainHyperas ytestHyperas traintestsplitXtrainaugmentR ytrainaugmentR testsize randomstate xtrain ytrain xtest ytestXtrainHyperas ytrainHyperasXtestHyperas ytestHyperas return xtrain ytrain xtest ytest def createLSTMModelxtrain ytrain xtest ytestlearningratechoice activationchoice relu linearsigmoidhardsigmoid tanh losschoice logcosh mae mse hingesquaredhinge njobs XtrainRGridXtrainsmallLSTMreshape TrainNum ytrainRGridytrainsmallLSTMreshape TrainNum Kclearsession model Sequential modeladdReshape TrainNum inputshape TrainNum modeladdBidirectionalLSTM returnsequencesTrueactivationreluinputshapeTrainNum modeladdDropoutuniform modeladdBidirectionalLSTM returnsequencesTrueactivationrelu modeladdDropoutuniform modeladdBidirectionalLSTM returnsequencesTrue activationrelu modeladdDropoutuniform modeladdFlatten modeladdDense modelcompileoptimizerNadamlosslogcosh modelfitxtrain ytrain batchsizechoice epochs showaccuracyTrue verbose validationsplit validationacc npamaxresulthistory mse printBest validation acc of epoch validationacc return loss mse status STATUSOK model model if name main bestrun bestmodel optimminimizemodelcreateLSTMModel dataLSTMHyperasData algotpesuggest maxevals trialsTrials notebooknameEscapeKanji encodingutf xtrain ytrain xtest ytest LSTMHyperasData printEvalutation of best performing model printbestmodelevaluatextest ytest printBest performing model chosen hyperparameters printbestrun Number of hyperparameters to optimize is reduced to BatchSize only to reduce possible error sources as following error persists Imports codingutf from future import printfunction try import tensorflow as tf except pass try import numpy as np except pass try import seaborn as sns except pass try import scipyio as sio except pass try import joblib except pass try import pandas as pd except pass try import matplotlibpyplot as plt except pass try import pyexcel as pe except pass try from hyperopt import Trials STATUSOK tpe except pass try from hyperas import optim except pass try from hyperasdistributions import choice uniform except pass try import sys except pass try import os except pass try import transforms d as TF d except pass try import statsmodels except pass try import random except pass try import bezier except pass try from imblearnoversampling import SMOTE except pass try from operator import itemgetter except pass try from statsmodels import robust except pass try from openpyxl import Workbook except pass try from ospath import dirname join except pass try from pylab import rcParams except pass try from time import time except pass try from numba import cuda except pass try import plotlyexpress as px except pass try import holoviews as hv except pass try import bokehio except pass try import bokehmodels except pass try import bokehpalettes except pass try import bokehplotting except pass try from ipywidgets import interact except pass try from math import sqrt except pass try from bokehpalettes import Spectral Spectral except pass try from bokehio import outputfile show pushnotebook curdoc except pass try from bokehplotting import figure outputfile show except pass try from bokehmodels import ColumnDataSource HoverTool LinearColorMapper ColorBar except pass try from bokehtransform import transform except pass try from bokehlayouts import widgetbox except pass try from bokehmodelswidgets import Dropdown CheckboxGroup Select Slider TextInput except pass try from sklearn import preprocessing except pass try from sklearnensemble import BaggingRegressor except pass try from sklearn import modelselection except pass try from sklearnpreprocessing import StandardScaler MinMaxScaler Normalizer except pass try from sklearnsvm import SVR except pass try from sklearnlinearmodel import LinearRegression except pass try from sklearnmodelselection import traintestsplit except pass try from sklearnmetrics import meansquarederror r score explainedvariancescore except pass try from sklearnmodelselection import crossvalscore crossvalpredict crossvalidate GridSearchCV RandomizedSearchCV except pass try from sklearnneuralnetwork import MLPRegressor except pass try from keraswrappersscikitlearn import KerasClassifier KerasRegressor except pass try from keraslayers import Dense Activation Conv D MaxPooling D Flatten Dropout LSTM Bidirectional Reshape except pass try from kerasmodels import Model Sequential except pass try from keraslayers import BatchNormalization except pass try from kerasoptimizers import Adam RMSprop SGD Nadam except pass try from kerasregularizers import l except pass try from kerascallbacks import EarlyStopping ModelCheckpoint TensorBoard except pass try from keras import backend as K except pass Hyperas search space def getspace return learningrate hpchoicelearningrate activation hpchoiceactivation relu linearsigmoidhardsigmoid tanh loss hpchoiceloss logcosh mae mse hingesquaredhinge Dropout hpuniformDropout Dropout hpuniformDropout Dropout hpuniformDropout batchsize hpchoicebatchsize Data Xtrainaugment pdreadexcelEscapeKanjiXxlsx ytrainaugment pdreadexcelEscapeKanjiyxlsx Xtrainaugment XtrainaugmentdropcolumnsDel ytrainaugment ytrainaugmentdropcolumnsDel Augmentor TrainNum XtrainaugmentRnparrayXtrainaugmentreshapeAugmentor TrainNum ytrainaugmentRnparrayytrainaugmentreshapeAugmentor TrainNum XtrainHyperas XtestHyperas ytrainHyperas ytestHyperas traintestsplitXtrainaugmentR ytrainaugmentR testsize randomstate xtrain ytrain xtest ytestXtrainHyperasastypefloat ytrainHyperasastypefloat XtestHyperasastypefloat ytestHyperasastypefloat Resulting replaced keras model def kerasfminfnctspace XtrainRGridXtrainsmallLSTMreshape TrainNum ytrainRGridytrainsmallLSTMreshape TrainNum Kclearsession model Sequential modeladdReshape TrainNum inputshape TrainNum modeladdBidirectionalLSTM returnsequencesTrueactivationreluinputshapeTrainNum modeladdDropoutspace learningrate modeladdBidirectionalLSTM returnsequencesTrueactivationrelu modeladdDropoutspace activation modeladdBidirectionalLSTM returnsequencesTrue activationrelu modeladdDropoutspace loss modeladdFlatten modeladdDense modelcompileoptimizerNadamlosslogcosh modelfitxtrain ytrain batchsizespace Dropout epochs showaccuracyTrue verbose validationsplit validationacc npamaxresulthistory mse printBest validation acc of epoch validationacc return loss mse status STATUSOK model model its best loss TypeError Traceback most recent call last ipythoninput c d b in module maxevals trialsTrials notebooknameEscapeKanji encodingutf xtrain ytrain xtest ytest LSTMHyperasData Anaconda envs Tensorflow lib sitepackages hyperas optimpy in minimizemodel data algo maxevals trials functions rseed notebookname verbose evalspace returnspace keeptemp notebooknamenotebookname verboseverbose keeptempkeeptemp bestmodel None Anaconda envs Tensorflow lib sitepackages hyperas optimpy in baseminimizermodel data functions algo maxevals trials rseed fullmodelstring notebookname verbose stack keeptemp trialstrials rstatenprandomRandomStaterseed returnargminTrue getspace Anaconda envs Tensorflow lib sitepackages hyperopt fminpy in fminfn space algo maxevals trials rstate allowtrialsfmin passexprmemoctrl catchevalexceptions verbose returnargmin pointstoevaluate maxqueuelen showprogressbar catchevalexceptionscatchevalexceptions returnargminreturnargmin showprogressbarshowprogressbar Anaconda envs Tensorflow lib sitepackages hyperopt basepy in fminself fn space algo maxevals rstate verbose passexprmemoctrl catchevalexceptions returnargmin showprogressbar catchevalexceptionscatchevalexceptions returnargminreturnargmin showprogressbarshowprogressbar Anaconda envs Tensorflow lib sitepackages hyperopt fminpy in fminfn space algo maxevals trials rstate allowtrialsfmin passexprmemoctrl catchevalexceptions verbose returnargmin pointstoevaluate maxqueuelen showprogressbar showprogressbarshowprogressbar rvalcatchevalexceptions catchevalexceptions rvalexhaust if returnargmin return trialsargmin Anaconda envs Tensorflow lib sitepackages hyperopt fminpy in exhaustself def exhaustself ndone lenselftrials selfrunselfmaxevals ndone blockuntildoneselfasynchronous selftrialsrefresh return self Anaconda envs Tensorflow lib sitepackages hyperopt fminpy in runself N blockuntildone else loop over trials and do the jobs directly selfserialevaluate try Anaconda envs Tensorflow lib sitepackages hyperopt fminpy in serialevaluateself N ctrl baseCtrlselftrials currenttrialtrial try result selfdomainevaluatespec ctrl except Exception as e loggerinfojob exception s stre Anaconda envs Tensorflow lib sitepackages hyperopt basepy in evaluateself config ctrl attachattachments memomemo printnodeonerrorselfrecevalprintnodeonerror rval selffnpyllrval if isinstancerval float int npnumber tempmodelpy in kerasfminfnctspace Anaconda envs Tensorflow lib sitepackages keras legacy interfacespy in wrapperargs kwargs warningswarnUpdate your objectname call to the Keras API signature stacklevel return funcargs kwargs wrapperoriginalfunction func return wrapper Anaconda envs Tensorflow lib sitepackages keras layers corepy in initself rate noiseshape seed kwargs def initself rate noiseshapeNone seedNone kwargs superDropout selfinitkwargs selfrate min max rate selfnoiseshape noiseshape selfseed seed TypeError not supported between instances of str and float Is there any known fix to that Much THX in advance Best regards Tobias First Lots of thanks for the amazing Hyperas work you already did Here the issue Aim is to optimize hyperparameters for a Keras LSTM via Hyperas While implying the structure of the example like this def LSTMHyperasData XtrainHyperas XtestHyperas ytrainHyperas ytestHyperas traintestsplitXtrainaugmentR ytrainaugmentR testsize randomstate return XtrainHyperas XtestHyperas ytrainHyperas ytestHyperas def createLSTMModellearningratechoice activationchoice relu linearsigmoidhardsigmoid tanh losschoice logcosh mae mse hingesquaredhinge njobs XtrainRGridXtrainsmallLSTMreshape TrainNum ytrainRGridytrainsmallLSTMreshape TrainNum actviationchoice relu linearsigmoidhardsigmoid tanh Kclearsession model Sequential modeladdReshape TrainNum inputshape TrainNum modeladdBidirectionalLSTM returnsequencesTrueactivationactivationinputshapeTrainNum modeladdDropoutuniform modeladdBidirectionalLSTM returnsequencesTrueactivationactivation modeladdDropoutuniform modeladdBidirectionalLSTM returnsequencesTrue activationactivation modeladdDropoutuniform modeladdFlatten modeladdDense modelcompileoptimizerchoice Nadam Adam RMSProp losschoice logcosh mae mse hingesquaredhinge modelfitXtrainHyperas ytrainHyperas batchsizechoice epochschoice showaccuracyTrue verbose validationsplit validationacc npamaxresulthistory valacc printBest validation acc of epoch validationacc return loss validationacc status STATUSOK model model if name main bestrun bestmodel optimminimizemodelcreateLSTMModel dataLSTMHyperasData algotpesuggest maxevals trialsTrials notebooknameNihondam XtrainHyperas XtestHyperas ytrainHyperas ytestHyperas data printEvalutation of best performing model printbestmodelevaluateXtestHyperas ytestHyperas printBest performing model chosen hyperparameters printbestrun the following error call was produced UnicodeDecodeError Traceback most recent call last ipythoninput f d a c in module maxevals trialsTrials notebooknameNihondam XtrainHyperas XtestHyperas ytrainHyperas ytestHyperas data printEvalutation of best performing model Anaconda envs Tensorflow lib sitepackages hyperas optimpy in minimizemodel data algo maxevals trials functions rseed notebookname verbose evalspace returnspace keeptemp notebooknamenotebookname verboseverbose keeptempkeeptemp bestmodel None Anaconda envs Tensorflow lib sitepackages hyperas optimpy in baseminimizermodel data functions algo maxevals trials rseed fullmodelstring notebookname verbose stack keeptemp modelstr fullmodelstring else modelstr gethyperoptmodelstringmodel data functions notebookname verbose stack tempfile tempmodelpy writetempfilesmodelstr tempfile Anaconda envs Tensorflow lib sitepackages hyperas optimpy in gethyperoptmodelstringmodel data functions notebookname verbose stack notebookpath osgetcwd ipynbformatnotebookname with opennotebookpath r as f notebook nbformatreadsfread nbformatNOCONVERT exporter PythonExporter source exporterfromnotebooknodenotebook Anaconda envs Tensorflow lib encodings cp py in decodeself input final class IncrementalDecodercodecsIncrementalDecoder def decodeself input finalFalse return codecscharmapdecodeinputselferrorsdecodingtable class StreamWriterCodeccodecsStreamWriter UnicodeDecodeError charmap codec cant decode byte x f in position character maps to undefined Is this a known issue Its struggling with the Notebook name chars it appears Hope this is indeed an issue for you and no waste of time Best regards Tobias two workstations both Windows jupyter notebookpython run the same code one is normal the other one is getting below error on executing the code Traceback most recent call last File C ProgramData Anaconda envs tensorflow lib sitepackages IPython core interactiveshellpy line in runcode execcodeobj selfuserglobalns selfuserns File ipythoninput f deadceafa line in module notebooknamemyillusiondeepnet File C ProgramData Anaconda envs tensorflow lib sitepackages hyperas optimpy line in minimize keeptempkeeptemp File C ProgramData Anaconda envs tensorflow lib sitepackages hyperas optimpy line in baseminimizer modelstr gethyperoptmodelstringmodel data functions notebookname verbose stack File C ProgramData Anaconda envs tensorflow lib sitepackages hyperas optimpy line in gethyperoptmodelstring imports extractimportscleanedsource verbose File C ProgramData Anaconda envs tensorflow lib sitepackages hyperas utilspy line in extractimports tree astparsesource File C ProgramData Anaconda envs tensorflow lib astpy line in parse return compilesource filename mode PyCFONLYAST File unknown line if name mainin SyntaxError invalid syntax Before filing an issue please make sure to tick the following boxes Make sure your issue hasnt been filed already Use GitHub search or manually check the existing issues also the closed ones Also make sure to check the FAQ section of our readme Install latest hyperas from GitHub pip install gitgitgithubcommaxpumperlahyperasgit Install latest hyperopt from GitHub pip install gitgitgithubcomhyperopthyperoptgit We have continuous integration running with Travis and make sure the build stays green If after installing test utilities with pip install pytest pytestcov pep pytestpep you cant successfully run python m pytest theres very likely a problem on your side that should be addressed before creating an issue Create a gist containing your complete script or a minimal version of it that can be used to reproduce your issue Also add your full stack trace to that gist In many cases your error message is enough to at least give some guidance 