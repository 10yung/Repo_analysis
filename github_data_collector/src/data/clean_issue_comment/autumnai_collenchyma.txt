Specifically autumnaicom redirects to some random ad or other dubious sites Not at all necessary but itd help me and hopefully other people avoid feeling like an idiot I am getting the following error when I try to build collenchyma on Windows C Users Maplicant cargo registry src githubcom ecc db ec collenchyma src tensorrs error nonexhaustive patterns type deviceDeviceType is nonempty E C Users Maplicant cargo registry src githubcom ecc db ec collenchyma src tensorrs match destination C Users Maplicant cargo registry src githubcom ecc db ec collenchyma src tensorrs help run rustc explain E to see a detailed explanation C Users Maplicant cargo registry src githubcom ecc db ec collenchyma src tensorrs help Please ensure that all possible cases are being handled possibly adding wildcards or more match arms C Users Maplicant cargo registry src githubcom ecc db ec collenchyma src tensorrs match destination error aborting due to previous error Im guessing this has to do with the match statement at tensorrs not having a default case but Im not sure Ive implemented feature related to decoupling from Main commit can be viewed here Below is commit message for convenience Change SharedTensorread signature from fn read self device DeviceType Result MemoryType into fn readD IDevice self device D Result DM New signature provides typelevel guarantee that if a Cuda device is passed into read then itll return Cuda memory and not Native or OpenCL Previously required additional unwraps asnativeunwrap are no longer required code is more clear and concise Internally SharedTensor uses Any type to store objects of different types uniformely Synchronization between memories is also done through typeerased interface This makes it possible to define a new Framework in an external crate or extract Cuda and OpenCL frameworks into their own crates Though error types would require some additional work Use of dynamic typing has drawbacks mainly slightly larger runtime overhead Before this patch benchmarks showed that SharedTensorread takes ns now it takes ns For comparison minimal synchronized CUDA operation will take about us Small NN layers on CPU are much faster eg input softmax layer takes about ns Still in typical NNs overhead looks negligible and I think its fair tradeoff for code clarity and better decoupling Here are actual benches before test benchsharedtensoraccesstimefirst bench nsiter test benchsharedtensoraccesstimesecond bench nsiter after test benchsharedtensoraccesstimefirst bench nsiter test benchsharedtensoraccesstimesecond bench nsiter Whats your opinion on it Ive implemented memory access API and syncronization based on bitmasks TesnsorTensorView and decoupling arent implemented Native and CUDA pass all tests OpenCL compiles but segfaults on my machine both with this PR and without it PR isnt ready to be merged yet Id like to fix plugins and Leaf first to see that there are no unexpected problems With Cuda i get this error ollenchymacargo test Running target debug backendspecs e dbe e aexe running tests test backendspecnativeitcanuseibackendtraitobject ok test backendspecnativeitcancreatedefaultbackend ok after that backendspecsrandumnumberexe stopped working GDB OUTPUT running tests New Thread x New Thread x c New Thread x c New Thread x c New Thread x d New Thread x ec New Thread x e New Thread x a New Thread xe c Program received signal SIGSEGV Segmentation fault Switching to Thread x e x b in cuInit stackframe x b in cuInit x ec in collenchymaframeworkscudaapidriverutilsAPIffiinit at src frameworks cuda api driverutilsrs x fcb in collenchymaframeworkscudaapidriverutilsAPIinit at src frameworks cuda api driverutilsrs x bfd in collenchymaframeworkscudaCudaIFrameworknew at src frameworks cudamodrs x dfe in backendspecsbackendIBackenddefaultcobackendBackendcoframeworkscudaCuda at srcbackendrs x cf in backendspecsbackendspeccudaitcancreatedefaultbackend at testsbackendspecsrs x e in boxedFFnBoxLTAGTcallboxh x c in syscommonunwindtrytryfnh x c b in syscommonunwindtryinnertryh ae bca caH s x cbfb in boxedFFnBoxLTAGTcallboxh x d e in systhreadThreadnewthreadstarth cb e bd c fLey x ffcfe in KERNEL BaseThreadInitThunk from C WINDOWS system kernel dll x ffd b c b in ntdllRtlUserThreadStart from C WINDOWS SYSTEM ntdlldll x in Backtrace stopped previous frame inner to this frame corrupt stack Ideally we could fill this table osx linux native x x cuda opencl It would be nice to have an API to fill SharedTensor with a constant value Currently closest thing is leafweightFillerTypeConstant value fill mut tensor There are two problems usability and performance On usability side this interface is available only from leaf crate from first glance looks like its have to do something with weights and is quite verbose On performance side its implemented by adding native device filling CPU mem and syncronizing with original device If original belongs to Cuda framework I think this operation can be done without allocating host memory filling it using CPU and doing a PCI transfer At least for SharedTensorf there is cuMemsetD I dont completely understand whole arhitecture but it seems that because the operation depends on backend it should be implemented as collenchyma plugin It looks like itd be too much to create separate repo for this so maybe it should be done inside collenchyma somewhere in srcplugins Well that said its not clear if its worth to do now In my opinion this mostly depends on how it affects performance And I havent seen any perf issues yet except one probably fixed in autumnaileaf Itd be good if collenchyma would link to CUDA libraries out of the box when using it as a feature To run the leafexamples on my machine I needed to provide my own buildrs to get the cuda lib dir added for link searching See this thread on rust users A CUDA cuMemAlloc returns an error when trying to allocate bytes We should wrap the CUDA driver call so that trying to allocate bytes returns a null pointer Before implementing that it should be checked if providing cuMemFree with a null pointer is valid The recommended workaround for now is allocating byte instead bytes 