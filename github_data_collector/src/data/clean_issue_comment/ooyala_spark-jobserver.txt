 Hi I have a running context for more than hrs with no running jobs When I try to start a new job SJS throws me the following response status NO SLOTS AVAILABLE result Too many running jobs for job context pipeline The limit for maxjobspercontext is set to default There are no threads running for the current context It will be really helpful if someone can guide me through this Thanks I am getting for following timeout message on invoking a job Any Help will be appreciated status ERROR result message Ask timed out on Actor akkaJobServerusercontextsupervisorxxxx after ms errorClass akkapatternAskTimeoutException stack akkapatternPromiseActorRefanonfun applymcVspAskSupportscala akkaactorScheduleranon runSchedulerscala scalaconcurrentFutureInternalCallbackExecutorscalaconcurrentFutureInternalCallbackExecutorunbatchedExecuteFuturescala scalaconcurrentFutureInternalCallbackExecutorexecuteFuturescala akkaactorLightArrayRevolverSchedulerTaskHolderexecuteTaskSchedulerscala akkaactorLightArrayRevolverScheduleranon executeBucket Schedulerscala akkaactorLightArrayRevolverScheduleranon nextTickSchedulerscala akkaactorLightArrayRevolverScheduleranon runSchedulerscala javalangThreadrunThreadjava I am using the velviasparkjobserver mesos spark and at the bottom I have added the jobserverconf Below is the stack strace ERROR jobserverJobManagerActor About to restart actor due to exception javautilconcurrentTimeoutException Futures timed out after seconds at scalaconcurrentimplPromiseDefaultPromisereadyPromisescala at scalaconcurrentimplPromiseDefaultPromiseresultPromisescala at scalaconcurrentAwaitanonfunresult applypackagescala at akkadispatchMonitorableThreadFactoryAkkaForkJoinWorkerThreadanon blockThreadPoolBuilderscala at scalaconcurrentforkjoinForkJoinPoolmanagedBlockForkJoinPooljava at akkadispatchMonitorableThreadFactoryAkkaForkJoinWorkerThreadblockOnThreadPoolBuilderscala at scalaconcurrentAwaitresultpackagescala at sparkjobserverJobManagerActoranonfunstartJobInternal applymcVspJobManagerActorscala at scalautilcontrolBreaksbreakableBreaksscala at sparkjobserverJobManagerActorstartJobInternalJobManagerActorscala at sparkjobserverJobManagerActoranonfunwrappedReceive applyOrElseJobManagerActorscala at scalaruntimeAbstractPartialFunctionmcVLspapplymcVLspAbstractPartialFunctionscala at scalaruntimeAbstractPartialFunctionmcVLspapplyAbstractPartialFunctionscala at scalaruntimeAbstractPartialFunctionmcVLspapplyAbstractPartialFunctionscala at ooyalacommonakkaActorStackanonfunreceive applyOrElseActorStackscala at scalaruntimeAbstractPartialFunctionmcVLspapplymcVLspAbstractPartialFunctionscala at scalaruntimeAbstractPartialFunctionmcVLspapplyAbstractPartialFunctionscala at scalaruntimeAbstractPartialFunctionmcVLspapplyAbstractPartialFunctionscala at ooyalacommonakkaSlf jLogginganonfunreceive anonfunapplyOrElse applymcVspSlf jLoggingscala at ooyalacommonakkaSlf jLoggingclassooyalacommonakkaSlf jLoggingwithAkkaSourceLoggingSlf jLoggingscala at ooyalacommonakkaSlf jLogginganonfunreceive applyOrElseSlf jLoggingscala at scalaruntimeAbstractPartialFunctionmcVLspapplymcVLspAbstractPartialFunctionscala at scalaruntimeAbstractPartialFunctionmcVLspapplyAbstractPartialFunctionscala at scalaruntimeAbstractPartialFunctionmcVLspapplyAbstractPartialFunctionscala at ooyalacommonakkaActorMetricsanonfunreceive applyOrElseActorMetricsscala at akkaactorActorclassaroundReceiveActorscala at ooyalacommonakkaInstrumentedActoraroundReceiveInstrumentedActorscala at akkaactorActorCellreceiveMessageActorCellscala at akkaactorActorCellinvokeActorCellscala at akkadispatchMailboxprocessMailboxMailboxscala at akkadispatchMailboxrunMailboxscala at akkadispatchForkJoinExecutorConfiguratorAkkaForkJoinTaskexecAbstractDispatcherscala at scalaconcurrentforkjoinForkJoinTaskdoExecForkJoinTaskjava at scalaconcurrentforkjoinForkJoinPoolWorkQueuerunTaskForkJoinPooljava at scalaconcurrentforkjoinForkJoinPoolrunWorkerForkJoinPooljava at scalaconcurrentforkjoinForkJoinWorkerThreadrunForkJoinWorkerThreadjava Jobserverconf Template for Spark Job Server Docker config You can easily override the spark master through SPARKMASTER env variable Spark Cluster Job Server configuration spark master local master SPARKMASTER Default of CPUs for jobs to use for Spark standalone cluster jobnumbercpus jobserver port jobdao sparkjobserverioJobSqlDAO contextperjvm true contextinittimeout s sqldao Directory where default H driver stores its data Only needed for H rootdir database Full JDBC URL init string Sorry needs to match above Substitutions may be used to launch jobserver but leave it out here in the default or tests wont pass jdbcurl jdbch filedatabaseh db predefined Spark contexts contexts mylowlatencycontext numcpucores Number of cores to allocate Required memorypernode m Executor memory per node Xmx style eg m G etc define additional contexts here universal context configuration These settings can be overridden see READMEmd contextsettings numcpucores Number of cores to allocate Required memorypernode m Executor memory per node Xmx style eg m G etc in case spark distribution should be accessed from HDFS as opposed to being installed on every mesos slave sparkexecutoruri hdfsnamenode appssparksparktgz uris of jars to be loaded into the classpath for this context Uris is a string list or a string separated by commas dependentjaruris filesomepathpresentineachmesosslavesomepackagejar If you wish to pass any settings directly to the sparkConf asis add them here in passthrough such as hadoop connection settings that dont use the spark prefix passthrough esnodes This needs to match SPARKHOME for cluster SparkContexts to be created successfully home usrlocalspark akka remotenettytcp This controls the maximum message size including job results that can be sent maximumframesize MiB spraycanserver uncomment the next line for making this an HTTPS example sslencryption on idletimeout s requesttimeout s pipelininglimit for maximum performance prevents StopReading ResumeReading messages to the IOBridge Needed for HTTP requests with missing Host headers defaulthostheader sprayio parsingmaxcontentlength m client The time period within which the TCP connecting process must be completed Set to infinite to disable connectingtimeout s I dont know where it come from because my cassandra is running in localhost and sparkjobserver too BTW If I cached a DataFrame in job call CachedJob when this job finished is cached still available for the others job use java result message comdatastaxdrivercoreexceptionsNoHostAvailableException All hosts tried for query failed tried comdatastaxdrivercoreexceptionsTransportException Cannot connect errorClass javalangRuntimeException stack comdatastaxdrivercoreControlConnectionreconnectInternalControlConnectionjava comdatastaxdrivercoreControlConnectionconnectControlConnectionjava comdatastaxdrivercoreClusterManagerinitClusterjava comdatastaxdrivercoreClustergetMetadataClusterjava Reference to undefined setting rootdocker from rootdocker JOBSERVERsparkjobserver projectBuildscala at sbtInitclassUninitializedSettingsscala at sbtDefUninitializedDefscala at sbtInitclassdelegateSettingsscala at sbtDefdelegateDefscala at sbtInitclasscompiledSettingsscala at sbtDefcompiledDefscala at sbtInitclassmakeSettingsscala at sbtDefmakeDefscala at sbtLoadapplyLoadscala at sbtLoaddefaultLoadLoadscala at sbtBuiltinCommandsdoLoadProjectMainscala at sbtBuiltinCommandsanonfunloadProjectImpl applyMainscala at sbtBuiltinCommandsanonfunloadProjectImpl applyMainscala at sbtCommandanonfunapplyEffect anonfunapply applyCommandscala at sbtCommandanonfunapplyEffect anonfunapply applyCommandscala at sbtCommandanonfunapplyEffect anonfunapply applyCommandscala at sbtCommandanonfunapplyEffect anonfunapply applyCommandscala at sbtCommandprocessCommandscala at sbtMainLoopanonfun anonfunapply applyMainLoopscala at sbtMainLoopanonfun anonfunapply applyMainLoopscala at sbtStateanon processStatescala at sbtMainLoopanonfun applyMainLoopscala at sbtMainLoopanonfun applyMainLoopscala at sbtErrorHandlingwideConvertErrorHandlingscala at sbtMainLoopnextMainLoopscala at sbtMainLooprunMainLoopscala at sbtMainLoopanonfunrunWithNewLog applyMainLoopscala at sbtMainLoopanonfunrunWithNewLog applyMainLoopscala at sbtUsingapplyUsingscala at sbtMainLooprunWithNewLogMainLoopscala at sbtMainLooprunAndClearLastMainLoopscala at sbtMainLooprunLoggedLoopMainLoopscala at sbtMainLooprunLoggedMainLoopscala at sbtStandardMainrunManagedMainscala at sbtxMainrunMainscala at xsbtbootLaunchanonfunrun applyLaunchscala at xsbtbootLaunchwithContextLoaderLaunchscala at xsbtbootLaunchrunLaunchscala at xsbtbootLaunchanonfunapply applyLaunchscala at xsbtbootLaunchlaunchLaunchscala at xsbtbootLaunchapplyLaunchscala at xsbtbootBootrunImplBootscala at xsbtbootBootmainBootscala at xsbtbootBootmainBootscala error Reference to undefined setting Hi I am not able to start spark job sever I am facing below error Please let me know how to resolve this issue I have configured one master and two workers in cluster mode serverstartsh serverstartsh line kill No such process serverstartsh line homespark binhadoop bincomputeclasspathsh No such file or directory Regards Rajesh Is their any configuration file where I can edit the limit UTF characters are being changed when the request gets to the CMI server When the string is received by the Akka Receiver inside JobActorManagerscala it is already changed Where is the Akka sender It seems there is a sender inside cmi that sends the string over It might be in WebApiscala and Im not sure how this piece can be built I can help fix this bug just need some help in how to get the whole thing built My list of jars is getting really large and it even stays there after restarting JobStatusActor already handles subscriptions from external actors Would be nice if we could publish statuses over WebSockets or JMS so that external apps can get push notifications rather than polling 