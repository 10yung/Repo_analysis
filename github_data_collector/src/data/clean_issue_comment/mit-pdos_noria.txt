Automatically merges adjacent filters and aggregations into a single operator when possible so that a single traversal of the data performs both functions Goes with the nomsql commit adding syntax for COUNTSUMCASE WHEN x THEN y ELSE z END Adds various tests for the operator and for the automatic merging Also refactors the way we store condition vectors and adds support for generating such a vector for the AND of two condition trees Setup I am trying to run a query that computes an average The graph and the operators are generated from a different language by a compiler but in SQL it would look something like this sql SELECT sumx count FROM Tab Error The query itself runs fine but I wanted to test how the performance would be if count and sumx were computed on different domains So I hacked into assignment to force these operators on their own domains When I do that however the join after the two calculations tries to access a non existent index in its right ancestor I expanded the error message see below which says that the right ancestor with id was short tries accessing index in the other slice which only has two elements in the generaterow function This is the error message for the two domains case in the case of four domains its the same but the id is different because more generated ingressegress operators right was short noriaserverdataflowsrcopsjoinrs Questions Is there something i am missing about domains Can I not just make any operator into its own domain Are there any invariants around what can go on a domain and what cant Runtime graphs Here are the dot graphs for two domains and four domains and for good measure the original working singe domain The relevant operators here are ohuageneratedopsacc count and ohuageneratedopsacc sumx and the join afterwards The rest is just generated code that does some column renaming How to reproduce I uploaded a branch joinafterdomainerrorreproduction to my fork that should contain the complete state of the system necessary including generated operators to reproduce the error In the udfbenchmarks directory run cargo run bin features avgsplitdomaintwodomainsftoml This will run the two domain scenario For one or four use the onedomaintoml and fourdomainstoml config respectively So I am trying to run this query follows at the end which I split into multiple subviews to circumvent some of the current quirks of the SQL noria supports Its rather long I apologize but because I dont really understand what the error is trying to tell me I am unable to reduce the example The actual failure occurs in noriaserversrccontrollermigratematerializationmodrs and reads Oct CRIT partially overlapping partial indices conflict cols Some Some child pcols parent The part of the query affected is the aggregation node produced by the count in pageviewcounts And here is the query graph as dumped by the system faildotpdf I previously had the error that it could not find a bogokey to aggregate the count over I then changed pageviewcounts to also SELECT ts which I believe is what it is now using for the count It may also be that the conflict is between the GROUP BY which is over userid ts and the actual key used for result lookups which is just userid Let me know if you have any idea how to fix this or what I could be using as a workaround sql CREATE TABLE clicks userid int pagetype int ts int Workaround because tables cant join on themselves clicks SELECT FROM clicks candidatepaths SELECT c userid c ts as ts c ts as ts FROM clicks c JOIN clicks c ON c userid c userid WHERE c pagetype AND c pagetype candidatepaths SELECT userid ts ts FROM candidatepaths WHERE ts ts ORDER BY userid ts ts matchingpaths SELECT userid maxts as ts ts FROM candidatepaths GROUP BY userid ts pageviewcounts SELECT cuserid ts ts ts FROM clicks c JOIN matchingpaths ON cuserid matchingpathsuserid pageviewcounts SELECT userid ts ts FROM pageviewcounts WHERE ts ts AND ts ts pageviewcounts SELECT userid count as pageviewcount FROM pageviewcounts GROUP BY userid ts VIEW clickstreamana SELECT userid sumpageviewcount FROM pageviewcounts WHERE userid In I have seen mention of user defined functions I think for Noria it probably makes sense that there are two kinds of them Some which are defined in terms of dataflow primitive operations I think existing internal views you can make are a case of that But probablymaybe having some slightly richer way to express those or just more basic operations would be useful An opaque imperative functions one could define from the app For those I would suggest that maybe Noria simply uses wasm as the language to define those Instead of getting into the hell of supporting a wide range of custom languages One would then have to define just what are some properties of this opaque function deterministic vs not for dataflow to be able to be computed correctly Am I missing something here Are there some fundamental issues with providing support for UDF What metadata about a function would Noria need Typing information for inputs and outputs I am moving this into a separate issue from a broad issue of mjjansen mentioned push notifications And jonhoo replied Push notifications basically pushing parts of the dataflow to the client is something thats definitely on our radar and was actually one of the motivations for using dataflow in the first place Dataflow is so amenable to distribution that in theory this should just be a matter of moving some of the dataflow nodes to a client machine In practice it gets a little more tricky though We dont have an implementation of it currently and its not at the top of our roadmap but it is a feature wed love to see I commented So for push notifications or I would say live query I think this is the more common term I do not think Noria has to provide any web API here just expose things through Rust API and then users can hook their own logic in Rust to push them to websockets or whatever And jonhoo replied So push notifications are tricky because they imply full materialization everywhere which comes at a steep cost There might be a good way to register interest in keys and then subscribe to updates for those keys but thats not something were actively working on Might be a neat additional feature to add eventually though it shouldnt be too hard as most of the infrastructure is already there I could not find documentation for which exactly SQL syntax is being usedsupported I would like to request some additional data types Timezone aware timestamps Binary blobs Compound data types allowing nested subobjects list of others objects or objects themselves This would allow Noria to work with more documentoriented data where fields have subdocuments or arrays of values or other subdocuments One could potentially represent this with highlynormalized tables but then it would still be useful for one to be able to create views where you could aggregate values into lists for example like PostgreSQL arrayagg function What I would like is that my apps state represented in materialized views contain such arrays I have found out that this is often much more efficient for many common cases like N relations In regular SQL many rows are duplicated N rows for each row which makes all those values duplicated both in memory an onwire between server and client Being able to represent that as an array is both more efficient and more natural Noria seems not to allow for a select query with two simultaneous aggregations I set up this very simple table CREATE TABLE tab x int y int PRIMARY KEYx And a query with two aggregations VIEW test SELECT county sumy FROM tab WHERE x GROUP BY x Which throws a cannot group by aggregation column in noriaserverdataflowsrcopsgroupedaggregaters By contrast if the select is only countx or sumx it works just fine I should also note that it also errors on count sumy My question would be whether this query is correct actually should work My guess is that it doesnt due to how the query graph is constructed One aggregate becomes the successor of the other and does not get the initial set of recordshas its automatic groupstate key include the computed column from the ancestor I learned about Noria from the TwoSigma talk and I find Noria extremely interesting and it can potentially for a great fit for my use case If I understand correctly the materialized view cache is eventually consistent with the new writes but not atomically ie the recalculation of the materialized view is being done async to the write operation with the machines best effort If this is the case may I ask if every transaction of write operation will trigger a recalc of the cache Or the recalc inside Noria actually has its own interval if there is how long to check if a recalc is required ie doing it in its own pace to avoid the backlog which can happen eg peaktime when the write operation is more frequent than the time it takes to do the recalc of the materialized view I understand from another GitHub issue that Noria at the moment is still a researchprototype and probably not as mature as MySQL etc for a general production use case but may I ask which subset of the systemfeature is actually mature enough to use with production data thank you very much Was looking at and am assuming its still current I am interested in contributing and was wondering if you had any progress on the roadmap since andor a contributions guide I was specifically thinking about the availability and faulttolerance considerations mentioned in the above issue Was there any dev work done on either that or that already covered this use case Please let me know if theres anything I can do