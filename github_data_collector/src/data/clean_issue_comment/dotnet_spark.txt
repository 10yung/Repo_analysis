Classes needed to complete the TFIDF example that completes part of Adds LoadSave to Bucketizer HashingTF IDF IDFModel Tokenizer Is there a community channel like slack or gitter where we can ask questions It would be useful to be able to ask questions when implementing changes and also it would probably stop some of the issues getting created and then left to hang around like I know the delta lake team have a public slack channel that works really well please dont say yammer Doc on how to add a new type to SerDe hope it helps someone else Describe the bug An error occurred while trying to enumerate a DataFrame containing a column of type date To Reproduce Steps to reproduce the behavior public void Test var dataFrame sparkSessionSqlSELECT FROM VALUES AS DateAsString dataFrame Show dataFrame PrintSchema var rows dataFrame CollectCount returns var dataFrame sparkSessionSqlSELECT FROM VALUES CAST AS date CAST AS date AS DateAsDate dataFrame Show dataFrame PrintSchema var rows dataFrame CollectCount failed with SystemNotImplementedException The method or operation is not implemented CommandLine output DateAsString root DateAsString string nullable false DateAsDate root DateAsDate date nullable true Exception SystemNotImplementedException The method or operation is not implemented at MicrosoftSparkSqlRowConvert at MicrosoftSparkSqlRowctorObject values StructType schema at MicrosoftSparkSqlRowConstructorGetRow at MicrosoftSparkSqlRowCollectorCollectISocketWrapper socketMoveNext at MicrosoftSparkSqlDataFrameGetRowsString funcNameMoveNext at SystemLinqEnumerableCount TSource IEnumerable source at MyTestTest in Expected behavior A DataFrame containing columns of type date can be enumerated Additional context Tested with a latest version of the net spark library This PR exposes the DataStreamWriterForeach API Users can use this API by creating a Serializable class that implements the following interface csharp public interface IForeachWriter bool Openlong partitionId long epochId void ProcessRow row void CloseException errorOrNull This userdefined class will be wrapped in a Wrapper that will call its respective methods according to the spark ForeachWriter lifecycle specifications The lifecycle of the methods are as follows For each partition with partitionId For each batchepoch of streaming dataif its streaming query with epochId Method OpenpartitionId epochId is called If Open returns true For each row in the partition and batchepoch method Processrow is called Method CloseerrorOrNull is called with errorif any seen while processing rows An example of a IForeachWriter can be something like the following csharp Serializable private class TestForeachWriter IForeachWriter ThreadStatic private static StreamWriter sstreamWriter private readonly string writePath public TestForeachWriterstring writePath writePath writePath public void CloseException errorOrNull sstreamWriterDispose public bool Openlong partitionId long epochId try sstreamWriter new StreamWriter PathCombine writePath sinkforeachWriterGuidNewGuidcsv return true catch return false public void ProcessRow value sstreamWriterWriteLinestringJoin valueValues Describe the bug A clear and concise description of what the bug is To Reproduce Prerequisites simple net application with a simple SQL query and a UDF which runs properly against a local apache spark Steps to reproduce the behavior Setup connection to a remote databricks apache spark I have tested against an Azure Databricks on your local dev machine using databricksconnect configure Test the connection using the databricksconnect test Test the net application without UDF first comment out UDF related line codes and make sure the simple query runs against configured remote Azure Databricks Uncomment UDF related line codes See error details summaryError copied from the command linesummary javascript T Z L Error JvmBridge JVM method execution failed Nonstatic method showString failed for class when called with arguments Index TypeInt Value Index TypeInt Value Index TypeBoolean ValueFalse T Z L Error JvmBridge orgapachesparkSparkException Job aborted due to stage failure Task in stage failed times most recent failure Lost task in stage TID executor orgapachesparkapipythonPythonException Traceback most recent call last File databrickssparkpythonpysparkworkerpy line in main dd sysversioninfo version Exception Python in worker has different version than that in driver PySpark cannot run with different minor versionsPlease check environment variables PYSPARKPYTHON and PYSPARKDRIVERPYTHON are correctly set at orgapachesparkapipythonBasePythonRunnerReaderIteratorhandlePythonExceptionPythonRunnerscala at orgapachesparksqlexecutionpythonPythonUDFRunneranon readPythonUDFRunnerscala at orgapachesparksqlexecutionpythonPythonUDFRunneranon readPythonUDFRunnerscala at orgapachesparkapipythonBasePythonRunnerReaderIteratorhasNextPythonRunnerscala at orgapachesparkInterruptibleIteratorhasNextInterruptibleIteratorscala at scalacollectionIteratoranon hasNextIteratorscala at scalacollectionIteratoranon hasNextIteratorscala at scalacollectionIteratoranon hasNextIteratorscala at orgapachesparksqlcatalystexpressionsGeneratedClassGeneratedIteratorForCodegenStage processNextUnknown Source at orgapachesparksqlexecutionBufferedRowIteratorhasNextBufferedRowIteratorjava at orgapachesparksqlexecutionWholeStageCodegenExecanonfun anon hasNextWholeStageCodegenExecscala at orgapachesparksqlexecutioncollectUnsafeRowBatchUtilsencodeUnsafeRowsUnsafeRowBatchUtilsscala at orgapachesparksqlexecutioncollectCollectoranonfun applyCollectorscala at orgapachesparksqlexecutioncollectCollectoranonfun applyCollectorscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskdoRunTaskTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunneranonfun applyExecutorscala at orgapachesparkutilUtilstryWithSafeFinallyUtilsscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Driver stacktrace at orgapachesparkschedulerDAGSchedulerorgapachesparkschedulerDAGSchedulerfailJobAndIndependentStagesDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunabortStage applyDAGSchedulerscala at scalacollectionmutableResizableArrayclassforeachResizableArrayscala at scalacollectionmutableArrayBufferforeachArrayBufferscala at orgapachesparkschedulerDAGSchedulerabortStageDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at orgapachesparkschedulerDAGScheduleranonfunhandleTaskSetFailed applyDAGSchedulerscala at scalaOptionforeachOptionscala at orgapachesparkschedulerDAGSchedulerhandleTaskSetFailedDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLoopdoOnReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkschedulerDAGSchedulerEventProcessLooponReceiveDAGSchedulerscala at orgapachesparkutilEventLoopanon runEventLoopscala at orgapachesparkschedulerDAGSchedulerrunJobDAGSchedulerscala at orgapachesparkSparkContextrunJobSparkContextscala at orgapachesparksqlexecutioncollectCollectorrunSparkJobsCollectorscala at orgapachesparksqlexecutioncollectCollectorcollectCollectorscala at orgapachesparksqlexecutioncollectCollectorcollectCollectorscala at orgapachesparksqlexecutioncollectCollectorcollectCollectorscala at orgapachesparksqlexecutionResultCacheManagergetOrComputeResultResultCacheManagerscala at orgapachesparksqlexecutionCollectLimitExecexecuteCollectResultlimitscala at orgapachesparksqlexecutionSparkPlanexecuteCollectSparkPlanscala at comdatabricksserviceSparkServiceImplanonfunexecutePlan anonfunapply applySparkServiceImplscala at comdatabricksserviceSparkServiceImplanonfunexecutePlan anonfunapply applySparkServiceImplscala at orgapachesparksqlexecutionSQLExecutionanonfunwithCustomExecutionEnv applySQLExecutionscala at orgapachesparksqlexecutionSQLExecutionwithSQLConfPropagatedSQLExecutionscala at orgapachesparksqlexecutionSQLExecutionwithCustomExecutionEnvSQLExecutionscala at orgapachesparksqlexecutionSQLExecutionwithNewExecutionIdSQLExecutionscala at comdatabricksserviceSparkServiceImplanonfunexecutePlan applySparkServiceImplscala at comdatabricksserviceSparkServiceImplanonfunexecutePlan applySparkServiceImplscala at comdatabricksloggingUsageLogginganonfunrecordOperation applyUsageLoggingscala at comdatabricksloggingUsageLogginganonfunwithAttributionContext applyUsageLoggingscala at scalautilDynamicVariablewithValueDynamicVariablescala at comdatabricksloggingUsageLoggingclasswithAttributionContextUsageLoggingscala at comdatabrickssparkutilPublicDBLoggingwithAttributionContextDatabricksSparkUsageLoggerscala at comdatabricksloggingUsageLoggingclasswithAttributionTagsUsageLoggingscala at comdatabrickssparkutilPublicDBLoggingwithAttributionTagsDatabricksSparkUsageLoggerscala at comdatabricksloggingUsageLoggingclassrecordOperationUsageLoggingscala at comdatabrickssparkutilPublicDBLoggingrecordOperationDatabricksSparkUsageLoggerscala at comdatabrickssparkutilPublicDBLoggingrecordOperation DatabricksSparkUsageLoggerscala at comdatabrickssparkutilDatabricksSparkUsageLoggerrecordOperationDatabricksSparkUsageLoggerscala at comdatabrickssparkutilUsageLoggerclassrecordOperationUsageLoggerscala at comdatabrickssparkutilDatabricksSparkUsageLoggerrecordOperationDatabricksSparkUsageLoggerscala at comdatabrickssparkutilUsageLoggingclassrecordOperationUsageLoggerscala at comdatabricksserviceSparkServiceImplrecordOperationSparkServiceImplscala at comdatabricksserviceSparkServiceImplexecutePlanSparkServiceImplscala at comdatabricksserviceSparkServiceRPCHandlercomdatabricksserviceSparkServiceRPCHandlerexecute SparkServiceRPCHandlerscala at comdatabricksserviceSparkServiceRPCHandleranonfunexecuteRPC applySparkServiceRPCHandlerscala at comdatabricksserviceSparkServiceRPCHandleranonfunexecuteRPC applySparkServiceRPCHandlerscala at scalautilDynamicVariablewithValueDynamicVariablescala at comdatabricksserviceSparkServiceRPCHandlerexecuteRPC SparkServiceRPCHandlerscala at comdatabricksserviceSparkServiceRPCHandleranon callSparkServiceRPCHandlerscala at comdatabricksserviceSparkServiceRPCHandleranon callSparkServiceRPCHandlerscala at javautilconcurrentFutureTaskrunFutureTaskjava at comdatabricksserviceSparkServiceRPCHandleranonfunexecuteRPC applySparkServiceRPCHandlerscala at comdatabricksserviceSparkServiceRPCHandleranonfunexecuteRPC applySparkServiceRPCHandlerscala at scalautilDynamicVariablewithValueDynamicVariablescala at comdatabricksserviceSparkServiceRPCHandlerexecuteRPCSparkServiceRPCHandlerscala at comdatabricksserviceSparkServiceRPCServletdoPostSparkServiceRPCServerscala at javaxservlethttpHttpServletserviceHttpServletjava at javaxservlethttpHttpServletserviceHttpServletjava at orgeclipsejettyservletServletHolderhandleServletHolderjava at orgeclipsejettyservletServletHandlerdoHandleServletHandlerjava at orgeclipsejettyservletServletHandlerdoScopeServletHandlerjava at orgeclipsejettyserverhandlerScopedHandlerhandleScopedHandlerjava at orgeclipsejettyserverhandlerHandlerWrapperhandleHandlerWrapperjava at orgeclipsejettyserverServerhandleServerjava at orgeclipsejettyserverHttpChannelhandleHttpChanneljava at orgeclipsejettyserverHttpConnectiononFillableHttpConnectionjava at orgeclipsejettyioAbstractConnectionReadCallbacksucceededAbstractConnectionjava at orgeclipsejettyioFillInterestfillableFillInterestjava at orgeclipsejettyioSelectChannelEndPoint runSelectChannelEndPointjava at orgeclipsejettyutilthreadstrategyExecuteProduceConsumeexecuteProduceConsumeExecuteProduceConsumejava at orgeclipsejettyutilthreadstrategyExecuteProduceConsumeproduceConsumeExecuteProduceConsumejava at orgeclipsejettyutilthreadstrategyExecuteProduceConsumerunExecuteProduceConsumejava at orgeclipsejettyutilthreadQueuedThreadPoolrunJobQueuedThreadPooljava at orgeclipsejettyutilthreadQueuedThreadPool runQueuedThreadPooljava at javalangThreadrunThreadjava Caused by orgapachesparkapipythonPythonException Traceback most recent call last File databrickssparkpythonpysparkworkerpy line in main dd sysversioninfo version Exception Python in worker has different version than that in driver PySpark cannot run with different minor versionsPlease check environment variables PYSPARKPYTHON and PYSPARKDRIVERPYTHON are correctly set at orgapachesparkapipythonBasePythonRunnerReaderIteratorhandlePythonExceptionPythonRunnerscala at orgapachesparksqlexecutionpythonPythonUDFRunneranon readPythonUDFRunnerscala at orgapachesparksqlexecutionpythonPythonUDFRunneranon readPythonUDFRunnerscala at orgapachesparkapipythonBasePythonRunnerReaderIteratorhasNextPythonRunnerscala at orgapachesparkInterruptibleIteratorhasNextInterruptibleIteratorscala at scalacollectionIteratoranon hasNextIteratorscala at scalacollectionIteratoranon hasNextIteratorscala at scalacollectionIteratoranon hasNextIteratorscala at orgapachesparksqlcatalystexpressionsGeneratedClassGeneratedIteratorForCodegenStage processNextUnknown Source at orgapachesparksqlexecutionBufferedRowIteratorhasNextBufferedRowIteratorjava at orgapachesparksqlexecutionWholeStageCodegenExecanonfun anon hasNextWholeStageCodegenExecscala at orgapachesparksqlexecutioncollectUnsafeRowBatchUtilsencodeUnsafeRowsUnsafeRowBatchUtilsscala at orgapachesparksqlexecutioncollectCollectoranonfun applyCollectorscala at orgapachesparksqlexecutioncollectCollectoranonfun applyCollectorscala at orgapachesparkschedulerResultTaskrunTaskResultTaskscala at orgapachesparkschedulerTaskdoRunTaskTaskscala at orgapachesparkschedulerTaskrunTaskscala at orgapachesparkexecutorExecutorTaskRunneranonfun applyExecutorscala at orgapachesparkutilUtilstryWithSafeFinallyUtilsscala at orgapachesparkexecutorExecutorTaskRunnerrunExecutorscala at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava more T Z L Exception JvmBridge JVM method execution failed Nonstatic method showString failed for class when called with arguments Index TypeInt Value Index TypeInt Value Index TypeBoolean ValueFalse at MicrosoftSparkInteropIpcJvmBridgeCallJavaMethodBoolean isStatic Object classNameOrJvmObjectReference String methodName Object args Unhandled exception SystemException JVM method execution failed Nonstatic method showString failed for class when called with arguments Index TypeInt Value Index TypeInt Value Index TypeBoolean ValueFalse at MicrosoftSparkInteropIpcJvmBridgeCallJavaMethodBoolean isStatic Object classNameOrJvmObjectReference String methodName Object args at MicrosoftSparkInteropIpcJvmBridgeCallNonStaticJavaMethodJvmObjectReference objectId String methodName Object args at MicrosoftSparkInteropIpcJvmObjectReferenceInvokeString methodName Object args at MicrosoftSparkSqlDataFrameShowInt numRows Int truncate Boolean vertical at TestAppProgramMainString args in C projects TestApp testdatascience Sources TestApp Programcsline details Expected behavior A net application containing a UDF works properly using connection to a remote databricks Additional context Similar program in Python same SQL query and similar UDF works using the same configured remote connection properly Application has been started using sparksubmit ie SPARKHOME bin sparksubmit class orgapachesparkdeploydotnetDotnetRunner master local microsoftspark x jar dotnet TestAppdll The build has successful as C Users Nivethan mySparkAppdotnet build Microsoft R Build Engine version g f fadfbe for NET Core Copyright C Microsoft Corporation All rights reserved Restore completed in ms for C Users Nivethan mySparkApp mySparkAppcsproj mySparkApp C Users Nivethan mySparkApp bin Debug netcoreapp mySparkAppdll Build succeeded Warnings Errors Time Elapsed And finally try to execute on apache spark will throw an error C Users Nivethan mySparkAppSPARKHOME bin sparksubmit class orgapachesparkdeploydotnetDotnetRunner master local bin Debug netcoreapp microsoftspark x jar dotnet bin Debug netcoreapp mySparkAppdll WARN NativeCodeLoader Unable to load nativehadoop library for your platform using builtinjava classes where applicable Using Sparks default log j profile orgapachesparklog jdefaultsproperties WARN DependencyUtils Local jar C Users Nivethan mySparkApp bin Debug netcoreapp microsoftspark x jar does not exist skipping WARN SparkSubmitanon Failed to load orgapachesparkdeploydotnetDotnetRunner javalangClassNotFoundException orgapachesparkdeploydotnetDotnetRunner at javanetURLClassLoaderfindClassUnknown Source at javalangClassLoaderloadClassUnknown Source at javalangClassLoaderloadClassUnknown Source at javalangClassforName Native Method at javalangClassforNameUnknown Source at orgapachesparkutilUtilsclassForNameUtilsscala at orgapachesparkdeploySparkSubmitorgapachesparkdeploySparkSubmitrunMainSparkSubmitscala at orgapachesparkdeploySparkSubmitdoRunMain SparkSubmitscala at orgapachesparkdeploySparkSubmitsubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitdoSubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitanon doSubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala INFO ShutdownHookManager Shutdown hook called INFO ShutdownHookManager Deleting directory C Users Nivethan AppData Local Temp spark f cb b a c e b fe df e C Users Nivethan mySparkAppSPARKHOME bin sparksubmit class orgapachesparkdeploydotnetDotnetRunner master local bin Debug netcoreapp microsoftspark x jar dotnet bin Debug netcoreapp mySparkAppdll WARN NativeCodeLoader Unable to load nativehadoop library for your platform using builtinjava classes where applicable Using Sparks default log j profile orgapachesparklog jdefaultsproperties WARN DependencyUtils Local jar C Users Nivethan mySparkApp bin Debug netcoreapp microsoftspark x jar does not exist skipping WARN SparkSubmitanon Failed to load orgapachesparkdeploydotnetDotnetRunner javalangClassNotFoundException orgapachesparkdeploydotnetDotnetRunner at javanetURLClassLoaderfindClassUnknown Source at javalangClassLoaderloadClassUnknown Source at javalangClassLoaderloadClassUnknown Source at javalangClassforName Native Method at javalangClassforNameUnknown Source at orgapachesparkutilUtilsclassForNameUtilsscala at orgapachesparkdeploySparkSubmitorgapachesparkdeploySparkSubmitrunMainSparkSubmitscala at orgapachesparkdeploySparkSubmitdoRunMain SparkSubmitscala at orgapachesparkdeploySparkSubmitsubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitdoSubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitanon doSubmitSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala at orgapachesparkdeploySparkSubmitmainSparkSubmitscala INFO ShutdownHookManager Shutdown hook called INFO ShutdownHookManager Deleting directory C Users Nivethan AppData Local Temp sparkadef becee bb a c fbf cc C Users Nivethan mySparkApp and my java verion details java version JavaTM SE Runtime Environment build b Java HotSpotTM Bit Server VM build b mixed mode kindly help me to resolve this issue This is to track implementation of the MLFeatures Bucketizer has been implemented in but there are more features that should be implemented Feature Extractors x TFIDF Word Vec CountVectorizer FeatureHasher Feature Transformers x Tokenizer StopWordsRemover ngram Binarizer PCA PolynormalExpansion Dicrete Cosine Transform DCT StringIndexer IndexToString OneHotEncoderEstimator VectorIndexer Normalizer StandardScaler MinMaxScaler MaxAbsScaler X Bucketizer ElementwiseProduct SQLTransformer VectorAssembler VectorSizeHint QuantileDiscretizer Imputer Feature Selectors VectorSlicer RFormula ChiSqSelector Locality Sensitive Hashing LSH Operations Feature Transformation Approximate Similarity Join Approximate Nearest Neighbour Search LSH Algorithms Bucketed Random Projection for Euclidean Distance MinHash for Jaccard Distance Ill try and carry on implementing theses will wait until pr has been completed to check that the code will go in MicrosoftSpark and not somewhere else etc If anyone else is going to implement probably best to put a comment here or something Adding DaemonWorkerTests into the MicrosoftSparkWorkerUnitTest project Fixes I am writing a Udf extension for DataFrame and I found that the FunctionsUdfstring stringmsg only allow one message to process Can I write a Udf that supports multiple messages processing at a time Thanks in advance