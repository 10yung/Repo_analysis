Installing and calling pep as directed now leads to this warning pep has been renamed to pycodestyle GitHub issue Use of the pep tool will be removed in a future release Please install and use pycodestyle instead pip install pycodestyle pycodestyle This PR updates the contribution guide to reflect the name change I am trying to balance my data by reducing the number of samples of the class but every time I specify the ratio via the samplingstrategy parameter I get the following error Code import matplotlibpyplot as plt import numpy as np from sklearndecomposition import PCA from imblearnundersampling import CondensedNearestNeighbour EditedNearestNeighbours AllKNN printdoc pca PCAncomponents samplingstrategy cnn CondensedNearestNeighboursamplingstrategy Xresampled yresampled cnnfitsampleXtrain Ytrain ValueError samplingstrategy as a dict for cleaning methods is not supported Please give a list of the classes to be targeted by the sampling Remark If the sampling strategy parameter is indeed removed as mentioned in the documentation then I would like to know if there is another way to specify the ratio Versions Linux amzn x x withglibc Python Anaconda Inc default Jan GCC NumPy SciPy ScikitLearn ImbalancedLearn Thanks for contributing Fixes What does this implementfix Explain your changes If the median standard deviation is the SMOTENC class will now store the categorical features before multiplying the s by the median standard deviation This way information about the most common categorical labels can still be used in getsamples Checklist Write tests Example import numpy as np from imblearnoversampling import SMOTENC from sklearndatasets import makeclassification nprandomseed Original data X nparray minority class minority class y nparray A A B B B Construct SMOTENC with masks smotenc SMOTENC False False False True samplingstrategy not majority kneighbors Resample Xresampled yresampled smotencfitresampleX y printXresampled printyresampled Output on master A A B B B A Only the last row is new It has the category in the fourth column even though all rows from the minority class have the category in the fourth column This is incorrect Output on this fork A A B B B A Here the resampled row correctly has the category in the fourth column Reference Issue Fixes What does this implementfix Explain your changes Converts the target vector in the binary or multiclass case Any other comments OMG what an evil number is related but it will be solved probably in a following PR because there is an extra check of the name in the y which I think that is redundant Please be aware that we are a loose team of volunteers so patience is necessary assistance handling other issues is very welcome We value all user contributions no matter how minor they are If we are slow to review either the pull request needs some benchmarking tinkering convincing etc or more likely the reviewers are simply busy In either case we ask for your understanding during the review process Thanks for contributing In tests it could be ok to have copypaste code but I believe that in common estimator checks we could remove the boilerplate of datasets generation for each test by creating a common fixture Apart from that we could reduce the number of instances of the datasets in order to speed up the execution of the commont tests The later could be measured though Description When running the method fit on the following Pipeline the code fails with TypeError If I remove the RandomOverSampler from the Pipeline then I face no error Is it a bug or a wrong initialization StepsCode to Reproduce python from imblearnpipeline import Pipeline from sklearnfeatureselection import VarianceThreshold from sklearnpreprocessing import StandardScaler from imblearnoversampling import RandomOverSampler from sklearndecomposition import PCA from sklearnneighbors import KNeighborsClassifier from sklearnutils import shuffle import numpy as np import pandas as pd mnisttrain pdreadcsv headerNonevalues mnisttest pdreadcsv headerNonevalues mnist npconcatenatemnisttrain mnisttest axis xfull mnist yfull mnist sdata starget shufflexfull yfull randomstate samples X sdata samples y starget samples Xtrain Xtest ytrain ytest traintestsplit X y testsize randomstate selector VarianceThreshold scaler StandardScaler ros RandomOverSampler pca PCA clf KNeighborsClassifiernjobs pipe Pipeline steps selector selector scaler scaler sampler ros pca pca kNN clf Xtrainshape is Ytrainshape is pipefitXtrain ytrain Expected Results No error is thrown Actual Results TypeError Traceback most recent call last ipythoninput da a d cb in module pipefitXtrain ytrain frames usrlocallibpython distpackagessklearnmodelselectionsearchpy in fitself X y groups fitparams refitstarttime timetime if y is not None selfbestestimatorfitX y fitparams else selfbestestimatorfitX fitparams usrlocallibpython distpackagesimblearnpipelinepy in fitself X y fitparams Xt yt fitparams selffitX y fitparams with printelapsedtimePipeline selflogmessagelenselfsteps usrlocallibpython distpackagesimblearnpipelinepy in fitself X y fitparams messageclsnamePipeline messageselflogmessagestepidx fitparamssteps name Replace the transformer of the step with the fitted usrlocallibpython distpackagesjoblibmemorypy in callself args kwargs def callself args kwargs return selfcachedcallargs kwargs def getstateself usrlocallibpython distpackagesjoblibmemorypy in cachedcallself args kwargs shelving if mustcall out metadata selfcallargs kwargs if selfmmapmode is not None Memmap the output at the first call to be consistent with usrlocallibpython distpackagesjoblibmemorypy in callself args kwargs if selfverbose printformatcallselffunc args kwargs output selffuncargs kwargs selfstorebackenddumpitem funcid argsid output verboseselfverbose usrlocallibpython distpackagesimblearnpipelinepy in fitresampleonesampler X y messageclsname message fitparams fitparams with printelapsedtimemessageclsname message Xres yres samplerfitresampleX y fitparams return Xres yres sampler usrlocallibpython distpackagesimblearnbasepy in fitresampleself X y output selffitresampleX y if selfXcolumns is not None or selfyname is not None usrlocallibpython distpackagesimblearnoversamplingrandomoversamplerpy in fitresampleself X y def fitresampleself X y randomstate checkrandomstateselfrandomstate targetstats Countery sampleindices rangeXshape usrlibpython collectionsinitpy in initargs kwds raise TypeErrorexpected at most arguments got d lenargs superCounter selfinit selfupdateargs kwds def missingself key usrlibpython collectionsinitpy in updateargs kwds superCounter selfupdateiterable fast path when counter is empty else countelementsself iterable if kwds selfupdatekwds TypeError unhashable type numpyndarray Versions Linux x withUbuntu bionic Python default Nov GCC NumPy SciPy ScikitLearn ImbalancedLearn dear sir presently I am working with imbalanced datasets having dimension billion instances and features I am using Daskdataframe as inputing library beacuse my data does not fit into my ram and willing to incremental machine learning model while using makepipeline from pipeline library I am getting am error that makepipeline does not work with partialfit function used for big data please suggest me way out to use imbalance learning algorithms with these datasets pytb AttributeError Traceback most recent call last ipythoninput d b cc in module oversamplerSMOTErandomstate smotetrain smotetarget oversamplerfitresampleXy printBefore OverSampling counts of label smotetarget label valuecounts Anaconda lib sitepackages imblearn basepy in fitresampleself X y checkclassificationtargetsy X y binarizey selfcheckXyX y selfsamplingstrategy checksamplingstrategy Anaconda lib sitepackages imblearn basepy in checkXyself X y acceptsparse if hasattry loc store information to build a series selfyname yname selfydtype ydtype else Anaconda lib sitepackages pandas core genericpy in getattrself name if selfinfoaxiscanholdidentifiersandholdsnamename return self name return objectgetattributeself name def setattrself name value AttributeError DataFrame object has no attribute name Description When using not majority method and when selfmedianstd based on the minority class standard deviations the new oversampled categorical field gets categories which dont belong to the given class but rather are any of the categories of the WHOLE categorical field across classes This is a violation of the main imputation logic in the original paper where the K nearest neighbours and their fields distributions are calculated and taken within the sameclass vectors This issue occurs through the following two code segments in smotepy class SMOTENC method fitresample def fitresampleself X y we can replace the entries of the categorical features with the median of the standard deviation It will ensure that whenever distance is computed between samples the difference will be equal to the median of the standard deviation as in the original paper Xohedata nponeslikeXohedata dtypeXohedtype selfmedianstd The problem occurs when the median std of the minority class is zero selfmedianstd the onehot vectors are multiplied by then we get zerovectors and all the information of the categories ie which category is represented is lost in smotepy class SMOTENC method generatesample def generatesampleself X nndata nnnum row col step for startidx endidx in zipnpcumsumcategoriessize npcumsumcategoriessize colmax allneighbors startidxendidx sumaxis tie breaking argmax colsel rngchoicenpflatnonzero npisclosecolmax colmaxmax Then colmax gets the zerovectors from the previous step and colsel gets a random tiebreaking choice from the WHOLE categories range including categories which dont belong to the resampled minority class This happens because no information was kept regarding the categories of the K nearest neighbours and thus theres no maximum value of any category across the vectors to determine the true value Example First three columns are continuous and the fourth is categorical data nparray A A B C C labels nparray class class class class class printdata array A A B C C dtypeU printlabels array class class class class class dtypeU Expected Results printresampleddata array A A B C C C dtypeU printresampledlabels array class class class class class class dtypeU Actual Results printresampleddata array A A B C C A dtypeU printresampledlabels array class class class class class class dtypeU Versions Darwin x i bit Python v f Aug GCC Apple Inc build dot NumPy SciPy ScikitLearn ImbalancedLearn 