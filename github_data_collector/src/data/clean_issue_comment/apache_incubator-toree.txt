Fix string values within Metadata the values needs to be json string Reply errors to iopuberror instead of iopubexecresult To support using the Toree kernel with Spark I had to patch in support for Scala This works for me now so thought I would try merging it back We had some problems with the nexus repository in conjunction with the Apache Toree incubator The coursier dependency manager is incompatible with Nexus repository manager We could not use the magics AddJar AddDeps in a normal way With the Ivy dependency manager we had no problems Changes We introduced a new setting ivysettings where an user can link an ivyconfiguration file Maybe it is useful for other people too The depsdir option configure destination path of dependencies downloaded with AddDeps magic The Scala kernel accepts command line arguments such as profile ip defaultrepositories It also supports passing settings to the Scala compiler eg Xmaxclassfilename the last one in particular is very useful when running Toree from inside Docker images or on encrypted volumes This patch allows users to pass command line arguments to the kernel via jupyter toree install kernelopts Xmaxclassfilename interpretersScalaPySparkSparkRSQL Not sure if kernelopts is the best name though kernelextraopts may be better since profile is already being passed to the kernel The goal of this PR is to decrease Torees startup time by breaking out the ScalaInterpreter initialization and running it in its own thread If you count the startup time as the time it takes KernelBootstrapinitizalize to complete I saw the average startup time go from s to s on my laptop I started the kernel ten times with the original code and my changes This supports both Python and Python now Just remember to export PYTHONEXECpython for example You are welcome It looks like the TOREE issue support for Spark Yarn was closed without definitive solution or something went wrong on the way Toree does support it but it wont work if a user doesnt add manually in their kerneljson definition the env vars for HADOOPCONFDIR Without that env var Spark doesnt know what to do with the option masteryarn set in TOREESPARKOPTS It would be desirable to have it by default and this patch provides this functionality Probably this is not the nicest way to solve the problem because it just hard codes more vars into the JSON file ideally it would be nice to have an interface to add or remove env vars from those files however HADOOPCONFDIR and SPARKCONFDIR look basic to be exported Even for an Spark Standalone deployment HADOOPCONFDIR wont hurt So here it goes our cents to improve a bit the situation I cloned the TOREE into TOREE to sign this issue 