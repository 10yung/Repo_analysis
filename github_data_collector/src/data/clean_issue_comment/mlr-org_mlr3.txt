Hi I would like to tune the number of top features to include in a model as a hyperparameter where the features are ranked by some importance measure as in the filtering method of feature selection In the old mlr I can do this by using makeFilterWrapper around a learner passing an argument like fwmethod and then tune a corresponding hyperparameter with a name like fwabs Sorry but I havent figured out how to do this in mlr I failed to find the relevant info in the documentation and in the manual mlr book it explains ways to obtain the importance measure of the features but doesnt seem to explain how to use it during tuning Much appreciated if any guidance could be provided on this r task tskmtcars learner lrnregrfeatureless learnertraintask taskdata asdatatabletask taskdatampg NULL preds learnerpredictnewdatataskdata preds PredictionRegr for observations rowid truth response rbind c f NA rbind c f NA rbind c f NA rbind c f NA rbind c f NA rbind c f NA The row ids are weird and in the wrong order It does not happen with all tasks and seems to be unrelated of the learner also tried rpart why does this run task tskpima learner lrnclassifsvm learnertraintask This issue is to track the various discussions about predicttype and predicttypes Ill summarise everything discussed on Mattermost below If Ive copied anything wrong please edit Raphael Why cant all return types be returned by default Bernd Some return types require extra hyperparameters and could cause unnecessary overhead Raphael Can we change predicttype default in LearnerClassif to prob Bernd This crashes if a learner cannot return prob whereas all classif learners return response Michel I also find it annoying that you are often forced to change the predicttype to prob in classif Raphael Can we allow predicttype to be a vector to increase user flexibility over returns Michel This is possible Raphael Does every learner need the same default predicttype or can we allow this to be changed in a learner definition Franz A problem with always returning prob and response is less flexibility in determining how to perform the reduction from prob to response eg default threshold value Proposed solution predicttypes is a class property trait and predicttype is a mutable object property predicttype can be a vector if a default for one pt to another isnt obvious eg threshold value then this should be done via pipelines see for example mlrhyperopt is my favorite way for using mlr because most of the time it brings me straight to what i am interested in with very little code mlrhyperopt also gives easy access to all innovative tuning strategies just by changing function arguments and a database of hyperparameters having this would convince me to make the switch from mlr to mlr do you plan an mlrhyperopt pendant in mlr mboecker will do this for all Learner classes now in the beginning Fixes berndbischl volunteered for a review Similar to tidymodelsbutcher autotest fails if the named vector returned by learnerimportance contains a name which is not present in taskfeaturenames However some learners return the variable importance for each level of a factor As a result the returned named vector contains names like factorlevel For example h oh odeeplearning in mlr Do we want to support variable importance for factor levels As we discussed jakobr I tried to convert our mlr docs to the R Roxygen docs Im not sure if usage NULL should still be needed I included it because otherwise the usage section would just say LearnerClassif