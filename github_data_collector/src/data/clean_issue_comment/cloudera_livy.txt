Bumps jacksonversion from to Updates jacksonannotations from to details summaryCommitssummary See full diff in compare view details br Updates jacksoncore from to details summaryCommitssummary fc mavenreleaseplugin prepare release jacksoncore a d a prepare for ce d e revert now unnecessary sonatype deploy plugin adf fd Add Sonatype deploy plugin to simplify releases ca ec array index out of bounds in hex lookup da e Fix nonblocking path still had potential problem but changed method i db f fadc Fix df b Additional commits viewable in compare view details br Updates jacksondatabind from to details summaryCommitssummary See full diff in compare view details br Updates jacksonmodulescala from to details summaryCommitssummary abae d Setting version to f jackson ac make test more robust by not relying on order of json elements d add basic test for try f set version to SNAPSHOT deb back to SNAPSHOT builds a c d c use scalatest in guava test bdfdb prepare release c test with jackson SNAPSHOT f publish SNAPSHOT Additional commits viewable in compare view details br Dependabot will resolve any conflicts with this PR as long as you dont alter it yourself You can also trigger a rebase manually by commenting dependabot rebase dependabotautomergestart dependabotautomergeend details summaryDependabot commands and optionssummary br You can trigger Dependabot actions by commenting on this PR dependabot rebase will rebase this PR dependabot recreate will recreate this PR overwriting any edits that have been made to it dependabot merge will merge this PR after your CI passes on it dependabot squash and merge will squash and merge this PR after your CI passes on it dependabot cancel merge will cancel a previously requested merge and block automerging dependabot reopen will reopen this PR if it is closed dependabot ignore this patchminormajor version will close this PR and stop Dependabot creating any more for this minormajor version unless you reopen the PR or upgrade to it yourself dependabot ignore this dependency will close this PR and stop Dependabot creating any more for this dependency unless you reopen the PR or upgrade to it yourself dependabot use these labels will set the current labels as the default for future PRs for this repo and language dependabot use these reviewers will set the current reviewers as the default for future PRs for this repo and language dependabot use these assignees will set the current assignees as the default for future PRs for this repo and language dependabot use this milestone will set the current milestone as the default for future PRs for this repo and language You can disable automated security fix PRs for this repo from the Security Alerts page details ERROR SessionServlet internal error javalangRuntimeException javaioIOException Unable to connect to provided ports at orgapachelivyrscUtilspropagateUtilsjava at orgapachelivyrscRSCClientFactorycreateClientRSCClientFactoryjava at orgapachelivyLivyClientBuilderbuildLivyClientBuilderjava at orgapachelivyserverinteractiveInteractiveSessionanonfun applyInteractiveSessionscala at orgapachelivyserverinteractiveInteractiveSessionanonfun applyInteractiveSessionscala at scalaOptionorElseOptionscala at orgapachelivyserverinteractiveInteractiveSessioncreateInteractiveSessionscala at orgapachelivyserverinteractiveInteractiveSessionServletcreateSessionInteractiveSessionServletscala at orgapachelivyserverinteractiveInteractiveSessionServletcreateSessionInteractiveSessionServletscala at orgapachelivyserverSessionServletanonfun applySessionServletscala at orgapachelivyserverSessionServletanonfun applySessionServletscala at orgscalatraScalatraBaseclassorgscalatraScalatraBaseliftActionScalatraBasescala at orgscalatraScalatraBaseanonfuninvoke applyScalatraBasescala at orgscalatraScalatraBaseanonfuninvoke applyScalatraBasescala at orgscalatraApiFormatsclasswithRouteMultiParamsApiFormatsscala at orgapachelivyserverJsonServletwithRouteMultiParamsJsonServletscala at orgscalatraScalatraBaseclassinvokeScalatraBasescala at orgscalatraScalatraServletinvokeScalatraServletscala at orgscalatraScalatraBaseanonfunrunRoutes anonfunapply applyScalatraBasescala at orgscalatraScalatraBaseanonfunrunRoutes anonfunapply applyScalatraBasescala at scalaOptionflatMapOptionscala at orgscalatraScalatraBaseanonfunrunRoutes applyScalatraBasescala at orgscalatraScalatraBaseanonfunrunRoutes applyScalatraBasescala at scalacollectionimmutableStreamflatMapStreamscala at orgscalatraScalatraBaseclassrunRoutesScalatraBasescala at orgscalatraScalatraServletrunRoutesScalatraServletscala at orgscalatraScalatraBaseclassrunActions ScalatraBasescala at orgscalatraScalatraBaseanonfunexecuteRoutes applymcVspScalatraBasescala at orgscalatraScalatraBaseanonfunexecuteRoutes applyScalatraBasescala at orgscalatraScalatraBaseanonfunexecuteRoutes applyScalatraBasescala at orgscalatraScalatraBaseclassorgscalatraScalatraBasecradleHaltScalatraBasescala at orgscalatraScalatraBaseclassexecuteRoutesScalatraBasescala at orgscalatraScalatraServletexecuteRoutesScalatraServletscala at orgscalatraScalatraBaseanonfunhandle applymcVspScalatraBasescala at orgscalatraScalatraBaseanonfunhandle applyScalatraBasescala at orgscalatraScalatraBaseanonfunhandle applyScalatraBasescala at scalautilDynamicVariablewithValueDynamicVariablescala at orgscalatraDynamicScopeclasswithResponseDynamicScopescala at orgscalatraScalatraServletwithResponseScalatraServletscala at orgscalatraDynamicScopeanonfunwithRequestResponse applyDynamicScopescala at scalautilDynamicVariablewithValueDynamicVariablescala at orgscalatraDynamicScopeclasswithRequestDynamicScopescala at orgscalatraScalatraServletwithRequestScalatraServletscala at orgscalatraDynamicScopeclasswithRequestResponseDynamicScopescala at orgscalatraScalatraServletwithRequestResponseScalatraServletscala at orgscalatraScalatraBaseclasshandleScalatraBasescala at orgscalatraScalatraServletorgscalatraservletServletBasesuperhandleScalatraServletscala at orgscalatraservletServletBaseclasshandleServletBasescala at orgapachelivyserverSessionServletorgscalatraMethodOverridesuperhandleSessionServletscala at orgscalatraMethodOverrideclasshandleMethodOverridescala at orgapachelivyserverSessionServletorgscalatraGZipSupportsuperhandleSessionServletscala at orgscalatraGZipSupportanonfunhandle applymcVspGZipSupportscala at orgscalatraGZipSupportanonfunhandle applyGZipSupportscala at orgscalatraGZipSupportanonfunhandle applyGZipSupportscala at scalautilDynamicVariablewithValueDynamicVariablescala at orgscalatraDynamicScopeclasswithResponseDynamicScopescala at orgscalatraScalatraServletwithResponseScalatraServletscala at orgscalatraDynamicScopeanonfunwithRequestResponse applyDynamicScopescala at scalautilDynamicVariablewithValueDynamicVariablescala at orgscalatraDynamicScopeclasswithRequestDynamicScopescala at orgscalatraScalatraServletwithRequestScalatraServletscala at orgscalatraDynamicScopeclasswithRequestResponseDynamicScopescala at orgscalatraScalatraServletwithRequestResponseScalatraServletscala at orgscalatraGZipSupportclasshandleGZipSupportscala at orgapachelivyserverinteractiveInteractiveSessionServletorgscalatraservletFileUploadSupportsuperhandleInteractiveSessionServletscala at orgscalatraservletFileUploadSupportclasshandleFileUploadSupportscala at orgapachelivyserverinteractiveInteractiveSessionServlethandleInteractiveSessionServletscala at orgscalatraScalatraServletserviceScalatraServletscala at javaxservlethttpHttpServletserviceHttpServletjava at orgeclipsejettyservletServletHolderhandleServletHolderjava at orgeclipsejettyservletServletHandlerdoHandleServletHandlerjava at orgeclipsejettyserverhandlerContextHandlerdoHandleContextHandlerjava at orgeclipsejettyservletServletHandlerdoScopeServletHandlerjava at orgeclipsejettyserverhandlerContextHandlerdoScopeContextHandlerjava at orgeclipsejettyserverhandlerScopedHandlerhandleScopedHandlerjava at orgeclipsejettyserverhandlerHandlerCollectionhandleHandlerCollectionjava at orgeclipsejettyserverhandlerHandlerWrapperhandleHandlerWrapperjava at orgeclipsejettyserverServerhandleServerjava at orgeclipsejettyserverHttpChannelhandleHttpChanneljava at orgeclipsejettyserverHttpConnectiononFillableHttpConnectionjava at orgeclipsejettyioAbstractConnection runAbstractConnectionjava at orgeclipsejettyutilthreadQueuedThreadPoolrunJobQueuedThreadPooljava at orgeclipsejettyutilthreadQueuedThreadPool runQueuedThreadPooljava at javalangThreadrunThreadjava Caused by javaioIOException Unable to connect to provided ports at orgapachelivyrscrpcRpcServerinitRpcServerjava at orgapachelivyrscRSCClientFactoryrefRSCClientFactoryjava at orgapachelivyrscRSCClientFactorycreateClientRSCClientFactoryjava more livy session Currently Livy doesnt support LDAP Authentication from clientsparkmagic to serverlivy We need to add LDAP authentication as thats preferable method due to security reasons We wont be able to use Knox for this purpose That is why I am raising this PR which contains LDAP authentication I am also adding config to disable batch endpoints Due to security reasons we dont want to keep batch endpoint open I am adding config so that We can disable it Current LivyServer already supports SSL but the functionality is not fully implemented it cannot support client side authentication also cannot specify advanced configurations Also SSL support for Livy http client is missing So here propose to add a full functionality SSL support for Livy server and client Changes Made Added logs cacheing as config driven Fixed adding driver process logs livy logs for local and client mode in interactive mode Made code changes for enabling multiple spark versions on Livy for spark batch jobs User can pass sparkVersion on run time for batch jobs and SPARKHOME and SPARKCONFDIR would be set according to given sparkVersion Need to set path for livyserversparkhomeversion in Livyconf and those versions which are added would be supported Assumption binlivyenvsh will continue to have SPARKHOME and SPARKCONFDIR which will be used as default spark version for batch and interactive subprocesscall commands in a PySpark snippet can potentially insert raw text into the sysstdout in the fakeshell main This will then fail to be correctly parsed by PythonInterpreter in the sendRequest as it will trigger a JsonParseException that is not caught Added code to catch the JsonParseException and then retry reads of stdout until a valid line of JSON is reached or retries have been attempted Kerberos over http requires larger header sizes than the default or the HTTP Error Request entity too large will be returned This patch increases the default for Livy to K and also allows this to be configurable With LIVY InteractiveSession bring in two session state one is from yarn and another is from repl session this bring the complexity of session state management compared to previous code So here propose to simplify the state management code and unify these two states This PR propose to add a SparkEnvironment to isolate Sparks related configurations and libraries also extend it to support multiple SparkEnvironment in LivyServer Why Current Livy Supports different Sparks with one build user could configure different spark home to choose the right Spark to run but this still requires stopping LivyServer updating configuration and restarting it To further extend the usability of Livy it would be better to support different Sparks in runtime when user create a session user could specify which Spark they wanted and Livy will pick right Spark and start application How to use To enable it we extend the Livy configurations to support multiple Spark profiles user could configure livyserversparkenvdefaultsparkhome xxx or TESTSPARKHOME xxx livyserversparkenvdefaultsparkconfdir xxx or TESTSPARKCONFDIR xxx and livyserversparkenvproductionsparkhome xxx or PRODUCTIONSPARKHOME xxx livyserversparkenvproductionsparkconfdir xxx or PRODUCTIONSPARKCONFDIR xxx Internally Livy will create two Spark environments test and product when user issue a session creation request he could specify sparkEnv with test in JSON body Livy will pick the right Spark environment and start application To be compatible with existing configuration and test if user configured livyserversparkhome xxx or SPARKHOME xxx This is equal to livyserversparkenvdefaultsparkhome xxx or DEFAULTSPARKHOME xxx Livy will treat these as default Spark environment If user didnt specify sparkEnv in JSON body then the default one will be picked Implementation To achieve this I introduced a SparkEnvironment class one LivyServer can have multiple SparkEnvironment based on configuration Also I refactored the code to move Spark related codes into this class Limitation Some configurations like spark master and deploy mode cannot be configured per Spark environment currently Works done and to be done x Code implementation for isolated spark environments x Add unit tests x Change launching scripts x Change docs and configuration files Please review and suggest thanks a lot