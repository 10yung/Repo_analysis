Except common which is handled in Signedoffby Julien Pivotto roidelapluieinuitseu Dont forget If the PR adds or changes a behaviour or fixes a bug of an exported API it would need a unite e test Where possible use only exported APIs for tests to simplify the review and make it as close as possible to an actual library usage No tests are needed for internal implementation changes Performance improvements would need a benchmark test to prove it All exposed objects should have a comment All comments should start with a capital letter and end with a full stop Signedoffby Julien Pivotto roidelapluieinuitseu Dont forget If the PR adds or changes a behaviour or fixes a bug of an exported API it would need a unite e test Where possible use only exported APIs for tests to simplify the review and make it as close as possible to an actual library usage No tests are needed for internal implementation changes Performance improvements would need a benchmark test to prove it All exposed objects should have a comment All comments should start with a capital letter and end with a full stop Inspired by and Signedoffby Julien Pivotto roidelapluieinuitseu Dont forget If the PR adds or changes a behaviour or fixes a bug of an exported API it would need a unite e test Where possible use only exported APIs for tests to simplify the review and make it as close as possible to an actual library usage No tests are needed for internal implementation changes Performance improvements would need a benchmark test to prove it All exposed objects should have a comment All comments should start with a capital letter and end with a full stop Dont forget If the PR adds or changes a behaviour or fixes a bug of an exported API it would need a unite e test Where possible use only exported APIs for tests to simplify the review and make it as close as possible to an actual library usage No tests are needed for internal implementation changes Performance improvements would need a benchmark test to prove it All exposed objects should have a comment All comments should start with a capital letter and end with a full stop This sentence was missing from this endpoint but it is present in the rest of them I think it might make sense to add a new rule to the PR template just in the case of new API endpoints Bug Report This is a similar issue as and What did you do I am running Prometheus with default retention and TSDB settings It is scraping k metrics per second What did you expect to see I expected the WAL to stay small and new compact TSDB block to be created What did you see instead Under which circumstances Under steady load of k metricssecond the compaction seems to run forever leading to the WAL and RAM filling up until OOM Due to this checkpointing also fails Prometheus crashes unclean and the cycle repeats Environment System information Production Linux amd x Reproduced on Darwin x Prometheus version Production Docker image of Reproduced with a c d ce f db c e d e d Alertmanager version not relevant Prometheus configuration file not relevant Alertmanager configuration file not relevant Reproduced with code go package main import githubcomprometheusprometheustsdb func main db err tsdbOpenDBReadOnlydata nil if err nil panicerr defer dbClose err dbFlushWALdata if err nil panicerr Logs no relevant errors or messages in log no output is printing during compaction running forever at of one CPU core Probable root cause During my reproduction I let the FlushWAL run until the RAM usage of my little program no longer went down starting at GB after TSDB and WAL load down to MB Then I paused the program with the debugger and detected the following situation I am running into the case of batchNames staying empty for every iteration of the top level forloop here The first label position is while maxPostings is and that causes it to break on the first iteration of the inner forloop leaving names untouched and batchNames empty and that causes it to get stuck in an endless loop Signedoffby Julien Pivotto roidelapluieinuitseu Dont forget If the PR adds or changes a behaviour or fixes a bug of an exported API it would need a unite e test Where possible use only exported APIs for tests to simplify the review and make it as close as possible to an actual library usage No tests are needed for internal implementation changes Performance improvements would need a benchmark test to prove it All exposed objects should have a comment All comments should start with a capital letter and end with a full stop This will make big queries that only touch the head faster though queries that touch both the head and a block will still be the same speed This probably wont help much with graphing unless the range is under an hour however it should make most recording rules faster PromQL benchmarks for histograms show only improvement but theyre only over k series Looks like wed be saving about s for a headonly query that touches M series so a M series histogramquantilerate m would go from around s to s This changes exposes the stripeSize const as a configurable option in tsdb Not passing in the option will result in the tsdb using the default stripe size that is uses today This is an important change for Cortexs new experimental TSDB feature as it allows us to reduce the memory footprint of TSDBs as they are scaled to many nodes More info about this memory usage can be found here codesome krasigeorgiev config scrapeconfigs jobname subprometheus scrapeinterval m scrapetimeout m metricspath federate scheme http consulsdconfigs server consul tagseparator scheme http allowstale true refreshinterval m tags kubernetes relabelconfigs prometheus version log levelerror ts T Z callerconsulgo componentdiscovery manager scrape discoveryconsul msgError refreshing service list errGet context canceled code Watch the catalog for new services we would like to watch This is called only when we dont know yet the names of the services and need to ask Consul the entire list of services func d Discovery watchServicesctx contextContext ch chan targetgroupGroup lastIndex uint services map string func catalog dclientCatalog levelDebugdloggerLogmsg Watching services tags dwatchedTags t timeNow opts consulQueryOptions WaitIndex lastIndex WaitTime watchTimeout AllowStale dallowStale NodeMeta dwatchedNodeMeta srvs meta err catalogServicesoptsWithContextctx elapsed timeSincet rpcDurationWithLabelValuescatalog servicesObserveelapsedSeconds if err nil levelErrordloggerLogmsg Error refreshing service list err err rpcFailuresCountInc timeSleepretryInterval return If the index equals the previous one the watch timed out with no update if metaLastIndex lastIndex return lastIndex metaLastIndex Check for new services for name range srvs catalogService returns a map of service name to tags we can use that to watch only the services that have the tag we are looking for if specified In the future consul will also support server side for service metadata if dshouldWatchname srvs name continue if ok services name ok continue We are already watching the service wctx cancel contextWithCancelctx dwatchServicewctx ch name services name cancel Check for removed services for name cancel range services if ok srvs name ok Call the watch cancellation function cancel deleteservices name Send clearing target group select case ctxDone return case ch targetgroupGroupSource name Another potential exemplar storage option this time without messing with the Appender interface Hooking up ExemplarStorage with other components such as scrape is left for a future PR Signedoffby Callum Styan callumstyangmailcom