Dear All I have successfully installed the RHive package rhiveenv hadoop home usrhdp hadoop hadoop conf usrhdp hadoopconf fs hdfsbdcmasternovalocal hive home usrhdp hive user name shivanand user home homeshivanand temp dir tmpshivanand rhiveconnect Error orgapachehadoopsecurityAccessControlException Permission denied usershivanand accessWRITE inoderhivelib rhiveudfjarhdfshdfsdrwxrxrx I can understand the error as it says permission denied However I am not able to find the rhivelib rhiveudfjar file it is located at usrlib RlibraryRHivejavarhiveudfjar So my question is from where does it get the location of rhiveudfjar file Hello Im having an issue with the function rhiveloadtable I managed to connect to Hive and both functions rhivequery and rhivewritetable work But whenever I try to call rhiveloadtable or rhiveloadtable it returns the following error Error javasqlSQLException Error while processing statement FAILED Execution Error return code from orgapachehadoophiveqlexecmrMapRedTask Do you have any idea how to resolve this problem Thanks in advance Hi I have an HDP cluster with Tez version and Hive Im using the below configurations to connect to Hive from R SyssetenvHIVEHOMEusrhdp hive SyssetenvRHIVEDATArhivedata SyssetenvHADOOPHOMEusrhdp hadoop SyssetenvRHIVEFSHOMERHive libraryRHive rhiveinit rhiveconnecthostxxxxxxxxx port hiveServer TRUEdefaultFShdfsmycluster Im able to get the results of aggregate query correctly but the MR jobs are not listed in the Resource Manager Web UI Any suggestions are greatly appreciated Thanks installpackagesRHive Warning in installpackages package RHive is not available for R version Dependency rJava is already there because I am using rhdfs as well and it works just fine I have installed Rserve too and that works fine too These packages are installed in rootRx redhatlinuxgnulibrary In my R working directory I have cloned RHive repo used ant build and R CMD build RHive Works fine until here but it just does not install RHive It keeps saying dependencies rJava Rserve are not available for package RHive How to fix this I am on a centos system HadoopHome and Hivehome have been set correctly Is NexR going to maintain this package or should it be forkedreplaced by an independant effort I am trying to use RHive package to connect to Hive on Hortonworks Data Platform When I execute rhiveconnecthost port hiveServer TRUE I received the following error message Cannot modify mapredchildenv at runtime It is not in list of params that are allowed to be modified at runtime I inserted the following property and value in the hivesitexml file as suggested by some other posts property namehivesecurityauthorizationsqlstdconfwhitelistappendname valuemapredchildenvvalue property But i am still getting the same error Any suggestion Thanks in advance Ive created a new UDAF as per below commands hsum functionprev sal ifisnullprev sal else prev sal hsumpartial functionaggsal aggsal hsummerge functionprev aggsal ifisnullprev aggsal else prev aggsal hsumterminate functionaggsal aggsal rhiveassignhsum hsum rhiveassignhsumpartial hsumpartial rhiveassignhsummerge hsummerge rhiveassignhsumterminate hsumterminate rhiveexportAllhsum Everything was fine till then and also file hsumRData has been created in rhiveudfusername directory But then when Im using the UDAF to run query on one of my tables as rhivequeryselect RAhsum prev sal from employee It gives me error Error while processing statement FAILED Execution Error return code from orgapachehadoophiveqlexecmrMapRedTask and when I checked the log I found below exception orgapachehadoophiveqlmetadataHiveException Hive Runtime Error while processing row empid prev sal at orgapachehadoophiveqlexecMapOperatorprocessMapOperatorjava at orgapachehadoophiveqlexecmrExecMappermapExecMapperjava more Caused by orgapachehadoophiveqlmetadataHiveException javaioFileNotFoundException File rhiveudfusernamehsumRData does not exist at comnexrrhivehiveudfRUDAFGenericRUDAFloadRObjectsRUDAFjava at comnexrrhivehiveudfRUDAFGenericRUDAFiterateRUDAFjava at orgapachehadoophiveqludfgenericGenericUDAFEvaluatoraggregateGenericUDAFEvaluatorjava at orgapachehadoophiveqlexecGroupByOperatorupdateAggregationsGroupByOperatorjava at orgapachehadoophiveqlexecGroupByOperatorprocessHashAggrGroupByOperatorjava at orgapachehadoophiveqlexecGroupByOperatorprocessKeyGroupByOperatorjava at orgapachehadoophiveqlexecGroupByOperatorprocessGroupByOperatorjava at orgapachehadoophiveqlexecOperatorforwardOperatorjava at orgapachehadoophiveqlexecSelectOperatorprocessSelectOperatorjava at orgapachehadoophiveqlexecOperatorforwardOperatorjava at orgapachehadoophiveqlexecTableScanOperatorprocessTableScanOperatorjava at orgapachehadoophiveqlexecMapOperatorMapOpCtxforwardMapOperatorjava at orgapachehadoophiveqlexecMapOperatorprocessMapOperatorjava more Caused by javaioFileNotFoundException File rhiveudfusernamehsumRData does not exist at orgapachehadoopfsRawLocalFileSystemdeprecatedGetFileStatusRawLocalFileSystemjava at orgapachehadoopfsRawLocalFileSystemgetFileLinkStatusInternalRawLocalFileSystemjava at orgapachehadoopfsRawLocalFileSystemgetFileStatusRawLocalFileSystemjava at orgapachehadoopfsFilterFileSystemgetFileStatusFilterFileSystemjava at orgapachehadoopfsFileUtilcopyFileUtiljava at orgapachehadoopfsFileUtilcopyFileUtiljava at orgapachehadoopfsLocalFileSystemcopyToLocalFileLocalFileSystemjava at comnexrrhivehiveudfRUDAFGenericRUDAFloadRObjectsRUDAFjava more attempt m As I mentioned abovehsumRData has already been created in rhiveudfusername directory when I ran the export command but I still get the exception javaioFileNotFoundException File rhiveudfusernamehsumRData does not exist at comnexrrhivehiveudfRUDAFGenericRUDAFloadRObjects I am using the following version of Hive cdh with R My typical jdbc string would look something like below if I were connecting via SQL Squirrel for instance jdbchive hiveservercom defaultAuthMech principalhiveHOSTSOMEDOMAINCOM See the following error after the connect note I have a valid credential prior to invoking R repl rhiveconnecthost hiveservercom port db default user bayroot password XXXXX defaultFShdfsnameservice rhive propertieshiveprincipalhiveHOSTSOMEDOMAINCOM Warning hiveServer argument has not been provided correctly RHive will use a default value hiveServer TRUE INFO jdbcUtils Supplied authorities hiveservercom INFO jdbcUtils Resolved authority hiveservercom INFO jdbcHiveConnection Will try to open client transport with JDBC Uri jdbchive hiveservercom defaultprincipalhiveHOSTSOMEDOMAINCOM ERROR transportTSaslTransport SASL negotiation failure javaxsecuritysaslSaslException GSS initiate failed Caused by GSSException No valid credentials provided Mechanism level Fail to create credential No service creds Please note this code was working fine in CDH which was hive I believe Package RHive Type Package Title R and Hive Version Fixes issue This patch is not mine its from winghc but I also need the fix Ive tested it locally it works perfectly 