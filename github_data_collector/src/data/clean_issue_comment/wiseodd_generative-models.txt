 The generator loss diverges and does not converge Even after adding Gaussian noise to input the Gloss diverges Please Help Hey guys Im using the conditionalgan code for tensorflow version to generate garment drawings the training images is RGB png file labels are vectors like this I just changed the feeding training data from mnist to my data but the generated images are shapeless I dont know why someone helps me thanks The attached is the modified code and images generated codegenerated imageszip Hello WiseOdd I have recognise you vanilla VAE which seems pretty neat despite of the fact that does not work as I remember a Gassian noise sparse model would work I have recently read where VAE are explained quite good more or less Threre is the PDF for X described as expectation value over PZ Now when you update your parameters of the Gaussian normally the variance is a diagonal matrix of sigma So of cause one could think about a variance for each point in the dimensionality of X but I am not qute sure that is the proper common idea behind the variance of the Gaussian distribution in generative models PX frac Dz sum forall z in Z PXZ Theta PZ using this annotation the expectation for sigma based on the data would be something similar to sum forall n in N braketX muz ThetaX muz Theta right Maybe you can take a look on that code Because your variance seems to appear as a matrix instead of a value or set of values for the Gaussian noise model So did you thought explicitly about a full covariance matrix or was it just trial and error in this case If trying out expectation values for the variance let me know what your experience is regards Markus change the deprecated torchVarialbe api into torchtensor with requiresgrad true hey first of all thank you for your great job its very clear in general and helpful My first question is your loop enumerate Vs which is something completely random does it has to enumerate in Xmb My second I think in this line you have to change vs to vprime like CD if not why SystemExit usrlocallibpython distpackagesIPythoncoreinteractiveshellpy UserWarning To exit use exit quit or CtrlD warnTo exit use exit quit or CtrlD stacklevel I can see the implementation computes KL div between qzxc and pzN I but the original formulation has conditional prior pzc Can you explain why you are still using zero mean unit Gaussian prior This replaces dim tensors with item to get a Python number from the tensors containing a single value Hi Can you explain why multiply from gradient Average the gradients for p in Dsharedparameters pgraddata pgraddata 