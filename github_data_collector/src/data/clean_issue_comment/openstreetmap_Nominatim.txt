Ive just had the index creation step fail on import because Postgesql run out of disk space When rerunning the indexing I noticed that the failing index was not created again Reading up on concurrent indexes it turns out that they are not deleted but are just marked as invalid on a failure Two things we should do to mitigate this odd behaviour The create index step should delete all invalid indexes first before attempting to create new ones Our fancy new check script should check for invalid indexes and report those together with the recommendation to run indexing again Invalid indexes can be found like this SELECT FROM pgclass pgindex WHERE pgindexindisvalid false AND pgindexindexrelid pgclassoid Submitting the name of the city in Russia Ufa service returns results UEFA Route de Gen ve Village des P cheurs Nyon Switzerland which is not Ufa nor even Russia in my city a large amout of places are being associated with a small hamlet that is located tens of kilometers away outside of the city and thus completely irrelevant im wondering if this is a bug or a mapping error some of thousands of examples these are being associated at level with which is tens of kilometers away returns Integer number expected for parameter zoom I think it makes sense that empty value should be ignored since the parameter is optional The query works when the parameter is not present There is an issue that Khimki is stated as an adminstrative part of Moscow whereas in fact it is administrative unit of Moscow Region Thank you Hi I would like to know if there is a way to get multiple results in reverse queries response I have an application that allow users to get their current location address but sometimes the returned address is incorrect and I would like to allow My users to pick the correct address from a list of nearby addresses We do get a lot of reports of impatient people who try queries on an incomplete import How about adding en extended status statusphpdbyes or similar which checks that all tables and indexes or one selected tableindex for each import step are there as expected and reports if the import obviously failed Then we could add this to the import instructions as the final step and tell people to not report anything before that doesnt work Follow up on While creating index it just uses core when there are more available and takes hours more to the usual import process While checking on pgstatactivity I found the below SQL to be active for to hours CREATE INDEX CONCURRENTLY idxsearchnamenameaddressvector ON searchname USING GIN nameaddressvector WITH fastupdate off When in the Netherlands Searching for Geleen will only return the boundary relation as a city which is correct There is also a placenode added as a label for the boundary relation this node is not returned as a seperate search result which is again correct Search result can be found here But when I search for Limbricht which is also a boundaryrelation with a placenode added as the label I get search results for the relation for the placenode which in my oppinion is not correct Search result can be found here Is there anything wrong in the tagging 