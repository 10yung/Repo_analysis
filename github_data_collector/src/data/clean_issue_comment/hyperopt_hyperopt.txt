Hey I wrote an objective function for a SARIMAX model because I want to find the model with the best hyperparameters and the best external regressors in one combined step The objective function takes several integer variables and one categorical variable as an input and returns the loss of a given configuration categorical variable in reality much more regressor combinations regressorcombinations regressor regressor regressor regressor search space searchspacesarimax p hprandintp d hprandintd q hprandintq P hprandintP D hprandintD Q hprandintQ s hpchoices regressors hpchoiceregressors regressorcombinations objective function def objectivesearchspacesarimax p searchspacesarimax p d searchspacesarimax d q searchspacesarimax q P searchspacesarimax P D searchspacesarimax D Q searchspacesarimax Q s searchspacesarimax s regressors searchspacesarimax regressors create model with hyperparameters and regressors and return loss If I run hyperopt I dont receive the names of the regressors that have been chosen but a number Out D P Q d regressors p q s Is that a bug or am I missing something crucial here In the obective function the SARIMAX model takes a list of regressors as a model input so this shouldnt be the problem Thanks in advance Ive tried some combinations of the algorithms using mix but some resulted in error For instance rand atpe Pass rand tpe anneal Pass rand atpe anneal Error rand atpe tpe Error Is this expected I havent found documentation about this The error is the following Running MIX Traceback most recent call last File examplepy line in module showprogressbarFalse File homeDocumentspyvirtenvsenvpy libpython sitepackageshyperoptfminpy line in fmin rvalexhaust File homeDocumentspyvirtenvsenvpy libpython sitepackageshyperoptfminpy line in exhaust selfrunselfmaxevals ndone blockuntildoneselfasynchronous File homeDocumentspyvirtenvsenvpy libpython sitepackageshyperoptfminpy line in run selfrstaterandint File homeDocumentspyvirtenvsenvpy libpython sitepackageshyperoptmixpy line in suggest seedintrngrandint File homeDocumentspyvirtenvsenvpy libpython sitepackageshyperopttpepy line in suggest d misc for d in docs keyslistdomainparamskeys File homeDocumentspyvirtenvsenvpy libpython sitepackageshyperoptbasepy line in miscstoidxsvals assert tidxs or tidxs misc tid AssertionError Running Hyperopt and Python Here is the code python from hyperopt import hp fmin mix rand anneal atpe tpe spaceeval from functools import partial define an objective function def objectiveargs case val args printobj case val if case case return val else return val define a search space space hpchoicea case hplognormalc case hpuniformc minimize the objective over the space mixsugpartialmixsuggest psuggest randsuggest annealsuggest tpesuggest atpesuggest for desc algo in MIXmixsug print Running desc best fminobjective space algoalgo maxevals showprogressbarFalse printbest a c printspaceevalspace best case Support dynamic allocation in hyperopt integration Only throw a warning when current task slots is smaller than requested parallelism When user specify parallelism to be greater than maxnumconcurrenttasks print a warning notify user that this will trigger spark executor dynamic allocation if spark configured with dynamic allocation mode When user do not specify parallelism it will be set to maxsparkdefaultparallelism maxnumconcurrenttasks as default behavior and print a deprecation warning next released version will remove this default behavior The MongoClient call does not forward kwargs Might be ideal to just forward the uri string directly rather than trying to parse it and pass it piece by piece marctorrellas reported some flakiness with Spark tests Looking at recent master tests I see main issues The most common failure is FAIL testtaskmaxFailureswarning hyperoptteststestsparkFMinTestCase Traceback most recent call last File hometravisbuildhyperopthyperopthyperoptteststestsparkpy line in testtaskmaxFailureswarning logoutputlogoutput AssertionError sparktaskmaxFailures not found in trial task started ntrial task succeeded result is status ok loss ntrial task thread exits normally and writes results back correctly nfmin thread exits normally ndispatcher thread exits normally nTotal Trials succeeded failed cancelled sparktaskmaxFailures warning missing from log trial task started trial task succeeded result is status ok loss trial task thread exits normally and writes results back correctly fmin thread exits normally dispatcher thread exits normally Eg I saw instance of FAIL testtimeoutwithoutjobcancellationfmintimeout hyperoptteststestsparkFMinTestCase Traceback most recent call last File hometravisbuildhyperopthyperopthyperoptteststestsparkpy line in testtimeoutwithoutjobcancellationfmintimeout selfassertTruesparktrialsfmincancelled AssertionError False is not true Eg This issue is for fixing these instances of flakiness Please add other Sparkrelated ones if you see any Hello there Thanks for this awesome work I have a quick question wants to clarify inside TPE we optimize the ratio of lxgx and x is an architecture instead of maximizing EI So my question is what algorithm are you using in optimizing lxgx Evolutionary algorithm Thank you I am trying to use Hyperopt to find the best learner for my dataset on Google Colab The dataset contains both categorical and numerical values but all of them are encoded successfully While searching for the optimal classifier I also wanted to get crossvalidation scores which is builtin functionality in hyperopt However when I tried to run my code I got the following error AttributeError NoneType object has no attribute randint I could not solve the issue alone it is related to an attribute defined in the randint fuction defined in stochasticpy My code and the output are below from sklearnmodelselection import KFold crossvalscore from hpsklearn import HyperoptEstimator anyclassifier from sklearnmodelselection import traintestsplit from hyperopt import tpe hp fmin Trials import numpy as np typeaustpredictors Xtrain Xtest ytrain ytest traintestsplitaustpredictors dfausttarget trainsize testsize ytrain ytraintonumpy ytest ytesttonumpy estim HyperoptEstimatorclassifieranyclassifierclf algo tpesuggest trialtimeout estimfitXtrain ytrain printestimscoreXtest ytest printestimbestmodel cvsc crossvalscoreestim Xtest ytest cv njobs mean printcvsc Output its best loss its best loss its best loss its best loss its best loss its best loss its best loss sit best loss its best loss its best loss learner GradientBoostingClassifiercriterionfriedmanmse initNone learningrate lossdeviance maxdepth maxfeaturessqrt maxleafnodesNone minimpuritydecrease minimpuritysplitNone minsamplesleaf minsamplessplit minweightfractionleaf nestimators niternochangeNone presortauto randomstate subsample tol validationfraction verbose warmstartFalse preprocs StandardScalercopyTrue withmeanFalse withstdFalse expreprocs Empty Traceback most recent call last usrlocallibpython distpackagesjoblibparallelpy in dispatchonebatchself iterator try tasks selfreadybatchesgetblockFalse except queueEmpty frames usrlibpython queuepy in getself block timeout if not selfqsize raise Empty elif timeout is None Empty During handling of the above exception another exception occurred AttributeError Traceback most recent call last ipythoninput d dc in module printestimbestmodel cvsc crossvalscoreestim Xtest ytest cv njobs mean printcvsc usrlocallibpython distpackagessklearnmodelselectionvalidationpy in crossvalscoreestimator X y groups scoring cv njobs verbose fitparams predispatch errorscore fitparamsfitparams predispatchpredispatch errorscoreerrorscore return cvresults testscore usrlocallibpython distpackagessklearnmodelselectionvalidationpy in crossvalidateestimator X y groups scoring cv njobs verbose fitparams predispatch returntrainscore returnestimator errorscore returntimesTrue returnestimatorreturnestimator errorscoreerrorscore for train test in cvsplitX y groups zippedscores listzipscores usrlocallibpython distpackagesjoblibparallelpy in callself iterable remaining jobs selfiterating False if selfdispatchonebatchiterator selfiterating selforiginaliterator is not None usrlocallibpython distpackagesjoblibparallelpy in dispatchonebatchself iterator bigbatchsize batchsize njobs islice listitertoolsisliceiterator bigbatchsize if lenislice return False usrlocallibpython distpackagessklearnmodelselectionvalidationpy in genexpr returntimesTrue returnestimatorreturnestimator errorscoreerrorscore for train test in cvsplitX y groups zippedscores listzipscores usrlocallibpython distpackagessklearnbasepy in cloneestimator safe for name param in newobjectparamsitems newobjectparams name cloneparam safeFalse newobject klassnewobjectparams paramsset newobjectgetparamsdeepFalse usrlocallibpython distpackageshpsklearnestimatorpy in initself preprocessing expreprocs classifier regressor space algo maxevals lossfn verbose trialtimeout fitincrement fitincrementdumpfilename seed usepartialfit selfspace hyperoptpyllasapplyspace selfspace space evaledspace spaceeval if expreprocs in evaledspace selfnexpps lenevaledspace expreprocs usrlocallibpython distpackageshyperoptpyllbasepy in evalself memo else args aeval for a in selfposargs kwargs dict n aeval for n a in selfnamedargs f scopeimpls selfname memo idself rval fargs kwargs usrlocallibpython distpackageshyperoptpyllbasepy in listcomp else args aeval for a in selfposargs kwargs dict n aeval for n a in selfnamedargs f scopeimpls selfname memo idself rval fargs kwargs usrlocallibpython distpackageshyperoptpyllbasepy in evalself memo return memo idself else args aeval for a in selfposargs kwargs dict n aeval for n a in selfnamedargs f scopeimpls selfname usrlocallibpython distpackageshyperoptpyllbasepy in listcomp return memo idself else args aeval for a in selfposargs kwargs dict n aeval for n a in selfnamedargs f scopeimpls selfname usrlocallibpython distpackageshyperoptpyllbasepy in evalself memo return memo idself else args aeval for a in selfposargs kwargs dict n aeval for n a in selfnamedargs f scopeimpls selfname usrlocallibpython distpackageshyperoptpyllbasepy in listcomp return memo idself else args aeval for a in selfposargs kwargs dict n aeval for n a in selfnamedargs f scopeimpls selfname usrlocallibpython distpackageshyperoptpyllbasepy in evalself memo kwargs dict n aeval for n a in selfnamedargs f scopeimpls selfname memo idself rval fargs kwargs return rval usrlocallibpython distpackageshyperoptpyllstochasticpy in randintupper rng size assert lenupper size return npasarray rngrandintuu for uu in upper return rngrandintupper sizesize AttributeError NoneType object has no attribute randint What is the lowest Spark version compatible with running Hyperopt in parallel on Spark Currently there is no place in the documentation that I could find My EMR cluster runs Spark hpuniformintfunction description should be added to wiki at this place This is an idea build on easyas suggested here I suppose this potentially leads into a broader discussion about progress monitoring of the optimization process For example there is currently no easy way to cancel the optimization process without access to the Trials object or a mechanism for monitoring no improvement in a while or even monitoring losses outside the main objective A more robust callback system in general with hooks into various steps of the optimization process would be extremely useful Something kind of like this comes to mind python class Callback def onoptimizationstartself trials def onoptimizationendself trials def ontrialstartself trials trial def ontrialendself trials trial I can think of a handful of things this could be used for Early stopping when there is insufficient improvement Early stopping when a threshold is passed Monitoring other properties of the trial object that are not the loss Custom progress monitoring that sends status information via HTTP to another service Custom progress bars with options for more than just a best loss f postfix I can technically do all of that myself but it requires calling fmin for a single iteration and handling all externally which is not a great option in a distributed context This should probably be opened as a separate issueenhancement I also dont mind taking the development of this on but it will have to wait until later this month