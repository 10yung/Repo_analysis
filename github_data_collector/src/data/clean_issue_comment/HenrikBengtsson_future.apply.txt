Is futurelapply intended to be nonblocking I thought it was but its not working for me Here is a minimal reproducible example with a simple function that serves no purpose except to take seconds to evaluate on my machine so I could test blocking and multicore behavior Im running Linux so my understanding is that multiprocess here implies multicore Output shown as comments r futurelapply blocks even in multiprocess You can see that resolved does not get evaluated until futurelapply has finished But it successfully distributes this across cores planmultiprocess date Fri May a futurelapplyrep functioni rnormirnormi resolvedfutureOfa Error Future a not found in environment RGlobalEnv a date Fri May heada date Fri May Note that I get an error when trying to call resolvedfutureOfa because a has already been resolved before it gets called and no future exists because it was implicit The calls to date are in there to show that it blocked for seconds while it was evaluating futurelapply Based on your response in I tried assigning futurelapply as an implicit future and using nested multiprocess evaluation though that was intended for someone running SGE This also blocks and now futurelapply is evaluated sequentially not on multiple cores I watched process allocation happening but you can see that it now blocks for twice as long seconds r Try nesting it in an implicit future call Still blocks But now this gets evaluated sequentially rather than distributed across cores planlistmultiprocess multiprocess date Fri May a futurelapplyrep functioni rnormirnormi resolvedfutureOfa FALSE date Fri May heada date Fri May I ran into this issue because Im trying to switch from mclapply to futurelapply for the great parallel RNG and I do get nonblocking behavior using an implicit future with mclapply resolved and date are both executed immediately after the mclapply call without blocking r This works as expected Setting mccores explicitly does distribute across multiple cores and its nonblocking libraryparallel planmultiprocess date Fri May a mclapplyrep functioni rnormirnormi mccores resolvedfutureOfa FALSE date Fri May heada date Fri May Incidentally if I replace the call to explicitly set mccores with mccoresfutureavailableCores I still get nonblocking behavior but now mclapply gets executed sequentially instead of being distributed across cores If I run mccoresfutureavailableCores I get Im not sure if this is a bug and I didnt explore it thoroughly but its not what I expected Thanks so much for your help and for all your work to bring R into the future This was a bit hard to track down Here goes datatable and bit both have setattr functions But the annoying thing about bitsetattr is that it returns NULL datatablesetattr returns the input object with the attribute modified invisibly So if you were to write a code like r y setattr L class Date todays date Im not saying this is how one should go about it but there are other cases where we need to set an attribute and assign the result to an object In this case depending on what setattr weve itll return the right expected result or NULL With this consider this code r requireparallel requiredoSNOW requireforeach requirefuture requirefutureapply requiredatatable foo functiondt catsprintf s s Sysgetpid captureoutputenvironmentsetattr sep n setattrdt key val nodes L cl futuremakeClusterPSOCKnodes plancluster workerscl persistentTRUE dt datatablex y ans values lapplyseqlennodes functionnode futurefoodt packagescbit datatable environment namespacedatatable environment namespacedatatable environment namespacedatatable environment namespacedatatable environment namespacedatatable Ive created a datatable in the local environment just for simplicity and am calling a function that sets the attribute in parallel Of course this function is terribly simplified as well Now the way this works as expected is to first load bit first and datatable next and then look for functions in foo and possibly load more packages and then run foo AFAICT And this works fine as you can see from the output If you were to check ans youd get the datatable with their attributes set Restart session IMPORTANT Now with everything else remaining intact if instead of running values I use futurelapply r ans futurelapplycl functionnode foodt futurepackagescbit datatable ans futurelapplycl functionnode foodt futurepackagescbit datatable environment namespacebit environment namespacebit environment namespacebit environment namespacebit environment namespacebit ans NULL NULL NULL NULL NULL Note how setattr refers to bit package I think this is because the packages get loaded after assessing setattr is used in foo and datatable from local env has a function called setattr and therefore gets loaded first followed by all packages in futurepackages r requireparallel requiredoSNOW requireforeach requirefuture requirefutureapply nodes L cl futuremakeClusterPSOCKnodes plancluster workerscl persistentTRUE foo functioni if i in Syssleep L i x systemtimeans futurelapplyx functioni msg sprintf s f ans f ascharacterSystime Sysgetpid i catmsg sep n ans fooi ans ans ans ans ans predefined chunk node wait until previous one completes ans predefined chunk node wait until previous one completes ans predefined chunk node wait until previous one completes ans predefined chunk node wait until previous one completes ans ans ans ans ans ans ans ans ans ans ans ans user system elapsed x more time registerDoSNOWcl systemtimeans foreachix dopar msg sprintf s f ans f ascharacterSystime Sysgetpid i fooi fooi returnmsg ans ans ans ans ans runs on next available free node ans ans ans ans ans ans ans ans ans ans ans ans ans ans ans user system elapsed results in times lesser runtime The point is even if things are random I understand theres orderingrandom there can be chunks that get stuck due to a big job when other nodes are potentially free I think its much more efficient to look for free nodes and assign jobs on the fly than to determine chunk sizes entries upfront What do you think The example shown below should be quite straightforward to follow The parallel case doesnt seem to be able to find the global var xa r packageVersionfuture packageVersionfutureapply requirefuture requirefutureapply foo functionxgetOptionxa L ygetOptionxb L x y plansequential futurelapply functioni foo planmultisession workers L futurelapply functioni foo optionsxa L plansequential futurelapply functioni foo planmultisession workers L futurelapply functioni foo I came across this behaviour while trying to understand the issue in my original scenario which is slightly different Ive a package say PKG which has a function say FOO as follows FOO functionxMYGLOBLALSx yMYGLOBALSy x y Then the sequential case works fine but multisession parallel version fails to find x and y defaults when run with the following code r requirefuture requirefutureapply requirePKG has function FOO MYGLOBALS listx L y L planmultisession workers L futurelapply functioni FOO has to extract the default values from the variable MYGLOBALS in the global environment Error in FOO object MYGLOBALS not found session info r sessionInfo R version Platform x w mingw x bit Running under Windows Server x build locale LCCOLLATEEnglishUnited Kingdom LCCTYPEEnglishUnited Kingdom LCMONETARYEnglishUnited Kingdom LCNUMERICC LCTIMEEnglishUnited Kingdom attached base packages stats graphics grDevices utils datasets methods base other attached packages futureapply future loaded via a namespace and not attached parallel tools listenv codetools digest globals Ive been using futurelapply to submit jobs to a cluster of gcloud compute nodes which is awesome Thanks so much for adding this userfriendly function One issue Im running into however concerns the behavior when one of my gcloud compute nodes goes down unexpectedly Heres what I see Error in unserializenodecon Failed to retrieve the value of ClusterFuture from cluster node on The reason reported was error reading from connection Calls futurelapply FutureRegistry collectValues value valueClusterFuture Execution halted Is there a good way to catch these errors for individual nodes so that I can still access results from the nodes which are still executing IE can we pass an onerror function to call to valuesfs For now I have wrapped these in a call to withCallingHandlers to catch ignore this error I havent tested it in a reallife situation but assuming it works this may be something to include in your vignette Common Issues with Solutions The code currently looks like something the following withCallingHandlers remotejobs futurelapplyseqlennumdatasims executesimtest futureseed xBEEF futurescheduling FutureError functione NULL mllg wrote Have you considered to introduce a control object in the fashion of passing a rpartcontrolobject to rpart A futurecontrolobject could bundle all arguments Would be good for the overview also in the documentation and Yes Ive been having internal as in lots of inner voices debates about this and its been discussed with other in the past Im not opposed to it The main reason Ive stayed away from it is that we have to deside exactly how the control elements should be controlled you would avoid inconsistencies like Youre meaning in the sense that the futureapply package and other similar highlevel packages eg furrr wont have to know about futurespecific arguments and can just pass whatever down to the future package Thats a nice side effect I havent thought of before However not all elements in futurecontrol should be passed down to the future package For instance scheduling and chunksize are higher level properties If so do they belong to a futurecontrol argument or should they be separate So several things to think of Thanks for bringing this up from an old note of mine Add support for generating seeds per chunk future i addition to per element as now Although not invariant to the number of workers and therefore not numerically reproducible if nbrOfWorkers vary this will still be statistically sound The advantage is performance the number of seeds that need to be pregenerated will be significantly lower when theres a large number of elements What should the API be ie how to specify that we want it per chunk without introducing more arguments Would futureseed per chunk vs futureseed per element TRUE as now Then what about seed numeric for specifying an initial seed which now gives per element seeds Hmm In futureapply futurelapplyX searches also X for possible globals Issue For long Xs this introduces a significant overhead especially if X does not contain any globals and we wouldnt have to search X in the first place For example r X vectorlist length e y futurelapplyX FUN identity All the slowness comes from an internal r gp futuregetGlobalsAndPackagesX globals TRUE Following the code this is slow because r names globalsfindGlobalsX is slow which in turn is because it effetively does r names lapplyX FUN globalsfindGlobals We might be able to speed up globalsfindGlobals a bit here but dont know how much UPDATE there was a lowhanging fruit in the globals package making it possible to speed this up lots cf Ill be running revdep checks on globals first and and second generation dependencies to make sure this doesnt break anything If all ok the need for working around this in futureapply is much smaller Regardless there could be a need for an argument controlling whether X should be searched for globals or not especially since it is likely that in most use cases X does not have globals Kind of an obscure issue but definitely an issue r libraryfutureapply plansequential futurelapply X FUN functionx y futureglobals listy Error in futureFUNfutureXjj object y not found z futurelapply X FUN functionx y futureglobals listy z Error in futureFUNfutureXjj object y not found Created on by the reprex package v Interestingly the y value is recognized as a global and makes it into the environment that the expression is evaluated in You can see this by debugging and making your way to this line of runUniprocessFuture Not sure why it cant be seen inside the lapply after that