Events and Snapshots are wrapped in some Akka classe The goal is to unwrap because those classes were never intended to serialized and saved to DB There is a branch in which this was fixed by James original PR However we may not integrate it into master and start over again The main reason is that the PR is done as such that allows users to keep the old column and have mixed mode in which old data is kept around using the wrappers and new data is saved unwrapped This strategy amounts to the complexity of the code plus the functionality is enableddisabled by flags Instead our current goal is to provide a new schema and a migration tool to allow previous journals to be migrated That means that users moving to will have to shutdown the system run the migration and restarting using the new version This is broken down in a three main tasks Journal Store refactoring Snapshot Store refactoring Migration tool The initial goal is to provide a tool based on FlyWay Enno has done some initial experiments and we are confident that its flexible and powerful enough to run all the migrations we need This will be a oneshot tool that will execute all the migration steps from x to We are not using FlyWay because we want to keep around a table with all applied migrations Users may delete the table if they want The reason is to use its migration functions The current migrations are The first migration is the creation of the new tables journalmessages tags and snapshots Users should be able to tweak the name of those tables This is an existing feature in the plugin and we need to keep it Note This is for users coming from x New users create the tables by themselves Migrate Snapshots to new table ie snapshots and unwrap the payload Migrate Events to new table ie journalmessages and unwrap payload When migrating the date the timestamp column must be filled with begin of epoch Move tags to its own table ie tags onetomany with Events table and split content currently commaseparated values Ideally we should be able to run the migration tool without adding custom serializers We should be able to read the byte array remove the current header and save only the snapshotevent payload back This need to be confirmed though Like the journal store the new snapshot will have a few more fields serid Int sermanifest String snapshotpayload String We need to refactor the Snapshot DAO for that new format The current table is snapshot Because we dont want destructive migrations we can add a new schema table called snapshots New users can just start using it from version onward Existing users will need to run the migration procedure to copy their data from snapshot to snapshots ByteArraySnapshotSerializer should be moved to the migration module as we will need it for running migrations reading old data from snapshot table The new journal store table will have a few more fields serid Int sermanifest String eventmanifest String eventpayload String writeruuid String timestamp column see Useful for metrics about readside processors lagging The timestamp will be addes as Long and defaulting to We need to refactor the Journal DAO for that new format The current table is called journal Instead of altering it we will design a new table structure and call it journalmessages New users can just start using it from version onward Existing users will need to run the migration procedure to copy their data from journal to journalmessages ByteArrayJournalSerializer should be moved to the migration module as we will need it for running migrations reading old data from the journal table Next to the journal table we need a tags table There is a onetomany relation between the two tables One event can have zero or more tags The Journal DAO must take this into account and execute inserts on both tables atomically Events by tag queries need to be refactored to consider the new tags table If you have a Lightbend Subscription please reach out via the Lightbend Portal Otherwise please use the discussakkaio forum for questions instead of posting them to the issue tracker Akka is introducing a timestamp in the EventEnvelope This will be very useful to calculate lags when consuming events We should add a migration that introduces a new column to safe the timestamp The default in Akka is being set to L begin of epoch ignasi pvlugter ygree If you have a Lightbend Subscription please reach out via the Lightbend Portal Short description The Oracle JDBC driver is now available from Maven Central and can be used instead of the jar from lib Short description Detect if this plugin of the old x series is on the classpath and make it fail if so Details As the group ID changes to comlightbendakka users may end up with two versions of this plugin on their classpath Find a way to detect that and fail Updates orgscalatestscalatest from to Release NotesChangelog Ill automatically update this PR to resolve conflicts as long as you dont change it yourself If youd like to skip this version you can just close this PR If you have any feedback just mention me in the comments below Have a fantastic day writing Scala details summaryIgnore future updatessummary Add this to your scalastewardconf file to ignore future updates of this dependency updatesignore groupId orgscalatest artifactId scalatest details details summaryApplied Migrationssummary details labels semverminor scalafixmigrations Short description By tagging the tests with the database they use the jobs could be split per database type Im not sure if that would be any faster