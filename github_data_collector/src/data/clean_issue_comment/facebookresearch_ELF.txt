I am having quite a bit of trouble trying to create a minimum working example for the RTS game in which I can get a single state visualize its variables and pass an action back to the environment I took a look at the Basic Usage section of the READMEmd but it looks like the code is not supposed to be used just interpreted as pseudocode For example I dont know where functions such as Init come from or what is the type and attributes of the context variable I then took a look at trainpy and evalpy which use the RTS but the code is highly abstracted and everything is passed as dictionaries whose values dont seem to have an explicit documentation Also these scripts dont show how a user can get a state and return an action to the environment or how to work with batches The closest I came to an answer was the documentation of the Python wrapper The page explicitly mentions variables with names such as s pi r a which I believe are states rewards actions and policies but there is not a full example depicting how to get to these values only code excerpts which must be pieced together and make no sense on their own I believe the project could benefit greatly from a documented minimum working example guiding users on creating their own agent Maybe create a random agent for the RTS game which others can then replace for their own agents I would like to add that I was able to compile the project and run the train and eval examples both on CPU and GPU on Python under Linux My frustration comes from being unable to customize anything This PR aims to fix the CI build of the repo on Travis I have listed my findings on Basically Tower Defense TD and Capture the Flag CF are not compiling since October due to a commit that made breaking changes in the elf base library in order to add features to the main RTS game MC It looks to me as though TD and CF are abandoned so Ive fixed the build of the MC module which was also broken for a different reason on travisyml and created this PR to discuss what to do with TD and CF I was trying to fix the CI build I noticed that an error occurs in the travisyml file in the following lines mkdir rtsbuildMC cd rtsbuildMC cmake DGAMEDIRgameMC make mkdir rtsbuildCF cd rtsbuildCF cmake DGAMEDIRgameCF make mkdir rtsbuildTD cd rtsbuildTD cmake DGAMEDIRgameTD make The first line had a problem related to using the wrong Python executable so I fixed it by pointing it towards what looks like the right executable inside the Travis container using DPYTHONEXECUTABLEoptpyenvshimspython The following two lines however are attempting to compile the contents of the buildCF and buildTD directories which appear to have incomplete files Can anyone tell me what these directories contain In this PR Ive deleted all mentions to the async keyword in the master branch of ELF to resume compatibility of the repository with Python ELF uses async as a name for variables and function parameters In Python async has become a reserved word The word is only used as argument to the copy and cuda methods which are methods from the pytorchTensor object But these methods dont use the value of the async argument for anything By removing mentions to the nowreserved keyword no change in the behavior of the package is expected Ive tested training a model using trainminirtssh on Python with both CPU and GPU and everything worked I believe this fixes and I created a new PR because I used my master branch as the head repository in which was a bad idea on my side HICan you provide the code for pytorch version When I trained I found that the computer memory occupancy was increasingI dont know what the problem is Now there is only selfplay or training with AISIMPLE If I want to train with different type RL models eg a player using ppo and the other one using A C how can I deal with it I started training miniRTS like weeks ago Without interrupting for now I have just the last part pasted trainer actor count newrecord False count bestwinrate strwinrate Win rate Best win rate straccwinrate Accumulated win rate its Iter Save to Filename save bin Command arguments trainpy batchsize frequpdate players typeAINNfs argsbackupAISIMPLEstart decay typeAISIMPLEfs numgames tqdm T additionallabels idlastterminal trainerstats winrate keysinreply V gpu Time spent ms actor train Verr avg min max accreward avg min max cost avg min max entropypi avg min max initreward avg min max nllpi avg min max predictedV avg min max reward avg min max totalentropy avg min max totalnll avg min max trainer actor count newrecord False count bestwinrate strwinrate Win rate Best win rate straccwinrate Accumulated win rate For now I do not now if there is any soft option to finish in current state to get result for research Info about workstation Memory GiB CPU Intel Core i GHz x FeForce GTX GB GDDR bit OS Ubuntu LTS async is a reserved word in Python So I think change install instruction like the following conda create n elf python or x or change parameter nameasync to the other Hi thanks for this great project I was wondering that which version of pytorch should I use for atari I use and it works well for minirts But when I eval atari breakoutbin with pretrained model these messages would appear Load from homeubuntuataribreakoutbin homeubuntuminiconda envselflibpython sitepackagestorchserializationpy SourceChangeWarning source code of class modelModelActorCritic has changed you can retieve the original source code by accessing the objects source attribute or set torchnnModuledumppatches True and use the patch tool to revert the changes warningswarnmsg SourceChangeWarning Traceback most recent call last File evalpy line in module model env modelloaders loadmodelGCparams File homeubuntuELFrlpytorchmodelloaderpy line in loadmodel modelloadselfload omitkeysomitkeys File homeubuntuELFrlpytorchmodelbasepy line in load data torchloadfilename File homeubuntuminiconda envselflibpython sitepackagestorchserializationpy line in load return loadf maplocation picklemodule File homeubuntuminiconda envselflibpython sitepackagestorchserializationpy line in load result unpicklerload ModuleNotFoundError No module named rlmethodcommon I guess this is because I use a wrong pytorch version for atari And if I use a model trained by myself it will just get stuck in I dont use a GPU for atari Running ROM file Random seed is Action set Version f cd d f b beb ec d staged Num Actions recvthread Group Collector Batchsize Info gid T name Collector Batchsize Info gid T name Collector Batchsize Info gid T name Collector Batchsize Info gid T name Load from homeubuntusave bin Loaded homeubuntusave bin its 