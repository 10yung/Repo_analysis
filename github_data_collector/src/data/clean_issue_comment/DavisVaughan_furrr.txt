I found the reason accounting for a large part of the lower performance of furrr vs purrr All libraries are loaded in each individual furrrfuturemap process eg Loading required package dplyr Attaching package dplyr I understand that each furrr process requires loading the libraries but my more pressing question is Why cant furrr access the libraries loaded in the global environment Or in other words Is there a way to assign libraries to the multicoremultisessionmultiprocess cluster analoge to how multidplyr does it The multidplyr is rather intuitive for that cluster newcluster clusterlibrarycluster dplyr They are quite hard to suppress see Should it be message Investigate other packages like progress It seems like when you use furrr as part of a package development process you need to reinstall the package to pass the right functions down to the workers Ive set up an example package to demonstrate this behaviour as a user my expectation is that the version of the function passed to the worker is the same one that I have loaded after running devtoolsloadall Thanks for the great package I have available cores and even when set explicitly to use most of them I still see activity in only every other one availableCores system requirefurrr planmultiprocess workers Is this due to the way Mac OS X reports or am I doing something wrong with how Im specifying how furrr should run MacOS Mojave sessionInfo R version Platform x appledarwin bit Running under macOS Mojave OS Windows R furrr future Putting a function into a list and then passing it into futuremap apparently causes it to not find functions appropriately r libraryextraDistr suppressPackageStartupMessageslibrarypurrr suppressPackageStartupMessageslibraryfurrr planmultiprocess Innermost function which uses something from a package innerfun function rbern from extraDistr A function that calls another which is passed to it in a list wrapperfun functionfunlist funlistsimfun A list of functions listoffuns listsimfun innerfun Will work map functioni wrapperfunlistoffuns Will fail to find rbern futuremap functioni wrapperfunlistoffuns Error in rbern could not find function rbern supCreated on by the reprex package v sup I am currently using mapdfr on a jsonlitefromJSON command I was able to run my script from the Rstudio IDE from the command line and scheduling a cron job that runs the API alone by itself However when I put the API call inside a function to call from futuremapdfr it failed but the same call was successful with just mapdfr Any insights about this issue would be helpful I know its bad practice to alter the working directory but sometimes folks do and its causing problems with one of our packages that generates and saves files to the working directory using furrrfuturemap The problem appears to be because getwd in futuremap refers to the wrong directory as evidenced by the fact that getwd in futuremap refers to a different directory than getwd in purrrmap r dir filepathtempdir sub setwddir printdir purrrmap f functionx getwd furrrfuturemap f functionx getwd printgetwd I encounter this basic pattern all the time I want to iterate over a large queue each item yielding an output that I want to eventually write to a file eg lines of JSON or CSV chunks to HDF etc The output is large so I dont want to keep the accumulating returned values in memory and writing interim values to a file either a tempfile I concatenate later or appendTRUE would be appropriate but I have to safely parallelize Writing a small file to disk for every element of x and then combining them all later tends to be costly in disk IO and Ill admit that I never knew how large a headache could be created by writing M files to the same folder on a Mac A happy medium might look like this if a worker always has its own stable PID for N workers I generate N files and append all results for individual x elements handled by that worker to that file Then outfilePIDcsv has no chance of corruption from multiple writes but we still get dramatically fewer intermediate files to concatenate Heres an example of what I mean r librarytidyverse libraryfurrr planmultisessionworkers setseed testx rpois testfunc functionx pid Sysgetpid somedata jsonlitetoJSONlistnorm rnorm mean x sd x writelinesx somedata path paste outfile pid json append TRUE invisiblex furrrfuturemaptestx testfunc That snippet works fine but it depends on workers having stable independent PIDs and Im not sure if thats a globally true assumption about future workers The magic of futurefurrr has been that I need not think too much about the nature of those workers Do you know if this is likely to be a safeenough pattern for cases like this progress T does not seem to display correctly when using futuremap functions inside mutate functions for nested list columns They just pop up at after the mutate is complete Hi Im working a lot with furrr inside Rstudio planmultiprocess However this is now kicked by rstudio because of stability reasons the error I now get is ONETIME WARNING Forked processing multicore is disabled in future when running R from RStudio because it is considered unstable Because of this planmulticore will fall back to plansequential and planmultiprocess will fall back to planmultisession not planmulticore as in the past For more details how to control forked processing or not and how to silence this warning in future R sessions see futuresupportsMulticore when switching to planmultisession a whole lot of things no longer work Any clue how to fix this