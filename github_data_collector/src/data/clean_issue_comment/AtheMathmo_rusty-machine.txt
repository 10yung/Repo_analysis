Mish is a novel activation function proposed in this paper It has shown promising results so far and has been adopted in several packages including TensorFlowAddons Tok Vec Layer SpaCys official NLP based ML library Eclipses deeplearning j AI CNTKX Extension of Microsofts CNTK Yolov Library in C dnet DL S Transformers OpenCV DNN Efficient Segmentation Networks Semantic Segmentation DLib PyWick All benchmarks analysis and links to official package implementations can be found in this repository Mish also was recently used for a submission on the Stanford DAWN Cifar Training Time Benchmark where it obtained accuracy in just seconds which is the current best score on GPU and second fastest overall Additionally Mish has shown to improve convergence rate by requiring less epochs Reference Mish also has shown consistent improved ImageNet scores and is more robust Reference Additional ImageNet benchmarks along with Network architectures and weights are avilable on my repository Summary of Vision related results Capture It would be nice to have Mish as an option within the activation function group This is the comparison of Mish with other conventional activation functions in a SEResNet for CIFAR se I get the error message from the title of this issue Its not very informative what exactly the problem is or how i can fix this I dont know if this is a problem in my code or in the library code Code Terminal RUSTBACKTRACE cargo run Compiling rust v homeflip titaniclinear regressionrust Finished dev unoptimized debuginfo targets in s Running targetdebugrust thread main panicked at assertion failed left right left right homeflip cargoregistrysrcgithubcom ecc db ec rulinalg srcvectorrs stack backtrace backtracebacktracelibunwindtrace at cargoregistrysrcgithubcom ecc db ec backtrace srcbacktracelibunwindrs backtracebacktracetraceunsynchronized at cargoregistrysrcgithubcom ecc db ec backtrace srcbacktracemodrs stdsyscommonbacktraceprintfmt at srclibstdsyscommonbacktracers stdsyscommonbacktraceprintDisplayBacktrace as corefmtDisplayfmt at srclibstdsyscommonbacktracers corefmtwrite at srclibcorefmtmodrs stdioWritewritefmt at srclibstdiomodrs stdsyscommonbacktraceprint at srclibstdsyscommonbacktracers stdsyscommonbacktraceprint at srclibstdsyscommonbacktracers stdpanickingdefaulthookclosure at srclibstdpanickingrs stdpanickingdefaulthook at srclibstdpanickingrs stdpanickingrustpanicwithhook at srclibstdpanickingrs stdpanickingcontinuepanicfmt at srclibstdpanickingrs stdpanickingbeginpanicfmt at srclibstdpanickingrs rulinalgvectorVectorTelemul at homeflip cargoregistrysrcgithubcom ecc db ec rustymachine stdmacrospanic macros rustymachinelearningtoolkitcostfnCrossEntropyError as rustymachinelearningtoolkitcostfnCostFuncrulinalgvectorVectorf cost at homeflip cargoregistrysrcgithubcom ecc db ec rustymachine srclearningtoolkitcostfnrs rustymachinelearninglogisticregBaseLogisticRegressor as rustymachinelearningoptimOptimizablecomputegrad at homeflip cargoregistrysrcgithubcom ecc db ec rustymachine srclearninglogisticregrs rustymachinelearningoptimgraddescGradientDesc as rustymachinelearningoptimOptimAlgorithmMoptimize at homeflip cargoregistrysrcgithubcom ecc db ec rustymachine srclearningoptimgraddescrs rustymachinelearninglogisticregLogisticRegressorA as rustymachinelearningSupModelrulinalgmatrixMatrixf rulinalgvectorVectorf train at homeflip cargoregistrysrcgithubcom ecc db ec rustymachine srclearninglogisticregrs rustrun at srcmainrs rustmain at srcmainrs stdrtlangstartclosure at rustc ea cb f a c e f srclibstdrtrs stdrtlangstartinternalclosure at srclibstdrtrs stdpanickingtrydocall at srclibstdpanickingrs rustmaybecatchpanic at srclibpanicunwindlibrs stdpanickingtry at srclibstdpanickingrs stdpaniccatchunwind at srclibstdpanicrs stdrtlangstartinternal at srclibstdrtrs stdrtlangstart at rustc ea cb f a c e f srclibstdrtrs main libcstartmain start I wanted to try rust for some data analysis after getting started with python In scikit there saw there is a OneHotEncoder which is useful for categorical data Could such encoder be considered for rustymachine I would avoid having to write a bunch of boilerplate code By the way i saw that the rust bindings for tensorflow have an open issue for the same thing The scikit OneHotEncoder is not the perfect design in my opinion but still its nice to have one Perhaps a different design would be more suitable for rustymachine Use sliceiter instead of intoiter to avoid future breakage anarrayintoiter currently just works because of the autoref feature which then calls T as IntoIteratorintoiter But in the future arrays will implement IntoIterator too In order to avoid problems in the future the call is replaced by iter which is shorter and more explicit A crater run showed that your crate is affected by a potential future change See for more information I am using the logit model use rustymachinelearninglogisticregLogisticRegressor and I would like to get corresponding pvalues and error rates for the coeffs my model looks like LogisticRegressor base BaseLogisticRegressor parameters Some Vector size data alg GradientDesc alpha iters how do I know which of theses parameters are statistically significant Prevent recursion stack overflow and make fewer allocations on large dbscan clusters This enables the use of rustymachine inside of WASM Thanks I can see that Stochastic Gradient Descent has already been implemented But linear regression works using simple gradient descent What are the challenges to implementing SGD for Linear Regression SGD implementation I get a sigkill when training on a x matrix Trying to run pca gives the following error use rustymachinelearningpcaPCA could not find pca in learning In case we are yet working on implementing pca the docs should say that