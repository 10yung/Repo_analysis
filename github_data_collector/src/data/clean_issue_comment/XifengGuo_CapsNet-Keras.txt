My problem I have a program which implements your capsule network to classify images The images are divided into three categories so it is a three way classification task I use data generators to feed data to the capsule net model but it throws up the error given below I have been stuck with this error for a long time I have found some solutions to these types of problems but they all involve in using the fit method belonging to the Sequential model api of keras My understanding of the usage of fit method tells me that I would have to pass my data in some format as to satisfy the arguments of x and y of the fit method I tried making a list of all the images I had by reading them using keraspreprocessingimageloadimg into a list but I quickly found out that I wont be able to accomplish the task this way as I ran into memory errors while making the list If someone could help me with this I would be extremely grateful My data set Two folders one for training images and one for testing images Further both of them are divided into three subfolders each namely Type Type and Type The error Im getting ValueError Error when checking model input the list of Numpy arrays that you are passing to your model is not the size the model expected Expected to see arrays but instead got the following list of arrays array Here is the partial code that I modified def CapsNetinputshape nclass routings x layersInputshapeinputshape conv layersConv Dfilters kernelsize strides paddingvalid activationrelu nameconv x Layer Conv D layer with squash activation then reshape to None numcapsule dimcapsule primarycaps PrimaryCapconv dimcapsule nchannels kernelsize strides paddingvalid Layer Capsule layer Routing algorithm works here digitcaps CapsuleLayernumcapsulenclass dimcapsule routingsroutings namedigitcapsprimarycaps Layer This is an auxiliary layer to replace each capsule with its length Just to match the true labels shape outcaps Lengthnamecapsnetdigitcaps Decoder network y layersInputshapenclass maskedbyy Mask digitcaps y The true label is used to mask the output of capsule layer For training masked Maskdigitcaps Mask using the capsule with maximal length For prediction Shared Decoder model in training and prediction decoder modelsSequentialnamedecoder decoderaddlayersDense activationrelu inputdim nclass decoderaddlayersDense activationrelu decoderaddlayersDensenpprodinputshape activationsigmoid decoderaddlayersReshapetargetshapeinputshape nameoutrecon Models for training and evaluation prediction trainmodel modelsModel x y outcaps decodermaskedbyy evalmodel modelsModelx outcaps decodermasked manipulate model noise layersInputshapenclass noiseddigitcaps layersAdd digitcaps noise maskednoisedy Mask noiseddigitcaps y manipulatemodel modelsModel x y noise decodermaskednoisedy return trainmodel evalmodel manipulatemodel def marginlossytrue ypred L ytrue KsquareKmaximum ypred ytrue KsquareKmaximum ypred return KmeanKsumL traindatadirectory restOfThePathtrainroi testdatadir restOfThePathtestroi traindatagen ImageDataGeneratorrescale testdatagen ImageDataGeneratorrescale trainmodel evalmodel manipulatemodel CapsNetinputshape nclass routings compile the model trainmodelcompileoptimizeroptimizersAdamlr loss marginloss mse lossweights metricscapsnet accuracy trainmodelsummary traingenerator traindatagenflowfromdirectorytraindatadirectory targetsize batchsize classmodecategorical shuffleTrue testgenerator testdatagenflowfromdirectorytestdatadir targetsize batchsize classmodecategorical shuffleTrue trainmodelfitgeneratortraingenerator validationdatatestgenerator validationsteps validation data sizebatch size placeholder values given epochs placeholder values given stepsperepoch train data size batch size placeholder values given verbose What ways exists for optimizing the speed of the trainingtesting of CapsNet Can Nvidias TensorRT framework optimize the interference of CapsNet Would CapsNet with EM routing help anything in this regard Ran multigpu training over cards for epochs This was a significant amount of training As saving of the model is only done after the train step any errors in the meantime which lead to program failure result in no saved model For any training done over SSH or in a screen with no XSession or forwarded session plotlog will fail at the end of training There is no error handling around this line nor any warning on program start that you require an XSession This should not be the case and UI should entirely be optional at the conclusion of training I suggest wrapping the plotlog in try except and ask for forgiveness as is the python way In addition it may be prudent to add a Snapshotesque callback similar to how tensorboards are done such that users can have more finegrain control over their saving schedule and not lose any progress due to unforeseen events Traceback python Traceback most recent call last File capsulenetmultigpupy line in module trainmodelmultimodel dataxtrain ytrain xtest ytest argsargs File capsulenetmultigpupy line in train plotlogargssavedir logcsv showTrue File homeashleyGitHubTestsCapsNetKerasutilspy line in plotlog fig pltfigurefigsize File homeashleyvirtualenvsnightlylibpython sitepackagesmatplotlibpyplotpy line in figure kwargs File homeashleyvirtualenvsnightlylibpython sitepackagesmatplotlibbackendbasespy line in newfiguremanager return clsnewfiguremanagergivenfigurenum fig File homeashleyvirtualenvsnightlylibpython sitepackagesmatplotlibbackendsbackendtkpy line in newfiguremanagergivenfigure window TkTkclassNamematplotlib File usrlib python tkinterinitpy line in init selftk tkintercreatescreenName baseName className interactive wantobjects useTk sync use tkinterTclError couldnt connect to display localhost How to save the trained model including weights I can pickle and save the model on disk but afterwards when I try to unpickle the saved file it fails It complains about a custom layer in the capsnetmodel Any help would be highly appreciated Hello I am using custom dataset with imagesHaving classes each contain images The dataset is divided to training and testing examples The input to the model is I trained the model using learning rate respectively with epoch batchsize and adam optimizer But the valcapsnetaccuracy did not improved from Why it is happened Should I increase number of images in my dataset Or any other changes in parameters or network can help me