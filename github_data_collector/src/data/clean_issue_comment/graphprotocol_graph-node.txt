Brendan on Discord reported this This works graphql query poolContractsDrawQuerypoolAddress ID drawId String winnerAddress String first Int skip Int poolContractid poolAddress block number This doesnt graphql query poolContractsDrawQuerypoolAddress ID blockNumber Int drawId String winnerAddress String first Int skip Int poolContractid poolAddress block number blockNumber Message Invalid value provided for argument blocknumber VariableblockNumber Location object Object Path undefined This also gets rid of all stored procedures that still refer to subgraphsentities This bumps Graph CLI in the one integration test we have and updates the test environment ports from to to and so on Move subgraph metadata from JSONB storage to relational storage One nice effect of this is that the one entity we change all the time SubgraphDeployment now lives in its own table rather than being intermingled with all the other metadata Since we have deployments but between k and k metadata entries we are now making changes in a much smaller table The migration in this PR takes about minutes against a production dump from yesterday I tested this by deploying new subgraphs locally mostly Uniswap and by running against a migrated production dump and indexing from their state in the dump not from the start the subgraphs protofiremakerdaogovernance graphprotocollivepeer graphprotocoluniswap protofiretokenregistry melonprojectmelon and daostackalchemy This fixes It seems that subgraph startsrestarts cause an error with the MetricsRegistry the error doesnt seem to cause a problem but its disconcerting to see that in the log This seems to happen when a subgraph gets restarted Heres an excerpt from the logs Jan DEBG Starting or restarting subgraph subgraphid Qmanfv Yz bMSFkxxAX JgDuHGE hy RYYE w pa c uWQh component SubgraphInstanceManager Jan DEBG Starting block stream subgraphid QmanfvYz bMSFkxx AX JgDuHGE hy RYYE w pa c uWQh component SubgraphInstanceManager Jan INFO Successfully created attribute indexes for subgraph entities subgraphid QmanfvYz bMSFkxxAX JgDuHGE hy RYYE w pa c uWQh compon ent SubgraphAssignmentProvider Jan DEBG Subgraph started startms subgraphid QmanfvY z bMSFkxxAX JgDuHGE hy RYYE w pa c uWQh component SubgraphRegistrar Jan INFO Start subgraph datasources subgraphid Qmanf vYz bMSFkxxAX JgDuHGE hy RYYE w pa c uWQh component SubgraphInstanceManager Jan ERRO registering metric QmanfvYz bMSFkxxAX JgDuHGE hy RYYE w pa c uWQhsynctotalsecs failed because descriptor Desc fqname QmanfvYz bMSFkxxAX JgDuHGE hy RYYE w pa c uWQhsynctotalsecs help total time spent syncing constlabelpairs variablelabels id dimhash already exists with the same fullyqualified name and const label values component MetricsRegistry Jan ERRO registering metric subgraphblocktriggercountQmanfvYz bMSFkxxAX JgDuHGE hy RYYE w pa c uWQh failed because descriptor Desc fqname subgraphblocktriggercountQmanfvYz bMSFkxxAX JgDuHGE hy RYYE w pa c uWQh help Measures the number of triggers in each block for a subgraph deployment constlabelpairs variablelabels id dimhash already exists with the same fullyqualified name and const label values component MetricsRegistry more with different metrics for the same subgraph When we execute GraphQL queries we set a deadline for how long the overall query is allowed to take Currently the deadline is only checked in between issuing SQL queries and a long running query can cause us to massively exceed the deadline We should set a sessiontimeout just before executing a query based on the remaining time until the deadline expires so that Postgres will abort the query if we exceed the deadline Since sessiontimeout is set per connection and sticks around after the query finishes we need to make sure to reset the sessiontimeout right after running the query so that other queries that later uses this connection is not affected by it The current approach in prefetch to use a window function to pick the top n rows for a set of parents can be very slow A better way to do this would be to use a lateral join along the lines of with parentsid as values select from parents p cross join lateral select from children c where cparentid pid order by csortkey limit n c This entails the following Update PLAN to reflect the changed query construction Change query generation in relationalqueries For the case where the parent stores childid change EntityQuery to pass pairs of parentid childid into query generation so that we can avoid the actual join with the parent table might be optional This brings into the future of futures by upgrading to tokio futures hyper and various other dependency upgrades This not only allows us to use asyncawait but also pushes us towards that by having updated dependencies Some parts of the code were updated to use asyncawait to serve as examples This is working fine as far as I have tested it Using stdfuture and async Theres now a Future trait that lives in std though helpers are still in the futures crate The major difference from the one in futures is that it has a single Output associated type instead of Item and Error same for streams It is easy to convert back and forth between a std future that has Output Result and the old futures by calling compat The async syntax can be thought of as a future literal and works on fns and blocks but not closures yet To use async in trait fns the asynctrait crate is required I havent tried that yet In blocks you usually want async move Inside an async fn or block you can use await on futures as it were the old andthen but more flexible Using future combinators is still useful so checkout the docs for FutureExt and TryFutureExt to catch up on them There is no new syntax for streams yet Sometimes the compiler will complain about Unpin I havent totally understood the pinning stuff but wrapping the future in a Boxpin usually fixes that Spawning tasks and panic handling Usually we want a tokio task panic to abort the process so that the node has a chance to recover by restarting Except in some situations such as in the runtime or in queries So instead of using tokiospawn directly we should choose between graphspawn which runs on the default threadpool and aborts on panic graphspawnblocking which is run on the blocking threadpool and aborts on panic graphspawnblockingallowpanic which is run on the blocking threadpool and allows panics A panic will result in an error in the JoinHandle Note that all of these now return a JoinHandle for joining the task which can be very useful Resolves since were now careful to use the blocking thread pool when called for and were also back to the default thread pool size Resolves panics in query processing are no longer fatal Bumps numbigint from to details summaryChangelogsummary pemSourced from a href changelogaemp blockquote h Release h ul lia href the codeautocfgcode build dependency to ali ul pstrongContributorsstrong a href a href h Release h ul lia href new codeBigUinttou digitscode methoda returns the number as a littleendian vector of base sup sup digits The same method on codeBigIntcode also returns the signli lia href now applies a modulus even for exponent a which also affects codeBigIntmodpowcodeli lia href now returns the correct sign for negative bases with even exponentsali ul pstrongContributorsstrong a href a href a href a href a href blockquote details details summaryCommitssummary ul lia href Merge a href lia href Release li lia href Merge a href lia href Update to autocfg li lia href Merge a href lia href Doc some minor clarifications and formatting nitsli lia href Merge a href lia href Release li lia href Fix clippyprecedenceli lia href Fix clippyredundantclosureli liAdditional commits viewable in a href viewali ul details br Dependabot compatibility score Dependabot will resolve any conflicts with this PR as long as you dont alter it yourself You can also trigger a rebase manually by commenting dependabot rebase dependabotautomergestart dependabotautomergeend details summaryDependabot commands and optionssummary br You can trigger Dependabot actions by commenting on this PR dependabot rebase will rebase this PR dependabot recreate will recreate this PR overwriting any edits that have been made to it dependabot merge will merge this PR after your CI passes on it dependabot squash and merge will squash and merge this PR after your CI passes on it dependabot cancel merge will cancel a previously requested merge and block automerging dependabot reopen will reopen this PR if it is closed dependabot close will close this PR and stop Dependabot recreating it You can achieve the same result by closing it manually dependabot ignore this major version will close this PR and stop Dependabot creating any more for this major version unless you reopen the PR or upgrade to it yourself dependabot ignore this minor version will close this PR and stop Dependabot creating any more for this minor version unless you reopen the PR or upgrade to it yourself dependabot ignore this dependency will close this PR and stop Dependabot creating any more for this dependency unless you reopen the PR or upgrade to it yourself dependabot use these labels will set the current labels as the default for future PRs for this repo and language dependabot use these reviewers will set the current reviewers as the default for future PRs for this repo and language dependabot use these assignees will set the current assignees as the default for future PRs for this repo and language dependabot use this milestone will set the current milestone as the default for future PRs for this repo and language dependabot badge me will comment on this PR with code to add a Dependabot enabled badge to your readme Additionally you can set the following in your Dependabot dashboard Update frequency including time of day and day of week Pull request limits per update run andor open at any time Outofrange updates receive only lockfile updates if desired Security updates receive only security updates if desired details Map between strings that represent bytes and bytea in the database the difference between subgraphs that use Bytes for ID and those that use String is transparent to subgraph users The only exception is that when an entity is stored with an id xdeadbeef it will be returned as the string deadbeef stripping the x prefix Currently this is only used for network indexing all usersupplied subgraphs still use String as their ID and there is no way for users to switch to Bytes Fixes 