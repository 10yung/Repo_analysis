Background we are using a springnetflix based microservice architecture running on kubernetes Most of the services are only being used internally and therefore there are no kubernetesServices The applications register themself to a EurekaServer To register a service spring uses either the IP Address of the Pod or the hostname Its possible to overwrite the hostname and fake another IP address But if I use telepresence with swapdeployment it looks that there is no chance to get the PODs IP Address shows a way to inject the PODs IP from the Downward API It would be totally great if you could add the PODs IP as an environment variable like eg TELEPRESENCEPODIP for swappeddeployments Thanks and cheers Hendrik What were you trying to do Turn on telepresence using telepresence namespace xenditintegration What did you expect to happen please tell us What happened instead please tell us the traceback is automatically included see below use to pass along full telepresencelog Automatically included information Command line usrlocalbintelepresence namespace xenditintegration Version Python version default Dec Clang clang kubectl version Client Version v dispatcher Server Version v gke oc version error Errno No such file or directory oc oc OS Darwin ip apsoutheast computeinternal Darwin Kernel Version Tue Aug PDT rootxnu RELEASEX x Traceback most recent call last File usrlocalbintelepresencetelepresenceclipy line in crashreporting yield File usrlocalbintelepresencetelepresencemainpy line in main runner remoteinfo env socksport ssh mountdir podinfo File usrlocalbintelepresencetelepresenceoutboundsetuppy line in launch runner remoteinfo command argsalsoproxy env ssh File usrlocalbintelepresencetelepresenceoutboundlocalpy line in launchvpn connectsshuttlerunner remoteinfo alsoproxy ssh File usrlocalbintelepresencetelepresenceoutboundvpnpy line in connectsshuttle raise RuntimeErrorvpntcp tunnel did not connect RuntimeError vpntcp tunnel did not connect Logs sult for bedgeapislackcom is TEL timed out after secs TEL Capturing python c import socket socketgethostbynamehellotelepresence asanitychecktelepresenceio c DNS request from to None bytes c DNS request from to None bytes T stdoutinfo Sanity check bhellotelepresence asanitychecktelepresenceio T stdoutinfo A query bedgeapislackcom T stdoutinfo Result for bedgeapislackcom is TEL timed out after secs c DNS request from to None bytes T stdoutinfo A query bwwwgstaticcom T stdoutinfo Result for bwwwgstaticcom is It would be handy to tweak the ServerAliveInterval and ServerCountMax arguments that telepresence sends to ssh as well as maybe passoverride other arguments What were you trying to do I was trying to swap one of my containers into our dev cluster This has been working for some time before without any problems but all of a sudden it has stopped working and I am not able to get it working again Already tried to upgrade and downgrade kubectl trying to swap different imagespods has not helped either Other collegues with the same telepresence version dont have the same problem What did you expect to happen I expected my local docker image to be deployed into our dev cluster What happened instead Telepresence apologized for containing a bug and sent me to this form Current versions in use telepresence docker build a fc f kubectl client Also tried and kubectl server There is no minikube in use Related issues with minikube Output Looks like theres a bug in our code Sorry about that Traceback most recent call last File usrbintelepresencetelepresenceclipy line in crashreporting yield File usrbintelepresencetelepresencemainpy line in main runner remoteinfo env socksport ssh mountdir podinfo File usrbintelepresencetelepresenceoutboundsetuppy line in launch podinfo File usrbintelepresencetelepresenceoutboundcontainerpy line in rundockercommand raise RuntimeErrorSSH to the network container failed to start RuntimeError SSH to the network container failed to start Here are the last few lines of the logfile see homeonexonexworkspaceauthtelepresencelog for the complete logs TEL exit in secs Traceback most recent call last File usrbinentrypointpy line in module main File usrbinentrypointpy line in main proxyloadssysargv File usrbinentrypointpy line in proxy SSH from local container to the cluster failed to start RuntimeError SSH from local container to the cluster failed to start INFO tini Main child exited normally with status TEL exit in secs TEL Network container exit Complete telepresencelog Uploading telepresencelog What were you trying to do try it out What did you expect to happen a shell open What happened instead please tell us the traceback is automatically included see below use to pass along full telepresencelog Automatically included information Command line usrlocalbintelepresence runshell Version Python version default Dec Clang clang kubectl version error Command kubectl version short returned nonzero exit status oc version error Errno No such file or directory oc oc OS Darwin ip ec internal Darwin Kernel Version Sun Dec PST rootxnu RELEASEX x Traceback most recent call last File usrlocalbintelepresencetelepresenceclipy line in crashreporting yield File usrlocalbintelepresencetelepresencemainpy line in main runner remoteinfo env socksport ssh mountdir podinfo File usrlocalbintelepresencetelepresenceoutboundsetuppy line in launch runner remoteinfo command argsalsoproxy env ssh File usrlocalbintelepresencetelepresenceoutboundlocalpy line in launchvpn connectsshuttlerunner remoteinfo alsoproxy ssh File usrlocalbintelepresencetelepresenceoutboundvpnpy line in connectsshuttle raise RuntimeErrorvpntcp tunnel did not connect RuntimeError vpntcp tunnel did not connect Logs stdoutinfo Result for bhellotelepresence compute amazonawscom is c DNS request from to None bytes T stdoutinfo Result for bhellotelepresence compute amazonawscom is c DNS request from to None bytes T stdoutinfo A query bgspe ssllsapplecom T stdoutinfo Result for bgspe ssllsapplecom is TEL timed out after secs TEL Capturing python c import socket socketgethostbynamehellotelepresence asanitychecktelepresenceio c DNS request from to None bytes T stdoutinfo Sanity check bhellotelepresence asanitychecktelepresenceio TEL timed out after secs Added the ability to set a node selector for a new deployment Fixes At least in VPN mode k sproxy logs EVERY query executed from telepresence host machine I see this as a privacy breach since any cluster or logging system user can see which websites were accessed by a telepresence user while they were connected to telepresence Example of log messages T stdoutinfo A query bgithubcom T stdoutinfo Result for bgithubcom is Ideally such logs messages would be disabled by default but it would be alright for us to have it as a CLI option since were using wrapper shellscript anyway What were you trying to do Connect to AKS cluster with telepresence What did you expect to happen I was expecting to get shell with access to aks services What happened instead T Pollerror Failed to contact Telepresence client T Pollerror An error occurred while connecting Address not available T Pollwarn Perhaps its time to exit Automatically included information Command line usrlocalbintelepresence runshell Version Python version default Dec Clang clang kubectl version Client Version v Server Version v oc version error Errno No such file or directory oc oc OS Darwin PrzemyslawsMacBookPro local Darwin Kernel Version Sun Dec PST rootxnu RELEASEX x Traceback most recent call last File usrlocalbintelepresencetelepresenceclipy line in crashreporting yield File usrlocalbintelepresencetelepresencemainpy line in main socksport ssh doconnectrunner remoteinfo File usrlocalbintelepresencetelepresenceconnectconnectpy line in doconnect argsfrompod File usrlocalbintelepresencetelepresenceconnectconnectpy line in connect raise RuntimeErrorSSH to the cluster failed to start See logfile RuntimeError SSH to the cluster failed to start See logfile Logs nodekubernetesiounreachableNoExecute for s Events Type Reason Age From Message Normal Scheduled s defaultscheduler Successfully assigned defaulttelepresence cfc c f qfl to aksagentpool Normal Pulling s kubelet aksagentpool Pulling image datawiretelepresencek s Normal Pulled s kubelet aksagentpool Successfully pulled image datawiretelepresencek s Normal Created s kubelet aksagentpool Created container telepresence Normal Started s kubelet aksagentpool Started container telepresence TEL ran in secs This is a weirdunconventional bug not from telepresence but there might be a workaround It happens on iTerm zsh macOS for me havent tested in other places Summary Cannot reinsert sudo password after telepresence crashesexits in the same terminal session Overview When telepresence is active it requires you to insert the sudo password After the connection is lost telepresence exits and goes back to the shell t erminal The most common action is to run telepresence again Password is asked again if Sudo Password timestamptimeout is expired Cannot insert new password How to reproduce sudo visudo editadd Defaults timestamptimeout to set the sudo password timeout to Run telepresence insert sudo password Kill the telepresence pod to force a Connection closed by remote host Run telepresence and try to insert sudo password again my result is that I can never press Return see image Screen Shot at What were you trying to do please tell us What did you expect to happen please tell us What happened instead please tell us the traceback is automatically included see below use to pass along full telepresencelog Automatically included information Command line usrlocalbintelepresence namespace kubefederationsystem swapdeployment kubefedcontrollermanager Version Python version default Nov Clang clang kubectl version Client Version v Server Version v oc version error Errno No such file or directory oc oc OS Darwin localhost Darwin Kernel Version Sat Nov PST rootxnu RELEASEX x Traceback most recent call last File usrlocalbintelepresencetelepresenceclipy line in crashreporting yield File usrlocalbintelepresencetelepresencemainpy line in main socksport ssh doconnectrunner remoteinfo File usrlocalbintelepresencetelepresenceconnectconnectpy line in doconnect argsfrompod File usrlocalbintelepresencetelepresenceconnectconnectpy line in connect raise RuntimeErrorSSH to the cluster failed to start See logfile RuntimeError SSH to the cluster failed to start See logfile Logs QoS Class Burstable NodeSelectors none Tolerations nodekubernetesionotreadyNoExecute for s nodekubernetesiounreachableNoExecute for s Events Type Reason Age From Message Normal Scheduled m s defaultscheduler Successfully assigned kubefederationsystemkubefedcontrolleb ecfbbc a e ff f b e f f n wmf to irybg xwe Normal Pulling m s kubelet irybg xwe pulling image datawiretelepresencek s Normal Pulled s kubelet irybg xwe Successfully pulled image datawiretelepresencek s Normal Created s kubelet irybg xwe Created container Normal Started s kubelet irybg xwe Started container TEL ran in secs 