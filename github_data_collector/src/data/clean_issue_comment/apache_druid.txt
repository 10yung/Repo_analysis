Fixes Description The tuningConfig type has changed in but the compaction task should be able to read the spec of the old version for rolling upgrades hr This PR has x been selfreviewed using the concurrency checklist Remove this item if the PR doesnt have any relation to concurrency added documentation for new or modified features or behaviors added Javadocs for most classes and all nontrivial methods Linked related entities via Javadoc links added or updated version license or notice information in licensesyaml added comments explaining the why and the intent of the code wherever would not be obvious for an unfamiliar reader x added unit tests or modified existing tests to cover new code paths added integration tests x been tested in a test Druid cluster Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend dataSource rdstack stream rdstack partitions replicas durationSeconds activeTasks publishingTasks latestOffsets minimumLag aggregateLag offsetsLastUpdated T Z suspended false healthy false state UNHEALTHYSUPERVISOR detailedState UNABLETOCONNECTTOSTREAM recentErrors timestamp T Z exceptionClass orgapachedruidjavautilcommonISE message orgapachedruidjavautilcommonISE Previous sequenceNumber is no longer available for partition You can clear the previous sequenceNumber and start reading from a valid message by using the supervisors reset API streamException true timestamp T Z exceptionClass orgapachedruidjavautilcommonISE message orgapachedruidjavautilcommonISE Previous sequenceNumber is no longer available for partition You can clear the previous sequenceNumber and start reading from a valid message by using the supervisors reset API streamException true timestamp T Z exceptionClass orgapachedruidjavautilcommonISE message orgapachedruidjavautilcommonISE Previous sequenceNumber is no longer available for partition You can clear the previous sequenceNumber and start reading from a valid message by using the supervisors reset API streamException true Auto Compaction does not work when coordinator is running on and MiddleManager is running on Affected Version coordinator is running on and MiddleManager is running on Description Auto Compaction does not work when coordinator is running on and MiddleManager is running on This is due to incompatibility when deserializing the json ingestion spec that is sent to MiddleManager from coordinator This will automatically fix itself since auto compaction is auto run after coordinator upgraded to T ERROR TaskMonitorCache orgapachecuratorframeworkrecipescachePathChildrenCache comfasterxmljacksondatabindexcInvalidTypeIdException Could not resolve type id index as a subtype of orgapachedruidindexingcommontaskbatchparallelParallelIndexTuningConfig known type ids indexparallel realtime for POJO property tuningConfig at Source byte typecompactidcompactautocompacttestnew T ZresourceavailabilityGroupcompactautocompacttestnew T ZrequiredCapacity dataSourceautocompacttestnew intervalnullsegments dataSourceautocompacttestnew interval T Z T Zversion T ZloadSpectypelocalpathtmprollingupgradetestvardruidsegmentsautocompacttest truncated bytes line column through reference chain orgapachedruidindexingcommontaskCompactionTask tuningConfig at comfasterxmljacksondatabindexcInvalidTypeIdExceptionfromInvalidTypeIdExceptionjava jacksondatabind jar at comfasterxmljacksondatabindDeserializationContextinvalidTypeIdExceptionDeserializationContextjava jacksondatabind jar at comfasterxmljacksondatabindDeserializationContexthandleUnknownTypeIdDeserializationContextjava jacksondatabind jar at comfasterxmljacksondatabindjsontypeimplTypeDeserializerBasehandleUnknownTypeIdTypeDeserializerBasejava jacksondatabind jar at comfasterxmljacksondatabindjsontypeimplTypeDeserializerBasefindDeserializerTypeDeserializerBasejava jacksondatabind jar at comfasterxmljacksondatabindjsontypeimplAsPropertyTypeDeserializerdeserializeTypedForIdAsPropertyTypeDeserializerjava jacksondatabind jar at comfasterxmljacksondatabindjsontypeimplAsPropertyTypeDeserializerdeserializeTypedFromObjectAsPropertyTypeDeserializerjava jacksondatabind jar at comfasterxmljacksondatabinddeserBeanDeserializerBasedeserializeWithTypeBeanDeserializerBasejava jacksondatabind jar at comfasterxmljacksondatabinddeserSettableBeanPropertydeserializeSettableBeanPropertyjava jacksondatabind jar at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeWithErrorWrappingBeanDeserializerjava jacksondatabind jar at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeUsingPropertyBasedBeanDeserializerjava jacksondatabind jar at comfasterxmljacksondatabinddeserBeanDeserializerBasedeserializeFromObjectUsingNonDefaultBeanDeserializerBasejava jacksondatabind jar at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeFromObjectBeanDeserializerjava jacksondatabind jar at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeOtherBeanDeserializerjava jacksondatabind jar at comfasterxmljacksondatabinddeserBeanDeserializerdeserializeBeanDeserializerjava jacksondatabind jar at comfasterxmljacksondatabindjsontypeimplAsPropertyTypeDeserializerdeserializeTypedForIdAsPropertyTypeDeserializerjava jacksondatabind jar at comfasterxmljacksondatabindjsontypeimplAsPropertyTypeDeserializerdeserializeTypedFromObjectAsPropertyTypeDeserializerjava jacksondatabind jar at comfasterxmljacksondatabinddeserAbstractDeserializerdeserializeWithTypeAbstractDeserializerjava jacksondatabind jar at comfasterxmljacksondatabinddeserimplTypeWrappedDeserializerdeserializeTypeWrappedDeserializerjava jacksondatabind jar at comfasterxmljacksondatabindObjectMapperreadMapAndCloseObjectMapperjava jacksondatabind jar at comfasterxmljacksondatabindObjectMapperreadValueObjectMapperjava jacksondatabind jar at orgapachedruidindexingworkerWorkerTaskMonitor childEventWorkerTaskMonitorjava druidindexingservice SNAPSHOTjar SNAPSHOT at orgapachecuratorframeworkrecipescachePathChildrenCache applyPathChildrenCachejava curatorrecipes jar at orgapachecuratorframeworkrecipescachePathChildrenCache applyPathChildrenCachejava curatorrecipes jar at orgapachecuratorframeworklistenListenerContainer runListenerContainerjava curatorframework jar at orgapachecuratorshadedcomgooglecommonutilconcurrentMoreExecutorsDirectExecutorexecuteMoreExecutorsjava curatorclient jar at orgapachecuratorframeworklistenListenerContainerforEachListenerContainerjava curatorframework jar at orgapachecuratorframeworkrecipescachePathChildrenCachecallListenersPathChildrenCachejava curatorrecipes jar at orgapachecuratorframeworkrecipescacheEventOperationinvokeEventOperationjava curatorrecipes jar at orgapachecuratorframeworkrecipescachePathChildrenCache runPathChildrenCachejava curatorrecipes jar at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Backport of to This PR adds some structure to the s and google extensions docs to indicate that they can be used for either deep storage or ingesting files They are structured to indicated what configuration is needed for each This also makes some stylistic changes to the avro and orc docs Update kafka ingestion specs in tutorial docs to use the new inputSpec instead of parseSpec Update first last aggregator docs to remove filterNullValues See for details azure extensions task log kill crashes with Not Implemented Affected Version incubating Description I have a small master query storage node cluster and need to be able to shrink the druidtasks table I added the following to my overlord configuration remove old logs druidindexerlogskillenabledtrue after in ms days hours minutes seconds ms druidindexerlogskilldurationToRetain and when the kill task ran I got T ERROR OverlordHelperManagerExec orgapachedruidindexingoverlordhelpersTaskLogAutoCleaner Failed to cleanup the task logs javalangUnsupportedOperationException not implemented at orgapachedruidstorageazureAzureTaskLogskillOlderThanAzureTaskLogsjava at orgapachedruidindexingoverlordhelpersTaskLogAutoCleaner runTaskLogAutoCleanerjava druidindexingservice incubatingjar incubating at orgapachedruidjavautilcommonconcurrentScheduledExecutors callScheduledExecutorsjava druidcore incubatingjar incubating at orgapachedruidjavautilcommonconcurrentScheduledExecutors callScheduledExecutorsjava druidcore incubatingjar incubating at orgapachedruidjavautilcommonconcurrentScheduledExecutors runScheduledExecutorsjava druidcore incubatingjar incubating at javautilconcurrentExecutorsRunnableAdaptercallExecutorsjava at javautilconcurrentFutureTaskrunFutureTaskjava at javautilconcurrentScheduledThreadPoolExecutorScheduledFutureTaskaccess ScheduledThreadPoolExecutorjava at javautilconcurrentScheduledThreadPoolExecutorScheduledFutureTaskrunScheduledThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava at javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava at javalangThreadrunThreadjava Is there a plan to implement this Description Apache Pig dependencies as well as related functionality were removed from the Avro parser in We internally use Pig extensively and the Pig specific transformation within the Avro parser extension is useful for us especially for parsing data bags I would like to add the fromPigAvroStorage flag based processing back to the Avro Parser In terms of tests I can find a way to test this without adding the Pig dependency back I apologize for missing out on raising this concern on the original PR Any objections gianm Fokko Replace XXXX with the id of the issue fixed in this PR Remove this section if there is no corresponding issue Dont reference the issue in the title of this pullrequest If you are a committer follow the PR action item checklist for committers Description Remove unnecessary casts Describe the goal of this PR what problem are you fixing If there is a corresponding issue referenced above its not necessary to repeat the description here however you may choose to keep one summary sentence Describe your patch what did you change in code How did you fix the problem If there are several relatively logically separate changes in this PR create a minisection for each of them For example Fixed the bug Renamed the class Added a forbiddenapis entry In each section please describe design decisions made including Choice of algorithms Behavioral aspects What configuration values are acceptable How are corner cases and error conditions handled such as when there are insufficient resources Class organization and design how the logic is split between classes inheritance composition design patterns Method organization and design how the logic is split between methods parameters and return types Naming class method API configuration HTTP endpoint names of emitted metrics Its good to describe an alternative design or mention an alternative name for every design or naming decision point and compare the alternatives with the designs that youve implemented or the names youve chosen to highlight the advantages of the chosen designs and names If there was a discussion of the design of the feature implemented in this PR elsewhere e g a Proposal issue any other issue or a thread in the development mailing list link to that discussion from this PR description and explain what have changed in your final design compared to your original proposal or the consensus version in the end of the discussion If something hasnt changed since the original discussion you can omit a detailed discussion of those aspects of the design here perhaps apart from brief mentioning for the sake of readability of this PR description Some of the aspects mentioned above may be omitted for simple and small changes hr This PR has been selfreviewed using the concurrency checklist Remove this item if the PR doesnt have any relation to concurrency added documentation for new or modified features or behaviors added Javadocs for most classes and all nontrivial methods Linked related entities via Javadoc links added or updated version license or notice information in licensesyaml added comments explaining the why and the intent of the code wherever would not be obvious for an unfamiliar reader added unit tests or modified existing tests to cover new code paths added integration tests been tested in a test Druid cluster Check the items by putting x in the brackets for the done things Not all of these items apply to every PR Remove the items which are not done or not relevant to the PR None of the items from the checklist above are strictly necessary but it would be very helpful if you at least selfreview the PR hr Key changedadded classes in this PR MyFoo OurBar TheirBaz 