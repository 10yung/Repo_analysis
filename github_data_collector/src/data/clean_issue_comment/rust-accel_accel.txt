A proposition to resolve Motivation kernel function cannot use any variable function and so on because it will be compiled as a stand alone device code rust fn add a mut f a a kernel pub fn add alla mut f n usize let i accelcoreindex unsafe add mut aoffseti add cannot find Resolution Compile entire crate both as x and nvptx targets rustptxlinker will eliminate nonPTX kernel code which does not called from PTX kernel Problems std must be compiled with nvptx Compile flow How to trigger nvptx build instead of procmacro This project is enough complicated for new developer to stop hacking A guide book like rustcguide is needed Wrap CUDA steraming API using asyncawait CI on GPU GitHub Actions with selfhosted runner works Stable Rust Stabilize Hostside code Deviceside code is outofscope because large amount of issues are remains for nvptx backend See the link x procmacro has been stabilized as x cargo check runs on stable Rust Update dependencies x syn quote procmacro x rustcudacudasys rustptxlinker Linker flavor using rustptxlinker has been merged into rustc x Rewrite accelderive with rustptxlinker x archive nvptx crate Document Needs a guide book Links rustlangrust NVPTX backend metabug rustcudawg Overview about existing solutions and approaches Are we CUDA yet Hi there I am running a program which contains some error and the Cuda runtime keeps returning MissingConfiguration I can see in the cudasys code that this enum value maps to nevertheless MissingConfiguration in the Cuda runtime maps to while is The API call failed because it was unable to allocate enough memory to perform the requested operation cudaErrorMemoryAllocation The device function being invoked usually via cudaLaunchKernel was not previously configured via the cudaConfigureCall function cudaErrorMissingConfiguration In the rust code there are no nor values PeerAccessAlreadyEnabled PeerAccessNotEnabled DeviceAlreadyInUse ProfilerDisabled I am using cuda is this version supported is this a version missmatch Should I generate the bindings myself from the Cuda header Cheers I have a crate that has N rust accel functions When I rebuild this crate even if I dont touch those N functions it seems to trigger N nvptxaccel rebuilds Is this avoidable Is there a way to mix rustaccel with raw cu files I would like to write some device helper functions in cu then call them from kernel functions defined in rustaccel Is there an example for how to do this See last slide of Is there a way to mark a field volatile in rustaccel This pull request addresses the issue that CUDA headers change between versions Thus over time cudasys becomes incompatible with newer CUDA versions See also For example Nvidia introduced a breaking API change going from version to They added a new field uuid to the beginning of cudasyscudartcudaDeviceProp making all the fields after uuid invalid memory locations We solve such compatibility issues by generating new bindings every time that cudasys is built This ensures that we are sourcecompatible with the installed CUDA version Unfortunately I have a little time to manage this project Id like to seek anyone interested in managingdeveloping this project