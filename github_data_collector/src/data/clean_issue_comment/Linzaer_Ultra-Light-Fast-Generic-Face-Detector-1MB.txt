 Linzaer I am trying to convert your existing slim model onnxcaffenncase for use in Kendryte chip k so that I have a full working flow before I use your model for training I am new to pytorch I installed pytorch without CUDA as I only have an AMD machine When I run python converttoonnxpy slim I get AssertionError Torch not compiled with CUDA enabled Is there a way to run the conversion without CUDA detectimgsonnxpy onnx versionRFB simplifiedonnx onnxsimplifier versionRFB onnx P Thank you for sharing such a great project I encountered this error when convert simplified onnx model to caffe model can you help me to solve it thank you very much Traceback most recent call last File convertCaffepy line in module convertToCaffegraph prototxtpath caffemodelpath File convertCaffepy line in convertToCaffe errunsupportedopnode File UltraLightFastGenericFaceDetector MBcaffeonnx caffeerrorutilspy line in unsupportedop ONNX node of type is not supported nformatnodeoptype TypeError ONNX node of type Slice is not supported Hi Linzaer awesome work once again I am unable to comprehend the below issue Shouldnt an INT quantized model run faster than the unquantized one for the same image file system settings MB model secs kB model secs Ultrafacemnn modelversionRFBRFB mnn imgs jpg Processing imgs jpg inference time s all time s Ultrafacemnn modelversionRFBRFB quantKL mnn imgs jpg Processing imgs jpg inference time s all time s First thanks for the great work the onnx models on python works just like expected Your models seem to be perfectly fitted for a javascript implementation light and fast but when I tried them on onnxjs in a browser it returns this error cannot resolve operator Shape with opsets aionnx v Is there a way to get around this error or should I investigate other solutions like onnx caffe webassembly onnx tensorflow tensroflowjs Thanks Is it possible to increase the resolution beyond the x which is currently the best available resolution AttributeError DataParallel object has no attribute initfrombasenet 