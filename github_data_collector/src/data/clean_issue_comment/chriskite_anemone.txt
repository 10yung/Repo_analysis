With this new release we would have the ability to use Proxy with authentication Support Phantomjs The parameter is called ignorewwwsubdomain Im using Anemone Its excelletnt But Garbled characters occur if the pages charset is not UTF or USASCII So I want to support other charsets For sitespecific crawlers its fair enough to use focuscrawl like this anemonefocuscrawl do page if pagedoc pagedocsearcha href map a URIparsea href else pagelinks end end However when using the discardpagebodies option pagedoc is nil by the time we enter this block In this pull request Ive moved until after focuscrawl has been called Also add this model anemonepagerb in your app ruby class AnemonePage include MongoidDocument field url field headers type MopedBSONBinary field data type MopedBSONBinary field body type MopedBSONBinary field links type Array field code type Integer field visited type Boolean field depth type Integer field referer field redirectto field responsetime type Integer field fetched type Boolean indexurl unique true end Also add this model anemonepagerb in your app ruby class AnemonePage include MongoidDocument field url field headers type MopedBSONBinary field data type MopedBSONBinary field body type MopedBSONBinary field links type Array field code type Integer field visited type Boolean field depth type Integer field referer field redirectto field responsetime type Integer field fetched type Boolean indexurl unique true end improve Redis storage engine performance added expiration to Redis page storage added stop crawl functionality improved RAM usage page queue got filled up too quickly 