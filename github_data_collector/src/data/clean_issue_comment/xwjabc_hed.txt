Thank you for your code Howevermy outputepochtrain have gray graphsand the training process can be carried out without error reportinglooking forward to your reply In the datasetspy file the original code is like this image image nparray Minus statistics but How can i get the new statistics number for my own dataset Thanks for your code and the model I trained is quite goodODS OIS I just have a question when i see the log during the trainingthe epoch average batchloss maintains at around after th epoch until the end Does this mean that the model does not converge When we evaluate the result we need to run the EdgeEvalDirm but whats the meaning of maxDist I am confused about it and there isnt codeCan you explian it or give some papers to explain it Thanks a lot Hi xwjabc Thanks for your code Could you please tell me if it is possible to have a higher batchsize for training I see that when I try this out I get the following error upsample torchnnfunctionalconvtranspose dscoredsn selfweightdeconv stride Expected tensor for argument input to have the same device as tensor for argument weight Just wondering if you know this already Thanks AA Hello thanks for sharing I want to get the five sideoutputs however Pytorch is different to caffe Is there any suggestions Thanks a lot Looking forward to your reply Thanks for this progect My compilation for Caffe or modified HED doesnt sussess I noticed cafffemodel can be converted into pickle with some tools But it still uses Caffe as Dependency Could you upload hedpretrainedbsdspy pickle file Thanks for your help Hi xwjabc Thanks for your contribution I have a question just in the line below else Zero initialization following official repository Reference heddocstutoriallayersmd mweightdatazero I see that you have used tensorflow too so this weight initializer is something like tftruncatednormalinitializermean or tfconstantinitializer Thanks in advance xavysp Thank you for this elegent project I am trying to train a HED model using my own dataset All the hyperparameters are followed by this project and the results is also reasonable However the fifth side outputs of all the test image shown below are almost gray which confuses me greatly Could you have some ideas about this scenario batch stimage batch stimage batch stimage Thanks for sharing your code and it works well I have some doubts about the learning rate Why learning rate for conv is x of base learning rate and classification layerdsns is x of base learning rate For funetuning learning rate for classification layerwhich is trained from scratch is usually set x compared to the backbone network parameters right Besides if I insert new layers into hed how should I set the learning rate for them