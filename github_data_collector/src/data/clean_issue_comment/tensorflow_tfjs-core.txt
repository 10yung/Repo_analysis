To see the logs from the Cloud Build CI please join either our discussion or announcement mailing list This adds an app that can serve as an integration testbed for tfjsreactnative The PR looks somewhat big because there is a fair amount of generated iOS and Android boilerplate The files that needs review all end in ts js and tsx and the regular js and ts configuration files we are used to A few assets that the app uses are also included The android and ios subfolders are pretty much all autogenerated Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend To see the logs from the Cloud Build CI please join either our discussion or announcement mailing list Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend the TF implementation of the pix pix model which fails conversion because of Unsupported Ops DecodeJpeg EncodePng DecodeBase the Open NSFW model also fails conversion with some of the same ops i wanted to try to implement some of these ops in TensorFlowjs starting with this pull request for DecodeBase and EncodeBase along with this tfjscore PR there is a corresponding PR in tfjsconverter To see the logs from the Cloud Build CI please join either our discussion or announcement mailing list Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend This PR aims to fix tensorflowtfjs and replaces After trying to implement specific webglcpu shaders in i realized ImageProjectiveTransform is not available in the ops list of C API Considering this Ive implemented it in a noshader way using tfgatherND as the cornerstone of the implementation This new version wont need to maintain multiple shaders but may be a little bit slower i havent fully tested the performance yet Since the implementation takes lines i have put it into a separated file required in imageopsts Please share your feedbacks and suggestions Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend This is an attempt to further break downsimplify PR Matrix band part is required for the backpropagation of many linear operations Implementation should behave the same way as in PythonCC Tensorflow Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend FEATURE add operator diagPart Description Please describe the pull request here Also if this is an issuebug fix please add the issue link for reference here Please do not delete this section For repository owners only Please remember to apply all applicable tags to your pull request Tags FEATURE BREAKING BUG PERF DEV DOC SECURITY For more info see Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Description LBFGS optimization was a requested feature This PR offers an LBFGSFunctionOptimizer that allows the optimization for loss functions of type Tensor D Scalar This is however still at least one step away from a training optimizer Any suggestion as to how to wrap the LBFGSFunctionOptimizer into an LBFGSOptimizer for training is welcome Suggestions for test cases and test functions are appreciated as well Please describe the pull request here Also if this is an issuebug fix please add the issue link for reference here Please do not delete this section For repository owners only Please remember to apply all applicable tags to your pull request Tags FEATURE BREAKING BUG PERF DEV DOC SECURITY For more info see Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend Description As discussed this is the first split of PR A faster QR Decomposition using a direct implementation of the Givens method including support of Backpropagation bandPart and triangularSolve are a prerequesites for symbolic backpropagation of the QR Decomposition Since both of the methods are frequently used in symbolic backpropagation I believe they both deserve a backend implementation matrixTriangularSolve and matrixBandParts are kernels in the PythonCC Tensorflow Implentation as well bandPart is currently implemented purely using TFJS methods In a quick performance trial bandPart was only x slower without a backend implementation Since it is only an Omn operation in the first place its not too worrysome The memory overhead however may be more of an issue depending on how broadcasting is implemented triangularSolve will allow solving linear equations systems in TFJS which is a requested feature All linting errors are now fixed but Im afraid the code might have become even less readable Suggestions as to how to improve this are welcome In my defense There was method to my codeformattingmadness Low level linear algebra is always hard to read at least to me So in NDJS I tried my best to format the code in a way that things that belong together are aligned reducing distractions and making bugs easier to spot As I said before it should not be too hard to implement qr and triangularSolve in WebGL In order to do that I will however need some guidance and introduction to the TFJS WebGL backend The randomized gradients test fails by a small margin roughly every in tests With the old implementation after fixing some reshape and disposal issues it fails roughly time in times in sometimes with a large margin Possible explaination The Householder implementation ignores sign changes in the input causing abrupt changes in the gradients Sadly tfrandomUniform does not seem to have a seed parameter which would make the tests reproducible If there are any questions about implementation details Im more than happy to answer them Quick Overview The qr implementation is twofold Whenever the resulting R is a square matrix the economic QR Decomposition qrEcoDecompKernel is computed For the gradients the same symbolic backpropagation as in PythonCC Tensorflow is used In all other cases the full QR Decomposition is computed using qrFullDecompKernel Backpropagation is computed via qrFullBackpropKernel using the Givens rotations sin and cos values that were recorded by qrFullDecompKernel Higher order derivatives are not yet supportedimplemented Why Givens Rotations The Householder method is the defacto standard for QR Decomposition so I feel like I have to explain why I chose Givens Rotations over it For NDJS I did some performance trials and could not see a significant performance difference between Givens and Householder in JS My guess is that the JS overhead outweighs the difference in FLOPs With Givens Rotations I was able to implement an economic QR Decomposition that requires only Omn memory instead of Om For Householder I could not find such an implementation Givens Methods is easier to implement in a numerically stable way eg no underflowsafe norm is required Givens Method is easier to backpropagate Givens Method guarantees detQ which is somewhat more canonical Givens Method is better parallelizable Givens Rotations seem to be smoother when it comes to Pertubation Householder do You reflect colum c to c e or c e This should result in smoother gradients If the input is already close to upper triangular a lot of operations can easily be skipped which may reduce the computation cost from Om n all the way down to Omn for upper triangular inputs Please do not delete this section For repository owners only Please remember to apply all applicable tags to your pull request Tags FEATURE BREAKING BUG PERF DEV DOC SECURITY For more info see Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend matMul now supports broadcasting Description Linear algebra operations seem to be widely requested and help was wanted so I thought Id try and help qr now has a lowlevel CPUimplementation At least on my machine this massively improves performance and memory efficiency lu and luSolve allow solving LES via LU Decomposition cholesky and choleskySolve allow solving symmetric positive definite LES via Cholesky Decomposition triangularSolve allows solving triangular LES or LES viar QR Decomposition adjoint and conj are now implemented setDiag diagPart and bandPart were implemented for symbolic backpropagation broadcastTo is now implemented matMul now supports matrix broadcasting PS A proof of concept WebGL implementation of the Cholesky Decomposition can be found here I will require some guidance if I am supposed to work it into TFJS as a Vertex Shader and some nonTensor uniform parameters are required QR and LU Decompostion as well as triangularSolve should not be to difficult to implement either PPS This is my first time with TypeScript and about my third time with JS so I apologize is the code is not up to standard The linting requirements arent even remotely met yet I will fix that iffonce the commit is otherwise accepted Please do not delete this section For repository owners only Please remember to apply all applicable tags to your pull request Tags FEATURE BREAKING BUG PERF DEV DOC SECURITY For more info see Reviewablestart This change is img src height alignabsmiddle altReviewable Reviewableend 