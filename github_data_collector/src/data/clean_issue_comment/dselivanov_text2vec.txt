 Hi Version OS Windows Is it possible that the extra arguments for createvocabulary are not catched As I could see in the source code for createvocabulary functionit ngram cngrammin L ngrammax L stopwords character sepngram windowsize L Maybe it should automatically use the class method createvocabularyitokenparallel which has the However I couldnt pass the export in any way to createvocabulary with an initialized itokenparallel and got the unused argument error Also for createdtm I could pass export to it without any problem Just saw the update notes for could it be related Best regards Yiyang This is related to which was closed I found seemingly working code able to load pretrained GloVe vectors to text vec I have not run this successfully due to somewhat slow reading of large files but perhaps it can help I would like to know what all the abbreviations mean Some I can guess like PUNCT but no idea what X might be I want to retain contractions but hard to choose options without documentation Thanks Great performance code provabletopicmodelspdf It will be useful to create a comprehensive practical guide for topic modeling Now we have all components in place POS tags and lemmatization thanks to udpipe package coherence measures thanks to Manuel work fast LDA thanks to WarpLDA in text vec fast nonnegative matrix factorization thanks to rsparse package multiword phrase extraction several approaches text vecCollocations udpipeasphrasemachine Steps find interesting nontrivial corpus with large number of documents demonstrate how to create tokenizer which only use particular POS create collocation model on top of that create documentterm matrix using tokens with multiword expression fit several topic models text vecLDA rsparseWRMF with different hyper parameters crossvalidate compare them using different coherence metrics demonstrate usage of external corpus for tcm calculation check on how coherence metrics are correlated is perplexity correlated with them There are already good vignettes in udpipe package topic modeling and phrase extraction They can be used as inspiration manuelbickel jwijffels anything we can add to the plan above This is mostly annoyance I think it would be logical if the ldamodel would also store the resulting doctopicdistr as part of the public fields doctopicdistr ldamodelfittransformx dtm niter convergencetol ncheckconvergence progressbar FALSE We can see that topicworddistribution is already there so having doctopicdistribution would make sense as well Or have I misunderstood something ldamodel WarpLDA Inherits from LDA Public clone function deep FALSE components active binding fittransform function x niter convergencetol ncheckconvergence gettopwords function n topicnumber Lprivatentopics lambda initialize function ntopics L doctopicprior ntopics topicwordprior ntopics plot function lambdastep reordertopics FALSE doclen privatedoclen topicworddistribution active binding transform function x niter convergencetol ncheckconvergence Seems that LDAvis package doesnt actively maintained and wont be updated on CRAN in near future In particular we need option to not reorder topics and fixes for NaN in jensenShannon see I just saw this work about NBSVM I was wondering if it would make sense to add the NB transformation part of text vec It would be a kind of reweighting weights depending of the data and well know to be a strong base line when combined to SVM may be other algo too Original paper is there Dear Dmitriy thank you again for solving issue concerning replacement of terms by multiple synonyms I now have a question concerning how to best incorporate dictionaries that include information on ngramscollocations eg city names A standard solution would be to simply replace all matched patterns in the text by the dashedversionofpatterns eg via strireplaceall However this is slow for large corpora and I am interested how you would solve this task in text vec As a workaround I trained a collocation model on a modified dictionary containing all terms bound by dashes leaving the first unigram unbound so the model sees only one prefix and suffix eg new yorkcity Please see below code example I was wondering if you would incorporate such dictionary information differently eg without training a model and manually defining colloactionstats or so I would appreciate your thoughts Thank you in advance librarytext vec txt cnew york city new york city district in new york san francisco dictngrams cnew york san francisco new york city the state of new york city city district modify dict for limiting to one prefixsuffix dictngramsdashed gsub dictngrams dictngramsdashed sub dictngramsdashed train model based on dict ccmodel Collocationsnewcollocationcountmin pmimin gensimmin lfmdmin Inf itdictdashed itokendictngramsdashed progressbar FALSE ccmodelpartialfititdictdashed ccmodelcollocationstat prefix suffix ni nj nij pmi lfmd gensim rankpmi ranklfmd rankgensim city district the stateofnewyorkcity san francisco new yorkcity new york ittxt itokentxt progressbar FALSE ittxtcc ccmodeltransformittxt v createvocabularyittxtcc side effect of cc model that might be interesting citydistrict is ranked lower than newyorcity and thus the latter is preferred over the former see below v Number of docs stopwords ngrammin ngrammax Vocabulary term termcount doccount district in newyork sanfrancisco newyorkcity 