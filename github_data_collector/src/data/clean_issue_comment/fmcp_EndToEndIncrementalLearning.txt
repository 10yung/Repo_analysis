fmcp I was going through your paper and am a little bit confused with the idea of distillation loss More specifically I am assuming that the groundtruth probability distribution of each sample is a onehot vector This means that the distillation loss effectively contains only one of the classes since all other classes would have psubisub So I dont see any point of raising the probabilities by T since it effectively only scales the loss term by a factor of T linearly loss log qsubisubsup Tsup Tlog qsubisub where i the index of the ground truth class Also coming to qsubisub I am assuming that by logits you mean the normalized softmax probabilities over the total classes old new When I try running the script experimentimagenetm with all the requiremetns satisfied it throws the following error I dont see the file in the repo as well Maybe the authors forgot to include those in the repo Thanks in advance for the help Undefined function or variable fcbuildExemplarsSetImagenet Error in experimentimagenet line exemplars fcbuildExemplarsSetImagenet exemplars opts Hi there After generating the imdbs using buildImdbsImageNetm I tried to use the resimagenet function in ResNetMatconvnet to train the first model on ImageNet but I had trouble loading the first imdb using this function optsimdb seems the only related parameter I can change to point to the path of the first imdb resimagenetm but it doesnt work when I set it Could you help me with it After read your paper I still dont understand what the classification layers mean Do they mean different fully connect layers Thank you for sharing the code I wonder the detail of obtaining the first ResNet model for the first classes in CIFAR I tried to reimplement your code with Pytorch However even at the first step the performance is only averaged on many random splits with your augmentation strategy but yours is nearly It is said that the first model is trained using ResNetMatconvnet Do you used any pretrained model by finetuning when train the first model fmcp Thanks for the help before on the cifar dataset Now I am trying to use the code to reproduce the imagenet results I notice that in the readmemd it mentioned that For ImageNet you only have to change the number of classes and relative paths to the dataset According to the steps under the USAGE I guess the first step I have to split the data first and then train a first model using the ResNetMatconvnet In cifar the buildimdbsm loads all data into memory and then splits the data I am wondering whats gonna to be load for the ImageNet data Thanks for the help and looking forward to the reply Can you provide the learning rate of training the first net model of each incremental step on cifar can you provide some source code for the step of getting the first model for each step size and iteration 