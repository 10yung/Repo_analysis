Hmm it looks like we fail to force singlethreaded mode for OpenMP on some machines the CRAN rdevellinuxx fedoraclang server throws sh futureforkmultithreadingenable FALSE Evaluate future in singlethreaded mode supportsompthreads TRUE Force singlethreaded processing for OpenMP Evaluate future in singlethreaded mode DONE futurevalue basewithVisiblebaselocalRhpcBLASctlompgetmaxthreads plan nbrOfWorkers Number of OpenMP threads in MulticoreFuture future Error enable nthreads L is not TRUE This issue should serve as a public place for the discussion HenrikBengtsson and I had via mail recently I wonder if it makes sense to support reproducible parallel streams via the default RNG kind MersenneTwister within a package to help users who are not aware that this RNG kind does not provide reproducible streams in parallel I am talking about the standard parallel backends in R and not specifically about the way one can do this via the future package Multicore backend r oldseed Randomseed seed sample we need to reset the seed first in case the user supplied a seed otherwise LEcuyerCMRG wont be used rmRandomseed envir globalenv setseedseed LEcuyerCMRG If the user uses setseednumber and goes parallel via the multicore backend the code above will ensure parallel RNG streams If you want to see in action has some tests to ensure the correct functioning Socket backend Here one can do r clusterSetRNGStreamcl iseed sample to support the default RNG kind in parallel scenarios General Whenever doing this I wonder if one should at least tell the user that this was done behind the scenes to make them aware of whats happening including eventual decreases in speed I create VMs using the following command in R vms gcevmclustervmprefixvmbasename clustersizeclustersize dockerimage mydocker sshargs listusernametestuser keypubhometestusersshgooglecomputeenginepub keyprivatehometestusersshgooglecomputeengine predefinedtype n highmem now when I SSH into the VMs I do not find the docker folder in the home directory testusertestservername gcloud beta compute project mytestproject ssh zone uscentral a rvm testuserrvm ls a bashhistory bashlogout bashprofile bashrc ssh I need to run the dockercredentialgcr configuredocker command to get the folderfile dockerconfigjson testuserrvm dockercredentialgcr configuredocker hometestuserdockerconfigjson configured to use this credential helper for GCR registries testuserrvm ls a bashhistory bashlogout bashprofile bashrc docker ssh So I try to SSH into the created VMs to configure docker vmnames paste vmbasename seq clustersize forsesh in vmnames session sshconnectsesh keyfilehometestusersshgooglecomputeengine sshexecwaitsessioncommanddockercredentialgcr configuredocker sshdisconnectsession Then I run the plan command planstrategycluster workers asclustervms dockerimagemydocker I get an error Error in unserializenodecon error reading from connection I tried makeClustervmnames and I get the error The authenticity of host ABCD cant be established XY key fingerprint is SHA abc d e f ghi j k l m no Are you sure you want to continue connecting yesno yes Warning Permanently added ABCD XY to the list of known hosts testuserABCD Permission denied publickey Any ideasuggestions on how to resolve this Hi Henrik would you accept a PR which adds a pkgdown site This would make reading your excellent vignettes even more fun If yes I would also ask whether I should enclose all of this in using the ciagnostic approach of the tic package from Kirill and myself This should come with no maintenance burden optimally and even with the option to easily update to YAML template updates in the future I am having issues with nested future calls Here Im using mlr and furrr both using future package When using them both together Im having issues to have the parallelized calls to terminate r librarymagrittr librarymlr librarymlr learners dtaslst list dta iris dplyrselectSpecies utilshead dta iris dplyrselectSpecies utilstail runxgb functiondta targetcolumn SepalLength ttsk mlr TaskRegrnewttsk backend dta target targetcolumn learner mlr lrn regrxgboost objective reglinear evalmetric rmse nrounds verbose learnertrainttsk learnerpredictttskresponse futureplanlistfuturesequential furrrfuturemapdtaslst runxgb progress TRUE works futureplanlistfuturemultiprocess futuresequential furrrfuturemapdtaslst runxgb progress TRUE doesnt terminate Ive had cases where the parallel runs do work once during a session but then not terminating on a rerun Sometimes when closing down the session after manually terminating the parallel run I get the below message r Error while shutting down parallel unable to terminate some child processes Upon googling this I found that I could do the following check r parallelmcparallelscann quiet TRUE pid fd attrclass parallelJob childProcess process Does anyone have any solutions to this Is this perhaps a bug Related to future or perhaps parallel or other package I was having the same issue when I was running the mlr package r Sysinfo sysname Linux release generic version Ubuntu SMP Tue Oct UTC machine x This might be a dumb question but is there a way my functions can detect whether they are running in the slave nodes They they can behave differently according to the situations Hello I m using future apply function with ssh connections cluster plan However future apply function makes retransmission of data frame or objects every mapping procedures even I use same datasets or objects when I m just changing parameters of estimations to find optimal condition Pseudo code is here R data mirtScience nFactors futureplancluster workers paste s futureapplyfututelapplyXnFactors FUN functionX datamirtmirtdata data X data data After run this code let s watch traffic status It seems do retransmission of data even I don t change any data for the parameter estimation How can I reduce data retransmission That s make me hard to operate HPC computing on some VPS provider they makes QoS limit every my calculation Best Seongho Make it possible to control futurerelated options per backend For example r planmultisession workers L waitinterval would make all multisession futures to wait seconds between pools instead of the default r getOptionfuturewaitinterval asnumericSysgetenvRFUTUREWAITINTERVAL This could be done by making waitinterval an argument to and a field of the Future See also I specified workers but all cores are used when set futureplanmultiprocess workers Issue We have from futurefutureoptions futurewaittimeout Maximum waiting time in seconds for a free worker before a timeout error is generated Default days futurewaitinterval Initial interval in seconds between polls Default seconds futurewaitalpha Positive scale factor used to increase the interval after each poll Default Those defaults are not set per se but through getOptionfuturewaitinterval in the different future packages However in the futurebatchtools package the default interval is seconds PS The default is seconds in BatchJobs Suggestion Documentclarify this difference Introduce another option getOptionfuturewaitscale so that we can use the same above defaults everywhere but where futurebatchtools uses getOptionfuturewaitscale Hmm thats just introducing yet another option without making it clearer to the user Introduce backendspecific options eg futurebatchtoolsfuturewaitinterval which if available will override the futureversewide futurewaitinterval option Need to think about this one andor make it possible to set these backendrelated options via plan eg planbatchtoolssge futurewaitinterval See also This came up in 