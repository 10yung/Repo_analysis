There will ve a discourse post as well There will ve a discourrse post as well Hello Since today we are not able to download the commonscodec from Maven which means we cannot bootstrap our EMR When checking the error logs both from our application and Amazon we saw that the bootstrap is failing on downloading that said library because it tries to connect via HTTP Resolving centralmavenorg centralmavenorg Connecting to centralmavenorg centralmavenorg connected HTTP request sent awaiting response HTTPS Required ERROR HTTPS Required With a quick research on the web we found out that since today Maven no longer supports plain HTTP so we tried to connect via HTTPS However that failed too with the message bellow Resolving centralmavenorg centralmavenorg Connecting to centralmavenorg centralmavenorg connected ERROR no certificate subject alternative name matches requested host name centralmavenorg To connect to centralmavenorg insecurely use nocheckcertificate Then we created another script to add as a custom Bootstrap We managed to add this script but it failed again this time pointing out that it cannot remove commonscodec jar Right now we are trying to pass as a parameter and see if it will work We will try to update it here as soon as possible no matter if it fixes or not Also Id like to point out that we are on saeast Project Stream Enrich Version Expected behavior EMR Bootstraping builds the cluster Actual behavior EMR fails at Bootstrap Steps to reproduce Start a new EMR using snowplowami bootstrap sh as the script Change to on snowplowami bootstrap sh Try to run it as you would Change to on snowplowami bootstrap sh Try to run it as you would normally Create a new self hosted bootstrap script and add it to your EMRs Bootstrap Make sure the new script has the same changes as those above Cheers Thank you for contributing to Snowplow Youll find a small checklist below which should help speed up the review process Have you signed the contributor license agreement Have you read the contributing guide x Have you added the appropriate unit tests x Have you run the tests through sbt test Is your pull request against the master branch Hi folks it just hotfix my jobs had crashed without that In SCE in order to make it possible to compose IO we made a decision to switch all client libraries to final tagless like encoding scala trait Weather F def temperature F Int It works great with IO Task ZIO etc but we cannot support them in Spark and Beam or maybe we can and then we should We decided to use Id in Spark and Beam which unfortunately makes SCE API not that composable as we would like to Imagine following code scala implicit val idWeather new Weather catsId def temperature Id Int printlnGetting weather implicit def syncWeather F catseffectSync new Weather F def temperature F Int catseffectSync F delay printlnGetting weather def one F implicit W Weather F M Monad F val weather F Int Wtemperature would be fine with def for berlin weather moscow weather yield moscow berlin def two F implicit W Weather F M Monad F val weather F Int Wtemperature would be fine with def Listfill weathersequence one Id does a different thing from one catseffectIO unsafeRunSync As a result we just need to be very careful in with constructs like val x F Something because in some cases it means it has been evaulated already and we cannot use many functional combinators so the code is not much better than pre cc benjben Reasoning is that it becomes too cumbersome to release patch releases of individual components and split work between different engineers Also I expect it should help with CICD process and external contributions We have came up with options on what to do with snowplowsnowplow as we dont want to lose this entrypoint Transform all projects into submodules as we did with trackers and periodically update them That would also allow us to bring loaders back to a snowplowsnowplow as technically theyre core part of pipeline Use this repo for documentation and publish it to GH pages Combination of and where we have most of docs on a dedicated docssnowplowanalyticscom and in repo just a summary of all components and links to extensive docs my personal preference Make this repo a repo for one of core components Scala Common Enrich most probably Regardless of above decision we need to Overhaul the main README and point to our commercial offer and Snowplow Mini for those who just wants to try out the technology Write a script that will move all existing issues into their appropriate projects with crossreference to original ticket AWS is removing Tomcat support on Elastic Beanstalk making our ClojureCollector incompatible AWS is changing its Cloudfront format We are contacting you because your AWS account contains at least one CloudFront web distribution with logging enabled Starting December Amazon CloudFront is adding the following seven new fields to access logs cport The port number of the request from the viewer timetofirstbyte The number of seconds between receiving the request and writing the first byte of the response as measured on the server xedgedetailedresulttype When the result type is an error this field contains the specific type of error sccontenttype The value of the HTTP ContentType header of the response sccontentlen The value of the HTTP ContentLength header of the response scrangestart When the response contains the HTTP ContentRange header this field contains the range start value scrangeend When the response contains the HTTP ContentRange header this field contains the range end value We often want to filter out events based on some configuration enabled eg we updated version of Beam Enrich or MaxMind DB and got an unexpected behavior we want to analyze only that set of events but currently cannot do this in a predictable way Should it be a hash of all config files How we can make sure the hash can be reversed