Finding this bug makes me even more impressed anyone has solved BipedalWalkerHardcorev it seems the observations from lidar have been inconsistent and incorrect returning the furthest hit result instead of closest In screenshots below Ive tweaked the lidar drawing routine to draw last in front of terrain and objects and draw every trace each frame to more clearly see whats happening Before fix lidar traces through ground and hits the side of a pit giving the agent the impression of a phantom canyon in front of the pit that only appears as it approaches the pit After fix lidar is stopped by terrain even when another object is behind it It feels very counterintuitive for Box Ds raycast to return furthest point first but when I double checked the PyBox D docs I found that is indeed how it works By returning you set the ray length to zero By returning the current fraction you proceed to find the closest point olegklimov Tagging you since your name pops up the most in relation to BipedalWalkerv Ive just restarted my models training with this fix applied and been watching the traces like a hawk worth noting it still seems to be imperfect sometimes slightly penetrating a surface but still looks much more accurate npuint dtypekind in nptypecodes AllInteger False npuint dtypechar in nptypecodes AllInteger True dtypekind A character code one of biufcmMOSUV identifying the general kind of data dtypechar A unique character code for each of the different builtin types Hi I use Ubuntu I can reproduce this error in a minimal example by creating a new conda environment and only pip install gym so that the env only contains the following packages certifi cloudpickle future gym numpy opencvpython pyglet scipy six When I run the following code in that env import gym env gymmakeCartPolev envreset for in range envrender envstepenvactionspacesample I get the following error Traceback most recent call last File frozen importlibbootstrap line in handlefromlist File frozen importlibbootstrap line in callwithframesremoved File homejroy anaconda envsirllibpython sitepackagesgymenvsclassiccontrolrenderingpy line in module from pygletgl import File homejroy anaconda envsirllibpython sitepackagespygletglinitpy line in module from xlib import XlibConfig as Config File homejroy anaconda envsirllibpython sitepackagespygletglxlibpy line in module from pygletcanvasxlib import XlibCanvas File homejroy anaconda envsirllibpython sitepackagespygletcanvasinitpy line in module from pygletcanvasxlib import XlibDisplay as Display File homejroy anaconda envsirllibpython sitepackagespygletcanvasxlibpy line in module from import xlibvidmoderestore File homejroy anaconda envsirllibpython sitepackagespygletcanvasxlibvidmoderestorepy line in module from pygletlibsx import xlib File homejroy anaconda envsirllibpython sitepackagespygletlibsx xlibpy line in module XEHeadOfExtensionListargtypes XEDataObject TypeError item in argtypes passes a union by value which is unsupported Any idea what is going on Thanks Edit I use python this error occurs while importing tensorflow version for openai gymPlease suggest any other tensorflow compatible versions The behaviors of Atari envs seem affected by the version of ataripy even though the env id the same python import gym env gymmakeMsPacmanNoFrameskipv envseed envreset done False t R while not done r done envstep t R r printt R Below is the output of this code for each pair of gym and ataripy It seem like ataripy is the cause of the difference but since gym requires ataripy in setuppy from it should be responsible for the version of ataripy That is why I opened this issue here not in gym ataripy gym ataripy gym ataripy gym ataripy gym ataripy gym ataripy gym ataripy gym ataripy I also confirmed such a difference for ChopperCommandNoFrameskipv I am concerned that these differences might significantly affect the evaluation of RL algorithms Has anyone investigated the effect Hi I am wondering for Mujoco tasks such as Hopperv HalfCheetahv and Swimmer what are these the highest score of these tasks we can gain Or how to judge when a task is solved Thanks I have only run a model on pong until now and when I used the gymwrapperMonitor to save the videos in the testing phase it only saved videos of the first two episodes and did not do the same for the rest Since seed is being called in default initialization of Space it should be controllable for reproducibility Hi there Id like to rotate target objectfor example object in default xml file Where is defined setting random position of target position