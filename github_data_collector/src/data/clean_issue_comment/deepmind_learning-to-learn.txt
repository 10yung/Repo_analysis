These requirements makes ticket irrelevant This project would not work with cifar New problems can be implemented very easily You can see in trainpy that the metaminimize method from the MetaOptimizer class is given a function that returns the TensorFlow operation that generates the loss function we want to minimize see problemspy for an example Its important that all operations with Python side effects eg queue creation must be done outside of the function passed to metaminimize The cifar function in problemspy is a good example of a loss function that uses TensorFlow queues I want to add accuracy is like lossbut if i add accuracy in buildaccuracy will like loss doing gradient to weightsSo could you help meThank you very much for your help when i try quadratic and minist expriment produce the follow error TypeError The two structures dont have the same nested structure Entire first structure Entire second structure LSTMStatehidden cell LSTMStatehidden cell please help me how can i address this problem thank you very much This PR solves some issue with running MNIST that can be found here I also added a Python gitignore and the google pylintrc Im trying to run w the following versions in python sonnetversion tensorflowversion and getting the following error python trainpy problemmnist savepathmnist WARNINGtensorflowFrom rootanacondalibpython sitepackagestensorflowcontriblearnpythonlearndatasetsmnistpy DataSetinit from tensorflowcontriblearnpythonlearndatasetsmnist is deprecated and will be removed in a future version Instructions for updating Please use alternatives such as officialmnistdatasetpy from tensorflowmodels Optimizee variables mlplinear w mlplinear b mlplinear w mlplinear b Problem variables Traceback most recent call last File rootanacondalibpython sitepackagestensorflowpythonutilnestpy line in assertsamestructure pywraptensorflowAssertSameStructurenest nest checktypes TypeError The two structures dont have the same nested structure Presumably this is a version issue does anyone know tensorflowsonnet versions where this repo will run Thanks Ben When I try to run problem cifar and cifarmulti experiments I run into an error that the boolean variable istraining is not specified as follows ValueError Boolean istraining flag must be explicitly specified when using batch normalization originally defined at File trainpy line in main problem netconfig netassignments utilgetconfigFLAGSproblem File qydatawwangbccodelearningtooptimizel lutilpy line in getconfig modemode File qydatawwangbccodelearningtooptimizel lproblemspy line in cifar usebatchnormbatchnorm File qydatawwangbcbinanacondalibpython sitepackagessonnetpythonmodulesnetsconvnetpy line in init superConvNet D selfinitnamename File qydatawwangbcbinanacondalibpython sitepackagessonnetpythonmodulesbasepy line in init customgetterselfcustomgetter originally defined at File trainpy line in main problem netconfig netassignments utilgetconfigFLAGSproblem File qydatawwangbccodelearningtooptimizel lutilpy line in getconfig modemode File qydatawwangbccodelearningtooptimizel lproblemspy line in cifar network sntSequential conv sntBatchFlatten mlp File qydatawwangbcbinanacondalibpython sitepackagessonnetpythonmodulessequentialpy line in init superSequential selfinitnamename File qydatawwangbcbinanacondalibpython sitepackagessonnetpythonmodulesbasepy line in init customgetterselfcustomgetter I think the istraining should be passed for the BN of both Conv d and MLP and sntSequential function seems to be misused since we need to pass extra build arguments Whats more the code network sntSequential conv sntBatchFlatten mlp shows that there is only one convolution layer in the network while there should be in the paper Could you please fix the bug and implement the complete layer CNN network Thanks a lot Using Adam optimizer not L L for the CIFAR problem If I print the cost after each epoch it doesnt decrease over time running with learning rate numsteps numepochs However printing the cost for each numstep it decreases within the epoch Why does it seem like the weights are being reset each epoch Ive also added code to check the training and validation accuracy after each epoch These are also not decreasing with each epoch Hi This is of course a minor issue but managed to make it run Ubuntu after installing dill Best Pedro 