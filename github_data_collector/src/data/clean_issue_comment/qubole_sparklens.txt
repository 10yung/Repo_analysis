While reading the for example the Printing Application timeline looking at jobs it is hard to relate a number to an action in the Spark program In the Spark UI there is a solution for this set the sparkjobdescription andor sparkjobGroupid in the driver for every eager action you want the Spark executors to do see the answers to Is it possible to add an option to Sparklens to choose to report the sparkjobdescription andor sparkjobGroupid with its Job id qubolesparklens now has a Chat Room on Gitter iamrohit has just created a chat room You can visit it here This pullrequest adds this badge to your READMEmd Gitter If my aim is a little off please let me know Happy chatting PS Click here if you would prefer not to receive automatic pullrequests from Gitter in future Sparklens is compiled against spark Spark has a dependency on json s wherein Spark onwards json s is used In the later version the method definition of orgjson sJsonMethodsparse has changed Fix uses reflection to resolve this backward incompatibility Added a framework for simplifying adding any metrics to Sparklens report Mapping the nodes of the sparkplan to the stages they were executed as a part of Autodetecting the skew join in the data Still a Work In Progress Following metrics related to the Driver are now reported driverHeapMax Max Heap memory allocated to the driver JVM driverMaxHeapCommitted Max Heap memory committed to the driver JVM driverMaxHeapUsed Max Heap memory used by the driver JVM driverCPUTime Total CPU Time allocated to the driver JVM driverGCCount Total major GCs happened during the lifetime of the JVM driverGCTime Part of driverCPUTime spent in the GC Sample output for a simple application Time spent in Driver vs Executors Driver WallClock Time m s Executor WallClock Time m s Total WallClock Time m s DriverMetrics driverMetrics NAME Value driverCPUTime hh driverGCCount driverGCTime ms driverHeapMax GB driverMaxHeapCommitted MB driverMaxHeapUsed MB When I upload the sparklens report json file to sparklens I dont get any reports delivered I have even checked my spam folders Hi I want to use Sparklens while running Spark Notebooks in a Databricks cluster Is that possible currently Hi First of all amazing project From the report generated from I see the ideal executor plot where it plot the minimal number of executors ideal which could have finished the same work in same amount of wall clock time I am curious what are the formulas equations for such plot If you can give me some explanation on how you guys approach it that would be great Thanks Hi I tried specifying an S location as sparksparklensdatadir and I am getting the following error The issue is reproduced in every job As per my understanding this is the code which is dumping the spark lens json file This should work with S directories as well ERROR Utils uncaught error in thread SparkListenerBus stopping SparkContext javalangExceptionInInitializerError at comamazonwsemrhadoopfsfilesTemporaryDirectoriesGeneratorcreateAndTrackTemporaryDirectoriesGeneratorjava at comamazonwsemrhadoopfsfilesTemporaryDirectoriesGeneratorcreateTemporaryDirectoriesTemporaryDirectoriesGeneratorjava at comamazonwsemrhadoopfss nS NativeFileSystemcreateS NativeFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at comamazonwsemrhadoopfsEmrFileSystemcreateEmrFileSystemjava at comqubolesparklensQuboleJobListenerdumpDataQuboleJobListenerscala at comqubolesparklensQuboleJobListeneronApplicationEndQuboleJobListenerscala at orgapachesparkschedulerSparkListenerBusclassdoPostEventSparkListenerBusscala at orgapachesparkschedulerLiveListenerBusdoPostEventLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusdoPostEventLiveListenerBusscala at orgapachesparkutilListenerBusclasspostToAllListenerBusscala at orgapachesparkschedulerLiveListenerBuspostToAllLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applymcVspLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applyLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applyLiveListenerBusscala at scalautilDynamicVariablewithValueDynamicVariablescala at orgapachesparkschedulerLiveListenerBusanon anonfunrun applymcVspLiveListenerBusscala at orgapachesparkutilUtilstryOrStopSparkContextUtilsscala at orgapachesparkschedulerLiveListenerBusanon runLiveListenerBusscala Caused by javalangIllegalStateException Shutdown in progress at javalangApplicationShutdownHooksaddApplicationShutdownHooksjava at javalangRuntimeaddShutdownHookRuntimejava at comamazonwsemrhadoopfsfilesTemporaryDirectoryShutdownHookclinitTemporaryDirectoryShutdownHookjava more ERROR Utils throw uncaught fatal error in thread SparkListenerBus javalangExceptionInInitializerError at comamazonwsemrhadoopfsfilesTemporaryDirectoriesGeneratorcreateAndTrackTemporaryDirectoriesGeneratorjava at comamazonwsemrhadoopfsfilesTemporaryDirectoriesGeneratorcreateTemporaryDirectoriesTemporaryDirectoriesGeneratorjava at comamazonwsemrhadoopfss nS NativeFileSystemcreateS NativeFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at comamazonwsemrhadoopfsEmrFileSystemcreateEmrFileSystemjava at comqubolesparklensQuboleJobListenerdumpDataQuboleJobListenerscala at comqubolesparklensQuboleJobListeneronApplicationEndQuboleJobListenerscala at orgapachesparkschedulerSparkListenerBusclassdoPostEventSparkListenerBusscala at orgapachesparkschedulerLiveListenerBusdoPostEventLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusdoPostEventLiveListenerBusscala at orgapachesparkutilListenerBusclasspostToAllListenerBusscala at orgapachesparkschedulerLiveListenerBuspostToAllLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applymcVspLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applyLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applyLiveListenerBusscala at scalautilDynamicVariablewithValueDynamicVariablescala at orgapachesparkschedulerLiveListenerBusanon anonfunrun applymcVspLiveListenerBusscala at orgapachesparkutilUtilstryOrStopSparkContextUtilsscala at orgapachesparkschedulerLiveListenerBusanon runLiveListenerBusscala Caused by javalangIllegalStateException Shutdown in progress at javalangApplicationShutdownHooksaddApplicationShutdownHooksjava at javalangRuntimeaddShutdownHookRuntimejava at comamazonwsemrhadoopfsfilesTemporaryDirectoryShutdownHookclinitTemporaryDirectoryShutdownHookjava more INFO SparkContext SparkContext already stopped Exception in thread SparkListenerBus javalangExceptionInInitializerError at comamazonwsemrhadoopfsfilesTemporaryDirectoriesGeneratorcreateAndTrackTemporaryDirectoriesGeneratorjava at comamazonwsemrhadoopfsfilesTemporaryDirectoriesGeneratorcreateTemporaryDirectoriesTemporaryDirectoriesGeneratorjava at comamazonwsemrhadoopfss nS NativeFileSystemcreateS NativeFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemjava at comamazonwsemrhadoopfsEmrFileSystemcreateEmrFileSystemjava at comqubolesparklensQuboleJobListenerdumpDataQuboleJobListenerscala at comqubolesparklensQuboleJobListeneronApplicationEndQuboleJobListenerscala at orgapachesparkschedulerSparkListenerBusclassdoPostEventSparkListenerBusscala at orgapachesparkschedulerLiveListenerBusdoPostEventLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusdoPostEventLiveListenerBusscala at orgapachesparkutilListenerBusclasspostToAllListenerBusscala at orgapachesparkschedulerLiveListenerBuspostToAllLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applymcVspLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applyLiveListenerBusscala at orgapachesparkschedulerLiveListenerBusanon anonfunrun anonfunapplymcVsp applyLiveListenerBusscala at scalautilDynamicVariablewithValueDynamicVariablescala at orgapachesparkschedulerLiveListenerBusanon anonfunrun applymcVspLiveListenerBusscala at orgapachesparkutilUtilstryOrStopSparkContextUtilsscala at orgapachesparkschedulerLiveListenerBusanon runLiveListenerBusscala Caused by javalangIllegalStateException Shutdown in progress at javalangApplicationShutdownHooksaddApplicationShutdownHooksjava at javalangRuntimeaddShutdownHookRuntimejava at comamazonwsemrhadoopfsfilesTemporaryDirectoryShutdownHookclinitTemporaryDirectoryShutdownHookjava more INFO YarnClusterSchedulerBackend Shutting down all executors I am trying to run sparklens on event logs of my application I am using following command binsparksubmit packages qubolesparklens s master local class comqubolesparklensappReporterApp quboledummyarg fileUsersshasidharinterestssparklenseventlogtxt sourcehistory I see following output in console Ivy Default Cache set to Usersshasidharivy cache The jars for the packages stored in Usersshasidharivy jars loading settings url jarfileUsersshasidharinterestssparkspark binhadoop jarsivy jarorgapacheivycoresettingsivysettingsxml qubolesparklens added as a dependency resolving dependencies orgapachesparksparksubmitparent confs default found qubolesparklens s in sparkpackages resolution report resolve ms artifacts dl ms modules in use qubolesparklens s from sparkpackages in default modules artifacts conf number searchdwnldedevicted numberdwnlded default retrieving orgapachesparksparksubmitparent confs default artifacts copied already retrieved kB ms WARN NativeCodeLoader Unable to load nativehadoop library for your platform using builtinjava classes where applicable Warning Local jar Usersshasidharinterestssparkspark binhadoop quboledummyarg does not exist skipping INFO ShutdownHookManager Shutdown hook called INFO ShutdownHookManager Deleting directory privatevarfolders trfd djjs yg mhmw zs tw gpTspark a a f f ddade b a What exactly I need to look at after this Does it generate sparklens json file If yes where I can see the output file 