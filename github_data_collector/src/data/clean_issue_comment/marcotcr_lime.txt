 grafik In this graphic what does the actually mean in odorfoul I assume its a probability How do the individual values contribute to the final explanation If edible is how can there be gillsizebroad of which should increase the probability of edible Thank you error code E Soft anaconda envs retinanet lib sitepackages lime limeimagepy in datalabelsself image fudgedimage segments classifierfn numsamples batchsize labelsextendpreds imgs pbarcurrval pbarupdate pbarfinish AttributeError ProgressBar object has no attribute currval Package version lime progressbar progressbar Dear Marco I have read your paper and use LIME to explain my model in Kaggle Default Risk competion data and encounter some struggle as following How can LIME choose or calculate xz Please refer your source code that is related to this part How can LIME divide group of each variables in its explanation Please help me address these issue thank you in advance Hi there I m trying to use the table explainer on categorical data and I have a highly dimensional dataset so I have to take a sample out of the dataset I fit the Label encoder and the One Hot encoder on the entire dataset and try to fit it but I m getting the error catfeat feat feat feat dfsample dfmsample labels dfsamplediscreas dfcat dfsample catfeat copy dfcatfillnaNA inplaceTrue categoricalnames for feature in catfeat le LabelEncoderfitdfm feature fillnaNA dfcat feature letransformdfcat feature categoricalnames feature leclasses dfcat dfcatastypefloat onehotencoder OneHotEncodercategoriesautofitdfm catfeat fillnaNA Xtrain Xtest ytrain ytest traintestsplitdfcat labels encodedtrain onehotencodertransformXtrain mdlc RandomForestClassifiernjobs nestimators mdlcfitencodedtrain ytrain predictfn lambda x mdlcpredictprobaonehotencodertransformx explainer limelimetabularLimeTabularExplainerXtrainvalues classnameslabels featurenames catfeat categoricalfeatures lendfcat categoricalnamescategoricalnames exp explainerexplaininstanceXtestvalues predictfn expshowinnotebook ValueError Found unknown categories in column during transform Any idea on what s going on Thanks Hello The only class Im using from lime is LimeTextExplainer Im trying to fit it into AWS lambda limitation which is mb Lime alone with all dependencies has this size Do you know maybe a way how to shrink it Hello First I would like to thank you for a very nice tool and for very efficient support and issues handling I am trying to use LimeTextExplainer with a bert model finetuned for YelpReviewsPolarity I was using the structure i found on The thing is that when evaluating a transformerbased classifier or any DNN for that matter the last layer is not softmaxed but rather argmaxed by default inorder to use LimeTextExplainer I wrote an additional method called predictprobastrlist nparray that return the desired np array of probabilities However since softmax is a rather arbitrary way to normalize the logits into the interval I played a little with the softmax temperature the result was a bit surprising first of all the word importance order seems to change while i was assuming it should be invariant to monotonous transformation second for some of the temperatures the values each word got became very small making it hard to display on default settings see attached screenshots In order to check this issue I also ran LimeTextExplainer on a default params RandomForest with an additional softmaxtemperature at the end and got similar behavior can you explain these results could you elaborate on the best practices to implement the necessary predictproba method is there a better way to normalize aside from softmax what causes the word coefficients to vanish thanks a lot Carmel code def predictprobaself strlist This function is fed to LimeTextExplainerexplaininstance as the classifierfn it gets a list of strings and gives back an nparray of probabilities that LIME needs to fit the explanations decision boundery Arguments strlist liststr list of strings if a single text is given it should be wrapped in len list Returns nparray an array of dimstrlistlen numoflabels of the probabilities for each label dataset selfconvertstrlisttodatasetstrlist evalsampler SequentialSamplerdataset dataloader DataLoader dataset samplerevalsampler batchsizeselfbatchsize preds None outlabelids None might be important for other transformers for batch in dataloader selfmodeleval batch tuplettoselfdevice for t in batch with torchnograd inputs inputids batch attentionmask batch if selfmodeltype in selftransformersmodels else None tokentypeids batch XLM dont use segmentids if selfmodeltype in bert xlnet else None outputs selfmodelinputs logits outputs in case modelforward gives more than one output then logits should be the first logits logitsdetachcpunumpy Lime collects the logits from ALL examples so it needs to detach each batchs logits form device back to cpu if preds is None preds logits outlabelids inputs labels detachcpunumpy else preds npappendpreds logits axis outlabelids npappendoutlabelids inputs labels detachcpunumpy axis if selfsoftmaxT is not None proba softmaxTpreds thetaselfsoftmaxT axis return proba else return preds screenshots Hello everyone I have trained my dataset with XGBoost classifier and used Pandas dataframe directly as Input data the Code is as follows Read csv file and prepare Input and Target columns df pdreadcsvBrokencsv encodingISO sep X df drop C axis Input column dropping the target column y df C Target column split test and Train dataset Xtrain Xtest ytrain ytest traintestsplitX y testsize Train using XGBoost classifier from xgboost import XGBClassifier xg XGBClassifier xgfitXtrain ytrain after Training i am trying to use LIME to slice through the dataframe I am using the iloc command but still i get an error TypeError sliceNone None None is an invalid key My Code is as follows prepare feature names for LIME Tabular explainer columnsNamesArr Xcolumnsvalues get column names from df listOfColumnNames listcolumnsNamesArr convert it to a list Column used as target breakage df C values get target values to be used in LIME tabular explainer LIME explainer explainer limelimetabularLimeTabularExplainerXtrainiloc featurenameslistOfColumnNames classnamesbreakageverboseTrue modeclassification which gives the error TypeError sliceNone None None is an invalid key Can anyone suggest where i am going wrong I just add a filter before selection features When I use LIME to get an explanation with a model I wouldnt get some features are come out in explanation result So I implement a filter before the feature selection That also can decrease the feature selections search space to speed up the feature selection Hi Ive used Lime on a pytorch CNN model trained on the MNIST dataset The problem Im having is that it works fine for most instances where it properly displays the boundaries but on certain predictions the following code temp mask explanationgetimageandmaskexplanationtoplabels positiveonlyTrue numfeatures hiderestFalse imgboundry markboundariestemp mask pltimshowimgboundry would just show the base image and setting positiveonly to False makes the entire image green with no boundaries Am I doing something wrong It works for some images and others have this issue I have an error as below Please help me explainerLimeone limelimetabularLimeTabularExplainerfulltrainnpary moderegression featurenames None featureselection lassopath Limeonemodel explainerLimeoneexplaininstancefulltestnpary modelpredict numfeatures AssertionError Traceback most recent call last C ProgramData Anaconda lib sitepackages lime limetabularpy in explaininstanceself datarow predictfn labels toplabels numfeatures numsamples distancemetric modelregressor try assert isinstanceyss npndarray and lenyssshape except AssertionError AssertionError During handling of the above exception another exception occurred ValueError Traceback most recent call last ipythoninput cb b c b in module Limeonemodel explainerLimeoneexplaininstancefulltestnpary modelpredict numfeatures C ProgramData Anaconda lib sitepackages lime limetabularpy in explaininstanceself datarow predictfn labels toplabels numfeatures numsamples distancemetric modelregressor except AssertionError raise ValueErrorYour model needs to output singledimensional numpyarrays not arrays of dimensionsformatyssshape predictedvalue yss ValueError Your model needs to output singledimensional numpyarrays not arrays of dimensions FYI fulltestnpary shape typefulltestnpary numpyndarray modelsummary Layer type Output Shape Param dense Dense None dense Dense None dense Dense None dense Dense None dense Dense None 