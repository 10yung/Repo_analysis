Hi Im trying to understand if I could use brigade to implement the following workflow one job is already running triggered by a push to a GitHub repository another commit is pushed triggering a new event before starting the job for a new event the previous running job is terminated once the old job is terminated the new one is started allowing for only one job the latest at any given time Not knowing brigade really well Im not sure of which part should be modified to allow that Would a brigadejs file be able to do those actions Or would it make more sense to write a custom gateway and possibly use some external state or just the kubernetes API Thank you in advance for taking a look at this This vcssidecar failure has happened times in recent memory but very intermittently Has anyone experienced this or knows of steps to prevent this failure Thanks in advance Output of kubectl logs BRIGADECONTAINERNAME c vcssidecar refsheadsmaster vcs refspecrefsheadsmaster git lsremote exitcode COMPANYNAMEvssshvisualstudiocomv COMPANYNAMETEAMPROJECTNAMEKubeBrigadeScript refsheadsmaster cut f Warning Permanently added vssshvisualstudiocom RSA to the list of known hosts remote A connection attempt failed because the connected party did not properly respond after a period of time or established connection failed because connected host has failed to respond fatal Could not read from remote repository Please make sure you have the correct access rights and the repository exists fullref git init q vcs cd vcs retry git fetch q force updateheadok COMPANYNAMEvssshvisualstudiocomv COMPANYNAMETEAMPROJECTNAMEKubeBrigadeScript refsheadsmaster local n local max local delay true git fetch q force updateheadok COMPANYNAMEvssshvisualstudiocomv COMPANYNAMETEAMPROJECTNAMEKubeBrigadeScript refsheadsmaster Warning Permanently added vssshvisualstudiocom RSA to the list of known hosts break retry git checkout q force refsheadsmaster local n local max local delay true git checkout q force refsheadsmaster error pathspec refsheadsmaster did not match any files known to git test lt echo Command failed Attempt Waiting for seconds before retrying sleep Command failed Attempt Waiting for seconds before retrying n true git checkout q force refsheadsmaster error pathspec refsheadsmaster did not match any files known to git test lt echo Command failed Attempt Waiting for seconds before retrying sleep Command failed Attempt Waiting for seconds before retrying n true git checkout q force refsheadsmaster error pathspec refsheadsmaster did not match any files known to git Command failed Attempt Waiting for seconds before retrying test lt echo Command failed Attempt Waiting for seconds before retrying sleep n true git checkout q force refsheadsmaster error pathspec refsheadsmaster did not match any files known to git test lt echo Command failed Attempt Waiting for seconds before retrying sleep Command failed Attempt Waiting for seconds before retrying n true git checkout q force refsheadsmaster error pathspec refsheadsmaster did not match any files known to git test lt fail The command has failed after attempts echo The command has failed after attempts The command has failed after attempts exit Output of brig version v g b be Output of kubectl version Client Version versionInfoMajor Minor GitVersionv GitCommit db a d dbc fa b e GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformdarwinamd Server Version versionInfoMajor Minor GitVersionv GitCommit da ba ad e d a d e f GitTreeStateclean BuildDate T Z GoVersiongo Compilergc Platformlinuxamd Cloud ProviderPlatform AKS GKE Minikube etc AKS If you use the brig CLI to create projects you dont have many options for adding values ex sshKey after initial creation The options as I currently see them are using brig CLI brig project get orgprojectname projectjson edit the json to include your desired values brig project delete orgprojectname brig project create f projectjson x using kubectl kubectl edit secret brigadeprojectid addmodify additional values in plaintext under the stringData toplevel key rather than data allowing the API to base encode the values OR base encode the values yourself and add them to the data key use the helm chart to create projects this chart has all of the hooks to getsetmodify values built in already this method is considered deprecated so it probably shouldnt be usedrecommended Proposals create brig project edit verb that bring up the project in EDITOR similar to kubectl edit create brig project getvalue and brig project setvalue verbs create a helmlike set flag on one or more of the existing verbs This probably isnt a huge deal once youve got a project established and working but Im currently in the experimentation phase and the effort required to addmodify a value seems higher than it should be I realize this may be nullified by whatever v s configuration documentmechanism is but project modification should still be a consideration going forward A manual inputconfigmation step would be useful in some types of workloads For example it could be implemented by adding a service ingressservicedeployment to Brigadejs API or by combination of dependecies in a project trigger an event from another project generic gateway with an extra input or one time secret It would be easier to manage secrets if projects configuration would only have references to particular secrets Eg this could allow jobs running in different namespaces to directly access secrets deployed there Generic gateway secret should be stored securely as a hash eg Argon Right now Generic Gateways secret is send in a path It could be logged by proxies Common approach is to use Authorization HTTP Header There are cases where a gateway in its capacity as the event broker seems like the logical candidate to take responsibility for reporting build andor job status upstream to the original source of the event To illustrate lets consider a scenario were familiar with today GitHub webhooks and statuses reported back to GH via its checks API and lets consider how our handling of that could be improved Currently GW receives a checksuiterequested or checksuiterequested event for example from GitHub Knowing that workers and jobs have no inherent permissions to report status back to GH using the checks API the gateway wraps the original payload in a new object that also encapsulates a token This new object becomes the payload that is added to the event that is emitted into Brigade The author of the brigadejs needs to be aware that depending on the type of event they are receiving there may or may not be a wrapper around the original payload In the case of a checksuiterequested or checksuiterequested event for example they extract the original payload from the wrapper before proceeding The author of the brigadejs may optionally retrieve the token that the gateway added to the payload This can be utilized in creating job sandwiches wherein every principal job in the pipeline is preceded and followed by additional jobs that use the token and the GH checks API to report job status This process is problematic mostly because brigadejs authors need to know too much about how the gateway has handled specific event payloads and brigadejs authors are left responsible for something the gateway probably could have handled itself It also delegates the worker permissions that it doesnt otherwise need An improved process could look like this GW receives an event of any type from GH and treats them all the same Every payload is passed on as is Knowing that workers and jobs have no inherent permissions to report status back to GH using the checks API for applicable event types the gateway adds a callback URL to a new field on the event not to a wrapper around the payload The author of the brigadejs can use the callback URL to report status to the gateway as each job starts and again as each completes Alternatively brigadier could be updated to do this automatically on job start and completion ifwhen such a callback URL is defined The GW receives the callback and uses the GH checks API to report status back to GH Please keep in mind that GH and the GH gateway are used above only for illustration This proposal could quite easily streamline the process of status reporting for quite a wide variety of events from quite a wide variety of sources Currently the controller passes most configuration to a worker through environment variables set on the workers container Some configuration however is obtained by the worker through an alternative channel it must use the k s API to locate and read the project secret At minimum the worker could be spared some effort by the controller mounting the project secret to the file system This lowers the bar for what is expected of custom workers and possibly moves us toward further restricting permissions on workers to make Brigade more secure on the whole Better still we could consider consolidating the two methods through which the controller passes configuration to the worker so that we dont have some set as environment variables and other configuration passed in via a secret Related to Currently the only record of a build is its underlying Kubernetes secret see Related the ability to inspect a builds results view logs etc depends entirely on the continued existence of the pods that implemented that builds jobs This effectively presents users with a choice between accepting a cluster littered with completed pods or cleaning up periodically and losing a potentially valuable papertrail of build results which for some use cases in some industries may not be an option It seems that there would be a lot to be gained by streaming worker and job logs somewhere where they can be persisted Doing so would enable us to clean up completed job pods more aggressively perhaps even having the worker do this immediately upon completion