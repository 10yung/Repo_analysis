Updates comgithubgseitzsbtrelease from to Release NotesChangelog Ill automatically update this PR to resolve conflicts as long as you dont change it yourself If youd like to skip this version you can just close this PR If you have any feedback just mention me in the comments below Have a fantastic day writing Scala details summaryIgnore future updatessummary Add this to your scalastewardconf file to ignore future updates of this dependency updatesignore groupId comgithubgseitz artifactId sbtrelease details labels sbtpluginupdate semverpatch Updates orgscalasbtsbt from to Release NotesChangelog Ill automatically update this PR to resolve conflicts as long as you dont change it yourself If youd like to skip this version you can just close this PR If you have any feedback just mention me in the comments below Have a fantastic day writing Scala details summaryIgnore future updatessummary Add this to your scalastewardconf file to ignore future updates of this dependency updatesignore groupId orgscalasbt artifactId sbt details labels libraryupdate semverpatch Updates comgoogleapisgoogleapiservicesbigquery from v rev to v rev Ill automatically update this PR to resolve conflicts as long as you dont change it yourself If youd like to skip this version you can just close this PR If you have any feedback just mention me in the comments below Have a fantastic day writing Scala details summaryIgnore future updatessummary Add this to your scalastewardconf file to ignore future updates of this dependency updatesignore groupId comgoogleapis artifactId googleapiservicesbigquery details labels libraryupdate If a record has nested repeated fields of different lengths BigDiffy incorrectly reports the differences There are two problems It directly sorts zips and compares so sorted elements can get offset and compared incorrectly It doesnt report that an item on the LHS or RHS was missing because of how the zip call functions Over time weve had some things leak into the diff methods that make it more cumbersome to use BigDiffy via code instead of CLI For example diffAvro here User has to manually pass in schema otherwise we they receive a noninformative error regarding null schema additionally user has to construct MultiKey manually even if still using a single key We should probably automatically retrieve the schema and pass in a keys string instead which will better match other parameters such as those passed into AvroDiffy Trying to run the diff also has an unclear two step process First create the diff then call saveStats We should document this properly or simplify the process Also passing in some SpecificRecord T results in a strange casting error and instead the user needs to pass a GenericRecord I just started using ratatool today and am using it for CaseClass and Avro generation I believe theres an issue in the way it handles or fails to handle logical types in avro Im using javascala type BigDecimal which in schema looks like this newlines added by me for easier reading json namecost type typebytes logicalTypedecimal precision scale Decimal logical type is documented here Whats happening when attempting to use avroOf MyGenericRecord is the type pattern match found in AvroGeneratorscala hits SchemaTypeBYTES and can generate byte Later the AvroCodec which does honor the BigDecimal logical type attempts to convert byte into a BigInteger see which fails with NumberFormatExceptionZero length BigInteger I feel theres a few options which could be done independently here Ill PR as Im able document the current limitation add support for common documented logical types to ratatool likely these can be done in independent PRs Scio master since beta has switched to latest magnolia for Scala while pinging my fork jto for Scala which is no longer supported Mixing different magnolia versions has caused problem in the past I portedcleaned up some common type classes into this new lib Itd be nice to consolidate various magnolia derivation code there case class generators port shapeless based diffy magnoliabased TBD WDYT A library should not contain application wide configuration In this particular case log jproperties should not be part of ratatoolcommon project Hackday project in need of feedback Working with data youre interested in Shape of data which could be your schema General case which is addressed by bigSampler Edge cases which this PR tries to tackle Its inspired by summary from R Todo Property and unit tests Support booleans Support floating point numbers Support for different formats protobuf Need to benchmark the multi key support changes introduced in to make sure the value class optimization is actually kicking in and theres no overhead of boxing