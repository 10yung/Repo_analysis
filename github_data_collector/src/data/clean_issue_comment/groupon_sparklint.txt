Attempting to run the embedded listener in sparkshell as sparkshell mastersparklocalhost conf sparkextraListenerscomgrouponsparklintSparklintListener packages comgrouponsparklintsparklintspark Results in shell exiting with javalangNoClassDefFoundError orghttp spackageHttpService Caused by javalangClassNotFoundException orghttp spackageHttpService at javanetURLClassLoaderfindClassURLClassLoaderjava at javalangClassLoaderloadClassClassLoaderjava at sunmiscLauncherAppClassLoaderloadClassLauncherjava at javalangClassLoaderloadClassClassLoaderjava more Welcome to version Using Scala version OpenJDK Bit Server VM Java java version openjdk version OpenJDK Runtime Environment build b OpenJDK Bit Server VM build b mixed mode I have set up sparklint in server mode using their docker image and added the spark event log directory of my streaming jobs as a source but the spark lint UI shows that the jobs are complete and active Is this a configuration issue or some problem with the docker image I have followed the instruction on their wiki Appreciate any pointers on this We would like to monitor live spark jobs in server mode We want all spark jobs to be in one place When you run in live mode there is only one SparkLint UI per job We would like all finished and running jobs to be under one SparkLint UI We are able to run in live mode where there is only one job per UI In server mode it seems to only show spark jobs that have finished Is there a way to see all jobs old and running in server mode Hi roboxue Can sparklint work on standalone spark cluster Thanks XD Hi So Ive just started using Databricks and Im pretty stoked about being able to use sparklint and checking on my jobs I currently upload my jars to Databricks and then invoke the methods that I am interested in I tried including sparklint from the sbt file as mentioned but the compilation always fails Let me know if you would want to see the logs in detail I will upload them if you would like to I then compiled only the sparklint code and uploaded it as a separate jar attached it to my cluster and in the other jar that holds my code I added the lines sparkconfsetsparkextraListeners comgrouponsparklintSparklintListener sparkconfsetsparksparklintport However I am unable to access the port or see any sort of indication in the logs that sparklint has been active during the job execution Can you please help me get this going on Databricks Hi Can sparklint also show this on the dashboard heap memory utilization for driver and executors Amount of data spilled to disk Thanks Manish It would be super nice if app can recommend sparksubmit parameters for the jobs One small comment The necessity of pressing playfast forward buttons is not intuitive Firstly I closed the application thinking that it isnt working A small popup that shows those buttons may be convenient Overall great app It helps a lot thank you so much Keep up the good work I have tried a few combinations when starting the UI docker run v pathtologsdirlogs p roboxuesparklint d logs open localhost But if I have lz files in the directory they are not picked up as sources I notice there is some code in sparklint that uses the lz codec Hi Tried the instruction provided in When I do a spark submit I do see the logs which says the below But when I hit the driver IP with port I cannot see the UI Could you please help me Are there any additional configs to be applied Logs INFO nio NIO SocketServerGroup Service bound to address INFO sparklintSparklint Server started on INFO sparkSparkContext Registered listener comgrouponsparklintSparklintListener I am unable to add the history server link which is hosted on Microsoft Azure HDInsight cloud I get the error unexpected HTTP status Credentials missing or Auth is not Basic Is there any way to provide the credentials