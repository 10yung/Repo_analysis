 Thanks for publishing this library I have been looking for something like this including Relaxed Radix Balanced Trees RRB trees trying to determine precisely how to guarantee Olog n time for arbitrary sequences of operations that include concatenating two Btrees used to represent integerindexed arrays The challenge seems to be to guarantee that the heightdepth of the tree does not exceed Olog n for an arbitrary sequence of concatenate split append prepend etc operations Does this library andor your book Optimizing Collections contain any kind of proof or argument that this is the case For example do you have any kind of invariants on the shape of the BTree data structure that is always true regardless of the sequence of operations that produced them that guarantee the depth remains at most Olog n Right now half open ranges and closed ranges are supported but there is no support for getting a fully open range start end or a half open range where the halfopen boundary is on the lower end start end I suggest to add methods suffixafter to BTree and SortedSet where I need it I can help with a MR if wanted This fix suspends BridgedLists countByEnumerating func on Linux Swifts Collection protocol has a number of nontrivial semantic constraints that are rather underdocumented one of these is that a collections SubSequence must be a collection that shares indices with the original instance The type system is currently not even able to enforce the requirement about SubSequence being a collection or that its index type must be the same as the toplevel collection Presumably these are going to be fixed but the requirement about sharing index values is unlikely to be ever enforced by the type system Slices of valid collections should have their start index the same as the index of their starting element in the original collection BTree gets this wrong let list List printlist startIndex let array Array printarray startIndex This means BTrees collection types arent really collections The way to fix this is to replace the custom SubSequence typealiases with one of the default Slice types in each This is a sourcebreaking change so it requires a major version bump The original BTree slicing behavior ie extracting a separate subcollection of the same type will be moved to a family of functions listextract or listsublist or somesuch Now that SE moved index manipulation methods into collections it would be possible to switch to unownedunsafe references inside BTreeWeakPath probably speeding up indexing considerably Perhaps even making indexing competitive with iteration This requires much more careful index invalidation so is likely a prerequisite SE BTree implements orderstatistic trees ie trees where each node maintains a count of all elements in the subtree under it This allows offsetbased access in logarithmic time which is highly useful eg we cant have a useful List without integer indices and offsetbased access also greatly enhances the usefulness of SortedSet and Map However maintaining these element counts doesnt come free they clearly have a performance cost It would be nice if we had a BTree variant that wasnt augmented if only to measure how much performance the augmentation costs If this cost is too large it might be worthwhile to provide an unaugmented BTree variant Furthermore while counting is probably the most frequently useful tree augmentation sometimes other statistics are needed The code that implements the counting augmentation can be generalized to provide quick logn access to the result of any monoid operation over a sequence of tree elements Some examples Counting this is what we already have Augmenting the tree with counts allows for efficient retrieval of elements at any offset enables fast navigation inside the tree etc count count counta b counta countb Weight The weight is a variant of counting where each element may have a different weight in the sum For example lets say the elements of the tree are themselves collections and the tree is used to represent a concatenation of its elements Augmenting the tree using a weight calculated from the sizes of each element enables efficient offsetbased access to any element in the concatenated list weight weight e eweight weighta b weighta weightb Maximum or minimum over some secondary key extracted from the elements Beyond getting easy access to the element that has the largestsmallest such key this also gives us an easy way to get the largestsmallest element to the left or right to any other element this has interesting applications max infinity max e keye maxa b maxmaxa maxb Any combinations of the above and more We could support interval trees wellseparated point pair decompositions etc Generalizing the existing BTreeNode to implement any such monoidcached tree would be straightforward but it would probably slow things down even more So itd probably be better to do support this in a separate implementation You mention that forEach is more efficient than a regular for loop for BTrees which isnt really ideal Its true that its a lot easier to write an efficient forEach implementation than to write an efficient iterator but its possible to write an efficient iterator As a proof of concept heres an improved BTreeIterator public class BTreeIteratorKey Comparable Value IteratorProtocol public typealias Element Key Value typealias Node BTreeNodeKey Value let node Node var iterator BTreeIterator var index initroot Node node root incrementChildIterator private func incrementChildIterator index if nodeisLeaf index nodechildrencount iterator nodechildren index makeIterator public func next Element if let childIterator iterator if let nextElement childIteratornext return nextElement else iterator nil return next else guard index nodeelementscount else return nil defer incrementChildIterator return nodeelements index My benchmarks show no significant performance difference between forin and forEach now Let me know what you think It would be nice if a native English speaker reviewed the documentation and fixed my bad grammar Also Id love to have a list of places where the existing text does a bad job of explaining the API 