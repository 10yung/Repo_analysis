I was trying to run the approx functions locally However they behaved differently from whats one the tutorial The approx sum needs arguments and I am not sure what to put in order to approximate Can someone help me use them Also I cannot use error samplewith shark describe rand OK numbers int Time taken seconds shark select approxsumnumbers from rand GC Metadata GC Threshold K K K secs Full GC Metadata GC Threshold K K K secs GC Systemgc K K K secs Full GC Systemgc K K K secs GC Systemgc K K K secs Full GC Systemgc K K K secs FAILED Error in semantic analysis Exactly one argument is expected shark select approxsumnumbers numbers numbers from rand GC Allocation Failure K K K secs GC Allocation Failure K K K secs GC Allocation Failure K K K secs OK NaN Confidence Time taken seconds Hi We are in the process of evaluating BlinkDB for supporting interactive count queries on a table with various filters As per we need to Copy the Spark and BlinkDB directories to slaves But from few talks i saw for BlinkDB looks like only spark client needs to be modified so that it modifies query plan to use sample tables instead of original table That means it is necessary for us to build install BlinkDB on only machine Please correct me if i am wrong about this Since our organization is huge it would be difficult to ask infrastructure team to apply patch on spark for supporting BlinkDB We are using Spark version currently It will be easier for us to ask our infrastructure team to upgrade Spark Version So wondering by when native support of BlinkDB will be available in Spark Also would be grateful if one can point us to documentation for creating proof of concept around BlinkDB sameeragarwal I use BlinkDB CLIand run simple SQL queries like select count from src within seconds I run into an error FAILED Parse Error line Failed to recognize predicate within Failed rule kwInner in join type specifier Blinkdb will fail if using SERDE for example ROW FORMAT SERDE orgopenxdatajsonserdeJsonSerDe JsonSerDe class will not be found because blinkdb will convert the command to ROW FORMAT SERDE orgopenxdatajsonserdejsonserde Suggest to modify SharkDriverscala line When I run simple SQL queries like Select approxcount from table where A xx within seconds I run into an error Parse Error mismatched input within expecting EOF near table Does blinkdb support clauses like within xx seconds as shown in the paper as running examples ERROR hivelog orgapachehadoopipcRemoteException Server IPC version cannot communicate with client version at orgapachehadoopipcClientcallClientjava at orgapachehadoopipcRPCInvokerinvokeRPCjava at comsunproxyProxy getProtocolVersionUnknown Source at orgapachehadoopipcRPCgetProxyRPCjava at orgapachehadoopipcRPCgetProxyRPCjava at orgapachehadoophdfsDFSClientcreateRPCNamenodeDFSClientjava at orgapachehadoophdfsDFSClientinitDFSClientjava at orgapachehadoophdfsDFSClientinitDFSClientjava at orgapachehadoophdfsDistributedFileSysteminitializeDistributedFileSystemjava at orgapachehadoopfsFileSystemcreateFileSystemFileSystemjava at orgapachehadoopfsFileSystemaccess FileSystemjava at orgapachehadoopfsFileSystemCachegetFileSystemjava at orgapachehadoopfsFileSystemgetFileSystemjava at orgapachehadoopfsFileSystemgetFileSystemjava at orgapachehadoopfsFileSystemgetFileSystemjava at orgapachehadoopfsPathgetFileSystemPathjava at orgapachehadoophivemetastoreWarehousegetFsWarehousejava at orgapachehadoophivemetastoreWarehousegetDnsPathWarehousejava at orgapachehadoophivemetastoreWarehousegetWhRootWarehousejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlergetDefaultDatabasePathHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlercreateDefaultDBcoreHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlercreateDefaultDBHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlerinitHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlerinitHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreClientinitHiveMetaStoreClientjava at orgapachehadoophiveqlmetadataHivecreateMetaStoreClientHivejava at orgapachehadoophiveqlmetadataHivegetMSCHivejava at orgapachehadoophiveqlmetadataHivegetAllDatabasesHivejava at sharkmemstore TableRecoveryreloadRddsTableRecoveryscala at sharkSharkCliDriverinitSharkCliDriverscala at sharkSharkCliDrivermainSharkCliDriverscala at sharkSharkCliDrivermainSharkCliDriverscala Exception in thread main orgapachehadoophiveqlmetadataHiveException MetaExceptionmessageGot exception orgapachehadoopipcRemoteException Server IPC version cannot communicate with client version at orgapachehadoophiveqlmetadataHivegetAllDatabasesHivejava at sharkmemstore TableRecoveryreloadRddsTableRecoveryscala at sharkSharkCliDriverinitSharkCliDriverscala at sharkSharkCliDrivermainSharkCliDriverscala at sharkSharkCliDrivermainSharkCliDriverscala Caused by MetaExceptionmessageGot exception orgapachehadoopipcRemoteException Server IPC version cannot communicate with client version at orgapachehadoophivemetastoreMetaStoreUtilslogAndThrowMetaExceptionMetaStoreUtilsjava at orgapachehadoophivemetastoreWarehousegetFsWarehousejava at orgapachehadoophivemetastoreWarehousegetDnsPathWarehousejava at orgapachehadoophivemetastoreWarehousegetWhRootWarehousejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlergetDefaultDatabasePathHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlercreateDefaultDBcoreHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlercreateDefaultDBHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlerinitHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreHMSHandlerinitHiveMetaStorejava at orgapachehadoophivemetastoreHiveMetaStoreClientinitHiveMetaStoreClientjava at orgapachehadoophiveqlmetadataHivecreateMetaStoreClientHivejava at orgapachehadoophiveqlmetadataHivegetMSCHivejava at orgapachehadoophiveqlmetadataHivegetAllDatabasesHivejava more Hi Any help would be appreciated I have followed the instruction to build blinkDB however when I firstly using ant building the submodule hiveblinkdb to the line ant package the version is cd blinkdb git submodule init git submodule update cd hiveblinkdb ant package errors exit asI changed nothing of the blinkDB files and settings ivyretrieve echo Project shims compile echo Project shims echo Building shims buildshims echo Project shims echo Compiling homeljzblinkDBblinkdbhiveblinkdbshimssrccommonjavahomeljzblinkDBblinkdbhiveblinkdbshimssrc java against hadoop homeljzblinkDBblinkdbhiveblinkdbbuildhadoopcorehadoop ivyinitsettings echo Project shims ivyresolvehadoopshim echo Project shims ivyresolve loading settings file homeljzblinkDBblinkdbhiveblinkdbivyivysettingsxml ivyretrievehadoopshim echo Project shims echo Building shims S buildshims echo Project shims echo Compiling homeljzblinkDBblinkdbhiveblinkdbshimssrccommonjavahomeljzblinkDBblinkdbhiveblinkdbshimssrccommonsecurejavahomeljzblinkDBblinkdbhiveblinkdbshimssrc Sjava against hadoop homeljzblinkDBblinkdbhiveblinkdbbuildhadoopcorehadoop ivyinitsettings echo Project shims ivyresolvehadoopshim echo Project shims ivyresolve loading settings file homeljzblinkDBblinkdbhiveblinkdbivyivysettingsxml ivyretrievehadoopshim echo Project shims javac Compiling source files to homeljzblinkDBblinkdbhiveblinkdbbuildshimsclasses javac warning options bootstrap class path not set in conjunction with source javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error package orgmortbayjettybio does not exist javac import orgmortbayjettybioSocketConnector javac javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error package orgmortbayjettyhandler does not exist javac import orgmortbayjettyhandlerRequestLogHandler javac javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error package orgmortbayjettywebapp does not exist javac import orgmortbayjettywebappWebAppContext javac javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error package orgmortbayjetty does not exist javac private static class Server extends orgmortbayjettyServer implements JettyShimsServer javac javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error Jetty SShims is not abstract and does not override abstract method startServerStringint in JettyShims javac public class Jetty SShims implements JettyShims javac javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error startServerStringint in Jetty SShims cannot implement startServerStringint in JettyShims javac public Server startServerString listen int port throws IOException javac javac return type orgapachehadoophiveshimsJetty SShimsServer is not compatible with orgapachehadoophiveshimsJettyShimsServer javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error orgapachehadoophiveshimsJetty SShimsServer is not abstract and does not override abstract method stop in orgapachehadoophiveshimsJettyShimsServer javac private static class Server extends orgmortbayjettyServer implements JettyShimsServer javac javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error cannot find symbol javac WebAppContext wac new WebAppContext javac javac symbol class WebAppContext javac location class Server javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error cannot find symbol javac WebAppContext wac new WebAppContext javac javac symbol class WebAppContext javac location class Server javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error cannot find symbol javac RequestLogHandler rlh new RequestLogHandler javac javac symbol class RequestLogHandler javac location class Server javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error cannot find symbol javac RequestLogHandler rlh new RequestLogHandler javac javac symbol class RequestLogHandler javac location class Server javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error cannot find symbol javac SocketConnector connector new SocketConnector javac javac symbol class SocketConnector javac location class Server javac homeljzblinkDBblinkdbhiveblinkdbshimssrc SjavaorgapachehadoophiveshimsJetty SShimsjava error cannot find symbol javac SocketConnector connector new SocketConnector javac javac symbol class SocketConnector javac location class Server javac Note homeljzblinkDBblinkdbhiveblinkdbshimssrccommonsecurejavaorgapachehadoophiveshimsHadoopShimsSecurejava uses or overrides a deprecated API javac Note Recompile with Xlintdeprecation for details javac Note homeljzblinkDBblinkdbhiveblinkdbshimssrccommonsecurejavaorgapachehadoophiveshimsHadoopShimsSecurejava uses unchecked or unsafe operations javac Note Recompile with Xlintunchecked for details javac errors javac warning BUILD FAILED homeljzblinkDBblinkdbhiveblinkdbbuildxml The following error occurred while executing this line homeljzblinkDBblinkdbhiveblinkdbbuildxml The following error occurred while executing this line homeljzblinkDBblinkdbhiveblinkdbshimsbuildxml The following error occurred while executing this line homeljzblinkDBblinkdbhiveblinkdbshimsbuildxml The following error occurred while executing this line homeljzblinkDBblinkdbhiveblinkdbshimsbuildxml Compile failed see the compiler error output for details Hi Have you got any experience deploying on CDH cluster with the Spark available in there Is the standalone Spark strictly necessary Thanks 