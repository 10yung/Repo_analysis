Good evening everyone This is my first time posting here and I m a complete PythonDeep LearningAI noobie for the time being so apologies in advance if I end up wasting your time after all with this whole Thread Anyways some days ago I was able to successfully install the ESRGAN Upsaler along with all of its prerequisites I tested my first image with my new RTX Super and the result came out in an astounding seconds considering that last time I tried it with a CPU it took hours Unfortunately though when I tried to replicate this whole process the following error popped up in the Anaconda Prompt and which I would appreciate it extremely if anyone could help me resolve it Traceback most recent call last File testpy line in output modelimgLRdatasqueezefloatcpuclamp numpy File C Users ctamv Anaconda lib sitepackages torch nn modules modulepy line in call result selfforwardinput kwargs File D FC AViberp zvh yqyrViberUniversal ESRGANmaster RRDBNetarchpy line in forward fea selflreluselfupconv Finterpolatefea scalefactor mode nearest File C Users ctamv Anaconda lib sitepackages torch nn functionalpy line in interpolate return torchCnnupsamplenearest dinput outputsize RuntimeError CUDA out of memory Tried to allocate GiB GPU GiB total capacity GiB already allocated GiB free MiB cached I have been trying for hours until now to solve this problem after visiting multiple other threads but with no success mostly because I don t even know where to input PyTorch commands in the fist place as the Anaconda Prompt doesn t let me run them Finally one last observation I did was the fact that according to the last line of the above output even though my GPUs full GBs of VRAM are correctly displayed along with the current GBs approximately that are being used and the cache the remaining GB of free VRAM are incorrectly displayed as with basic calculations they should had been AT LEAST GBs of free VRAM if the above numbers are corect Apologies again for my general ignorance on the subjectand thanks in advance for your help GAN hello when i was reading the RRDBNetarchpy I found that you use interpolatemodenearest to up sampling Compared with some other modelslike EDSR which use pixel shuffle Is there any advantage to using this interpolate Thank you Hi inspired from your model I have written a similar ESRGAN model with spectralnormalization and a few other tweaks Although mostly the underlying model architecture is same I am also using VGG for feature extraction Im trying to train the model to super resolve images which VGG has never been trained on My generator is not producing the highest quality images there are a few distortions although the perception of image is excellent I believe the fault lies in the discriminator not being able to discriminate between fake and real images Will you please suggest something I can do to mitigate it I was thinking if I have to remove VGG part I can extend the discriminator to be a proper robust CNN OR I can train a VGG model without pretrained weights on my own dataset and then use it to extract features Will that work hellothanks for you wanderful workthis project helps me a lot I want to train the model to fit my own scales size actually my picture is low quality but the same size with the HR picturesso I must modify your net and thus I can not use your pretrain model RRDNPSNRx so I want to know the train details about your pretrain model like iterations and learning rateetc Hi In your paperfirst you train a PSNRoriented model with the L loss and then train the RAGAN I want to knew before you train the RAGANhow much iterations do you train the PSNRoriented model Hello Xintao Have you compared ESRGAN model with the xiaomi s FALSR model How about the results thank you Zeyu Hi ran into an error saying RRDBESRGANx pth not founds in models might be a little stupid qn but where can I find the original pretrained model Thanks for your work I am wondering how to retrain the RRDBPSNRx pth model from scratch Can I do that by changing some options in 