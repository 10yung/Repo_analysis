Hi I want to generate infrared images from visual images I have paired infraredvisual images for training FLIR and one other dataset I have attached sample Is this project appropriate for this work i already tried pix pix pix pixHD and currently trying MUNIT but it do not generate good output I only have paired images is there any method to generate labels and instances for better training Right now i just want to focus on categories person vehicle background I am waiting for your kind suggestions Hi author I have a question about the quantitative evaluation For Cityscapes dataset I run evaluation scripts and the result is that mIoU accuracy FID It has some difference with results shown in your paper especially the accuracy is obviously higher than your I use the bilinear downsample method for label maps as you answered in issue Current versions of scipy doesnt have toimage so spade repo needs to be pinned to an older scipy version to work Dataset cocostuff dataset training script python trainpy datasetmode coco dataroot skydataspade usevae batchSize gpuids checkpointsdir temp printfreq savelatestfreq saveepochfreq training GPU V G screen print epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal epoch iters time KLD GAN GANFeat VGG DFake Dreal Loss is as the same as epoch Why this network does not convergence Hello I used pretrained model for coco stuff to test on val I generated instances for val dataset so to generate images the model take val instance as input but why the path for valimg also needed Hello I would like to ask if SPADE takes fixed dimension maps because I am trying to use your pre trained model for COCO Stuff dataset to generate RGB Images for my own Sementic maps but i got that error We got that error complaining about the dimensions which really different form the input that SPADE use RuntimeError Given groups weight of size expected input to have channels but got channels instead The dimension of the semantic maps that i am using I would like to know the properties of the semantic maps that SPADE used to generate RGB Images and if you can recommend me any way to solve this problem Thanks I am interested in finetuning the pretrained version of this network network which is based on ADE K However when experimenting with this model by running the following code bash python trainpy nameade kpretrained datasetmodeade k datarootdataade k nopairingcheck continuetrain checkpointsdirdatacheckpointsade kpretrained I receive the following error FileNotFoundError Errno No such file or directory datacheckpointsade kpretrainedlatestnetDpth Checking the files in the Google Drive link linked to in the paper I see that indeed for all of the pretrained versions of this network whose weights have been distributed only the generator network weights gpth are available Are the discriminator weights not publicly available Hello I hope to compare with your experimental results in my dissertation May I ask if it is convenient for you to provide val generated pictures on ADE K COCOstuff cityscapes We will make accurate citations in the paper thank you very much