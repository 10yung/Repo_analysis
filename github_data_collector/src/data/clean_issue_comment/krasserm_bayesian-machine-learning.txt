Thank you very much for this very descriptive and detailed implementation of BNNs I am trying to implement BNN for a custom function which takes multiple inputs and produces one output How can I define noise in such a case Thank you very much for your implementation Its highly helpful Im attempting to learn different functions using the BNN model I restrict the range of training values to be discontinuous For example in an attempt to learn a polynomial function x I slightly change the number of neurons and number of layers for better prediction and train the network with equally sampled values from to and from to When testing the network with equally sampled values from to I would expect the Epistemic uncertainty to be high at the range of values that the network has not seen during the training ie from to from to and from to Observations after testing The predicted mean is close to the expected test value in the trained range as expected The variance of predicted values in the untrained range is high as expected The variance of predicted values in the untrained range is lower which is contradictory to the concept of determining epistemic uncertainty through BNN Could there be any explanation for this and Is there some way to make the model to have high variance in all the ranges of untrained data Polynomial function I have also done trained the exact model you have presented for Sin function with discontinuous range of training data and have observed the same issue Sinincomplete Thanks a lot in advance Just a quick introduction PlaidML is a backend that can be used to allow GPUbased learning on different hardware in my case a Mac with an AMD GPU If I use PlaidML as a backend import os osenviron KERASBACKEND plaidmlkerasbackend from keras import backend as K from keras import activations ini And then attempt to use the the DenseVariational layer class DenseVariationalLayer def initself outputdim kllossweight activationNone kwargs selfoutputdim outputdim selfkllossweight kllossweight selfactivation activationsgetactivation superinitkwargs def buildself inputshape selftrainableweightsappendpriorparams selfkernelmu selfaddweightnamekernelmu shapeinputshape selfoutputdim initializerinitializersnormalstddevpriorsigma trainableTrue selfbiasmu selfaddweightnamebiasmu shapeselfoutputdim initializerinitializersnormalstddevpriorsigma trainableTrue selfkernelrho selfaddweightnamekernelrho shapeinputshape selfoutputdim initializerinitializersconstant trainableTrue selfbiasrho selfaddweightnamebiasrho shapeselfoutputdim initializerinitializersconstant trainableTrue superbuildinputshape def callself x kernelsigma tfmathsoftplusselfkernelrho kernel selfkernelmu kernelsigma tfrandomnormalselfkernelmushape biassigma tfmathsoftplusselfbiasrho bias selfbiasmu biassigma tfrandomnormalselfbiasmushape selfaddlossselfkllosskernel selfkernelmu kernelsigma selfkllossbias selfbiasmu biassigma return selfactivationKdotx kernel bias def computeoutputshapeself inputshape return inputshape selfoutputdim def kllossself w mu sigma variationaldist tfdistributionsNormalmu sigma return selfkllossweight Ksumvariationaldistlogprobw logmixturepriorprobw I get the following error when constructing a sequential model modeladdDenseVariational kllossweightkllossweight activationsigmoid Traceback most recent call last File usrlocallibpython sitepackagestensorflowcorepythonframeworktensorutilpy line in maketensorproto strvalues compatasbytesx for x in protovalues File usrlocallibpython sitepackagestensorflowcorepythonframeworktensorutilpy line in listcomp strvalues compatasbytesx for x in protovalues File usrlocallibpython sitepackagestensorflowcorepythonutilcompatpy line in asbytes bytesortext TypeError Expected binary or unicode string got tileValue densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational kernelrho Tensor FLOAT During handling of the above exception another exception occurred Traceback most recent call last File stdin line in module File usrlocallibpython sitepackageskerasenginesequentialpy line in add outputtensor layerselfoutputs File usrlocallibpython sitepackageskerasenginebaselayerpy line in call output selfcallinputs kwargs File stdin line in call File usrlocallibpython sitepackagestensorflowcorepythonopsgennnopspy line in softplus Softplus featuresfeatures namename File usrlocallibpython sitepackagestensorflowcorepythonframeworkopdeflibrarypy line in applyophelper raise err File usrlocallibpython sitepackagestensorflowcorepythonframeworkopdeflibrarypy line in applyophelper preferreddtypedefaultdtype File usrlocallibpython sitepackagestensorflowcorepythonframeworkopspy line in internalconverttotensor ret conversionfuncvalue dtypedtype namename asrefasref File usrlocallibpython sitepackagestensorflowcorepythonframeworkconstantoppy line in constanttensorconversionfunction return constantv dtypedtype namename File usrlocallibpython sitepackagestensorflowcorepythonframeworkconstantoppy line in constant allowbroadcastTrue File usrlocallibpython sitepackagestensorflowcorepythonframeworkconstantoppy line in constantimpl allowbroadcastallowbroadcast File usrlocallibpython sitepackagestensorflowcorepythonframeworktensorutilpy line in maketensorproto supported type typevalues values TypeError Failed to convert object of type class plaidmltileValue to Tensor Contents densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational densevariational kernelrho Tensor FLOAT Consider casting elements to a supported type This may just come with the package if the underlying issue is similar to here but is there any way to make these layers function without tying them so close to Tensorflow directly Hi Thanks a lot for sharing your code on Bayesian NN it sure was very useful However when experimenting on regression problems variables and classification problems the model does not seem to learn anything The loss pretty much remains constant after a few iterations This is especially true for Relu activation To show this I am attaching a zip file where when you run the file exampleregressionpy you get the following plot tmp BayesianNNProblemzip As you can see the model does not learn the shape when we have features This actually changes if I change the activation from relu to tanh any reason why Additionally I also tried your model for classifying fashion mnist data and unfortunately the model does not learn anything here and simply produces an accuracy of I am not sure as to what is wrong here Any help is greatly appreciated Thanks Vineeth I just want to say thanks for this repo Great explanations for an interesting topic