Hello I have had some ZeroDivisionErrors trying to get the RougeL summary level score for one of my data The problem was in the function unionlcs of rougepy where the union longest common subsequence count was divided by the combined LCS length I added the case when combinedlcslength was equal to to return and its working fine now I mean I added that case locally I cannot change it in this repository Does it sound right py def unionlcsevaluatedsentences referencesentence if lenevaluatedsentences raise ValueErrorCollections must contain at least sentence lcsunion set referencewords splitintowordsreferencesentence combinedlcslength for evals in evaluatedsentences evaluatedwords splitintowordsevals lcs setreconlcsreferencewords evaluatedwords combinedlcslength lenlcs lcsunion lcsunionunionlcs unionlcscount lenlcsunion Here the modification if combinedlcslength return unionlcsvalue unionlcscount combinedlcslength return unionlcsvalue It seems to be irrationally stressing the processor while Lsa doesnt Whats up In command sumyeval random modsumsomename txt languageenglish filedocstexttxt formatplaintext How I can change different parameters of Rouge evaluation like a c b m n w I found that sumy will distinguish heading and other sentences so checked the source code and I found that Whether a line is heading is decided by strisupper function But in a str composed by Chinese characters if it contains an uppercase alphabet the isupper will return True but actually it is just a normal sentence instead of heading For example s N s N s s isupper True s isupper True s isupper False My corpus contains paragraphs and the speed is slow More than mins Could you please introduce sumys performance And which stage will make it slow when corpus is large Thanks Hi i read the code of computing term frequency in LexRank metrics term tf maxtf I dont understand why do u divide the maximum count of word in that sentence rather than use the number of occurrences of the word in the sentencedescribed in the original lexrank paper or just normalize it by dividing total count of all words Hi master firstly im very grateful for that python implementation But i didnt understand how Summary Level ROUGEL works via code Sentence level type of rouge we can use more than a sentence for candidate summary After that we compute lcs reference summary Candidate Sentence and Candidate Sentence respectively when i try to use it on command prompt how i do write it or how should the structure of my candidate sentences be in localtxt file Just one line or each line for each sentence Thanks Hi I will be brief so as not to distract When working algorithm produces a row the first proposals from the text for example LexRankSummarizer numbers are the sequence number proposals in the in the source text Alternative implementation gives the following result on the same text Results LexRank Regards Alexander Hi I checked the code for Edmundson summarizer As I figured out it doesnt do anything for English Basically it suppose to extract cue words and significant words and the words in title and rank the sentences based in these scores and the location Well when the input is a raw text file then the summarizer works based on the location of the sentence Is that right There is no method to extract the cue words and significant words as well as title words for the text So in this way the implementation is wrong I suppose Let me know if I did not understand your code or Im making a mistake Thanks I use NLTK to tokenize text into sentences words But thats big package Maybe something smaller would be better Something like 