In the releasing section of the docs we mention maintainers should go over the changes and add entries to the changelog I noticed other projects add entries to it as part of PRs which seemed like an idea we could adopt to reduce the amount of work on a release I realize that exact example this doesnt play very well with SemVer as it forces us to write a version number that might be change depending on other PRs that are merged Though we could simply state UNRELEASED or something until we actually cut the release Thoughts Fixes Use the same logic from proxyhttp in the Proxy config eg detects if credentials are present in the proxy URL and adds the authorization header accordingly Also remove the credentials for the URL When doing something like this proxy http https def runsyncurl with httpxClientverifyFalse proxiesproxy as client response clientgeturl printresponse runsync Response Proxy Authentication Required For a private proxy that includes authentication the request will fail with a Proxy Authentication Required error I think httpx is doing something like this from urllib import ProxyManager proxy urllib ProxyManager x proxyrequestGET xstatus instead of this from urllib import ProxyManager makeheaders defaultheaders makeheadersproxybasicauthuserpass proxy urllib ProxyManager headersdefaultheaders x proxyrequestGET xstatus I slept some more on and I think Ive come up with something quite nice Main changes compared to We always use an exponential backoff so no more Schedule API Just a backofffactor know on the retries config class The default behavior is to retry on connection failures No more RetryableError base class which of our exceptions are retryable is hardcoded in the default behavior Being able to override retryflow isnt really useful in itself because extending a retry flow even by copypasting our code really isnt easy due to many generator gotchas to watch for So this PR implements some extension capability mainly via the RetryLimits interface and being able to pass I guess in an incremental approach we could restrict this PR to retriesint and retriesRetriesint backofffactorfloat and move the extension mechanism to a separatefuture PR Im putting everything in here first to get some more feedback on the direction Things still to do Perrequest retries Sync retries Add tests This wont be easy as there are many code paths to account for Hence probably the motivation for splitting this in two steps Notes to reviewers Read the new docs for an overview of the functionality Use this script to try things out Usage HTTPXLOGLEVELdebug python examplepy without starting the server to try the behavior on connection failures Start the dummy server uvicorn exampleapp Rerun the script to try the custom behavior implemented by RetryOnStatusCodes While retries are ongoing you can turn off the server and see that it switches to retrying on connection failures again If you get the server back up it will retry on status codes etc This continues until either policy runs out of retries Which I think is quite niceresilient python import asyncio import typing import httpx from starletteresponses import PlainTextResponse class RetryOnStatusCodeshttpxRetryLimits def initself limit int statuscodes typingContainer int None selflimit limit selfstatuscodes statuscodes def retryflow self request httpxRequest typingGenerator httpxRequest httpxResponse None retriesleft selflimit while True response yield request if responsestatuscode not in selfstatuscodes return if retriesleft try responseraiseforstatus except httpxHTTPError as exc raise httpxTooManyRetriesexc responseresponse else raise httpxTooManyRetriesresponseresponse retriesleft async def main None url retries httpxRetries RetryOnStatusCodeslimit statuscodes backofffactor async with httpxAsyncClientretriesretries as client r await clientgeturl printr async def appscope receive send response PlainTextResponsestatuscode await responsescope receive send if name main asynciorunmain async def httpupload async with httpxAsyncClientverifyFalse as client datapath ospathjoinPARENTPATH datafileblobdata indexpath ospathjoinPARENTPATH datafileblobindex files uploadfile opendatapath rb openindexpath rb files uploadfile opendatapath rb uploadfile openindexpath rb params requestId sdkVersion V area CH response await sessionposturl dataparams filesfiles self httpxcontentstreamsMultipartStreamFileField object at x f c ea def renderdataself bytes if isinstanceselffile str content selffile else content selffileread E AttributeError list object has no attribute read or def iterfields self data dict files dict typingIterator typingUnion FileField DataField for name value in dataitems if isinstancevalue list dict for item in value yield selfDataFieldnamename valueitem else yield selfDataFieldnamename valuevalue for name value in filesitems E AttributeError list object has no attribute items Excuse me how should I use I was reading the excellent and wanted to test the awesome httpx just for fun It mentions this issue about setting a timeout for request completion which would make sense for both the sync and the async case which I think would be a nice addition the the high level api I think it can already be done with the stream api and readtimeouts I was wondering if there was a higher level way Edit see how aiohttp handles timeouts Currently httpx only provides the requests equivalent elapsed property on Response objects It would be very useful if more fine grained timing information would be available From working with curl the following have been helpful name resolution tcp connected protocol connected eg TLS done request last byte sent response first byte arrived total eg what elapsed is now Of course this all becomes a bit more complicated with pooled connections keepalive http etc Ive noticed a couple of projects lately which use private module names inside the package Id initially found it an odd style but actually its a really smart approach that helps you enforce that only the toplevel API that youre exposing is actually public API For example right now users might do something like python from httpxconfig import SSLConfig from httpxmodels import Origin from httpxauth import FunctionAuth None of which are actually considered public API by us but thats not immediately obvious to the user Weve mentioned in chat or elsewher I dont recall that we really want to ensure our users are only ever using import httpx or from httpx import SOMETHING and yes we could simply mention that in our documentation But actually itd be far clearer if we actually used private module names and enforced that users would be aware if they choose to import and use nonpublic API This isnt strictly a breaking API change but we would only want to make it on a median version bump or since its likely that at least some of our users are currently using submodule import styles Wed also want to update our test cases so that were using public API wherever possible and so that its clearer where there are cases that were using private API which would either indicate unittesting to an extent or that weve got some part of API that were planning to expose but havent yet finalised on I think we might also want to do a bit of rejigging of how we handle all with this too We probably dont actually want to support from httpx import Somewhat related to this is that weve got a bunch of methods on classes that we dont document arent treating as public API and probably ought to move into private methods Eg on the Client everything below buildrequest and send should probably be private API However lets treat that as a seperate issue to be discussed This issue isnt neccessarily something that I think we ought to do or not do However since weve got our public API pretty squared away now and are starting to think about a release its something that we really ought to discuss and make sure were absolutely happy with whatever we land on Something thats come up as a possible point of design contention has been if AsyncClient ought to strictly only provide a contextmanaged interface or if were okay with supporting init and optionally calling aclose Currently were supporting either style and thats working fine for our users but If we ever wanted to support background tasks then structured concurrency means wed want the client instances to be contextmanaged so that weve got well defined lifetimes for any background running tasks The context managed style also means strictly managed resource managment Connections have wellscoped lifetimes rather than cleanup on interpreter exit Do we need to be able to support background tasks Well possibly We dont strictly need background tasks to support our HTTP implementation so long as were using HTTP shortish timeouts on connections that have no activity If were not running a background task on it then if theres no requestresponse activity progressing the connection then we wont respond to HTTP pings and servers will time us out However if we did have background tasks then We could have nicer HTTP keepalive timeouts where we actually properly expire connections in the background after their timeout period We could optionally support longlived HTTP connections holding onto a connection for longer periods of time in order to provide lower latency when the next request is made Also Ive no idea how this ties in with HTTP Other relevant factors here Its also possible that some limited kinds of global tasks might at some point be supported by trio One reason I was initially reticant about strictly enforcing context managed async clients is that I wasnt clear how thatd fit in with the ASGI style but having put some more thought in there its clear that it can fit in with ASGIs lifespan messaging Eg Wed be suggesting a deliberate disparity with the sync case which is a bit odd I dont think wed want to be able to enforce context managed sync clients It wouldnt work with WSGI and anyways wed like folks to be able to switch over from using requests to using httpx and we wouldnt be able to justify the constraint Its also less valuable since we wouldnt be running background tasks in the sync case anyways so itd only be relevant wrt clean connection lifetimes Simply having an async context managed class doesnt actually tie in fully with And wed like a nursery available within this context See conversation around You can do it with some clever metaclassing or you can potnentially call directly into the nursery aenter and aexit but it might not neccessarily be the API wed want to adopt if we wanted a nusery available within AsyncClient I think wed probably on ok ground here tho theres options available I dont have any clear answer on this What weve got at the moment is working fine for our users but its feasible that adopting the more constrained option could prevent issues further down the line What is the dispatcher API and why is it useful The dispatcher is the part of the system thats responsible for actually sending the request and returning a response to the client Having an API to override the dispatcher used by the client allows you to take complete control over that process and switch out the default behaviour with something else For instance the plug in to a WSGI app and plug in to an ASGI app cases that we support are implemented as dispatcher classes that send the request to a Python web application rather than sending a network request Currently the dispatchers are considered private API but really wed like a public API here at some point This issue is for discussing what we think that API should be Right now the API is python def sendrequest Request timeout Timeout None Response def close Withasync equivelents for the async case Thats actually pretty okay but if were looking at a public API we ought to figure out if its actually what we want to expose Theres a case to be made for making the dispatcher API just take plain primitive datastructures rather than dealing with RequestResponse models Thatd make for a more portable interface that could be used in other packages without importing httpx That might look something like this python def sendself verb bytes url bytes headers List Tuple bytes bytes body Iterator bytes timeout Timeout None return protocol statuscode statusmessage headers responsebody def close Both the request and response bodies would be byteiterable closable interfaces or byte asynciterable closable interfaces Everything else would be plain ol Python datastructures Thoughts Its feasible that url could be defined as a tuple or url components instead so that we can keep pass a parsed url objects from the client to a dispatcher interface We do need to have the timeout be part of the dispatch interface since we want to be able to support configuredperrequest timeout values Id guess wed need to define that as an optional fourtuple of connectreadwritepool float timeout values We might want to think about defining expected exception types Theres no support for HTTP trailing headers in this interface Perhaps we dont care about that or could the ContentStreamclose perhaps optionally return a list of headers maybe Something thatd potentially be interesting about defining this interface in a really strict primitive datastructures way would be that we could pull out our dispatcher implementations into a really tightly scoped package httpcore thatd just provide the plain network dispatchers without any client smarts around them Interesting amongst other things because itd provide a nice justthenetworkbackend for other client libs to potentially use too switch too I think a useful first take onto all of this might be an exploratory pull request that switches us over to using a plainer dispatch API just to get a feel for how thatd look A very first initial take on that could still use the URL ContentStream and Timeout primitives This also potentially ties in with whatever the hip teams plans are For instance right now were using our own dispatcher implementation currently in the async case only but planned for both cases but we would have the option of using the hip backend once its available Its not obvious to me if wed want to do that or if wed prefer to continue with our existing backend which is looking pretty nice now but it could be a point of collaboration or something to discuss Alternately we might decide that this falls into architecture astronauting territory and that the existing API is just fine thankyouverymuch