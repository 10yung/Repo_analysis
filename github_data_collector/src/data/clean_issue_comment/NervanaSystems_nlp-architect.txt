When attempting to export a Q BERT model to ONNX TorchScript reports a runtime error Since the quantized forward methods embed Tensors with grads from layer instance attributes rather than input parameters exporting the model has to be done with explicit torch script tracing however that creates a traced model with lacks fidelity with the python model as branching behavior is not captured However attempting to create a script model with TorchScript which should encode that behavior results in a missing config attribute on the BertModel superclass To Reproduce Steps to reproduce the behavior Train a Q Bert model nlptrain transformerglue taskname mrpc modelnameorpath bertbaseuncased modeltype quantbert learningrate e outputdir DATADIR datadir GLUEDIR evaluateduringtraining dolowercase pergputrainbatchsize pergpuevalbatchsize maxseqlength Load the bit model for inference import torch from nlparchitectmodelstransformersquantizedbert import QuantizedBertForSequenceClassification model QuantizedBertForSequenceClassificationfrompretrainedconfigsdatadir from bitTrue device torchdevicecuda modeltodevice modeleval Attempt to create the script model scriptmodel torchjitscriptmodel This produces the error Traceback most recent call last File converttorchq bertviaonnxtotensorflowpy line in module scriptmodel torchjitscriptmodel File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitinitpy line in script return torchjittorchjitrecursiverecursivescriptobj File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitrecursivepy line in recursivescript return copytoscriptmodulemod overloadstubs stubs File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitrecursivepy line in copytoscriptmodule torchjitcreatemethodsfromstubsscriptmodule stubs File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitinitpy line in createmethodsfromstubs selfccreatemethodsself defs rcbs defaults File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitrecursivepy line in makestrongsubmodule newstrongsubmodule recursivescriptmodule File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitrecursivepy line in recursivescript return copytoscriptmodulemod overloadstubs stubs File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitrecursivepy line in copytoscriptmodule torchjitcreatemethodsfromstubsscriptmodule stubs File homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestorchjitinitpy line in createmethodsfromstubs selfccreatemethodsself defs rcbs defaults RuntimeError module has no attribute config at homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestransformersmodelingbertpy We can provide a selfattention mask of dimensions batchsize fromseqlength toseqlength ourselves in which case we just need to make it broadcastable to all heads if attentionmaskdim extendedattentionmask attentionmask None Provided a padding mask of dimensions batchsize seqlength if the model is a decoder apply a causal mask in addition to the padding mask if the model is an encoder make the mask broadcastable to batchsize numheads seqlength seqlength if attentionmaskdim if selfconfigisdecoder HERE batchsize seqlength inputshape seqids torcharangeseqlength devicedevice causalmask seqids None None repeatbatchsize seqlength seqids None None extendedattentionmask causalmask None attentionmask None None else extendedattentionmask attentionmask None None Since attentionmask is for positions we want to attend and for masked positions this operation will create a tensor which is for torchnlparchitectmodelstransformersquantizedbertQuantizedBertModelforward is being compiled since it was called from torchnlparchitectmodelstransformersquantizedbertQuantizedBertForSequenceClassificationforward at homekrhyslocalsharevirtualenvsq bertS V VUlibpython sitepackagestransformersmodelingbertpy def forwardself inputidsNone attentionmaskNone tokentypeidsNone positionidsNone headmaskNone inputsembedsNone labelsNone outputs selfbertinputids HERE attentionmaskattentionmask tokentypeidstokentypeids positionidspositionids headmaskheadmask inputsembedsinputsembeds pooledoutput outputs pooledoutput selfdropoutpooledoutput Expected behavior It should produce a script model without error Environment setup OS LinuxMac OS Ubuntu Xenial Python version Additional context It may be possible to create pure helper quantized forward functions with explicit arguments which have the torchjitscript annotations which are called by the quantized layer forward methods Note that the HuggingFace transformers Bert model can be exported to ONNX Hi we d greatly appreciate any feedback regarding any plans as announced here of integrating the new crossdoc coreference resolution approach by Barhom et al into NLPArchitect Also we were wondering if there is a published paperpreprint on the approach that is currently part of NLP Architect cf Cheers Anastasia Hello I am executing examplescrossdoccorefcrossdoccorefsievespy and got the following error FileNotFoundError Referent Dict file not found or not in pathC Users annaz PycharmProjects nlparchitect dataset corefdict tsv How could I get this file Thank you in advance Best Anastasia Im using the ABSA UI to classify a large set of reviews However when I select Classify Raw Data I get this runtime error RuntimeError Parser not initialized try parseTrue at init However I also get the same error message when I provide parsed data Here is my output error RuntimeErrorParser not initialized try parseTrue at init Traceback most recent call last File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehserverprotocolhandlerpy line in handle work yield handlermessage connection File LibraryFrameworksPythonframeworkVersions libpython sitepackagestornadogenpy line in run value futureresult File LibraryFrameworksPythonframeworkVersions libpython sitepackagestornadogenpy line in run yielded selfgensendvalue File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehserversessionpy line in needsdocumentlockwrapper result yield yieldforallfuturesfuncself args kwargs File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehserversessionpy line in handlepatch messageapplytodocumentselfdocument self File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehprotocolmessagespatchdocpy line in applytodocument docapplyjsonpatchselfcontent setter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehdocumentdocumentpy line in applyjsonpatch patchedobjsetfromjsonattr value modelsreferences settersetter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehcorehaspropspy line in setfromjson descriptorsetfromjsonself json models setter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehcorepropertydescriptorspy line in setfromjson models setter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehcorepropertydescriptorspy line in setfromjson selfinternalsetobj json settersetter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehcorepropertydescriptorspy line in internalset selfrealsetobj old value hinthint settersetter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehcorepropertydescriptorspy line in realset selftriggerobj old value hinthint settersetter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehcorepropertydescriptorspy line in trigger objtriggerselfname old value hint setter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehmodelpy line in trigger superModel selftriggerattr old new hinthint settersetter File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehutilcallbackmanagerpy line in trigger selfdocumentnotifychangeself attr old new hint setter invoke File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehdocumentdocumentpy line in notifychange selftriggeronchangeevent File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehdocumentdocumentpy line in triggeronchange selfwithselfascurdoceventcallbackinvoker File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehdocumentdocumentpy line in withselfascurdoc return f File LibraryFrameworksPythonframeworkVersions libpython sitepackagesbokehutilcallbackmanagerpy line in invoke callbackattr old new File LibraryFrameworksPythonframeworkVersions libpython sitepackagesnlparchitectsolutionsabsasolutionuipy line in inferfilecallback opinionlexSENTIMENTOUT opinionscsv File LibraryFrameworksPythonframeworkVersions libpython sitepackagesnlparchitectsolutionsabsasolutionsentimentsolutionpy line in run sentimentdoc inferencerunparseddocparseddoc File LibraryFrameworksPythonframeworkVersions libpython sitepackagesnlparchitectmodelsabsainferenceinferencepy line in run raise RuntimeErrorParser not initialized try parseTrue at init RuntimeError Parser not initialized try parseTrue at init Need to check Transformer models are working forward Combine tests with a new validation scheme Describe the bug mobile version of website with blue colors instead of NLP Architect With your bit quantized GNMT model I understand that the weights are quantized to bit and then treated as floating point during inference Does this mean that the bit weights are interacting with float activations Or are the activations also effectively quantized to bit Feature related to new ml model for NLP architect library negation understanding model needs to be implemented 