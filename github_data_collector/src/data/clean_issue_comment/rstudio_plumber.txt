First let me start off by saying thank you for an awesome flexible package for deploying APIs using R I see in the docs that one can set a custom error handler using something like wherecustomerrorhandler is a function that handles errors as they come up similar to the defaultErrorHandler used by Plumber r plumbplumberapiR rsetErrorHandlercustomerrorhandler rrun This works great and I was able to get my custom error handling working well However I didnt see in the docs or source a way to use an annotation like one can for creating serializers or filters for defining a custom error handler for an app Ive forked the repo and created a working proof of concept for adding this which was based off of how filters and serializers were implemented Ive also tested this locally and publishing an API to RStudio Connect that includes and uses custom error handling which is the use case I was looking for the errorhandling annotation for Im happy to submit this as a PR if this approach is reasonable after I add bit more checking for eg that only one errorhandler is provided Closes My fork of sellorms demo at contains an example of reliably processing multipart data using mimeparsemultipart This PR adds special treatment for multipart input Pull Request Before you submit a pull request please do the following Add an entry to NEWS concisely describing what you changed Add unit tests in the teststestthat directory Run BuildCheck Package in the RStudio IDE or devtoolscheck to make sure your change did not add any messages warnings or errors Doing these things will make it easier for the plumber development team to evaluate your pull request Even so we may still decide to modify your code or even not merge it at all Factors that may prevent us from merging the pull request include breaking backward compatibility adding a feature that we do not consider relevant for plumber is hard to understand is hard to maintain in the future is computationally expensive is not intuitive for people to use We will try to be responsive and provide feedback in case we decide not to merge your pull request Minimal reproducible example Finally please include a minimal reprex The goal of a reprex is to make it as easy as possible for me to recreate your problem so that I can fix it If youve never heard of a reprex before start by reading and follow the advice further down the page Do NOT include session info unless its explicitly asked for or youve used reprexreprex si TRUE to hide it away r reprexreprex libraryplumber insert reprex here Delete these instructions once you have read them Brief description of the original problem and the approach behind your solution r insert reprex here PR task list x Update NEWS x Add tests x Update documentation with devtoolsdocument Hi How can I send serialized data to the server Ive seen the example to receive serialized data back provided by shrektan but I cant get the other way working Below the code robjserializer is the registered serializer from the above link I receive the back but req is not what I sent in the body post api serializer robjserializer functionreq printreqpostBody return post httrPOSTurl body baseserializelistmyarg NULLFALSE encoderaw httrcontenttypeapplicationoctetstream Here the serializer plumberaddSerializerrobjserializer function functionval req res errorHandler tryCatch ressetHeaderContentType applicationoctetstream resbody baseserializeval NULL ascii FALSE printhi returnrestoResponse error functione errorHandlerreq res e Context I want to be able to send large serialized data objects to docker worker nodes Using the json serialization takes too long Christian Copying an email thread here to continue discussion mftokic Oct I m trying to integrate the Plumber API with Microsoft Flow and would like to run an asynchronous call to my API For this to work in flow I will need to have a response status of Accepted along with a location header containing a URL to check on the status of the request I was wondering if you could help me with those two responses For the response I wrote the below code Does this look right to respond back to the API call that it is accepted resstatus For the header response with location URL I wrote the below code How can I change this to have the URL dynamically created so the MS Flow can poll that URL to see if the API call and r script is still running ressetHeaderlocation Thanks for your help schloerke I would like to make sure I understand your situation correctly You would like to visit the API to start calculations You would like to poll a url while the calculations are working You would like to redirect the poll to a response if the calculations are ready Is this process long Such as hr much longer than a browser connection Or is it more like seconds mftokic Yes that s correct Calling the API will kick off a long running forecasting process using statistical time series and ML models that will easily take over an hour I m trying to implement the API call in Microsoft Flow where there is a timeout limitation of minutes You can make asynchronous calls for longer running calls where Flow will call a location header URL to see if it is still processing or finished please see below picture and link for more details schloerke Ive attached a file below This should implement that idea of a long poll process If you change the response status to it will work great in the browser as a proof of concept details summarytokicRsummary r run in R session plumberplumbtokicRrunport visit in browser begin workqueue list get begin functionreq res get unique id while id paste sampleletters replace TRUE collapse in namesworkqueue TRUE initiate work in separate thread workqueue id listNULL laterlater function idx sample workqueue id listiris mtcars Titanic idx wait seconds redirect to status resstatus ressetHeaderLocation paste status id ressetHeaderretryafter didnt know if it was seconds or milliseconds id Poll the work queue html get statusid functionreq res id yell if unknown id if id in namesworkqueue stopunknown id id in work queue paste namesworkqueue collapse if isnullworkqueue id not ready yet display status of id ascharacterhtmltoolstagList if watching on a browser refresh the webpage every second htmltoolstagsscript htmlwidgetsJS setTimeoutfunction windowlocationreload Systime htmltoolstagsbr id id else data ready redirect to answer of id resstatus ressetHeaderLocation paste answer id helpful note paste redirecting to answer id get answerid json functionid yell if unknown id if id in namesworkqueue stopunknown id id in work queue return data workqueue id details mftokic This is great thank you I ve been playing around with it the past day and have learned a ton like how you can implement the later function to allow for immediate responses in API calls I have a few questions around the process you called out in the example When running your example script within a machine learning ML workflow the status endpoint will not respond immediately when called after trys because R is busy running the ML code after the second delay I think this can be fixed if I moved my API into a more scalable hosting environment instead of running just a single instance on one core I m trying to build a POC using a Windows Server and think the best way to host it on windows would be with PM I ve tried following the examples in the documentation but it s hard to implement correctly since the examples were meant for a linux server not a windows server I think the issue is around correctly defining the custom interpreter in PM to use R instead of the default JSPythonPerl Do you have any advice on how to implement the RBased wrapper for Windows I believe the below example is a bash script first line of code that will tell PM to use the RScript application when running the plumber R file If you think there is a better way to host the API on a windows server please let me know I d like to use RStudio Connect or digital ocean but I will need to first provide a working proof of concept on existing servers we have before I can convince senior leadership to spend additional dollars It s also hard to convince people right off the bat to start using a nonmicrosoft product before anything gets developed System details Output of sessioninfosessioninfo R version Platform x redhatlinuxgnu bit Running under CentOS Linux Core Matrix products default BLASLAPACK usrlib RliblibRblasso locale LCCTYPEC LCNUMERICC LCTIMEenUSUTF LCCOLLATEenUSUTF LCMONETARYenUSUTF LCMESSAGESenUSUTF LCPAPERenUSUTF LCNAMEC LCADDRESSC LCTELEPHONEC LCMEASUREMENTenUSUTF LCIDENTIFICATIONC attached base packages parallel stats graphics grDevices utils datasets methods base other attached packages urltools httr lobstr stringr yaml xml SweetAleRt SummeRnote shinyWidgets shinyjs shinydashboard shinyBS sharepointr RMySQL rintrojs RColorBrewer promises plotly openssl officer lubridate ldapr Hmisc Formula survival lattice jsonlite gitlabr magrittr ggplot future fullcalendaR dtplyr DT dplyr directlabels dbplyr DBI datatable colourpicker bcrypt shiny loaded via a namespace and not attached tools backports R rpart lazyeval colorspace nnet withr tidyselect gridExtra curl compiler htmlTable triebeard labeling scales checkmate quadprog askpass plumber digest foreign base enc pkgconfig htmltools htmlwidgets rlang rstudioapi crosstalk acepack zip Matrix Rcpp munsell arpr stringi plyr grid listenv crayon miniUI splines knitr pillar uuid codetools glue V latticeExtra httpuv gtable purrr tidyr assertthat xfun mime xtable later viridisLite tibble cluster globals Example application or steps to reproduce the problem If youre able to create one a reprexreprex REProducible EXample is extremely helpful to us For instructions on how to create good reprex please see We understand the interactive nature of plumber having two separate reprex outputs generating the server and calling server is perfectly acceptable R get getData functionn datadocallrbind replicaten mtcars simplify F returndata Describe the problem in detail Requesting large datasets via plumber results in a large memory consumption of the plumber process which is ok After the request ist finished this memory is not released by the garbage collection This means if GB were allocated for serving the request the process will keep the allocated memory forever until restarted Even after requesting a small dataset after the large one the memory wont be released Im not quite sure if this is actually a bug or if I am doing something wrong Thanks for your help Example application Suppose we have the following API R srv plumberplumbernew srvhandlePOST submit functionreq res TODO Actual work resheaders ContentType textplain resbody Submitted res srvrunhost If you send a GET request to this API instead of the POST request it is expecting you see the following eg with curl curl sv X GET localhost submit GET submit HTTP Host localhost UserAgent curl Accept HTTP Not Found Date Mon Sep GMT ContentType applicationjson Date Mon Sep PM GMT ContentLength error Resource Not Found Describe the problem in detail There is a wellknown and wellsupported HTTP status code for the specific issue of this URI is valid but the method is not namely Method Not Allowed It would be nice if Plumber could support returning this method instead of falling back to From a cursory look at how routing is implemented this should be quite possible It might require that users add a new error handler though Steps to reproduce Configure stdout and stderr to output to different places Launch plumber through Rscript with a file like this r libraryplumber r plumbsomefileR rrunhost host port port Check the standard output and standard error that is produced Expected behavior information messages such as Starting server to listen on port should go into standard output Actual behavior information messages go into standard error instead Shiny has an option called shinyautoreload that monitors source files for changes and automatically reloads the Shiny app It would be nice if Plumber had a similar option System details Output of sessioninfosessioninfo Session info setting value version R version os Ubuntu LTS system x linuxgnu ui RStudio language EN collate enUSUTF ctype enUSUTF tz Zulu date Packages package version date lib source assertthat CRAN R backports CRAN R bit CRAN R bit CRAN R bitops CRAN R blob CRAN R brew CRAN R callr CRAN R caret CRAN R cellranger CRAN R chron CRAN R class CRAN R cli CRAN R coda CRAN R codetools CRAN R colorspace CRAN R CompatibilityAPI local crayon CRAN R datatable CRAN R dbautojoinr Github N h l sTdbautojoinr e ee DBI CRAN R dbplyr CRAN R desc CRAN R devtools CRAN R DiagrammeR CRAN R digest CRAN R downloader CRAN R dplyr CRAN R esquisse CRAN R evaluate CRAN R extrafont CRAN R extrafontdb CRAN R foreach local fs CRAN R gdtools CRAN R generics CRAN R gg D Github AckerDWMgg Dffdd ggbiplot Github vqvggbiplot e ggplot CRAN R ggpubr CRAN R ggsignif CRAN R ggthemes CRAN R glue CRAN R gower CRAN R gridExtra CRAN R gtable CRAN R hms CRAN R hrbrthemes CRAN R htmltools CRAN R htmlwidgets CRAN R httpuv CRAN R httr CRAN R igraph CRAN R influenceR CRAN R ipred CRAN R iterators local janitor CRAN R jsonlite CRAN R knitr CRAN R later CRAN R lattice CRAN R lava CRAN R lazyeval CRAN R lubridate CRAN R magrittr CRAN R MASS CRAN R Matrix CRAN R MatrixModels CRAN R mcmc CRAN R MCMCpack CRAN R memoise CRAN R MicrosoftML local mime CRAN R miniUI CRAN R misc d CRAN R ModelMetrics CRAN R mongolite CRAN R mrupdate local munsell CRAN R nlme CRAN R nnet CRAN R odbc CRAN R ore CRAN R pillar CRAN R pkgbuild CRAN R pkgconfig CRAN R pkgload CRAN R plot D CRAN R plumber CRAN R plyr CRAN R prettyunits CRAN R processx CRAN R prodlim CRAN R promises CRAN R ps CRAN R purrr CRAN R qdapTools CRAN R quantreg CRAN R R CRAN R RColorBrewer CRAN R Rcpp CRAN R RCurl CRAN R readr CRAN R readtext CRAN R readxl CRAN R recipes CRAN R remotes CRAN R reportr CRAN R reshape CRAN R RevoMods local RevoScaleR local RevoUtils local RevoUtilsMath local rgexf CRAN R rhandsontable CRAN R rjson CRAN R rlang CRAN R rmarkdown CRAN R RNifti CRAN R Rook CRAN R rpart CRAN R rprojroot CRAN R rstudioapi CRAN R Rttf pt CRAN R scales CRAN R sessioninfo CRAN R shiny CRAN R shinyWidgets CRAN R SparseM CRAN R stringi CRAN R stringr CRAN R survival CRAN R testthat CRAN R tibble CRAN R tidyr CRAN R tidyselect CRAN R tidyxl CRAN R timeDate CRAN R tractorbase CRAN R usethis CRAN R vctrs CRAN R viridis CRAN R viridisLite CRAN R visNetwork CRAN R withr CRAN R writexl CRAN R xfun CRAN R XML CRAN R xtable CRAN R yaml CRAN R zeallot CRAN R datahomen h l stRx pclinuxgnulibrary datamlserver librariesRServer datamlserver runtimeRlibrary Describe the problem in detail Because of the nature of the problem its hard to make a reproducible code However I can explain it So the error appears on the VM which runs Plumber to create a service that will do Web Scraping from several websites for sever terms The information is then transformed into a tibble saved to a MongoDB via mongolite and returned to the user as a JSON Now if a term returns few results like page or the error is never encountered However if a term returns many pages of results or tens of pages then my local computer will continue waiting for ever for Plumber in the remote VM to send the results and plumber will just hang having produced this error and never returning the results or informing the local computer that it will not Ive already searched for it and came across these topics However they reference a different issue connection reset which is not what I have witness Is there any parameter or something that I can pass to Plumber so that even if a request is taking a long time it could take minutes for all I know the connection does not get terminated Thanks for taking the time to file a feature request Please take the time to search for an existing feature request to avoid creating duplicate requests If you find an existing feature request please give it a thumbsup reaction as well use these reactions to help prioritize the implementation of these features in the future If the feature has not yet been filed then please describe the feature youd like to see become a part of plumber See Shinys guide on how to write good feature requests httpuv somewhat recently added the feature that static files can be served without calling R code On top of potential performance improvements httpuv also enables HTTP caching directives for static files so that files dont have to be retransmitted every time a page is viewed in browser for example plotly is around MB of minified javascript which is noticeable plumber could be extended with a new slot staticPaths which is a named list specifying which URLs are mapped to local directories much like assets does now I could probably prepare a pull request if wanted 