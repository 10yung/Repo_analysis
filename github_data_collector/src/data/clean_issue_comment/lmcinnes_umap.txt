I have installed both versions and for umaplearn Is there a good beginners manual to get me started yet Thanks Dave The basic example in the README hangs when using UMAP from the master or dev branch python import umap from sklearndatasets import loaddigits digits loaddigits embedding umapUMAPfittransformdigitsdata If I do pip install umaplearn then the code works as expected taking only seconds However it hangs when using a version of UMAP built from the dev branch or master It looks like it is doing something since I see the message homegclendenanaconda envsumapdebuglibpython sitepackagesumapspectralpy UserWarning Embedding a total of separate connected components using metaembedding experimental ncomponents I think the commit where this occurs is It works as expected on the commit prior to that one However I dont know enough about numbatbb to explain why this might be happening Hello Im having the same issue as in except Im on Ubuntu This occurred for several numba versions and seems to be fixed in Update the issue may be coming from llvmlite Downgrading to fixed the issue Im trying out the plotdiagnostic function in the dev branch of UMAP Im using commit fc aa with pynndescent if that matters When I run umapplotdiagnosticembedder diagnostictypelocaldim I get this error TypeError Traceback most recent call last ipythoninput e c in module localdims umapplotdiagnosticovisualembedder diagnostictypelocaldim projectsumapumapplotpy in diagnosticumapobject diagnostictype nhoodsize localvariancethreshold ax cmap pointsize background width height elif diagnostictype localdim highdindices highddists nhoodsearchumapobject umapobjectnneighbors data umapobjectrawdata localdim npemptydatashape dtypenpint projectsumapumapplotpy in nhoodsearchumapobject nhoodsize rngstate umapobjectdistancefunc umapobjectdistargs projectsumapumapnndescentpy in initialisesearchforest data querypoints nneighbors rngstate dist distargs if forest is not None for tree in forest initfromtree tree data querypoints results rngstate dist distargs TypeError NNDescent object is not iterable Itd be great to add other correlations as distances such as Spearmans rho or the new correlation coefficient called phik I am aware that its possible to use any distance metric using either metricprecomputed or implementing a custom function but itd be more convenient to pass metricspearmanrho or phik directly Hi There Im analyzing singlecell rnaseq data using scanpy on a Ubuntu virtual machine with cpus and the following package versions umaplearn installed from the dev branch earlier today pynndescent scanpy dev g f d installed from the master branch earlier today Im using the development version of umap because it is supposed to have support for parallelized computation of the nearest neighbors Specifically scanpy calls from umapumap import nearestneighbors randomstate checkrandomstaterandomstate knnindices knndists forest nearestneighbors X nneighbors randomstaterandomstate metricmetric metrickwdsmetrickwds angularangular verboseverbose the code is working but empirically is just using a single CPU It also gives the following warning message optminiconda envspy libpython sitepackagesnumbacompilerpy NumbaPerformanceWarning The keyword argument parallelTrue was specified but no transformation for parallel execution was possible To find out why try turning on parallel diagnostics see for help File optminiconda envspy libpython sitepackagesumapnndescentpy line numbanjitparallelTrue def nndescent selffuncirloc and when I turn on numba parallel diagnostics that gives the report below Any idea what is going on or if parallelized approximate nearest neighbors computations is supposed to be supported Thanks Parallel Accelerator Optimizing Function makenndescentlocalsnndescent optminiconda envspy libpython sitepackagesumapnndescentpy Parallel loop listing for Function makenndescentlocalsnndescent optminiconda envspy libpython sitepackagesumapnndescentpy loop ID numbanjitparallelTrue def nndescent data nneighbors rngstate maxcandidates niters delta rho rptreeinitTrue leafarrayNone verboseFalse nvertices datashape currentgraph makeheapdatashape nneighbors for i in rangedatashape indices rejectionsamplenneighbors datashape rngstate for j in rangeindicesshape d distdata i data indices j distargs heappushcurrentgraph i d indices j heappushcurrentgraph indices j d i if rptreeinit for n in rangeleafarrayshape for i in rangeleafarrayshape if leafarray n i break for j in rangei leafarrayshape if leafarray n j break d dist data leafarray n i data leafarray n j distargs heappush currentgraph leafarray n i d leafarray n j heappush currentgraph leafarray n j d leafarray n i for n in rangeniters if verbose print t n niters candidateneighbors buildcandidates currentgraph nvertices nneighbors maxcandidates rngstate c for i in rangenvertices for j in rangemaxcandidates p intcandidateneighbors i j if p or taurandrngstate rho continue for k in rangemaxcandidates q intcandidateneighbors i k if q or not candidateneighbors i j and not candidateneighbors i k continue d distdata p data q distargs c heappushcurrentgraph p d q c heappushcurrentgraph q d p if c delta nneighbors datashape break return deheapsortcurrentgraph Fusing loops Attempting fusion of parallel loops combines loops with similar properties Before Optimisation After Optimisation Parallel structure is already optimal Loop invariant code motion Instruction hoisting No instruction hoisting found Over the time there are a lot of issues where we have to ask for reproducible code snippets in case of problems Maybe it would be good to have an issue template that reminds people to add code that allows use to reproduce their problems as well as write us their used version Hi Ive run across an error in the transform function when trying to find neighbor samples using the rejectionsample due to my own overlooking of parameter transformqueuesize by default set to This made the while loop in the rejectionsample function never converge as the number of desired neighbors was bigger than the actual fitted population Adding a simple size test before starting rejectionsample could help other users make my mistake Thanks for your amazing work I have two UMAP transform objects that Ive trained on two separate datasets one x and one x in dimension Both of these transform objects produce a successful and reasonable embedding in dimensions using the training set I have an additional k rows of data for each of the two feature sizes and which I am using as test data When I transform the k x array into k x there is no issue However the content of the k x array that is produced when I transform the k x input array is entirely NaNs I have already verified that the inputs do not contain any NaNs or infinities Additionally taking a smaller subset of the input set such as rows also produces a x output that is full of NaNs Is there any reason why this might be the case Im wondering if perhaps there is an inherent size limit to the number of features for new data that is not a constraint on the original data I think Dynamic Time Warping DTW distance would be a nice addition when we deal with time series While searching for UMAP DTW on Google I found this implementation I didnt try it I dont know if it correctly works but I think it could be useful to add DTW to builtin distances in UMAP