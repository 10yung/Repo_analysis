Hi Im looking to parse GFF format fasta files specifically to extract the genomic fasta sequence which are after the FASTA line Heres an example gff file that has that in it Is there any way to extract those data through the rustbio API If so I might try helping implement one any particular pointers on that For the FASTA directive perhaps it makes sense to provide an iterator over the sequences as biofastaRecords consuming the reader since it is at the end of the file Thanks Our current implementation of fastq parsing does not strictly handle all valid forms of fastq In particular we do not handle when sequencequality lines are wrapped A simple failing test case to illustrate rust test fn testreadsequenceandqualityarewrappedishandled let fq static u bid description nACGT nGGGG nC n n n n n let mut reader Readernewfq let mut actual Recordnew readerread mut actualunwrap let expected Recordwithattrsid Somedescription bACGTGGGGC b asserteqactual expected This test fails with the following thread iofastqteststestreadsequenceandqualityarewrappedishandled panicked at assertion failed left right left Record id id desc Somedescription seq ACGT n qual C n right Record id id desc Somedescription seq ACGTGGGGC qual srciofastqrs As an aside it would also be worth discussing whether my expected Record is correct ie do we want to keep the newline characters in the seq member of Record and then have the method seq strip them out Or should we always strip them It would be great to come to a collective decision on how Fastq should be handled I am happy to contribute a bunch of test cases and corners cases and also implement I have many similar sequences of different lengths and need to get the consensus of them From the docs the poa module should work for this but any example provided Rustbio works fine in wasm targets both unknownunknown and wasi But it is easy to start having problems if more dependencies are added and as the scope of the library increases k yavi opened an issue about adding SingleCell Data related functions and started implementing them in Because it depends on HDF libraries for input it is not compiling in wasm targets anymore This is an example of a use case that would break Are features something that rustbio would support Or do they complicate development too much I think its fine to add all features to default and have full support for them But being able to pick a smaller feature set also allows compiling to other interesting targets even if not all functionality is supported Hi team rustbio I am excited to make my first PR contribution to this great community effort As discussed in the idea is to support parsing writing and converting various single cell cellvfeature count matrices Initial effort for comparing mtx loom H EDS CSV wrt their size loading time and memory can be found here As this is my first contribution please feel free to comment if I missed any contributor guidelines I do have a few questions whats the guidelines for logging the progress I really like progress monitors or at least being able to log at what stage the pipeline has reached but I was unsure how to do that in rustbio world What are the guidelines for propagating the Error object upstream to the library currently I am working with generic Boxdyn Error PS This PR adds the EDS based parsers I will add the support for other formats ones I have few more cycles Hi guys I was wondering if we plan to support various singlecell data analyses related packages within rustbio or may be some subecosystem As a starter Ive been writing very basic functions for parsing various matrix formats in singlecell world here My motivation with this PR is to start the discussions to questions like how should we be storing retrieving the genefeature expression data usually in the form of sparse matrix as efficiently disk space RAM usage loading time as possible What would be an optimal interim format we should use to convert one format to other In EDS repo I started to explore this a bit While working with alevin we have to deal with big matrices increasingly moving towards the order of millions of rowscells and we have to process it through other tools requiring various types of output matrix formats Id love to integrate this with rustbio as it already provides an awesome suite of libraries but not sure whats the best way to do so or more fundamentally that if my implementations are the most efficient versions possible Also Itd be great if in the future we start to integrate various other widely used tools like tSNE Umap seurat monocle etc Thanks again Firstly thank you for rustbio Im a new user and enjoying it I just want to confirm that bioalignmentpairwiseAligner does not also align the reverse complement Is there an aligner in rustbio that does The workaround is straight forward enough of course reverse complement one of the two sequences and repeat the alignment and keep the one with the better alignment score It seems like a common operation though that could benefit from a function if it doesnt already exist I set it as a draft PR to ask for comments before going further I want to have an unified one of opening a FASTA or FASTQ stream and parse it The approach here uses new enums fastxReader and fastxRecord wrapping their fasta and fastq equivalents pub enum ReaderR ioRead FASTAfastaReaderR FASTQfastqReaderR and then I implemented the FastqRead and FastaRead traits for the new fastxReader These are closed types with enums opposed to using open types defining a trait and moving trait objects around But I dont foresee this being adapted to other RecordReader formats especially GFF and BED the other available in this crate I cant do this outside rustbio because I use the Readernew method to check it is a FASTA or FASTQ file and then create the appropriate fastaReader or fastqReader struct I had to change private fields in both structs so I made the internals of the struct pubcrate to let them be initialized in the crate and I dont think the reader and line fields should be exposed in any way outside the crate I also made the read method in fastqReader more into what its counterpart in fastaReader is doing avoiding clearing the linebuf field in the beginning which defeated the purpose of setting it during the initialization in fastxReadernew TODO x more tests I only copied two from the fasta and fastq modules x finish the unimplemented bits x error handling when creating a new Reader x maybe avoid reimplementing the Records iterator docs Ive been toying with building a Wavelet tree for doing rankselect queries over arbitary alphabets It seems like the RankSelect data structure would be a great choice for the underlying bitmaps Things would be easier if the RankSelect structure supported a push operation Could this be added or is it designed to be static constructed from a BitVec and never modified